{
  "data": [
    {
      "id": "2412.00648",
      "abstract": "Rotating the activation and weight matrices to reduce the influence of outliers in large language models (LLMs) has recently attracted significant attention, particularly in the context of model quantization. Prior studies have shown that in low-precision quantization scenarios, such as 4-bit weights and 4-bit activations (W4A4), randomized Hadamard transforms can achieve significantly higher accuracy than randomized orthogonal transforms. Notably, the reason behind this phenomenon remains unknown. In this paper, we find that these transformations show substantial improvement in eliminating outliers for common tokens and achieve similar quantization error. The primary reason for the accuracy difference lies in the fact that randomized Hadamard transforms can slightly reduce the quantization error for tokens with massive activations while randomized orthogonal transforms increase the quantization error. Due to the extreme rarity of these tokens and their critical impact on model accuracy, we consider this a long-tail optimization problem, and therefore construct a simple yet effective method: a weighted loss function. Additionally, we propose an optimization strategy for the rotation matrix that involves alternating optimization of quantization parameters while employing orthogonal Procrustes transforms to refine the rotation matrix. This makes the distribution of the rotated activation values more conducive to quantization, especially for tokens with massive activations. Our method enhances the Rotated LLMs by achieving dual free, Outlier-Free and Massive Activation-Free, dubbed as DFRot. Extensive experiments demonstrate the effectiveness and efficiency of DFRot. By tuning the rotation matrix using just a single sample, DFRot achieves a perplexity improvement of 0.98 and 0.95 on W4A4KV4 and W4A4KV16, respectively, for LLaMA3-70B, a model known for its quantization challenges.",
      "authors": [
        "Jingyang Xiang",
        "Sai Qian Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-01T02:55:08+00:00",
          "link": "https://arxiv.org/abs/2412.00648v1",
          "size": "21182kb",
          "version": "v1"
        },
        {
          "date": "2024-12-03T04:14:31+00:00",
          "link": "https://arxiv.org/abs/2412.00648v2",
          "size": "21182kb",
          "version": "v2"
        },
        {
          "date": "2025-07-13T03:23:53+00:00",
          "link": "https://arxiv.org/abs/2412.00648v3",
          "size": "17622kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T15:36:44+00:00",
          "link": "https://arxiv.org/abs/2412.00648v4",
          "size": "17622kb",
          "version": "v4"
        }
      ],
      "title": "DFRot: Achieving Outlier-Free and Massive Activation-Free for Rotated LLMs with Refined Rotation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.00648",
        "PDF": "https://arxiv.org/pdf/2412.00648"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on optimization strategies for model quantization and demonstrates improvements in quantization accuracy. It does not involve processing or creation of LLM training datasets."
      },
      "tasks": [
        "Quantization"
      ],
      "repo_urls": [
        "https://github.com/jingyangxiang/dfrot"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.12355",
      "abstract": "Drug overdose remains a critical global health issue, often driven by misuse of opioids, painkillers, and psychiatric medications. Traditional research methods face limitations, whereas social media offers real-time insights into self-reported substance use and overdose symptoms. This study proposes an AI-driven NLP framework trained on annotated social media data to detect commonly used drugs and associated overdose symptoms. Using a hybrid annotation strategy with LLMs and human annotators, we applied traditional ML models, neural networks, and advanced transformer-based models. Our framework achieved 98% accuracy in multi-class and 97% in multi-label classification, outperforming baseline models by up to 8%. These findings highlight the potential of AI for supporting public health surveillance and personalized intervention strategies.",
      "authors": [
        "Muhammad Ahmad",
        "Fida Ullah",
        "Muhammad Usman",
        "Umyh Habiba",
        "ldar Batyrshin and Grigori Sidorov"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-16T02:33:19+00:00",
          "link": "https://arxiv.org/abs/2504.12355v1",
          "size": "939kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T16:35:20+00:00",
          "link": "https://arxiv.org/abs/2504.12355v2",
          "size": "942kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T05:21:49+00:00",
          "link": "https://arxiv.org/abs/2504.12355v3",
          "size": "942kb",
          "version": "v3"
        }
      ],
      "title": "Leveraging Large Language Models for Multi-Class and Multi-Label Detection of Drug Use and Overdose Symptoms on Social Media",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12355",
        "PDF": "https://arxiv.org/pdf/2504.12355"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper uses an LLM to process and annotate social media data to detect drug use, it does not primarily focus on developing new methods for data processing during LLM training."
      },
      "tasks": [
        "Multi-Label Classification",
        "MUlTI-LABEL-ClASSIFICATION"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10808",
      "abstract": "In the era of the Fourth Industrial Revolution, cybersecurity and intrusion detection systems are vital for the secure and reliable operation of IoT and IIoT environments. A key challenge in this domain is the scarcity of labeled cyber-attack data, as most industrial systems operate under normal conditions. This data imbalance, combined with the high cost of annotation, hinders the effective training of machine learning models. Moreover, rapid detection of attacks is essential, especially in critical infrastructure, to prevent large-scale disruptions. To address these challenges, we propose a real-time intrusion detection system based on a semi-supervised contrastive learning framework using the Kolmogorov-Arnold Network (KAN). Our method leverages abundant unlabeled data to distinguish between normal and attack behaviors effectively. We validate our approach on three benchmark datasets: UNSW-NB15, BoT-IoT, and Gas Pipeline, using only 2.20 percent, 1.28 percent, and 8 percent of labeled samples, respectively, to simulate real-world conditions. Experimental results show that our method outperforms existing contrastive learning-based approaches. We further compare KAN with a traditional multilayer perceptron (MLP), demonstrating KAN's superior performance in both detection accuracy and robustness under limited supervision. KAN's ability to model complex relationships and its learnable activation functions are also explored and visualized, offering interpretability and potential for rule extraction. The method supports multi-class classification and proves effective in safety-critical environments where reliability is paramount.",
      "authors": [
        "Mohammad Alikhani",
        "Reza Kazemi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Systems and Control (cs.SY)",
        "Signal Processing (eess.SP)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T21:02:34+00:00",
          "link": "https://arxiv.org/abs/2507.10808v1",
          "size": "942kb",
          "version": "v1"
        }
      ],
      "title": "Contrastive-KAN: A Semi-Supervised Intrusion Detection Framework for Cybersecurity with scarce Labeled Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10808",
        "HTML": "https://arxiv.org/html/2507.10808v1",
        "PDF": "https://arxiv.org/pdf/2507.10808"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a semi-supervised intrusion detection framework utilizing contrastive learning, without focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10871",
      "abstract": "Neurons exhibit intricate geometries within their neurite networks, which play a crucial role in processes such as signaling and nutrient transport. Accurate simulation of material transport in the networks is essential for understanding these biological phenomena but poses significant computational challenges because of the complex tree-like structures involved. Traditional approaches are time-intensive and resource-demanding, yet the inherent properties of neuron trees, which consists primarily of pipes with steady-state parabolic velocity profiles and bifurcations, provide opportunities for computational optimization. To address these challenges, we propose a Graph-Autoencoder-based Latent Dynamics Surrogate (GALDS) model, which is specifically designed to streamline the simulation of material transport in neural trees. GALDS employs a graph autoencoder to encode latent representations of the network's geometry, velocity fields, and concentration profiles. These latent space representations are then assembled into a global graph, which is subsequently used to predict system dynamics in the latent space via a trained graph latent space system dynamic model, inspired by the Neural Ordinary Differential Equations (Neural ODEs) concept. The integration of an autoencoder allows for the use of smaller graph neural network models with reduced training data requirements. Furthermore, the Neural ODE component effectively mitigates the issue of error accumulation commonly encountered in recurrent neural networks. The effectiveness of the GALDS model is demonstrated through results on eight unseen geometries and four abnormal transport examples, where our approach achieves mean relative error of 3% with maximum relative error <8% and demonstrates a 10-fold speed improvement compared to previous surrogate model approaches.",
      "authors": [
        "Tsung Yeh Hsieh",
        "Yongjie Jessica Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Medical Physics (physics.med-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T00:22:00+00:00",
          "link": "https://arxiv.org/abs/2507.10871v1",
          "size": "15886kb",
          "version": "v1"
        }
      ],
      "title": "GALDS: A Graph-Autoencoder-based Latent Dynamics Surrogate model to predict neurite material transport",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10871",
        "HTML": "https://arxiv.org/html/2507.10871v1",
        "PDF": "https://arxiv.org/pdf/2507.10871"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a Graph-Autoencoder-based model for simulating material transport in neural networks, with no mention of LLM training data processing or related techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10972",
      "abstract": "Large language models, with their strong reasoning ability and rich knowledge, have brought revolution to many tasks of AI, but their impact on sign language generation remains limited due to its complexity and unique rules. In this paper, we propose TEAch Me Sign (TEAM-Sign), treating sign language as another natural language. By fine-tuning an LLM, we enable it to learn the correspondence between text and sign language, and facilitate generation. Considering the differences between sign and spoken language, we employ a stepwise prompting strategy to extract the inherent sign language knowledge within the LLM, thereby supporting the learning and generation process. Experimental results on How2Sign and Phoenix14T datasets demonstrate that our approach effectively leverages both the sign language knowledge and reasoning capabilities of LLM to align the different distribution and grammatical rules between sign and spoken language.",
      "authors": [
        "Zhaoyi An",
        "Rei Kawakami"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T04:31:52+00:00",
          "link": "https://arxiv.org/abs/2507.10972v1",
          "size": "633kb",
          "version": "v1"
        }
      ],
      "title": "Teach Me Sign: Stepwise Prompting LLM for Sign Language Production",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10972",
        "HTML": "https://arxiv.org/html/2507.10972v1",
        "PDF": "https://arxiv.org/pdf/2507.10972"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on fine-tuning an existing LLM for sign language production, using a stepwise prompting strategy, but it does not primarily contribute to LLM training-data processing or introduce new datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11447",
      "abstract": "This paper presents a state-estimation solution for legged robots that uses a set of low-cost, compact, and lightweight sensors to achieve low-drift pose and velocity estimation under challenging locomotion conditions. The key idea is to leverage multiple inertial measurement units on different links of the robot to correct a major error source in standard proprioceptive odometry. We fuse the inertial sensor information and joint encoder measurements in an extended Kalman filter, then combine the velocity estimate from this filter with camera data in a factor-graph-based sliding-window estimator to form a visual-inertial-leg odometry method. We validate our state estimator through comprehensive theoretical analysis and hardware experiments performed using real-world robot data collected during a variety of challenging locomotion tasks. Our algorithm consistently achieves minimal position deviation, even in scenarios involving substantial ground impact, foot slippage, and sudden body rotations. A C++ implementation, along with a large-scale dataset, is available at https://github.com/ShuoYangRobotics/Cerberus2.0.",
      "authors": [
        "Shuo Yang",
        "John Z. Zhang",
        "Ibrahima Sory Sow",
        "and Zachary Manchester"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:12:56+00:00",
          "link": "https://arxiv.org/abs/2507.11447v1",
          "size": "3952kb",
          "version": "v1"
        }
      ],
      "title": "Multi-IMU Sensor Fusion for Legged Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11447",
        "PDF": "https://arxiv.org/pdf/2507.11447"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a state-estimation method for legged robots, which does not involve LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.08547",
      "abstract": "This paper studies the rational synthesis problem for multi-player games played on graphs when rational players are following subgame perfect equilibria. In these games, one player, the system, declares his strategy upfront, and the other players, composing the environment, then rationally respond by playing strategies forming a subgame perfect equilibrium. We study the complexity of the rational synthesis problem when the players have {\\omega}-regular objectives encoded as parity objectives. Our algorithm is based on an encoding into a three-player game with imperfect information, showing that the problem is in 2ExpTime. When the number of environment players is fixed, the problem is in ExpTime and is NP- and coNP-hard. Moreover, for a fixed number of players and reachability objectives, we get a polynomial algorithm.",
      "authors": [
        "V\\'eronique Bruy\\`ere",
        "Jean-Fran\\c{c}ois Raskin",
        "Alexis Reynouard",
        "Marie Van Den Bogaard"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-11T17:03:58+00:00",
          "link": "https://arxiv.org/abs/2412.08547v1",
          "size": "60kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T12:55:55+00:00",
          "link": "https://arxiv.org/abs/2412.08547v2",
          "size": "68kb",
          "version": "v2"
        }
      ],
      "title": "The Non-Cooperative Rational Synthesis Problem for Subgame Perfect Equilibria and omega-regular Objectives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.08547",
        "HTML": "https://arxiv.org/html/2412.08547v2",
        "PDF": "https://arxiv.org/pdf/2412.08547"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the rational synthesis problem for games with subgame perfect equilibria, with no relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.05397",
      "abstract": "We examine the problem of learning sequential tasks from a single visual demonstration. A key challenge arises when demonstrations are temporally misaligned due to variations in timing, differences in embodiment, or inconsistencies in execution. Existing approaches treat imitation as a distribution-matching problem, aligning individual frames between the agent and the demonstration. However, we show that such frame-level matching fails to enforce temporal ordering or ensure consistent progress. Our key insight is that matching should instead be defined at the level of sequences. We propose that perfect matching occurs when one sequence successfully covers all the subgoals in the same order as the other sequence. We present ORCA (ORdered Coverage Alignment), a dense per-timestep reward function that measures the probability of the agent covering demonstration frames in the correct order. On temporally misaligned demonstrations, we show that agents trained with the ORCA reward achieve $4.5$x improvement ($0.11 \\rightarrow 0.50$ average normalized returns) for Meta-world tasks and $6.6$x improvement ($6.55 \\rightarrow 43.3$ average returns) for Humanoid-v4 tasks compared to the best frame-level matching algorithms. We also provide empirical analysis showing that ORCA is robust to varying levels of temporal misalignment. Our code is available at https://github.com/portal-cornell/orca/",
      "authors": [
        "William Huey",
        "Huaxiaoyue Wang",
        "Anne Wu",
        "Yoav Artzi",
        "Sanjiban Choudhury"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-08T01:03:43+00:00",
          "link": "https://arxiv.org/abs/2502.05397v1",
          "size": "26380kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T18:25:48+00:00",
          "link": "https://arxiv.org/abs/2502.05397v2",
          "size": "23050kb",
          "version": "v2"
        }
      ],
      "title": "Imitation Learning from a Single Temporally Misaligned Video",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05397",
        "HTML": "https://arxiv.org/html/2502.05397v2",
        "PDF": "https://arxiv.org/pdf/2502.05397"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses imitation learning from temporally misaligned video demonstrations, which pertains to sequence alignment in agent learning, not LLM training-data processing."
      },
      "tasks": [
        "Imitation Learning"
      ],
      "repo_urls": [
        "https://github.com/portal-cornell/orca"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.12668",
      "abstract": "Rate-Splitting Multiple Access (RSMA) has been recognized as a promising multiple access technique for future wireless communication systems. Recent research demonstrates that RSMA can maintain its superiority without relying on Successive Interference Cancellation (SIC) receivers. In practical systems, SIC-free receivers are more attractive than SIC receivers because of their low complexity and latency. This paper evaluates the theoretical limits of RSMA with and without SIC receivers under finite constellations. We first derive the constellation-constrained rate expressions for RSMA. We then design algorithms based on projected subgradient ascent to optimize the precoders and maximize the weighted sum-rate or max-min fairness among users. To apply the proposed optimization algorithms to large-scale systems, one challenge lies in the exponentially increasing computational complexity brought about by the constellation-constrained rate expressions. In light of this, we propose methods to avoid such computational burden. Numerical results show that, under optimized precoders, SIC-free RSMA leads to minor losses in both weighted sum-rate and max-min fairness in comparison to RSMA with SIC receivers, making it a viable option for future implementations.",
      "authors": [
        "Sibo Zhang",
        "Bruno Clerckx",
        "David Vargas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-15T00:20:21+00:00",
          "link": "https://arxiv.org/abs/2506.12668v1",
          "size": "250kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T15:46:34+00:00",
          "link": "https://arxiv.org/abs/2506.12668v2",
          "size": "258kb",
          "version": "v2"
        }
      ],
      "title": "SIC-Free Rate-Splitting Multiple Access: Constellation-Constrained Optimization and Application to Large-Scale Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12668",
        "HTML": "https://arxiv.org/html/2506.12668v2",
        "PDF": "https://arxiv.org/pdf/2506.12668"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on Rate-Splitting Multiple Access (RSMA) in wireless communication systems, which is unrelated to processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03439",
      "abstract": "Complementation of finite automata is a basic operation used in numerous applications. The standard way to complement a nondeterministic finite automaton (NFA) is to transform it into an equivalent deterministic finite automaton (DFA) and complement the DFA. The DFA can, however, be exponentially larger than the corresponding NFA. In this paper, we study several alternative approaches to complementation, which are based either on reverse powerset construction or on two novel constructions that exploit a commonly occurring structure of NFAs. Our experiment on a large data set shows that using a different than the classical approach can in many cases yield significantly smaller complements.",
      "authors": [
        "Luk\\'a\\v{s} Hol\\'ik and Ond\\v{r}ej Leng\\'al and Juraj Major and Ad\\'ela \\v{S}t\\v{e}pkov\\'a and Jan Strej\\v{c}ek"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T09:55:16+00:00",
          "link": "https://arxiv.org/abs/2507.03439v1",
          "size": "600kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T19:29:45+00:00",
          "link": "https://arxiv.org/abs/2507.03439v2",
          "size": "605kb",
          "version": "v2"
        }
      ],
      "title": "On Complementation of Nondeterministic Finite Automata without Full Determinization (Technical Report)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03439",
        "PDF": "https://arxiv.org/pdf/2507.03439"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses alternative approaches for the complementation of nondeterministic finite automata, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06313",
      "abstract": "Transformer-based Language Models' computation and memory overhead increase quadratically as a function of sequence length. The quadratic cost poses challenges when employing LLMs for processing long sequences. In this work, we introduce \\ourmodelacronym~(Extend at Test-Time), method for extending the context length of short context Transformer-based LLMs, with constant memory requirement and linear computation overhead. ETT enable the extension of the context length at test-time by efficient fine-tuning the model's parameters on the input context, chunked into overlapping small subsequences. We evaluate ETT on LongBench by extending the context length of GPT-Large and Phi-2 up to 32 times, increasing from 1k to 32k tokens. This results in up to a 30 percent improvement in the model's accuracy. We also study how context can be stored in LLM's weights effectively and efficiently. Through a detailed ablation study, we examine which Transformer modules are most beneficial to fine-tune at test-time. Interestingly, we find that fine-tuning the second layer of the FFNs is more effective than full fine-tuning, leading to a further improvement in the models' accuracy.",
      "authors": [
        "Kiarash Zahirnia",
        "Zahra Golpayegani",
        "Walid Ahmed",
        "Yang Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T18:06:45+00:00",
          "link": "https://arxiv.org/abs/2507.06313v1",
          "size": "223kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T13:47:22+00:00",
          "link": "https://arxiv.org/abs/2507.06313v2",
          "size": "223kb",
          "version": "v2"
        }
      ],
      "title": "ETT: Expanding the Long Context Understanding Capability of LLMs at Test-Time",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06313",
        "HTML": "https://arxiv.org/html/2507.06313v2",
        "PDF": "https://arxiv.org/pdf/2507.06313"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a method (ETT) for extending context length for LLMs at test-time by fine-tuning. However, it is primarily focused on model performance improvement rather than the processing of training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10553",
      "abstract": "A three-dimensional SPH computational framework is presented for modeling fluid-structure interactions with structural deformation and failure. We combine weakly compressible SPH with a pseudo-spring-based SPH solver to capture the fluid flow and deformable structures. A unified modeling approach captures the solid boundaries and fluid-structure interfaces without penalty-based contact force. The $\\delta$-SPH technique improves the pressure calculations in the fluid phase, while structural damage is modeled using a pseudo-spring approach, with particle interactions limited to its neighbors. The present framework can capture the three-dimensional crack surfaces in structures without any computationally intensive crack-tracking algorithm or visibility criteria. The framework has been proven effective against existing models and experimental data, demonstrating high accuracy and robustness in simulating detailed fracture patterns and offering insights into the impact of hydrodynamic events on structural integrity.",
      "authors": [
        "Vishabjeet Singh",
        "Chong Peng and Md Rushdie Ibne Islam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-27T04:30:48+00:00",
          "link": "https://arxiv.org/abs/2507.10553v1",
          "size": "11627kb",
          "version": "v1"
        }
      ],
      "title": "Three-dimensional SPH modeling of brittle fracture under hydrodynamic loading",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10553",
        "HTML": "https://arxiv.org/html/2507.10553v1",
        "PDF": "https://arxiv.org/pdf/2507.10553"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a computational framework for modeling fluid-structure interactions, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10570",
      "abstract": "Hypergraphs provide a powerful framework for modeling complex systems and networks with higher-order interactions beyond simple pairwise relationships. However, graph-based clustering approaches, which focus primarily on pairwise relations, fail to represent higher-order interactions, often resulting in low-quality clustering outcomes. In this work, we introduce a novel approach for local clustering in hypergraphs based on higher-order motifs, small connected subgraphs in which nodes may be linked by interactions of any order, extending motif-based techniques previously applied to standard graphs. Our method exploits hypergraph-specific higher-order motifs to better characterize local structures and optimize motif conductance. We propose two alternative strategies for identifying local clusters around a seed hyperedge: a core-based method utilizing hypergraph core decomposition and a BFS-based method based on breadth-first exploration. We construct an auxiliary hypergraph to facilitate efficient partitioning and introduce a framework for local motif-based clustering. Extensive experiments on real-world datasets demonstrate the effectiveness of our framework and provide a comparative analysis of the two proposed clustering strategies in terms of clustering quality and computational efficiency.",
      "authors": [
        "Giuseppe F. Italiano",
        "Athanasios L. Konstantinidis",
        "Anna Mpanti",
        "Fariba Ranjbar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T14:28:08+00:00",
          "link": "https://arxiv.org/abs/2507.10570v1",
          "size": "240kb",
          "version": "v1"
        }
      ],
      "title": "Local Clustering in Hypergraphs through Higher-Order Motifs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10570",
        "HTML": "https://arxiv.org/html/2507.10570v1",
        "PDF": "https://arxiv.org/pdf/2507.10570"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses local clustering in hypergraphs using higher-order motifs, with no connection to LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11245",
      "abstract": "With the rapid development of foundation video generation technologies, long video generation models have exhibited promising research potential thanks to expanded content creation space. Recent studies reveal that the goal of long video generation tasks is not only to extend video duration but also to accurately express richer narrative content within longer videos. However, due to the lack of evaluation benchmarks specifically designed for long video generation models, the current assessment of these models primarily relies on benchmarks with simple narrative prompts (e.g., VBench). To the best of our knowledge, our proposed NarrLV is the first benchmark to comprehensively evaluate the Narrative expression capabilities of Long Video generation models. Inspired by film narrative theory, (i) we first introduce the basic narrative unit maintaining continuous visual presentation in videos as Temporal Narrative Atom (TNA), and use its count to quantitatively measure narrative richness. Guided by three key film narrative elements influencing TNA changes, we construct an automatic prompt generation pipeline capable of producing evaluation prompts with a flexibly expandable number of TNAs. (ii) Then, based on the three progressive levels of narrative content expression, we design an effective evaluation metric using the MLLM-based question generation and answering framework. (iii) Finally, we conduct extensive evaluations on existing long video generation models and the foundation generation models. Experimental results demonstrate that our metric aligns closely with human judgments. The derived evaluation outcomes reveal the detailed capability boundaries of current video generation models in narrative content expression.",
      "authors": [
        "X. Feng",
        "H. Yu",
        "M. Wu",
        "S. Hu",
        "J. Chen",
        "C. Zhu",
        "J. Wu",
        "X. Chu",
        "K. Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:19:18+00:00",
          "link": "https://arxiv.org/abs/2507.11245v1",
          "size": "24572kb",
          "version": "v1"
        }
      ],
      "title": "NarrLV: Towards a Comprehensive Narrative-Centric Evaluation for Long Video Generation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11245",
        "PDF": "https://arxiv.org/pdf/2507.11245"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark for evaluating video generation models, focusing on narrative content, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11291",
      "abstract": "Permutation patterns and pattern avoidance are central, well-studied concepts in combinatorics and computer science. Given two permutations $\\tau$ and $\\pi$, the pattern matching problem (PPM) asks whether $\\tau$ contains $\\pi$. This problem arises in various contexts in computer science and statistics and has been studied extensively in exact-, parameterized-, approximate-, property-testing- and other formulations.\n  In this paper, we study pattern matching in a \\emph{streaming setting}, when the input $\\tau$ is revealed sequentially, one element at a time. There is extensive work on the space complexity of various statistics in streams of integers. The novelty of our setting is that the input stream is \\emph{a permutation}, which allows inferring some information about future inputs. Our algorithms crucially take advantage of this fact, while existing lower bound techniques become difficult to apply.\n  We show that the complexity of the problem changes dramatically depending on the pattern~$\\pi$. The space requirement is: $\\Theta(k\\log{n})$ for the monotone patterns $\\pi = 12\\dots k$, or $\\pi = k\\dots21$, $O(\\sqrt{n\\log{n}})$ for $\\pi \\in \\{312,132\\}$, $O(\\sqrt{n} \\log n)$ for $\\pi \\in \\{231,213\\}$, and $\\widetilde{\\Theta}_{\\pi}(n)$ for all other $\\pi$. If $\\tau$ is an arbitrary sequence of integers (not necessary a permutation), we show that the complexity is $\\widetilde{\\Theta}_{\\pi}(n)$ in all except the first (monotone) cases.",
      "authors": [
        "Benjamin Aram Berendsohn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:18:04+00:00",
          "link": "https://arxiv.org/abs/2507.11291v1",
          "size": "26kb",
          "version": "v1"
        }
      ],
      "title": "Permutation patterns in streams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11291",
        "HTML": "https://arxiv.org/html/2507.11291v1",
        "PDF": "https://arxiv.org/pdf/2507.11291"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses permutation pattern matching within streaming inputs, a topic related to combinatorics and algorithm complexity, but does not discuss or contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05713",
      "abstract": "Retrieval-Augmented Generation (RAG) is a widely adopted approach for improving the factuality of large language models (LLMs) by incorporating external knowledge at inference time. Although there exist multiple RAG benchmarks for English, evaluation resources for other languages, including Russian, remain scarce and static, failing to capture the dynamic nature of real-world deployments. In this work, we present DRAGON (Dynamic RAG Benchmark On News), the first dynamic benchmark for evaluating RAG systems in Russian on a changing news corpora. DRAGON is built upon a regularly updated corpus of Russian news and public documents and supports comprehensive evaluation of both the retriever and generator components. Question generation is performed automatically with the use of Knowledge Graph constructed from the corpus and enables the extraction of four core question types aligned with distinct subgraph patterns. We release a complete evaluation framework comprising the pipeline for automatic question generation, evaluation scripts, which are potentially reusable for other languages and multilingual settings, and benchmark data. We also launch a public leaderboard to encourage community participation and comparison.",
      "authors": [
        "Fedor Chernogorskii",
        "Sergei Averkiev",
        "Liliya Kudraleeva",
        "Zaven Martirosian",
        "Maria Tikhonova",
        "Valentin Malykh",
        "Alena Fenogenova"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T06:52:43+00:00",
          "link": "https://arxiv.org/abs/2507.05713v1",
          "size": "4010kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T07:36:34+00:00",
          "link": "https://arxiv.org/abs/2507.05713v2",
          "size": "4016kb",
          "version": "v2"
        }
      ],
      "title": "DRAGON: Dynamic RAG Benchmark On News",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05713",
        "HTML": "https://arxiv.org/html/2507.05713v2",
        "PDF": "https://arxiv.org/pdf/2507.05713"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the creation of DRAGON, a dynamic benchmark for RAG systems, which involves data generation processes like automatic question generation and use of a knowledge graph. However, it primarily focuses on evaluation of retrieval-augmented systems rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10933",
      "abstract": "In this paper, we explore how large language models (LLMs) approach financial decision-making by systematically comparing their responses to those of human participants across the globe. We posed a set of commonly used financial decision-making questions to seven leading LLMs, including five models from the GPT series(GPT-4o, GPT-4.5, o1, o3-mini), Gemini 2.0 Flash, and DeepSeek R1. We then compared their outputs to human responses drawn from a dataset covering 53 nations. Our analysis reveals three main results. First, LLMs generally exhibit a risk-neutral decision-making pattern, favoring choices aligned with expected value calculations when faced with lottery-type questions. Second, when evaluating trade-offs between present and future, LLMs occasionally produce responses that appear inconsistent with normative reasoning. Third, when we examine cross-national similarities, we find that the LLMs' aggregate responses most closely resemble those of participants from Tanzania. These findings contribute to the understanding of how LLMs emulate human-like decision behaviors and highlight potential cultural and training influences embedded within their outputs.",
      "authors": [
        "Orhan Erdem",
        "Ragavi Pobbathi Ashok"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "General Economics (econ.GN)",
        "Artificial Intelligence (cs.AI)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T02:54:12+00:00",
          "link": "https://arxiv.org/abs/2507.10933v1",
          "size": "684kb",
          "version": "v1"
        }
      ],
      "title": "Artificial Finance: How AI Thinks About Money",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10933",
        "PDF": "https://arxiv.org/pdf/2507.10933"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While it involves LLMs, the paper is focused on evaluating their outputs in financial contexts, rather than on processing or engineering training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10935",
      "abstract": "Cross-view localization, the task of estimating a camera's 3-degrees-of-freedom (3-DoF) pose by aligning ground-level images with satellite images, is crucial for large-scale outdoor applications like autonomous navigation and augmented reality. Existing methods often rely on fully supervised learning, which requires costly ground-truth pose annotations. In this work, we propose GeoDistill, a Geometry guided weakly supervised self distillation framework that uses teacher-student learning with Field-of-View (FoV)-based masking to enhance local feature learning for robust cross-view localization. In GeoDistill, the teacher model localizes a panoramic image, while the student model predicts locations from a limited FoV counterpart created by FoV-based masking. By aligning the student's predictions with those of the teacher, the student focuses on key features like lane lines and ignores textureless regions, such as roads. This results in more accurate predictions and reduced uncertainty, regardless of whether the query images are panoramas or limited FoV images. Our experiments show that GeoDistill significantly improves localization performance across different frameworks. Additionally, we introduce a novel orientation estimation network that predicts relative orientation without requiring precise planar position ground truth. GeoDistill provides a scalable and efficient solution for real-world cross-view localization challenges. Code and model can be found at https://github.com/tongshw/GeoDistill.",
      "authors": [
        "Shaowen Tong",
        "Zimin Xia",
        "Alexandre Alahi",
        "Xuming He",
        "Yujiao Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T03:00:15+00:00",
          "link": "https://arxiv.org/abs/2507.10935v1",
          "size": "18082kb",
          "version": "v1"
        }
      ],
      "title": "GeoDistill: Geometry-Guided Self-Distillation for Weakly Supervised Cross-View Localization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10935",
        "HTML": "https://arxiv.org/html/2507.10935v1",
        "PDF": "https://arxiv.org/pdf/2507.10935"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses methods for improving cross-view localization via self-distillation and geometry guidance, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11115",
      "abstract": "(Induced) Subgraph Isomorphism and Maximum Common (Induced) Subgraph are fundamental problems in graph pattern matching and similarity computation. In graphs derived from time-series data or protein structures, a natural total ordering of vertices often arises from their underlying structure, such as temporal sequences or amino acid sequences. This motivates the study of problem variants that respect this inherent ordering. This paper addresses Ordered (Induced) Subgraph Isomorphism (O(I)SI) and its generalization, Maximum Common Ordered (Induced) Subgraph (MCO(I)S), which seek to find subgraph isomorphisms that preserve the vertex orderings of two given ordered graphs. Our main contributions are threefold: (1) We prove that these problems remain NP-complete even when restricted to small graph classes, such as trees of depth 2 and threshold graphs. (2) We establish a gap in computational complexity between OSI and OISI on certain graph classes. For instance, OSI is polynomial-time solvable for interval graphs with their interval orderings, whereas OISI remains NP-complete under the same setting. (3) We demonstrate that the tractability of these problems can depend on the vertex ordering. For example, while OISI is NP-complete on threshold graphs, its generalization, MCOIS, can be solved in polynomial time if the specific vertex orderings that characterize the threshold graphs are provided.",
      "authors": [
        "Haruya Imamura",
        "Yasuaki Kobayashi",
        "Yota Otachi",
        "Toshiki Saitoh",
        "Keita Sato",
        "Asahi Takaoka",
        "and Ryo Yoshinaka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:10:13+00:00",
          "link": "https://arxiv.org/abs/2507.11115v1",
          "size": "667kb",
          "version": "v1"
        }
      ],
      "title": "Finding Order-Preserving Subgraphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11115",
        "HTML": "https://arxiv.org/html/2507.11115v1",
        "PDF": "https://arxiv.org/pdf/2507.11115"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on graph pattern matching and does not address any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11135",
      "abstract": "Autonomous systems are becoming an integral part of many application domains, like in the mobility sector. However, ensuring their safe and correct behaviour in dynamic and complex environments remains a significant challenge, where systems should autonomously make decisions e.g., about manoeuvring. We propose in this paper a general collaborative approach for increasing the level of trustworthiness in the environment of operation and improve reliability and good decision making in autonomous system. In the presence of conflicting information, aggregation becomes a major issue for trustworthy decision making based on collaborative data sharing. Unlike classical approaches in the literature that rely on consensus or majority as aggregation rule, we exploit the fact that autonomous systems have different quality attributes like perception quality. We use this criteria to determine which autonomous systems are trustworthy and borrow concepts from social epistemology to define aggregation and propagation rules, used for automated decision making. We use Binary Decision Diagrams (BDDs) as formal models for beliefs aggregation and propagation, and formulate reduction rules to reduce the size of the BDDs and allow efficient computation structures for collaborative automated reasoning.",
      "authors": [
        "Selma Saidi",
        "Omar Laimona",
        "Christoph Schmickler and Dirk Ziegenbein"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:37:28+00:00",
          "link": "https://arxiv.org/abs/2507.11135v1",
          "size": "37180kb",
          "version": "v1"
        }
      ],
      "title": "Collaborative Trustworthiness for Good Decision Making in Autonomous Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11135",
        "HTML": "https://arxiv.org/html/2507.11135v1",
        "PDF": "https://arxiv.org/pdf/2507.11135"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing trustworthiness in autonomous systems through decision-making processes and does not discuss any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11362",
      "abstract": "With the increasing reliance on software and automation nowadays, tight deadlines, limited resources, and prioritization of functionality over security can lead to insecure coding practices. When not handled properly, these constraints cause unaddressed security vulnerabilities to accumulate over time, forming Security Debts (SDs). Despite their critical importance, there is limited empirical evidence on how software practitioners perceive, manage, and communicate SDs in real-world settings. In this paper, we present a qualitative empirical study based on semi-structured interviews with 22 software practitioners across various roles, organizations, and countries. We address four research questions: i) we assess software practitioners' knowledge of SDs and awareness of associated security risks, ii) we investigate their behavior towards SDs, iii) we explore common tools and strategies used to mitigate SDs, and iv) we analyze how security risks are communicated within teams and to decision makers. We observe variations in how practitioners perceive and manage SDs, with some prioritizing delivery speed over security, while others consistently maintain security as a priority. Our findings emphasize the need for stronger integration of security practices across the Software Development Life Cycle (SDLC), more consistent use of mitigation strategies, better balancing of deadlines, resources, and security-related tasks, with attention to the Confidentiality, Integrity, and Availability (CIA) triad.",
      "authors": [
        "Chaima Boufaied",
        "Taher Ghaleb",
        "Zainab Masood"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:28:28+00:00",
          "link": "https://arxiv.org/abs/2507.11362v1",
          "size": "84kb",
          "version": "v1"
        }
      ],
      "title": "Security Debt in Practice: Nuanced Insights from Practitioners",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11362",
        "HTML": "https://arxiv.org/html/2507.11362v1",
        "PDF": "https://arxiv.org/pdf/2507.11362"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on security practices and perceptions in software development and does not discuss LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.09609",
      "abstract": "We propose Score-of-Mixture Training (SMT), a novel framework for training one-step generative models by minimizing a class of divergences called the $\\alpha$-skew Jensen--Shannon divergence. At its core, SMT estimates the score of mixture distributions between real and fake samples across multiple noise levels. Similar to consistency models, our approach supports both training from scratch (SMT) and distillation using a pretrained diffusion model, which we call Score-of-Mixture Distillation (SMD). It is simple to implement, requires minimal hyperparameter tuning, and ensures stable training. Experiments on CIFAR-10 and ImageNet 64x64 show that SMT/SMD are competitive with and can even outperform existing methods.",
      "authors": [
        "Tejas Jayashankar",
        "J. Jon Ryu",
        "Gregory Wornell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-13T18:57:20+00:00",
          "link": "https://arxiv.org/abs/2502.09609v1",
          "size": "8659kb",
          "version": "v1"
        },
        {
          "date": "2025-02-14T02:32:22+00:00",
          "link": "https://arxiv.org/abs/2502.09609v2",
          "size": "8659kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T20:18:41+00:00",
          "link": "https://arxiv.org/abs/2502.09609v3",
          "size": "12883kb",
          "version": "v3"
        }
      ],
      "title": "Score-of-Mixture Training: Training One-Step Generative Models Made Simple via Score Estimation of Mixture Distributions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.09609",
        "PDF": "https://arxiv.org/pdf/2502.09609"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses score estimation for generative models and primarily focuses on model optimization and training techniques, with no specific emphasis on LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.08606",
      "abstract": "We introduce DocPolarBERT, a layout-aware BERT model for document understanding that eliminates the need for absolute 2D positional embeddings. We extend self-attention to take into account text block positions in relative polar coordinate system rather than the Cartesian one. Despite being pre-trained on a dataset more than six times smaller than the widely used IIT-CDIP corpus, DocPolarBERT achieves state-of-the-art results. These results demonstrate that a carefully designed attention mechanism can compensate for reduced pre-training data, offering an efficient and effective alternative for document understanding.",
      "authors": [
        "Benno Uthayasooriyar",
        "Antoine Ly",
        "Franck Vermet",
        "Caio Corro"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:00:56+00:00",
          "link": "https://arxiv.org/abs/2507.08606v1",
          "size": "813kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T07:51:41+00:00",
          "link": "https://arxiv.org/abs/2507.08606v2",
          "size": "813kb",
          "version": "v2"
        }
      ],
      "title": "DocPolarBERT: A Pre-trained Model for Document Understanding with Relative Polar Coordinate Encoding of Layout Structures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08606",
        "PDF": "https://arxiv.org/pdf/2507.08606"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper details advancements in document understanding models using layout-aware BERT without focusing on LLM training data processing or creation of new datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11296",
      "abstract": "Bimanual manipulation is crucial in robotics, enabling complex tasks in industrial automation and household services. However, it poses significant challenges due to the high-dimensional action space and intricate coordination requirements. While video prediction has been recently studied for representation learning and control, leveraging its ability to capture rich dynamic and behavioral information, its potential for enhancing bimanual coordination remains underexplored. To bridge this gap, we propose a unified diffusion-based framework for the joint optimization of video and action prediction. Specifically, we propose a multi-frame latent prediction strategy that encodes future states in a compressed latent space, preserving task-relevant features. Furthermore, we introduce a unidirectional attention mechanism where video prediction is conditioned on the action, while action prediction remains independent of video prediction. This design allows us to omit video prediction during inference, significantly enhancing efficiency. Experiments on two simulated benchmarks and a real-world setting demonstrate a significant improvement in the success rate over the strong baseline ACT using our method, achieving a \\textbf{24.9\\%} increase on ALOHA, an \\textbf{11.1\\%} increase on RoboTwin, and a \\textbf{32.5\\%} increase in real-world experiments. Our models and code are publicly available at https://github.com/return-sleep/Diffusion_based_imaginative_Coordination.",
      "authors": [
        "Huilin Xu",
        "Jian Ding",
        "Jiakun Xu",
        "Ruixiang Wang",
        "Jun Chen",
        "Jinjie Mai",
        "Yanwei Fu",
        "Bernard Ghanem",
        "Feng Xu",
        "Mohamed Elhoseiny"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:21:32+00:00",
          "link": "https://arxiv.org/abs/2507.11296v1",
          "size": "26195kb",
          "version": "v1"
        }
      ],
      "title": "Diffusion-Based Imaginative Coordination for Bimanual Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11296",
        "PDF": "https://arxiv.org/pdf/2507.11296"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered around a diffusion-based framework for robotic manipulation, which does not involve LLM training data processing or related tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11441",
      "abstract": "Vision AutoRegressive model (VAR) was recently introduced as an alternative to Diffusion Models (DMs) in image generation domain. In this work we focus on its adaptations, which aim to fine-tune pre-trained models to perform specific downstream tasks, like medical data generation. While for DMs there exist many techniques, adaptations for VAR remain underexplored. Similarly, differentially private (DP) adaptations-ones that aim to preserve privacy of the adaptation data-have been extensively studied for DMs, while VAR lacks such solutions. In our work, we implement and benchmark many strategies for VAR, and compare them to state-of-the-art DM adaptation strategies. We observe that VAR outperforms DMs for non-DP adaptations, however, the performance of DP suffers, which necessitates further research in private adaptations for VAR. Code is available at https://github.com/sprintml/finetuning_var_dp.",
      "authors": [
        "Kaif Shaikh",
        "Antoni Kowalczuk",
        "Franziska Boenisch",
        "Adam Dziedzic"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:05:30+00:00",
          "link": "https://arxiv.org/abs/2507.11441v1",
          "size": "84kb",
          "version": "v1"
        }
      ],
      "title": "Implementing Adaptations for Vision AutoRegressive Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11441",
        "HTML": "https://arxiv.org/html/2507.11441v1",
        "PDF": "https://arxiv.org/pdf/2507.11441"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with fine-tuning adaptations for Vision AutoRegressive models in image generation, not addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11467",
      "abstract": "Code LLMs have become extremely popular recently for modeling source code across a variety of tasks, such as generation, translation, and summarization. However, transformer-based models are limited in their capabilities to reason through structured, analytical properties of code, such as control and data flow. Previous work has explored the modeling of these properties with structured data and graph neural networks. However, these approaches lack the generative capabilities and scale of modern LLMs. In this work, we introduce a novel approach to combine the strengths of modeling both code as text and more structured forms.",
      "authors": [
        "Daniel Nichols",
        "Konstantinos Parasyris",
        "Harshitha Menon",
        "Brian R. Bartoldson",
        "Giorgis Georgakoudis",
        "Tal Ben-Nun",
        "Abhinav Bhatele"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:39:12+00:00",
          "link": "https://arxiv.org/abs/2507.11467v1",
          "size": "184kb",
          "version": "v1"
        }
      ],
      "title": "Modeling Code: Is Text All You Need?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11467",
        "HTML": "https://arxiv.org/html/2507.11467v1",
        "PDF": "https://arxiv.org/pdf/2507.11467"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a novel approach for modeling code combining text and structured data but does not focus on LLM training data processing, focusing more on model architecture and capability."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.09975",
      "abstract": "Large language models (LLMs) are quickly being adopted in a wide range of learning experiences, especially via ubiquitous and broadly accessible chat interfaces like ChatGPT and Copilot. This type of interface is readily available to students and teachers around the world, yet relatively little research has been done to assess the impact of such generic tools on student learning. Coding education is an interesting test case, both because LLMs have strong performance on coding tasks, and because LLM-powered support tools are rapidly becoming part of the workflow of professional software engineers. To help understand the impact of generic LLM use on coding education, we conducted a large-scale randomized control trial with 5,831 students from 146 countries in an online coding class in which we provided some students with access to a chat interface with GPT-4. We estimate positive benefits on exam performance for adopters, the students who used the tool, but over all students, the advertisement of GPT-4 led to a significant average decrease in exam participation. We observe similar decreases in other forms of course engagement. However, this decrease is modulated by the student's country of origin. Offering access to LLMs to students from low human development index countries increased their exam participation rate on average. Our results suggest there may be promising benefits to using LLMs in an introductory coding class, but also potential harms for engagement, which makes their longer term impact on student success unclear. Our work highlights the need for additional investigations to help understand the potential impact of future adoption and integration of LLMs into classrooms.",
      "authors": [
        "Allen Nie",
        "Yash Chandak",
        "Miroslav Suzara",
        "Ali Malik",
        "Juliette Woodrow",
        "Matt Peng",
        "Mehran Sahami",
        "Emma Brunskill",
        "Chris Piech"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-25T15:39:22+00:00",
          "link": "https://arxiv.org/abs/2407.09975v1",
          "size": "3811kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T02:39:33+00:00",
          "link": "https://arxiv.org/abs/2407.09975v2",
          "size": "3812kb",
          "version": "v2"
        }
      ],
      "title": "The GPT Surprise: Offering Large Language Model Chat in a Massive Coding Class Reduced Engagement but Increased Adopters Exam Performances",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.09975",
        "PDF": "https://arxiv.org/pdf/2407.09975"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines the impact of generic LLM chat interfaces on student engagement and performance in a coding class, without addressing LLM training data processing or dataset creation."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08297",
      "abstract": "We present Kwaipilot-AutoThink (KAT), an open-source 40B large language model developed to address the overthinking problem in reasoning-intensive tasks, where an automatic thinking training paradigm is proposed to dynamically switch between reasoning and non-reasoning modes based on task complexity. Specifically, first, we construct the dual-regime dataset based on a novel tagging pipeline and a multi-agent synthesis strategy, and then we apply Multi-Token Prediction (MTP)-enhanced knowledge distillation, enabling efficient and fine-grained reasoning transfer with minimal pretraining cost. Besides, we implement a cold-start initialization strategy that introduces mode-selection priors using majority-vote signals and intent-aware prompting. Finally, we propose Step-SRPO, a reinforcement learning algorithm that incorporates intermediate supervision into the GRPO framework, offering structured guidance over both reasoning-mode selection and response accuracy. Extensive experiments across multiple benchmarks demonstrate that KAT consistently matches or even outperforms current state-of-the-art models, including DeepSeek-R1-0528 and Qwen3-235B-A22B, across a wide range of reasoning-intensive tasks while reducing token usage by up to approximately 30\\%. Beyond academic evaluation, KAT has been successfully deployed in Kwaipilot (i.e., Kuaishou's internal coding assistant), and improves real-world development workflows with high accuracy, efficiency, and controllable reasoning behaviors. Moreover, we are actively training a 200B Mixture-of-Experts (MoE) with 40B activation parameters, where the early-stage results already demonstrate promising improvements in performance and efficiency, further showing the scalability of the AutoThink paradigm.",
      "authors": [
        "Zizheng Zhan",
        "Ken Deng",
        "Huaixi Tang",
        "Wen Xiang",
        "Kun Wu",
        "Weihao Li",
        "Wenqiang Zhu",
        "Jingxuan Xu",
        "Lecheng Huang",
        "Zongxian Feng",
        "Shaojie Wang",
        "Shangpeng Yan",
        "Xuxing Chen",
        "Jiaheng Liu",
        "Zhongyuan Peng",
        "Zuchen Gao",
        "Haoyang Huang",
        "Xiaojiang Zhang",
        "Jinghui Wang",
        "Zheng Lin",
        "Mengtong Li",
        "Huiming Wang",
        "Ziqi Zhan",
        "Yanan Wu",
        "Yuanxing Zhang",
        "Jian Yang",
        "Guang Chen",
        "Haotian Zhang",
        "Bin Chen",
        "Bing Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T04:07:10+00:00",
          "link": "https://arxiv.org/abs/2507.08297v1",
          "size": "14313kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T12:04:21+00:00",
          "link": "https://arxiv.org/abs/2507.08297v2",
          "size": "14313kb",
          "version": "v2"
        }
      ],
      "title": "KAT-V1: Kwai-AutoThink Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08297",
        "HTML": "https://arxiv.org/html/2507.08297v2",
        "PDF": "https://arxiv.org/pdf/2507.08297"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a new LLM and associated methods like multi-agent synthesis strategy for dataset construction, but the main focus is on model architecture and reasoning improvement rather than explicit data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11017",
      "abstract": "Post-training quantization (PTQ) offers an efficient approach to compressing large language models (LLMs), significantly reducing memory access and computational costs. Existing compensation-based weight calibration methods often rely on a second-order Taylor expansion to model quantization error, under the assumption that the first-order term is negligible in well-trained full-precision models. However, we reveal that the progressive compensation process introduces accumulated first-order deviations between latent weights and their full-precision counterparts, making this assumption fundamentally flawed. To address this, we propose FOEM, a novel PTQ method that explicitly incorporates first-order gradient terms to improve quantization error compensation. FOEM approximates gradients by directly computing the difference between latent and full-precision weights, avoiding the high cost and limited generalization of backpropagation-based gradient computation. This approach introduces minimal additional computational overhead. Moreover, FOEM leverages precomputed Cholesky factors to efficiently recover the inverse of Hessian submatrices in real time. Extensive experiments across a wide range of models and benchmarks demonstrate that FOEM consistently outperforms the classical GPTQ method. In 3-bit weight-only quantization, FOEM reduces the perplexity of Llama3-8B by 89.6%, and improves the 5-shot MMLU accuracy of Llama3-70B from 51.7% to 74.9%, approaching the full-precision performance of 78.6%. Furthermore, FOEM can be seamlessly integrated with advanced techniques such as GPTAQ and SpinQuant, yielding additional improvements under the challenging W4A4KV4 setting, and further narrowing the accuracy gap with full-precision baselines beyond what current state-of-the-art methods achieve. The code is available at https://github.com/Xingyu-Zheng/FOEM.",
      "authors": [
        "Xingyu Zheng",
        "Haotong Qin",
        "Yuye Li",
        "Jiakai Wang",
        "Jinyang Guo",
        "Michele Magno",
        "Xianglong Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T06:18:46+00:00",
          "link": "https://arxiv.org/abs/2507.11017v1",
          "size": "1522kb",
          "version": "v1"
        }
      ],
      "title": "First-Order Error Matters: Accurate Compensation for Quantized Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11017",
        "HTML": "https://arxiv.org/html/2507.11017v1",
        "PDF": "https://arxiv.org/pdf/2507.11017"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily discusses post-training quantization to improve computational efficiency of LLMs without addressing training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11040",
      "abstract": "We present GLOD, a transformer-first architecture for object detection in high-resolution satellite imagery. GLOD replaces CNN backbones with a Swin Transformer for end-to-end feature extraction, combined with novel UpConvMixer blocks for robust upsampling and Fusion Blocks for multi-scale feature integration. Our approach achieves 32.95\\% on xView, outperforming SOTA methods by 11.46\\%. Key innovations include asymmetric fusion with CBAM attention and a multi-path head design capturing objects across scales. The architecture is optimized for satellite imagery challenges, leveraging spatial priors while maintaining computational efficiency.",
      "authors": [
        "Nicolas Drapier",
        "Aladine Chetouani",
        "Aur\\'elien Chateigner"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T07:10:34+00:00",
          "link": "https://arxiv.org/abs/2507.11040v1",
          "size": "11509kb",
          "version": "v1"
        }
      ],
      "title": "Combining Transformers and CNNs for Efficient Object Detection in High-Resolution Satellite Imagery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11040",
        "HTML": "https://arxiv.org/html/2507.11040v1",
        "PDF": "https://arxiv.org/pdf/2507.11040"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on object detection in satellite imagery using transformers and CNNs and does not mention LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.08494",
      "abstract": "The challenge of CPU evaluation lies in the fact that user-perceived performance metrics can only be measured on an independently running system consisting of the CPU and other indispensable components, and hence it is difficult to accurately attribute the deviations in the evaluation outcomes to the differences between the CPUs. Our experiments reveal that the industry-standard CPU benchmark, SPEC CPU2017, suffers from a significant flaw: for the identical CPU, undefined configurations of other indispensable components introduce uncontrolled variability in evaluation outcomes.\n  We propose a rigorous CPU evaluation methodology. Through theoretical analysis and pioneering controlled experiments, we systematically compare our methodology against four established methodologies: the SPEC CPU 2017, two DOE variants, and one RCTs approach. The results show our methodology can achieve consistent and comparable evaluation outcomes, while others exhibit inherent limations.",
      "authors": [
        "Chenxi Wang",
        "Lei Wang",
        "Wanling Gao",
        "Fanda Fan",
        "Yuchen Su",
        "Yutong Zhou",
        "Yikang Yang",
        "Jianfeng Zhan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-13T10:28:10+00:00",
          "link": "https://arxiv.org/abs/2411.08494v1",
          "size": "4404kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T08:05:00+00:00",
          "link": "https://arxiv.org/abs/2411.08494v2",
          "size": "1212kb",
          "version": "v2"
        }
      ],
      "title": "Achieving Consistent and Comparable CPU Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.08494",
        "HTML": "https://arxiv.org/html/2411.08494v2",
        "PDF": "https://arxiv.org/pdf/2411.08494"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses CPU evaluation methodology and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19777",
      "abstract": "Recommendation fairness has recently attracted much attention. In the real world, recommendation systems are driven by user behavior, and since users with the same sensitive feature (e.g., gender and age) tend to have the same patterns, recommendation models can easily capture the strong correlation preference of sensitive features and thus cause recommendation unfairness. Diffusion model (DM) as a new generative model paradigm has achieved great success in recommendation systems. DM's ability to model uncertainty and represent diversity, and its modeling mechanism has a high degree of adaptability with the real-world recommendation process with bias. Therefore, we use DM to effectively model the fairness of recommendation and enhance the diversity. This paper proposes a FairGENerative sequential Recommendation model based on DM, FairGENRec. In the training phase, we inject random noise into the original distribution under the guidance of the sensitive feature recognition model, and a sequential denoise model is designed for the reverse reconstruction of items. Simultaneously, recommendation fairness modeling is completed by injecting multi-interests representational information that eliminates the bias of sensitive user features into the generated results. In the inference phase, the model obtains the noise in the form of noise addition by using the history interactions which is followed by reverse iteration to reconstruct the target item representation. Finally, our extensive experiments on three datasets demonstrate the dual enhancement effect of FairGENRec on accuracy and fairness, while the statistical analysis of the cases visualizes the degree of improvement on the fairness of the recommendation.",
      "authors": [
        "Yang Liu",
        "Feng Wu",
        "Xuefang Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T16:42:46+00:00",
          "link": "https://arxiv.org/abs/2506.19777v1",
          "size": "664kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T14:55:37+00:00",
          "link": "https://arxiv.org/abs/2506.19777v2",
          "size": "649kb",
          "version": "v2"
        }
      ],
      "title": "Alleviating User-Sensitive bias with Fair Generative Sequential Recommendation Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19777",
        "HTML": "https://arxiv.org/html/2506.19777v2",
        "PDF": "https://arxiv.org/pdf/2506.19777"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on recommendation fairness using a generative model, without discussing any LLM-specific training data processing or creation techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00585",
      "abstract": "In recent years, it has been found that \"grandmother cells\" in the primary visual cortex (V1) of macaques can directly recognize visual input with complex shapes. This inspires us to examine the value of these cells in promoting the research of medical image segmentation. In this paper, we design a Similarity Memory Prior Network (Sim-MPNet) for medical image segmentation. Specifically, we propose a Dynamic Memory Weights-Loss Attention (DMW-LA), which matches and remembers the category features of specific lesions or organs in medical images through the similarity memory prior in the prototype memory bank, thus helping the network to learn subtle texture changes between categories. DMW-LA also dynamically updates the similarity memory prior in reverse through Weight-Loss Dynamic (W-LD) update strategy, effectively assisting the network directly extract category features. In addition, we propose the Double-Similarity Global Internal Enhancement Module (DS-GIM) to deeply explore the internal differences in the feature distribution of input data through cosine similarity and euclidean distance. Extensive experiments on four public datasets show that Sim-MPNet has better segmentation performance than other state-of-the-art methods. Our code is available on https://github.com/vpsg-research/Sim-MPNet.",
      "authors": [
        "Hao Tang",
        "Zhiqing Guo",
        "Liejun Wang",
        "Chao Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T09:06:40+00:00",
          "link": "https://arxiv.org/abs/2507.00585v1",
          "size": "2565kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T13:49:51+00:00",
          "link": "https://arxiv.org/abs/2507.00585v2",
          "size": "1978kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T14:26:08+00:00",
          "link": "https://arxiv.org/abs/2507.00585v3",
          "size": "1978kb",
          "version": "v3"
        }
      ],
      "title": "Similarity Memory Prior is All You Need for Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00585",
        "HTML": "https://arxiv.org/html/2507.00585v3",
        "PDF": "https://arxiv.org/pdf/2507.00585"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a method for medical image segmentation using a novel neural network architecture, without discussing any aspect of LLM training data processing, collection, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06608",
      "abstract": "Monolithic serving with chunked prefill improves GPU utilization by batching prefill and decode together, but suffers from fine-grained phase interference. Engine-level prefill-decode (PD) disaggregation avoids interference but incurs higher hardware and coordination overhead. Prior intra-GPU disaggregation approaches multiplex prefill and decode within a single GPU, using SLO-based tuning guided by heuristics from offline profiling or reactive feedback loops. However, these methods respond reactively to performance issues rather than anticipating them, limiting adaptability under dynamic workloads.\n  We ask: can we achieve proactive intra-GPU disaggregation that adapts effectively to dynamic workloads? The key challenge lies in managing the conflicting resource demands of prefill and decode under varying conditions. We first show that GPU resources exhibit diminishing returns -- beyond a saturation point, more allocation yields minimal latency benefit. Second, we observe that memory bandwidth contention becomes a critical bottleneck. These insights motivate a design that dynamically partitions GPU resources across prefill and decode phases, while jointly considering compute capacity, memory footprint, and bandwidth contention.\n  Evaluated on diverse LLMs and workloads, our system Nexus achieves up to 2.2x higher throughput, 20x lower TTFT, and 2.5x lower TBT than vLLM; outperforms SGLang by up to 2x; and matches or exceeds disaggregated vLLM.",
      "authors": [
        "Xiaoxiang Shi",
        "Colin Cai",
        "Junjia Du"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T07:27:18+00:00",
          "link": "https://arxiv.org/abs/2507.06608v1",
          "size": "848kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T15:48:42+00:00",
          "link": "https://arxiv.org/abs/2507.06608v2",
          "size": "849kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T01:17:17+00:00",
          "link": "https://arxiv.org/abs/2507.06608v3",
          "size": "800kb",
          "version": "v3"
        }
      ],
      "title": "Proactive Intra-GPU Disaggregation of Prefill and Decode in LLM Serving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06608",
        "HTML": "https://arxiv.org/html/2507.06608v3",
        "PDF": "https://arxiv.org/pdf/2507.06608"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper concentrates on GPU resource allocation techniques for LLM serving, not on the collection, processing, or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11399",
      "abstract": "We consider one-dimensional hyperbolic PDEs, linear and nonlinear, with random initial data. Our focus is the {\\em pointwise statistics,} i.e., the probability measure of the solution at any fixed point in space and time. For linear hyperbolic equations, the probability density function (PDF) of these statistics satisfies the same linear PDE. For nonlinear hyperbolic PDEs, we derive a linear transport equation for the cumulative distribution function (CDF) and a nonlocal linear PDE for the PDF. Both results are valid only as long as no shocks have formed, a limitation which is inherent to the problem, as demonstrated by a counterexample. For systems of linear hyperbolic equations, we introduce the multi-point statistics and derive their evolution equations. In all of the settings we consider, the resulting PDEs for the statistics are of practical significance: they enable efficient evaluation of the random dynamics, without requiring an ensemble of solutions of the underlying PDE, and their cost is not affected by the dimension of the random parameter space. Additionally, the evolution equations for the statistics lead to a priori statistical error bounds for Monte Carlo methods (in particular, Kernel Density Estimators) when applied to hyperbolic PDEs with random data.",
      "authors": [
        "Alina Chertock",
        "Pierre Degond",
        "Amir Sagiv",
        "Li Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Analysis of PDEs (math.AP)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:09:22+00:00",
          "link": "https://arxiv.org/abs/2507.11399v1",
          "size": "1295kb",
          "version": "v1"
        }
      ],
      "title": "The Evolution of Pointwise Statistics in Hyperbolic Equations with Random Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11399",
        "HTML": "https://arxiv.org/html/2507.11399v1",
        "PDF": "https://arxiv.org/pdf/2507.11399"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on the evolution of pointwise statistics in hyperbolic equations with random data, without any connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.19106",
      "abstract": "Mining information from graph databases is becoming overly important. To approach this problem, current methods focus on identifying subgraphs with specific topologies; as of today, no work has been dedicated to jointly expressing the syntax and semantics of mining operations over rich property graphs. We define MINE GRAPH RULE, a new operator for mining association rules from property graph databases, by following a research trend that has already been pursued for relational and XML databases. We describe the syntax and semantics of the operator, which allows measuring the support and confidence of each rule, and then we show many examples of increasing complexity, thereby providing a gentle introduction to the rich expressive power of the language, which is designed to be easy-to-use by GQL experts. Although the emphasis of this paper is on providing the syntax and semantics of the MINE GRAPH RULE operator, with several examples of use, we also developed an implementation of the operator on top of Neo4j, the most successful/adopted graph database system to date; the implementation is available as a portable Neo4j plugin, which we use to showcase real-world applications. At the end of our paper, we show the execution performance in a variety of synthetically generated settings, by varying the text of operators, the size of the graph, the ratio between node types, the method for creating relationships, and the maximum support and confidence; we also show our operator at work on two real-life graphs respectively describing music playlists and archived literature, and provide interesting examples of extracted association rules.",
      "authors": [
        "Francesco Cambria",
        "Francesco Invernici",
        "Anna Bernasconi and Stefano Ceri"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-27T11:33:16+00:00",
          "link": "https://arxiv.org/abs/2406.19106v1",
          "size": "3097kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T13:30:59+00:00",
          "link": "https://arxiv.org/abs/2406.19106v2",
          "size": "1967kb",
          "version": "v2"
        }
      ],
      "title": "MINE GRAPH RULE: A New Cypher-like Operator for Mining Association Rules on Property Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.19106",
        "HTML": "https://arxiv.org/html/2406.19106v2",
        "PDF": "https://arxiv.org/pdf/2406.19106"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a new operator for mining association rules on property graphs, which is not related to LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/frinve/mine_graph_rule"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.02857",
      "abstract": "We present a novel approach to reconstruct gas and dark matter projected density maps of galaxy clusters using score-based generative modeling. Our diffusion model takes in mock SZ and X-ray images as conditional inputs, and generates realizations of corresponding gas and dark matter maps by sampling from a learned data posterior. We train and validate the performance of our model by using mock data from a cosmological simulation. The model accurately reconstructs both the mean and spread of the radial density profiles in the spatial domain, indicating that the model is able to distinguish between clusters of different mass sizes. In the spectral domain, the model achieves close-to-unity values for the bias and cross-correlation coefficients, indicating that the model can accurately probe cluster structures on both large and small scales. Our experiments demonstrate the ability of score models to learn a strong, nonlinear, and unbiased mapping between input observables and fundamental density distributions of galaxy clusters. These diffusion models can be further fine-tuned and generalized to not only take in additional observables as inputs, but also real observations and predict unknown density distributions of galaxy clusters.",
      "authors": [
        "Alan Hsu",
        "Matthew Ho",
        "Joyce Lin",
        "Carleen Markey",
        "Michelle Ntampaka",
        "Hy Trac",
        "Barnab\\'as P\\'oczos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-03T18:00:03+00:00",
          "link": "https://arxiv.org/abs/2410.02857v1",
          "size": "2337kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T21:03:29+00:00",
          "link": "https://arxiv.org/abs/2410.02857v2",
          "size": "2994kb",
          "version": "v2"
        }
      ],
      "title": "Reconstructing Galaxy Cluster Mass Maps using Score-based Generative Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.02857",
        "HTML": "https://arxiv.org/html/2410.02857",
        "PDF": "https://arxiv.org/pdf/2410.02857"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on reconstructing galaxy cluster maps using score-based generative modeling, which has no relevance to LLM training data processing."
      },
      "tasks": [
        "Unity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09688",
      "abstract": "When planning transportation whose operation requires non-consumable resources, the peak demand for allocated resources is often of higher interest than the duration of resource usage. For instance, it is more cost-effective to deliver parcels with a single truck over eight hours than to use two trucks for four hours, as long as the time suffices. To model such scenarios, we introduce the novel minimum peak cost flow over time problem, whose objective is to minimise the maximum cost at all points in time rather than minimising the integral of costs. We focus on minimising peak costs of temporally repeated flows. These are desirable for practical applications due to their simple structure. This yields the minimum-peak-cost temporally repeated flow problem (MPC-TRF).\n  We show that the simple structure of temporally repeated flows comes with the drawback of arbitrarily bad approximation ratios compared to general flows over time. Furthermore, our complexity analysis shows the integral version of MPC-TRF is strongly NP-hard, even under strong restrictions. On the positive side, we identify two benign special cases: unit-cost series-parallel networks and networks with time horizon at least twice as long as the longest path in the network (with respect to the transit time). In both cases, we show that integral optimal flows if the desired flow value equals the maximum flow value and fractional optimal flows for arbitrary flow values can be found in polynomial time. For each of these cases, we provide an explicit algorithm that constructs an optimal solution.",
      "authors": [
        "Mariia Anapolska",
        "Emma Ahrens",
        "Christina B\\\"using",
        "Felix Engelhardt",
        "Timo Gersing",
        "Corinna Mathwieser",
        "Sabrian Schmitz",
        "Sophia Wrede"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T15:50:52+00:00",
          "link": "https://arxiv.org/abs/2507.09688v1",
          "size": "52kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T12:56:09+00:00",
          "link": "https://arxiv.org/abs/2507.09688v2",
          "size": "52kb",
          "version": "v2"
        }
      ],
      "title": "Minimum-Peak-Cost Flows Over Time",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09688",
        "HTML": "https://arxiv.org/html/2507.09688v2",
        "PDF": "https://arxiv.org/pdf/2507.09688"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work focuses on optimization problems related to transportation and resource planning, unrelated to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10748",
      "abstract": "Neuromorphic systems using in-memory or event-driven computing are motivated by the need for more energy-efficient processing of artificial intelligence workloads. Emerging neuromorphic architectures aim to combine traditional digital designs with the computational efficiency of analog computing and novel device technologies. A crucial problem in the rapid exploration and co-design of such architectures is the lack of tools for fast and accurate modeling and simulation. Typical mixed-signal design tools integrate a digital simulator with an analog solver like SPICE, which is prohibitively slow for large systems. By contrast, behavioral modeling of analog components is faster, but existing approaches are fixed to specific architectures with limited energy and performance modeling. In this paper, we propose LASANA, a novel approach that leverages machine learning to derive data-driven surrogate models of analog sub-blocks in a digital backend architecture. LASANA uses SPICE-level simulations of a circuit to train ML models that predict circuit energy, performance, and behavior at analog/digital interfaces. Such models can provide energy and performance annotation on top of existing behavioral models or function as replacements to analog simulation. We apply LASANA to an analog crossbar array and a spiking neuron circuit. Running MNIST and spiking MNIST, LASANA surrogates demonstrate up to three orders of magnitude speedup over SPICE, with energy, latency, and behavioral error less than 7%, 8%, and 2%, respectively.",
      "authors": [
        "Jason Ho",
        "James A. Boyle",
        "Linshen Liu",
        "Andreas Gerstlauer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:13:45+00:00",
          "link": "https://arxiv.org/abs/2507.10748v1",
          "size": "1626kb",
          "version": "v1"
        }
      ],
      "title": "LASANA: Large-scale Surrogate Modeling for Analog Neuromorphic Architecture Exploration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10748",
        "HTML": "https://arxiv.org/html/2507.10748v1",
        "PDF": "https://arxiv.org/pdf/2507.10748"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on surrogate modeling for neuromorphic architectures and does not involve LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11287",
      "abstract": "In this paper, we study task-oriented human grasp synthesis, a new grasp synthesis task that demands both task and context awareness. At the core of our method is the task-aware contact maps. Unlike traditional contact maps that only reason about the manipulated object and its relation with the hand, our enhanced maps take into account scene and task information. This comprehensive map is critical for hand-object interaction, enabling accurate grasping poses that align with the task. We propose a two-stage pipeline that first constructs a task-aware contact map informed by the scene and task. In the subsequent stage, we use this contact map to synthesize task-oriented human grasps. We introduce a new dataset and a metric for the proposed task to evaluate our approach. Our experiments validate the importance of modeling both scene and task, demonstrating significant improvements over existing methods in both grasp quality and task performance. See our project page for more details: https://hcis-lab.github.io/TOHGS/",
      "authors": [
        "An-Lun Liu",
        "Yu-Wei Chao",
        "Yi-Ting Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:11:55+00:00",
          "link": "https://arxiv.org/abs/2507.11287v1",
          "size": "33412kb",
          "version": "v1"
        }
      ],
      "title": "Task-Oriented Human Grasp Synthesis via Context- and Task-Aware Diffusers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11287",
        "HTML": "https://arxiv.org/html/2507.11287v1",
        "PDF": "https://arxiv.org/pdf/2507.11287"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies human grasp synthesis for robotic tasks, involving task-aware contact maps, but does not involve LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11419",
      "abstract": "Bilateral trade is a central problem in algorithmic economics, and recent work has explored how to design trading mechanisms using no-regret learning algorithms. However, no-regret learning is impossible when budget balance has to be enforced at each time step. Bernasconi et al. [Ber+24] show how this impossibility can be circumvented by relaxing the budget balance constraint to hold only globally over all time steps. In particular, they design an algorithm achieving regret of the order of $\\tilde O(T^{3/4})$ and provide a lower bound of $\\Omega(T^{5/7})$.\n  In this work, we interpolate between these two extremes by studying how the optimal regret rate varies with the allowed violation of the global budget balance constraint. Specifically, we design an algorithm that, by violating the constraint by at most $T^{\\beta}$ for any given $\\beta \\in [\\frac{3}{4}, \\frac{6}{7}]$, attains regret $\\tilde O(T^{1 - \\beta/3})$. We complement this result with a matching lower bound, thus fully characterizing the trade-off between regret and budget violation. Our results show that both the $\\tilde O(T^{3/4})$ upper bound in the global budget balance case and the $\\Omega(T^{5/7})$ lower bound under unconstrained budget balance violation obtained by Bernasconi et al. [Ber+24] are tight.",
      "authors": [
        "Anna Lunghi",
        "Matteo Castiglioni",
        "Alberto Marchesi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:45:36+00:00",
          "link": "https://arxiv.org/abs/2507.11419v1",
          "size": "86kb",
          "version": "v1"
        }
      ],
      "title": "Better Regret Rates in Bilateral Trade via Sublinear Budget Violation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11419",
        "HTML": "https://arxiv.org/html/2507.11419v1",
        "PDF": "https://arxiv.org/pdf/2507.11419"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered around algorithmic economics and trading mechanisms with no aspects related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.06779",
      "abstract": "Learning intrinsic bias from limited data has been considered the main reason for the failure of deepfake detection with generalizability. Apart from the discovered content and specific-forgery bias, we reveal a novel spatial bias, where detectors inertly anticipate observing structural forgery clues appearing at the image center, also can lead to the poor generalization of existing methods. We present ED$^4$, a simple and effective strategy, to address aforementioned biases explicitly at the data level in a unified framework rather than implicit disentanglement via network design. In particular, we develop ClockMix to produce facial structure preserved mixtures with arbitrary samples, which allows the detector to learn from an exponentially extended data distribution with much more diverse identities, backgrounds, local manipulation traces, and the co-occurrence of multiple forgery artifacts. We further propose the Adversarial Spatial Consistency Module (AdvSCM) to prevent extracting features with spatial bias, which adversarially generates spatial-inconsistent images and constrains their extracted feature to be consistent. As a model-agnostic debiasing strategy, ED$^4$ is plug-and-play: it can be integrated with various deepfake detectors to obtain significant benefits. We conduct extensive experiments to demonstrate its effectiveness and superiority over existing deepfake detection approaches.",
      "authors": [
        "Jikang Cheng",
        "Ying Zhang",
        "Qin Zou",
        "Zhiyuan Yan",
        "Chao Liang",
        "Zhongyuan Wang",
        "Chen Li"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-13T10:05:20+00:00",
          "link": "https://arxiv.org/abs/2408.06779v1",
          "size": "2017kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T13:53:15+00:00",
          "link": "https://arxiv.org/abs/2408.06779v2",
          "size": "1368kb",
          "version": "v2"
        }
      ],
      "title": "ED$^4$: Explicit Data-level Debiasing for Deepfake Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.06779",
        "HTML": "https://arxiv.org/html/2408.06779v2",
        "PDF": "https://arxiv.org/pdf/2408.06779"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes ED^4, a data-level debiasing strategy aimed at improving data quality by addressing biases in deepfake detection, involving techniques like data augmentation via ClockMix. This directly contributes to improving the quality of data, thus fitting the 'core' category for data processing."
      },
      "tasks": [
        "DeepFake Detection",
        "Disentanglement",
        "Face Swapping"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05297",
      "abstract": "We prove that any optimal, independent, and zero unanimous fuzzy classification aggregation function of a continuum of individual classifications of $m\\ge 3$ objects into $2\\le p\\le m$ types must be a weighted arithmetic mean. We also provide a characterization for the case when $m=p=2$.",
      "authors": [
        "Zijun Meng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Theoretical Economics (econ.TH)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T09:13:22+00:00",
          "link": "https://arxiv.org/abs/2507.05297v1",
          "size": "4kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T08:41:46+00:00",
          "link": "https://arxiv.org/abs/2507.05297v2",
          "size": "99kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T16:18:21+00:00",
          "link": "https://arxiv.org/abs/2507.05297v3",
          "size": "100kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T09:53:58+00:00",
          "link": "https://arxiv.org/abs/2507.05297v4",
          "size": "320kb",
          "version": "v4"
        }
      ],
      "title": "Continuous Classification Aggregation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05297",
        "HTML": "https://arxiv.org/html/2507.05297",
        "PDF": "https://arxiv.org/pdf/2507.05297"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses optimal fuzzy classification aggregation functions and provides theoretical characterizations, with no relevance to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10844",
      "abstract": "Object detection traditionally relies on fixed category sets, requiring costly re-training to handle novel objects. While Open-World and Open-Vocabulary Object Detection (OWOD and OVOD) improve flexibility, OWOD lacks semantic labels for unknowns, and OVOD depends on user prompts, limiting autonomy. We propose an LLM-guided agentic object detection (LAOD) framework that enables fully label-free, zero-shot detection by prompting a Large Language Model (LLM) to generate scene-specific object names. These are passed to an open-vocabulary detector for localization, allowing the system to adapt its goals dynamically. We introduce two new metrics, Class-Agnostic Average Precision (CAAP) and Semantic Naming Average Precision (SNAP), to separately evaluate localization and naming. Experiments on LVIS, COCO, and COCO-OOD validate our approach, showing strong performance in detecting and naming novel objects. Our method offers enhanced autonomy and adaptability for open-world understanding.",
      "authors": [
        "Furkan Mumcu",
        "Michael J. Jones",
        "Anoop Cherian",
        "Yasin Yilmaz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T22:30:48+00:00",
          "link": "https://arxiv.org/abs/2507.10844v1",
          "size": "734kb",
          "version": "v1"
        }
      ],
      "title": "LLM-Guided Agentic Object Detection for Open-World Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10844",
        "HTML": "https://arxiv.org/html/2507.10844v1",
        "PDF": "https://arxiv.org/pdf/2507.10844"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper leverages LLMs to assist in object detection, it does not focus on the processing or creation of LLM training data but rather uses LLMs in a novel application context."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.08933",
      "abstract": "Although deep neural networks are well-known for their outstanding performance in tackling complex tasks, their hunger for computational resources remains a significant hurdle, posing energy-consumption issues and restricting their deployment on resource-constrained devices, preventing their widespread adoption. In this paper, we present an optimal transport-based method to reduce the depth of over-parametrized deep neural networks, alleviating their computational burden. More specifically, we propose a new regularization strategy based on the Max-Sliced Wasserstein distance to minimize the distance between the intermediate feature distributions in the neural network. We show that minimizing this distance enables the complete removal of intermediate layers in the network, achieving better performance/depth trade-off compared to existing techniques. We assess the effectiveness of our method on traditional image classification setups and extend it to generative image models. Our code is available at https://github.com/VGCQ/LaCoOT.",
      "authors": [
        "Victor Qu\\'etu",
        "Zhu Liao",
        "Nour Hezbri",
        "Fabio Pizzati",
        "Enzo Tartaglione"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-13T09:03:53+00:00",
          "link": "https://arxiv.org/abs/2406.08933v1",
          "size": "265kb",
          "version": "v1"
        },
        {
          "date": "2025-07-07T12:01:32+00:00",
          "link": "https://arxiv.org/abs/2406.08933v2",
          "size": "7380kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T08:40:26+00:00",
          "link": "https://arxiv.org/abs/2406.08933v3",
          "size": "7391kb",
          "version": "v3"
        }
      ],
      "title": "LaCoOT: Layer Collapse through Optimal Transport",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.08933",
        "HTML": "https://arxiv.org/html/2406.08933v3",
        "PDF": "https://arxiv.org/pdf/2406.08933"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for reducing the depth of neural networks, which is related to model efficiency, not LLM training data processing."
      },
      "tasks": [
        "image-classification",
        "Image Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08831",
      "abstract": "Vision-Language Navigation in Continuous Environments (VLNCE), where an agent follows instructions and moves freely to reach a destination, is a key research problem in embodied AI. However, most navigation policies are sensitive to viewpoint changes, i.e., variations in camera height and viewing angle that alter the agent's observation. In this paper, we introduce a generalized scenario, V2-VLNCE (VLNCE with Varied Viewpoints), and propose VIL (View Invariant Learning), a view-invariant post-training strategy that enhances the robustness of existing navigation policies to changes in camera viewpoint. VIL employs a contrastive learning framework to learn sparse and view-invariant features. Additionally, we introduce a teacher-student framework for the Waypoint Predictor Module, a core component of most VLNCE baselines, where a view-dependent teacher model distills knowledge into a view-invariant student model. We employ an end-to-end training paradigm to jointly optimize these components, thus eliminating the cost for individual module training. Empirical results show that our method outperforms state-of-the-art approaches on V2-VLNCE by 8-15% measured on Success Rate for two standard benchmark datasets R2R-CE and RxR-CE. Furthermore, we evaluate VIL under the standard VLNCE setting and find that, despite being trained for varied viewpoints, it often still improves performance. On the more challenging RxR-CE dataset, our method also achieved state-of-the-art performance across all metrics when compared to other map-free methods. This suggests that adding VIL does not diminish the standard viewpoint performance and can serve as a plug-and-play post-training method.",
      "authors": [
        "Josh Qixuan Sun",
        "Xiaoying Xing",
        "Huaiyuan Weng",
        "Chul Min Yeum",
        "Mark Crowley"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T18:04:35+00:00",
          "link": "https://arxiv.org/abs/2507.08831v1",
          "size": "3427kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T01:49:08+00:00",
          "link": "https://arxiv.org/abs/2507.08831v2",
          "size": "3429kb",
          "version": "v2"
        }
      ],
      "title": "View Invariant Learning for Vision-Language Navigation in Continuous Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08831",
        "HTML": "https://arxiv.org/html/2507.08831v2",
        "PDF": "https://arxiv.org/pdf/2507.08831"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses vision-language navigation and introduces a technique for viewpoint invariance. It does not involve any processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10750",
      "abstract": "Thanks to the availability of massive amounts of data, computing resources, and advanced algorithms, AI has entered nearly every sector. This has sparked significant investment and interest, particularly in building data centers with the necessary hardware and software to develop and operate AI models and AI-based workflows. In this technical review article, we present energy consumption scenarios of data centers and impact on GHG emissions, considering both near-term projections (up to 2030) and long-term outlook (2035 and beyond). We address the quintessential question of whether AI will have a net positive, neutral, or negative impact on CO2 emissions by 2035. Additionally, we discuss AI's potential to automate, create efficient and disruptive workflows across various fields related to energy production, supply and consumption. In the near-term scenario, the growing demand for AI will likely strain computing resources, lead to increase in electricity consumption and therefore associated CO2 emissions. This is due to the power-hungry nature of big data centers and the requirements for training and running of large and complex AI models, as well as the penetration of AI assistant search and applications for public use. However, the long-term outlook could be more promising. AI has the potential to be a game-changer in CO2 reduction. Its ability to further automate and optimize processes across industries, from energy production to logistics, could significantly decrease our carbon footprint. This positive impact is anticipated to outweigh the initial emissions bump, creating value for businesses and society in areas where traditional solutions have fallen short. In essence, AI might cause some initial growing pains for the environment, but it has the potential to support climate mitigation efforts.",
      "authors": [
        "Pandu Devarakota",
        "Nicolas Tsesmetzis",
        "Faruk O. Alpak",
        "Apurva Gala",
        "Detlef Hohl"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:16:27+00:00",
          "link": "https://arxiv.org/abs/2507.10750v1",
          "size": "1837kb",
          "version": "v1"
        }
      ],
      "title": "AI and the Net-Zero Journey: Energy Demand, Emissions, and the Potential for Transition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10750",
        "HTML": "https://arxiv.org/html/2507.10750v1",
        "PDF": "https://arxiv.org/pdf/2507.10750"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a technical review about AI's impact on energy consumption and emissions but does not involve LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11004",
      "abstract": "This paper presents HerO 2, Team HUMANE's system for the AVeriTeC shared task at the FEVER-25 workshop. HerO 2 is an enhanced version of HerO, the best-performing open-source model from the previous year's challenge. It improves evidence quality through document summarization and answer reformulation, optimizes veracity prediction via post-training quantization under computational constraints, and enhances overall system performance by integrating updated language model (LM) backbones. HerO 2 ranked second on the leaderboard while achieving the shortest runtime among the top three systems, demonstrating both high efficiency and strong potential for real-world fact verification. The code is available at https://github.com/ssu-humane/HerO2.",
      "authors": [
        "Yejun Yoon",
        "Jaeyoon Jung",
        "Seunghyun Yoon",
        "and Kunwoo Park"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T05:42:50+00:00",
          "link": "https://arxiv.org/abs/2507.11004v1",
          "size": "319kb",
          "version": "v1"
        }
      ],
      "title": "Team HUMANE at AVeriTeC 2025: HerO 2 for Efficient Fact Verification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11004",
        "HTML": "https://arxiv.org/html/2507.11004v1",
        "PDF": "https://arxiv.org/pdf/2507.11004"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces HerO 2, a system for fact verification with improved performance through model enhancements, and does not discuss LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11119",
      "abstract": "Hard samples pose a significant challenge in person re-identification (ReID) tasks, particularly in clothing-changing person Re-ID (CC-ReID). Their inherent ambiguity or similarity, coupled with the lack of explicit definitions, makes them a fundamental bottleneck. These issues not only limit the design of targeted learning strategies but also diminish the model's robustness under clothing or viewpoint changes. In this paper, we propose a novel multimodal-guided Hard Sample Generation and Learning (HSGL) framework, which is the first effort to unify textual and visual modalities to explicitly define, generate, and optimize hard samples within a unified paradigm. HSGL comprises two core components: (1) Dual-Granularity Hard Sample Generation (DGHSG), which leverages multimodal cues to synthesize semantically consistent samples, including both coarse- and fine-grained hard positives and negatives for effectively increasing the hardness and diversity of the training data. (2) Hard Sample Adaptive Learning (HSAL), which introduces a hardness-aware optimization strategy that adjusts feature distances based on textual semantic labels, encouraging the separation of hard positives and drawing hard negatives closer in the embedding space to enhance the model's discriminative capability and robustness to hard samples. Extensive experiments on multiple CC-ReID benchmarks demonstrate the effectiveness of our approach and highlight the potential of multimodal-guided hard sample generation and learning for robust CC-ReID. Notably, HSAL significantly accelerates the convergence of the targeted learning procedure and achieves state-of-the-art performance on both PRCC and LTCC datasets. The code is available at https://github.com/undooo/TryHarder-ACMMM25.",
      "authors": [
        "Hankun Liu",
        "Yujian Zhao",
        "Guanglin Niu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:14:01+00:00",
          "link": "https://arxiv.org/abs/2507.11119v1",
          "size": "19592kb",
          "version": "v1"
        }
      ],
      "title": "Try Harder: Hard Sample Generation and Learning for Clothes-Changing Person Re-ID",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11119",
        "HTML": "https://arxiv.org/html/2507.11119v1",
        "PDF": "https://arxiv.org/pdf/2507.11119"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on generating hard samples for person re-identification tasks, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11193",
      "abstract": "Starting from a recent a posteriori error estimator for the finite element solution of the wave equation with explicit time-stepping [Grote, Lakkis, Santos, 2024], we devise a space-time adaptive strategy which includes both time evolving meshes and local time-stepping [Diaz, Grote, 2009] to overcome any overly stringent CFL stability restriction on the time-step due to local mesh refinement. Moreover, at each time-step the adaptive algorithm monitors the accuracy thanks to the error indicators and recomputes the current step on a refined mesh until the desired tolerance is met; meanwhile, the mesh is coarsened in regions of smaller errors. Leapfrog based local time-stepping is applied in all regions of local mesh refinement to incorporate adaptivity into fully explicit time integration with mesh change while retaining efficiency. Numerical results illustrate the optimal rate of convergence of the a posteriori error estimators on time evolving meshes.",
      "authors": [
        "Marcus J. Grote",
        "Omar Lakkis",
        "Carina S. Santos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:53:57+00:00",
          "link": "https://arxiv.org/abs/2507.11193v1",
          "size": "3845kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive FEM with explicit time integration for the wave equation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11193",
        "HTML": "https://arxiv.org/html/2507.11193v1",
        "PDF": "https://arxiv.org/pdf/2507.11193"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Discusses adaptive finite element methods for wave equations, without any connection to LLM training data engineering or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.08513",
      "abstract": "Explainable AI (XAI) and interpretable machine learning methods help to build trust in model predictions and derived insights, yet also present a perverse incentive for analysts to manipulate XAI metrics to support pre-specified conclusions. This paper introduces the concept of X-hacking, a form of p-hacking applied to XAI metrics such as SHAP values. We show how easily an automated machine learning pipeline can be adapted to exploit model multiplicity at scale: searching a Rashomon set of 'defensible' models with similar predictive performance to find a desired explanation. We formulate the trade-off between explanation and accuracy as a multi-objective optimisation problem, and illustrate empirically on familiar real-world datasets that, on average, Bayesian optimisation accelerates X-hacking 3-fold for features susceptible to it, versus random sampling. We show the vulnerability of a dataset to X-hacking can be determined by information redundancy among features. Finally, we suggest possible methods for detection and prevention, and discuss ethical implications for the credibility and reproducibility of XAI.",
      "authors": [
        "Rahul Sharma",
        "Sergey Redyuk",
        "Sumantrak Mukherjee",
        "Andrea \\v{S}ipka",
        "Eyke H\\\"ullermeier",
        "Sebastian Vollmer",
        "David Selby"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-16T17:21:33+00:00",
          "link": "https://arxiv.org/abs/2401.08513v1",
          "size": "4034kb",
          "version": "v1"
        },
        {
          "date": "2024-02-12T14:53:33+00:00",
          "link": "https://arxiv.org/abs/2401.08513v2",
          "size": "4108kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T15:11:53+00:00",
          "link": "https://arxiv.org/abs/2401.08513v3",
          "size": "4788kb",
          "version": "v3"
        }
      ],
      "title": "X Hacking: The Threat of Misguided AutoML",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.08513",
        "HTML": "https://arxiv.org/html/2401.08513v3",
        "PDF": "https://arxiv.org/pdf/2401.08513"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the manipulation of explainable AI (XAI) metrics and optimization in machine learning pipelines, without discussing LLM training-data processing or engineering."
      },
      "tasks": [
        "AutoML",
        "Interpretable Machine Learning"
      ],
      "repo_urls": [
        "https://github.com/selbosh/p-hacking"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.21033",
      "abstract": "We present Plancraft, a multi-modal evaluation dataset for LLM agents. Plancraft has both a text-only and multi-modal interface, based on the Minecraft crafting GUI. We include the Minecraft Wiki to evaluate tool use and Retrieval Augmented Generation (RAG), as well as a handcrafted planner and Oracle Retriever, to ablate the different components of a modern agent architecture. To evaluate decision-making, Plancraft also includes a subset of examples that are intentionally unsolvable, providing a realistic challenge that requires the agent not only to complete tasks but also to decide whether they are solvable at all. We benchmark both open-source and closed-source LLMs and compare their performance and efficiency to a handcrafted planner. Overall, we find that LLMs and VLMs struggle with the planning problems that Plancraft introduces, and offer suggestions on how to improve their capabilities.",
      "authors": [
        "Gautier Dagan",
        "Frank Keller",
        "Alex Lascarides"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-30T15:58:41+00:00",
          "link": "https://arxiv.org/abs/2412.21033v1",
          "size": "418kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T09:27:28+00:00",
          "link": "https://arxiv.org/abs/2412.21033v2",
          "size": "367kb",
          "version": "v2"
        }
      ],
      "title": "Plancraft: an evaluation dataset for planning with LLM agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.21033",
        "HTML": "https://arxiv.org/html/2412.21033v2",
        "PDF": "https://arxiv.org/pdf/2412.21033"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces an evaluation dataset for LLM agents but focuses on benchmarking and tool use evaluation rather than LLM training data processing or engineering."
      },
      "tasks": [
        "Decision Making",
        "Minecraft",
        "RAG",
        "Retrieval-augmented Generation"
      ],
      "repo_urls": [
        "https://github.com/gautierdag/plancraft"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.22803",
      "abstract": "Recent advances in deep learning have led to increasingly complex models with deeper layers and more parameters, reducing interpretability and making their decisions harder to understand. While many methods explain black-box reasoning, most lack effective interventions or only operate at sample-level without modifying the model itself. To address this, we propose the Concept Bottleneck Model for Enhancing Human-Neural Network Mutual Understanding (CBM-HNMU). CBM-HNMU leverages the Concept Bottleneck Model (CBM) as an interpretable framework to approximate black-box reasoning and communicate conceptual understanding. Detrimental concepts are automatically identified and refined (removed/replaced) based on global gradient contributions. The modified CBM then distills corrected knowledge back into the black-box model, enhancing both interpretability and accuracy. We evaluate CBM-HNMU on various CNN and transformer-based models across Flower-102, CIFAR-10, CIFAR-100, FGVC-Aircraft, and CUB-200, achieving a maximum accuracy improvement of 2.64% and a maximum increase in average accuracy across 1.03%. Source code is available at: https://github.com/XiGuaBo/CBM-HNMU.",
      "authors": [
        "Nuoye Xiong",
        "Anqi Dong",
        "Ning Wang",
        "Cong Hua",
        "Guangming Zhu",
        "Lin Mei",
        "Peiyi Shen",
        "Liang Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T08:11:29+00:00",
          "link": "https://arxiv.org/abs/2506.22803v1",
          "size": "34443kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T14:13:41+00:00",
          "link": "https://arxiv.org/abs/2506.22803v2",
          "size": "10752kb",
          "version": "v2"
        }
      ],
      "title": "Intervening in Black Box: Concept Bottleneck Model for Enhancing Human Neural Network Mutual Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22803",
        "HTML": "https://arxiv.org/html/2506.22803v2",
        "PDF": "https://arxiv.org/pdf/2506.22803"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on model interpretability and modifying neural networks rather than processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10637",
      "abstract": "Continual learning in computer vision requires that models adapt to a continuous stream of tasks without forgetting prior knowledge, yet existing approaches often tip the balance heavily toward either plasticity or stability. We introduce RDBP, a simple, low-overhead baseline that unites two complementary mechanisms: ReLUDown, a lightweight activation modification that preserves feature sensitivity while preventing neuron dormancy, and Decreasing Backpropagation, a biologically inspired gradient-scheduling scheme that progressively shields early layers from catastrophic updates. Evaluated on the Continual ImageNet benchmark, RDBP matches or exceeds the plasticity and stability of state-of-the-art methods while reducing computational cost. RDBP thus provides both a practical solution for real-world continual learning and a clear benchmark against which future continual learning strategies can be measured.",
      "authors": [
        "\\'E. K\\\"unzel",
        "A. Jaziri",
        "V. Ramesh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:18:26+00:00",
          "link": "https://arxiv.org/abs/2507.10637v1",
          "size": "2144kb",
          "version": "v1"
        }
      ],
      "title": "A Simple Baseline for Stable and Plastic Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10637",
        "HTML": "https://arxiv.org/html/2507.10637v1",
        "PDF": "https://arxiv.org/pdf/2507.10637"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a baseline for continual learning in computer vision, which does not involve LLM training data processing or engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10733",
      "abstract": "Backdoor attacks involve either poisoning the training data or directly modifying the model in order to implant a hidden behavior, that causes the model to misclassify inputs when a specific trigger is present. During inference, the model maintains high accuracy on benign samples but misclassifies poisoned samples into an attacker-specified target class. Existing research on backdoor attacks has explored developing triggers in the spatial, spectral (frequency), and semantic (feature) domains, aiming to make them stealthy. While some approaches have considered designing triggers that are imperceptible in both spatial and spectral domains, few have incorporated the semantic domain. In this paper, we propose a novel backdoor attack, termed 3S-attack, which is stealthy across the spatial, spectral, and semantic domains. The key idea is to exploit the semantic features of benign samples as triggers, using Gradient-weighted Class Activation Mapping (Grad-CAM) and a preliminary model for extraction. The trigger is then embedded in the spectral domain, followed by pixel-level restrictions after converting the samples back to the spatial domain. This process minimizes the distance between poisoned and benign samples, making the attack harder to detect by existing defenses and human inspection. Extensive experiments on various datasets, along with theoretical analysis, demonstrate the stealthiness of 3S-attack and highlight the need for stronger defenses to ensure AI security. Our code is available at: https://anonymous.4open.science/r/anon-project-3776/",
      "authors": [
        "Jianyao Yin",
        "Luca Arnaboldi",
        "Honglong Chen",
        "Pascal Berrang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:56:55+00:00",
          "link": "https://arxiv.org/abs/2507.10733v1",
          "size": "1498kb",
          "version": "v1"
        }
      ],
      "title": "3S-Attack: Spatial, Spectral and Semantic Invisible Backdoor Attack Against DNN Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10733",
        "HTML": "https://arxiv.org/html/2507.10733v1",
        "PDF": "https://arxiv.org/pdf/2507.10733"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on backdoor attacks in DNN models and does not address the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10838",
      "abstract": "We address deterministic resource allocation in point-to-point multi-terminal AWGN channels without inter-terminal interference, with particular focus on optimizing quantile transmission rates for cell-edge terminal service. Classical utility-based approaches -- such as minimum rate, sumrate, and proportional fairness -- are either overconservative, or inappropriate, or do not provide a rigorous and/or interpretable foundation for fair rate optimization at the edge. To overcome these challenges, we employ Conditional Value-at-Risk (CVaR), a popular coherent risk measure, and establish its equivalence with the sum-least-$\\alpha$th-quantile (SL$\\alpha$Q) utility. This connection enables an exact convex reformulation of the SL$\\alpha$Q maximization problem, facilitating analytical tractability and precise and interpretable control over cell-edge terminal performance. Utilizing Lagrangian duality, we provide (for the first time) parameterized closed-form solutions for the optimal resource policy -- which is of waterfilling-type -- as well as the associated (auxiliary) Value-at-Risk variable. We further develop a novel inexact dual subgradient descent algorithm of minimal complexity to determine globally optimal resource policies, and we rigorously establish its convergence. The resulting edge waterfilling algorithm iteratively and efficiently allocates resources while explicitly ensuring transmission rate fairness across (cell-edge) terminals. Several (even large-scale) numerical experiments validate the effectiveness of the proposed method for enabling robust quantile rate optimization at the edge.",
      "authors": [
        "Gokberk Yaylali",
        "Ahmad Ali Khan",
        "Dionysios S. Kalogerias"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T22:13:54+00:00",
          "link": "https://arxiv.org/abs/2507.10838v1",
          "size": "192kb",
          "version": "v1"
        }
      ],
      "title": "Waterfilling at the Edge: Optimal Percentile Resource Allocation via Risk-Averse Reduction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10838",
        "HTML": "https://arxiv.org/html/2507.10838v1",
        "PDF": "https://arxiv.org/pdf/2507.10838"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses resource allocation in communication systems, which is unrelated to LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2208.02656",
      "abstract": "Representation learning algorithms offer the opportunity to learn invariant representations of the input data with regard to nuisance factors. Many authors have leveraged such strategies to learn fair representations, i.e., vectors where information about sensitive attributes is removed. These methods are attractive as they may be interpreted as minimizing the mutual information between a neural layer's activations and a sensitive attribute. However, the theoretical grounding of such methods relies either on the computation of infinitely accurate adversaries or on minimizing a variational upper bound of a mutual information estimate. In this paper, we propose a methodology for direct computation of the mutual information between a neural layer and a sensitive attribute. We employ stochastically-activated binary neural networks, which lets us treat neurons as random variables. We are then able to compute (not bound) the mutual information between a layer and a sensitive attribute and use this information as a regularization factor during gradient descent. We show that this method compares favorably with the state of the art in fair representation learning and that the learned representations display a higher level of invariance compared to full-precision neural networks.",
      "authors": [
        "Mattia Cerrato",
        "Marius K\\\"oppel",
        "Roberto Esposito",
        "Stefan Kramer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2022-08-04T13:36:06+00:00",
          "link": "https://arxiv.org/abs/2208.02656v1",
          "size": "1308kb",
          "version": "v1"
        },
        {
          "date": "2022-12-02T14:32:37+00:00",
          "link": "https://arxiv.org/abs/2208.02656v2",
          "size": "1440kb",
          "version": "v2"
        }
      ],
      "title": "Invariant Representations with Stochastically Quantized Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2208.02656",
        "PDF": "https://arxiv.org/pdf/2208.02656"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for calculating mutual information in neural networks to improve invariant representation learning, with no focus on LLM training data processing."
      },
      "tasks": [
        "Attribute",
        "Representation Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.03751",
      "abstract": "The Knaster-Tarski theorem, also known as Tarski's theorem, guarantees that every monotone function defined on a complete lattice has a fixed point. We analyze the query complexity of finding such a fixed point on the $k$-dimensional grid of side length $n$ under the $\\leq$ relation. Specifically, there is an unknown monotone function $f: \\{0,1,\\ldots, n-1\\}^k \\to \\{0,1,\\ldots, n-1\\}^k$ and an algorithm must query a vertex $v$ to learn $f(v)$.\n  A key special case of interest is the Boolean hypercube $\\{0,1\\}^k$, which is isomorphic to the power set lattice--the original setting of the Knaster-Tarski theorem. We prove a lower bound that characterizes the randomized and deterministic query complexity of the Tarski search problem on the Boolean hypercube as $\\Theta(k)$. More generally, we give a randomized lower bound of $\\Omega\\left( k + \\frac{k \\log{n}}{\\log{k}} \\right)$ for the $k$-dimensional grid of side length $n$, which is asymptotically optimal in high dimensions when $k$ is large relative to $n$.",
      "authors": [
        "Simina Br\\^anzei and Reed Phillips and Nicholas Recker"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-05T17:59:08+00:00",
          "link": "https://arxiv.org/abs/2409.03751v1",
          "size": "188kb",
          "version": "v1"
        },
        {
          "date": "2024-12-11T01:44:19+00:00",
          "link": "https://arxiv.org/abs/2409.03751v2",
          "size": "189kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T19:01:02+00:00",
          "link": "https://arxiv.org/abs/2409.03751v3",
          "size": "94kb",
          "version": "v3"
        }
      ],
      "title": "The Randomized Query Complexity of Finding a Tarski Fixed Point on the Boolean Hypercube",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.03751",
        "HTML": "https://arxiv.org/html/2409.03751v3",
        "PDF": "https://arxiv.org/pdf/2409.03751"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyses the query complexity in finding fixed points on the Boolean hypercube, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.05209",
      "abstract": "Evaluations of large language model (LLM) risks and capabilities are increasingly being incorporated into AI risk management and governance frameworks. Currently, most risk evaluations are conducted by designing inputs that elicit harmful behaviors from the system. However, this approach suffers from two limitations. First, input-output evaluations cannot fully evaluate realistic risks from open-weight models. Second, the behaviors identified during any particular input-output evaluation can only lower-bound the model's worst-possible-case input-output behavior. As a complementary method for eliciting harmful behaviors, we propose evaluating LLMs with model tampering attacks which allow for modifications to latent activations or weights. We pit state-of-the-art techniques for removing harmful LLM capabilities against a suite of 5 input-space and 6 model tampering attacks. In addition to benchmarking these methods against each other, we show that (1) model resilience to capability elicitation attacks lies on a low-dimensional robustness subspace; (2) the success rate of model tampering attacks can empirically predict and offer conservative estimates for the success of held-out input-space attacks; and (3) state-of-the-art unlearning methods can easily be undone within 16 steps of fine-tuning. Together, these results highlight the difficulty of suppressing harmful LLM capabilities and show that model tampering attacks enable substantially more rigorous evaluations than input-space attacks alone.",
      "authors": [
        "Zora Che",
        "Stephen Casper",
        "Robert Kirk",
        "Anirudh Satheesh",
        "Stewart Slocum",
        "Lev E McKinney",
        "Rohit Gandikota",
        "Aidan Ewart",
        "Domenic Rosati",
        "Zichu Wu",
        "Zikui Cai",
        "Bilal Chughtai",
        "Yarin Gal",
        "Furong Huang",
        "Dylan Hadfield-Menell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-03T18:59:16+00:00",
          "link": "https://arxiv.org/abs/2502.05209v1",
          "size": "2890kb",
          "version": "v1"
        },
        {
          "date": "2025-04-12T22:03:08+00:00",
          "link": "https://arxiv.org/abs/2502.05209v2",
          "size": "2918kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T18:46:27+00:00",
          "link": "https://arxiv.org/abs/2502.05209v3",
          "size": "1032kb",
          "version": "v3"
        }
      ],
      "title": "Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05209",
        "HTML": "https://arxiv.org/html/2502.05209v3",
        "PDF": "https://arxiv.org/pdf/2502.05209"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores model tampering attacks and their effects on LLM evaluation, but it does not involve processing or creating LLM training data."
      },
      "tasks": [
        "Benchmarking",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10622",
      "abstract": "The rapid expansion of Internet of Things (IoT) networks has led to a surge in security vulnerabilities, emphasizing the critical need for robust anomaly detection and classification techniques. In this work, we propose a novel approach for identifying anomalies in IoT network traffic by leveraging the Mel-frequency cepstral coefficients (MFCC) and ResNet-18, a deep learning model known for its effectiveness in feature extraction and image-based tasks. Learnable MFCCs enable adaptive spectral feature representation, capturing the temporal patterns inherent in network traffic more effectively than traditional fixed MFCCs. We demonstrate that transforming raw signals into MFCCs maps the data into a higher-dimensional space, enhancing class separability and enabling more effective multiclass classification. Our approach combines the strengths of MFCCs with the robust feature extraction capabilities of ResNet-18, offering a powerful framework for anomaly detection. The proposed model is evaluated on three widely used IoT intrusion detection datasets: CICIoT2023, NSL-KDD, and IoTID20. The experimental results highlight the potential of integrating adaptive signal processing techniques with deep learning architectures to achieve robust and scalable anomaly detection in heterogeneous IoT network landscapes.",
      "authors": [
        "HyeYoung Lee",
        "Muhammad Nadeem",
        "Pavel Tsoi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T01:25:26+00:00",
          "link": "https://arxiv.org/abs/2507.10622v1",
          "size": "1259kb",
          "version": "v1"
        }
      ],
      "title": "Spectral Feature Extraction for Robust Network Intrusion Detection Using MFCCs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10622",
        "HTML": "https://arxiv.org/html/2507.10622v1",
        "PDF": "https://arxiv.org/pdf/2507.10622"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on network intrusion detection using MFCCs and ResNet-18, and does not discuss any aspect of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11479",
      "abstract": "AI-enhanced Extended Reality (XR) aims to deliver adaptive, immersive experiences-yet current systems fall short due to shallow user modeling and limited cognitive context. We introduce Perspective-Aware AI in Extended Reality (PAiR), a foundational framework for integrating Perspective-Aware AI (PAi) with XR to enable interpretable, context-aware experiences grounded in user identity. PAi is built on Chronicles: reasoning-ready identity models learned from multimodal digital footprints that capture users' cognitive and experiential evolution. PAiR employs these models in a closed-loop system linking dynamic user states with immersive environments. We present PAiR's architecture, detailing its modules and system flow, and demonstrate its utility through two proof-of-concept scenarios implemented in the Unity-based OpenDome engine. PAiR opens a new direction for human-AI interaction by embedding perspective-based identity models into immersive systems.",
      "authors": [
        "Daniel Platnick",
        "Matti Gruener",
        "Marjan Alirezaie",
        "Kent Larson",
        "Dava J. Newman",
        "Hossein Rahnama"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Graphics (cs.GR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-05T14:53:20+00:00",
          "link": "https://arxiv.org/abs/2507.11479v1",
          "size": "7242kb",
          "version": "v1"
        }
      ],
      "title": "Perspective-Aware AI in Extended Reality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11479",
        "HTML": "https://arxiv.org/html/2507.11479v1",
        "PDF": "https://arxiv.org/pdf/2507.11479"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an AI framework for XR experiences, focusing on user modeling and immersive systems without mentioning any contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.03884",
      "abstract": "The fast growth of deep learning has brought great progress in AI-based applications. However, these models are often seen as \"black boxes,\" which makes them hard to understand, explain, or trust. Explainable Artificial Intelligence (XAI) tries to make AI decisions clearer so that people can understand how and why the model makes certain choices. Even though many studies have focused on XAI, there is still a lack of standard ways to measure how well these explanation methods work in real-world situations. This study introduces a single evaluation framework for XAI. It uses both numbers and user feedback to check if the explanations are correct, easy to understand, fair, complete, and reliable. The framework focuses on users' needs and different application areas, which helps improve the trust and use of AI in important fields. To fix problems in current evaluation methods, we propose clear steps, including loading data, creating explanations, and fully testing them. We also suggest setting common benchmarks. We show the value of this framework through case studies in healthcare, finance, farming, and self-driving systems. These examples prove that our method can support fair and trustworthy evaluation of XAI methods. This work gives a clear and practical way to improve transparency and trust in AI systems used in the real world.",
      "authors": [
        "Md. Ariful Islam",
        "Md Abrar Jahin",
        "M. F. Mridha",
        "and Nilanjan Dey"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-05T05:30:10+00:00",
          "link": "https://arxiv.org/abs/2412.03884v1",
          "size": "6627kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T17:10:45+00:00",
          "link": "https://arxiv.org/abs/2412.03884v2",
          "size": "6827kb",
          "version": "v2"
        }
      ],
      "title": "A Unified Framework for Evaluating the Effectiveness and Enhancing the Transparency of Explainable AI Methods in Real-World Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.03884",
        "HTML": "https://arxiv.org/html/2412.03884v2",
        "PDF": "https://arxiv.org/pdf/2412.03884"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study provides a framework for evaluating explainable AI methods, focusing on transparency of AI decisions and not on LLM training data processing."
      },
      "tasks": [
        "Explainable artificial intelligence",
        "Explainable Artificial Intelligence (XAI)",
        "Fairness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.21418",
      "abstract": "Focused Ultrasound Ablation Surgery (FUAS) has emerged as a promising non-invasive therapeutic modality, valued for its safety and precision. Nevertheless, its clinical implementation entails intricate tasks such as multimodal image interpretation, personalized dose planning, and real-time intraoperative decision-making processes that demand intelligent assistance to improve efficiency and reliability. We introduce FUAS-Agents, an autonomous agent system that leverages the multimodal understanding and tool-using capabilities of large language models (LLMs). By integrating patient profiles and MRI data, FUAS-Agents orchestrates a suite of specialized medical AI tools, including segmentation, treatment dose prediction, and clinical guideline retrieval, to generate personalized treatment plans comprising MRI image, dose parameters, and therapeutic strategies. We evaluate the system in a uterine fibroid treatment scenario. Human assessment by four senior FUAS experts indicates that 82.5%, 82.5%, 87.5%, and 97.5% of the generated plans were rated 4 or above (on a 5-point scale) in terms of completeness, accuracy, fluency, and clinical compliance, respectively. These results demonstrate the potential of LLM-driven agents in enhancing decision-making across complex clinical workflows, and exemplify a translational paradigm that combines general-purpose models with specialized expert systems to solve practical challenges in vertical healthcare domains.",
      "authors": [
        "Lina Zhao and Jiaxing Bai and Zihao Bian and Qingyue Chen and Yafang Li and Guangbo Li and Min He and Huaiyuan Yao and Zongjiu Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T16:43:31+00:00",
          "link": "https://arxiv.org/abs/2505.21418v1",
          "size": "10733kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T00:18:33+00:00",
          "link": "https://arxiv.org/abs/2505.21418v2",
          "size": "10726kb",
          "version": "v2"
        }
      ],
      "title": "Autonomous Multi-Modal LLM Agents for Treatment Planning in Focused Ultrasound Ablation Surgery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.21418",
        "HTML": "https://arxiv.org/html/2505.21418v2",
        "PDF": "https://arxiv.org/pdf/2505.21418"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a system for treatment planning in surgery using LLM agents. It focuses on the application of LLMs in clinical settings without any focus on training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10602",
      "abstract": "Learning from demonstration provides a sample-efficient approach to acquiring complex behaviors, enabling robots to move robustly, compliantly, and with fluidity. In this context, Dynamic Motion Primitives offer built - in stability and robustness to disturbances but often struggle to capture complex periodic behaviors. Moreover, they are limited in their ability to interpolate between different tasks. These shortcomings substantially narrow their applicability, excluding a wide class of practically meaningful tasks such as locomotion and rhythmic tool use. In this work, we introduce Orbitally Stable Motion Primitives (OSMPs) - a framework that combines a learned diffeomorphic encoder with a supercritical Hopf bifurcation in latent space, enabling the accurate acquisition of periodic motions from demonstrations while ensuring formal guarantees of orbital stability and transverse contraction. Furthermore, by conditioning the bijective encoder on the task, we enable a single learned policy to represent multiple motion objectives, yielding consistent zero-shot generalization to unseen motion objectives within the training distribution. We validate the proposed approach through extensive simulation and real-world experiments across a diverse range of robotic platforms - from collaborative arms and soft manipulators to a bio-inspired rigid-soft turtle robot - demonstrating its versatility and effectiveness in consistently outperforming state-of-the-art baselines such as diffusion policies, among others.",
      "authors": [
        "Maximilian St\\\"olzle and T. Konstantin Rusch and Zach J. Patterson and Rodrigo P\\'erez-Dattari and Francesco Stella and Josie Hughes and Cosimo Della Santina and Daniela Rus"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T17:10:03+00:00",
          "link": "https://arxiv.org/abs/2507.10602v1",
          "size": "31080kb",
          "version": "v1"
        }
      ],
      "title": "Learning to Move in Rhythm: Task-Conditioned Motion Policies with Orbital Stability Guarantees",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10602",
        "HTML": "https://arxiv.org/html/2507.10602v1",
        "PDF": "https://arxiv.org/pdf/2507.10602"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for motion primitives in robotics, dealing with motion learning and demonstrations, which is not related to processing or managing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.00554",
      "abstract": "Robotic manipulation of volumetric elastoplastic deformable materials, from foods such as dough to construction materials like clay, is in its infancy, largely due to the difficulty of modelling and perception in a high-dimensional space. Simulating the dynamics of such materials is computationally expensive. It tends to suffer from inaccurately estimated physics parameters of the materials and the environment, impeding high-precision manipulation. Estimating such parameters from raw point clouds captured by optical cameras suffers further from heavy occlusions. To address this challenge, this work introduces a novel Differentiable Physics-based System Identification (DPSI) framework that enables a robot arm to infer the physics parameters of elastoplastic materials and the environment using simple manipulation motions and incomplete 3D point clouds, aligning the simulation with the real world. Extensive experiments show that with only a single real-world interaction, the estimated parameters, Young's modulus, Poisson's ratio, yield stress and friction coefficients, can accurately simulate visually and physically realistic deformation behaviours induced by unseen and long-horizon manipulation motions. Additionally, the DPSI framework inherently provides physically intuitive interpretations for the parameters in contrast to black-box approaches such as deep neural networks. The project is fully open-sourced via https://ianyangchina.github.io/SI4RP-data/.",
      "authors": [
        "Xintong Yang",
        "Ze Ji",
        "Yu-Kun Lai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-01T13:04:25+00:00",
          "link": "https://arxiv.org/abs/2411.00554v1",
          "size": "36649kb",
          "version": "v1"
        },
        {
          "date": "2024-11-22T15:15:22+00:00",
          "link": "https://arxiv.org/abs/2411.00554v2",
          "size": "21196kb",
          "version": "v2"
        },
        {
          "date": "2025-02-18T08:35:55+00:00",
          "link": "https://arxiv.org/abs/2411.00554v3",
          "size": "24605kb",
          "version": "v3"
        }
      ],
      "title": "Differentiable Physics-based System Identification for Robotic Manipulation of Elastoplastic Materials",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.00554",
        "HTML": "https://arxiv.org/html/2411.00554",
        "PDF": "https://arxiv.org/pdf/2411.00554"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work focuses on the robotic manipulation of elastoplastic materials using a physics-based system identification framework, and does not involve LLM training data processing."
      },
      "tasks": [
        "Friction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.18637",
      "abstract": "Semantic communication, leveraging advanced deep learning techniques, emerges as a new paradigm that meets the requirements of next-generation wireless networks. However, current semantic communication systems, which employ neural coding for feature extraction from raw data, have not adequately addressed the fundamental question: Is general feature extraction through deep neural networks sufficient for understanding semantic meaning within raw data in semantic communication? This article is thus motivated to clarify two critical aspects: semantic understanding and general semantic representation. This article presents a standardized definition on semantic coding, an extensive neural coding scheme for general semantic representation that clearly represents underlying data semantics based on contextual modeling. With these general semantic representations obtained, both human- and machine-centric end-to-end data transmission can be achieved through only minimal specialized modifications, such as fine-tuning and regularization. This article contributes to establishing a commonsense that semantic communication extends far beyond mere feature transmission, focusing instead on conveying compact semantic representations through context-aware coding schemes.",
      "authors": [
        "Hai-Long Qin",
        "Jincheng Dai",
        "Sixian Wang",
        "Xiaoqi Qin",
        "Shuo Shao",
        "Kai Niu",
        "Wenjun Xu and Ping Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-24T10:52:01+00:00",
          "link": "https://arxiv.org/abs/2505.18637v1",
          "size": "2991kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T13:56:20+00:00",
          "link": "https://arxiv.org/abs/2505.18637v2",
          "size": "2969kb",
          "version": "v2"
        }
      ],
      "title": "Neural Coding Is Not Always Semantic: Towards the Standardized Coding Workflow in Semantic Communications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.18637",
        "HTML": "https://arxiv.org/html/2505.18637v2",
        "PDF": "https://arxiv.org/pdf/2505.18637"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses semantic communication and neural coding which is not related to the collection or processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09291",
      "abstract": "Floorplans provide a compact representation of the building's structure, revealing not only layout information but also detailed semantics such as the locations of windows and doors. However, contemporary floorplan localization techniques mostly focus on matching depth-based structural cues, ignoring the rich semantics communicated within floorplans. In this work, we introduce a semantic-aware localization framework that jointly estimates depth and semantic rays, consolidating over both for predicting a structural-semantic probability volume. Our probability volume is constructed in a coarse-to-fine manner: We first sample a small set of rays to obtain an initial low-resolution probability volume. We then refine these probabilities by performing a denser sampling only in high-probability regions and process the refined values for predicting a 2D location and orientation angle. We conduct an evaluation on two standard floorplan localization benchmarks. Our experiments demonstrate that our approach substantially outperforms state-of-the-art methods, achieving significant improvements in recall metrics compared to prior works. Moreover, we show that our framework can easily incorporate additional metadata such as room labels, enabling additional gains in both accuracy and efficiency.",
      "authors": [
        "Yuval Grader",
        "Hadar Averbuch-Elor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T14:01:54+00:00",
          "link": "https://arxiv.org/abs/2507.09291v1",
          "size": "9674kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T13:35:01+00:00",
          "link": "https://arxiv.org/abs/2507.09291v2",
          "size": "9674kb",
          "version": "v2"
        }
      ],
      "title": "Supercharging Floorplan Localization with Semantic Rays",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09291",
        "HTML": "https://arxiv.org/html/2507.09291v2",
        "PDF": "https://arxiv.org/pdf/2507.09291"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a method for floorplan localization using semantic rays and probability volumes, without discussing any aspect of LLM training data processing or creation of new training datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09884",
      "abstract": "Large language models (LLMs) increasingly rely on reinforcement learning (RL) to enhance their reasoning capabilities through feedback. A critical challenge is verifying the consistency of model-generated responses and reference answers, since these responses are often lengthy, diverse, and nuanced. Rule-based verifiers struggle with complexity, prompting the use of model-based verifiers. However, specialized verifiers lack flexibility, while general LLM judges can be inconsistent. Existing research primarily focuses on building better verifiers, yet a systematic evaluation of different types of verifiers' performance across domains remains lacking, severely constraining the reliable development of Reinforcement Learning with Verifiable Reward (RLVR). To address this, we propose VerifyBench--a cross-domain comprehensive benchmark for systematically evaluating verifiers. We construct 4,000 expert-level questions covering mathematics, physics, chemistry, and biology. Each question is equipped with reference answers and diverse responses. The reliability of the evaluation is ensured through a rigorous annotation process conducted by a multidisciplinary expert team. We design a four-dimensional experimental framework to comprehensively compare the performance boundaries of specialized verifiers and general LLMs under combined conditions of extracted answers vs. complete responses, and short vs. long outputs. Our evaluation uncovers fundamental trade-offs in verifiers: while specialized verifiers achieve leading accuracy, they exhibit deficiencies in recall; general models show stronger inclusivity but unstable precision. More importantly, we discover verifiers' high sensitivity to input structure and inherent limitations in cross-domain generalization, providing critical insights into the bottlenecks of current verifier technology.",
      "authors": [
        "Xuzhao Li and Xuchen Li and Shiyu Hu and Yongzhen Guo and Wentao Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T03:45:24+00:00",
          "link": "https://arxiv.org/abs/2507.09884v1",
          "size": "5338kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T05:01:49+00:00",
          "link": "https://arxiv.org/abs/2507.09884v2",
          "size": "5352kb",
          "version": "v2"
        }
      ],
      "title": "VerifyBench: A Systematic Benchmark for Evaluating Reasoning Verifiers Across Domains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09884",
        "HTML": "https://arxiv.org/html/2507.09884v2",
        "PDF": "https://arxiv.org/pdf/2507.09884"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with evaluating verifiers for LLM-generated responses and does not address any LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10787",
      "abstract": "This paper introduces MISS-QA, the first benchmark specifically designed to evaluate the ability of models to interpret schematic diagrams within scientific literature. MISS-QA comprises 1,500 expert-annotated examples over 465 scientific papers. In this benchmark, models are tasked with interpreting schematic diagrams that illustrate research overviews and answering corresponding information-seeking questions based on the broader context of the paper. We assess the performance of 18 frontier multimodal foundation models, including o4-mini, Gemini-2.5-Flash, and Qwen2.5-VL. We reveal a significant performance gap between these models and human experts on MISS-QA. Our analysis of model performance on unanswerable questions and our detailed error analysis further highlight the strengths and limitations of current models, offering key insights to enhance models in comprehending multimodal scientific literature.",
      "authors": [
        "Yilun Zhao",
        "Chengye Wang",
        "Chuhan Li",
        "Arman Cohan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T20:35:25+00:00",
          "link": "https://arxiv.org/abs/2507.10787v1",
          "size": "15298kb",
          "version": "v1"
        }
      ],
      "title": "Can Multimodal Foundation Models Understand Schematic Diagrams? An Empirical Study on Information-Seeking QA over Scientific Papers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10787",
        "PDF": "https://arxiv.org/pdf/2507.10787"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a new benchmark for evaluating models on interpreting schematic diagrams, it primarily focuses on model evaluation rather than directly contributing to LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.19403",
      "abstract": "Discrete choice models are essential for modelling various decision-making processes in human behaviour. However, the specification of these models has depended heavily on domain knowledge from experts, and the fully automated but interpretable modelling of complex human behaviours has been a long-standing challenge. In this paper, we introduce the differentiable discrete choice model (Diff-DCM), a fully data-driven method for the interpretable modelling, learning, prediction, and control of complex human behaviours, which is realised by differentiable programming. Solely from input features and choice outcomes without any prior knowledge, Diff-DCM can estimate interpretable closed-form utility functions that reproduce observed behaviours. Comprehensive experiments with both synthetic and real-world data demonstrate that Diff-DCM can be applied to various types of data and requires only a small amount of computational resources for the estimations, which can be completed within tens of seconds on a laptop without any accelerators. In these experiments, we also demonstrate that, using its differentiability, Diff-DCM can provide useful insights into human behaviours, such as an optimal intervention path for effective behavioural changes. This study provides a strong basis for the fully automated and reliable modelling, prediction, and control of human behaviours.",
      "authors": [
        "Fumiyasu Makinoshima",
        "Tatsuya Mitomi",
        "Fumiya Makihara",
        "Eigo Segawa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-27T01:53:18+00:00",
          "link": "https://arxiv.org/abs/2412.19403v1",
          "size": "2492kb",
          "version": "v1"
        },
        {
          "date": "2025-01-08T02:43:21+00:00",
          "link": "https://arxiv.org/abs/2412.19403v2",
          "size": "2492kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T05:16:51+00:00",
          "link": "https://arxiv.org/abs/2412.19403v3",
          "size": "2493kb",
          "version": "v3"
        }
      ],
      "title": "Fully Data-driven but Interpretable Human Behavioural Modelling with Differentiable Discrete Choice Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.19403",
        "HTML": "https://arxiv.org/html/2412.19403v3",
        "PDF": "https://arxiv.org/pdf/2412.19403"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a discrete choice model for human behavioral modeling, with no discussion on LLM training data processing or dataset creation."
      },
      "tasks": [
        "Discrete Choice Models"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10582",
      "abstract": "Unstructured text from legal, medical, and administrative sources offers a rich but underutilized resource for research in public health and the social sciences. However, large-scale analysis is hampered by two key challenges: the presence of sensitive, personally identifiable information, and significant heterogeneity in structure and language. We present a modular toolchain that prepares such text data for embedding-based analysis, relying entirely on open-weight models that run on local hardware, requiring only a workstation-level GPU and supporting privacy-sensitive research.\n  The toolchain employs large language model (LLM) prompting to standardize, summarize, and, when needed, translate texts to English for greater comparability. Anonymization is achieved via LLM-based redaction, supplemented with named entity recognition and rule-based methods to minimize the risk of disclosure. We demonstrate the toolchain on a corpus of 10,842 Swedish court decisions under the Care of Abusers Act (LVM), comprising over 56,000 pages. Each document is processed into an anonymized, standardized summary and transformed into a document-level embedding. Validation, including manual review, automated scanning, and predictive evaluation shows the toolchain effectively removes identifying information while retaining semantic content. As an illustrative application, we train a predictive model using embedding vectors derived from a small set of manually labeled summaries, demonstrating the toolchain's capacity for semi-automated content analysis at scale.\n  By enabling structured, privacy-conscious analysis of sensitive documents, our toolchain opens new possibilities for large-scale research in domains where textual data was previously inaccessible due to privacy and heterogeneity constraints.",
      "authors": [
        "Anders Ledberg",
        "Anna Thal\\'en"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T11:58:36+00:00",
          "link": "https://arxiv.org/abs/2507.10582v1",
          "size": "23kb",
          "version": "v1"
        }
      ],
      "title": "Transforming Sensitive Documents into Quantitative Data: An AI-Based Preprocessing Toolchain for Structured and Privacy-Conscious Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10582",
        "HTML": "https://arxiv.org/html/2507.10582v1",
        "PDF": "https://arxiv.org/pdf/2507.10582"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents an AI-based preprocessing toolchain for transforming sensitive documents into anonymized, standardized summaries, focusing on data preparation and anonymization for analysis, which is a direct contribution to LLM training-data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10757",
      "abstract": "Current blockchain execution throughput is limited by data contention, reducing execution layer parallelism. Fast Ahead-of-Formation Optimization (FAFO) is the first blockchain transaction scheduler to address this problem by reordering transactions before block formation for maximum concurrency. FAFO uses CPU-optimized cache-friendly Bloom filters to efficiently detect conflicts and schedule parallel transaction execution at high throughput and low overhead.\n  We integrate the Rust EVM client (REVM) into FAFO and achieve over 1.1 million native ETH transfers per second and over half a million ERC20 transfers per second on a single node (Table 1), with 91% lower cost compared to state-of-the-art sharded execution. Unlike many other existing high throughput blockchain execution clients, FAFO uses QMDB to Merkleize world state after every block, enabling light clients and stateless validation for ZK-based vApps. FAFO scales with minimal synchronization overhead, scaling linearly with additional CPU resources until it fully exploits the maximum parallelism of the underlying transaction flow. FAFO proves that the high throughput necessary to support future decentralized applications can be achieved with a streamlined execution layer and innovations in blockchain transaction scheduler design. FAFO is open-sourced at https://github.com/LayerZero-Labs/fafo.",
      "authors": [
        "Ryan Zarick",
        "Isaac Zhang",
        "Daniel Wong",
        "Thomas Kim",
        "Bryan Pellegrino",
        "Mignon Li",
        "Kelvin Wong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:31:06+00:00",
          "link": "https://arxiv.org/abs/2507.10757v1",
          "size": "131kb",
          "version": "v1"
        }
      ],
      "title": "FAFO: Over 1 million TPS on a single node running EVM while still Merkleizing every block",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10757",
        "HTML": "https://arxiv.org/html/2507.10757v1",
        "PDF": "https://arxiv.org/pdf/2507.10757"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a blockchain transaction scheduler and does not involve processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10899",
      "abstract": "Imitation learning for mobile manipulation is a key challenge in the field of robotic manipulation. However, current mobile manipulation frameworks typically decouple navigation and manipulation, executing manipulation only after reaching a certain location. This can lead to performance degradation when navigation is imprecise, especially due to misalignment in approach angles. To enable a mobile manipulator to perform the same task from diverse orientations, an essential capability for building general-purpose robotic models, we propose an object-centric method based on SAM2, a foundation model towards solving promptable visual segmentation in images, which incorporates manipulation orientation information into our model. Our approach enables consistent understanding of the same task from different orientations. We deploy the model on a custom-built mobile manipulator and evaluate it on a pick-and-place task under varied orientation angles. Compared to Action Chunking Transformer, our model maintains superior generalization when trained with demonstrations from varied approach angles. This work significantly enhances the generalization and robustness of imitation learning-based mobile manipulation systems.",
      "authors": [
        "Wang Zhicheng",
        "Satoshi Yagi",
        "Satoshi Yamamori",
        "Jun Morimoto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T01:26:59+00:00",
          "link": "https://arxiv.org/abs/2507.10899v1",
          "size": "9878kb",
          "version": "v1"
        }
      ],
      "title": "Object-Centric Mobile Manipulation through SAM2-Guided Perception and Imitation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10899",
        "HTML": "https://arxiv.org/html/2507.10899v1",
        "PDF": "https://arxiv.org/pdf/2507.10899"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses mobile manipulation through imitation learning and visual perception. It does not touch upon LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11490",
      "abstract": "Recognizing how technical systems can embody social values or cause harms, human-computer interaction (HCI) research often approaches addressing values and ethics in design by creating tools to help tech workers integrate social values into the design of products. While useful, these approaches usually do not consider the politics embedded in the broader processes, organizations, social systems, and governance structures that affect the types of actions that tech workers can take to address values and ethics. This paper argues that creating infrastructures to support values and ethics work, rather than tools, is an approach that takes these broader processes into account and opens them up for (re)design. Drawing on prior research conceptualizing infrastructures from science \\& technology studies and media studies, this paper outlines conceptual insights from infrastructures studies that open up new tactics for HCI researchers and designers seeking to support values and ethics in design.",
      "authors": [
        "Richmond Y. Wong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:02:39+00:00",
          "link": "https://arxiv.org/abs/2507.11490v1",
          "size": "162kb",
          "version": "v1"
        }
      ],
      "title": "Towards Creating Infrastructures for Values and Ethics Work in the Production of Software Technologies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11490",
        "HTML": "https://arxiv.org/html/2507.11490v1",
        "PDF": "https://arxiv.org/pdf/2507.11490"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses ethical considerations in software design infrastructures, without mentioning LLM training data processing or related techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.10781",
      "abstract": "To observe how individual behavior shapes a larger community's actions, agent-based modeling and simulation (ABMS) has been widely adopted by researchers in social sciences, economics, and epidemiology. While simulations can be run on general-purpose ABMS frameworks, these tools are not specifically designed for social networks and, therefore, provide limited features, increasing the effort required for complex simulations. In this paper, we introduce Crowd, a social network simulator that adopts the agent-based modeling methodology to model real-world phenomena within a network environment. Designed to facilitate easy and quick modeling, Crowd supports simulation setup through YAML configuration and enables further customization with user-defined methods. Other features include no-code simulations for diffusion tasks, interactive visualizations, data aggregation, and chart drawing facilities. Designed in Python, Crowd also supports generative agents and connects easily with Python's libraries for data analysis and machine learning. Finally, we include three case studies to illustrate the use of the framework, including generative agents in epidemics, influence maximization, and networked trust games.",
      "authors": [
        "Ann Nedime Nese Rende",
        "Tolga Yilmaz",
        "\\\"Ozg\\\"ur Ulusoy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-14T10:35:40+00:00",
          "link": "https://arxiv.org/abs/2412.10781v1",
          "size": "3301kb",
          "version": "v1"
        },
        {
          "date": "2025-03-26T05:11:39+00:00",
          "link": "https://arxiv.org/abs/2412.10781v2",
          "size": "3329kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T15:01:49+00:00",
          "link": "https://arxiv.org/abs/2412.10781v3",
          "size": "3328kb",
          "version": "v3"
        }
      ],
      "title": "Crowd: A Social Network Simulation Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.10781",
        "HTML": "https://arxiv.org/html/2412.10781v3",
        "PDF": "https://arxiv.org/pdf/2412.10781"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a social network simulation framework and does not address any aspect of LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/bilkent-social-systems-research-group/crowd-ui",
        "https://github.com/bilkent-social-systems-research-group/crowd"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.02575",
      "abstract": "We present a unified framework for embedding and analyzing dynamical systems using generalized projection operators rooted in local conservation laws. By representing physical, biological, and engineered systems as graphs with incidence and cycle matrices, we derive dual projection operators that decompose network fluxes and potentials. This formalism aligns with principles of non-equilibrium thermodynamics and captures a broad class of systems governed by flux-forcing relationships and local constraints. We extend this approach to collective dynamics through the PRojective Embedding of Dynamical Systems (PrEDS), which lifts low-dimensional dynamics into a high-dimensional space, enabling both replication and recovery of the original dynamics. When systems fall within the PrEDS class, their collective behavior can be effectively approximated through projection onto a mean-field space. We demonstrate the versatility of PrEDS across diverse domains, including resistive and memristive circuits, adaptive flow networks (e.g., slime molds), elastic string networks, and particle swarms. Notably, we establish a direct correspondence between PrEDS and swarm dynamics, revealing new insights into optimization and self-organization. Our results offer a general theoretical foundation for analyzing complex networked systems and for designing systems that self-organize through local interactions.",
      "authors": [
        "Frank Barrows and Guanming Zhang and Satyam Anand and Zixi Chen and Jonathan Lin and Aman Desai and Stefano Martiniani and Francesco Caravelli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Soft Condensed Matter (cond-mat.soft)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Multiagent Systems (cs.MA)",
        "Adaptation and Self-Organizing Systems (nlin.AO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T12:31:18+00:00",
          "link": "https://arxiv.org/abs/2507.02575v1",
          "size": "11502kb",
          "version": "v1"
        },
        {
          "date": "2025-07-04T05:12:57+00:00",
          "link": "https://arxiv.org/abs/2507.02575v2",
          "size": "11502kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T07:09:32+00:00",
          "link": "https://arxiv.org/abs/2507.02575v3",
          "size": "11502kb",
          "version": "v3"
        }
      ],
      "title": "A unifying approach to self-organizing systems interacting via conservation laws",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02575",
        "PDF": "https://arxiv.org/pdf/2507.02575"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a theoretical framework for analyzing dynamical systems and does not address LLM training data processing or related engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11161",
      "abstract": "In recent years, contrastive learning has achieved state-of-the-art performance in the territory of self-supervised representation learning. Many previous works have attempted to provide the theoretical understanding underlying the success of contrastive learning. Almost all of them rely on a default assumption, i.e., the label consistency assumption, which may not hold in practice (the probability of failure is called labeling error) due to the strength and randomness of common augmentation strategies, such as random resized crop (RRC). This paper investigates the theoretical impact of labeling error on the downstream classification performance of contrastive learning. We first reveal several significant negative impacts of labeling error on downstream classification risk. To mitigate these impacts, data dimensionality reduction method (e.g., singular value decomposition, SVD) is applied on original data to reduce false positive samples, and establish both theoretical and empirical evaluations. Moreover, it is also found that SVD acts as a double-edged sword, which may lead to the deterioration of downstream classification accuracy due to the reduced connectivity of the augmentation graph. Based on the above observations, we give the augmentation suggestion that we should use some moderate embedding dimension (such as $512, 1024$ in our experiments), data inflation, weak augmentation, and SVD to ensure large graph connectivity and small labeling error to improve model performance.",
      "authors": [
        "Jun Chen",
        "Hong Chen",
        "Yonghua Yu",
        "Yiming Ying"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:09:55+00:00",
          "link": "https://arxiv.org/abs/2507.11161v1",
          "size": "1865kb",
          "version": "v1"
        }
      ],
      "title": "How does Labeling Error Impact Contrastive Learning? A Perspective from Data Dimensionality Reduction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11161",
        "HTML": "https://arxiv.org/html/2507.11161v1",
        "PDF": "https://arxiv.org/pdf/2507.11161"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper investigates the impact of labeling error in contrastive learning and suggests data dimensionality reduction. While it deals with data quality and preprocessing, it is not specific to LLM training data processing and focuses on contrastive learning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11505",
      "abstract": "One of the major challenges in enterprise data analysis is the task of finding joinable tables that are conceptually related and provide meaningful insights. Traditionally, joinable tables have been discovered through a search for similar columns, where two columns are considered similar syntactically if there is a set overlap or they are considered similar semantically if either the column embeddings or value embeddings are closer in the embedding space. However, for enterprise data lakes, column similarity is not sufficient to identify joinable columns and tables. The context of the query column is important. Hence, in this work, we first define context-aware column joinability. Then we propose a multi-criteria approach, called TOPJoin, for joinable column search. We evaluate TOPJoin against existing join search baselines over one academic and one real-world join search benchmark. Through experiments, we find that TOPJoin performs better on both benchmarks than the baselines.",
      "authors": [
        "Harsha Kokel",
        "Aamod Khatiwada",
        "Tejaswini Pedapati",
        "Haritha Ananthakrishnan",
        "Oktie Hassanzadeh",
        "Horst Samulowitz",
        "Kavitha Srinivas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:20:56+00:00",
          "link": "https://arxiv.org/abs/2507.11505v1",
          "size": "86kb",
          "version": "v1"
        }
      ],
      "title": "TOPJoin: A Context-Aware Multi-Criteria Approach for Joinable Column Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11505",
        "HTML": "https://arxiv.org/html/2507.11505v1",
        "PDF": "https://arxiv.org/pdf/2507.11505"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a context-aware approach for joinable column search in enterprise data, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.09781",
      "abstract": "Contrastive learning operates on a simple yet effective principle: Embeddings of positive pairs are pulled together, while those of negative pairs are pushed apart. In this paper, we propose a unified framework for understanding contrastive learning through the lens of cosine similarity, and present two key theoretical insights derived from this framework. First, in full-batch settings, we show that perfect alignment of positive pairs is unattainable when negative-pair similarities fall below a threshold, and this misalignment can be mitigated by incorporating within-view negative pairs into the objective. Second, in mini-batch settings, smaller batch sizes induce stronger separation among negative pairs in the embedding space, i.e., higher variance in their similarities, which in turn degrades the quality of learned representations compared to full-batch settings. To address this, we propose an auxiliary loss that reduces the variance of negative-pair similarities in mini-batch settings. Empirical results show that incorporating the proposed loss improves performance in small-batch settings.",
      "authors": [
        "Chungpa Lee",
        "Sehee Lim",
        "Kibok Lee",
        "Jy-yong Sohn"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T14:21:05+00:00",
          "link": "https://arxiv.org/abs/2506.09781v1",
          "size": "869kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T05:49:44+00:00",
          "link": "https://arxiv.org/abs/2506.09781v2",
          "size": "869kb",
          "version": "v2"
        }
      ],
      "title": "On the Similarities of Embeddings in Contrastive Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09781",
        "HTML": "https://arxiv.org/html/2506.09781v2",
        "PDF": "https://arxiv.org/pdf/2506.09781"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on contrastive learning and embedding similarities, without addressing LLM training data processing or contributions to dataset preparation or improvement."
      },
      "tasks": [
        "Contrastive Learning"
      ],
      "repo_urls": [
        "https://github.com/leechungpa/embedding-similarity-cl"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10626",
      "abstract": "Predicting soccer match outcomes is a challenging task due to the inherently unpredictable nature of the game and the numerous dynamic factors influencing results. While it conventionally relies on meticulous feature engineering, deep learning techniques have recently shown a great promise in learning effective player and team representations directly for soccer outcome prediction. However, existing methods often overlook the heterogeneous nature of interactions among players and teams, which is crucial for accurately modeling match dynamics. To address this gap, we propose HIGFormer (Heterogeneous Interaction Graph Transformer), a novel graph-augmented transformer-based deep learning model for soccer outcome prediction. HIGFormer introduces a multi-level interaction framework that captures both fine-grained player dynamics and high-level team interactions. Specifically, it comprises (1) a Player Interaction Network, which encodes player performance through heterogeneous interaction graphs, combining local graph convolutions with a global graph-augmented transformer; (2) a Team Interaction Network, which constructs interaction graphs from a team-to-team perspective to model historical match relationships; and (3) a Match Comparison Transformer, which jointly analyzes both team and player-level information to predict match outcomes. Extensive experiments on the WyScout Open Access Dataset, a large-scale real-world soccer dataset, demonstrate that HIGFormer significantly outperforms existing methods in prediction accuracy. Furthermore, we provide valuable insights into leveraging our model for player performance evaluation, offering a new perspective on talent scouting and team strategy analysis.",
      "authors": [
        "Lintao Wang",
        "Shiwen Xu",
        "Michael Horton",
        "Joachim Gudmundsson",
        "Zhiyong Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T06:43:36+00:00",
          "link": "https://arxiv.org/abs/2507.10626v1",
          "size": "1229kb",
          "version": "v1"
        }
      ],
      "title": "Player-Team Heterogeneous Interaction Graph Transformer for Soccer Outcome Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10626",
        "HTML": "https://arxiv.org/html/2507.10626v1",
        "PDF": "https://arxiv.org/pdf/2507.10626"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a model for predicting soccer outcomes rather than focusing on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11230",
      "abstract": "Understanding the multilingual mechanisms of large language models (LLMs) provides insight into how they process different languages, yet this remains challenging. Existing studies often focus on individual neurons, but their polysemantic nature makes it difficult to isolate language-specific units from cross-lingual representations. To address this, we explore sparse autoencoders (SAEs) for their ability to learn monosemantic features that represent concrete and abstract concepts across languages in LLMs. While some of these features are language-independent, the presence of language-specific features remains underexplored. In this work, we introduce SAE-LAPE, a method based on feature activation probability, to identify language-specific features within the feed-forward network. We find that many such features predominantly appear in the middle to final layers of the model and are interpretable. These features influence the model's multilingual performance and language output and can be used for language identification with performance comparable to fastText along with more interpretability. Our code is available at https://github.com/LyzanderAndrylie/language-specific-features .",
      "authors": [
        "Lyzander Marciano Andrylie",
        "Inaya Rahmanisa",
        "Mahardika Krisna Ihsani",
        "Alfan Farizki Wicaksono",
        "Haryo Akbarianto Wibowo",
        "Alham Fikri Aji"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:00:30+00:00",
          "link": "https://arxiv.org/abs/2507.11230v1",
          "size": "18215kb",
          "version": "v1"
        }
      ],
      "title": "Sparse Autoencoders Can Capture Language-Specific Concepts Across Diverse Languages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11230",
        "PDF": "https://arxiv.org/pdf/2507.11230"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on understanding multilingual mechanisms in LLMs using sparse autoencoders, but does not discuss data processing or creation related to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.03461",
      "abstract": "Radar signal recognition (RSR) plays a pivotal role in electronic warfare (EW), as accurately classifying radar signals is critical for informing decision-making. Recent advances in deep learning have shown significant potential in improving RSR in domains with ample annotated data. However, these methods fall short in EW scenarios where annotated radio frequency (RF) data are scarce or impractical to obtain. To address these challenges, we introduce a self-supervised learning (SSL) method which utilises masked signal modelling and RF domain adaption to perform few-shot RSR and enhance performance in environments with limited RF samples and annotations. We propose a two-step approach, first pre-training masked autoencoders (MAE) on baseband in-phase and quadrature (I/Q) signals from diverse RF domains, and then transferring the learned representations to the radar domain, where annotated data are scarce. Empirical results show that our lightweight self-supervised ResNet1D model with domain adaptation achieves up to a 17.5% improvement in 1-shot classification accuracy when pre-trained on in-domain signals (i.e., radar signals) and up to a 16.31% improvement when pre-trained on out-of-domain signals (i.e., comm signals), compared to its baseline without using SSL. We also present reference results for several MAE designs and pre-training strategies, establishing a new benchmark for few-shot radar signal classification.",
      "authors": [
        "Zi Huang",
        "Simon Denman",
        "Akila Pemasiri",
        "Clinton Fookes",
        "Terrence Martin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-07T01:35:56+00:00",
          "link": "https://arxiv.org/abs/2501.03461v1",
          "size": "2136kb",
          "version": "v1"
        },
        {
          "date": "2025-01-14T04:53:30+00:00",
          "link": "https://arxiv.org/abs/2501.03461v2",
          "size": "2136kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T12:08:06+00:00",
          "link": "https://arxiv.org/abs/2501.03461v3",
          "size": "3619kb",
          "version": "v3"
        }
      ],
      "title": "Few-Shot Radar Signal Recognition through Self-Supervised Learning and Radio Frequency Domain Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.03461",
        "HTML": "https://arxiv.org/html/2501.03461v3",
        "PDF": "https://arxiv.org/pdf/2501.03461"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work targets radar signal recognition through self-supervised learning and domain adaptation, which is unrelated to LLM training data processing or engineering."
      },
      "tasks": [
        "Domain Adaptation",
        "Self-Supervised Learning"
      ],
      "repo_urls": [
        "https://github.com/abcxyzi/radcharssl"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.12110",
      "abstract": "While large language model (LLM) agents can effectively use external tools for complex real-world tasks, they require memory systems to leverage historical experiences. Current memory systems enable basic storage and retrieval but lack sophisticated memory organization, despite recent attempts to incorporate graph databases. Moreover, these systems' fixed operations and structures limit their adaptability across diverse tasks. To address this limitation, this paper proposes a novel agentic memory system for LLM agents that can dynamically organize memories in an agentic way. Following the basic principles of the Zettelkasten method, we designed our memory system to create interconnected knowledge networks through dynamic indexing and linking. When a new memory is added, we generate a comprehensive note containing multiple structured attributes, including contextual descriptions, keywords, and tags. The system then analyzes historical memories to identify relevant connections, establishing links where meaningful similarities exist. Additionally, this process enables memory evolution - as new memories are integrated, they can trigger updates to the contextual representations and attributes of existing historical memories, allowing the memory network to continuously refine its understanding. Our approach combines the structured organization principles of Zettelkasten with the flexibility of agent-driven decision making, allowing for more adaptive and context-aware memory management. Empirical experiments on six foundation models show superior improvement against existing SOTA baselines. The source code for evaluating performance is available at https://github.com/WujiangXu/A-mem, while the source code of the agentic memory system is available at https://github.com/WujiangXu/A-mem-sys.",
      "authors": [
        "Wujiang Xu and Kai Mei and Hang Gao and Juntao Tan and Zujie Liang and Yongfeng Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-17T18:36:14+00:00",
          "link": "https://arxiv.org/abs/2502.12110v1",
          "size": "603kb",
          "version": "v1"
        },
        {
          "date": "2025-03-03T04:14:02+00:00",
          "link": "https://arxiv.org/abs/2502.12110v2",
          "size": "603kb",
          "version": "v2"
        },
        {
          "date": "2025-03-04T15:09:10+00:00",
          "link": "https://arxiv.org/abs/2502.12110v3",
          "size": "603kb",
          "version": "v3"
        },
        {
          "date": "2025-04-14T15:21:49+00:00",
          "link": "https://arxiv.org/abs/2502.12110v4",
          "size": "603kb",
          "version": "v4"
        },
        {
          "date": "2025-04-18T17:26:57+00:00",
          "link": "https://arxiv.org/abs/2502.12110v5",
          "size": "603kb",
          "version": "v5"
        },
        {
          "date": "2025-05-11T18:10:25+00:00",
          "link": "https://arxiv.org/abs/2502.12110v6",
          "size": "2620kb",
          "version": "v6"
        },
        {
          "date": "2025-05-21T05:16:32+00:00",
          "link": "https://arxiv.org/abs/2502.12110v7",
          "size": "2629kb",
          "version": "v7"
        },
        {
          "date": "2025-05-27T02:44:13+00:00",
          "link": "https://arxiv.org/abs/2502.12110v8",
          "size": "1002kb",
          "version": "v8"
        },
        {
          "date": "2025-06-02T22:21:21+00:00",
          "link": "https://arxiv.org/abs/2502.12110v9",
          "size": "995kb",
          "version": "v9"
        },
        {
          "date": "2025-07-15T00:44:52+00:00",
          "link": "https://arxiv.org/abs/2502.12110v10",
          "size": "599kb",
          "version": "v10"
        }
      ],
      "title": "A-MEM: Agentic Memory for LLM Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12110",
        "HTML": "https://arxiv.org/html/2502.12110",
        "PDF": "https://arxiv.org/pdf/2502.12110"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on memory systems for LLM agents leveraging historical experiences and dynamic organization, not explicitly on processing or enhancing LLM training data."
      },
      "tasks": [
        "Large Language Model"
      ],
      "repo_urls": [
        "https://github.com/wujiangxu/agenticmemory",
        "https://github.com/agiresearch/aios",
        "https://github.com/agiresearch/a-mem",
        "https://github.com/agiresearch/litecua"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10773",
      "abstract": "Self-disclosure is important to help us feel better, yet is often difficult. This difficulty can arise from how we think people are going to react to our self-disclosure. In this workshop paper, we briefly discuss self-disclosure to conversational user interfaces (CUIs) in relation to various social cues. We then, discuss how expressions of uncertainty or representation of a CUI's reasoning could help encourage self-disclosure, by making a CUI's intended \"theory of mind\" more transparent to users.",
      "authors": [
        "Samuel Rhys Cox"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:57:18+00:00",
          "link": "https://arxiv.org/abs/2507.10773v1",
          "size": "906kb",
          "version": "v1"
        }
      ],
      "title": "Theory of Mind and Self-Disclosure to CUIs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10773",
        "HTML": "https://arxiv.org/html/2507.10773v1",
        "PDF": "https://arxiv.org/pdf/2507.10773"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses self-disclosure and conversational user interfaces without focusing on any aspect of processing or managing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.07149",
      "abstract": "Human motion is a behavioral biometric trait that can be used to identify individuals and infer private attributes such as medical conditions. This poses a serious threat to privacy as motion extraction from video and motion capture are increasingly used for a variety of applications, including mixed reality, robotics, medicine, and the quantified self. In order to protect the privacy of the tracked individuals, anonymization techniques that preserve the utility of the data are required. However, anonymizing motion data is a challenging task because there are many dependencies in motion sequences (such as physiological constraints) that, if ignored, make the anonymized motion sequence appear unnatural. In this paper, we propose Pantomime, a full-body anonymization technique for motion data, which uses foundation motion models to generate motion sequences that adhere to the dependencies in the data, thus keeping the utility of the anonymized data high. Our results show that Pantomime can maintain the naturalness of the motion sequences while reducing the identification accuracy to 10%.",
      "authors": [
        "Simon Hanisch",
        "Julian Todt",
        "Thorsten Strufe"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-13T09:22:30+00:00",
          "link": "https://arxiv.org/abs/2501.07149v1",
          "size": "1298kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T09:10:05+00:00",
          "link": "https://arxiv.org/abs/2501.07149v2",
          "size": "1306kb",
          "version": "v2"
        }
      ],
      "title": "Pantomime: Motion Data Anonymization using Foundation Motion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.07149",
        "HTML": "https://arxiv.org/html/2501.07149v2",
        "PDF": "https://arxiv.org/pdf/2501.07149"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces Pantomime for motion data anonymization but does not discuss the processing of LLM training data or any related data operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10613",
      "abstract": "Traditional scaling laws in natural language processing suggest that increasing model size and training data enhances performance. However, recent studies reveal deviations, particularly in large language models, where performance improvements decelerate, which is a phenomenon known as sub-scaling. This paper revisits these scaling laws by examining the impact of data quality and training strategies on model performance. Through extensive empirical analysis of over 400 models, we identify high data density and non-optimal resource allocation as key factors contributing to sub-scaling. High data density leads to diminishing returns due to redundant information, while optimal resource allocation is crucial for sustained performance improvements. We propose a sub-optimal scaling law that better predicts performance in sub-scaling regimes, highlighting the importance of data quality and diversity.",
      "authors": [
        "Zhengyu Chen",
        "Siqi Wang",
        "Teng Xiao",
        "Yudong Wang",
        "Shiqi Chen",
        "Xunliang Cai",
        "Junxian He",
        "Jingang Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T15:15:24+00:00",
          "link": "https://arxiv.org/abs/2507.10613v1",
          "size": "3054kb",
          "version": "v1"
        }
      ],
      "title": "Sub-Scaling Laws: On the Role of Data Density and Training Strategies in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10613",
        "HTML": "https://arxiv.org/html/2507.10613v1",
        "PDF": "https://arxiv.org/pdf/2507.10613"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper examines the impact of data quality and density on LLM performance, addressing data processing factors such as redundancy and resource allocation, which directly relate to optimizing LLM training data and contribute to data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10632",
      "abstract": "In this paper, we propose RFF-GP-HSMM, a fast unsupervised time-series segmentation method that incorporates random Fourier features (RFF) to address the high computational cost of the Gaussian process hidden semi-Markov model (GP-HSMM). GP-HSMM models time-series data using Gaussian processes, requiring inversion of an N times N kernel matrix during training, where N is the number of data points. As the scale of the data increases, matrix inversion incurs a significant computational cost. To address this, the proposed method approximates the Gaussian process with linear regression using RFF, preserving expressive power while eliminating the need for inversion of the kernel matrix. Experiments on the Carnegie Mellon University (CMU) motion-capture dataset demonstrate that the proposed method achieves segmentation performance comparable to that of conventional methods, with approximately 278 times faster segmentation on time-series data comprising 39,200 frames.",
      "authors": [
        "Issei Saito",
        "Masatoshi Nagano",
        "Tomoaki Nakamura",
        "Daichi Mochihashi",
        "and Koki Mimura"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:41:03+00:00",
          "link": "https://arxiv.org/abs/2507.10632v1",
          "size": "351kb",
          "version": "v1"
        }
      ],
      "title": "Scalable Unsupervised Segmentation via Random Fourier Feature-based Gaussian Process",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10632",
        "HTML": "https://arxiv.org/html/2507.10632v1",
        "PDF": "https://arxiv.org/pdf/2507.10632"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for time-series segmentation using random Fourier features, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10986",
      "abstract": "Stellar flare forecasting, a critical research frontier in astronomy, offers profound insights into stellar activity. However, the field is constrained by both the sparsity of recorded flare events and the absence of domain-specific large-scale predictive models. To address these challenges, this study introduces StellarF (Stellar Flare Forecasting), a novel large model that leverages Low-Rank (LoRA) and Adapter techniques to parameter-efficient learning for stellar flare forecasting. At its core, StellarF integrates an flare statistical information module with a historical flare record module, enabling multi-scale pattern recognition from observational data. Extensive experiments on our self-constructed datasets (derived from Kepler and TESS light curves) demonstrate that StellarF achieves state-of-the-art performance compared to existing methods. The proposed prediction paradigm establishes a novel methodological framework for advancing astrophysical research and cross-disciplinary applications.",
      "authors": [
        "Tianyu Su",
        "Zhiqiang Zou",
        "Ali Luo",
        "Xiao Kong",
        "Qingyu Lu",
        "Min Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T04:59:22+00:00",
          "link": "https://arxiv.org/abs/2507.10986v1",
          "size": "17071kb",
          "version": "v1"
        }
      ],
      "title": "StellarF: A Lora-Adapter Integrated Large Model Framework for Stellar Flare Forecasting with Historical & Statistical Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10986",
        "HTML": "https://arxiv.org/html/2507.10986v1",
        "PDF": "https://arxiv.org/pdf/2507.10986"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a model for stellar flare forecasting and does not mention any contribution to LLM training data processing or dataset construction."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11014",
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in code generation across various domains. However, their effectiveness in generating simulation scripts for domain-specific environments like ns-3 remains underexplored. Despite the growing interest in automating network simulations, existing tools primarily focus on interactive automation over rigorous evaluation. To facilitate systematic evaluation, we introduce SIMCODE, the first benchmark to evaluate LLMs' ability to generate ns-3 simulation code from natural language. SIMCODE includes 400 tasks across introductory, intermediate, and advanced levels, with solutions and test cases. Using SIMCODE, we evaluate three prominent LLMs, Gemini-2.0, GPT-4.1, and Qwen-3, across six prompt techniques. Furthermore, investigating task-specific fine-tuning's impact reveals that while GPT-4.1 outperforms others, execution accuracy remains modest, with substantial room for improvement. Error analysis identifies missing headers and API mismatches as dominant failures. Nevertheless, SIMCODE provides a foundational step toward evaluating LLMs and research in domain-aware generative systems.",
      "authors": [
        "Tasnim Ahmed",
        "Mirza Mohammad Azwad",
        "Salimur Choudhury"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T06:14:45+00:00",
          "link": "https://arxiv.org/abs/2507.11014v1",
          "size": "276kb",
          "version": "v1"
        }
      ],
      "title": "SIMCODE: A Benchmark for Natural Language to ns-3 Network Simulation Code Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11014",
        "HTML": "https://arxiv.org/html/2507.11014v1",
        "PDF": "https://arxiv.org/pdf/2507.11014"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces the SIMCODE benchmark for evaluating code generation from natural language, focusing on LLM capability evaluation rather than on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11168",
      "abstract": "The increasing need for robustness, reliability, and determinism in wireless networks for industrial and mission-critical applications is the driver for the growth of new innovative methods. The study presented in this work makes use of machine learning techniques to predict channel quality in a Wi-Fi network in terms of the frame delivery ratio. Predictions can be used proactively to adjust communication parameters at runtime and optimize network operations for industrial applications. Methods including convolutional neural networks and long short-term memory were analyzed on datasets acquired from a real Wi-Fi setup across multiple channels. The models were compared in terms of prediction accuracy and computational complexity. Results show that the frame delivery ratio can be reliably predicted, and convolutional neural networks, although slightly less effective than other models, are more efficient in terms of CPU usage and memory consumption. This enhances the model's usability on embedded and industrial systems.",
      "authors": [
        "Gabriele Formis",
        "Amanda Ericson",
        "Stefan Forsstrom",
        "Kyi Thar",
        "Gianluca Cena",
        "Stefano Scanzio"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:18:32+00:00",
          "link": "https://arxiv.org/abs/2507.11168v1",
          "size": "183kb",
          "version": "v1"
        }
      ],
      "title": "Improving Wi-Fi Network Performance Prediction with Deep Learning Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11168",
        "HTML": "https://arxiv.org/html/2507.11168v1",
        "PDF": "https://arxiv.org/pdf/2507.11168"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using machine learning to predict Wi-Fi network performance, with no mention of LLM training data processing or data engineering specific to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.13367",
      "abstract": "Vertical federated learning has garnered significant attention as it allows clients to train machine learning models collaboratively without sharing local data, which protects the client's local private data. However, existing VFL methods face challenges when dealing with heterogeneous local models among participants, which affects optimization convergence and generalization. To address this challenge, this paper proposes a novel approach called Vertical federated learning for training multiple Heterogeneous models (VFedMH). VFedMH focuses on aggregating the local embeddings of each participant's knowledge during forward propagation. To protect the participants' local embedding values, we propose an embedding protection method based on lightweight blinding factors. In particular, participants obtain local embedding using local heterogeneous models. Then the passive party, who owns only features of the sample, injects the blinding factor into the local embedding and sends it to the active party. The active party aggregates local embeddings to obtain global knowledge embeddings and sends them to passive parties. The passive parties then utilize the global embeddings to propagate forward on their local heterogeneous networks. However, the passive party does not own the sample labels, so the local model gradient cannot be calculated locally. To overcome this limitation, the active party assists the passive party in computing its local heterogeneous model gradients. Then, each participant trains their local model using the heterogeneous model gradients. The objective is to minimize the loss value of their respective local heterogeneous models. Extensive experiments are conducted to demonstrate that VFedMH can simultaneously train multiple heterogeneous models with heterogeneous optimization and outperform some recent methods in model performance.",
      "authors": [
        "Shuo Wang and Keke Gai and Jing Yu and Liehuang Zhu and Kim-Kwang Raymond Choo and Bin Xiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-20T09:22:51+00:00",
          "link": "https://arxiv.org/abs/2310.13367v1",
          "size": "2048kb",
          "version": "v1"
        },
        {
          "date": "2024-02-08T08:24:53+00:00",
          "link": "https://arxiv.org/abs/2310.13367v2",
          "size": "23728kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T10:01:29+00:00",
          "link": "https://arxiv.org/abs/2310.13367v3",
          "size": "14443kb",
          "version": "v3"
        }
      ],
      "title": "EASTER: Embedding Aggregation-based Heterogeneous Models Training in Vertical Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.13367",
        "HTML": "https://arxiv.org/html/2310.13367v3",
        "PDF": "https://arxiv.org/pdf/2310.13367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on federated learning and hierarchical model training, with an emphasis on embedding aggregation methods, and does not discuss processing or creating LLM training data."
      },
      "tasks": [
        "Federated Learning",
        "Vertical Federated Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2312.03908",
      "abstract": "We present a framework for generating convex approximations of complex contact models, incorporating experimentally validated models like Hunt & Crossley coupled with Coulomb's law of friction alongside the principle of maximum dissipation. Our approach is robust across a wide range of stiffness values, making it suitable for both compliant surfaces and rigid approximations. We evaluate these approximations across a wide variety of test cases, detailing properties and limitations. We implement a fully differentiable solution in the open-source robotics toolkit, Drake. Our novel hybrid approach enables computation of gradients for complex geometric models while reusing factorizations from contact resolution. We demonstrate robust simulation of robotic tasks at interactive rates, with accurately resolved stiction and contact transitions, supporting effective sim-to-real transfer.",
      "authors": [
        "Alejandro Castro",
        "Xuchen Han",
        "Joseph Masterjohn"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-06T21:05:39+00:00",
          "link": "https://arxiv.org/abs/2312.03908v1",
          "size": "2550kb",
          "version": "v1"
        },
        {
          "date": "2024-11-18T20:32:39+00:00",
          "link": "https://arxiv.org/abs/2312.03908v2",
          "size": "4731kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T14:02:25+00:00",
          "link": "https://arxiv.org/abs/2312.03908v3",
          "size": "4735kb",
          "version": "v3"
        }
      ],
      "title": "Irrotational Contact Fields",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.03908",
        "HTML": "https://arxiv.org/html/2312.03908v3",
        "PDF": "https://arxiv.org/pdf/2312.03908"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research presents a framework for contact model approximation in robotics, which is unrelated to LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.11238",
      "abstract": "Despite the prevalence of reconstruction-based deep learning methods, time series anomaly detection remains a tremendous challenge. Existing approaches often struggle with limited temporal contexts, insufficient representation of normal patterns, and flawed evaluation metrics, all of which hinder their effectiveness in detecting anomalous behavior. To address these issues, we introduce a $\\textbf{Sim}$ple dissimilarity-based approach for time series $\\textbf{A}$nomaly $\\textbf{D}$etection, referred to as $\\textbf{SimAD}$. Specifically, SimAD first incorporates a patching-based feature extractor capable of processing extended temporal windows and employs the EmbedPatch encoder to fully integrate normal behavioral patterns. Second, we design an innovative ContrastFusion module in SimAD, which strengthens the robustness of anomaly detection by highlighting the distributional differences between normal and abnormal data. Third, we introduce two robust enhanced evaluation metrics, Unbiased Affiliation (UAff) and Normalized Affiliation (NAff), designed to overcome the limitations of existing metrics by providing better distinctiveness and semantic clarity. The reliability of these two metrics has been demonstrated by both theoretical and experimental analyses. Experiments conducted on seven diverse time series datasets clearly demonstrate SimAD's superior performance compared to state-of-the-art methods, achieving relative improvements of $\\textbf{19.85%}$ on F1, $\\textbf{4.44%}$ on Aff-F1, $\\textbf{77.79%}$ on NAff-F1, and $\\textbf{9.69%}$ on AUC on six multivariate datasets. Code and pre-trained models are available at https://github.com/EmorZz1G/SimAD.",
      "authors": [
        "Zhijie Zhong",
        "Zhiwen Yu",
        "Xing Xi",
        "Yue Xu",
        "Wenming Cao",
        "Yiyuan Yang",
        "Kaixiang Yang",
        "Jane You"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-18T09:37:04+00:00",
          "link": "https://arxiv.org/abs/2405.11238v1",
          "size": "2635kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T03:06:06+00:00",
          "link": "https://arxiv.org/abs/2405.11238v2",
          "size": "6287kb",
          "version": "v2"
        }
      ],
      "title": "SimAD: A Simple Dissimilarity-based Approach for Time Series Anomaly Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.11238",
        "HTML": "https://arxiv.org/html/2405.11238v2",
        "PDF": "https://arxiv.org/pdf/2405.11238"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a time series anomaly detection method using dissimilarity-based approaches. It does not involve LLM training data processing."
      },
      "tasks": [
        "Anomaly Detection",
        "Time Series",
        "Time Series Anomaly Detection"
      ],
      "repo_urls": [
        "https://github.com/emorzz1g/simad"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10957",
      "abstract": "Recent advancements in Large Language Models (LLMs) have brought them closer to matching human cognition across a variety of tasks. How well do these models align with human performance in detecting and mapping analogies? Prior research has shown that LLMs can extract similarities from analogy problems but lack robust human-like reasoning. Building on Webb, Holyoak, and Lu (2023), the current study focused on a story-based analogical mapping task and conducted a fine-grained evaluation of LLM reasoning abilities compared to human performance. First, it explored the semantic representation of analogies in LLMs, using sentence embeddings to assess whether they capture the similarity between the source and target texts of an analogy, and the dissimilarity between the source and distractor texts. Second, it investigated the effectiveness of explicitly prompting LLMs to explain analogies. Throughout, we examine whether LLMs exhibit similar performance profiles to those observed in humans by evaluating their reasoning at the level of individual analogies, and not just at the level of overall accuracy (as prior studies have done). Our experiments include evaluating the impact of model size (8B vs. 70B parameters) and performance variation across state-of-the-art model architectures such as GPT-4 and LLaMA3. This work advances our understanding of the analogical reasoning abilities of LLMs and their potential as models of human reasoning.",
      "authors": [
        "Kalit Inani",
        "Keshav Kabra",
        "Vijay Marupudi",
        "Sashank Varma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T03:40:21+00:00",
          "link": "https://arxiv.org/abs/2507.10957v1",
          "size": "600kb",
          "version": "v1"
        }
      ],
      "title": "Modeling Understanding of Story-Based Analogies Using Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10957",
        "HTML": "https://arxiv.org/html/2507.10957v1",
        "PDF": "https://arxiv.org/pdf/2507.10957"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study evaluates the analogical reasoning abilities of LLMs and does not focus on training data processing or engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10624",
      "abstract": "Large Language Models (LLMs) display striking surface fluency yet systematically fail at tasks requiring symbolic reasoning, arithmetic accuracy, and logical consistency. This paper offers a structural diagnosis of such failures, revealing a persistent gap between \\textit{comprehension} and \\textit{competence}. Through controlled experiments and architectural analysis, we demonstrate that LLMs often articulate correct principles without reliably applying them--a failure rooted not in knowledge access, but in computational execution. We term this phenomenon the computational \\textit{split-brain syndrome}, where instruction and action pathways are geometrically and functionally dissociated. This core limitation recurs across domains, from mathematical operations to relational inferences, and explains why model behavior remains brittle even under idealized prompting. We argue that LLMs function as powerful pattern completion engines, but lack the architectural scaffolding for principled, compositional reasoning. Our findings delineate the boundary of current LLM capabilities and motivate future models with metacognitive control, principle lifting, and structurally grounded execution. This diagnosis also clarifies why mechanistic interpretability findings may reflect training-specific pattern coordination rather than universal computational principles, and why the geometric separation between instruction and execution pathways suggests limitations in neural introspection and mechanistic analysis.",
      "authors": [
        "Zheng Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T04:01:45+00:00",
          "link": "https://arxiv.org/abs/2507.10624v1",
          "size": "1041kb",
          "version": "v1"
        }
      ],
      "title": "Comprehension Without Competence: Architectural Limits of LLMs in Symbolic Computation and Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10624",
        "HTML": "https://arxiv.org/html/2507.10624v1",
        "PDF": "https://arxiv.org/pdf/2507.10624"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides an analysis of architectural limitations in LLMs with respect to symbolic reasoning and does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10859",
      "abstract": "The rapid progress of Large Language Models (LLMs) has empowered omni models to act as voice assistants capable of understanding spoken dialogues. These models can process multimodal inputs beyond text, such as speech and visual data, enabling more context-aware interactions. However, current benchmarks fall short in comprehensively evaluating how well these models generate context-aware responses, particularly when it comes to implicitly understanding fine-grained speech characteristics, such as pitch, emotion, timbre, and volume or the environmental acoustic context such as background sounds. Additionally, they inadequately assess the ability of models to align paralinguistic cues with complementary visual signals to inform their responses. To address these gaps, we introduce MultiVox, the first omni voice assistant benchmark designed to evaluate the ability of voice assistants to integrate spoken and visual cues including paralinguistic speech features for truly multimodal understanding. Specifically, MultiVox includes 1000 human-annotated and recorded speech dialogues that encompass diverse paralinguistic features and a range of visual cues such as images and videos. Our evaluation on 9 state-of-the-art models reveals that, although humans excel at these tasks, current models consistently struggle to produce contextually grounded responses.",
      "authors": [
        "Ramaneswaran Selvakumar",
        "Ashish Seth",
        "Nishit Anand",
        "Utkarsh Tyagi",
        "Sonal Kumar",
        "Sreyan Ghosh",
        "Dinesh Manocha"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T23:20:42+00:00",
          "link": "https://arxiv.org/abs/2507.10859v1",
          "size": "4049kb",
          "version": "v1"
        }
      ],
      "title": "MultiVox: Benchmarking Voice Assistants for Multimodal Interactions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10859",
        "HTML": "https://arxiv.org/html/2507.10859v1",
        "PDF": "https://arxiv.org/pdf/2507.10859"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a benchmark (MultiVox) for evaluating multimodal interaction in voice assistants but does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10967",
      "abstract": "This position paper introduces Self++, a novel nine-level framework for co-determined living in the Metaverse, grounded in Self-Determination Theory. Self++ prioritises human flourishing by progressively cultivating competence, autonomy, and relatedness through dynamic human-AI collaboration in extended reality (XR). Unlike technologically deterministic approaches, Self++ emphasises user empowerment by enhancing competency, mitigating cognitive biases and leveraging XR's immersive capabilities. Key research directions proposed include exploring the boundaries of user-defined AI autonomy, designing for meaningful social connection in XR, and establishing proactive ethical safeguards. Ultimately, Self++ offers a roadmap for creating a human-centred, AI-enhanced Metaverse where technology amplifies, rather than diminishes, human potential.",
      "authors": [
        "Thammathip Piumsomboon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T04:11:59+00:00",
          "link": "https://arxiv.org/abs/2507.10967v1",
          "size": "38kb",
          "version": "v1"
        }
      ],
      "title": "Self++: Merging Human and AI for Co-Determined XR Living in the Metaverse",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10967",
        "HTML": "https://arxiv.org/html/2507.10967v1",
        "PDF": "https://arxiv.org/pdf/2507.10967"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a framework for human-AI collaboration in the Metaverse and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.04051",
      "abstract": "Diffusion models exhibit impressive scalability in robotic task learning, yet they struggle to adapt to novel, highly dynamic environments. This limitation primarily stems from their constrained replanning ability: they either operate at a low frequency due to a time-consuming iterative sampling process, or are unable to adapt to unforeseen feedback in case of rapid replanning. To address these challenges, we propose RA-DP, a novel diffusion policy framework with training-free high-frequency replanning ability that solves the above limitations in adapting to unforeseen dynamic environments. Specifically, our method integrates guidance signals which are often easily obtained in the new environment during the diffusion sampling process, and utilizes a novel action queue mechanism to generate replanned actions at every denoising step without retraining, thus forming a complete training-free framework for robot motion adaptation in unseen environments. Extensive evaluations have been conducted in both well-recognized simulation benchmarks and real robot tasks. Results show that RA-DP outperforms the state-of-the-art diffusion-based methods in terms of replanning frequency and success rate. Moreover, we show that our framework is theoretically compatible with any training-free guidance signal.",
      "authors": [
        "Xi Ye",
        "Rui Heng Yang",
        "Jun Jin",
        "Yinchuan Li",
        "Amir Rasouli"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T03:07:39+00:00",
          "link": "https://arxiv.org/abs/2503.04051v1",
          "size": "1406kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T14:18:16+00:00",
          "link": "https://arxiv.org/abs/2503.04051v2",
          "size": "1204kb",
          "version": "v2"
        }
      ],
      "title": "RA-DP: Rapid Adaptive Diffusion Policy for Training-Free High-frequency Robotics Replanning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04051",
        "HTML": "https://arxiv.org/html/2503.04051v2",
        "PDF": "https://arxiv.org/pdf/2503.04051"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The RA-DP method addresses high-frequency replanning in robotics, focusing on diffusion models rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.18191",
      "abstract": "Cloud platforms host thousands of tenants that demand POSIX semantics, high throughput, and rapid evolution from their storage layer. Kernel-native distributed file systems supply raw speed, but their privileged code base couples every release to the kernel, widens the blast radius of crashes, and slows innovation. FUSE-based distributed file systems flip those trade-offs: they run in user space for fast deployment and strong fault isolation, yet the FUSE interface disables the kernel's write-back page cache whenever strong consistency is required. Practitioners must therefore choose between (i) weak consistency with fast write-back caching or (ii) strong consistency with slow write-through I/O, an limitation that has kept FUSE distributed file systems out of write-intensive cloud workloads.\n  To this end, We present DistFUSE, the first distributed FUSE file system that delivers write-back kernel caching and strong consistency. DistFUSE achieves this by offloading userspace consistency control to the kernel driver, allowing coordinated access to the kernel's page cache across nodes. This design eliminates blind local cache updates and ensures cluster-wide strong consistency without compromising performance. In our evaluation, DistFUSE achieves up to 68.0% higher throughput and 40.4% lower latency than the existing write-through design of FUSE-based distributed file system.",
      "authors": [
        "Haoyu Li",
        "Jingkai Fu",
        "Qing Li",
        "Windsor Hsu",
        "Asaf Cidon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Operating Systems (cs.OS)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-23T20:18:16+00:00",
          "link": "https://arxiv.org/abs/2503.18191v1",
          "size": "246kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T19:51:09+00:00",
          "link": "https://arxiv.org/abs/2503.18191v2",
          "size": "336kb",
          "version": "v2"
        }
      ],
      "title": "Enabling the Write-Back Page Cache with Strong Consistency in Distributed Userspace File Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.18191",
        "HTML": "https://arxiv.org/html/2503.18191v2",
        "PDF": "https://arxiv.org/pdf/2503.18191"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents DistFUSE for improving write-back kernel caching and strong consistency in distributed file systems, not addressing LLM training data preprocessing or dataset modification."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10601",
      "abstract": "Diffusion MRI (dMRI) tractography is currently the only method for in vivo mapping of the brain's white matter (WM) connections. Tractometry is an advanced tractography analysis technique for along-tract profiling to investigate the morphology and microstructural properties along the fiber tracts. Tractometry has become an essential tool for studying local along-tract differences between different populations (e.g., health vs disease). In this study, we propose a novel atlas-guided fine-scale tractometry method, namely AGFS-Tractometry, that leverages tract spatial information and permutation testing to enhance the along-tract statistical analysis between populations. There are two major contributions in AGFS-Tractometry. First, we create a novel atlas-guided tract profiling template that enables consistent, fine-scale, along-tract parcellation of subject-specific fiber tracts. Second, we propose a novel nonparametric permutation testing group comparison method to enable simultaneous analysis across all along-tract parcels while correcting for multiple comparisons. We perform experimental evaluations on synthetic datasets with known group differences and in vivo real data. We compare AGFS-Tractometry with two state-of-the-art tractometry methods, including Automated Fiber-tract Quantification (AFQ) and BUndle ANalytics (BUAN). Our results show that the proposed AGFS-Tractometry obtains enhanced sensitivity and specificity in detecting local WM differences. In the real data analysis experiments, AGFS-Tractometry can identify more regions with significant differences, which are anatomically consistent with the existing literature. Overall, these demonstrate the ability of AGFS-Tractometry to detect subtle or spatially localized WM group-level differences. The created tract profiling template and related code are available at: https://github.com/ZhengRuixi/AGFS-Tractometry.git.",
      "authors": [
        "Ruixi Zheng",
        "Wei Zhang",
        "Yijie Li",
        "Xi Zhu",
        "Zhou Lan",
        "Jarrett Rushmore",
        "Yogesh Rathi",
        "Nikos Makris",
        "Lauren J. O'Donnell and Fan Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T15:48:02+00:00",
          "link": "https://arxiv.org/abs/2507.10601v1",
          "size": "4843kb",
          "version": "v1"
        }
      ],
      "title": "AGFS-Tractometry: A Novel Atlas-Guided Fine-Scale Tractometry Approach for Enhanced Along-Tract Group Statistical Comparison Using Diffusion MRI Tractography",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10601",
        "HTML": "https://arxiv.org/html/2507.10601v1",
        "PDF": "https://arxiv.org/pdf/2507.10601"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on a novel tractometry approach using diffusion MRI for brain tract analysis, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10644",
      "abstract": "The concept of the Web of Agents (WoA), which transforms the static, document-centric Web into an environment of autonomous agents acting on users' behalf, has attracted growing interest as large language models (LLMs) become more capable. However, research in this area is still fragmented across different communities. Contemporary surveys catalog the latest LLM-powered frameworks, while the rich histories of Multi-Agent Systems (MAS) and the Semantic Web are often treated as separate, legacy domains. This fragmentation obscures the intellectual lineage of modern systems and hinders a holistic understanding of the field's trajectory. We present the first comprehensive evolutionary overview of the WoA. We show that modern protocols like A2A and the MCP, are direct evolutionary responses to the well-documented limitations of earlier standards like FIPA standards and OWL-based semantic agents. To systematize this analysis, we introduce a four-axis taxonomy (semantic foundation, communication paradigm, locus of intelligence, discovery mechanism). This framework provides a unified analytical lens for comparing agent architectures across all generations, revealing a clear line of descent where others have seen a disconnect. Our analysis identifies a paradigm shift in the 'locus of intelligence': from being encoded in external data (Semantic Web) or the platform (MAS) to being embedded within the agent's core model (LLM). This shift is foundational to modern Agentic AI, enabling the scalable and adaptive systems the WoA has long envisioned. We conclude that while new protocols are essential, they are insufficient for building a robust, open, trustworthy ecosystem. Finally, we argue that the next research frontier lies in solving persistent socio-technical challenges, and we map out a new agenda focused on decentralized identity, economic models, security, and governance for the emerging WoA.",
      "authors": [
        "Tatiana Petrova (1)",
        "Aleksandr Puzikov (1)",
        "Boris Bliznukov (1)",
        "Radu State (1) ((1) SEDAN SnT",
        "University of Luxembourg",
        "Luxembourg",
        "Luxembourg)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)",
        "Human-Computer Interaction (cs.HC)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:47:19+00:00",
          "link": "https://arxiv.org/abs/2507.10644v1",
          "size": "1312kb",
          "version": "v1"
        }
      ],
      "title": "From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10644",
        "HTML": "https://arxiv.org/html/2507.10644v1",
        "PDF": "https://arxiv.org/pdf/2507.10644"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an overview of agent architectures in the Web of Agents and does not address LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10781",
      "abstract": "We present a logic programming framework that orchestrates multiple variants of an optimization problem and reasons about their results to support high-stakes medical decision-making. The logic programming layer coordinates the construction and evaluation of multiple optimization formulations, translating solutions into logical facts that support further symbolic reasoning and ensure efficient resource allocation-specifically targeting the \"right patient, right platform, right escort, right time, right destination\" principle. This capability is integrated into GuardianTwin, a decision support system for Forward Medical Evacuation (MEDEVAC), where rapid and explainable resource allocation is critical. Through a series of experiments, our framework demonstrates an average reduction in casualties by 35.75 % compared to standard baselines. Additionally, we explore how users engage with the system via an intuitive interface that delivers explainable insights, ultimately enhancing decision-making in critical situations. This work demonstrates how logic programming can serve as a foundation for modular, interpretable, and operationally effective optimization in mission-critical domains.",
      "authors": [
        "Jaikrishna Manojkumar Patil",
        "Adam Chapman",
        "Richard Knuszka",
        "John Chapman",
        "Paulo Shakarian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T20:12:51+00:00",
          "link": "https://arxiv.org/abs/2507.10781v1",
          "size": "4946kb",
          "version": "v1"
        }
      ],
      "title": "Reasoning about Medical Triage Optimization with Logic Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10781",
        "HTML": "https://arxiv.org/html/2507.10781v1",
        "PDF": "https://arxiv.org/pdf/2507.10781"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about logic programming for medical triage optimization and does not discuss LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11387",
      "abstract": "Selecting an appropriate divergence measure is a critical aspect of machine learning, as it directly impacts model performance. Among the most widely used, we find the Kullback-Leibler (KL) divergence, originally introduced in kinetic theory as a measure of relative entropy between probability distributions. Just as in machine learning, the ability to quantify the proximity of probability distributions plays a central role in kinetic theory. In this paper, we present a comparative review of divergence measures rooted in kinetic theory, highlighting their theoretical foundations and exploring their potential applications in machine learning and artificial intelligence.",
      "authors": [
        "Gennaro Auricchio",
        "Giovanni Brigati",
        "Paolo Giudici and Giuseppe Toscani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Mathematical Physics (math-ph)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)",
        "Mathematical Physics (math.MP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:56:25+00:00",
          "link": "https://arxiv.org/abs/2507.11387v1",
          "size": "69kb",
          "version": "v1"
        }
      ],
      "title": "From Kinetic Theory to AI: a Rediscovery of High-Dimensional Divergences and Their Properties",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11387",
        "HTML": "https://arxiv.org/html/2507.11387v1",
        "PDF": "https://arxiv.org/pdf/2507.11387"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper reviews divergence measures and their applications in AI, without mentioning any LLM training data processing techniques or contributions."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11406",
      "abstract": "Heegaard splittings provide a natural representation of closed 3-manifolds by gluing handlebodies along a common surface. These splittings can be equivalently given by two finite sets of meridians lying in the surface, which define a Heegaard diagram. We present a data structure to effectively represent Heegaard diagrams as normal curves with respect to triangulations of a surface of complexity measured by the space required to express the normal coordinates' vectors in binary. This structure can be significantly more compressed than triangulations of 3-manifolds, given exponential gains for some families. Even with this succinct definition of complexity, we establish polynomial time algorithms for comparing and manipulating diagrams, performing stabilizations, detecting trivial stabilizations and reductions, and computing topological invariants of the underlying manifolds, such as their fundamental and first homology groups. We also contrast early implementations of our techniques with standard software programs for 3-manifolds, achieving better precision and faster algorithms for the average cases and exponential gains in speed for some particular presentations of the inputs.",
      "authors": [
        "Henrique Ennes and Cl\\'ement Maria"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Geometry (cs.CG)",
        "Data Structures and Algorithms (cs.DS)",
        "Geometric Topology (math.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:24:49+00:00",
          "link": "https://arxiv.org/abs/2507.11406v1",
          "size": "265kb",
          "version": "v1"
        }
      ],
      "title": "Compressed data structures for Heegaard splittings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11406",
        "HTML": "https://arxiv.org/html/2507.11406v1",
        "PDF": "https://arxiv.org/pdf/2507.11406"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses data structures for representing 3-manifolds, which is unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10749",
      "abstract": "Safety-critical scenarios are essential for training and evaluating autonomous driving (AD) systems, yet remain extremely rare in real-world driving datasets. To address this, we propose Real-world Crash Grounding (RCG), a scenario generation framework that integrates crash-informed semantics into adversarial perturbation pipelines. We construct a safety-aware behavior representation through contrastive pre-training on large-scale driving logs, followed by fine-tuning on a small, crash-rich dataset with approximate trajectory annotations extracted from video. This embedding captures semantic structure aligned with real-world accident behaviors and supports selection of adversary trajectories that are both high-risk and behaviorally realistic. We incorporate the resulting selection mechanism into two prior scenario generation pipelines, replacing their handcrafted scoring objectives with an embedding-based criterion. Experimental results show that ego agents trained against these generated scenarios achieve consistently higher downstream success rates, with an average improvement of 9.2% across seven evaluation settings. Qualitative and quantitative analyses further demonstrate that our approach produces more plausible and nuanced adversary behaviors, enabling more effective and realistic stress testing of AD systems. Code and tools will be released publicly.",
      "authors": [
        "Benjamin Stoler",
        "Juliet Yang",
        "Jonathan Francis",
        "Jean Oh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:16:13+00:00",
          "link": "https://arxiv.org/abs/2507.10749v1",
          "size": "26974kb",
          "version": "v1"
        }
      ],
      "title": "RCG: Safety-Critical Scenario Generation for Robust Autonomous Driving via Real-World Crash Grounding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10749",
        "HTML": "https://arxiv.org/html/2507.10749v1",
        "PDF": "https://arxiv.org/pdf/2507.10749"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a scenario generation framework for autonomous driving using real-world crash data but does not focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10881",
      "abstract": "Tubular tree structures, such as blood vessels and airways, are essential in human anatomy and accurately tracking them while preserving their topology is crucial for various downstream tasks. Trexplorer is a recurrent model designed for centerline tracking in 3D medical images but it struggles with predicting duplicate branches and terminating tracking prematurely. To address these issues, we present Trexplorer Super, an enhanced version that notably improves performance through novel advancements. However, evaluating centerline tracking models is challenging due to the lack of public datasets. To enable thorough evaluation, we develop three centerline datasets, one synthetic and two real, each with increasing difficulty. Using these datasets, we conduct a comprehensive evaluation of existing state-of-the-art (SOTA) models and compare them with our approach. Trexplorer Super outperforms previous SOTA models on every dataset. Our results also highlight that strong performance on synthetic data does not necessarily translate to real datasets. The code and datasets are available at https://github.com/RomStriker/Trexplorer-Super.",
      "authors": [
        "Roman Naeem",
        "David Hagerman",
        "Jennifer Alv\\'en",
        "Lennart Svensson",
        "and Fredrik Kahl"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T00:51:30+00:00",
          "link": "https://arxiv.org/abs/2507.10881v1",
          "size": "8654kb",
          "version": "v1"
        }
      ],
      "title": "Trexplorer Super: Topologically Correct Centerline Tree Tracking of Tubular Objects in CT Volumes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10881",
        "HTML": "https://arxiv.org/html/2507.10881v1",
        "PDF": "https://arxiv.org/pdf/2507.10881"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper develops new datasets for evaluating models, which involves data processing, but it is primarily focused on model evaluation rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11199",
      "abstract": "Mutation testing has emerged as a powerful technique for evaluating the effectiveness of test suites for Deep Neural Networks. Among existing approaches, the statistical mutant killing criterion of DeepCrime has leveraged statistical testing to determine whether a mutant significantly differs from the original model. However, it suffers from a critical limitation: it violates the monotonicity property, meaning that expanding a test set may result in previously killed mutants no longer being classified as killed. In this technical report, we propose a new formulation of statistical mutant killing based on Fisher exact test that preserves the statistical rigour of it while ensuring monotonicity.",
      "authors": [
        "Jinhan Kim",
        "Nargiz Humbatova",
        "Gunel Jahangirova",
        "Shin Yoo",
        "Paolo Tonella"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T11:12:08+00:00",
          "link": "https://arxiv.org/abs/2507.11199v1",
          "size": "37kb",
          "version": "v1"
        }
      ],
      "title": "New Formulation of DNN Statistical Mutation Killing for Ensuring Monotonicity: A Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11199",
        "HTML": "https://arxiv.org/html/2507.11199v1",
        "PDF": "https://arxiv.org/pdf/2507.11199"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with mutation testing for Deep Neural Networks, focusing on statistical mutant killing and monotonicity. It does not cover LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05313",
      "abstract": "We investigate the use of Long Short-Term Memory (LSTM) and Decomposition-LSTM (DLSTM) networks, combined with an ensemble algorithm, to predict solar flare occurrences using time-series data from the GOES catalog. The dataset spans from 2003 to 2023 and includes 151,071 flare events. Among approximately possible patterns, 7,552 yearly pattern windows are identified, highlighting the challenge of long-term forecasting due to the Sun's complex, self-organized criticality-driven behavior. A sliding window technique is employed to detect temporal quasi-patterns in both irregular and regularized flare time series. Regularization reduces complexity, enhances large flare activity, and captures active days more effectively. To address class imbalance, resampling methods are applied. LSTM and DLSTM models are trained on sequences of peak fluxes and waiting times from irregular time series, while LSTM and DLSTM, integrated with an ensemble approach, are applied to sliding windows of regularized time series with a 3-hour interval. Performance metrics, particularly TSS (0.74), recall (0.95) and the area under the curve (AUC=0.87) in the receiver operating characteristic (ROC), indicate that DLSTM with an ensemble approach on regularized time series outperforms other models, offering more accurate large-flare forecasts with fewer false errors compared to models trained on irregular time series. The superior performance of DLSTM is attributed to its ability to decompose time series into trend and seasonal components, effectively isolating random noise. This study underscores the potential of advanced machine learning techniques for solar flare prediction and highlights the importance of incorporating various solar cycle phases and resampling strategies to enhance forecasting reliability.",
      "authors": [
        "Zeinab Hassani",
        "Davud Mohammadpur",
        "Hossein Safari"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Solar and Stellar Astrophysics (astro-ph.SR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T13:17:38+00:00",
          "link": "https://arxiv.org/abs/2507.05313v1",
          "size": "1627kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T07:37:58+00:00",
          "link": "https://arxiv.org/abs/2507.05313v2",
          "size": "1627kb",
          "version": "v2"
        }
      ],
      "title": "Solar Flare Prediction Using Long Short-term Memory (LSTM) and Decomposition-LSTM with Sliding Window Pattern Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05313",
        "PDF": "https://arxiv.org/pdf/2507.05313"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper pertains to solar flare prediction using LSTM models on time-series data. It does not contribute to LLM training data processing or any data engineering related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11070",
      "abstract": "We propose a transfer learning framework for sound source reconstruction in Near-field Acoustic Holography (NAH), which adapts a well-trained data-driven model from one type of sound source to another using a physics-informed procedure. The framework comprises two stages: (1) supervised pre-training of a complex-valued convolutional neural network (CV-CNN) on a large dataset, and (2) purely physics-informed fine-tuning on a single data sample based on the Kirchhoff-Helmholtz integral. This method follows the principles of transfer learning by enabling generalization across different datasets through physics-informed adaptation. The effectiveness of the approach is validated by transferring a pre-trained model from a rectangular plate dataset to a violin top plate dataset, where it shows improved reconstruction accuracy compared to the pre-trained model and delivers performance comparable to that of Compressive-Equivalent Source Method (C-ESM). Furthermore, for successful modes, the fine-tuned model outperforms both the pre-trained model and C-ESM in accuracy.",
      "authors": [
        "Xinmeng Luan",
        "Mirco Pezzoli",
        "Fabio Antonacci",
        "Augusto Sarti"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:03:05+00:00",
          "link": "https://arxiv.org/abs/2507.11070v1",
          "size": "2054kb",
          "version": "v1"
        }
      ],
      "title": "Physics-Informed Transfer Learning for Data-Driven Sound Source Reconstruction in Near-Field Acoustic Holography",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11070",
        "HTML": "https://arxiv.org/html/2507.11070v1",
        "PDF": "https://arxiv.org/pdf/2507.11070"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a transfer learning framework for sound source reconstruction and does not address LLM training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11090",
      "abstract": "With the rapid growth of online social networks, strengthening their stability has emerged as a key research focus. This study aims to identify influential relationships that significantly impact community stability. In this paper, we introduce and explore the anchor trussness reinforcement problem to reinforce the overall user engagement of networks by anchoring some edges. Specifically, for a given graph $G$ and a budget $b$, we aim to identify $b$ edges whose anchoring maximizes the trussness gain, which is the cumulative increment of trussness across all edges in $G$. We establish the NP-hardness of the problem. To address this problem, we introduce a greedy framework that iteratively selects the current best edge. To scale for larger networks, we first propose an upward-route method to constrain potential trussness increment edges. Augmented with a support check strategy, this approach enables the efficient computation of the trussness gain for anchoring one edge. Then, we design a classification tree structure to minimize redundant computations in each iteration by organizing edges based on their trussness. We conduct extensive experiments on 8 real-world networks to validate the efficiency and effectiveness of the proposed model and methods.",
      "authors": [
        "Hongbo Qiu",
        "Renjie Sun",
        "Chen chen",
        "Xiaoyang Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:33:02+00:00",
          "link": "https://arxiv.org/abs/2507.11090v1",
          "size": "3253kb",
          "version": "v1"
        }
      ],
      "title": "Enhance Stability of Network by Edge Anchor",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11090",
        "HTML": "https://arxiv.org/html/2507.11090v1",
        "PDF": "https://arxiv.org/pdf/2507.11090"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study explores methods for reinforcing network stability by anchoring network edges, which does not involve any LLM training data processing or relevant data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11183",
      "abstract": "Federated learning is a machine learning approach that enables multiple devices (i.e., agents) to train a shared model cooperatively without exchanging raw data. This technique keeps data localized on user devices, ensuring privacy and security, while each agent trains the model on their own data and only shares model updates. The communication overhead is a significant challenge due to the frequent exchange of model updates between the agents and the central server. In this paper, we propose a communication-efficient federated learning scheme that utilizes low-rank approximation of neural network gradients and quantization to significantly reduce the network load of the decentralized learning process with minimal impact on the model's accuracy.",
      "authors": [
        "Dimitrios Kritsiolis and Constantine Kotropoulos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:37:59+00:00",
          "link": "https://arxiv.org/abs/2507.11183v1",
          "size": "992kb",
          "version": "v1"
        }
      ],
      "title": "Quantized Rank Reduction: A Communications-Efficient Federated Learning Scheme for Network-Critical Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11183",
        "HTML": "https://arxiv.org/html/2507.11183v1",
        "PDF": "https://arxiv.org/pdf/2507.11183"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work is focused on federated learning and minimizing communication overhead, with no discussion related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10432",
      "abstract": "With the rapid advancements in Artificial Intelligence Generated Image (AGI) technology, the accurate assessment of their quality has become an increasingly vital requirement. Prevailing methods typically rely on cross-modal models like CLIP or BLIP to evaluate text-image alignment and visual quality. However, when applied to AGIs, these methods encounter two primary challenges: semantic misalignment and details perception missing. To address these limitations, we propose Text-Visual Semantic Constrained AI-Generated Image Quality Assessment (SC-AGIQA), a unified framework that leverages text-visual semantic constraints to significantly enhance the comprehensive evaluation of both text-image consistency and perceptual distortion in AI-generated images. Our approach integrates key capabilities from multiple models and tackles the aforementioned challenges by introducing two core modules: the Text-assisted Semantic Alignment Module (TSAM), which leverages Multimodal Large Language Models (MLLMs) to bridge the semantic gap by generating an image description and comparing it against the original prompt for a refined consistency check, and the Frequency-domain Fine-Grained Degradation Perception Module (FFDPM), which draws inspiration from Human Visual System (HVS) properties by employing frequency domain analysis combined with perceptual sensitivity weighting to better quantify subtle visual distortions and enhance the capture of fine-grained visual quality details in images. Extensive experiments conducted on multiple benchmark datasets demonstrate that SC-AGIQA outperforms existing state-of-the-art methods. The code is publicly available at https://github.com/mozhu1/SC-AGIQA.",
      "authors": [
        "Qiang Li and Qingsen Yan and Haojian Huang and Peng Wu and Haokui Zhang and Yanning Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:21:05+00:00",
          "link": "https://arxiv.org/abs/2507.10432v1",
          "size": "4656kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T04:56:51+00:00",
          "link": "https://arxiv.org/abs/2507.10432v2",
          "size": "3000kb",
          "version": "v2"
        }
      ],
      "title": "Text-Visual Semantic Constrained AI-Generated Image Quality Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10432",
        "HTML": "https://arxiv.org/html/2507.10432v2",
        "PDF": "https://arxiv.org/pdf/2507.10432"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about assessing the quality of AI-generated images using text-visual semantic constraints, and does not address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11098",
      "abstract": "In the Orthogonal Vectors problem (OV), we are given two families $A, B$ of subsets of $\\{1,\\ldots,d\\}$, each of size $n$, and the task is to decide whether there exists a pair $a \\in A$ and $b \\in B$ such that $a \\cap b = \\emptyset$. Straightforward algorithms for this problem run in $\\mathcal{O}(n^2 \\cdot d)$ or $\\mathcal{O}(2^d \\cdot n)$ time, and assuming SETH, there is no $2^{o(d)}\\cdot n^{2-\\varepsilon}$ time algorithm that solves this problem for any constant $\\varepsilon > 0$.\n  Williams (FOCS 2024) presented a $\\tilde{\\mathcal{O}}(1.35^d \\cdot n)$-time algorithm for the problem, based on the succinct equality-rank decomposition of the disjointness matrix. In this paper, we present a combinatorial algorithm that runs in randomized time $\\tilde{\\mathcal{O}}(1.25^d n)$. This can be improved to $\\mathcal{O}(1.16^d \\cdot n)$ using computer-aided evaluations.\n  We generalize our result to the $k$-Orthogonal Vectors problem, where given $k$ families $A_1,\\ldots,A_k$ of subsets of $\\{1,\\ldots,d\\}$, each of size $n$, the task is to find elements $a_i \\in A_i$ for every $i \\in \\{1,\\ldots,k\\}$ such that $a_1 \\cap a_2 \\cap \\ldots \\cap a_k = \\emptyset$. We show that for every fixed $k \\ge 2$, there exists $\\varepsilon_k > 0$ such that the $k$-OV problem can be solved in time $\\mathcal{O}(2^{(1 - \\varepsilon_k)\\cdot d}\\cdot n)$. We also show that, asymptotically, this is the best we can hope for: for any $\\varepsilon > 0$ there exists a $k \\ge 2$ such that $2^{(1 - \\varepsilon)\\cdot d} \\cdot n^{\\mathcal{O}(1)}$ time algorithm for $k$-Orthogonal Vectors would contradict the Set Cover Conjecture.",
      "authors": [
        "Anita D\\\"urr",
        "Evangelos Kipouridis",
        "Karol W\\k{e}grzycki"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:45:24+00:00",
          "link": "https://arxiv.org/abs/2507.11098v1",
          "size": "51kb",
          "version": "v1"
        }
      ],
      "title": "Faster algorithms for k-Orthogonal Vectors in low dimension",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11098",
        "HTML": "https://arxiv.org/html/2507.11098v1",
        "PDF": "https://arxiv.org/pdf/2507.11098"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on algorithms for the k-Orthogonal Vectors problem and does not discuss any aspect of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11252",
      "abstract": "Smoke is the first visible indicator of a wildfire.With the advancement of deep learning, image-based smoke detection has become a crucial method for detecting and preventing forest fires. However, the scarcity of smoke image data from forest fires is one of the significant factors hindering the detection of forest fire smoke. Image generation models offer a promising solution for synthesizing realistic smoke images. However, current inpainting models exhibit limitations in generating high-quality smoke representations, particularly manifesting as inconsistencies between synthesized smoke and background contexts. To solve these problems, we proposed a comprehensive framework for generating forest fire smoke images. Firstly, we employed the pre-trained segmentation model and the multimodal model to obtain smoke masks and image captions.Then, to address the insufficient utilization of masks and masked images by inpainting models, we introduced a network architecture guided by mask and masked image features. We also proposed a new loss function, the mask random difference loss, which enhances the consistency of the generated effects around the mask by randomly expanding and eroding the mask edges.Finally, to generate a smoke image dataset using random masks for subsequent detection tasks, we incorporated smoke characteristics and use a multimodal large language model as a filtering tool to select diverse and reasonable smoke images, thereby improving the quality of the synthetic dataset. Experiments showed that our generated smoke images are realistic and diverse, and effectively enhance the performance of forest fire smoke detection models. Code is available at https://github.com/wghr123/MFGDiffusion.",
      "authors": [
        "Guanghao Wu",
        "Chen Xu",
        "Hai Song",
        "Chong Wang",
        "Qixing Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:25:35+00:00",
          "link": "https://arxiv.org/abs/2507.11252v1",
          "size": "12126kb",
          "version": "v1"
        }
      ],
      "title": "MFGDiffusion: Mask-Guided Smoke Synthesis for Enhanced Forest Fire Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11252",
        "HTML": "https://arxiv.org/html/2507.11252v1",
        "PDF": "https://arxiv.org/pdf/2507.11252"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper proposes a framework for generating a smoke image dataset using data generation and filtering techniques, focusing on creating high-quality training data for image detection models."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.05786",
      "abstract": "We study the problem of online convex optimization (OCO) under unknown linear constraints that are either static, or stochastically time-varying. For this problem, we introduce an algorithm that we term Optimistically Safe OCO (OSOCO) and show that it enjoys $\\tilde{O}(\\sqrt{T})$ regret and no constraint violation. In the case of static linear constraints, this improves on the previous best known $\\tilde{O}(T^{2/3})$ regret under the same assumptions. In the case of stochastic time-varying constraints, our work supplements existing results that show $O(\\sqrt{T})$ regret and $O(\\sqrt{T})$ cumulative violation under more general convex constraints and a different set of assumptions. In addition to our theoretical guarantees, we also give numerical results that further validate the effectiveness of our approach.",
      "authors": [
        "Spencer Hutchinson",
        "Tianyi Chen",
        "Mahnoosh Alizadeh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-09T04:01:39+00:00",
          "link": "https://arxiv.org/abs/2403.05786v1",
          "size": "980kb",
          "version": "v1"
        },
        {
          "date": "2024-05-27T22:07:51+00:00",
          "link": "https://arxiv.org/abs/2403.05786v2",
          "size": "1717kb",
          "version": "v2"
        },
        {
          "date": "2024-10-14T22:10:38+00:00",
          "link": "https://arxiv.org/abs/2403.05786v3",
          "size": "1734kb",
          "version": "v3"
        }
      ],
      "title": "Optimistic Safety for Online Convex Optimization with Unknown Linear Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.05786",
        "HTML": "https://arxiv.org/html/2403.05786",
        "PDF": "https://arxiv.org/pdf/2403.05786"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses online convex optimization with constraints, not involving any aspect of LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2406.10600",
      "abstract": "Radar-based perception has gained increasing attention in autonomous driving, yet the inherent sparsity of radars poses challenges. Radar raw data often contains excessive noise, whereas radar point clouds retain only limited information. In this work, we holistically treat the sparse nature of radar data by introducing an adaptive subsampling method together with a tailored network architecture that exploits the sparsity patterns to discover global and local dependencies in the radar signal. Our subsampling module selects a subset of pixels from range-doppler (RD) spectra that contribute most to the downstream perception tasks. To improve the feature extraction on sparse subsampled data, we propose a new way of applying graph neural networks on radar data and design a novel two-branch backbone to capture both global and local neighbor information. An attentive fusion module is applied to combine features from both branches. Experiments on the RADIal dataset show that our SparseRadNet exceeds state-of-the-art (SOTA) performance in object detection and achieves close to SOTA accuracy in freespace segmentation, meanwhile using sparse subsampled input data.",
      "authors": [
        "Jialong Wu",
        "Mirko Meuter",
        "Markus Schoeler",
        "Matthias Rottmann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-15T11:26:10+00:00",
          "link": "https://arxiv.org/abs/2406.10600v1",
          "size": "8094kb",
          "version": "v1"
        },
        {
          "date": "2024-06-18T08:35:59+00:00",
          "link": "https://arxiv.org/abs/2406.10600v2",
          "size": "8092kb",
          "version": "v2"
        },
        {
          "date": "2024-07-11T07:43:36+00:00",
          "link": "https://arxiv.org/abs/2406.10600v3",
          "size": "11252kb",
          "version": "v3"
        },
        {
          "date": "2024-07-16T08:29:30+00:00",
          "link": "https://arxiv.org/abs/2406.10600v4",
          "size": "11244kb",
          "version": "v4"
        }
      ],
      "title": "SparseRadNet: Sparse Perception Neural Network on Subsampled Radar Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.10600",
        "HTML": "https://arxiv.org/html/2406.10600",
        "PDF": "https://arxiv.org/pdf/2406.10600"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on adaptive subsampling and neural network architecture for radar data in autonomous driving, unrelated to LLM training data processing."
      },
      "tasks": [
        "Autonomous Driving",
        "object-detection",
        "Object Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.10157",
      "abstract": "Social simulation is transforming traditional social science research by modeling human behavior through interactions between virtual individuals and their environments. With recent advances in large language models (LLMs), this approach has shown growing potential in capturing individual differences and predicting group behaviors. However, existing methods face alignment challenges related to the environment, target users, interaction mechanisms, and behavioral patterns. To this end, we introduce SocioVerse, an LLM-agent-driven world model for social simulation. Our framework features four powerful alignment components and a user pool of 10 million real individuals. To validate its effectiveness, we conducted large-scale simulation experiments across three distinct domains: politics, news, and economics. Results demonstrate that SocioVerse can reflect large-scale population dynamics while ensuring diversity, credibility, and representativeness through standardized procedures and minimal manual adjustments.",
      "authors": [
        "Xinnong Zhang",
        "Jiayu Lin",
        "Xinyi Mou",
        "Shiyue Yang",
        "Xiawei Liu",
        "Libo Sun",
        "Hanjia Lyu",
        "Yihang Yang",
        "Weihong Qi",
        "Yue Chen",
        "Guanying Li",
        "Ling Yan",
        "Yao Hu",
        "Siming Chen",
        "Yu Wang",
        "Xuanjing Huang",
        "Jiebo Luo",
        "Shiping Tang",
        "Libo Wu",
        "Baohua Zhou",
        "Zhongyu Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-14T12:12:52+00:00",
          "link": "https://arxiv.org/abs/2504.10157v1",
          "size": "1552kb",
          "version": "v1"
        },
        {
          "date": "2025-04-23T06:08:32+00:00",
          "link": "https://arxiv.org/abs/2504.10157v2",
          "size": "1552kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T11:14:36+00:00",
          "link": "https://arxiv.org/abs/2504.10157v3",
          "size": "1552kb",
          "version": "v3"
        }
      ],
      "title": "SocioVerse: A World Model for Social Simulation Powered by LLM Agents and A Pool of 10 Million Real-World Users",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.10157",
        "HTML": "https://arxiv.org/html/2504.10157v3",
        "PDF": "https://arxiv.org/pdf/2504.10157"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on social simulation using LLM agents and aligning them with real-world contexts but does not address the processing of LLM training data itself."
      },
      "datasets": [
        {
          "dataset_name": "Lishi0905/SocioVerse",
          "downloads": "42",
          "likes": "12",
          "link": "https://huggingface.co/datasets/Lishi0905/SocioVerse"
        }
      ],
      "tasks": [
        "Diversity",
        "Face Alignment"
      ],
      "repo_urls": [
        "https://github.com/fudandisc/socioverse"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.22791",
      "abstract": "Semantic caching significantly reduces computational costs and improves efficiency by storing and reusing large language model (LLM) responses. However, existing systems rely primarily on matching individual queries, lacking awareness of multi-turn dialogue contexts, which leads to incorrect cache hits when similar queries appear in different conversational settings. This demonstration introduces ContextCache, a context-aware semantic caching system for multi-turn dialogues. ContextCache employs a two-stage retrieval architecture that first executes vector-based retrieval on the current query to identify potential matches and then integrates current and historical dialogue representations through self-attention mechanisms for precise contextual matching. Evaluation of real-world conversations shows that ContextCache improves precision and recall compared to existing methods. Additionally, cached responses exhibit approximately 10 times lower latency than direct LLM invocation, enabling significant computational cost reductions for LLM conversational applications.",
      "authors": [
        "Jianxin Yan",
        "Wangze Ni",
        "Lei Chen",
        "Xuemin Lin",
        "Peng Cheng",
        "Zhan Qin",
        "Kui Ren"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T07:25:12+00:00",
          "link": "https://arxiv.org/abs/2506.22791v1",
          "size": "898kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T14:42:00+00:00",
          "link": "https://arxiv.org/abs/2506.22791v2",
          "size": "1310kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T12:59:47+00:00",
          "link": "https://arxiv.org/abs/2506.22791v3",
          "size": "1286kb",
          "version": "v3"
        }
      ],
      "title": "ContextCache: Context-Aware Semantic Cache for Multi-Turn Queries in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22791",
        "HTML": "https://arxiv.org/html/2506.22791v3",
        "PDF": "https://arxiv.org/pdf/2506.22791"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces a semantic caching system for LLM efficiency but does not address the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06858",
      "abstract": "This study presents findings from long-term biometric evaluations conducted at the Biometric Evaluation Center (bez). Over the course of two and a half years, our ongoing research with over 400 participants representing diverse ethnicities, genders, and age groups were regularly assessed using a variety of biometric tools and techniques at the controlled testing facilities. Our findings are based on the General Data Protection Regulation-compliant local bez database with more than 238.000 biometric data sets categorized into multiple biometric modalities such as face and finger. We used state-of-the-art face recognition algorithms to analyze long-term comparison scores. Our results show that these scores fluctuate more significantly between individual days than over the entire measurement period. These findings highlight the importance of testing biometric characteristics of the same individuals over a longer period of time in a controlled measurement environment and lays the groundwork for future advancements in biometric data analysis.",
      "authors": [
        "Mathias Schulz",
        "Alexander Spenke",
        "Pia Funk",
        "Florian Bl\\\"umel",
        "Markus Rohde",
        "Ralph Breithaupt",
        "Gerd Nolden",
        "Norbert Jung",
        "Robert Lange"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T13:59:31+00:00",
          "link": "https://arxiv.org/abs/2507.06858v1",
          "size": "865kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T08:24:51+00:00",
          "link": "https://arxiv.org/abs/2507.06858v2",
          "size": "857kb",
          "version": "v2"
        }
      ],
      "title": "Longitudinal Study of Facial Biometrics at the BEZ: Temporal Variance Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06858",
        "HTML": "https://arxiv.org/html/2507.06858v2",
        "PDF": "https://arxiv.org/pdf/2507.06858"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is concerned with biometric evaluations and variance analysis over time, with no mention of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.01064",
      "abstract": "Roadside monocular 3D detection requires detecting objects of predefined classes in an RGB frame and predicting their 3D attributes, such as bird's-eye-view (BEV) locations. It has broad applications in traffic control, vehicle-vehicle communication, and vehicle-infrastructure cooperative perception. To address this task, we introduce Promptable 3D Detector (Pro3D), a novel detector design that leverages 2D detections as prompts. We build our Pro3D upon two key insights. First, compared to a typical 3D detector, a 2D detector is ``easier'' to train due to fewer loss terms and performs significantly better at localizing objects w.r.t 2D metrics. Second, once 2D detections precisely locate objects in the image, a 3D detector can focus on lifting these detections into 3D BEV, especially when fixed camera pose or scene geometry provide an informative prior. To encode and incorporate 2D detections, we explore three methods: (a) concatenating features from both 2D and 3D detectors, (b) attentively fusing 2D and 3D detector features, and (c) encoding properties of predicted 2D bounding boxes \\{$x$, $y$, width, height, label\\} and attentively fusing them with the 3D detector feature. Interestingly, the third method significantly outperforms the others, underscoring the effectiveness of 2D detections as prompts that offer precise object targets and allow the 3D detector to focus on lifting them into 3D. Pro3D is adaptable for use with a wide range of 2D and 3D detectors with minimal modifications. Comprehensive experiments demonstrate that our Pro3D significantly enhances existing methods, achieving state-of-the-art results on two contemporary benchmarks.",
      "authors": [
        "Yechi Ma",
        "Yanan Li",
        "Wei Hua",
        "Shu Kong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-01T11:57:34+00:00",
          "link": "https://arxiv.org/abs/2404.01064v1",
          "size": "4882kb",
          "version": "v1"
        },
        {
          "date": "2024-04-04T09:48:30+00:00",
          "link": "https://arxiv.org/abs/2404.01064v2",
          "size": "4882kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T01:23:44+00:00",
          "link": "https://arxiv.org/abs/2404.01064v3",
          "size": "4225kb",
          "version": "v3"
        }
      ],
      "title": "Roadside Monocular 3D Detection Prompted by 2D Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.01064",
        "HTML": "https://arxiv.org/html/2404.01064v3",
        "PDF": "https://arxiv.org/pdf/2404.01064"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a 3D detector leveraging 2D detections in monocular vision, focusing on object detection enhancement, without discussing any aspect of LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.21308",
      "abstract": "Privacy risks in differentially private (DP) systems increase significantly when data is correlated, as standard DP metrics often underestimate the resulting privacy leakage, leaving sensitive information vulnerable. Given the ubiquity of dependencies in real-world databases, this oversight poses a critical challenge for privacy protections. Bayesian differential privacy (BDP) extends DP to account for these correlations, yet current BDP mechanisms indicate notable utility loss, limiting its adoption.\n  In this work, we address whether BDP can be realistically implemented in common data structures without sacrificing utility -- a key factor for its applicability. By analyzing arbitrary and structured correlation models, including Gaussian multivariate distributions and Markov chains, we derive practical utility guarantees for BDP. Our contributions include theoretical links between DP and BDP and a novel methodology for adapting DP mechanisms to meet the BDP requirements. Through evaluations on real-world databases, we demonstrate that our novel theorems enable the design of BDP mechanisms that maintain competitive utility, paving the way for practical privacy-preserving data practices in correlated settings.",
      "authors": [
        "Martin Lange",
        "Patricia Guerra-Balboa",
        "Javier Parra-Arnau",
        "Thorsten Strufe"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T14:25:44+00:00",
          "link": "https://arxiv.org/abs/2506.21308v1",
          "size": "893kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T13:10:10+00:00",
          "link": "https://arxiv.org/abs/2506.21308v2",
          "size": "893kb",
          "version": "v2"
        }
      ],
      "title": "Balancing Privacy and Utility in Correlated Data: A Study of Bayesian Differential Privacy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21308",
        "PDF": "https://arxiv.org/pdf/2506.21308"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on privacy in data systems with correlated data, with a primary emphasis on Bayesian differential privacy rather than on LLM training-data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10618",
      "abstract": "Algorithmic innovation in the pretraining of large language models has driven a massive reduction in the total compute required to reach a given level of capability. In this paper we empirically investigate the compute requirements for developing algorithmic innovations. We catalog 36 pre-training algorithmic innovations used in Llama 3 and DeepSeek-V3. For each innovation we estimate both the total FLOP used in development and the FLOP/s of the hardware utilized. Innovations using significant resources double in their requirements each year. We then use this dataset to investigate the effect of compute caps on innovation. Our analysis suggests that compute caps alone are unlikely to dramatically slow AI algorithmic progress. Even stringent compute caps -- such as capping total operations to the compute used to train GPT-2 or capping hardware capacity to 8 H100 GPUs -- could still have allowed for half of the cataloged innovations.",
      "authors": [
        "Peter Barnett"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T21:28:02+00:00",
          "link": "https://arxiv.org/abs/2507.10618v1",
          "size": "345kb",
          "version": "v1"
        }
      ],
      "title": "Compute Requirements for Algorithmic Innovation in Frontier AI Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10618",
        "HTML": "https://arxiv.org/html/2507.10618v1",
        "PDF": "https://arxiv.org/pdf/2507.10618"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses algorithmic innovations and compute requirements in LLM pretraining but does not focus on training data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10886",
      "abstract": "AI models need to be unlearned to fulfill the requirements of legal acts such as the AI Act or GDPR, and also because of the need to remove toxic content, debiasing, the impact of malicious instances, or changes in the data distribution structure in which a model works. Unfortunately, removing knowledge may cause undesirable side effects, such as a deterioration in model performance. In this paper, we investigate the problem of adversarial unlearning, where a malicious party intentionally sends unlearn requests to deteriorate the model's performance maximally. We show that this phenomenon and the adversary's capabilities depend on many factors, primarily on the backbone model itself and strategy/limitations in selecting data to be unlearned. The main result of this work is a new method of protecting model performance from these side effects, both in the case of unlearned behavior resulting from spontaneous processes and adversary actions.",
      "authors": [
        "Patryk Jasiorski and Marek Klonowski and Micha{\\l} Wo\\'zniak"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T00:59:42+00:00",
          "link": "https://arxiv.org/abs/2507.10886v1",
          "size": "201kb",
          "version": "v1"
        }
      ],
      "title": "How to Protect Models against Adversarial Unlearning?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10886",
        "HTML": "https://arxiv.org/html/2507.10886v1",
        "PDF": "https://arxiv.org/pdf/2507.10886"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses protection against adversarial unlearning and mentions data selection, but it does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10897",
      "abstract": "Schema matching is a foundational task in enterprise data integration, aiming to align disparate data sources. While traditional methods handle simple one-to-one table mappings, they often struggle with complex multi-table schema matching in real-world applications. We present LLMatch, a unified and modular schema matching framework. LLMatch decomposes schema matching into three distinct stages: schema preparation, table-candidate selection, and column-level alignment, enabling component-level evaluation and future-proof compatibility. It includes a novel two-stage optimization strategy: a Rollup module that consolidates semantically related columns into higher-order concepts, followed by a Drilldown module that re-expands these concepts for fine-grained column mapping. To address the scarcity of complex semantic matching benchmarks, we introduce SchemaNet, a benchmark derived from real-world schema pairs across three enterprise domains, designed to capture the challenges of multi-table schema alignment in practical settings. Experiments demonstrate that LLMatch significantly improves matching accuracy in complex schema matching settings and substantially boosts engineer productivity in real-world data integration.",
      "authors": [
        "Sha Wang and Yuchen Li and Hanhua Xiao and Bing Tian Dai and Roy Ka-Wei Lee and Yanfei Dong and Lambert Deng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T01:24:49+00:00",
          "link": "https://arxiv.org/abs/2507.10897v1",
          "size": "177kb",
          "version": "v1"
        }
      ],
      "title": "LLMATCH: A Unified Schema Matching Framework with Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10897",
        "HTML": "https://arxiv.org/html/2507.10897v1",
        "PDF": "https://arxiv.org/pdf/2507.10897"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on schema matching for data integration and not on LLM training data processing. It introduces the LLMatch framework and SchemaNet benchmark without discussing LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11240",
      "abstract": "We study the Continuous-Discrete Kalman Filter (CD-KF) for State-Space Models (SSMs) where continuous-time dynamics are observed via multiple sensors with discrete, irregularly timed measurements. Our focus extends to scenarios in which the measurement process is coupled with the states of an auxiliary SSM. For instance, higher measurement rates may increase energy consumption or heat generation, while a sensor's accuracy can depend on its own spatial trajectory or that of the measured target. Each sensor thus carries distinct costs and constraints associated with its measurement rate and additional constraints and costs on the auxiliary state. We model measurement occurrences as independent Poisson processes with sensor-specific rates and derive an upper bound on the mean posterior covariance matrix of the CD-KF along the mean auxiliary state. The bound is continuously differentiable with respect to the measurement rates, which enables efficient gradient-based optimization. Exploiting this bound, we propose a finite-horizon optimal control framework to optimize measurement rates and auxiliary-state dynamics jointly. We further introduce a deterministic method for scheduling measurement times from the optimized rates. Empirical results in state-space filtering and dynamic temporal Gaussian process regression demonstrate that our approach achieves improved trade-offs between resource usage and estimation accuracy.",
      "authors": [
        "Mohamad Al Ahdab",
        "John Leth",
        "and Zheng-Hua Tan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:13:03+00:00",
          "link": "https://arxiv.org/abs/2507.11240v1",
          "size": "1366kb",
          "version": "v1"
        }
      ],
      "title": "Optimal Sensor Scheduling and Selection for Continuous-Discrete Kalman Filtering with Auxiliary Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11240",
        "HTML": "https://arxiv.org/html/2507.11240v1",
        "PDF": "https://arxiv.org/pdf/2507.11240"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimal sensor scheduling and selection for Kalman filtering, without discussing LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2203.11837",
      "abstract": "It is known that the stability of a feedback interconnection of two linear time-invariant systems implies that the graphs of the open-loop systems are quadratically separated. This separation is defined by an object known as the multiplier. The theory of integral quadratic constraints shows that the converse also holds under certain conditions. This paper establishes that if the feedback is robustly stable against certain structured uncertainty, then there always exists a multiplier that takes a corresponding form. In particular, if the feedback is robustly stable to certain gain-type uncertainty, then there exists a corresponding multiplier that is of phase-type, i.e., its diagonal blocks are zeros. These results build on the notion of phases of matrices and systems, which was recently introduced in the field of control. Similarly, if the feedback is robustly stable to certain phase-type uncertainty, then there exists a gain-type multiplier, i.e., its off-diagonal blocks are zeros. The results are meaningfully instructive in the search for a valid multiplier for establishing robust closed-loop stability, and cover the well-known small-gain and the recent small-phase theorems.",
      "authors": [
        "Axel Ringh",
        "Xin Mao",
        "Wei Chen",
        "Li Qiu",
        "Sei Zhen Khong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2022-03-22T16:04:21+00:00",
          "link": "https://arxiv.org/abs/2203.11837v1",
          "size": "77kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T18:38:36+00:00",
          "link": "https://arxiv.org/abs/2203.11837v2",
          "size": "84kb",
          "version": "v2"
        }
      ],
      "title": "Gain and phase type multipliers for feedback robustness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2203.11837",
        "HTML": "https://arxiv.org/html/2203.11837v2",
        "PDF": "https://arxiv.org/pdf/2203.11837"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about feedback robustness and control systems, involving multipliers and system stability, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2301.12753",
      "abstract": "With the growth of data, it is more important than ever to develop an efficient and robust method for solving the consistent matrix equation AXB=C. The randomized Kaczmarz (RK) method has received a lot of attention because of its computational efficiency and low memory footprint. A recently proposed approach is the matrix equation relaxed greedy RK (ME-RGRK) method, which greedily uses the loss of the index pair as a threshold to detect and avoid projecting the working rows onto that are too far from the current iterate. In this work, we utilize the Polyak's and Nesterov's momentums to further speed up the convergence rate of the ME-RGRK method. The resulting methods are shown to converge linearly to a least-squares solution with minimum Frobenius norm. Finally, some numerical experiments are provided to illustrate the feasibility and effectiveness of our proposed methods. In addition, a real-world application, i.e., tensor product surface fitting in computer-aided geometry design, has also been presented for explanatory purpose.",
      "authors": [
        "Nian-Ci Wu",
        "Yang Zhou",
        "and Zhaolu Tian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2023-01-30T09:55:37+00:00",
          "link": "https://arxiv.org/abs/2301.12753v1",
          "size": "9193kb",
          "version": "v1"
        }
      ],
      "title": "On the relaxed greedy randomized Kaczmarz methods with momentum acceleration for solving matrix equation AXB=C",
      "links": {
        "Abstract": "https://arxiv.org/abs/2301.12753",
        "PDF": "https://arxiv.org/pdf/2301.12753"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on solving matrix equations with improved algorithms, and no aspect of LLM training data processing or dataset handling is addressed."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.16923",
      "abstract": "Endowing the set of functional graphs (FGs) with the sum (disjoint union of graphs) and product (standard direct product on graphs) operations induces on FGs a structure of a commutative semiring R. The operations on R can be naturally extended to the set of univariate polynomials R[X] over R. This paper provides a polynomial time algorithm for deciding if equations of the type AX=B have solutions when A is just a single cycle and B a set of cycles of identical size. We also prove a similar complexity result for some variants of the previous equation.",
      "authors": [
        "Alberto Dennunzio and Enrico Formenti and Luciano Margara and Sara Riva"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-26T10:18:49+00:00",
          "link": "https://arxiv.org/abs/2402.16923v1",
          "size": "526kb",
          "version": "v1"
        },
        {
          "date": "2024-10-10T11:06:12+00:00",
          "link": "https://arxiv.org/abs/2402.16923v2",
          "size": "527kb",
          "version": "v2"
        },
        {
          "date": "2024-10-13T08:10:56+00:00",
          "link": "https://arxiv.org/abs/2402.16923v3",
          "size": "527kb",
          "version": "v3"
        },
        {
          "date": "2025-05-15T16:00:01+00:00",
          "link": "https://arxiv.org/abs/2402.16923v4",
          "size": "40kb",
          "version": "v4"
        },
        {
          "date": "2025-06-24T08:09:30+00:00",
          "link": "https://arxiv.org/abs/2402.16923v5",
          "size": "87kb",
          "version": "v5"
        },
        {
          "date": "2025-07-15T08:52:43+00:00",
          "link": "https://arxiv.org/abs/2402.16923v6",
          "size": "52kb",
          "version": "v6"
        }
      ],
      "title": "On solving basic equations over the semiring of functional digraphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.16923",
        "HTML": "https://arxiv.org/html/2402.16923",
        "PDF": "https://arxiv.org/pdf/2402.16923"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with mathematical equations in the context of functional digraphs and commutative semirings, which does not pertain to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.04057",
      "abstract": "Large language models (LLMs) have shown impressive capabilities in generating program code, opening exciting opportunities for applying program synthesis to games. In this work, we explore the potential of LLMs to directly synthesize usable code for a wide range of gaming applications, focusing on two programming languages, Python and Java. We use an evolutionary hill-climbing algorithm, where the mutations and seeds of the initial programs are controlled by LLMs. For Python, the framework covers various game-related tasks, including five miniature versions of Atari games, ten levels of Baba is You, an environment inspired by Asteroids, and a maze generation task. For Java, the framework contains 12 games from the TAG tabletop games framework. Across 29 tasks, we evaluated 12 language models for Python and 8 for Java. Our findings suggest that the performance of LLMs depends more on the task than on model size. While larger models generate more executable programs, these do not always result in higher-quality solutions but are much more expensive. No model has a clear advantage, although on any specific task, one model may be better. Trying many models on a problem and using the best results across them is more reliable than using just one.",
      "authors": [
        "Manuel Eberhardinger",
        "James Goodman",
        "Alexander Dockhorn",
        "Diego Perez-Liebana",
        "Raluca D. Gaina",
        "Duygu \\c{C}akmak",
        "Setareh Maghsudi",
        "Simon Lucas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-05T10:50:58+00:00",
          "link": "https://arxiv.org/abs/2412.04057v1",
          "size": "1258kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T07:45:41+00:00",
          "link": "https://arxiv.org/abs/2412.04057v2",
          "size": "1356kb",
          "version": "v2"
        }
      ],
      "title": "From Code to Play: Benchmarking Program Search for Games Using Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.04057",
        "HTML": "https://arxiv.org/html/2412.04057v2",
        "PDF": "https://arxiv.org/pdf/2412.04057"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on benchmarking program synthesis for games using LLMs, with no mention of processing or creating LLM training data."
      },
      "tasks": [
        "Atari Games",
        "Benchmarking",
        "Program Synthesis",
        "TAG"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.11258",
      "abstract": "In https://arxiv.org/pdf/2405.10094 (also published at LICS'24 conference), Lyon and Ostropolski-Nalewaja answer the question of the decidability of quasi-dense modallogics, and give an upper bound in EXPSPACE. Unfortunately, their intricate proof contains a major flaw that cannot be fixed, leaving the question wide open. In this paper we provide a correct and rather simple and direct proof of it by introducing a new variant of the well-know filtration method based on paths in a canonical model and improve the hypothetical membership to membership NEXPTIME.",
      "authors": [
        "Olivier Gasquet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:31:41+00:00",
          "link": "https://arxiv.org/abs/2507.11258v1",
          "size": "9kb",
          "version": "v1"
        }
      ],
      "title": "Path-filtration for modal logics applied to revisiting quasi-dense logics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11258",
        "HTML": "https://arxiv.org/html/2507.11258v1",
        "PDF": "https://arxiv.org/pdf/2507.11258"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about a correction in modal logics concerning the decidability of quasi-dense logics. It does not involve LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11344",
      "abstract": "Large language models are increasingly used to support high-stakes decisions, potentially influencing who is granted bail or receives a loan. Naive chain-of-thought sampling can improve average decision accuracy, but has also been shown to amplify unfair bias. To address this challenge and enable the trustworthy use of reasoning models in high-stakes decision-making, we propose a framework for training a generalizable Fairness Reward Model (FRM). Our model assigns a fairness score to LLM reasoning, enabling the system to down-weight biased trajectories and favor equitable ones when aggregating decisions across reasoning chains. We show that a single Fairness Reward Model, trained on weakly supervised, LLM-annotated examples of biased versus unbiased reasoning, transfers across tasks, domains, and model families without additional fine-tuning. Applied to real-world decision-making tasks including recidivism prediction and social media moderation, we show that our approach consistently improves fairness while matching, or even surpassing, baseline accuracy.",
      "authors": [
        "Zara Hall",
        "Melanie Subbiah",
        "Thomas P Zollo",
        "Kathleen McKeown",
        "Richard Zemel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:20:23+00:00",
          "link": "https://arxiv.org/abs/2507.11344v1",
          "size": "8156kb",
          "version": "v1"
        }
      ],
      "title": "Guiding LLM Decision-Making with Fairness Reward Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11344",
        "HTML": "https://arxiv.org/html/2507.11344v1",
        "PDF": "https://arxiv.org/pdf/2507.11344"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses a Fairness Reward Model used during decision-making with LLMs, it primarily focuses on model architecture and does not describe significant novel contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.10061",
      "abstract": "Recent work on human animation usually involves audio, pose, or movement maps conditions, thereby achieves vivid animation quality. However, these methods often face practical challenges due to extra control conditions, cumbersome condition injection modules, or limitation to head region driving. Hence, we ask if it is possible to achieve striking half-body human animation while simplifying unnecessary conditions. To this end, we propose a half-body human animation method, dubbed EchoMimicV2, that leverages a novel Audio-Pose Dynamic Harmonization strategy, including Pose Sampling and Audio Diffusion, to enhance half-body details, facial and gestural expressiveness, and meanwhile reduce conditions redundancy. To compensate for the scarcity of half-body data, we utilize Head Partial Attention to seamlessly accommodate headshot data into our training framework, which can be omitted during inference, providing a free lunch for animation. Furthermore, we design the Phase-specific Denoising Loss to guide motion, detail, and low-level quality for animation in specific phases, respectively. Besides, we also present a novel benchmark for evaluating the effectiveness of half-body human animation. Extensive experiments and analyses demonstrate that EchoMimicV2 surpasses existing methods in both quantitative and qualitative evaluations.",
      "authors": [
        "Rang Meng",
        "Xingyu Zhang",
        "Yuming Li",
        "Chenguang Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-15T09:23:18+00:00",
          "link": "https://arxiv.org/abs/2411.10061v1",
          "size": "4884kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T10:02:14+00:00",
          "link": "https://arxiv.org/abs/2411.10061v2",
          "size": "4877kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T02:31:52+00:00",
          "link": "https://arxiv.org/abs/2411.10061v3",
          "size": "4877kb",
          "version": "v3"
        }
      ],
      "title": "EchoMimicV2: Towards Striking, Simplified, and Semi-Body Human Animation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.10061",
        "HTML": "https://arxiv.org/html/2411.10061v3",
        "PDF": "https://arxiv.org/pdf/2411.10061"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes methods for human animation but does not involve LLM training data processing."
      },
      "models": [
        {
          "model_path": "BadToBest/EchoMimicV2",
          "downloads": "0",
          "likes": "127",
          "trending_score": "0.0",
          "link": "https://huggingface.co/BadToBest/EchoMimicV2"
        },
        {
          "model_path": "camenduru/EchoMimicV2",
          "downloads": "0",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/camenduru/EchoMimicV2"
        }
      ],
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Meng_EchoMimicV2_Towards_Striking_Simplified_and_Semi-Body_Human_Animation_CVPR_2025_paper.html",
      "tasks": [
        "Audio-Driven Body Animation",
        "Human Animation",
        "Image to Video Generation",
        "Subject-driven Video Generation",
        "Video Generation"
      ],
      "repo_urls": [
        "https://github.com/antgroup/echomimic_v2"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.11126",
      "abstract": "We present a tool called Hoax for the execution of {\\omega}-automata expressed in the popular HOA format. The tool leverages the notion of trap sets to enable runtime monitoring of any (non-parity) acceptance condition supported by the format. When the automaton is not monitorable, the tool may still be able to recognise so-called ugly prefixes, and determine that no further observation will ever lead to a conclusive verdict. The tool is open-source and highly configurable. We present its formal foundations, its design, and compare it against the trace analyser PyContract on a lock acquisition scenario.",
      "authors": [
        "Luca Di Stefano"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:22:24+00:00",
          "link": "https://arxiv.org/abs/2507.11126v1",
          "size": "36kb",
          "version": "v1"
        }
      ],
      "title": "Execution and monitoring of HOA automata with HOAX",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11126",
        "PDF": "https://arxiv.org/pdf/2507.11126"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a tool for executing and monitoring automata, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11325",
      "abstract": "Accurate liver and tumor segmentation on abdominal CT images is critical for reliable diagnosis and treatment planning, but remains challenging due to complex anatomical structures, variability in tumor appearance, and limited annotated data. To address these issues, we introduce Hyperbolic-convolutions Adaptive-temporal-attention with Neural-representation and Synaptic-plasticity Network (HANS-Net), a novel segmentation framework that synergistically combines hyperbolic convolutions for hierarchical geometric representation, a wavelet-inspired decomposition module for multi-scale texture learning, a biologically motivated synaptic plasticity mechanism for adaptive feature enhancement, and an implicit neural representation branch to model fine-grained and continuous anatomical boundaries. Additionally, we incorporate uncertainty-aware Monte Carlo dropout to quantify prediction confidence and lightweight temporal attention to improve inter-slice consistency without sacrificing efficiency. Extensive evaluations of the LiTS dataset demonstrate that HANS-Net achieves a mean Dice score of 93.26%, an IoU of 88.09%, an average symmetric surface distance (ASSD) of 0.72 mm, and a volume overlap error (VOE) of 11.91%. Furthermore, cross-dataset validation on the 3D-IRCADb-01 dataset obtains an average Dice of 87.45%, IoU of 80.30%, ASSD of 1.525 mm, and VOE of 19.71%, indicating strong generalization across different datasets. These results confirm the effectiveness and robustness of HANS-Net in providing anatomically consistent, accurate, and confident liver and tumor segmentation.",
      "authors": [
        "Arefin Ittesafun Abian",
        "Ripon Kumar Debnath",
        "Md. Abdur Rahman",
        "Mohaimenul Azam Khan Raiaan",
        "Md Rafiqul Islam",
        "Asif Karim",
        "Reem E. Mohamed",
        "Sami Azam"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:56:37+00:00",
          "link": "https://arxiv.org/abs/2507.11325v1",
          "size": "11206kb",
          "version": "v1"
        }
      ],
      "title": "HANS-Net: Hyperbolic Convolution and Adaptive Temporal Attention for Accurate and Generalizable Liver and Tumor Segmentation in CT Imaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11325",
        "HTML": "https://arxiv.org/html/2507.11325v1",
        "PDF": "https://arxiv.org/pdf/2507.11325"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on liver and tumor segmentation in CT imaging using a novel framework and does not discuss any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11405",
      "abstract": "The rapid advancement of large language models (LLMs) has heightened concerns about benchmark data contamination (BDC), where models inadvertently memorize evaluation data, inflating performance metrics and undermining genuine generalization assessment. This paper introduces the Data Contamination Risk (DCR) framework, a lightweight, interpretable pipeline designed to detect and quantify BDC across four granular levels: semantic, informational, data, and label. By synthesizing contamination scores via a fuzzy inference system, DCR produces a unified DCR Factor that adjusts raw accuracy to reflect contamination-aware performance. Validated on 9 LLMs (0.5B-72B) across sentiment analysis, fake news detection, and arithmetic reasoning tasks, the DCR framework reliably diagnoses contamination severity and with accuracy adjusted using the DCR Factor to within 4% average error across the three benchmarks compared to the uncontaminated baseline. Emphasizing computational efficiency and transparency, DCR provides a practical tool for integrating contamination assessment into routine evaluations, fostering fairer comparisons and enhancing the credibility of LLM benchmarking practices.",
      "authors": [
        "Cheng Xu",
        "Nan Yan",
        "Shuhao Guan",
        "Changhong Jin",
        "Yuke Mei",
        "Yibing Guo",
        "M-Tahar Kechadi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:23:53+00:00",
          "link": "https://arxiv.org/abs/2507.11405v1",
          "size": "398kb",
          "version": "v1"
        }
      ],
      "title": "DCR: Quantifying Data Contamination in LLMs Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11405",
        "HTML": "https://arxiv.org/html/2507.11405v1",
        "PDF": "https://arxiv.org/pdf/2507.11405"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the Data Contamination Risk (DCR) framework for evaluating and diagnosing benchmark data contamination in LLMs, which directly involves data processing to ensure high data quality for LLM evaluation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07935",
      "abstract": "Given the rapid adoption of generative AI and its potential to impact a wide range of tasks, understanding the effects of AI on the economy is one of society's most important questions. In this work, we take a step toward that goal by analyzing the work activities people do with AI, how successfully and broadly those activities are done, and combine that with data on what occupations do those activities. We analyze a dataset of 200k anonymized and privacy-scrubbed conversations between users and Microsoft Bing Copilot, a publicly available generative AI system. We find the most common work activities people seek AI assistance for involve gathering information and writing, while the most common activities that AI itself is performing are providing information and assistance, writing, teaching, and advising. Combining these activity classifications with measurements of task success and scope of impact, we compute an AI applicability score for each occupation. We find the highest AI applicability scores for knowledge work occupation groups such as computer and mathematical, and office and administrative support, as well as occupations such as sales whose work activities involve providing and communicating information. Additionally, we characterize the types of work activities performed most successfully, how wage and education correlate with AI applicability, and how real-world usage compares to predictions of occupational AI impact.",
      "authors": [
        "Kiran Tomlinson",
        "Sonia Jaffe",
        "Will Wang",
        "Scott Counts",
        "Siddharth Suri"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:16:33+00:00",
          "link": "https://arxiv.org/abs/2507.07935v1",
          "size": "859kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T15:35:12+00:00",
          "link": "https://arxiv.org/abs/2507.07935v2",
          "size": "859kb",
          "version": "v2"
        }
      ],
      "title": "Working with AI: Measuring the Occupational Implications of Generative AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07935",
        "PDF": "https://arxiv.org/pdf/2507.07935"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on analyzing the impact of generative AI on occupational activities using a dataset of user conversations, but it does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11261",
      "abstract": "3D visual grounding aims to identify and localize objects in a 3D space based on textual descriptions. However, existing methods struggle with disentangling targets from anchors in complex multi-anchor queries and resolving inconsistencies in spatial descriptions caused by perspective variations. To tackle these challenges, we propose ViewSRD, a framework that formulates 3D visual grounding as a structured multi-view decomposition process. First, the Simple Relation Decoupling (SRD) module restructures complex multi-anchor queries into a set of targeted single-anchor statements, generating a structured set of perspective-aware descriptions that clarify positional relationships. These decomposed representations serve as the foundation for the Multi-view Textual-Scene Interaction (Multi-TSI) module, which integrates textual and scene features across multiple viewpoints using shared, Cross-modal Consistent View Tokens (CCVTs) to preserve spatial correlations. Finally, a Textual-Scene Reasoning module synthesizes multi-view predictions into a unified and robust 3D visual grounding. Experiments on 3D visual grounding datasets show that ViewSRD significantly outperforms state-of-the-art methods, particularly in complex queries requiring precise spatial differentiation.",
      "authors": [
        "Ronggang Huang",
        "Haoxin Yang",
        "Yan Cai",
        "Xuemiao Xu",
        "Huaidong Zhang",
        "Shengfeng He"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:35:01+00:00",
          "link": "https://arxiv.org/abs/2507.11261v1",
          "size": "5755kb",
          "version": "v1"
        }
      ],
      "title": "ViewSRD: 3D Visual Grounding via Structured Multi-View Decomposition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11261",
        "HTML": "https://arxiv.org/html/2507.11261v1",
        "PDF": "https://arxiv.org/pdf/2507.11261"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for 3D visual grounding via structured multi-view decomposition, concentrating on spatial correlations and object localization. It is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.12458",
      "abstract": "The advent of generative artificial intelligence (GenAI) technologies has been changing the research landscape and potentially has significant implications for Digital Humanities (DH), a field inherently intertwined with technologies. This article investigates how DH scholars adopt and critically evaluate GenAI technologies for research. Drawing on 76 responses collected from an international survey study and 15 semi-structured interviews with DH scholars, we explored the rationale for adopting GenAI tools in research, identified the specific practices of using GenAI tools, and analyzed scholars' collective perceptions regarding the benefits, risks, and challenges. The results reveal that DH research communities hold divided opinions and differing imaginations towards the role of GenAI in DH scholarship. While scholars acknowledge the benefits of GenAI in enhancing research efficiency and enabling reskilling, many remain concerned about its potential to disrupt their intellectual identities. Situated within the history of DH and viewed through the lens of Actor-Network Theory, our findings suggest that the adoption of GenAI is gradually changing the field, though this transformation remains contested, shaped by ongoing negotiations among multiple human and non-human actors. Our study is one of the first empirical analyses on this topic and has the potential to serve as a building block for future inquiries into the impact of GenAI on DH scholarship.",
      "authors": [
        "Rongqian Ma",
        "Meredith Dedema",
        "Andrew Cox"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-18T18:33:00+00:00",
          "link": "https://arxiv.org/abs/2404.12458v1",
          "size": "668kb",
          "version": "v1"
        },
        {
          "date": "2024-10-07T18:07:54+00:00",
          "link": "https://arxiv.org/abs/2404.12458v2",
          "size": "698kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T18:43:30+00:00",
          "link": "https://arxiv.org/abs/2404.12458v3",
          "size": "886kb",
          "version": "v3"
        }
      ],
      "title": "A dancing bear, a colleague, or a sharpened toolbox? The cautious adoption of generative AI technologies in digital humanities research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.12458",
        "PDF": "https://arxiv.org/pdf/2404.12458"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the adoption of GenAI in digital humanities and does not focus on processing or creating LLM training data."
      },
      "tasks": [
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.03217",
      "abstract": "INTRODUCTION: Quantification of amyloid plaques (A), neurofibrillary tangles (T2), and neurodegeneration (N) using PET and MRI is critical for Alzheimer's disease (AD) diagnosis and prognosis. Existing pipelines face limitations regarding processing time, variability in tracer types, and challenges in multimodal integration.\n  METHODS: We developed petBrain, a novel end-to-end processing pipeline for amyloid-PET, tau-PET, and structural MRI. It leverages deep learning-based segmentation, standardized biomarker quantification (Centiloid, CenTauR, HAVAs), and simultaneous estimation of A, T2, and N biomarkers. The pipeline is implemented as a web-based platform, requiring no local computational infrastructure or specialized software knowledge.\n  RESULTS: petBrain provides reliable and rapid biomarker quantification, with results comparable to existing pipelines for A and T2. It shows strong concordance with data processed in ADNI databases. The staging and quantification of A/T2/N by petBrain demonstrated good agreement with CSF/plasma biomarkers, clinical status, and cognitive performance.\n  DISCUSSION: petBrain represents a powerful and openly accessible platform for standardized AD biomarker analysis, facilitating applications in clinical research.",
      "authors": [
        "Pierrick Coup\\'e",
        "Boris Mansencal",
        "Flor\\'eal Morandat",
        "Sergio Morell-Ortega",
        "Nicolas Villain",
        "Jose V. Manj\\'on",
        "Vincent Planche"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-03T07:44:04+00:00",
          "link": "https://arxiv.org/abs/2506.03217v1",
          "size": "2070kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T14:08:11+00:00",
          "link": "https://arxiv.org/abs/2506.03217v2",
          "size": "3071kb",
          "version": "v2"
        }
      ],
      "title": "petBrain: A New Pipeline for Amyloid, Tau Tangles and Neurodegeneration Quantification Using PET and MRI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03217",
        "PDF": "https://arxiv.org/pdf/2506.03217"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a pipeline for medical imaging analysis and biomarker quantification, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Prognosis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10737",
      "abstract": "High-throughput screening techniques, such as microscopy imaging of cellular responses to genetic and chemical perturbations, play a crucial role in drug discovery and biomedical research. However, robust perturbation screening for \\textit{de novo} cell lines remains challenging due to the significant morphological and biological heterogeneity across cell lines. To address this, we propose a novel framework that integrates external biological knowledge into existing pretraining strategies to enhance microscopy image profiling models. Our approach explicitly disentangles perturbation-specific and cell line-specific representations using external biological information. Specifically, we construct a knowledge graph leveraging protein interaction data from STRING and Hetionet databases to guide models toward perturbation-specific features during pretraining. Additionally, we incorporate transcriptomic features from single-cell foundation models to capture cell line-specific representations. By learning these disentangled features, our method improves the generalization of imaging models to \\textit{de novo} cell lines. We evaluate our framework on the RxRx database through one-shot fine-tuning on an RxRx1 cell line and few-shot fine-tuning on cell lines from the RxRx19a dataset. Experimental results demonstrate that our method enhances microscopy image profiling for \\textit{de novo} cell lines, highlighting its effectiveness in real-world phenotype-based drug discovery applications.",
      "authors": [
        "Jiayuan Chen",
        "Thai-Hoang Pham",
        "Yuanlong Wang",
        "Ping Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:01:06+00:00",
          "link": "https://arxiv.org/abs/2507.10737v1",
          "size": "2266kb",
          "version": "v1"
        }
      ],
      "title": "Integrating Biological Knowledge for Robust Microscopy Image Profiling on De Novo Cell Lines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10737",
        "HTML": "https://arxiv.org/html/2507.10737v1",
        "PDF": "https://arxiv.org/pdf/2507.10737"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for integrating biological knowledge in microscopy imaging but does not address LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10743",
      "abstract": "Sex trafficking refers to the use of force, fraud, or coercion to compel an individual to perform in commercial sex acts against their will. Adult service websites (ASWs) have and continue to be linked to sex trafficking, offering a platform for traffickers to advertise their victims. Thus, organizations involved in the fight against sex trafficking often use ASW data when attempting to identify potential sex trafficking victims. A critical challenge in transforming ASW data into actionable insight is text analysis. Previous research using ASW data has shown that ASW ad text is important for linking ads. However, working with this text is challenging due to its extensive use of emojis, poor grammar, and deliberate obfuscation to evade law enforcement scrutiny. We conduct a comprehensive study of language modeling approaches for this application area, including simple information retrieval methods, pre-trained transformers, and custom transformer models. We demonstrate that characteristics of ASW text data allow efficient custom transformer models to be trained with relatively small GPU resources and used efficiently for inference on consumer hardware. Our custom models outperform fine-tuned variants of well-known encoder-only transformer models, including BERT-base, RoBERTa, and ModernBERT, on accuracy, recall, F1 score, and ROC AUC. We demonstrate the use of our best-performing custom configuration on three tasks related to ASW data analysis: (i) decomposing the giant component in a graph representation of ASW data, (ii) clustering ASW ad text, and (iii) using the learned token embeddings to understand the use of emojis in the illicit context we study. The models we develop represent a significant advancement in ASW text analysis, which can be leveraged in a variety of downstream applications and research.",
      "authors": [
        "Nickolas Freeman",
        "Thanh Nguyen",
        "Gregory Bott",
        "Jason Parton",
        "Collin Francel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:08:07+00:00",
          "link": "https://arxiv.org/abs/2507.10743v1",
          "size": "1972kb",
          "version": "v1"
        }
      ],
      "title": "Language Models for Adult Service Website Text Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10743",
        "HTML": "https://arxiv.org/html/2507.10743v1",
        "PDF": "https://arxiv.org/pdf/2507.10743"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses training language models for text analysis of Adult Service Websites, but it primarily focuses on modeling and does not contribute technically to LLM training data processing techniques such as data preparation or quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11071",
      "abstract": "Log anomaly detection using traditional rule based or deep learning based methods is often challenging due to the large volume and highly complex nature of log sequence. So effective way of detection of anomalous sequence of logs is crucial for system maintenance and development. This paper proposes parameter efficient finetuning specifically low rank adaptation (LoRA) and adapter based approaches for finding contextual anomalies in sequence of logs in large log data set. It compares different tiny large language models (LLMs) on the Thunderbird dataset. The results show that LoRA based finetuning provides substantial performance improvements of 18 to 19 percentage over LogBert based full finetuning approach, achieving accuracy scores between 97.76% and 98.83% compared to 79.37%.",
      "authors": [
        "Isaiah Thompson Ocansey",
        "Ritwik Bhattacharya",
        "Tanmay Sen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:04:31+00:00",
          "link": "https://arxiv.org/abs/2507.11071v1",
          "size": "84kb",
          "version": "v1"
        }
      ],
      "title": "LogTinyLLM: Tiny Large Language Models Based Contextual Log Anomaly Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11071",
        "HTML": "https://arxiv.org/html/2507.11071v1",
        "PDF": "https://arxiv.org/pdf/2507.11071"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While this paper involves finetuning LLMs for log anomaly detection, it does not focus primarily on training data processing or creation of high-quality data for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11075",
      "abstract": "Marker-free human pose estimation (HPE) has found increasing applications in various fields. Current HPE suffers from occasional errors in keypoint recognition and random fluctuation in keypoint trajectories when analyzing kinematic human poses. The performance of existing deep learning-based models for HPE refinement is considerably limited by inaccurate training datasets in which the keypoints are manually annotated. This paper proposed a novel method to overcome the difficulty through joint angle-based modeling. The key techniques include: (i) A joint angle-based model of human pose, which is robust to describe kinematic human poses; (ii) Approximating temporal variation of joint angles through high order Fourier series to get reliable \"ground truth\"; (iii) A bidirectional recurrent network is designed as a post-processing module to refine the estimation of well-established HRNet. Trained with the high-quality dataset constructed using our method, the network demonstrates outstanding performance to correct wrongly recognized joints and smooth their spatiotemporal trajectories. Tests show that joint angle-based refinement (JAR) outperforms the state-of-the-art HPE refinement network in challenging cases like figure skating and breaking.",
      "authors": [
        "Chang Peng",
        "Yifei Zhou",
        "Huifeng Xi",
        "Shiqing Huang",
        "Chuangye Chen",
        "Jianming Yang",
        "Bao Yang",
        "Zhenyu Jiang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:16:39+00:00",
          "link": "https://arxiv.org/abs/2507.11075v1",
          "size": "2074kb",
          "version": "v1"
        }
      ],
      "title": "Joint angle model based learning to refine kinematic human pose estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11075",
        "PDF": "https://arxiv.org/pdf/2507.11075"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves human pose estimation refinement using a dataset constructed by their method, but the focus is on model refinement and not primarily on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10726",
      "abstract": "Understanding relationships between documents in large-scale corpora is essential for knowledge discovery and information organization. However, existing approaches rely heavily on manual annotation or predefined relationship taxonomies. We propose EDR-MQ (Extracting Document Relations by Marginalizing over User Queries), a novel framework that discovers document relationships through query marginalization. EDR-MQ is based on the insight that strongly related documents often co-occur in results across diverse user queries, enabling us to estimate joint probabilities between document pairs by marginalizing over a collection of queries. To enable this query marginalization approach, we develop Multiply Conditioned Retrieval-Augmented Generation (MC-RAG), which employs conditional retrieval where subsequent document retrievals depend on previously retrieved content. By observing co-occurrence patterns across diverse queries, EDR-MQ estimates joint probabilities between document pairs without requiring labeled training data or predefined taxonomies. Experimental results show that our query marginalization approach successfully identifies meaningful document relationships, revealing topical clusters, evidence chains, and cross-domain connections that are not apparent through traditional similarity-based methods. Our query-driven framework offers a practical approach to document organization that adapts to different user perspectives and information needs.",
      "authors": [
        "Yuki Iwamoto and Kaoru Tsunoda and Ken Kaneiwa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:47:13+00:00",
          "link": "https://arxiv.org/abs/2507.10726v1",
          "size": "2906kb",
          "version": "v1"
        }
      ],
      "title": "Extracting Document Relations from Search Corpus by Marginalizing over User Queries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10726",
        "HTML": "https://arxiv.org/html/2507.10726v1",
        "PDF": "https://arxiv.org/pdf/2507.10726"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for extracting document relations from corpora via query marginalization, which is not directly related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11211",
      "abstract": "This letter presents a novel coarse-to-fine motion planning framework for robotic manipulation in cluttered, unmodeled environments. The system integrates a dual-camera perception setup with a B-spline-based model predictive control (MPC) scheme. Initially, the planner generates feasible global trajectories from partial and uncertain observations. As new visual data are incrementally fused, both the environment model and motion planning are progressively refined. A vision-based cost function promotes target-driven exploration, while a refined kernel-perceptron collision detector enables efficient constraint updates for real-time planning. The framework accommodates closed-chain kinematics and supports dynamic replanning. Experiments on a multi-arm platform validate its robustness and adaptability under uncertainties and clutter.",
      "authors": [
        "Chen Cai",
        "Ernesto Dickel Saraiva",
        "Ya-jun Pan",
        "Steven Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T11:27:57+00:00",
          "link": "https://arxiv.org/abs/2507.11211v1",
          "size": "4442kb",
          "version": "v1"
        }
      ],
      "title": "MPC-based Coarse-to-Fine Motion Planning for Robotic Object Transportation in Cluttered Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11211",
        "HTML": "https://arxiv.org/html/2507.11211v1",
        "PDF": "https://arxiv.org/pdf/2507.11211"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper talks about a robotic motion planning framework and does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11267",
      "abstract": "Automatic Target Detection (ATD) and Recognition (ATR) from Thermal Infrared (TI) imagery in the defense and surveillance domain is a challenging computer vision (CV) task in comparison to the commercial autonomous vehicle perception domain. Limited datasets, peculiar domain-specific and TI modality-specific challenges, i.e., limited hardware, scale invariance issues due to greater distances, deliberate occlusion by tactical vehicles, lower sensor resolution and resultant lack of structural information in targets, effects of weather, temperature, and time of day variations, and varying target to clutter ratios all result in increased intra-class variability and higher inter-class similarity, making accurate real-time ATR a challenging CV task. Resultantly, contemporary state-of-the-art (SOTA) deep learning architectures underperform in the ATR domain. We propose a modified anchor-based single-stage detector, called YOLOatr, based on a modified YOLOv5s, with optimal modifications to the detection heads, feature fusion in the neck, and a custom augmentation profile. We evaluate the performance of our proposed model on a comprehensive DSIAC MWIR dataset for real-time ATR over both correlated and decorrelated testing protocols. The results demonstrate that our proposed model achieves state-of-the-art ATR performance of up to 99.6%.",
      "authors": [
        "Aon Safdar",
        "Usman Akram",
        "Waseem Anwar",
        "Basit Malik",
        "Mian Ibad Ali"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:41:01+00:00",
          "link": "https://arxiv.org/abs/2507.11267v1",
          "size": "2490kb",
          "version": "v1"
        }
      ],
      "title": "YOLOatr : Deep Learning Based Automatic Target Detection and Localization in Thermal Infrared Imagery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11267",
        "PDF": "https://arxiv.org/pdf/2507.11267"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents modifications to a YOLOv5s architecture for infrared imagery detection, emphasizing model-specific technical adjustments without reference to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.01507",
      "abstract": "This work analyzes transfer learning of the Variational Quantum Circuit (VQC). Our framework begins with a pretrained VQC configured in one domain and calculates the transition of 1-parameter unitary subgroups required for a new domain. A formalism is established to investigate the adaptability and capability of a VQC under the analysis of loss bounds. Our theory observes knowledge transfer in VQCs and provides a heuristic interpretation for the mechanism. An analytical fine-tuning method is derived to attain the optimal transition for adaptations of similar domains.",
      "authors": [
        "Huan-Hsin Tseng",
        "Hsin-Yi Lin",
        "Samuel Yen-Chi Chen",
        "Shinjae Yoo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-02T19:26:25+00:00",
          "link": "https://arxiv.org/abs/2501.01507v1",
          "size": "2067kb",
          "version": "v1"
        },
        {
          "date": "2025-02-16T22:33:35+00:00",
          "link": "https://arxiv.org/abs/2501.01507v2",
          "size": "2068kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T20:11:55+00:00",
          "link": "https://arxiv.org/abs/2501.01507v3",
          "size": "2064kb",
          "version": "v3"
        }
      ],
      "title": "Transfer Learning Analysis of Variational Quantum Circuits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.01507",
        "HTML": "https://arxiv.org/html/2501.01507v3",
        "PDF": "https://arxiv.org/pdf/2501.01507"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper analyzes transfer learning in Variational Quantum Circuits, focusing on model transfer between domains without addressing LLM training data processing or engineering."
      },
      "tasks": [
        "Transfer Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.14407",
      "abstract": "Retrieval systems are central to many NLP pipelines, but often rely on surface-level cues such as keyword overlap and lexical semantic similarity. To evaluate retrieval beyond these shallow signals, recent benchmarks introduce reasoning-heavy queries; however, they primarily shift the burden to query-side processing techniques -- like prompting or multi-hop retrieval -- that can help resolve complexity. In contrast, we present ImpliRet, a benchmark that shifts the reasoning challenge to document-side processing: The queries are simple, but relevance depends on facts stated implicitly in documents through temporal (e.g., resolving \"two days ago\"), arithmetic, and world knowledge relationships. We evaluate a range of sparse and dense retrievers, all of which struggle in this setting: the best nDCG@10 is only 14.91%. We also test whether long-context models can overcome this limitation. But even with a short context of only thirty documents, including the positive document, GPT-o4-mini scores only 55.54%, showing that document-side reasoning remains a challenge. Our codes are available at: github.com/ZeinabTaghavi/IMPLIRET",
      "authors": [
        "Zeinab Sadat Taghavi",
        "Ali Modarressi",
        "Yunpu Ma",
        "Hinrich Sch\\\"utze"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T11:08:29+00:00",
          "link": "https://arxiv.org/abs/2506.14407v1",
          "size": "1079kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T13:16:23+00:00",
          "link": "https://arxiv.org/abs/2506.14407v2",
          "size": "1079kb",
          "version": "v2"
        }
      ],
      "title": "ImpliRet: Benchmarking the Implicit Fact Retrieval Challenge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14407",
        "HTML": "https://arxiv.org/html/2506.14407v2",
        "PDF": "https://arxiv.org/pdf/2506.14407"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper evaluates a benchmark for retrieval systems, it does not focus on creating or processing LLM training data, only the evaluation of retrieval methods."
      },
      "datasets": [
        {
          "dataset_name": "zeinabTaghavi/ImpliRet",
          "downloads": "416",
          "likes": "0",
          "link": "https://huggingface.co/datasets/zeinabTaghavi/ImpliRet"
        }
      ],
      "tasks": [
        "Benchmarking",
        "Retrieval",
        "Semantic Similarity",
        "Semantic Textual Similarity",
        "World Knowledge"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10998",
      "abstract": "Adversarial attacks on tabular data present fundamental challenges distinct from image or text domains due to the heterogeneous nature of mixed categorical and numerical features. Unlike images where pixel perturbations maintain visual similarity, tabular data lacks intuitive similarity metrics, making it difficult to define imperceptible modifications. Additionally, traditional gradient-based methods prioritise $\\ell_p$-norm constraints, often producing adversarial examples that deviate from the original data distributions, making them detectable. We propose a latent space perturbation framework using a mixed-input Variational Autoencoder (VAE) to generate imperceptible adversarial examples. The proposed VAE integrates categorical embeddings and numerical features into a unified latent manifold, enabling perturbations that preserve statistical consistency. We specify In-Distribution Success Rate (IDSR) to measure the proportion of adversarial examples that remain statistically indistinguishable from the input distribution. Evaluation across six publicly available datasets and three model architectures demonstrates that our method achieves substantially lower outlier rates and more consistent performance compared to traditional input-space attacks and other VAE-based methods adapted from image domain approaches. Our comprehensive analysis includes hyperparameter sensitivity, sparsity control mechanisms, and generative architectural comparisons, revealing that VAE-based attacks depend critically on reconstruction quality but offer superior practical utility when sufficient training data is available. This work highlights the importance of on-manifold perturbations for realistic adversarial attacks on tabular data, offering a robust approach for practical deployment. The source code can be accessed through https://github.com/ZhipengHe/VAE-TabAttack.",
      "authors": [
        "Zhipeng He",
        "Alexander Stevens",
        "Chun Ouyang",
        "Johannes De Smedt",
        "Alistair Barros",
        "Catarina Moreira"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T05:34:44+00:00",
          "link": "https://arxiv.org/abs/2507.10998v1",
          "size": "3522kb",
          "version": "v1"
        }
      ],
      "title": "Crafting Imperceptible On-Manifold Adversarial Attacks for Tabular Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10998",
        "HTML": "https://arxiv.org/html/2507.10998v1",
        "PDF": "https://arxiv.org/pdf/2507.10998"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses adversarial attacks on tabular data rather than LLM training data processing, not contributing to methods for improving LLM data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11031",
      "abstract": "We study the mixing time of Glauber dynamics on monotone systems. For monotone systems satisfying the entropic independence condition, we prove a new mixing time comparison result for Glauber dynamics. For concrete applications, we obtain $\\tilde{O}(n)$ mixing time for the random cluster model induced by the ferromagnetic Ising model with consistently biased external fields, and $\\tilde{O}(n^2)$ mixing time for the bipartite hardcore model under the one-sided uniqueness condition, where $n$ is the number of variables in corresponding models, improving the best known results in [Chen and Zhang, SODA'23] and [Chen, Liu, and Yin, FOCS'23], respectively.\n  Our proof combines ideas from the stochastic dominance argument in the classical censoring inequality and the recently developed high-dimensional expanders. The key step in the proof is a novel comparison result between the Glauber dynamics and the field dynamics for monotone systems.",
      "authors": [
        "Weiming Feng",
        "Minji Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Data Structures and Algorithms (cs.DS)",
        "Mathematical Physics (math-ph)",
        "Mathematical Physics (math.MP)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T06:51:55+00:00",
          "link": "https://arxiv.org/abs/2507.11031v1",
          "size": "47kb",
          "version": "v1"
        }
      ],
      "title": "Rapid Mixing of Glauber Dynamics for Monotone Systems via Entropic Independence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11031",
        "HTML": "https://arxiv.org/html/2507.11031v1",
        "PDF": "https://arxiv.org/pdf/2507.11031"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with mixing time of Glauber dynamics for monotone systems and does not involve any aspect of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.04387",
      "abstract": "In differential privacy (DP) mechanisms, it can be beneficial to release \"redundant\" outputs, where some quantities can be estimated in multiple ways by combining different privatized values. Indeed, the DP 2020 Decennial Census products published by the U.S. Census Bureau consist of such redundant noisy counts. When redundancy is present, the DP output can be improved by enforcing self-consistency (i.e., estimators obtained using different noisy counts result in the same value), and we show that the minimum variance processing is a linear projection. However, standard projection algorithms require excessive computation and memory, making them impractical for large-scale applications such as the Decennial Census. We propose the Scalable Efficient Algorithm for Best Linear Unbiased Estimate (SEA BLUE), based on a two-step process of aggregation and differencing that 1) enforces self-consistency through a linear and unbiased procedure, 2) is computationally and memory efficient, 3) achieves the minimum variance solution under certain structural assumptions, and 4) is empirically shown to be robust to violations of these structural assumptions. We propose three methods of calculating confidence intervals from our estimates, under various assumptions. Finally, we apply SEA BLUE to two 2010 Census demonstration products, illustrating its scalability and validity.",
      "authors": [
        "Jordan Awan",
        "Adam Edwards",
        "Paul Bartholomew",
        "Andrew Sillers"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation (stat.CO)",
        "Cryptography and Security (cs.CR)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-06T16:27:34+00:00",
          "link": "https://arxiv.org/abs/2409.04387v1",
          "size": "480kb",
          "version": "v1"
        },
        {
          "date": "2024-09-24T18:39:26+00:00",
          "link": "https://arxiv.org/abs/2409.04387v2",
          "size": "480kb",
          "version": "v2"
        },
        {
          "date": "2024-10-29T15:49:09+00:00",
          "link": "https://arxiv.org/abs/2409.04387v3",
          "size": "480kb",
          "version": "v3"
        },
        {
          "date": "2025-04-29T12:48:51+00:00",
          "link": "https://arxiv.org/abs/2409.04387v4",
          "size": "596kb",
          "version": "v4"
        },
        {
          "date": "2025-06-30T12:55:44+00:00",
          "link": "https://arxiv.org/abs/2409.04387v5",
          "size": "367kb",
          "version": "v5"
        },
        {
          "date": "2025-07-15T13:02:02+00:00",
          "link": "https://arxiv.org/abs/2409.04387v6",
          "size": "361kb",
          "version": "v6"
        }
      ],
      "title": "Best Linear Unbiased Estimate from Privatized Contingency Tables",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.04387",
        "HTML": "https://arxiv.org/html/2409.04387",
        "PDF": "https://arxiv.org/pdf/2409.04387"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on improving differential privacy outputs for the Census, without any reference to LLM training data or its processing methodologies."
      },
      "repo_urls": [
        "https://github.com/JordanAwan/SeaBlue"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.15704",
      "abstract": "With the explosive growth of academic literature, effectively evaluating the knowledge value of literature has become quite essential. However, most of the existing methods focus on modeling the entire citation network, which is structurally complex and often suffers from long sequence dependencies when dealing with text embeddings. Thus, they might have low efficiency and poor robustness in different fields. To address these issues, a novel knowledge evaluation method is proposed, called EMK-KEN. The model consists of two modules. Specifically, the first module utilizes MetaFP and Mamba to capture semantic features of node metadata and text embeddings to learn contextual representations of each paper. The second module utilizes KAN to further capture the structural information of citation networks in order to learn the differences in different fields of networks. Extensive experiments based on ten benchmark datasets show that our method outperforms the state-of-the-art competitors in effectiveness and robustness.",
      "authors": [
        "Zehui Qu",
        "Chengzhi Liu",
        "Hanwen Cui and Xianping Yu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-19T06:27:46+00:00",
          "link": "https://arxiv.org/abs/2502.15704v1",
          "size": "11383kb",
          "version": "v1"
        }
      ],
      "title": "EMK-KEN: A High-Performance Approach for Assessing Knowledge Value in Citation Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15704",
        "HTML": "https://arxiv.org/html/2502.15704",
        "PDF": "https://arxiv.org/pdf/2502.15704"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses knowledge evaluation in citation networks, focusing on semantic and structural information, but does not involve LLM training data processing."
      },
      "tasks": [
        "Mamba"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.00355",
      "abstract": "In this letter, we investigate a novel pinching antenna (PA)-aided wireless powered communication network (WPCN), in which multiple PAs are activated along a waveguide to establish robust line-of-sight links with multiple devices. Both time division multiple access (TDMA) and non-orthogonal multiple access (NOMA) protocols are considered in the PA-WPCN. Moreover, some practical considerations, including a proportional power model for the PAs, a waveguide transmission loss model, and a nonlinear energy harvesting model, are incorporated into the PA-WPCN. Furthermore, we formulate a sum-rate maximization problem by jointly optimizing resource allocation and PAs position. To address the challenging problem of the PAs position optimization, we propose a high-performance element-wise (EW) algorithm and a low-complexity stochastic parameter differential evolution (SPDE) algorithm. Numerical results validate the remarkable performance of the proposed PA-WPCN and the effectiveness of our algorithms, indicating that optimal performance is attained when the PA power distribution ratio of approximately 0.55-0.6.",
      "authors": [
        "Yixuan Li",
        "Hongbo Xu",
        "Ming Zeng",
        "Yuanwei Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-31T02:37:31+00:00",
          "link": "https://arxiv.org/abs/2506.00355v1",
          "size": "1215kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T09:03:15+00:00",
          "link": "https://arxiv.org/abs/2506.00355v2",
          "size": "1750kb",
          "version": "v2"
        }
      ],
      "title": "Pinching Antenna-Aided Wireless Powered Communication Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.00355",
        "HTML": "https://arxiv.org/html/2506.00355v2",
        "PDF": "https://arxiv.org/pdf/2506.00355"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study is centered on optimizing resource allocation in wireless networks using pinching antennas, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10422",
      "abstract": "The widespread adoption of generative AI (GenAI) tools such as GitHub Copilot and ChatGPT is transforming software development. Since generated source code is virtually impossible to distinguish from manually written code, their real-world usage and impact on open-source software development remain poorly understood. In this paper, we introduce the concept of self-admitted GenAI usage, that is, developers explicitly referring to the use of GenAI tools for content creation in software artifacts. Using this concept as a lens to study how GenAI tools are integrated into open-source software projects, we analyze a curated sample of more than 250,000 GitHub repositories, identifying 1,292 such self-admissions across 156 repositories in commit messages, code comments, and project documentation. Using a mixed methods approach, we derive a taxonomy of 32 tasks, 10 content types, and 11 purposes associated with GenAI usage based on 284 qualitatively coded mentions. We then analyze 13 documents with policies and usage guidelines for GenAI tools and conduct a developer survey to uncover the ethical, legal, and practical concerns behind them. Our findings reveal that developers actively manage how GenAI is used in their projects, highlighting the need for project-level transparency, attribution, and quality control practices in the new era of AI-assisted software development. Finally, we examine the impact of GenAI adoption on code churn in 151 repositories with self-admitted GenAI usage and find no general increase, contradicting popular narratives on the impact of GenAI on software development.",
      "authors": [
        "Tao Xiao",
        "Youmei Fan",
        "Fabio Calefato",
        "Christoph Treude",
        "Raula Gaikovina Kula",
        "Hideaki Hata",
        "Sebastian Baltes"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:05:49+00:00",
          "link": "https://arxiv.org/abs/2507.10422v1",
          "size": "72kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T07:34:48+00:00",
          "link": "https://arxiv.org/abs/2507.10422v2",
          "size": "73kb",
          "version": "v2"
        }
      ],
      "title": "Self-Admitted GenAI Usage in Open-Source Software",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10422",
        "HTML": "https://arxiv.org/html/2507.10422v2",
        "PDF": "https://arxiv.org/pdf/2507.10422"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the use of GenAI tools in software development and discusses their integration and impact on software projects, but it does not discuss processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10614",
      "abstract": "The integration of large language models (LLMs) into automated algorithm design has shown promising potential. A prevalent approach embeds LLMs within search routines to iteratively generate and refine candidate algorithms. However, most existing methods rely on off-the-shelf LLMs trained for general coding tasks,leaving a key question open: Do we need LLMs specifically tailored for algorithm design? If so, how can such LLMs be effectively obtained and how well can they generalize across different algorithm design tasks? In this paper, we take a first step toward answering these questions by exploring fine-tuning of LLMs for algorithm design. We introduce a Diversity-Aware Rank based (DAR) sampling strategy to balance training data diversity and quality, then we leverage direct preference optimization to efficiently align LLM outputs with task objectives. Our experiments, conducted on Llama-3.2-1B-Instruct and Llama- 3.1-8B-Instruct, span three distinct algorithm design tasks. Results suggest that finetuned LLMs can significantly outperform their off-the-shelf counterparts with the smaller Llama-3.2-1B-Instruct and match the larger Llama-3.1-8B-Instruct on the admissible set problem. Moreover, we observe promising generalization: LLMs finetuned on specific algorithm design tasks also improve performance on related tasks with varying settings. These findings highlight the value of task-specific adaptation for LLMs in algorithm design and open new avenues for future research.",
      "authors": [
        "Fei Liu",
        "Rui Zhang",
        "Xi Lin",
        "Zhichao Lu",
        "Qingfu Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T15:21:23+00:00",
          "link": "https://arxiv.org/abs/2507.10614v1",
          "size": "307kb",
          "version": "v1"
        }
      ],
      "title": "Fine-tuning Large Language Model for Automated Algorithm Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10614",
        "PDF": "https://arxiv.org/pdf/2507.10614"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper discusses fine-tuning LLMs for a specific task using a novel sampling strategy for training data, but the main focus is on model performance and not on the broad aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10638",
      "abstract": "We introduce a novel classification framework, ZClassifier, that replaces conventional deterministic logits with diagonal Gaussian-distributed logits. Our method simultaneously addresses temperature scaling and manifold approximation by minimizing the Kullback-Leibler (KL) divergence between the predicted Gaussian distributions and a unit isotropic Gaussian. This unifies uncertainty calibration and latent control in a principled probabilistic manner, enabling a natural interpretation of class confidence and geometric consistency. Experiments on CIFAR-10 and CIFAR-100 show that ZClassifier improves over softmax classifiers in robustness, calibration, and latent separation. We also demonstrate its effectiveness for classifier-guided generation by interpreting logits as Gaussian semantic potentials.",
      "authors": [
        "Shim Soon Yong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:30:40+00:00",
          "link": "https://arxiv.org/abs/2507.10638v1",
          "size": "417kb",
          "version": "v1"
        }
      ],
      "title": "ZClassifier: Temperature Tuning and Manifold Approximation via KL Divergence on Logit Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10638",
        "HTML": "https://arxiv.org/html/2507.10638v1",
        "PDF": "https://arxiv.org/pdf/2507.10638"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on a classification framework improving robustness and calibration in deep learning, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10814",
      "abstract": "General-purpose robotic manipulation, including reach and grasp, is essential for deployment into households and workspaces involving diverse and evolving tasks. Recent advances propose using large pre-trained models, such as Large Language Models and object detectors, to boost robotic perception in reinforcement learning. These models, trained on large datasets via self-supervised learning, can process text prompts and identify diverse objects in scenes, an invaluable skill in RL where learning object interaction is resource-intensive. This study demonstrates how to integrate such models into Goal-Conditioned Reinforcement Learning to enable general and versatile robotic reach and grasp capabilities. We use a pre-trained object detection model to enable the agent to identify the object from a text prompt and generate a mask for goal conditioning. Mask-based goal conditioning provides object-agnostic cues, improving feature sharing and generalization. The effectiveness of the proposed framework is demonstrated in a simulated reach-and-grasp task, where the mask-based goal conditioning consistently maintains a $\\sim$90\\% success rate in grasping both in and out-of-distribution objects, while also ensuring faster convergence to higher returns.",
      "authors": [
        "Huiyi Wang and Fahim Shahriar and Alireza Azimi and Gautham Vasan and Rupam Mahmood and Colin Bellinger"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T21:21:46+00:00",
          "link": "https://arxiv.org/abs/2507.10814v1",
          "size": "2387kb",
          "version": "v1"
        }
      ],
      "title": "Versatile and Generalizable Manipulation via Goal-Conditioned Reinforcement Learning with Grounded Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10814",
        "HTML": "https://arxiv.org/html/2507.10814v1",
        "PDF": "https://arxiv.org/pdf/2507.10814"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study integrates pre-trained models in reinforcement learning for robotic manipulation without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11019",
      "abstract": "Score-function policy gradients have delivered strong results in game-playing, robotics and language-model fine-tuning. Yet its high-variance often undermines training stability. On the other hand, pathwise policy gradients alleviate the training variance, but are reliable only when driven by an accurate action-conditioned value function which is notoriously hard to train without relying on past off-policy data. In this paper, we discuss how to construct a value-gradient driven, on-policy algorithm that allow training Q-value models purely from on-policy data, unlocking the possibility of using pathwise policy updates in the context of on-policy learning. We show how to balance stochastic policies for exploration with constrained policy updates for stable training, and evaluate important architectural components that facilitate accurate value function learning. Building on these insights, we propose Relative Entropy Pathwise Policy Optimization (REPPO), an efficient on-policy algorithm that combines the sample-efficiency of pathwise policy gradients with the simplicity and minimal memory footprint of standard on-policy learning. We demonstrate that REPPO provides strong empirical performance at decreased sample requirements, wall-clock time, memory footprint as well as high hyperparameter robustness in a set of experiments on two standard GPU-parallelized benchmarks.",
      "authors": [
        "Claas Voelcker",
        "Axel Brunnbauer",
        "Marcel Hussing",
        "Michal Nauman",
        "Pieter Abbeel",
        "Eric Eaton",
        "Radu Grosu",
        "Amir-massoud Farahmand",
        "Igor Gilitschenski"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T06:24:07+00:00",
          "link": "https://arxiv.org/abs/2507.11019v1",
          "size": "2922kb",
          "version": "v1"
        }
      ],
      "title": "Relative Entropy Pathwise Policy Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11019",
        "HTML": "https://arxiv.org/html/2507.11019v1",
        "PDF": "https://arxiv.org/pdf/2507.11019"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on developing policy optimization algorithms for learning environments, without discussing the processing or improvement of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.02016",
      "abstract": "The study of neural networks from the perspective of Fourier features has garnered significant attention. While existing analytical research suggests that neural networks tend to learn low-frequency features, a clear attribution method for identifying the specific learned Fourier features has remained elusive. To bridge this gap, we propose a novel Fourier feature attribution method grounded in signal decomposition theory. Additionally, we analyze the differences between game-theoretic attribution metrics for Fourier and spatial domain features, demonstrating that game-theoretic evaluation metrics are better suited for Fourier-based feature attribution.\n  Our experiments show that Fourier feature attribution exhibits superior feature selection capabilities compared to spatial domain attribution methods. For instance, in the case of Vision Transformers (ViTs) on the ImageNet dataset, only $8\\%$ of the Fourier features are required to maintain the original predictions for $80\\%$ of the samples. Furthermore, we compare the specificity of features identified by our method against traditional spatial domain attribution methods. Results reveal that Fourier features exhibit greater intra-class concentration and inter-class distinctiveness, indicating their potential for more efficient classification and explainable AI algorithms.",
      "authors": [
        "Zechen Liu",
        "Feiyang Zhang",
        "Wei Song",
        "Xiang Li",
        "Wei Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-02T13:20:19+00:00",
          "link": "https://arxiv.org/abs/2504.02016v1",
          "size": "6919kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T09:58:14+00:00",
          "link": "https://arxiv.org/abs/2504.02016v2",
          "size": "12466kb",
          "version": "v2"
        }
      ],
      "title": "Fast Fourier Correlation is a Highly Efficient and Accurate Feature Attribution Algorithm from the Perspective of Control Theory and Game Theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.02016",
        "HTML": "https://arxiv.org/html/2504.02016v2",
        "PDF": "https://arxiv.org/pdf/2504.02016"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study addresses feature attribution using Fourier analysis but does not contribute to the processing or creation of LLM training datasets."
      },
      "tasks": [
        "feature selection",
        "Specificity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10958",
      "abstract": "This Working Note summarizes the participation of the DS@GT team in two eRisk 2025 challenges. For the Pilot Task on conversational depression detection with large language-models (LLMs), we adopted a prompt-engineering strategy in which diverse LLMs conducted BDI-II-based assessments and produced structured JSON outputs. Because ground-truth labels were unavailable, we evaluated cross-model agreement and internal consistency. Our prompt design methodology aligned model outputs with BDI-II criteria and enabled the analysis of conversational cues that influenced the prediction of symptoms. Our best submission, second on the official leaderboard, achieved DCHR = 0.50, ADODL = 0.89, and ASHR = 0.27.",
      "authors": [
        "Anthony Miyaguchi",
        "David Guecha",
        "Yuwen Chiu",
        "Sidharth Gaur"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T03:40:46+00:00",
          "link": "https://arxiv.org/abs/2507.10958v1",
          "size": "619kb",
          "version": "v1"
        }
      ],
      "title": "DS@GT at eRisk 2025: From prompts to predictions, benchmarking early depression detection with conversational agent based assessments and temporal attention models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10958",
        "PDF": "https://arxiv.org/pdf/2507.10958"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on prompt-engineering and LLM evaluation for depression detection but does not primarily address training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.07078",
      "abstract": "Recognising emotions in context involves identifying an individual's apparent emotions while considering contextual cues from the surrounding scene. Previous approaches to this task have typically designed explicit scene-encoding architectures or incorporated external scene-related information, such as captions. However, these methods often utilise limited contextual information or rely on intricate training pipelines to decouple noise from relevant information. In this work, we leverage the capabilities of Vision-and-Large-Language Models (VLLMs) to enhance in-context emotion classification in a more straightforward manner. Our proposed method follows a simple yet effective two-stage approach. First, we prompt VLLMs to generate natural language descriptions of the subject's apparent emotion in relation to the visual context. Second, the descriptions, along with the visual input, are used to train a transformer-based architecture that fuses text and visual features before the final classification task. This method not only simplifies the training process but also significantly improves performance. Experimental results demonstrate that the textual descriptions effectively guide the model to constrain the noisy visual input, allowing our fused architecture to outperform individual modalities. Our approach achieves state-of-the-art performance across three datasets, BoLD, EMOTIC, and CAER-S, without bells and whistles. The code will be made publicly available on github: https://github.com/NickyFot/EmoCommonSense.git",
      "authors": [
        "Alexandros Xenos",
        "Niki Maria Foteinopoulou",
        "Ioanna Ntinou",
        "Ioannis Patras",
        "Georgios Tzimiropoulos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-10T15:09:15+00:00",
          "link": "https://arxiv.org/abs/2404.07078v1",
          "size": "19764kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T11:18:24+00:00",
          "link": "https://arxiv.org/abs/2404.07078v2",
          "size": "4968kb",
          "version": "v2"
        }
      ],
      "title": "VLLMs Provide Better Context for Emotion Understanding Through Common Sense Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.07078",
        "HTML": "https://arxiv.org/html/2404.07078v2",
        "PDF": "https://arxiv.org/pdf/2404.07078"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving emotion classification using VLLMs and not on LLM training data processing or engineering."
      },
      "tasks": [
        "Common Sense Reasoning",
        "Emotion Classification",
        "Emotion Recognition in Context"
      ],
      "repo_urls": [
        "https://github.com/nickyfot/emocommonsense"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.15858",
      "abstract": "Connectionist temporal classification (CTC)-based scene text recognition (STR) methods, e.g., SVTR, are widely employed in OCR applications, mainly due to their simple architecture, which only contains a visual model and a CTC-aligned linear classifier, and therefore fast inference. However, they generally exhibit worse accuracy than encoder-decoder-based methods (EDTRs) due to struggling with text irregularity and linguistic missing. To address these challenges, we propose SVTRv2, a CTC model endowed with the ability to handle text irregularities and model linguistic context. First, a multi-size resizing strategy is proposed to resize text instances to appropriate predefined sizes, effectively avoiding severe text distortion. Meanwhile, we introduce a feature rearrangement module to ensure that visual features accommodate the requirement of CTC, thus alleviating the alignment puzzle. Second, we propose a semantic guidance module. It integrates linguistic context into the visual features, allowing CTC model to leverage language information for accuracy improvement. This module can be omitted at the inference stage and would not increase the time cost. We extensively evaluate SVTRv2 in both standard and recent challenging benchmarks, where SVTRv2 is fairly compared to popular STR models across multiple scenarios, including different types of text irregularity, languages, long text, and whether employing pretraining. SVTRv2 surpasses most EDTRs across the scenarios in terms of accuracy and inference speed. Code: https://github.com/Topdu/OpenOCR.",
      "authors": [
        "Yongkun Du",
        "Zhineng Chen",
        "Hongtao Xie",
        "Caiyan Jia",
        "Yu-Gang Jiang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-24T14:21:35+00:00",
          "link": "https://arxiv.org/abs/2411.15858v1",
          "size": "8413kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T09:49:40+00:00",
          "link": "https://arxiv.org/abs/2411.15858v2",
          "size": "8429kb",
          "version": "v2"
        }
      ],
      "title": "SVTRv2: CTC Beats Encoder-Decoder Models in Scene Text Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.15858",
        "HTML": "https://arxiv.org/html/2411.15858v2",
        "PDF": "https://arxiv.org/pdf/2411.15858"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes improvements in a CTC-based model for scene text recognition, focusing on solving text irregularity and linguistic challenges. It does not involve LLM training data processing or data engineering steps."
      },
      "tasks": [
        "Decoder",
        "Optical Character Recognition (OCR)",
        "Scene Text Recognition"
      ],
      "repo_urls": [
        "https://github.com/topdu/openocr"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.01860",
      "abstract": "We investigate the hyperbolic decomposition of the Dirichlet norm and distance between autoregressive moving average (ARMA) models. With the K\\\"ahler information geometry of linear systems in Hardy spaces and weighted Hardy spaces, we demonstrate that the Dirichlet norm and distance of ARMA models, corresponding to the mutual information between the past and future, are decomposed into functions of the hyperbolic distances between the poles and zeros of the ARMA models. Moreover, the distance is also expressed with separate terms from AR parts, MA parts, and AR-MA cross terms. Furthermore, the hyperbolic decomposition is helpful for the model order reduction of ARMA models.",
      "authors": [
        "Jaehyung Choi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-02T16:12:24+00:00",
          "link": "https://arxiv.org/abs/2504.01860v1",
          "size": "7kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T22:21:36+00:00",
          "link": "https://arxiv.org/abs/2504.01860v2",
          "size": "7kb",
          "version": "v2"
        }
      ],
      "title": "Hyperbolic decomposition of Dirichlet distance for ARMA models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.01860",
        "HTML": "https://arxiv.org/html/2504.01860v2",
        "PDF": "https://arxiv.org/pdf/2504.01860"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the hyperbolic decomposition of Dirichlet distance for ARMA models, which is unrelated to any processing of LLM training data or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10610",
      "abstract": "Graphical user interface (GUI) agents built on multimodal large language models (MLLMs) have recently demonstrated strong decision-making abilities in screen-based interaction tasks. However, they remain highly vulnerable to pop-up-based environmental injection attacks, where malicious visual elements divert model attention and lead to unsafe or incorrect actions. Existing defense methods either require costly retraining or perform poorly under inductive interference. In this work, we systematically study how such attacks alter the attention behavior of GUI agents and uncover a layer-wise attention divergence pattern between correct and incorrect outputs. Based on this insight, we propose \\textbf{LaSM}, a \\textit{Layer-wise Scaling Mechanism} that selectively amplifies attention and MLP modules in critical layers. LaSM improves the alignment between model saliency and task-relevant regions without additional training. Extensive experiments across 12 types of pop-up perturbations and 4 different model backbones show that LaSM consistently enhances the defense success rate. When combined with prompt-level alerts, LaSM achieves over 98\\% robustness even under strong inductive attacks. Our findings reveal that attention misalignment is a core vulnerability in MLLM agents and can be effectively addressed through selective layer-wise modulation.",
      "authors": [
        "Zihe Yan",
        "Zhuosheng Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T08:36:09+00:00",
          "link": "https://arxiv.org/abs/2507.10610v1",
          "size": "3121kb",
          "version": "v1"
        }
      ],
      "title": "LaSM: Layer-wise Scaling Mechanism for Defending Pop-up Attack on GUI Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10610",
        "HTML": "https://arxiv.org/html/2507.10610v1",
        "PDF": "https://arxiv.org/pdf/2507.10610"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a defense mechanism for GUI agents in multimodal LLMs against pop-up attacks, without any mention of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.12334",
      "abstract": "In many applications, especially due to lack of supervision or privacy concerns, the training data is grouped into bags of instances (feature-vectors) and for each bag we have only an aggregate label derived from the instance-labels in the bag. In learning from label proportions (LLP) the aggregate label is the average of the instance-labels in a bag, and a significant body of work has focused on training models in the LLP setting to predict instance-labels. In practice however, the training data may have fully supervised albeit covariate-shifted source data, along with the usual target data with bag-labels, and we wish to train a good instance-level predictor on the target domain. We call this the covariate-shifted hybrid LLP problem. Fully supervised covariate shifted data often has useful training signals and the goal is to leverage them for better predictive performance in the hybrid LLP setting. To achieve this, we develop methods for hybrid LLP which naturally incorporate the target bag-labels along with the source instance-labels, in the domain adaptation framework. Apart from proving theoretical guarantees bounding the target generalization error, we also conduct experiments on several publicly available datasets showing that our methods outperform LLP and domain adaptation baselines as well techniques from previous related work.",
      "authors": [
        "Sagalpreet Singh",
        "Navodita Sharma",
        "Shreyas Havaldar",
        "Rishi Saket",
        "Aravindan Raghuveer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-19T08:36:34+00:00",
          "link": "https://arxiv.org/abs/2411.12334v1",
          "size": "36kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T06:25:46+00:00",
          "link": "https://arxiv.org/abs/2411.12334v2",
          "size": "47kb",
          "version": "v2"
        }
      ],
      "title": "Learning from Label Proportions and Covariate-shifted Instances",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.12334",
        "HTML": "https://arxiv.org/html/2411.12334v2",
        "PDF": "https://arxiv.org/pdf/2411.12334"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with learning from label proportions and covariate-shifted instances, but it does not address any aspects related to LLM training data processing or data engineering."
      },
      "tasks": [
        "Domain Adaptation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.19086",
      "abstract": "We adopt Gaussian Processes (GPs) as latent functions for probabilistic forecasting of intermittent time series. The model is trained in a Bayesian framework that accounts for the uncertainty about the latent function. We couple the latent GP variable with two types of forecast distributions: the negative binomial (NegBinGP) and the Tweedie distribution (TweedieGP). While the negative binomial has already been used in forecasting intermittent time series, this is the first time in which a fully parameterized Tweedie density is used for intermittent time series. We properly evaluate the Tweedie density, which has both a point mass at zero and heavy tails, avoiding simplifying assumptions made in existing models. We test our models on thousands of intermittent count time series. Results show that our models provide consistently better probabilistic forecasts than the competitors. In particular, TweedieGP obtains the best estimates of the highest quantiles, thus showing that it is more flexible than NegBinGP.",
      "authors": [
        "Stefano Damato",
        "Dario Azzimonti and Giorgio Corani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-26T12:31:56+00:00",
          "link": "https://arxiv.org/abs/2502.19086v1",
          "size": "1564kb",
          "version": "v1"
        },
        {
          "date": "2025-02-27T10:32:12+00:00",
          "link": "https://arxiv.org/abs/2502.19086v2",
          "size": "1564kb",
          "version": "v2"
        },
        {
          "date": "2025-05-13T22:38:37+00:00",
          "link": "https://arxiv.org/abs/2502.19086v3",
          "size": "4061kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T21:24:25+00:00",
          "link": "https://arxiv.org/abs/2502.19086v4",
          "size": "2016kb",
          "version": "v4"
        }
      ],
      "title": "Forecasting intermittent time series with Gaussian Processes and Tweedie likelihood",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.19086",
        "HTML": "https://arxiv.org/html/2502.19086v4",
        "PDF": "https://arxiv.org/pdf/2502.19086"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the application of Gaussian Processes for probabilistic forecasting of time series, which is unrelated to LLM training data processing."
      },
      "tasks": [
        "Gaussian Processes",
        "Time Series"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09116",
      "abstract": "Despite substantial improvements in ASR, performance tends to degrade when faced with adverse conditions such as speaker accents. Generative error correction (GER) leverages the rich linguistic knowledge and exceptional reasoning ability of LLMs, significantly outperforming typical LM methods. However, it lacks specificity in accented speech scenarios. In this study, we leverage GER to improve the accuracy of transcription predictions by addressing the two primary features of accented speech recognition. To fully leverage pronunciation information, we propose the multi-modal GER, which integrates pronunciation information from the speech modality, and the multi-granularity GER, which incorporates fine-grained phoneme-level information related to pronunciation. These two methods enable the LLM to utilize the pronunciation information of accented speech and the semantic information from word-level hypotheses for accurate transcription predictions through LoRA fine-tuning. On the one hand, we employ a three-stage training strategy to train separate multi-modal GER models for each accent to obtain mono-accent LoRA experts. By adopting our proposed HDMoLE method, which incorporates hierarchical routing and dynamic thresholds within the mixture of LoRA experts, we effectively merge multiple mono-accent LoRA experts within a single multi-modal GER to overcome the challenges posed by accent diversity. On the other hand, multi-granularity GER leverages the N-best word-level and phoneme-level hypotheses generated by the HDMoLE model to predict the final accented speech transcriptions. Experimental results on the multi-accent English dataset demonstrate the efficacy of our proposed methods. Our methods achieve a remarkable relative WER reduction of 67.35% compared to the Whisper-large-v3 baseline.",
      "authors": [
        "Bingshen Mu",
        "Kun Wei",
        "Pengcheng Guo",
        "Lei Xie"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T02:14:50+00:00",
          "link": "https://arxiv.org/abs/2507.09116v1",
          "size": "1770kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T02:03:44+00:00",
          "link": "https://arxiv.org/abs/2507.09116v2",
          "size": "1770kb",
          "version": "v2"
        }
      ],
      "title": "Mixture of LoRA Experts with Multi-Modal and Multi-Granularity LLM Generative Error Correction for Accented Speech Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09116",
        "HTML": "https://arxiv.org/html/2507.09116v2",
        "PDF": "https://arxiv.org/pdf/2507.09116"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper applies LoRA fine-tuning for error correction in ASR. While it involves LLMs, it doesn't focus on the processing of LLM training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10911",
      "abstract": "Therapy recommendation for chronic patients with multimorbidity is challenging due to risks of treatment conflicts. Existing decision support systems face scalability limitations. Inspired by the way in which general practitioners (GP) manage multimorbidity patients, occasionally convening multidisciplinary team (MDT) collaboration, this study investigated the feasibility and value of using a Large Language Model (LLM)-based multi-agent system (MAS) for safer therapy recommendations. We designed a single agent and a MAS framework simulating MDT decision-making by enabling discussion among LLM agents to resolve medical conflicts. The systems were evaluated on therapy planning tasks for multimorbidity patients using benchmark cases. We compared MAS performance with single-agent approaches and real-world benchmarks. An important contribution of our study is the definition of evaluation metrics that go beyond the technical precision and recall and allow the inspection of clinical goals met and medication burden of the proposed advices to a gold standard benchmark. Our results show that with current LLMs, a single agent GP performs as well as MDTs. The best-scoring models provide correct recommendations that address all clinical goals, yet the advices are incomplete. Some models also present unnecessary medications, resulting in unnecessary conflicts between medication and conditions or drug-drug interactions.",
      "authors": [
        "Yicong Wu",
        "Ting Chen",
        "Irit Hochberg",
        "Zhoujian Sun",
        "Ruth Edry",
        "Zhengxing Huang",
        "Mor Peleg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T02:01:38+00:00",
          "link": "https://arxiv.org/abs/2507.10911v1",
          "size": "934kb",
          "version": "v1"
        }
      ],
      "title": "Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10911",
        "PDF": "https://arxiv.org/pdf/2507.10911"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study evaluates LLM-based systems for therapy recommendations but does not involve processing or creating training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11102",
      "abstract": "The emergence of Multimodal Large Language Models (MLLMs) has revolutionized image understanding by bridging textual and visual modalities. However, these models often struggle with capturing fine-grained semantic information, such as the precise identification and analysis of object keypoints. Keypoints, as structure-aware, pixel-level, and compact representations of objects, particularly articulated ones, play a crucial role in applications such as fine-grained image analysis, object retrieval, and behavior recognition. In this paper, we propose KptLLM++, a novel multimodal large language model that specifically designed for generic keypoint comprehension through the integration of diverse input modalities guided by user-defined instructions. By unifying keypoint detection across varied contexts, KptLLM++ establishes itself as an advanced interface, fostering more effective human-AI collaboration. The model is built upon a novel identify-then-detect paradigm, which first interprets keypoint semantics and subsequently localizes their precise positions through a structured chain-of-thought reasoning mechanism. To push the boundaries of performance, we have scaled up the training dataset to over 500K samples, encompassing diverse objects, keypoint categories, image styles, and scenarios with complex occlusions. This extensive scaling enables KptLLM++ to unlock its potential, achieving remarkable accuracy and generalization. Comprehensive experiments on multiple keypoint detection benchmarks demonstrate its state-of-the-art performance, underscoring its potential as a unified solution for fine-grained image understanding and its transformative implications for human-AI interaction.",
      "authors": [
        "Jie Yang",
        "Wang Zeng",
        "Sheng Jin",
        "Lumin Xu",
        "Wentao Liu",
        "Chen Qian",
        "Zhen Li",
        "Ruimao Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:52:28+00:00",
          "link": "https://arxiv.org/abs/2507.11102v1",
          "size": "5702kb",
          "version": "v1"
        }
      ],
      "title": "KptLLM++: Towards Generic Keypoint Comprehension with Large Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11102",
        "HTML": "https://arxiv.org/html/2507.11102v1",
        "PDF": "https://arxiv.org/pdf/2507.11102"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper on KptLLM++ discusses scaling up the training dataset, its primary focus is on model architecture for multimodal LLMs, not on data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2308.09730",
      "abstract": "The credibility of Artificial Intelligence (AI) models for medical imaging continues to be a challenge, affected by the diversity of models, the data used to train the models, and applicability of their combination to produce reproducible results for new data. In this work we aimed to explore if the emerging Virtual Imaging Trials (VIT) methodologies can provide an objective resource to approach this challenge. The study was conducted for the case example of COVID-19 diagnosis using clinical and virtual computed tomography (CT) and chest radiography (CXR) processed with convolutional neural networks (CNNs). Multiple AI models were developed and tested using 3D ResNet-like and 2D EfficientNetv2 architectures across diverse datasets. The performance differences were evaluated in terms of the area under the curve (AUC) and the DeLong method for AUC confidence intervals. The models trained on the most diverse datasets showed the highest external testing performance, with AUC values ranging from 0.73 to 0.76 for CT and 0.70 to 0.73 for CXR. Internal testing yielded higher AUC values (0.77 to 0.85 for CT and 0.77 to 1.0 for CXR), highlighting a substantial drop in performance during external validation, which underscores the importance of diverse and comprehensive training and testing data. Most notably, the VIT approach provided objective assessment of the utility of diverse models and datasets while further providing insight into the influence of dataset characteristics, patient factors, and imaging physics on AI efficacy. The VIT approach can be used to enhance model transparency and reliability, offering nuanced insights into the factors driving AI performance and bridging the gap between experimental and clinical settings.",
      "authors": [
        "Fakrul Islam Tushar",
        "Lavsen Dahal",
        "Saman Sotoudeh-Paima",
        "Ehsan Abadi",
        "W. Paul Segars",
        "Ehsan Samei",
        "Joseph Y. Lo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-08-17T19:12:32+00:00",
          "link": "https://arxiv.org/abs/2308.09730v1",
          "size": "1176kb",
          "version": "v1"
        },
        {
          "date": "2024-03-31T19:28:25+00:00",
          "link": "https://arxiv.org/abs/2308.09730v2",
          "size": "853kb",
          "version": "v2"
        },
        {
          "date": "2024-10-27T06:03:16+00:00",
          "link": "https://arxiv.org/abs/2308.09730v3",
          "size": "1094kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T22:39:09+00:00",
          "link": "https://arxiv.org/abs/2308.09730v4",
          "size": "1133kb",
          "version": "v4"
        }
      ],
      "title": "The Utility of the Virtual Imaging Trials Methodology for Objective Characterization of AI Systems and Training Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2308.09730",
        "PDF": "https://arxiv.org/pdf/2308.09730"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper explores diverse datasets affecting AI model performance, it does not focus on specific techniques or processes for LLM training data. It provides insights into AI performance related to dataset characteristics."
      },
      "tasks": [
        "3D Classification",
        "Computed Tomography (CT)",
        "COVID-19 Diagnosis"
      ],
      "repo_urls": [
        "https://gitlab.oit.duke.edu/cvit-public/cvit_revicovid19",
        "https://github.com/fitushar/CVIT_ReviCOVID19"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.08889",
      "abstract": "A spring in parallel with an effort source (e.g., electric motor or human muscle) can reduce its energy consumption and effort (i.e., torque or force) depending on the spring stiffness, spring preload, and actuation task. However, selecting the spring stiffness and preload that guarantees effort or energy reduction for an arbitrary set of tasks is a design challenge. This work formulates a convex optimization problem to guarantee that a parallel spring reduces the root-mean-square source effort or energy consumption for multiple tasks. Specifically, we guarantee the benefits across multiple tasks by enforcing a set of convex quadratic constraints in our optimization variables, the parallel spring stiffness and preload. These quadratic constraints are equivalent to ellipses in the stiffness and preload plane; any combination of stiffness and preload inside the ellipse represents a parallel spring that minimizes effort source or energy consumption with respect to an actuator without a spring. This geometric interpretation intuitively guides the stiffness and preload selection process. We analytically and experimentally prove the convex quadratic function of the spring stiffness and preload. As applications, we analyze the stiffness and preload selection of a parallel spring for a knee exoskeleton using human muscle as the effort source and a prosthetic ankle powered by electric motors. The source code associated with our framework is available as supplemental open-source software.",
      "authors": [
        "Kang Yang",
        "Myia Dickens",
        "James Schmiedeler",
        "and Edgar Bol\\'ivar-Nieto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-13T14:55:20+00:00",
          "link": "https://arxiv.org/abs/2409.08889v1",
          "size": "1685kb",
          "version": "v1"
        },
        {
          "date": "2024-11-22T13:37:17+00:00",
          "link": "https://arxiv.org/abs/2409.08889v2",
          "size": "1857kb",
          "version": "v2"
        },
        {
          "date": "2025-05-07T22:07:55+00:00",
          "link": "https://arxiv.org/abs/2409.08889v3",
          "size": "1890kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T20:48:34+00:00",
          "link": "https://arxiv.org/abs/2409.08889v4",
          "size": "1690kb",
          "version": "v4"
        }
      ],
      "title": "Extending the Benefits of Parallel Elasticity across Multiple Actuation Tasks: A Geometric and Optimization-Based Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.08889",
        "PDF": "https://arxiv.org/pdf/2409.08889"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on optimization for energy reduction in actuators and does not involve LLM training data or related data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10568",
      "abstract": "Spiking neural networks inherently rely on the precise timing of discrete spike events for information processing. Incorporating additional bio-inspired degrees of freedom, such as trainable synaptic transmission delays and adaptive firing thresholds, is essential for fully leveraging the temporal dynamics of SNNs. Although recent methods have demonstrated the benefits of training synaptic weights and delays, both in terms of accuracy and temporal representation, these techniques typically rely on discrete-time simulations, surrogate gradient approximations, or full access to internal state variables such as membrane potentials. Such requirements limit training precision and efficiency and pose challenges for neuromorphic hardware implementation due to increased memory and I/O bandwidth demands. To overcome these challenges, we propose an analytical event-driven learning framework that computes exact loss gradients not only with respect to synaptic weights and transmission delays but also to adaptive neuronal firing thresholds. Experiments on multiple benchmarks demonstrate significant gains in accuracy (up to 7%), timing precision, and robustness compared to existing methods.",
      "authors": [
        "Arman Ferdowsi and Atakan Aral"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T11:55:27+00:00",
          "link": "https://arxiv.org/abs/2507.10568v1",
          "size": "779kb",
          "version": "v1"
        }
      ],
      "title": "An Exact Gradient Framework for Training Spiking Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10568",
        "HTML": "https://arxiv.org/html/2507.10568v1",
        "PDF": "https://arxiv.org/pdf/2507.10568"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on an exact gradient framework for training spiking neural networks, which is unrelated to processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11234",
      "abstract": "The Skolem Problem asks to determine whether a given linear recurrence sequence (LRS) $\\langle u_n \\rangle_{n=0}^\\infty$ over the integers has a zero term, that is, whether there exists $n$ such that $u_n = 0$. Decidability of the problem is open in general, with the most notable positive result being a decision procedure for LRS of order at most 4.\n  In this paper we consider a bounded version of the Skolem Problem, in which the input consists of an LRS $\\langle u_n \\rangle_{n=0}^\\infty$ and a bound $N \\in \\mathbb N$ (with all integers written in binary), and the task is to determine whether there exists $n\\in\\{0,\\ldots,N\\}$ such that $u_n=0$. We give a randomised algorithm for this problem that, for all $d\\in \\mathbb N$, runs in polynomial time on the class of LRS of order at most $d$. As a corollary we show that the (unrestricted) Skolem Problem for LRS of order at most 4 lies in $\\mathsf{coRP}$, improving the best previous upper bound of $\\mathsf{NP}^{\\mathsf{RP}}$.\n  The running time of our algorithm is exponential in the order of the LRS -- a dependence that appears necessary in view of the $\\mathsf{NP}$-hardness of the Bounded Skolem Problem. However, even for LRS of a fixed order, the problem involves detecting zeros within an exponentially large range. For this, our algorithm relies on results from $p$-adic analysis to isolate polynomially many candidate zeros and then test in randomised polynomial time whether each candidate is an actual zero by reduction to arithmetic-circuit identity testing.",
      "authors": [
        "Piotr Bacik and Jo\\\"el Ouaknine and James Worrell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:04:28+00:00",
          "link": "https://arxiv.org/abs/2507.11234v1",
          "size": "26kb",
          "version": "v1"
        }
      ],
      "title": "On the Complexity of the Skolem Problem at Low Orders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11234",
        "HTML": "https://arxiv.org/html/2507.11234v1",
        "PDF": "https://arxiv.org/pdf/2507.11234"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with the complexity of the Skolem Problem and does not address LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11430",
      "abstract": "Federated Learning (FL) has undergone significant development since its inception in 2016, advancing from basic algorithms to complex methodologies tailored to address diverse challenges and use cases. However, research and benchmarking of novel FL techniques against a plethora of established state-of-the-art solutions remain challenging. To streamline this process, we introduce FLsim, a comprehensive FL simulation framework designed to meet the diverse requirements of FL workflows in the literature. FLsim is characterized by its modularity, scalability, resource efficiency, and controlled reproducibility of experimental outcomes. Its easy to use interface allows users to specify customized FL requirements through job configuration, which supports: (a) customized data distributions, ranging from non-independent and identically distributed (non-iid) data to independent and identically distributed (iid) data, (b) selection of local learning algorithms according to user preferences, with complete agnosticism to ML libraries, (c) choice of network topology illustrating communication patterns among nodes, (d) definition of model aggregation and consensus algorithms, and (e) pluggable blockchain support for enhanced robustness. Through a series of experimental evaluations, we demonstrate the effectiveness and versatility of FLsim in simulating a diverse range of state-of-the-art FL experiments. We envisage that FLsim would mark a significant advancement in FL simulation frameworks, offering unprecedented flexibility and functionality for researchers and practitioners alike.",
      "authors": [
        "Arnab Mukherjee",
        "Raju Halder",
        "Joydeep Chandra"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:53:01+00:00",
          "link": "https://arxiv.org/abs/2507.11430v1",
          "size": "1812kb",
          "version": "v1"
        }
      ],
      "title": "FLsim: A Modular and Library-Agnostic Simulation Framework for Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11430",
        "PDF": "https://arxiv.org/pdf/2507.11430"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a simulation framework for federated learning without mentioning any contributions related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.08054",
      "abstract": "Safety alignment approaches in large language models (LLMs) often lead to the over-refusal of benign queries, significantly diminishing their utility in sensitive scenarios. To address this challenge, we introduce FalseReject, a comprehensive resource containing 16k seemingly toxic queries accompanied by structured responses across 44 safety-related categories. We propose a graph-informed adversarial multi-agent interaction framework to generate diverse and complex prompts, while structuring responses with explicit reasoning to aid models in accurately distinguishing safe from unsafe contexts. FalseReject includes training datasets tailored for both standard instruction-tuned models and reasoning-oriented models, as well as a human-annotated benchmark test set. Our extensive benchmarking on 29 state-of-the-art (SOTA) LLMs reveals persistent over-refusal challenges. Empirical results demonstrate that supervised finetuning with FalseReject substantially reduces unnecessary refusals without compromising overall safety or general language capabilities.",
      "authors": [
        "Zhehao Zhang",
        "Weijie Xu",
        "Fanyou Wu",
        "Chandan K. Reddy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-12T20:45:25+00:00",
          "link": "https://arxiv.org/abs/2505.08054v1",
          "size": "7506kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T10:03:15+00:00",
          "link": "https://arxiv.org/abs/2505.08054v2",
          "size": "6339kb",
          "version": "v2"
        }
      ],
      "title": "FalseReject: A Resource for Improving Contextual Safety and Mitigating Over-Refusals in LLMs via Structured Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.08054",
        "HTML": "https://arxiv.org/html/2505.08054v2",
        "PDF": "https://arxiv.org/pdf/2505.08054"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper creates a new dataset (FalseReject) and details the data processing steps for training datasets to improve LLM safety alignment, focusing specifically on data engineering operations."
      },
      "datasets": [
        {
          "dataset_name": "AmazonScience/FalseReject",
          "downloads": "141",
          "likes": "5",
          "link": "https://huggingface.co/datasets/AmazonScience/FalseReject"
        }
      ],
      "tasks": [
        "16k",
        "Benchmarking",
        "Safety Alignment"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.11279",
      "abstract": "Observer bias and inconsistencies in traditional plant phenotyping methods limit the accuracy and reproducibility of fine-grained plant analysis. To overcome these challenges, we developed TomatoMAP, a comprehensive dataset for Solanum lycopersicum using an Internet of Things (IoT) based imaging system with standardized data acquisition protocols. Our dataset contains 64,464 RGB images that capture 12 different plant poses from four camera elevation angles. Each image includes manually annotated bounding boxes for seven regions of interest (ROIs), including leaves, panicle, batch of flowers, batch of fruits, axillary shoot, shoot and whole plant area, along with 50 fine-grained growth stage classifications based on the BBCH scale. Additionally, we provide 3,616 high-resolution image subset with pixel-wise semantic and instance segmentation annotations for fine-grained phenotyping. We validated our dataset using a cascading model deep learning framework combining MobileNetv3 for classification, YOLOv11 for object detection, and MaskRCNN for segmentation. Through AI vs. Human analysis involving five domain experts, we demonstrate that the models trained on our dataset achieve accuracy and speed comparable to the experts. Cohen's Kappa and inter-rater agreement heatmap confirm the reliability of automated fine-grained phenotyping using our approach.",
      "authors": [
        "Yujie Zhang",
        "Sabine Struckmeyer",
        "Andreas Kolb",
        "Sven Reichardt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:56:13+00:00",
          "link": "https://arxiv.org/abs/2507.11279v1",
          "size": "2272kb",
          "version": "v1"
        }
      ],
      "title": "Tomato Multi-Angle Multi-Pose Dataset for Fine-Grained Phenotyping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11279",
        "HTML": "https://arxiv.org/html/2507.11279v1",
        "PDF": "https://arxiv.org/pdf/2507.11279"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper focuses on the development of a new dataset for plant phenotyping with clear, detailed data processing steps. This includes standardized data acquisition protocols and various annotations, significantly improving data quality for phenotyping."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.05287",
      "abstract": "We study the problem of online multi-group learning, a learning model in which an online learner must simultaneously achieve small prediction regret on a large collection of (possibly overlapping) subsequences corresponding to a family of groups. Groups are subsets of the context space, and in fairness applications, they may correspond to subpopulations defined by expressive functions of demographic attributes. In contrast to previous work on this learning model, we consider scenarios in which the family of groups is too large to explicitly enumerate, and hence we seek algorithms that only access groups via an optimization oracle. In this paper, we design such oracle-efficient algorithms with sublinear regret under a variety of settings, including: (i) the i.i.d. setting, (ii) the adversarial setting with smoothed context distributions, and (iii) the adversarial transductive setting.",
      "authors": [
        "Samuel Deng",
        "Daniel Hsu",
        "Jingwen Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Science and Game Theory (cs.GT)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-07T23:00:02+00:00",
          "link": "https://arxiv.org/abs/2406.05287v1",
          "size": "184kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T18:43:51+00:00",
          "link": "https://arxiv.org/abs/2406.05287v2",
          "size": "157kb",
          "version": "v2"
        }
      ],
      "title": "Group-wise oracle-efficient algorithms for online multi-group learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.05287",
        "PDF": "https://arxiv.org/pdf/2406.05287"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses algorithm design for online multi-group learning without discussing LLM training data processing."
      },
      "tasks": [
        "Fairness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.12351",
      "abstract": "Here we study the multipacking problems for geometric point sets with respect to their Euclidean distances. We consider a set of $n$ points $P$ and define $N_s[v]$ as the subset of $P$ that includes the $s$ nearest points of $v \\in P$ and the point $v$ itself. We assume that the \\emph{$s$-th neighbor} of each point is unique, for every $s \\in \\{0, 1, 2, \\dots , n-1\\}$. For a natural number $r \\leq n-1$, an $r$-multipacking is a set $ M \\subseteq P $ such that for each point $ v \\in P $ and for every integer $ 1\\leq s \\leq r $, $|N_s[v]\\cap M|\\leq (s+1)/2$. The $r$-multipacking number of $ P $ is the maximum cardinality of an $r$-multipacking of $ P $ and is denoted by $ \\MP_{r}(P) $. For $r=n-1$, an $r$-multipacking is called a multipacking and $r$-multipacking number is called as multipacking number. For $r=1 \\text{ and } 2$, we study the problem of computing a maximum $r$-multipacking of the point sets in $\\mathbb{R}^2$. We show that a maximum $1$-multipacking can be computed in polynomial time but computing a maximum $2$-multipacking is \\textsc{NP-hard}. Further, we provide approximation and parameterized solutions to the $2$-multipacking problem.",
      "authors": [
        "Arun Kumar Das",
        "Sandip Das",
        "Sk Samim Islam",
        "Ritam M Mitra",
        "Bodhayan Roy"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computational Geometry (cs.CG)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-19T09:07:50+00:00",
          "link": "https://arxiv.org/abs/2411.12351v1",
          "size": "475kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T06:50:13+00:00",
          "link": "https://arxiv.org/abs/2411.12351v2",
          "size": "272kb",
          "version": "v2"
        }
      ],
      "title": "Multipacking in Euclidean Metric Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.12351",
        "HTML": "https://arxiv.org/html/2411.12351v2",
        "PDF": "https://arxiv.org/pdf/2411.12351"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study is focused on multipacking problems in Euclidean metric space, which is irrelevant to LLM training data processing or any related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10672",
      "abstract": "Vision Language Action (VLA) models represent a transformative shift in robotics, with the aim of unifying visual perception, natural language understanding, and embodied control within a single learning framework. This review presents a comprehensive and forward-looking synthesis of the VLA paradigm, with a particular emphasis on robotic manipulation and instruction-driven autonomy. We comprehensively analyze 102 VLA models, 26 foundational datasets, and 12 simulation platforms that collectively shape the development and evaluation of VLAs models. These models are categorized into key architectural paradigms, each reflecting distinct strategies for integrating vision, language, and control in robotic systems. Foundational datasets are evaluated using a novel criterion based on task complexity, variety of modalities, and dataset scale, allowing a comparative analysis of their suitability for generalist policy learning. We introduce a two-dimensional characterization framework that organizes these datasets based on semantic richness and multimodal alignment, showing underexplored regions in the current data landscape. Simulation environments are evaluated for their effectiveness in generating large-scale data, as well as their ability to facilitate transfer from simulation to real-world settings and the variety of supported tasks. Using both academic and industrial contributions, we recognize ongoing challenges and outline strategic directions such as scalable pretraining protocols, modular architectural design, and robust multimodal alignment strategies. This review serves as both a technical reference and a conceptual roadmap for advancing embodiment and robotic control, providing insights that span from dataset generation to real world deployment of generalist robotic agents.",
      "authors": [
        "Muhayy Ud Din and Waseem Akram and Lyes Saad Saoud",
        "Jan Rosell and Irfan Hussain"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:00:34+00:00",
          "link": "https://arxiv.org/abs/2507.10672v1",
          "size": "11444kb",
          "version": "v1"
        }
      ],
      "title": "Vision Language Action Models in Robotic Manipulation: A Systematic Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10672",
        "HTML": "https://arxiv.org/html/2507.10672v1",
        "PDF": "https://arxiv.org/pdf/2507.10672"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a review of Vision Language Action models in robotics, highlighting datasets and models but does not discuss any aspect of processing or engineering LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11463",
      "abstract": "We study when a Riemann difference of order $ n $ possesses the Marcinkiewicz-Zygmund (MZ) property: that is, whether the conditions $ f(h) = o(h^{n-1}) $ and $ Df(h) = o(h^n) $ imply $ f(h) = o(h^n) $. This implication is known to hold for some classical examples with geometric nodes, such as $ \\{0, 1, q, \\dots, q^{n-1}\\} $ and $ \\{1, q, \\dots, q^n\\} $, leading to a conjecture that these are the only such Riemann differences with the MZ property. However, this conjecture was disproved by the third-order example with nodes $ \\{-1, 0, 1, 2\\} $, and we provide further counterexamples and a general classification here.\n  We establish a complete analytic criterion for the MZ property by developing a recurrence framework: we analyze when a function $ R(h) $ satisfying $ D(h) = R(qh) - A R(h) $, together with $ D(h) = o(h^n) $ and $ R(h) = o(h^{n-1}) $, forces $ R(h) = o(h^n) $. We prove that this holds if and only if $ A $ lies outside a critical modulus annulus determined by $ q $ and $ n $, covering both $ |q| > 1 $ and $ |q| < 1 $ cases. This leads to a complete characterization of all Riemann differences with geometric nodes that possess the MZ property, and provides a flexible analytic framework applicable to broader classes of generalized differences.",
      "authors": [
        "Hajrudin Fejzi\\'c"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Classical Analysis and ODEs (math.CA)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:34:35+00:00",
          "link": "https://arxiv.org/abs/2507.11463v1",
          "size": "16kb",
          "version": "v1"
        }
      ],
      "title": "The Marcinkiewicz-Zygmund Property for Riemann Differences with Geometric Nodes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11463",
        "HTML": "https://arxiv.org/html/2507.11463v1",
        "PDF": "https://arxiv.org/pdf/2507.11463"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses mathematical properties of Riemann differences and does not involve any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11499",
      "abstract": "Next-Generation Radio Access Networks (NGRAN) aim to support diverse vertical applications with strict security, latency, and Service-Level Agreement (SLA) requirements. These demands introduce challenges in securing the infrastructure, allocating resources dynamically, and enabling real-time reconfiguration. This demo presents SnSRIC, a secure and intelligent network slicing framework that mitigates a range of Distributed Denial-of-Service (DDoS) attacks in Open RAN environments. SnSRIC incorporates an AI-driven xApp that dynamically allocates Physical Resource Blocks (PRBs) to active users while enforcing slice-level security. The system detects anomalous behavior, distinguishes between benign and malicious devices, and uses the E2 interface to throttle rogue signaling while maintaining service continuity for legitimate users.",
      "authors": [
        "Adhwaa Alchaab",
        "Ayman Younis",
        "Dario Pompili"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T03:55:04+00:00",
          "link": "https://arxiv.org/abs/2507.11499v1",
          "size": "331kb",
          "version": "v1"
        }
      ],
      "title": "Demo: Secure Edge Server for Network Slicing and Resource Allocation in Open RAN",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11499",
        "HTML": "https://arxiv.org/html/2507.11499v1",
        "PDF": "https://arxiv.org/pdf/2507.11499"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on secure resource allocation in radio access networks (NGRAN) and does not mention LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.23145",
      "abstract": "Recent inversion-free, flow-based image editing methods such as FlowEdit leverages a pre-trained noise-to-image flow model such as Stable Diffusion 3, enabling text-driven manipulation by solving an ordinary differential equation (ODE). While the lack of exact latent inversion is a core advantage of these methods, it often results in unstable editing trajectories and poor source consistency. To address this limitation, we propose {\\em FlowAlign}, a novel inversion-free flow-based framework for consistent image editing with optimal control-based trajectory control. Specifically, FlowAlign introduces source similarity at the terminal point as a regularization term to promote smoother and more consistent trajectories during the editing process. Notably, our terminal point regularization is shown to explicitly balance semantic alignment with the edit prompt and structural consistency with the source image along the trajectory. Furthermore, FlowAlign naturally supports reverse editing by simply reversing the ODE trajectory, highliting the reversible and consistent nature of the transformation. Extensive experiments demonstrate that FlowAlign outperforms existing methods in both source preservation and editing controllability.",
      "authors": [
        "Jeongsol Kim",
        "Yeobin Hong",
        "Jonghyun Park",
        "Jong Chul Ye"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T06:33:16+00:00",
          "link": "https://arxiv.org/abs/2505.23145v1",
          "size": "21574kb",
          "version": "v1"
        },
        {
          "date": "2025-06-17T12:51:50+00:00",
          "link": "https://arxiv.org/abs/2505.23145v2",
          "size": "21575kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T20:27:44+00:00",
          "link": "https://arxiv.org/abs/2505.23145v3",
          "size": "21573kb",
          "version": "v3"
        }
      ],
      "title": "FlowAlign: Trajectory-Regularized, Inversion-Free Flow-based Image Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23145",
        "HTML": "https://arxiv.org/html/2505.23145v3",
        "PDF": "https://arxiv.org/pdf/2505.23145"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on image editing using inversion-free flow-based methods and does not discuss LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/flowalign/flowalign"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10581",
      "abstract": "Deep learning employs multi-layer neural networks trained via the backpropagation algorithm. This approach has achieved success across many domains and relies on adaptive gradient methods such as the Adam optimizer. Sequence modeling evolved from recurrent neural networks to attention-based models, culminating in the Transformer architecture. Transformers have achieved state-of-the-art performance in natural language processing (for example, BERT and GPT-3) and have been applied in computer vision and computational biology. However, theoretical understanding of these models remains limited. In this paper, we examine the mathematical foundations of deep learning and Transformers and present a novel theoretical result. We review key concepts from linear algebra, probability, and optimization that underpin deep learning, and we analyze the multi-head self-attention mechanism and the backpropagation algorithm in detail. Our main contribution is a universal approximation theorem for Transformers: we prove that a single-layer Transformer, comprising one self-attention layer followed by a position-wise feed-forward network with ReLU activation, can approximate any continuous sequence-to-sequence mapping on a compact domain to arbitrary precision. We provide a formal statement and a complete proof. Finally, we present case studies that demonstrate the practical implications of this result. Our findings advance the theoretical understanding of Transformer models and help bridge the gap between theory and practice.",
      "authors": [
        "Esmail Gumaan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T11:37:39+00:00",
          "link": "https://arxiv.org/abs/2507.10581v1",
          "size": "1801kb",
          "version": "v1"
        }
      ],
      "title": "Universal Approximation Theorem for a Single-Layer Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10581",
        "HTML": "https://arxiv.org/html/2507.10581v1",
        "PDF": "https://arxiv.org/pdf/2507.10581"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper provides a theoretical result related to Transformers, but it does not involve any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10595",
      "abstract": "Deep graph clustering (DGC) for attribute-missing graphs is an unsupervised task aimed at partitioning nodes with incomplete attributes into distinct clusters. Addressing this challenging issue is vital for practical applications. However, research in this area remains underexplored. Existing imputation methods for attribute-missing graphs often fail to account for the varying amounts of information available across node neighborhoods, leading to unreliable results, especially for nodes with insufficient known neighborhood. To address this issue, we propose a novel method named Divide-Then-Rule Graph Completion (DTRGC). This method first addresses nodes with sufficient known neighborhood information and treats the imputed results as new knowledge to iteratively impute more challenging nodes, while leveraging clustering information to correct imputation errors. Specifically, Dynamic Cluster-Aware Feature Propagation (DCFP) initializes missing node attributes by adjusting propagation weights based on the clustering structure. Subsequently, Hierarchical Neighborhood-aware Imputation (HNAI) categorizes attribute-missing nodes into three groups based on the completeness of their neighborhood attributes. The imputation is performed hierarchically, prioritizing the groups with nodes that have the most available neighborhood information. The cluster structure is then used to refine the imputation and correct potential errors. Finally, Hop-wise Representation Enhancement (HRE) integrates information across multiple hops, thereby enriching the expressiveness of node representations. Experimental results on six widely used graph datasets show that DTRGC significantly improves the clustering performance of various DGC methods under attribute-missing graphs.",
      "authors": [
        "Yaowen Hu",
        "Wenxuan Tu",
        "Yue Liu",
        "Miaomiao Li",
        "Wenpeng Lu",
        "Zhigang Luo",
        "Xinwang Liu",
        "Ping Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T03:33:19+00:00",
          "link": "https://arxiv.org/abs/2507.10595v1",
          "size": "9263kb",
          "version": "v1"
        }
      ],
      "title": "Divide-Then-Rule: A Cluster-Driven Hierarchical Interpolator for Attribute-Missing Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10595",
        "HTML": "https://arxiv.org/html/2507.10595v1",
        "PDF": "https://arxiv.org/pdf/2507.10595"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on deep graph clustering for attribute-missing graphs and proposes a novel method for imputation based on clustering, which does not directly concern LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10701",
      "abstract": "In this article, we develop a kernel-based framework for constructing dynamic, pathdependent trading strategies under a mean-variance optimisation criterion. Building on the theoretical results of (Muca Cirone and Salvi, 2025), we parameterise trading strategies as functions in a reproducing kernel Hilbert space (RKHS), enabling a flexible and non-Markovian approach to optimal portfolio problems. We compare this with the signature-based framework of (Futter, Horvath, Wiese, 2023) and demonstrate that both significantly outperform classical Markovian methods when the asset dynamics or predictive signals exhibit temporal dependencies for both synthetic and market-data examples. Using kernels in this context provides significant modelling flexibility, as the choice of feature embedding can range from randomised signatures to the final layers of neural network architectures. Crucially, our framework retains closed-form solutions and provides an alternative to gradient-based optimisation.",
      "authors": [
        "Owen Futter",
        "Nicola Muca Cirone",
        "Blanka Horvath"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Trading and Market Microstructure (q-fin.TR)",
        "Machine Learning (cs.LG)",
        "Mathematical Finance (q-fin.MF)",
        "Portfolio Management (q-fin.PM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:17:50+00:00",
          "link": "https://arxiv.org/abs/2507.10701v1",
          "size": "2431kb",
          "version": "v1"
        }
      ],
      "title": "Kernel Learning for Mean-Variance Trading Strategies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10701",
        "HTML": "https://arxiv.org/html/2507.10701v1",
        "PDF": "https://arxiv.org/pdf/2507.10701"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on kernel-based frameworks for trading strategies, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11141",
      "abstract": "We study quantifiers and interpolation properties in \\emph{orthologic}, a non-distributive weakening of classical logic that is sound for formula validity with respect to classical logic, yet has a quadratic-time decision procedure. We present a sequent-based proof system for quantified orthologic, which we prove sound and complete for the class of all complete ortholattices. We show that orthologic does not admit quantifier elimination in general. Despite that, we show that interpolants always exist in orthologic. We give an algorithm to compute interpolants efficiently. We expect our result to be useful to quickly establish unreachability as a component of verification algorithms.",
      "authors": [
        "Simon Guilloud",
        "Sankalp Gambhir",
        "Viktor Kun\\v{c}ak"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:47:20+00:00",
          "link": "https://arxiv.org/abs/2507.11141v1",
          "size": "231kb",
          "version": "v1"
        }
      ],
      "title": "Interpolation and Quantifiers in Ortholattices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11141",
        "HTML": "https://arxiv.org/html/2507.11141v1",
        "PDF": "https://arxiv.org/pdf/2507.11141"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores logic and computational theories unrelated to LLM training data handling or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11173",
      "abstract": "Autonomous unmanned aerial vehicles (UAVs) rely on global navigation satellite system (GNSS) pseudorange measurements for accurate real-time localization and navigation. However, this dependence exposes them to sophisticated spoofing threats, where adversaries manipulate pseudoranges to deceive UAV receivers. Among these, drift-evasive spoofing attacks subtly perturb measurements, gradually diverting the UAVs trajectory without triggering conventional signal-level anti-spoofing mechanisms. Traditional distributional shift detection techniques often require accumulating a threshold number of samples, causing delays that impede rapid detection and timely response. Consequently, robust temporal-scale detection methods are essential to identify attack onset and enable contingency planning with alternative sensing modalities, improving resilience against stealthy adversarial manipulations. This study explores a Bayesian online change point detection (BOCPD) approach that monitors temporal shifts in value estimates from a reinforcement learning (RL) critic network to detect subtle behavioural deviations in UAV navigation. Experimental results show that this temporal value-based framework outperforms conventional GNSS spoofing detectors, temporal semi-supervised learning frameworks, and the Page-Hinkley test, achieving higher detection accuracy and lower false-positive and false-negative rates for drift-evasive spoofing attacks.",
      "authors": [
        "Deepak Kumar Panda",
        "Weisi Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:27:27+00:00",
          "link": "https://arxiv.org/abs/2507.11173v1",
          "size": "650kb",
          "version": "v1"
        }
      ],
      "title": "Real-Time Bayesian Detection of Drift-Evasive GNSS Spoofing in Reinforcement Learning Based UAV Deconfliction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11173",
        "HTML": "https://arxiv.org/html/2507.11173v1",
        "PDF": "https://arxiv.org/pdf/2507.11173"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores Bayesian detection of spoofing in UAVs, utilizing RL networks. It does not address any LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11506",
      "abstract": "To meet the increasing demand of deep learning (DL) models, AI chips are employing both off-chip memory (e.g., HBM) and high-bandwidth low-latency interconnect for direct inter-core data exchange. However, it is not easy to explore the efficiency of these inter-core connected AI (ICCA) chips, due to a fundamental tussle among compute (per-core execution), communication (inter-core data exchange), and I/O (off-chip data access).\n  In this paper, we develop Elk, a DL compiler framework to maximize the efficiency of ICCA chips by jointly trading off all the three performance factors discussed above. Elk structures these performance factors into configurable parameters and forms a global trade-off space in the DL compiler. To systematically explore this space and maximize overall efficiency, Elk employs a new inductive operator scheduling policy and a cost-aware on-chip memory allocation algorithm. It generates globally optimized execution plans that best overlap off-chip data loading and on-chip execution. To examine the efficiency of Elk, we build a full-fledged emulator based on a real ICCA chip IPU-POD4, and an ICCA chip simulator for sensitivity analysis with different interconnect network topologies. Elk achieves 94% of the ideal roofline performance of ICCA chips on average, showing the benefits of supporting large DL models on ICCA chips. We also show Elk's capability of enabling architecture design space exploration for new ICCA chip development.",
      "authors": [
        "Yiqi Liu",
        "Yuqi Xue",
        "Noelle Crawford",
        "Jilong Xue",
        "Jian Huang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:21:31+00:00",
          "link": "https://arxiv.org/abs/2507.11506v1",
          "size": "1289kb",
          "version": "v1"
        }
      ],
      "title": "Elk: Exploring the Efficiency of Inter-core Connected AI Chips with Deep Learning Compiler Techniques",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11506",
        "HTML": "https://arxiv.org/html/2507.11506v1",
        "PDF": "https://arxiv.org/pdf/2507.11506"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on optimizing AI chips for deep learning tasks, with no mention of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10609",
      "abstract": "The United Arab Emirates (UAE) relies heavily on seawater desalination to meet over 90% of its drinking water needs. Desalination processes are highly energy intensive and account for approximately 15% of the UAE's electricity consumption, contributing to over 22% of the country's energy-related CO2 emissions. Moreover, these processes face significant sustainability challenges in the face of climate uncertainties such as rising seawater temperatures, salinity, and aerosol optical depth (AOD). AOD greatly affects the operational and economic performance of solar-powered desalination systems through photovoltaic soiling, membrane fouling, and water turbidity cycles.\n  This study proposes a novel pipelined two-stage predictive modelling architecture: the first stage forecasts AOD using satellite-derived time series and meteorological data; the second stage uses the predicted AOD and other meteorological factors to predict desalination performance efficiency losses. The framework achieved 98% accuracy, and SHAP (SHapley Additive exPlanations) was used to reveal key drivers of system degradation. Furthermore, this study proposes a dust-aware rule-based control logic for desalination systems based on predicted values of AOD and solar efficiency. This control logic is used to adjust the desalination plant feed water pressure, adapt maintenance scheduling, and regulate energy source switching.\n  To enhance the practical utility of the research findings, the predictive models and rule-based controls were packaged into an interactive dashboard for scenario and predictive analytics. This provides a management decision-support system for climate-adaptive planning.",
      "authors": [
        "Obumneme Nwafor",
        "Chioma Nwafor",
        "Amro Zakaria",
        "Nkechi Nwankwo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T08:07:43+00:00",
          "link": "https://arxiv.org/abs/2507.10609v1",
          "size": "1926kb",
          "version": "v1"
        }
      ],
      "title": "A Feed-Forward Artificial Intelligence Pipeline for Sustainable Desalination under Climate Uncertainties: UAE Insights",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10609",
        "PDF": "https://arxiv.org/pdf/2507.10609"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a predictive modeling architecture for desalination performance under climate conditions and does not discuss any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10923",
      "abstract": "Protein language models have emerged as powerful tools for sequence generation, offering substantial advantages in functional optimization and denovo design. However, these models also present significant risks of generating harmful protein sequences, such as those that enhance viral transmissibility or evade immune responses. These concerns underscore critical biosafety and ethical challenges. To address these issues, we propose a Knowledge-guided Preference Optimization (KPO) framework that integrates prior knowledge via a Protein Safety Knowledge Graph. This framework utilizes an efficient graph pruning strategy to identify preferred sequences and employs reinforcement learning to minimize the risk of generating harmful proteins. Experimental results demonstrate that KPO effectively reduces the likelihood of producing hazardous sequences while maintaining high functionality, offering a robust safety assurance framework for applying generative models in biotechnology.",
      "authors": [
        "Yuhao Wang",
        "Keyan Ding",
        "Kehua Feng",
        "Zeyuan Wang",
        "Ming Qin",
        "Xiaotong Li",
        "Qiang Zhang",
        "Huajun Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T02:30:33+00:00",
          "link": "https://arxiv.org/abs/2507.10923v1",
          "size": "1409kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10923",
        "HTML": "https://arxiv.org/html/2507.10923v1",
        "PDF": "https://arxiv.org/pdf/2507.10923"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses protein sequence generation and safety issues, which does not relate to LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10978",
      "abstract": "Gait is becoming popular as a method of person re-identification because of its ability to identify people at a distance. However, most current works in gait recognition do not address the practical problem of occlusions. Among those which do, some require paired tuples of occluded and holistic sequences, which are impractical to collect in the real world. Further, these approaches work on occlusions but fail to retain performance on holistic inputs. To address these challenges, we propose RG-Gait, a method for residual correction for occluded gait recognition with holistic retention. We model the problem as a residual learning task, conceptualizing the occluded gait signature as a residual deviation from the holistic gait representation. Our proposed network adaptively integrates the learned residual, significantly improving performance on occluded gait sequences without compromising the holistic recognition accuracy. We evaluate our approach on the challenging Gait3D, GREW and BRIAR datasets and show that learning the residual can be an effective technique to tackle occluded gait recognition with holistic retention.",
      "authors": [
        "Ayush Gupta",
        "Siyuan Huang",
        "Rama Chellappa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T04:45:14+00:00",
          "link": "https://arxiv.org/abs/2507.10978v1",
          "size": "1084kb",
          "version": "v1"
        }
      ],
      "title": "Mind the Gap: Bridging Occlusion in Gait Recognition via Residual Gap Correction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10978",
        "HTML": "https://arxiv.org/html/2507.10978v1",
        "PDF": "https://arxiv.org/pdf/2507.10978"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work addresses occlusion in gait recognition and does not involve processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11538",
      "abstract": "Production-grade LLM systems require robust adherence to dozens or even hundreds of instructions simultaneously. However, the instruction-following capabilities of LLMs at high instruction densities have not yet been characterized, as existing benchmarks only evaluate models on tasks with a single or few instructions. We introduce IFScale, a simple benchmark of 500 keyword-inclusion instructions for a business report writing task to measure how instruction-following performance degrades as instruction density increases. We evaluate 20 state-of-the-art models across seven major providers and find that even the best frontier models only achieve 68% accuracy at the max density of 500 instructions. Our analysis reveals model size and reasoning capability to correlate with 3 distinct performance degradation patterns, bias towards earlier instructions, and distinct categories of instruction-following errors. Our insights can help inform design of instruction-dense prompts in real-world applications and highlight important performance-latency tradeoffs. We open-source the benchmark and all results for further analysis at https://distylai.github.io/IFScale.",
      "authors": [
        "Daniel Jaroslawicz",
        "Brendan Whiting",
        "Parth Shah",
        "Karime Maamari"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:59:42+00:00",
          "link": "https://arxiv.org/abs/2507.11538v1",
          "size": "6761kb",
          "version": "v1"
        }
      ],
      "title": "How Many Instructions Can LLMs Follow at Once?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11538",
        "HTML": "https://arxiv.org/html/2507.11538v1",
        "PDF": "https://arxiv.org/pdf/2507.11538"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark for evaluating instruction-following capabilities of LLMs but does not focus on training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09850",
      "abstract": "Reasoning-capable language models achieve state-of-the-art performance in diverse complex tasks by generating long, explicit Chain-of-Thought (CoT) traces. While recent works show that base models can acquire such reasoning traces via reinforcement learning or distillation from stronger models like DeepSeek-R1, previous works demonstrate that even short CoT prompting without fine-tuning is able to improve reasoning. We ask whether long CoT can be induced in a base model using only prompting or minimal tuning. Using just 20 long CoT examples from the reasoning model \\texttt{QwQ-32B-Preview}, we lightly fine-tune the base model \\texttt{Qwen2.5-32B}. The resulting model outperforms the much larger \\texttt{Qwen2.5-Math-72B-Instruct}, showing that a handful of high-quality examples can unlock strong reasoning capabilities. We further explore using CoT data from non-reasoning models and human annotators, enhanced with prompt engineering, multi-pass editing, and structural guidance. However, neither matches the performance of reasoning model traces, suggesting that certain latent qualities of expert CoT are difficult to replicate. We analyze key properties of reasoning data, such as problem difficulty, diversity, and answer length, that influence reasoning distillation. While challenges remain, we are optimistic that carefully curated human-written CoT, even in small quantities, can activate reasoning behaviors in base models. We release our human-authored dataset across refinement stages and invite further investigation into what makes small-scale reasoning supervision so effective.",
      "authors": [
        "Wei Du",
        "Branislav Kisacanin",
        "George Armstrong",
        "Shubham Toshniwal",
        "Ivan Moshkov",
        "Alexan Ayrapetyan",
        "Sadegh Mahdavi",
        "Dan Zhao",
        "Shizhe Diao",
        "Dragan Masulovic",
        "Marius Stanean",
        "Advaith Avadhanam",
        "Max Wang",
        "Ashmit Dutta",
        "Shitij Govil",
        "Sri Yanamandara",
        "Mihir Tandon",
        "Sriram Ananthakrishnan",
        "Vedant Rathi",
        "David Zhang",
        "Joonseok Kang",
        "Leon Luo",
        "Titu Andreescu",
        "Boris Ginsburg",
        "and Igor Gitman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T01:14:50+00:00",
          "link": "https://arxiv.org/abs/2507.09850v1",
          "size": "120kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T16:14:53+00:00",
          "link": "https://arxiv.org/abs/2507.09850v2",
          "size": "120kb",
          "version": "v2"
        }
      ],
      "title": "Is Human-Written Data Enough? The Challenge of Teaching Reasoning to LLMs Without RL or Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09850",
        "PDF": "https://arxiv.org/pdf/2507.09850"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the effectiveness of human-written data for reasoning in LLMs and explores data characteristics, but it focuses more on the reasoning capability rather than substantial data processing methodologies."
      },
      "datasets": [
        {
          "dataset_name": "nvidia/Nemotron-Math-HumanReasoning",
          "downloads": "5",
          "likes": "2",
          "link": "https://huggingface.co/datasets/nvidia/Nemotron-Math-HumanReasoning"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10893",
      "abstract": "Recently, AI-based weather forecast models have achieved impressive advances. These models have reached accuracy levels comparable to traditional NWP systems, marking a significant milestone in data-driven weather prediction. However, they mostly leverage Transformer-based architectures, which often leads to high training complexity and resource demands due to the massive parameter sizes. In this study, we introduce a modernized CNN-based model for global weather forecasting that delivers competitive accuracy while significantly reducing computational requirements. To present a systematic modernization roadmap, we highlight key architectural enhancements across multiple design scales from an earlier CNN-based approach. KAI-a incorporates a scale-invariant architecture and InceptionNeXt-based blocks within a geophysically-aware design, tailored to the structure of Earth system data. Trained on the ERA5 daily dataset with 67 atmospheric variables, the model contains about 7 million parameters and completes training in just 12 hours on a single NVIDIA L40s GPU. Our evaluation shows that KAI-a matches the performance of state-of-the-art models in medium-range weather forecasting, while offering a significantly lightweight design. Furthermore, case studies on the 2018 European heatwave and the East Asian summer monsoon demonstrate KAI-a's robust skill in capturing extreme events, reinforcing its practical utility.",
      "authors": [
        "Minjong Cheon",
        "Eunhan Goo",
        "Su-Hyeon Shin",
        "Muhammad Ahmed",
        "Hyungjun Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T01:16:32+00:00",
          "link": "https://arxiv.org/abs/2507.10893v1",
          "size": "31655kb",
          "version": "v1"
        }
      ],
      "title": "Modernizing CNN-based Weather Forecast Model towards Higher Computational Efficiency",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10893",
        "HTML": "https://arxiv.org/html/2507.10893v1",
        "PDF": "https://arxiv.org/pdf/2507.10893"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a CNN-based weather forecast model, focusing on architectural efficiency and not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11222",
      "abstract": "Finite-State Machines (FSMs) are critical for modeling the operational logic of network protocols, enabling verification, analysis, and vulnerability discovery. However, existing FSM extraction techniques face limitations such as scalability, incomplete coverage, and ambiguity in natural language specifications. In this paper, we propose FlowFSM, a novel agentic framework that leverages Large Language Models (LLMs) combined with prompt chaining and chain-of-thought reasoning to extract accurate FSMs from raw RFC documents. FlowFSM systematically processes protocol specifications, identifies state transitions, and constructs structured rule-books by chaining agent outputs. Experimental evaluation across FTP and RTSP protocols demonstrates that FlowFSM achieves high extraction precision while minimizing hallucinated transitions, showing promising results. Our findings highlight the potential of agent-based LLM systems in the advancement of protocol analysis and FSM inference for cybersecurity and reverse engineering applications.",
      "authors": [
        "Fares Wael",
        "Youssef Maklad",
        "Ali Hamdi",
        "Wael Elsersy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T11:50:25+00:00",
          "link": "https://arxiv.org/abs/2507.11222v1",
          "size": "488kb",
          "version": "v1"
        }
      ],
      "title": "An Agentic Flow for Finite State Machine Extraction using Prompt Chaining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11222",
        "HTML": "https://arxiv.org/html/2507.11222v1",
        "PDF": "https://arxiv.org/pdf/2507.11222"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions using LLMs in prompt chaining for FSM extraction but does not primarily focus on processing LLM training data, instead on protocol analysis involving FSM inference."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11350",
      "abstract": "Distributionally Robust Optimization (DRO) is a worst-case approach to decision making when there is model uncertainty. Though formulated as a single-objective problem, we show that it is intrinsically multi-objective in that DRO solutions map out a near-Pareto-optimal frontier between expected cost and a measure of robustness called worst-case sensitivity (WCS). We take this as the starting point and explore robust decision making through a multi-objective lens. We show that WCS is a measure of spread and derive WCS for a collection of uncertainty sets commonly used in DRO. These sensitivity measures identify the errors against which the nominal expected cost is most vulnerable and the uncertainty set for the worst-case problem that most effectively mitigates it. The associated mean-sensitivity frontier is used to select its size. The multi-objective perspective provides a quantitative measure of robustness and a sensitivity-based approach to addressing important conceptual gaps in DRO -- how to choose the family and size of uncertainty sets for a given cost distribution, and how this affects the solution.",
      "authors": [
        "Jun-ya Gotoh",
        "Michael Jong Kim",
        "Andrew E.B. Lim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:23:06+00:00",
          "link": "https://arxiv.org/abs/2507.11350v1",
          "size": "1947kb",
          "version": "v1"
        }
      ],
      "title": "Distributionally Robust Optimization is a Multi-Objective Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11350",
        "HTML": "https://arxiv.org/html/2507.11350v1",
        "PDF": "https://arxiv.org/pdf/2507.11350"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses distributionally robust optimization as a multi-objective problem, which is unrelated to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11477",
      "abstract": "Online conversations are often interrupted by trolling, which causes emotional distress and conflict among users. Previous research has focused on moderating harmful content after it has been posted, but ways to manage emotions in real-time remain unexplored. This study suggests a comment queuing mechanism that delays comment publishing, encourages self-reflection, and reduces the impact of impulsive and toxic comments. To assess the efficacy of this approach, a mixed-method research design is used. An analysis of 15,000 user interactions on Reddit showed that this approach could reduce the spread of hate speech and anger by up to 15%, with only 4% of comments being delayed for about 47 seconds on average. We also surveyed users for feedback on the mechanism. The results showed that 93. 3\\% of the participants thought that the queuing mechanism could help calm the discussions and showed interest in seeing it used on social media platforms. Furthermore, 83% believed it would reduce impulsive comments and balance the emotional tone in conversations. We found a strong link between users' typical emotional states while using social media and their perceptions of the delay, with calm users finding the mechanism helpful and frustrated users anticipating frustration.",
      "authors": [
        "Akriti Verma",
        "Shama Islam",
        "Valeh Moghaddam and Adnan Anwar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-05T07:42:19+00:00",
          "link": "https://arxiv.org/abs/2507.11477v1",
          "size": "997kb",
          "version": "v1"
        }
      ],
      "title": "Queueing for Civility: User Perspectives on Regulating Emotions in Online Conversations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11477",
        "PDF": "https://arxiv.org/pdf/2507.11477"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores a queuing mechanism to moderate online conversations by delaying comments to mitigate impulsive behavior, with no mention of LLM training data processing or data engineering operations for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2205.06132",
      "abstract": "This paper studies markets where a set of indivisible items is sold to bidders with quasilinear, unit-demand valuations, subject to a hard budget constraint. Without financial constraints the well-known assignment market model of Shapley and Shubik (1971) allows for a simple ascending auction format that is incentive-compatible, and strongly Pareto-optimal. However, this auction model does not capture the possibility that bidders face hard budget constraints. We design an iterative auction that depends on demand queries and an easily verifiable additional condition to maintain the properties in the presence of budget constraints. If instead this additional condition does not hold, incentive compatibility and core stability are at odds, and we cannot hope to achieve strong Pareto optimality in a simple ascending auction even with truthful bidding. Moreover, even in a complete information model where the auctioneer has access to valuations and budget constraints, the problem is NP-hard.",
      "authors": [
        "Eleni Batziou",
        "Martin Bichler",
        "Maximilian Fichtl"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Theoretical Economics (econ.TH)"
      ],
      "submission_historys": [
        {
          "date": "2022-05-12T14:50:19+00:00",
          "link": "https://arxiv.org/abs/2205.06132v1",
          "size": "176kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T19:21:28+00:00",
          "link": "https://arxiv.org/abs/2205.06132v2",
          "size": "222kb",
          "version": "v2"
        }
      ],
      "title": "Assignment Markets with Budget Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2205.06132",
        "HTML": "https://arxiv.org/html/2205.06132v2",
        "PDF": "https://arxiv.org/pdf/2205.06132"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study concerns assignment markets and auction mechanisms, with no relevance to the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.04966",
      "abstract": "Automatic test generation plays a critical role in software quality assurance. While the recent advances in Search-Based Software Testing (SBST) and Large Language Models (LLMs) have shown promise in generating useful tests, these techniques still struggle to cover certain branches. Reaching these hard-to-cover branches usually requires constructing complex objects and resolving intricate inter-procedural dependencies in branch conditions, which poses significant challenges for existing test generation techniques. In this work, we propose TELPA, a novel technique aimed at addressing these challenges. Its key insight lies in extracting real usage scenarios of the target method under test to learn how to construct complex objects and extracting methods entailing inter-procedural dependencies with hard-to-cover branches to learn the semantics of branch constraints. To enhance efficiency and effectiveness, TELPA identifies a set of ineffective tests as counter-examples for LLMs and employs a feedback-based process to iteratively refine these counter-examples. Then, TELPA integrates program analysis results and counter-examples into the prompt, guiding LLMs to gain deeper understandings of the semantics of the target method and generate diverse tests that can reach the hard-to-cover branches. Our experimental results on 27 open-source Python projects demonstrate that TELPA significantly outperforms the state-of-the-art SBST and LLM-based techniques, achieving an average improvement of 31.39% and 22.22% in terms of branch coverage.",
      "authors": [
        "Chen Yang",
        "Junjie Chen",
        "Bin Lin",
        "Ziqi Wang",
        "Jianyi Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-07T14:08:28+00:00",
          "link": "https://arxiv.org/abs/2404.04966v1",
          "size": "3345kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T03:52:37+00:00",
          "link": "https://arxiv.org/abs/2404.04966v2",
          "size": "471kb",
          "version": "v2"
        }
      ],
      "title": "Advancing Code Coverage: Incorporating Program Analysis with Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.04966",
        "HTML": "https://arxiv.org/html/2404.04966v2",
        "PDF": "https://arxiv.org/pdf/2404.04966"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents TELPA, an approach for enhancing test generation by integrating program analysis with LLMs. There is some mention of data processing for learning usage scenarios but it primarily addresses software testing improvement rather than LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/ZJU-ACES-ISE/ChatUniTest"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.12020",
      "abstract": "Marginalization -- summing a function over all assignments to a subset of its inputs -- is a fundamental computational problem with applications from probabilistic inference to formal verification. Despite its computational hardness in general, there exist many classes of functions (e.g., probabilistic models) for which marginalization remains tractable, and they can be commonly expressed by polynomial size arithmetic circuits computing multilinear polynomials. This raises the question, can all functions with polynomial time marginalization algorithms be succinctly expressed by such circuits? We give a negative answer, exhibiting simple functions with tractable marginalization yet no efficient representation by known models, assuming $\\textsf{FP}\\neq\\#\\textsf{P}$ (an assumption implied by $\\textsf{P} \\neq \\textsf{NP}$). To this end, we identify a hierarchy of complexity classes corresponding to stronger forms of marginalization, all of which are efficiently computable on the known circuit models. We conclude with a completeness result, showing that whenever there is an efficient real RAM performing virtual evidence marginalization for a function, then there are small circuits for that function's multilinear representation.",
      "authors": [
        "Oliver Broadrick",
        "Sanyam Agarwal",
        "Guy Van den Broeck",
        "Markus Bl\\\"aser"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-17T07:54:56+00:00",
          "link": "https://arxiv.org/abs/2506.12020v1",
          "size": "64kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T18:43:07+00:00",
          "link": "https://arxiv.org/abs/2506.12020v2",
          "size": "50kb",
          "version": "v2"
        }
      ],
      "title": "The Limits of Tractable Marginalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12020",
        "HTML": "https://arxiv.org/html/2506.12020v2",
        "PDF": "https://arxiv.org/pdf/2506.12020"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus here is on marginalization in computational functions, with no discussion or contribution related to the processing or creation of training data for large language models."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.10753",
      "abstract": "Effective backlog management is critical for ensuring that development teams remain aligned with evolving requirements and stakeholder expectations. However, as product backlogs consistently grow in scale and complexity, they tend to become cluttered with redundant, outdated, or poorly defined tasks, complicating prioritization and decision making processes. This study investigates whether a generative-AI (GenAI) assistant can automate backlog grooming in Agile software projects without sacrificing accuracy or transparency. Through Design Science cycles, we developed a Jira plug-in that embeds backlog issues with the vector database, detects duplicates via cosine similarity, and leverage the GPT-4o model to propose merges, deletions, or new issues. We found that AI-assisted backlog grooming achieved 100 percent precision while reducing the time-to-completion by 45 percent. The findings demonstrated the tool's potential to streamline backlog refinement processes while improving user experiences.",
      "authors": [
        "Kasper Lien Oftebro",
        "Anh Nguyen-Duc and Kai-Kristian Kemell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:22:57+00:00",
          "link": "https://arxiv.org/abs/2507.10753v1",
          "size": "796kb",
          "version": "v1"
        }
      ],
      "title": "GenAI-Enabled Backlog Grooming in Agile Software Projects: An Empirical Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10753",
        "HTML": "https://arxiv.org/html/2507.10753v1",
        "PDF": "https://arxiv.org/pdf/2507.10753"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper discusses using GenAI for backlog grooming in software projects, which involves processing tasks but not LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11079",
      "abstract": "In multiple unmanned ground vehicle confrontations, autonomously evolving multi-agent tactical decisions from situational awareness remain a significant challenge. Traditional handcraft rule-based methods become vulnerable in the complicated and transient battlefield environment, and current reinforcement learning methods mainly focus on action manipulation instead of strategic decisions due to lack of interpretability. Here, we propose a vision-language model-based commander to address the issue of intelligent perception-to-decision reasoning in autonomous confrontations. Our method integrates a vision language model for scene understanding and a lightweight large language model for strategic reasoning, achieving unified perception and decision within a shared semantic space, with strong adaptability and interpretability. Unlike rule-based search and reinforcement learning methods, the combination of the two modules establishes a full-chain process, reflecting the cognitive process of human commanders. Simulation and ablation experiments validate that the proposed approach achieves a win rate of over 80% compared with baseline models.",
      "authors": [
        "Li Wang",
        "Qizhen Wu",
        "Lei Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:22:37+00:00",
          "link": "https://arxiv.org/abs/2507.11079v1",
          "size": "940kb",
          "version": "v1"
        }
      ],
      "title": "Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11079",
        "HTML": "https://arxiv.org/html/2507.11079v1",
        "PDF": "https://arxiv.org/pdf/2507.11079"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on tactical decision-making using a vision-language model for autonomous confrontations, without mention of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11094",
      "abstract": "With the rapid growth of unstructured and semistructured data, parallelizing graph algorithms has become essential for efficiency. However, due to the inherent irregularity in computation, memory access patterns, and communication, graph algorithms are notoriously difficult to parallelize. To address this challenge, several libraries, frameworks, and domain-specific languages (DSLs) have been proposed to ease the parallel programming burden for domain experts. Existing frameworks partially or fully abstract away parallelism intricacies, provide intuitive scheduling mnemonics, and employ program analysis to identify data races and generate synchronization code. Despite these advances, most frameworks are limited in their abstractions and runtime optimizations, especially when dealing with static graphs. In contrast, many real-world graphs are inherently dynamic, with evolving structures over time through insertions, deletions, and modifications of vertices, edges, and attributes. Generating efficient and correctly synchronized code for such dynamic graph algorithms remains a significant challenge.\n  In this work, we introduce an abstraction scheme and runtime optimizations for the efficient processing of morph algorithms. Specifically, given an initial graph G and a set of updates $\\Delta$G involving edge insertions and deletions, we express the dynamic processing logic through a DSL and automatically generate parallel code targeting multicore, distributed, and many-core environments. We demonstrate the effectiveness of our approach by applying the DSL-generated code to ten large graphs with diverse characteristics and three widely used algorithms: Shortest Paths, PageRank, and Triangle Counting.",
      "authors": [
        "Nibedita Behera",
        "Ashwina Kumar",
        "Atharva Chougule",
        "Mohammed Shan P S",
        "Rushabh Nirdosh Lalwani",
        "Rupesh Nasre"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:41:49+00:00",
          "link": "https://arxiv.org/abs/2507.11094v1",
          "size": "2491kb",
          "version": "v1"
        }
      ],
      "title": "Generating Dynamic Graph Algorithms for Multiple Backends for a Graph DSL",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11094",
        "HTML": "https://arxiv.org/html/2507.11094v1",
        "PDF": "https://arxiv.org/pdf/2507.11094"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses generating parallel code for dynamic graph algorithms using a graph DSL but does not address LLM training data processing or any related data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11167",
      "abstract": "We present LISA, a proof system and proof assistant for constructing proofs in schematic first-order logic and axiomatic set theory. The logical kernel of the system is a proof checker for first-order logic with equality and schematic predicate and function symbols. It implements polynomial-time proof checking and uses the axioms of ortholattices (which implies the irrelevance of the order of conjuncts and disjuncts and additional propositional laws). The kernel supports the notion of theorems (whose proofs are not expanded), as well as definitions of predicate symbols and objects whose unique existence is proven. A domain-specific language enables construction of proofs and development of proof tactics with user-friendly tools and presentation, while remaining within the general-purpose language, Scala. We describe the LISA proof system and illustrate the flavour and the level of abstraction of proofs written in LISA. This includes a proof-generating tactic for propositional tautologies, leveraging the ortholattice properties to reduce the size of proofs. We also present early formalization of set theory in LISA, including Cantor's theorem.",
      "authors": [
        "Simon Guilloud",
        "Sankalp Gambhir",
        "Viktor Kun\\v{c}ak"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:17:42+00:00",
          "link": "https://arxiv.org/abs/2507.11167v1",
          "size": "234kb",
          "version": "v1"
        }
      ],
      "title": "LISA -- A Modern Proof System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11167",
        "HTML": "https://arxiv.org/html/2507.11167v1",
        "PDF": "https://arxiv.org/pdf/2507.11167"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a proof system for formal logic and does not pertain to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11293",
      "abstract": "In semiconductor packaging, accurately recovering 3D information is crucial for non-destructive testing (NDT) to localize circuit defects. This paper presents a novel approach called the 3D Magnetic Inverse Routine (3D MIR), which leverages Magnetic Field Images (MFI) to retrieve the parameters for the 3D current flow of a single-segment. The 3D MIR integrates a deep learning (DL)-based Convolutional Neural Network (CNN), spatial-physics-based constraints, and optimization techniques. The method operates in three stages: i) The CNN model processes the MFI data to predict ($\\ell/z_o$), where $\\ell$ is the wire length and $z_o$ is the wire's vertical depth beneath the magnetic sensors and classify segment type ($c$). ii) By leveraging spatial-physics-based constraints, the routine provides initial estimates for the position ($x_o$, $y_o$, $z_o$), length ($\\ell$), current ($I$), and current flow direction (positive or negative) of the current segment. iii) An optimizer then adjusts these five parameters ($x_o$, $y_o$, $z_o$, $\\ell$, $I$) to minimize the difference between the reconstructed MFI and the actual MFI. The results demonstrate that the 3D MIR method accurately recovers 3D information with high precision, setting a new benchmark for magnetic image reconstruction in semiconductor packaging. This method highlights the potential of combining DL and physics-driven optimization in practical applications.",
      "authors": [
        "J. Senthilnath",
        "Chen Hao",
        "F. C. Wellstood"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:20:13+00:00",
          "link": "https://arxiv.org/abs/2507.11293v1",
          "size": "2308kb",
          "version": "v1"
        }
      ],
      "title": "3D Magnetic Inverse Routine for Single-Segment Magnetic Field Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11293",
        "HTML": "https://arxiv.org/html/2507.11293v1",
        "PDF": "https://arxiv.org/pdf/2507.11293"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on 3D magnetic image reconstruction for semiconductor testing using machine learning, without relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2309.00788",
      "abstract": "We prove the sharp embedding between the spectral Barron space and the Besov space with embedding constants independent of the input dimension. Given the spectral Barron space as the target function space, we prove a dimension-free convergence result that if the neural network contains $L$ hidden layers with $N$ units per layer, then the upper and lower bounds of the $L^2$-approximation error are $\\mathcal{O}(N^{-sL})$ with $0 < sL\\le 1/2$, where $s\\ge 0$ is the smoothness index of the spectral Barron space.",
      "authors": [
        "Yulei Liao",
        "Pingbing Ming"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-02T01:43:12+00:00",
          "link": "https://arxiv.org/abs/2309.00788v1",
          "size": "29kb",
          "version": "v1"
        },
        {
          "date": "2025-04-04T13:15:35+00:00",
          "link": "https://arxiv.org/abs/2309.00788v2",
          "size": "31kb",
          "version": "v2"
        }
      ],
      "title": "Spectral Barron space for deep neural network approximation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.00788",
        "HTML": "https://arxiv.org/html/2309.00788",
        "PDF": "https://arxiv.org/pdf/2309.00788"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with neural network approximation using spectral Barron space, without any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11086",
      "abstract": "The growing prevalence of cross-border financial activities in global markets has underscored the necessity of accurately identifying and classifying foreign entities. This practice is essential within the Spanish financial system for ensuring robust risk management, regulatory adherence, and the prevention of financial misconduct. This process involves a labor-intensive entity-matching task, where entities need to be validated against available reference sources. Challenges arise from linguistic variations, special characters, outdated names, and changes in legal forms, complicating traditional matching algorithms like Jaccard, cosine, and Levenshtein distances. These methods struggle with contextual nuances and semantic relationships, leading to mismatches. To address these limitations, we explore Large Language Models (LLMs) as a flexible alternative. LLMs leverage extensive training to interpret context, handle abbreviations, and adapt to legal transitions. We evaluate traditional methods, Hugging Face-based LLMs, and interface-based LLMs (e.g., Microsoft Copilot, Alibaba's Qwen 2.5) using a dataset of 65 Portuguese company cases. Results show traditional methods achieve accuracies over 92% but suffer high false positive rates (20-40%). Interface-based LLMs outperform, achieving accuracies above 93%, F1 scores exceeding 96%, and lower false positives (40-80%).",
      "authors": [
        "Andres Azqueta-Gavald\\'on and Joaquin Ramos Cosgrove"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:28:24+00:00",
          "link": "https://arxiv.org/abs/2507.11086v1",
          "size": "115kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Traditional Algorithms: Leveraging LLMs for Accurate Cross-Border Entity Identification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11086",
        "HTML": "https://arxiv.org/html/2507.11086v1",
        "PDF": "https://arxiv.org/pdf/2507.11086"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores using LLMs for entity matching in financial systems but does not address training data processing for LLMs or related techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11207",
      "abstract": "Suppose $\\mathcal{X}$ is an $n$-correct set of nodes in the plane, that is, it admits a unisolvent interpolation with bivariate polynomials of total degree less than or equal to $n.$ Then an algebraic curve $q$ of degree $k\\le n$ can pass through at most $d(n,k)$ nodes of $\\Xset,$ where $d(n,k)={{n+2}\\choose {2}}-{{n+2-k}\\choose {2}}.$ A curve $q$ of degree $k\\le n$ is called maximal if it passes through exactly $d(n,k)$ nodes of $\\mathcal{X}.$ In particular, a maximal line is a line passing through $d(n,1)=n+1$ nodes of $\\mathcal{X}.$ Maximal curves are an important tool for the study of $n$-correct sets. We present new properties of maximal curves, as well as extensions of known properties.",
      "authors": [
        "H. Hakopian",
        "G. Vardanyan",
        "N. Vardanyan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Algebraic Geometry (math.AG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T11:26:09+00:00",
          "link": "https://arxiv.org/abs/2507.11207v1",
          "size": "288kb",
          "version": "v1"
        }
      ],
      "title": "On maximal curves of $n$-correct sets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11207",
        "HTML": "https://arxiv.org/html/2507.11207v1",
        "PDF": "https://arxiv.org/pdf/2507.11207"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on algebraic curves and interpolation with bivariate polynomials, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11446",
      "abstract": "In a graph, a vertex dominates itself and its neighbors, and a dominating set is a set of vertices that together dominate the entire graph. Given a graph and two dominating sets of equal size $k$, the {\\em Dominating Set Reconfiguration with Token sliding} (DSR-TS) problem asks whether one can, by iteratively replacing a vertex by an adjacent one, transform the first set into the second one, while ensuring that every set during the reconfiguration process is a dominating set.\n  The token jumping variant, where a vertex can be replaced by a non-adjacent one, is known to be efficiently solvable on many graph classes such as planar, bounded treewidth, and the very broad notion of nowhere-dense classes of graphs. Alternatively, some algorithms also exist for the reconfiguration of independent sets in the token sliding paradigm for graph classes with bounded degree or large girth.\n  We show that DSR-TS is W[2]-hard when parameterized $k$, the pathwidth of the instance, and the iteration of the reconfiguration sequence (a recently introduced parameter). This is a setting where both the token jumping and the independent set variants are fixed parameter tractable. Not restricting the iteration yields W[2] hardness already on graphs with treewidth 9 and pathwidth 13.\n  In the directed variant (DSR-DTS), we are only allowed to replace a vertex with an out-neighbor. We show that DSR-DTS is NP-hard on DAGs of treewidth 5 and W[2]-hard for both the case of DAGs of depth 3 parameterized by $k$, and the case of DAGs when parameterized by $k$ and the pathwidth of the instance (independent set reconfiguration is again FPT in both settings).",
      "authors": [
        "Jona Dirks",
        "Alexandre Vigny"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:09:47+00:00",
          "link": "https://arxiv.org/abs/2507.11446v1",
          "size": "174kb",
          "version": "v1"
        }
      ],
      "title": "Lower bounds for dominating set reconfiguration on sparse (directed) graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11446",
        "HTML": "https://arxiv.org/html/2507.11446v1",
        "PDF": "https://arxiv.org/pdf/2507.11446"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the complexity of a graph algorithm problem and does not relate to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.02487",
      "abstract": "We investigate the real-time voltage regulation problem in distribution systems employing online feedback optimization (OFO) with short-range communication between physical neighbours. OFO does not need an accurate grid model nor estimated consumption of non-controllable loads, affords fast calculations, and demonstrates robustness to uncertainties and disturbances, which render it particularly suitable for real-time distribution system applications. However, many OFO controllers require centralized communication, making them susceptible to single-point failures. This paper proposes a distributed OFO design based on a nested feedback optimization strategy and analyzes its convergence. The strategy preserves end-users' privacy by keeping voltage data local. Numerical study results demonstrate that the proposed design achieves effective voltage regulation and outperforms other distributed and local approaches.",
      "authors": [
        "Sen Zhan",
        "Nikolaos G. Paterakis",
        "Wouter van den Akker",
        "Anne van der Molen",
        "Johan Morren and Han Slootweg"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-03T21:29:40+00:00",
          "link": "https://arxiv.org/abs/2405.02487v1",
          "size": "420kb",
          "version": "v1"
        },
        {
          "date": "2024-08-22T13:51:42+00:00",
          "link": "https://arxiv.org/abs/2405.02487v2",
          "size": "1007kb",
          "version": "v2"
        },
        {
          "date": "2024-10-11T07:16:37+00:00",
          "link": "https://arxiv.org/abs/2405.02487v3",
          "size": "3500kb",
          "version": "v3"
        },
        {
          "date": "2025-07-13T22:09:33+00:00",
          "link": "https://arxiv.org/abs/2405.02487v4",
          "size": "3799kb",
          "version": "v4"
        }
      ],
      "title": "Distributed Online Feedback Optimization for Real-time Distribution System Voltage Regulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.02487",
        "HTML": "https://arxiv.org/html/2405.02487",
        "PDF": "https://arxiv.org/pdf/2405.02487"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on real-time voltage regulation in distribution systems using online feedback optimization. It does not discuss LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.14251",
      "abstract": "Subject-specific modeling is a powerful tool in cardiovascular research, providing insights beyond the reach of current clinical diagnostics. Limitations in available clinical data require the incorporation of uncertainty into models to improve guidance for personalized treatments. However, for clinical relevance, such modeling must be computationally efficient. In this study, we used a one-dimensional (1D) fluid dynamics model informed by experimental data from a dog model of chronic thromboembolic pulmonary hypertension (CTEPH), incorporating measurements from multiple subjects under both baseline and CTEPH conditions. Surgical intervention can alleviate CTEPH, yet patients with microvascular disease (e.g., remodeling and narrowing of small vessels) often exhibit persistent pulmonary hypertension, highlighting the importance of assessing microvascular disease severity. Thus, each lung was modeled separately to account for the heterogeneous nature of CTEPH, allowing us to explore lung-specific microvascular narrowing and resistance. We compared inferred parameters between baseline and CTEPH and examined their correlation with clinical markers of disease severity. To accelerate model calibration, we employed Gaussian process (GP) emulators, enabling the estimation of microvascular parameters and their uncertainties within a clinically feasible timeframe. Our results demonstrated that CTEPH leads to heterogeneous microvascular adaptation, reflected in distinct parameter shifts. Notably, the changes in model parameters strongly correlated with disease severity, especially in the lung previously reported to have more advanced disease. This framework provides a rapid, uncertainty-aware method for evaluating microvascular dysfunction in CTEPH and may support more targeted treatment strategies within a timeframe suitable for clinical application.",
      "authors": [
        "Amirreza Kachabi",
        "Sofia Altieri Correa",
        "Naomi C. Chesler",
        "Mitchel J. Colebank"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Applications (stat.AP)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Biological Physics (physics.bio-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-20T04:36:22+00:00",
          "link": "https://arxiv.org/abs/2502.14251v1",
          "size": "2555kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T19:43:50+00:00",
          "link": "https://arxiv.org/abs/2502.14251v2",
          "size": "9143kb",
          "version": "v2"
        }
      ],
      "title": "Bayesian Parameter Inference and Uncertainty Quantification for a Computational Pulmonary Hemodynamics Model Using Gaussian Processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.14251",
        "PDF": "https://arxiv.org/pdf/2502.14251"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work is concentrated on using Gaussian Processes for uncertainty quantification in a cardiovascular model and does not involve any LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10860",
      "abstract": "Real-time Automatic Speech Recognition (ASR) is a fundamental building block for many commercial applications of ML, including live captioning, dictation, meeting transcriptions, and medical scribes. Accuracy and latency are the most important factors when companies select a system to deploy. We present WhisperKit, an optimized on-device inference system for real-time ASR that significantly outperforms leading cloud-based systems. We benchmark against server-side systems that deploy a diverse set of models, including a frontier model (OpenAI gpt-4o-transcribe), a proprietary model (Deepgram nova-3), and an open-source model (Fireworks large-v3-turbo).Our results show that WhisperKit matches the lowest latency at 0.46s while achieving the highest accuracy 2.2% WER. The optimizations behind the WhisperKit system are described in detail in this paper.",
      "authors": [
        "Atila Orhon",
        "Arda Okan",
        "Berkin Durmus",
        "Zach Nagengast",
        "Eduardo Pacheco"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T23:20:55+00:00",
          "link": "https://arxiv.org/abs/2507.10860v1",
          "size": "2849kb",
          "version": "v1"
        }
      ],
      "title": "WhisperKit: On-device Real-time ASR with Billion-Scale Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10860",
        "HTML": "https://arxiv.org/html/2507.10860v1",
        "PDF": "https://arxiv.org/pdf/2507.10860"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing an on-device inference system for Automatic Speech Recognition (ASR) and benchmarks it against server-side systems, without discussing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10639",
      "abstract": "State-of-the-art large language models (LLMs) show high performance across a wide range of tasks in many domains of science. In the field of electronic design automation (EDA), it is yet to be determined to what extent they are capable to understand, adapt, and dimension electronic circuits. This paper focuses on the application of LLMs to switched-mode power supply (SMPS) design on printed circuit boards (PCBs). Particular challenges for LLMs in this context include their limited ability to interpret results from key simulation tools like SPICE and the multi-step design process. To address these challenges, we suggest SPICEAssistant, a framework that provides a broad selection of tools to an LLM. The tools serve as an interface to SPICE, allowing the LLM to interact flexibly with the simulator to estimate the impact of its modifications to the circuit. To evaluate the performance of SPICEAssistant, we defined a benchmark consisting of 256 questions testing the ability to adapt circuit netlists to fulfil different SMPS design tasks. The benchmarking results show that simulation feedback effectively improves SMPS design capabilities of LLMs. An increasing number of simulation iterations leads to enhanced performance. The SPICEAssistant framework significantly outperforms the standalone LLM GPT-4o on the benchmark by approximately 38%.",
      "authors": [
        "Simon Nau",
        "Jan Krummenauer",
        "Andr\\'e Zimmermann"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:41:12+00:00",
          "link": "https://arxiv.org/abs/2507.10639v1",
          "size": "1934kb",
          "version": "v1"
        }
      ],
      "title": "SPICEAssistant: LLM using SPICE Simulation Tools for Schematic Design of Switched-Mode Power Supplies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10639",
        "HTML": "https://arxiv.org/html/2507.10639v1",
        "PDF": "https://arxiv.org/pdf/2507.10639"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with applying LLMs to electronic design automation tasks and does not involve LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10641",
      "abstract": "Large Language Models have shown impressive capabilities in coding tasks like code generation and code completion, as they have been trained on a large amount of code data. Also, since one of the core pretraining objectives is Next Token Prediction, these models tends to learn surface-level syntactic patterns in code. However, this does not guarantee code comprehension ability i.e. the ability to capture the semantics of the code. In our opinion, this is the reason why these models often underperform on tasks that require deeper semantic understanding, such as code debugging and code optimization. To address this, we propose fine-tuning these models specifically for code comprehension tasks using large-scale datasets, enabling them to develop a more robust understanding of code semantics. We evaluate three code models of varying sizes on a suite of code comprehension tasks designed to assess semantic understanding beyond surface-level syntactic pattern matching. In particular, we analyze performance on the Subjectivity Grading Task and observe that model performance improves after fine-tuning on relevant downstream tasks. The most significant improvement is seen in the QWQ-32B model, where accuracy increases from 70% to 83.47%. A similar or explainable trend is observed across other models, clearly indicating an enhancement in code comprehension ability. Among the models studied, the DPO-fine-tuned Codestral-22B achieves the highest micro-accuracy of 87.66% on the Subjectivity Grading Task.",
      "authors": [
        "Jayant Havare",
        "Saurav Chaudhary",
        "Ganesh Ramakrishnan",
        "Kaushik Maharajan",
        "Srikanth Tamilselvam"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:19:49+00:00",
          "link": "https://arxiv.org/abs/2507.10641v1",
          "size": "442kb",
          "version": "v1"
        }
      ],
      "title": "A Code Comprehension Benchmark for Large Language Models for Code",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10641",
        "HTML": "https://arxiv.org/html/2507.10641v1",
        "PDF": "https://arxiv.org/pdf/2507.10641"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Although the paper discusses fine-tuning LLMs for code comprehension tasks, it does not provide substantial details on unique data processing steps or innovations specifically tailored for LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10803",
      "abstract": "Background Large language models (LLMs) face challenges in inductive thematic analysis, a task requiring deep interpretive and domain-specific expertise. We evaluated the feasibility of using LLMs to replicate expert-driven thematic analysis of social media data. Methods Using two temporally non-intersecting Reddit datasets on xylazine (n=286 and n=686, for model optimization and validation, respectively) with twelve expert-derived themes, we evaluated five LLMs against expert coding. We modeled the task as a series of binary classifications, rather than a single, multi-label classification, employing zero-, single-, and few-shot prompting strategies and measuring performance via accuracy, precision, recall, and F1-score. Results On the validation set, GPT-4o with two-shot prompting performed best (accuracy: 90.9%; F1-score: 0.71). For high-prevalence themes, model-derived thematic distributions closely mirrored expert classifications (e.g., xylazine use: 13.6% vs. 17.8%; MOUD use: 16.5% vs. 17.8%). Conclusions Our findings suggest that few-shot LLM-based approaches can automate thematic analyses, offering a scalable supplement for qualitative research. Keywords: thematic analysis, large language models, natural language processing, qualitative analysis, social media, prompt engineering, public health",
      "authors": [
        "JaMor Hairston",
        "Ritvik Ranjan",
        "Sahithi Lakamana",
        "Anthony Spadaro",
        "Selen Bozkurt",
        "Jeanmarie Perrone",
        "Abeed Sarker"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Emerging Technologies (cs.ET)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T20:57:52+00:00",
          "link": "https://arxiv.org/abs/2507.10803v1",
          "size": "536kb",
          "version": "v1"
        }
      ],
      "title": "Automated Thematic Analyses Using LLMs: Xylazine Wound Management Social Media Chatter Use Case",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10803",
        "PDF": "https://arxiv.org/pdf/2507.10803"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on thematic analysis using LLMs for social media data, not on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11129",
      "abstract": "Humans perceive the world through multimodal cues to understand and interact with the environment. Learning a scene representation for multiple modalities enhances comprehension of the physical world. However, modality conflicts, arising from inherent distinctions among different modalities, present two critical challenges: property disparity and granularity disparity. To address these challenges, we propose a general framework, MMOne, to represent multiple modalities in one scene, which can be readily extended to additional modalities. Specifically, a modality modeling module with a novel modality indicator is proposed to capture the unique properties of each modality. Additionally, we design a multimodal decomposition mechanism to separate multi-modal Gaussians into single-modal Gaussians based on modality differences. We address the essential distinctions among modalities by disentangling multimodal information into shared and modality-specific components, resulting in a more compact and efficient multimodal scene representation. Extensive experiments demonstrate that our method consistently enhances the representation capability for each modality and is scalable to additional modalities. The code is available at https://github.com/Neal2020GitHub/MMOne.",
      "authors": [
        "Zhifeng Gu",
        "Bing Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:29:29+00:00",
          "link": "https://arxiv.org/abs/2507.11129v1",
          "size": "2261kb",
          "version": "v1"
        }
      ],
      "title": "MMOne: Representing Multiple Modalities in One Scene",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11129",
        "HTML": "https://arxiv.org/html/2507.11129v1",
        "PDF": "https://arxiv.org/pdf/2507.11129"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing a framework for multimodal scene representation and does not discuss LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11520",
      "abstract": "Many empirical systems contain complex interactions of arbitrary size, representing, for example, chemical reactions, social groups, co-authorship relationships, and ecological dependencies. These interactions are known as higher-order interactions and the collection of these interactions comprise a higher-order network, or hypergraph. Hypergraphs have established themselves as a popular and versatile mathematical representation of such systems and a number of software packages written in various programming languages have been designed to analyze these networks. However, the ecosystem of higher-order network analysis software is fragmented due to specialization of each software's programming interface and compatible data representations. To enable seamless data exchange between higher-order network analysis software packages, we introduce the Hypergraph Interchange Format (HIF), a standardized format for storing higher-order network data. HIF supports multiple types of higher-order networks, including undirected hypergraphs, directed hypergraphs, and simplicial complexes, while actively exploring extensions to represent multiplex hypergraphs, temporal hypergraphs, and ordered hypergraphs. To accommodate the wide variety of metadata used in different contexts, HIF also includes support for attributes associated with nodes, edges, and incidences. This initiative is a collaborative effort involving authors, maintainers, and contributors from prominent hypergraph software packages. This project introduces a JSON schema with corresponding documentation and unit tests, example HIF-compliant datasets, and tutorials demonstrating the use of HIF with several popular higher-order network analysis software packages.",
      "authors": [
        "Mart\\'in Coll",
        "Cliff A. Joslyn",
        "Nicholas W. Landry",
        "Quintino Francesco Lotito",
        "Audun Myers",
        "Joshua Pickard",
        "Brenda Praggastis",
        "and Przemys{\\l}aw Szufel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:45:09+00:00",
          "link": "https://arxiv.org/abs/2507.11520v1",
          "size": "2063kb",
          "version": "v1"
        }
      ],
      "title": "HIF: The hypergraph interchange format for higher-order networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11520",
        "HTML": "https://arxiv.org/html/2507.11520v1",
        "PDF": "https://arxiv.org/pdf/2507.11520"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a standardized format for higher-order network data and does not focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.00077",
      "abstract": "Large language models (LLMs) are a powerful tool with the ability to match human capabilities and behavior in many settings. Retrieval-augmented generation (RAG) further allows LLMs to generate diverse output depending on the contents of their RAG database. This motivates their use in the social sciences to study human behavior between individuals when large-scale experiments are infeasible. However, LLMs depend on complex, computationally expensive algorithms. In this paper, we introduce interacting Gaussian mixture models (GMMs) as an alternative to similar frameworks using LLMs. We compare a simplified model of GMMs to select experimental simulations of LLMs whose updating and response depend on feedback from other LLMs. We find that interacting GMMs capture important features of the dynamics in interacting LLMs, and we investigate key similarities and differences between interacting LLMs and GMMs. We conclude by discussing the benefits of Gaussian mixture models, potential modifications, and future research directions.",
      "authors": [
        "Edward L. Wang",
        "Tianyu Wang",
        "Hayden Helm",
        "Avanti Athreya",
        "Vince Lyzinski",
        "Carey E. Priebe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T23:39:24+00:00",
          "link": "https://arxiv.org/abs/2506.00077v1",
          "size": "901kb",
          "version": "v1"
        },
        {
          "date": "2025-06-03T16:01:41+00:00",
          "link": "https://arxiv.org/abs/2506.00077v2",
          "size": "901kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T15:17:21+00:00",
          "link": "https://arxiv.org/abs/2506.00077v3",
          "size": "901kb",
          "version": "v3"
        }
      ],
      "title": "Gaussian mixture models as a proxy for interacting language models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.00077",
        "HTML": "https://arxiv.org/html/2506.00077v3",
        "PDF": "https://arxiv.org/pdf/2506.00077"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on using Gaussian mixture models as an alternative to LLMs for social science simulations, without addressing training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11165",
      "abstract": "As high-performance computing architectures evolve, more scientific computing workflows are being deployed on advanced computing platforms such as GPUs. These workflows can produce raw data at extremely high throughputs, requiring urgent high-ratio and low-latency error-bounded data compression solutions. In this paper, we propose cuSZ-Hi, an optimized high-ratio GPU-based scientific error-bounded lossy compressor with a flexible, domain-irrelevant, and fully open-source framework design. Our novel contributions are: 1) We maximally optimize the parallelized interpolation-based data prediction scheme on GPUs, enabling the full functionalities of interpolation-based scientific data prediction that are adaptive to diverse data characteristics; 2) We thoroughly explore and investigate lossless data encoding techniques, then craft and incorporate the best-fit lossless encoding pipelines for maximizing the compression ratio of cuSZ-Hi; 3) We systematically evaluate cuSZ-Hi on benchmarking datasets together with representative baselines. Compared to existing state-of-the-art scientific lossy compressors, with comparative or better throughput than existing high-ratio scientific error-bounded lossy compressors on GPUs, cuSZ-Hi can achieve up to 249% compression ratio improvement under the same error bound, and up to 215% compression ratio improvement under the same decompression data PSNR.",
      "authors": [
        "Shixun Wu",
        "Jinwen Pan",
        "Jinyang Liu",
        "Jiannan Tian",
        "Ziwei Qiu",
        "Jiajun Huang",
        "Kai Zhao",
        "Xin Liang",
        "Sheng Di",
        "Zizhong Chen",
        "Franck Cappello"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:14:14+00:00",
          "link": "https://arxiv.org/abs/2507.11165v1",
          "size": "2919kb",
          "version": "v1"
        }
      ],
      "title": "Boosting Scientific Error-Bounded Lossy Compression through Optimized Synergistic Lossy-Lossless Orchestration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11165",
        "HTML": "https://arxiv.org/html/2507.11165v1",
        "PDF": "https://arxiv.org/pdf/2507.11165"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The work focuses on scientific data compression techniques for high-performance computing, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.23367",
      "abstract": "PAN-sharpening aims to fuse high-resolution panchromatic (PAN) images with low-resolution multi-spectral (MS) images to generate high-resolution multi-spectral (HRMS) outputs. However, cross-modality misalignment -- caused by sensor placement, acquisition timing, and resolution disparity -- induces a fundamental challenge. Conventional deep learning methods assume perfect pixel-wise alignment and rely on per-pixel reconstruction losses, leading to spectral distortion, double edges, and blurring when misalignment is present. To address this, we propose PAN-Crafter, a modality-consistent alignment framework that explicitly mitigates the misalignment gap between PAN and MS modalities. At its core, Modality-Adaptive Reconstruction (MARs) enables a single network to jointly reconstruct HRMS and PAN images, leveraging PAN's high-frequency details as auxiliary self-supervision. Additionally, we introduce Cross-Modality Alignment-Aware Attention (CM3A), a novel mechanism that bidirectionally aligns MS texture to PAN structure and vice versa, enabling adaptive feature refinement across modalities. Extensive experiments on multiple benchmark datasets demonstrate that our PAN-Crafter outperforms the most recent state-of-the-art method in all metrics, even with 50.11$\\times$ faster inference time and 0.63$\\times$ the memory size. Furthermore, it demonstrates strong generalization performance on unseen satellite datasets, showing its robustness across different conditions.",
      "authors": [
        "Jeonghyeok Do",
        "Sungpyo Kim",
        "Geunhyuk Youk",
        "Jaehyup Lee",
        "Munchurl Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T11:46:21+00:00",
          "link": "https://arxiv.org/abs/2505.23367v1",
          "size": "6773kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T06:54:06+00:00",
          "link": "https://arxiv.org/abs/2505.23367v2",
          "size": "6752kb",
          "version": "v2"
        }
      ],
      "title": "PAN-Crafter: Learning Modality-Consistent Alignment for PAN-Sharpening",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23367",
        "HTML": "https://arxiv.org/html/2505.23367v2",
        "PDF": "https://arxiv.org/pdf/2505.23367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses the alignment challenge in PAN-sharpening for image processing and does not pertain to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.09367",
      "abstract": "As cities evolve toward more complex and multimodal transportation systems, the need for human-centered multi-agent simulation tools has never been more urgent. Yet most existing platforms remain limited - they often separate different types of road users, rely on scripted or pre-defined behaviors, overlook public transit users as active participants, and are rarely designed with accessibility in mind for non-technical users. To address this gap, this paper presents the specifications of a multi-agent simulation platform designed to support real-time, human-centered, and immersive studies of all road users, accompanied by open-source scripts for replication. Using high-fidelity immersive virtual environments, our platform enables interaction across public transit users, pedestrians, cyclists, automated vehicles, and drivers. The architecture is modular, extensible, and designed for accessibility. The system integrates hardware-specific modules - including an omnidirectional treadmill, a seating arrangement, a smart trainer, and an actuated cockpit. Additionally, the platform collects multimodal physiological, neurological, and behavioral data through embedded sensing devices such as functional near-infrared spectroscopy (fNIRS), eye tracking, and wrist-based biosensors. To show the usability of this system, we present three use cases. Simulation for All aims to lower the barrier to entry for high-fidelity transportation simulation, support experimentation across disciplines, and advance our understanding of multimodal mobility in complex urban environments.",
      "authors": [
        "Shiva Azimi",
        "Arash Tavakoli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T18:07:19+00:00",
          "link": "https://arxiv.org/abs/2507.09367v1",
          "size": "36246kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T15:50:39+00:00",
          "link": "https://arxiv.org/abs/2507.09367v2",
          "size": "36246kb",
          "version": "v2"
        }
      ],
      "title": "Simulation for All: A Step-by-Step Cookbook for Developing Human-Centered Multi-Agent Transportation Simulators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09367",
        "HTML": "https://arxiv.org/html/2507.09367v2",
        "PDF": "https://arxiv.org/pdf/2507.09367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a multi-agent transportation simulation platform, which does not relate to LLM training data processing or creation, focusing instead on simulation and data collection in virtual environments."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10627",
      "abstract": "Given a graph $G$ defined in a domain $\\mathcal{G}$, we investigate locally differentially private mechanisms to release a degree sequence on $\\mathcal{G}$ that accurately approximates the actual degree distribution. Existing solutions for this problem mostly use graph projection techniques based on edge deletion process, using a threshold parameter $\\theta$ to bound node degrees. However, this approach presents a fundamental trade-off in threshold parameter selection. While large $\\theta$ values introduce substantial noise in the released degree sequence, small $\\theta$ values result in more edges removed than necessary. Furthermore, $\\theta$ selection leads to an excessive communication cost. To remedy existing solutions' deficiencies, we present CADR-LDP, an efficient framework incorporating encryption techniques and differentially private mechanisms to release the degree sequence. In CADR-LDP, we first use the crypto-assisted Optimal-$\\theta$-Selection method to select the optimal parameter with a low communication cost. Then, we use the LPEA-LOW method to add some edges for each node with the edge addition process in local projection. LPEA-LOW prioritizes the projection with low-degree nodes, which can retain more edges for such nodes and reduce the projection error. Theoretical analysis shows that CADR-LDP satisfies $\\epsilon$-node local differential privacy. The experimental results on eight graph datasets show that our solution outperforms existing methods.",
      "authors": [
        "Xiaojian Zhang and Junqing Wang and Kerui Chen and Peiyuan Zhao and Huiyuan Bai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:04:08+00:00",
          "link": "https://arxiv.org/abs/2507.10627v1",
          "size": "3642kb",
          "version": "v1"
        }
      ],
      "title": "Crypto-Assisted Graph Degree Sequence Release under Local Differential Privacy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10627",
        "HTML": "https://arxiv.org/html/2507.10627v1",
        "PDF": "https://arxiv.org/pdf/2507.10627"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses privacy-preserving mechanisms in graph data release but does not relate to LLM training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.13444",
      "abstract": "Large Language Models (LLMs) have shown impressive capabilities, yet updating their knowledge remains a significant challenge, often leading to outdated or inaccurate responses. A proposed solution is the integration of external knowledge bases, such as knowledge graphs, with LLMs. Most existing methods use a paradigm that treats the whole question as the objective, with relevant knowledge being incrementally retrieved from the knowledge graph. However, this paradigm often leads to a granularity mismatch between the target question and the retrieved entities and relations. As a result, the information in the question cannot precisely correspond to the retrieved knowledge. This may cause redundant exploration or omission of vital knowledge, thereby leading to enhanced computational consumption and reduced retrieval accuracy. To address the limitations of coarse-grained knowledge exploration, we propose FiSKE, a novel paradigm for Fine-grained Stateful Knowledge Exploration. FiSKE first decomposes questions into fine-grained clues, then employs an adaptive mapping strategy during knowledge exploration process to resolve ambiguity in clue-to-graph mappings. This strategy dynamically infers contextual correspondences while maintaining a stateful record of the mappings. A clue-driven termination mechanism ensures rigorous augmentation--leveraging fully mapped paths for LLMs while reverting to chain-of-thought reasoning when necessary. Our approach balances precision and efficiency. Experiments on multiple datasets revealed that our paradigm surpasses current advanced methods in knowledge retrieval while significantly reducing the average number of LLM invocations.",
      "authors": [
        "Dehao Tao",
        "Congqi Wang",
        "Feng Huang",
        "Junhao Chen",
        "Yongfeng Huang and Minghu Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-24T13:36:50+00:00",
          "link": "https://arxiv.org/abs/2401.13444v1",
          "size": "167kb",
          "version": "v1"
        },
        {
          "date": "2024-08-19T03:25:52+00:00",
          "link": "https://arxiv.org/abs/2401.13444v2",
          "size": "112kb",
          "version": "v2"
        },
        {
          "date": "2025-01-27T09:39:49+00:00",
          "link": "https://arxiv.org/abs/2401.13444v3",
          "size": "771kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T02:25:49+00:00",
          "link": "https://arxiv.org/abs/2401.13444v4",
          "size": "582kb",
          "version": "v4"
        }
      ],
      "title": "Fine-grained Stateful Knowledge Exploration: Effective and Efficient Graph Retrieval with Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.13444",
        "HTML": "https://arxiv.org/html/2401.13444v4",
        "PDF": "https://arxiv.org/pdf/2401.13444"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper addresses knowledge exploration in LLMs but does not focus primarily on the processing or engineering of training data for LLMs. It instead proposes a retrieval method using external knowledge graphs."
      },
      "tasks": [
        "Knowledge Base Question Answering",
        "Knowledge Graphs",
        "Question Answering",
        "Retrieval"
      ],
      "repo_urls": [
        "https://github.com/nnnoidea/stateful-KGQA"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.14959",
      "abstract": "Intrinsic self-correction was proposed to improve LLMs' responses via feedback prompts solely based on their inherent capability. However, recent works show that LLMs' intrinsic self-correction fails without oracle labels as feedback prompts. In this paper, we aim to interpret LLMs' intrinsic self-correction for different tasks, especially for those failure cases. By including one simple task and three complex tasks with state-of-the-art (SOTA) LLMs like ChatGPT families (o1, 4o, 3.5-turbo) and Llama families (2-7B, 3-8B, and 3.1-8B), we design three interpretation methods to reveal the dark side of LLMs' intrinsic self-correction. We identify intrinsic self-correction can (1) cause LLMs to waver both intermedia and final answers and lead to prompt bias on simple factual questions; (2) introduce human-like cognitive bias on complex tasks. In light of our findings, we also provide two simple yet effective strategies for alleviation: question repeating and supervised fine-tuning with a few samples. We open-source our work at https://x-isc.info/.",
      "authors": [
        "Qingjie Zhang",
        "Di Wang",
        "Haoting Qian",
        "Yiming Li",
        "Tianwei Zhang",
        "Minlie Huang",
        "Ke Xu",
        "Hewu Li",
        "Yan Liu",
        "Han Qiu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-19T15:39:31+00:00",
          "link": "https://arxiv.org/abs/2412.14959v1",
          "size": "15663kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T07:07:14+00:00",
          "link": "https://arxiv.org/abs/2412.14959v2",
          "size": "6234kb",
          "version": "v2"
        }
      ],
      "title": "Understanding the Dark Side of LLMs' Intrinsic Self-Correction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.14959",
        "HTML": "https://arxiv.org/html/2412.14959v2",
        "PDF": "https://arxiv.org/pdf/2412.14959"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses LLMs' intrinsic self-correction with a mention of supervised fine-tuning but does not primarily focus on data processing methods or detailed steps in processing LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.11003",
      "abstract": "With the advent of vision-language models (e.g., CLIP) in zero- and few-shot settings, CLIP has been widely applied to zero-shot anomaly detection (ZSAD) in recent research, where the rare classes are essential and expected in many applications. This study introduces \\textbf{FiSeCLIP} for ZSAD with training-free \\textbf{CLIP}, combining the feature matching with the cross-modal alignment. Testing with the entire dataset is impractical, while batch-based testing better aligns with real industrial needs, and images within a batch can serve as mutual reference points. Accordingly, FiSeCLIP utilizes other images in the same batch as reference information for the current image. However, the lack of labels for these references can introduce ambiguity, we apply text information to \\textbf{fi}lter out noisy features. In addition, we further explore CLIP's inherent potential to restore its local \\textbf{se}mantic correlation, adapting it for fine-grained anomaly detection tasks to enable a more accurate filtering process. Our approach exhibits superior performance for both anomaly classification and segmentation on anomaly detection benchmarks, building a stronger baseline for the direction, e.g., on MVTec-AD, FiSeCLIP outperforms the SOTA AdaCLIP by +4.6\\%$\\uparrow$/+5.7\\%$\\uparrow$ in segmentation metrics AU-ROC/$F_1$-max.",
      "authors": [
        "Yuhu Bai",
        "Jiangning Zhang",
        "Yunkang Cao",
        "Guangyuan Lu",
        "Qingdong He",
        "Xiangtai Li",
        "Guanzhong Tian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T05:42:17+00:00",
          "link": "https://arxiv.org/abs/2507.11003v1",
          "size": "1190kb",
          "version": "v1"
        }
      ],
      "title": "Bridge Feature Matching and Cross-Modal Alignment with Mutual-filtering for Zero-shot Anomaly Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11003",
        "HTML": "https://arxiv.org/html/2507.11003v1",
        "PDF": "https://arxiv.org/pdf/2507.11003"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on zero-shot anomaly detection using visual-language models, specifically FiSeCLIP, and does not address LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11093",
      "abstract": "The fluid antenna system (FAS) has emerged as a new physical-layer concept to provide enhanced propagation conditions for multiuser multiple-input multiple-output (MIMO) communications over conventional fixed arrays. This work focuses on minimizing the maximum symbol error probability (SEP) under $M$-ary phase shift keying (MPSK) signaling in a multiuser downlink equipped with FAS, where each antenna moves within nonoverlapping intervals. This specific problem of joint SEP minimization with FAS and constructive interference (CI) precoding has not been previously addressed. The resulting problem turns out to be a nonconvex and nonsmooth optimization challenge. We transform the SEP minimization problem into a safety margin maximization problem in constructive interference precoding. Then, we customize a smoothing technique and a block coordinate descent (BCD) algorithm, with emphasis on low computational complexity. Simulation results show that our approach can reduce bit error rate (BER) compared to both the fixed arrays and FAS designed by existing particle swarm optimization (PSO). Also, our approach shows attractively low computational complexity compared to PSO benchmarks.",
      "authors": [
        "Wenxuan Sun",
        "Mingjie Shao",
        "Luteng Zhu",
        "Yao Ge",
        "Tong Zhang",
        "Zhi Liu"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:40:21+00:00",
          "link": "https://arxiv.org/abs/2507.11093v1",
          "size": "3111kb",
          "version": "v1"
        }
      ],
      "title": "Optimizing Fluid Antenna Configurations for Constructive Interference Precoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11093",
        "HTML": "https://arxiv.org/html/2507.11093v1",
        "PDF": "https://arxiv.org/pdf/2507.11093"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing fluid antenna configurations for MIMO communications, which is unrelated to LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11229",
      "abstract": "Knowledge graphs (KGs) are vital for enabling knowledge reasoning across various domains. Recent KG reasoning methods that integrate both global and local information have achieved promising results. However, existing methods often suffer from score over-smoothing, which blurs the distinction between correct and incorrect answers and hinders reasoning effectiveness. To address this, we propose DuetGraph, a coarse-to-fine KG reasoning mechanism with dual-pathway global-local fusion. DuetGraph tackles over-smoothing by segregating -- rather than stacking -- the processing of local (via message passing) and global (via attention) information into two distinct pathways, preventing mutual interference and preserving representational discrimination. In addition, DuetGraph introduces a coarse-to-fine optimization, which partitions entities into high- and low-score subsets. This strategy narrows the candidate space and sharpens the score gap between the two subsets, which alleviates over-smoothing and enhances inference quality. Extensive experiments on various datasets demonstrate that DuetGraph achieves state-of-the-art (SOTA) performance, with up to an 8.7% improvement in reasoning quality and a 1.8$\\times$ acceleration in training efficiency.",
      "authors": [
        "Jin Li",
        "Zezhong Ding",
        "Xike Xie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T11:59:15+00:00",
          "link": "https://arxiv.org/abs/2507.11229v1",
          "size": "248kb",
          "version": "v1"
        }
      ],
      "title": "DuetGraph: Coarse-to-Fine Knowledge Graph Reasoning with Dual-Pathway Global-Local Fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11229",
        "HTML": "https://arxiv.org/html/2507.11229v1",
        "PDF": "https://arxiv.org/pdf/2507.11229"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "DuetGraph is focused on knowledge graph reasoning using a new dual-pathway fusion model. It does not discuss LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11525",
      "abstract": "Ambiguity in natural language instructions poses significant risks in safety-critical human-robot interaction, particularly in domains such as surgery. To address this, we propose a framework that uses Large Language Models (LLMs) for ambiguity detection specifically designed for collaborative surgical scenarios. Our method employs an ensemble of LLM evaluators, each configured with distinct prompting techniques to identify linguistic, contextual, procedural, and critical ambiguities. A chain-of-thought evaluator is included to systematically analyze instruction structure for potential issues. Individual evaluator assessments are synthesized through conformal prediction, which yields non-conformity scores based on comparison to a labeled calibration dataset. Evaluating Llama 3.2 11B and Gemma 3 12B, we observed classification accuracy exceeding 60% in differentiating ambiguous from unambiguous surgical instructions. Our approach improves the safety and reliability of human-robot collaboration in surgery by offering a mechanism to identify potentially ambiguous instructions before robot action.",
      "authors": [
        "Ana Davila",
        "Jacinto Colan",
        "Yasuhisa Hasegawa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:53:36+00:00",
          "link": "https://arxiv.org/abs/2507.11525v1",
          "size": "497kb",
          "version": "v1"
        }
      ],
      "title": "LLM-based ambiguity detection in natural language instructions for collaborative surgical robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11525",
        "HTML": "https://arxiv.org/html/2507.11525v1",
        "PDF": "https://arxiv.org/pdf/2507.11525"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for ambiguity detection in language instructions using LLMs, which does not involve LLM training data processing or dataset creation aspects."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.18858",
      "abstract": "Large Language Models have received significant attention due to their abilities to solve a wide range of complex tasks. However these models memorize a significant proportion of their training data, posing a serious threat when disclosed at inference time. To mitigate this unintended memorization, it is crucial to understand what elements are memorized and why. This area of research is largely unexplored, with most existing works providing a posteriori explanations. To address this gap, we propose a new approach to detect memorized samples a priori in LLMs fine-tuned for classification tasks. This method is effective from the early stages of training and readily adaptable to other classification settings, such as training vision models from scratch. Our method is supported by new theoretical results, and requires a low computational budget. We achieve strong empirical results, paving the way for the systematic identification and protection of vulnerable samples before they are memorized.",
      "authors": [
        "J\\'er\\'emie Dentan",
        "Davide Buscaldi",
        "Aymen Shabou",
        "Sonia Vanier"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-27T15:53:55+00:00",
          "link": "https://arxiv.org/abs/2409.18858v1",
          "size": "1430kb",
          "version": "v1"
        },
        {
          "date": "2025-06-05T08:05:59+00:00",
          "link": "https://arxiv.org/abs/2409.18858v2",
          "size": "1323kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T13:11:07+00:00",
          "link": "https://arxiv.org/abs/2409.18858v3",
          "size": "1323kb",
          "version": "v3"
        }
      ],
      "title": "Predicting memorization within Large Language Models fine-tuned for classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.18858",
        "HTML": "https://arxiv.org/html/2409.18858v3",
        "PDF": "https://arxiv.org/pdf/2409.18858"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a method to predict memorization of training samples within LLMs, which is somewhat related to training-data understanding, but it does not focus on data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.20946",
      "abstract": "This work studies the challenge of optimal energy management in building-based microgrids through a collaborative and privacy-preserving framework. We evaluated two common RL algorithms (PPO and TRPO) in different collaborative setups to manage distributed energy resources (DERs) efficiently. Using a customized version of the CityLearn environment and synthetically generated data, we simulate and design net-zero energy scenarios for microgrids composed of multiple buildings. Our approach emphasizes reducing energy costs and carbon emissions while ensuring privacy. Experimental results demonstrate that Federated TRPO is comparable with state-of-the-art federated RL methodologies without hyperparameter tuning. The proposed framework highlights the feasibility of collaborative learning for achieving optimal control policies in energy systems, advancing the goals of sustainable and efficient smart grids. Our code is accessible \\href{https://github.com/Optimization-and-Machine-Learning-Lab/energy_fed_trpo.git}{\\textit{this repo}}.",
      "authors": [
        "Nicolas M Cuadrado Avila",
        "Samuel Horv\\'ath",
        "Martin Tak\\'a\\v{c}"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-30T13:38:31+00:00",
          "link": "https://arxiv.org/abs/2412.20946v1",
          "size": "22432kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T07:46:57+00:00",
          "link": "https://arxiv.org/abs/2412.20946v2",
          "size": "8769kb",
          "version": "v2"
        }
      ],
      "title": "Generalising Battery Control in Net-Zero Buildings via Personalised Federated RL",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.20946",
        "HTML": "https://arxiv.org/html/2412.20946v2",
        "PDF": "https://arxiv.org/pdf/2412.20946"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily addresses optimal energy management in microgrids using federated reinforcement learning and does not discuss LLM training data processing or engineering."
      },
      "tasks": [
        "energy management",
        "Federated Learning",
        "Management",
        "Privacy Preserving"
      ],
      "repo_urls": [
        "https://github.com/Optimization-and-Machine-Learning-Lab/energy_fed_trpo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.11146",
      "abstract": "Debugging complex systems is a crucial yet time-consuming task. This paper presents the use of automata learning and testing techniques to obtain concise and informative bug descriptions. We introduce the concepts of Failure Explanations (FE), Eventual Failure Explanations (EFE), and Early Detection (ED) to provide meaningful summaries of failing behavior patterns. By factoring out irrelevant information and focusing on essential test patterns, our approach aims to enhance bug detection and understanding. We evaluate our methods using various test patterns and real-world benchmarks, demonstrating their effectiveness in producing compact and informative bug descriptions.",
      "authors": [
        "Tom Yaacov",
        "Gera Weiss",
        "Gal Amram",
        "Avi Hayoun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:54:08+00:00",
          "link": "https://arxiv.org/abs/2507.11146v1",
          "size": "193kb",
          "version": "v1"
        }
      ],
      "title": "Automata Models for Effective Bug Description",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11146",
        "HTML": "https://arxiv.org/html/2507.11146v1",
        "PDF": "https://arxiv.org/pdf/2507.11146"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper emphasizes techniques for bug description using automata models and does not address LLM training data processing or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06565",
      "abstract": "Large-language models (LLMs) turn writing into a live exchange between humans and software. We characterize this new medium as a discursive network that treats people and LLMs as equal nodes and tracks how their statements circulate. We define the generation of erroneous information as invalidation (any factual, logical, or structural breach) and show it follows four hazards: drift from truth, self-repair, fresh fabrication, and external detection. We develop a general mathematical model of discursive networks that shows that a network governed only by drift and self-repair stabilizes at a modest error rate. Giving each false claim even a small chance of peer review shifts the system to a truth-dominant state. We operationalize peer review with the open-source \\emph{Flaws-of-Others (FOO) algorithm}: a configurable loop in which any set of agents critique one another while a harmonizer merges their verdicts. We identify an ethical transgression, epithesis, that occurs when humans fail to engage in the discursive network. The takeaway is practical and cultural: reliability in this new medium comes not from perfecting single models but from connecting imperfect ones into networks that enforce mutual accountability.",
      "authors": [
        "Juan B. Guti\\'errez"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T05:39:56+00:00",
          "link": "https://arxiv.org/abs/2507.06565v1",
          "size": "742kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T19:34:51+00:00",
          "link": "https://arxiv.org/abs/2507.06565v2",
          "size": "742kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T17:19:46+00:00",
          "link": "https://arxiv.org/abs/2507.06565v3",
          "size": "849kb",
          "version": "v3"
        }
      ],
      "title": "A Mathematical Theory of Discursive Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06565",
        "HTML": "https://arxiv.org/html/2507.06565v3",
        "PDF": "https://arxiv.org/pdf/2507.06565"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a mathematical model of discursive networks and ethical implications, rather than data processing or engineering methods for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10589",
      "abstract": "Pneumonia, particularly when induced by diseases like COVID-19, remains a critical global health challenge requiring rapid and accurate diagnosis. This study presents a comprehensive comparison of traditional machine learning and state-of-the-art deep learning approaches for automated pneumonia detection using chest X-rays (CXRs). We evaluate multiple methodologies, ranging from conventional machine learning techniques (PCA-based clustering, Logistic Regression, and Support Vector Classification) to advanced deep learning architectures including Convolutional Neural Networks (Modified LeNet, DenseNet-121) and various Vision Transformer (ViT) implementations (Deep-ViT, Compact Convolutional Transformer, and Cross-ViT). Using a dataset of 5,856 pediatric CXR images, we demonstrate that Vision Transformers, particularly the Cross-ViT architecture, achieve superior performance with 88.25% accuracy and 99.42% recall, surpassing traditional CNN approaches. Our analysis reveals that architectural choices impact performance more significantly than model size, with Cross-ViT's 75M parameters outperforming larger models. The study also addresses practical considerations including computational efficiency, training requirements, and the critical balance between precision and recall in medical diagnostics. Our findings suggest that Vision Transformers offer a promising direction for automated pneumonia detection, potentially enabling more rapid and accurate diagnosis during health crises.",
      "authors": [
        "Gaurav Singh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:26:24+00:00",
          "link": "https://arxiv.org/abs/2507.10589v1",
          "size": "6914kb",
          "version": "v1"
        }
      ],
      "title": "Comparative Analysis of Vision Transformers and Traditional Deep Learning Approaches for Automated Pneumonia Detection in Chest X-Rays",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10589",
        "HTML": "https://arxiv.org/html/2507.10589v1",
        "PDF": "https://arxiv.org/pdf/2507.10589"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study analyzes Vision Transformers versus deep learning for pneumonia detection, focusing on model evaluation and architectural impact on performance, not on LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10608",
      "abstract": "Conventional anti-money laundering (AML) systems predominantly focus on identifying anomalous entities or transactions, flagging them for manual investigation based on statistical deviation or suspicious behavior. This paradigm, however, misconstrues the true nature of money laundering, which is rarely anomalous but often deliberate, repeated, and concealed within consistent behavioral routines. In this paper, we challenge the entity-centric approach and propose a network-theoretic perspective that emphasizes detecting predefined laundering patterns across directed transaction networks. We introduce the notion of behavioral consistency as the core trait of laundering activity, and argue that such patterns are better captured through subgraph structures expressing semantic and functional roles - not solely geometry. Crucially, we explore the concept of pattern fragility: the sensitivity of laundering patterns to small attribute changes and, conversely, their semantic robustness even under drastic topological transformations. We claim that laundering detection should not hinge on statistical outliers, but on preservation of behavioral essence, and propose a reconceptualization of pattern similarity grounded in this insight. This philosophical and practical shift has implications for how AML systems model, scan, and interpret networks in the fight against financial crime.",
      "authors": [
        "Danny Butvinik",
        "Ofir Yakobi",
        "Michal Einhorn Cohen",
        "and Elina Maliarsky"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T06:26:27+00:00",
          "link": "https://arxiv.org/abs/2507.10608v1",
          "size": "618kb",
          "version": "v1"
        }
      ],
      "title": "The Shape of Deceit: Behavioral Consistency and Fragility in Money Laundering Patterns",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10608",
        "PDF": "https://arxiv.org/pdf/2507.10608"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses money laundering detection using network theory, without any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10913",
      "abstract": "This paper presents a multi-agent reinforcement learning (MARL) framework for cooperative collision avoidance of UAV swarms leveraging domain knowledge-driven reward. The reward is derived from knowledge in the domain of image processing, approximating contours on a two-dimensional field. By modeling obstacles as maxima on the field, collisions are inherently avoided as contours never go through peaks or intersect. Additionally, counters are smooth and energy-efficient. Our framework enables training with large swarm sizes as the agent interaction is minimized and the need for complex credit assignment schemes or observation sharing mechanisms in state-of-the-art MARL approaches are eliminated. Moreover, UAVs obtain the ability to adapt to complex environments where contours may be non-viable or non-existent through intensive training. Extensive experiments are conducted to evaluate the performances of our framework against state-of-the-art MARL algorithms.",
      "authors": [
        "Shuangyao Huang",
        "Haibo Zhang",
        "Zhiyi Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T02:09:53+00:00",
          "link": "https://arxiv.org/abs/2507.10913v1",
          "size": "19186kb",
          "version": "v1"
        }
      ],
      "title": "A Learning Framework For Cooperative Collision Avoidance of UAV Swarms Leveraging Domain Knowledge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10913",
        "HTML": "https://arxiv.org/html/2507.10913v1",
        "PDF": "https://arxiv.org/pdf/2507.10913"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a collision avoidance framework for UAVs using MARL, without addressing any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11324",
      "abstract": "Privacy Preserving Synthetic Data Generation (PP-SDG) has emerged to produce synthetic datasets from personal data while maintaining privacy and utility. Differential privacy (DP) is the property of a PP-SDG mechanism that establishes how protected individuals are when sharing their sensitive data. It is however difficult to interpret the privacy loss ($\\varepsilon$) expressed by DP. To make the actual risk associated with the privacy loss more transparent, multiple privacy metrics (PMs) have been proposed to assess the privacy risk of the data. These PMs are utilized in separate studies to assess newly introduced PP-SDG mechanisms. Consequently, these PMs embody the same assumptions as the PP-SDG mechanism they were made to assess. Therefore, a thorough definition of how these are calculated is necessary. In this work, we present the assumptions and mathematical formulations of 17 distinct privacy metrics.",
      "authors": [
        "Frederik Marinus Trudslev and Matteo Lissandrini and Juan Manuel Rodriguez and Martin B{\\o}gsted and Daniele Dell'Aglio"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:56:02+00:00",
          "link": "https://arxiv.org/abs/2507.11324v1",
          "size": "175kb",
          "version": "v1"
        }
      ],
      "title": "A Review of Privacy Metrics for Privacy-Preserving Synthetic Data Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11324",
        "HTML": "https://arxiv.org/html/2507.11324v1",
        "PDF": "https://arxiv.org/pdf/2507.11324"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on privacy metrics for synthetic data generation, which does not contribute directly to processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11540",
      "abstract": "Depth estimation is a fundamental task in 3D computer vision, crucial for applications such as 3D reconstruction, free-viewpoint rendering, robotics, autonomous driving, and AR/VR technologies. Traditional methods relying on hardware sensors like LiDAR are often limited by high costs, low resolution, and environmental sensitivity, limiting their applicability in real-world scenarios. Recent advances in vision-based methods offer a promising alternative, yet they face challenges in generalization and stability due to either the low-capacity model architectures or the reliance on domain-specific and small-scale datasets. The emergence of scaling laws and foundation models in other domains has inspired the development of \"depth foundation models\": deep neural networks trained on large datasets with strong zero-shot generalization capabilities. This paper surveys the evolution of deep learning architectures and paradigms for depth estimation across the monocular, stereo, multi-view, and monocular video settings. We explore the potential of these models to address existing challenges and provide a comprehensive overview of large-scale datasets that can facilitate their development. By identifying key architectures and training strategies, we aim to highlight the path towards robust depth foundation models, offering insights into their future research and applications.",
      "authors": [
        "Zhen Xu",
        "Hongyu Zhou",
        "Sida Peng",
        "Haotong Lin",
        "Haoyu Guo",
        "Jiahao Shao",
        "Peishan Yang",
        "Qinglin Yang",
        "Sheng Miao",
        "Xingyi He",
        "Yifan Wang",
        "Yue Wang",
        "Ruizhen Hu",
        "Yiyi Liao",
        "Xiaowei Zhou",
        "Hujun Bao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:59:59+00:00",
          "link": "https://arxiv.org/abs/2507.11540v1",
          "size": "7826kb",
          "version": "v1"
        }
      ],
      "title": "Towards Depth Foundation Model: Recent Trends in Vision-Based Depth Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11540",
        "HTML": "https://arxiv.org/html/2507.11540v1",
        "PDF": "https://arxiv.org/pdf/2507.11540"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper surveys advancements in vision-based depth estimation and discusses large-scale datasets for developing depth foundation models. It does not focus on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.04896",
      "abstract": "In this study, we address the challenge of detecting ``discursive communities'' on X/Twitter by focusing on the role of verified users as the main content creators in online political debates. The analysis centers on three major Italian political events in 2022 - the Presidential election, a governmental crisis, and the general elections - occurring before the introduction of paid account verification. We propose and compare two novel methodologies, MonoDC and BiDC, which exploit, respectively, the retweet network among users and a similarity network based on shared audiences, while integrating a maximum entropy null model to filter out the inherent noise in online social networks. Our results demonstrate that leveraging verified users-considered as indicators of prestige and authority-leads to significantly clear community partitions that closely reflect the actual political affiliations, outperforming standard community detection algorithms applied to the entire retweet network. Moreover, the comparison of different methodologies and user sets suggests that the status conferred by the blue verification tick plays a dominant role in shaping online discourse, with important implications for platform governance, especially in light of the recent shift to paid verification.",
      "authors": [
        "Stefano Guarino",
        "Ayoub Mounim",
        "Guido Caldarelli and Fabio Saracco"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-08T09:04:46+00:00",
          "link": "https://arxiv.org/abs/2405.04896v1",
          "size": "924kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T13:12:47+00:00",
          "link": "https://arxiv.org/abs/2405.04896v2",
          "size": "1103kb",
          "version": "v2"
        }
      ],
      "title": "Verified authors shape X/Twitter discursive communities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.04896",
        "HTML": "https://arxiv.org/html/2405.04896v2",
        "PDF": "https://arxiv.org/pdf/2405.04896"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study investigates discursive communities on Twitter during political events, focusing on community detection algorithms. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.17460",
      "abstract": "Language models (LMs) show promise for vulnerability detection but struggle with long, real-world code due to sparse and uncertain vulnerability locations. These issues, exacerbated by token limits, often cause models to miss vulnerability-related signals, thereby impairing effective learning. A key intuition is to enhance LMs with concise, information-rich context. Commit-based annotations offer precise, CWE-agnostic supervision, but are unavailable during inference, as they depend on historical code changes. Moreover, their extreme sparsity, often covering only a few lines, makes it difficult for LMs to process directly. In this paper, we propose FocusVul, a model-agnostic framework that improves LM-based vulnerability detection by learning to select sensitive context. FocusVul learns commit-based annotation patterns through hierarchical semantic modeling and generalizes them to identify line-level vulnerability-relevant regions during inference. It then extracts LM-oriented context via both dependency and execution flows surrounding selected regions, yielding semantically rich inputs for effective vulnerability detection. Experiments on real-world benchmarks show that FocusVul consistently outperforms heuristic-based and full-function fine-tuning approaches, improving classification performance by 164.04% and reducing FLOPs by 19.12% on average.",
      "authors": [
        "Xinran Zheng",
        "Xingzhi Qian",
        "Huichi Zhou",
        "Shuo Yang",
        "Yiling He",
        "Suman Jana",
        "Lorenzo Cavallaro"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-23T04:41:54+00:00",
          "link": "https://arxiv.org/abs/2505.17460v1",
          "size": "597kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T11:35:29+00:00",
          "link": "https://arxiv.org/abs/2505.17460v2",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T18:40:01+00:00",
          "link": "https://arxiv.org/abs/2505.17460v3",
          "size": "0kb",
          "version": "v3"
        }
      ],
      "title": "Learning to Focus: Context Extraction for Efficient Code Vulnerability Detection with Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.17460",
        "PDF": "https://arxiv.org/pdf/2505.17460"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper briefly discusses learning to select context for language models, which could be viewed as a preprocessing step for code data but does not focus primarily on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11030",
      "abstract": "While open-vocabulary semantic segmentation (OVSS) can segment an image into semantic regions based on arbitrarily given text descriptions even for classes unseen during training, it fails to understand personal texts (e.g., `my mug cup') for segmenting regions of specific interest to users. This paper addresses challenges like recognizing `my mug cup' among `multiple mug cups'. To overcome this challenge, we introduce a novel task termed \\textit{personalized open-vocabulary semantic segmentation} and propose a text prompt tuning-based plug-in method designed to recognize personal visual concepts using a few pairs of images and masks, while maintaining the performance of the original OVSS. Based on the observation that reducing false predictions is essential when applying text prompt tuning to this task, our proposed method employs `negative mask proposal' that captures visual concepts other than the personalized concept. We further improve the performance by enriching the representation of text prompts by injecting visual embeddings of the personal concept into them. This approach enhances personalized OVSS without compromising the original OVSS performance. We demonstrate the superiority of our method on our newly established benchmarks for this task, including FSS$^\\text{per}$, CUB$^\\text{per}$, and ADE$^\\text{per}$.",
      "authors": [
        "Sunghyun Park",
        "Jungsoo Lee",
        "Shubhankar Borse",
        "Munawar Hayat",
        "Sungha Choi",
        "Kyuwoong Hwang",
        "Fatih Porikli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T06:51:07+00:00",
          "link": "https://arxiv.org/abs/2507.11030v1",
          "size": "24062kb",
          "version": "v1"
        }
      ],
      "title": "Personalized OVSS: Understanding Personal Concept in Open-Vocabulary Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11030",
        "HTML": "https://arxiv.org/html/2507.11030v1",
        "PDF": "https://arxiv.org/pdf/2507.11030"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on creating a task and method in open-vocabulary semantic segmentation rather than any LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11049",
      "abstract": "As online news consumption grows, personalized recommendation systems have become integral to digital journalism. However, these systems risk reinforcing filter bubbles and political polarization by failing to incorporate diverse perspectives. Stance detection -- identifying a text's position on a target -- can help mitigate this by enabling viewpoint-aware recommendations and data-driven analyses of media bias. Yet, existing stance detection research remains largely limited to short texts and high-resource languages. To address these gaps, we introduce \\textsc{K-News-Stance}, the first Korean dataset for article-level stance detection, comprising 2,000 news articles with article-level and 19,650 segment-level stance annotations across 47 societal issues. We also propose \\textsc{JoA-ICL}, a \\textbf{Jo}urnalism-guided \\textbf{A}gentic \\textbf{I}n-\\textbf{C}ontext \\textbf{L}earning framework that employs a language model agent to predict the stances of key structural segments (e.g., leads, quotes), which are then aggregated to infer the overall article stance. Experiments show that \\textsc{JoA-ICL} outperforms existing stance detection methods, highlighting the benefits of segment-level agency in capturing the overall position of long-form news articles. Two case studies further demonstrate its broader utility in promoting viewpoint diversity in news recommendations and uncovering patterns of media bias.",
      "authors": [
        "Dahyun Lee",
        "Jonghyeon Choi",
        "Jiyoung Han",
        "and Kunwoo Park"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T07:22:04+00:00",
          "link": "https://arxiv.org/abs/2507.11049v1",
          "size": "2072kb",
          "version": "v1"
        }
      ],
      "title": "Journalism-Guided Agentic In-Context Learning for News Stance Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11049",
        "HTML": "https://arxiv.org/html/2507.11049v1",
        "PDF": "https://arxiv.org/pdf/2507.11049"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper introduces a new dataset (\textsc{K-News-Stance}) for stance detection but focuses more on the model framework and stance prediction rather than data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11331",
      "abstract": "Transformer models rely heavily on scaled dot-product attention (SDPA), typically implemented using the FlashAttention algorithm. However, current systolic-array-based accelerators face significant challenges when executing FlashAttention. Systolic arrays can only achieve high utilization for consecutive and large matrix multiplications. In contrast, FlashAttention requires frequently interleaved matrix multiplications and softmax operations.\n  The frequent data swaps between the systolic array and external vector units result in low systolic array utilization. This is further exacerbated by the fact that softmax involves numerous non-matrix operations, which are not well-suited for systolic arrays. Moreover, the concurrent execution of matrix multiplication on systolic arrays and softmax on vector units leads to register file and SRAM port contention, further degrading performance.\n  To overcome these limitations, we propose FSA, an enhanced systolic array architecture that enables the entire FlashAttention algorithm to run entirely within a single systolic array, eliminating the need for external vector units. At the core of FSA is SystolicAttention, a novel scheduling algorithm that maps FlashAttention operations onto systolic arrays with fine-grained, element-wise overlap. This significantly improves array utilization while preserving the original floating-point operation order to maintain numerical stability.\n  We implement FSA in synthesizable RTL and evaluate its performance against state-of-the-art commercial accelerators. Our results show that FSA achieves 1.77x and 4.83x higher attention FLOPs/s utilization compared to AWS NeuronCore-v2 and Google TPUv5e, respectively, with only about 10% area overhead.",
      "authors": [
        "Jiawei Lin",
        "Guokai Chen",
        "Yuanlong Li",
        "Thomas Bourgeat"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:04:17+00:00",
          "link": "https://arxiv.org/abs/2507.11331v1",
          "size": "528kb",
          "version": "v1"
        }
      ],
      "title": "SystolicAttention: Fusing FlashAttention within a Single Systolic Array",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11331",
        "HTML": "https://arxiv.org/html/2507.11331v1",
        "PDF": "https://arxiv.org/pdf/2507.11331"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses an architectural solution for Transformer model processing efficiency and not on training data processing or engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.04025",
      "abstract": "Research ideation involves broad exploring and deep refining ideas. Both require deep engagement with literature. Existing tools focus primarily on idea broad generation, yet offer little support for iterative specification, refinement, and evaluation needed to further develop initial ideas. To bridge this gap, we introduce IdeaSynth, a research idea development system that uses LLMs to provide literature-grounded feedback for articulating research problems, solutions, evaluations, and contributions. IdeaSynth represents these idea facets as nodes on a canvas, and allow researchers to iteratively refine them by creating and exploring variations and composing them. Our lab study (N=20) showed that participants, while using IdeaSynth, explored more alternative ideas and expanded initial ideas with more details compared to a strong LLM-based baseline. Our deployment study (N=7) demonstrated that participants effectively used IdeaSynth for real-world research projects at various ideation stages from developing initial ideas to revising framings of mature manuscripts, highlighting the possibilities to adopt IdeaSynth in researcher's workflows.",
      "authors": [
        "Kevin Pu",
        "K. J. Kevin Feng",
        "Tovi Grossman",
        "Tom Hope",
        "Bhavana Dalvi Mishra",
        "Matt Latzke",
        "Jonathan Bragg",
        "Joseph Chee Chang",
        "Pao Siangliulue"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-05T04:06:07+00:00",
          "link": "https://arxiv.org/abs/2410.04025v1",
          "size": "8718kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T15:05:45+00:00",
          "link": "https://arxiv.org/abs/2410.04025v2",
          "size": "8385kb",
          "version": "v2"
        }
      ],
      "title": "IdeaSynth: Iterative Research Idea Development Through Evolving and Composing Idea Facets with Literature-Grounded Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.04025",
        "HTML": "https://arxiv.org/html/2410.04025v2",
        "PDF": "https://arxiv.org/pdf/2410.04025"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a tool for research idea development and does not make contributions to LLM training data processing or dataset engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.15842",
      "abstract": "Maritime systems, including ships and ports, are critical components of global infrastructure, essential for transporting over 80% of the world's goods and supporting internet connectivity. However, these systems face growing cybersecurity threats, as shown by recent attacks disrupting Maersk, one of the world's largest shipping companies, causing widespread impacts on international trade. The unique challenges of the maritime environment--such as diverse operational conditions, extensive physical access points, fragmented regulatory frameworks, and its deeply interconnected structure--require maritime-specific cybersecurity research. Despite the sector's importance, maritime cybersecurity remains underexplored, leaving significant gaps in understanding its challenges and risks.\n  To address these gaps, we investigate how maritime system operators perceive and navigate cybersecurity challenges within this complex landscape. We conducted a user study comprising surveys and semi-structured interviews with 21 officer-level mariners. Participants reported direct experiences with shipboard cyber-attacks, including GPS spoofing and logistics-disrupting ransomware, demonstrating the real-world impact of these threats. Our findings reveal systemic and human-centric issues, such as training poorly aligned with maritime needs, insufficient detection and response tools, and serious gaps in mariners' cybersecurity understanding. Our contributions include a categorization of threats identified by mariners and recommendations for improving maritime security, including better training, response protocols, and regulation. These insights aim to guide future research and policy to strengthen the resilience of maritime systems.",
      "authors": [
        "Anna Raymaker",
        "Akshaya Kumar",
        "Miuyin Yong Wong",
        "Ryan Pickren",
        "Animesh Chhotaray",
        "Frank Li",
        "Saman Zonouz",
        "Raheem Beyah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T19:45:35+00:00",
          "link": "https://arxiv.org/abs/2506.15842v1",
          "size": "213kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T21:31:09+00:00",
          "link": "https://arxiv.org/abs/2506.15842v2",
          "size": "213kb",
          "version": "v2"
        }
      ],
      "title": "A Sea of Cyber Threats: Maritime Cybersecurity from the Perspective of Mariners",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15842",
        "HTML": "https://arxiv.org/html/2506.15842v2",
        "PDF": "https://arxiv.org/pdf/2506.15842"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with cybersecurity in maritime systems, offering insights into mariners' perceptions of cybersecurity threats, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10903",
      "abstract": "Effective management of Service Function Chains (SFCs) and optimal Virtual Network Function (VNF) placement are critical challenges in modern Software-Defined Networking (SDN) and Network Function Virtualization (NFV) environments. Although Deep Reinforcement Learning (DRL) is widely adopted for dynamic network decision-making, its inherent dependency on structured data and fixed action rules often limits adaptability and responsiveness, particularly under unpredictable network conditions. This paper introduces LiLM-RDB-SFC, a novel approach combining Lightweight Language Model (LiLM) with Relational Database (RDB) to answer network state queries to guide DRL model for efficient SFC provisioning. Our proposed approach leverages two LiLMs, Bidirectional and Auto-Regressive Transformers (BART) and the Fine-tuned Language Net T5 (FLAN-T5), to interpret network data and support diverse query types related to SFC demands, data center resources, and VNF availability. Results demonstrate that FLAN-T5 outperforms BART with a lower test loss (0.00161 compared to 0.00734), higher accuracy (94.79% compared to 80.2%), and less processing time (2h 2min compared to 2h 38min). Moreover, when compared to the large language model SQLCoder, FLAN-T5 matches the accuracy of SQLCoder while cutting processing time by 96% (SQLCoder: 54 h 43 min; FLAN-T5: 2 h 2 min).",
      "authors": [
        "Parisa Fard Moshiri",
        "Xinyu Zhu",
        "Poonam Lohan",
        "Burak Kantarci",
        "Emil Janulewicz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T01:42:44+00:00",
          "link": "https://arxiv.org/abs/2507.10903v1",
          "size": "5070kb",
          "version": "v1"
        }
      ],
      "title": "LiLM-RDB-SFC: Lightweight Language Model with Relational Database-Guided DRL for Optimized SFC Provisioning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10903",
        "HTML": "https://arxiv.org/html/2507.10903v1",
        "PDF": "https://arxiv.org/pdf/2507.10903"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on using lightweight language models and DRL for network function provisioning. It does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11128",
      "abstract": "Large Language Models (LLMs) can memorize and reveal personal information, raising concerns regarding compliance with the EU's GDPR, particularly the Right to Be Forgotten (RTBF). Existing machine unlearning methods assume the data to forget is already known but do not address how to identify which individual-fact associations are stored in the model. Privacy auditing techniques typically operate at the population level or target a small set of identifiers, limiting applicability to individual-level data inquiries. We introduce WikiMem, a dataset of over 5,000 natural language canaries covering 243 human-related properties from Wikidata, and a model-agnostic metric to quantify human-fact associations in LLMs. Our approach ranks ground-truth values against counterfactuals using calibrated negative log-likelihood across paraphrased prompts. We evaluate 200 individuals across 15 LLMs (410M-70B parameters), showing that memorization correlates with subject web presence and model scale. We provide a foundation for identifying memorized personal data in LLMs at the individual level, enabling the dynamic construction of forget sets for machine unlearning and RTBF requests.",
      "authors": [
        "Dimitri Staufer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:28:44+00:00",
          "link": "https://arxiv.org/abs/2507.11128v1",
          "size": "83kb",
          "version": "v1"
        }
      ],
      "title": "What Should LLMs Forget? Quantifying Personal Data in LLMs for Right-to-Be-Forgotten Requests",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11128",
        "HTML": "https://arxiv.org/html/2507.11128v1",
        "PDF": "https://arxiv.org/pdf/2507.11128"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the WikiMem dataset and methods for identifying memorized personal data in LLMs, focusing on data processing for GDPR compliance and forget requests, which is central to improving LLM training data handling."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.00258",
      "abstract": "This paper offers a roadmap for the development of scalable aligned artificial intelligence (AI) from first principle descriptions of natural intelligence. In brief, a possible path toward scalable aligned AI rests upon enabling artificial agents to learn a good model of the world that includes a good model of our preferences. For this, the main objective is creating agents that learn to represent the world and other agents' world models; a problem that falls under structure learning (a.k.a. causal representation learning or model discovery). We expose the structure learning and alignment problems with this goal in mind, as well as principles to guide us forward, synthesizing various ideas across mathematics, statistics, and cognitive science. 1) We discuss the essential role of core knowledge, information geometry and model reduction in structure learning, and suggest core structural modules to learn a wide range of naturalistic worlds. 2) We outline a way toward aligned agents through structure learning and theory of mind. As an illustrative example, we mathematically sketch Asimov's Laws of Robotics, which prescribe agents to act cautiously to minimize the ill-being of other agents. We supplement this example by proposing refined approaches to alignment. These observations may guide the development of artificial intelligence in helping to scale existing -- or design new -- aligned structure learning systems.",
      "authors": [
        "Lancelot Da Costa",
        "Tom\\'a\\v{s} Gaven\\v{c}iak",
        "David Hyland",
        "Mandana Samiei",
        "Cristian Dragos-Manta",
        "Candice Pattisapu",
        "Adeel Razi",
        "Karl Friston"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-30T22:06:06+00:00",
          "link": "https://arxiv.org/abs/2410.00258v1",
          "size": "9388kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T16:05:04+00:00",
          "link": "https://arxiv.org/abs/2410.00258v2",
          "size": "6846kb",
          "version": "v2"
        }
      ],
      "title": "Possible Principles for Aligned Structure Learning Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.00258",
        "HTML": "https://arxiv.org/html/2410.00258v2",
        "PDF": "https://arxiv.org/pdf/2410.00258"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper concentrates on principles for aligned structure learning agents, without addressing LLM training data processing or engineering."
      },
      "tasks": [
        "Representation Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.23550",
      "abstract": "We find an efficient approach to approximately convert matrix product states (MPSs) into restricted Boltzmann machine wave functions consisting of a multinomial hidden unit through a canonical polyadic (CP) decomposition of the MPSs. This method allows us to generate well-behaved initial neural network quantum states for quantum many-body ground-state calculations in polynomial time of the number of variational parameters and systematically shorten the distance between the initial states and the ground states with increasing the rank of the CP decomposition. We demonstrate the efficiency of our method by taking the transverse-field Ising model as an example and discuss possible applications of our method to more general quantum many-body systems in which the ground-state wave functions possess complex nodal structures.",
      "authors": [
        "Ryui Kaneko",
        "Shimpei Goto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Strongly Correlated Electrons (cond-mat.str-el)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T06:49:31+00:00",
          "link": "https://arxiv.org/abs/2506.23550v1",
          "size": "1821kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T03:56:08+00:00",
          "link": "https://arxiv.org/abs/2506.23550v2",
          "size": "2013kb",
          "version": "v2"
        }
      ],
      "title": "Seeding neural network quantum states with tensor network states",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23550",
        "HTML": "https://arxiv.org/html/2506.23550v2",
        "PDF": "https://arxiv.org/pdf/2506.23550"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses quantum state representations through neural networks and does not address LLM training data processing or dataset construction."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10689",
      "abstract": "Traditional Low-Light Image Enhancement (LLIE) methods primarily focus on uniform brightness adjustment, often neglecting instance-level semantic information and the inherent characteristics of different features. To address these limitations, we propose CWNet (Causal Wavelet Network), a novel architecture that leverages wavelet transforms for causal reasoning. Specifically, our approach comprises two key components: 1) Inspired by the concept of intervention in causality, we adopt a causal reasoning perspective to reveal the underlying causal relationships in low-light enhancement. From a global perspective, we employ a metric learning strategy to ensure causal embeddings adhere to causal principles, separating them from non-causal confounding factors while focusing on the invariance of causal factors. At the local level, we introduce an instance-level CLIP semantic loss to precisely maintain causal factor consistency. 2) Based on our causal analysis, we present a wavelet transform-based backbone network that effectively optimizes the recovery of frequency information, ensuring precise enhancement tailored to the specific attributes of wavelet transforms. Extensive experiments demonstrate that CWNet significantly outperforms current state-of-the-art methods across multiple datasets, showcasing its robust performance across diverse scenes. Code is available at https://github.com/bywlzts/CWNet-Causal-Wavelet-Network.",
      "authors": [
        "Tongshun Zhang",
        "Pingping Liu",
        "Yubing Lu",
        "Mengen Cai",
        "Zijian Zhang",
        "Zhe Zhang",
        "Qiuzhan Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:04:37+00:00",
          "link": "https://arxiv.org/abs/2507.10689v1",
          "size": "6683kb",
          "version": "v1"
        }
      ],
      "title": "CWNet: Causal Wavelet Network for Low-Light Image Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10689",
        "HTML": "https://arxiv.org/html/2507.10689v1",
        "PDF": "https://arxiv.org/pdf/2507.10689"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus here is on low-light image enhancement using CWNet, a novel network architecture, with no discussion on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10927",
      "abstract": "Cloud storage introduces critical privacy challenges for encrypted data retrieval, where fuzzy multi-keyword search enables approximate matching while preserving data confidentiality. Existing solutions face fundamental trade-offs between security and efficiency: linear-search mechanisms provide adaptive security but incur prohibitive overhead for large-scale data, while tree-based indexes improve performance at the cost of branch leakage vulnerabilities.\n  To address these limitations, we propose DVFS - a dynamic verifiable fuzzy search service with three core innovations: (1) An \\textit{adaptive-secure fuzzy search} method integrating locality-sensitive hashing with virtual binary trees, eliminating branch leakage while reducing search complexity from linear to sublinear ($O(\\log n)$ time); (2) A \\textit{dual-repository version control} mechanism supporting dynamic updates with forward privacy, preventing information leakage during operations; (3) A \\textit{blockchain-based verification system} that ensures correctness and completeness via smart contracts, achieving $O(\\log n)$ verification complexity.\n  Our solution advances secure encrypted retrieval by simultaneously resolving the security-performance paradox and enabling trustworthy dynamic operations.",
      "authors": [
        "Jie Zhang",
        "Xiaohong Li",
        "Man Zheng",
        "Zhe Hou",
        "Guangdong Bai and Ruitao Feng"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T02:36:30+00:00",
          "link": "https://arxiv.org/abs/2507.10927v1",
          "size": "375kb",
          "version": "v1"
        }
      ],
      "title": "DVFS: A Dynamic Verifiable Fuzzy Search Service for Encrypted Cloud Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10927",
        "HTML": "https://arxiv.org/html/2507.10927v1",
        "PDF": "https://arxiv.org/pdf/2507.10927"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses encrypted cloud data retrieval and proposes methods related to secure search rather than processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11021",
      "abstract": "Autonomous vehicles must balance ranked objectives, such as minimizing travel time, ensuring safety, and coordinating with traffic. Games of ordered preference effectively model these interactions but become computationally intractable as the time horizon, number of players, or number of preference levels increase. While receding horizon frameworks mitigate long-horizon intractability by solving sequential shorter games, often warm-started, they do not resolve the complexity growth inherent in existing methods for solving games of ordered preference. This paper introduces a solution strategy that avoids excessive complexity growth by approximating solutions using lexicographic iterated best response (IBR) in receding horizon, termed \"lexicographic IBR over time.\" Lexicographic IBR over time uses past information to accelerate convergence. We demonstrate through simulated traffic scenarios that lexicographic IBR over time efficiently computes approximate-optimal solutions for receding horizon games of ordered preference, converging towards generalized Nash equilibria.",
      "authors": [
        "Pau de las Heras Molins",
        "Eric Roy-Almonacid",
        "Dong Ho Lee",
        "Lasse Peters",
        "David Fridovich-Keil",
        "and Georgios Bakirtzis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Computer Science and Game Theory (cs.GT)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T06:28:32+00:00",
          "link": "https://arxiv.org/abs/2507.11021v1",
          "size": "1284kb",
          "version": "v1"
        }
      ],
      "title": "Approximate solutions to games of ordered preference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11021",
        "PDF": "https://arxiv.org/pdf/2507.11021"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on solution strategies for games of ordered preference, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11253",
      "abstract": "Tilt stability is a fundamental concept of variational analysis and optimization that plays a pivotal role in both theoretical issues and numerical computations. This paper investigates tilt stability of local minimizers for a general class of composite optimization problems in finite dimensions, where extended-real-valued objectives are compositions of parabolically regular and smooth functions. Under the weakest metric subregularity constraint qualification and other verifiable conditions, we establish unified neighborhood and pointbased characterizations of tilt stability via second-order generalized differentiation. The obtained results provide a rigorous theoretical foundation for further developments on variational stability and numerical algorithms of optimization and related topics.",
      "authors": [
        "Boris S. Mordukhovich",
        "Peipei Tang",
        "Chengjing Wang"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:25:59+00:00",
          "link": "https://arxiv.org/abs/2507.11253v1",
          "size": "32kb",
          "version": "v1"
        }
      ],
      "title": "Second-Order Characterizations of Tilt Stability in Composite Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11253",
        "HTML": "https://arxiv.org/html/2507.11253v1",
        "PDF": "https://arxiv.org/pdf/2507.11253"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper covers optimization problem stability, with no focus or contribution related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11330",
      "abstract": "Novelty is a crucial criterion in the peer review process for evaluating academic papers. Traditionally, it's judged by experts or measure by unique reference combinations. Both methods have limitations: experts have limited knowledge, and the effectiveness of the combination method is uncertain. Moreover, it's unclear if unique citations truly measure novelty. The large language model (LLM) possesses a wealth of knowledge, while human experts possess judgment abilities that the LLM does not possess. Therefore, our research integrates the knowledge and abilities of LLM and human experts to address the limitations of novelty assessment. The most common novelty in academic papers is the introduction of new methods. In this paper, we propose leveraging human knowledge and LLM to assist pretrained language models (PLMs, e.g. BERT etc.) in predicting the method novelty of papers. Specifically, we extract sentences related to the novelty of the academic paper from peer review reports and use LLM to summarize the methodology section of the academic paper, which are then used to fine-tune PLMs. In addition, we have designed a text-guided fusion module with novel Sparse-Attention to better integrate human and LLM knowledge. We compared the method we proposed with a large number of baselines. Extensive experiments demonstrate that our method achieves superior performance.",
      "authors": [
        "Wenqing Wu",
        "Chengzhi Zhang",
        "Yi Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Digital Libraries (cs.DL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:03:55+00:00",
          "link": "https://arxiv.org/abs/2507.11330v1",
          "size": "3937kb",
          "version": "v1"
        }
      ],
      "title": "Automated Novelty Evaluation of Academic Paper: A Collaborative Approach Integrating Human and Large Language Model Knowledge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11330",
        "HTML": "https://arxiv.org/html/2507.11330v1",
        "PDF": "https://arxiv.org/pdf/2507.11330"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper leverages LLMs to improve novelty evaluation in peer review, it focuses on summarization for model fine-tuning rather than processing training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10599",
      "abstract": "As large language models (LLMs) increasingly power conversational agents, understanding how they model users' emotional states is critical for ethical deployment. Inspired by emotion wheels -- a psychological framework that argues emotions organize hierarchically -- we analyze probabilistic dependencies between emotional states in model outputs. We find that LLMs naturally form hierarchical emotion trees that align with human psychological models, and larger models develop more complex hierarchies. We also uncover systematic biases in emotion recognition across socioeconomic personas, with compounding misclassifications for intersectional, underrepresented groups. Human studies reveal striking parallels, suggesting that LLMs internalize aspects of social perception. Beyond highlighting emergent emotional reasoning in LLMs, our results hint at the potential of using cognitively-grounded theories for developing better model evaluations.",
      "authors": [
        "Bo Zhao",
        "Maya Okawa",
        "Eric J. Bigelow",
        "Rose Yu",
        "Tomer Ullman",
        "Ekdeep Singh Lubana",
        "Hidenori Tanaka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T15:12:46+00:00",
          "link": "https://arxiv.org/abs/2507.10599v1",
          "size": "25674kb",
          "version": "v1"
        }
      ],
      "title": "Emergence of Hierarchical Emotion Organization in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10599",
        "HTML": "https://arxiv.org/html/2507.10599v1",
        "PDF": "https://arxiv.org/pdf/2507.10599"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines the hierarchical emotion organization in LLM outputs, focusing on model evaluation and biases in emotion recognition without discussing training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11170",
      "abstract": "In this paper, we propose a novel learning-based robust feedback linearization strategy to ensure precise trajectory tracking for an important family of Lagrangian systems. We assume a nominal knowledge of the dynamics is given but no a-priori bounds on the model mismatch are available. In our approach, the key ingredient is the adoption of a regression framework based on Gaussian Processes (GPR) to estimate the model mismatch. This estimate is added to the outer loop of a classical feedback linearization scheme based on the nominal knowledge available. Then, to compensate for the residual uncertainty, we robustify the controller including an additional term whose size is designed based on the variance provided by the GPR framework. We proved that, with high probability, the proposed scheme is able to guarantee asymptotic tracking of a desired trajectory. We tested numerically our strategy on a 2 degrees of freedom planar robot.",
      "authors": [
        "Giulio Giacomuzzo",
        "Mohamed Abdelwahab",
        "Marco Cal\\`i",
        "Alberto Dalla Libera",
        "Ruggero Carli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:22:46+00:00",
          "link": "https://arxiv.org/abs/2507.11170v1",
          "size": "397kb",
          "version": "v1"
        }
      ],
      "title": "A Robust Controller based on Gaussian Processes for Robotic Manipulators with Unknown Uncertainty",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11170",
        "HTML": "https://arxiv.org/html/2507.11170v1",
        "PDF": "https://arxiv.org/pdf/2507.11170"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a robust control strategy for robotic manipulators, involving Gaussian Processes for uncertainty estimation, without any relevance to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02825",
      "abstract": "Benchmarks are essential for quantitatively tracking progress in AI. As AI agents become increasingly capable, researchers and practitioners have introduced agentic benchmarks to evaluate agents on complex, real-world tasks. These benchmarks typically measure agent capabilities by evaluating task outcomes via specific reward designs. However, we show that many agentic benchmarks have issues in task setup or reward design. For example, SWE-bench Verified uses insufficient test cases, while TAU-bench counts empty responses as successful. Such issues can lead to under- or overestimation of agents' performance by up to 100% in relative terms. To make agentic evaluation rigorous, we introduce the Agentic Benchmark Checklist (ABC), a set of guidelines that we synthesized from our benchmark-building experience, a survey of best practices, and previously reported issues. When applied to CVE-Bench, a benchmark with a particularly complex evaluation design, ABC reduces the performance overestimation by 33%.",
      "authors": [
        "Yuxuan Zhu",
        "Tengjun Jin",
        "Yada Pruksachatkun",
        "Andy Zhang",
        "Shu Liu",
        "Sasha Cui",
        "Sayash Kapoor",
        "Shayne Longpre",
        "Kevin Meng",
        "Rebecca Weiss",
        "Fazl Barez",
        "Rahul Gupta",
        "Jwala Dhamala",
        "Jacob Merizian",
        "Mario Giulianelli",
        "Harry Coppock",
        "Cozmin Ududec",
        "Jasjeet Sekhon",
        "Jacob Steinhardt",
        "Antony Kellerman",
        "Sarah Schwettmann",
        "Matei Zaharia",
        "Ion Stoica",
        "Percy Liang",
        "Daniel Kang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T17:35:31+00:00",
          "link": "https://arxiv.org/abs/2507.02825v1",
          "size": "671kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T21:45:08+00:00",
          "link": "https://arxiv.org/abs/2507.02825v2",
          "size": "671kb",
          "version": "v2"
        },
        {
          "date": "2025-07-10T16:42:37+00:00",
          "link": "https://arxiv.org/abs/2507.02825v3",
          "size": "671kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T18:42:56+00:00",
          "link": "https://arxiv.org/abs/2507.02825v4",
          "size": "671kb",
          "version": "v4"
        }
      ],
      "title": "Establishing Best Practices for Building Rigorous Agentic Benchmarks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02825",
        "HTML": "https://arxiv.org/html/2507.02825v4",
        "PDF": "https://arxiv.org/pdf/2507.02825"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on establishing best practices for creating agentic benchmarks, which is unrelated to LLM training data processing as it primarily addresses benchmarking methodologies."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05653",
      "abstract": "Serverless platforms such as Kubernetes are increasingly adopted in high-performance computing, yet autoscaling remains challenging under highly dynamic and heterogeneous workloads. Existing approaches often rely on uniform reactive policies or unconditioned predictive models, ignoring both workload semantics and prediction uncertainty. We present AAPA, an archetype-aware predictive autoscaler that classifies workloads into four behavioral patterns--SPIKE, PERIODIC, RAMP, and STATIONARY--and applies tailored scaling strategies with confidence-based adjustments. To support reproducible evaluation, we release AAPAset, a weakly labeled dataset of 300\\,000 Azure Functions workload windows spanning diverse patterns. AAPA reduces SLO violations by up to 50\\% and lowers latency by 40\\% compared to Kubernetes HPA, albeit at 2--8~$\\times$ higher resource usage under spike-dominated conditions. To assess trade-offs, we propose the Resource Efficiency Index (REI), a unified metric balancing performance, cost, and scaling smoothness. Our results demonstrate the importance of modeling workload heterogeneity and uncertainty in autoscaling design.",
      "authors": [
        "Guilin Zhang",
        "Srinivas Vippagunta",
        "Raghavendra Nandagopal",
        "Suchitra Raman",
        "Jeff Xu",
        "Marcus Pfeiffer",
        "Shreeshankar Chatterjee",
        "Ziqi Tan",
        "Wulan Guo",
        "and Hailong Jiang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T04:13:10+00:00",
          "link": "https://arxiv.org/abs/2507.05653v1",
          "size": "113kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T01:21:56+00:00",
          "link": "https://arxiv.org/abs/2507.05653v2",
          "size": "139kb",
          "version": "v2"
        }
      ],
      "title": "AAPA: An Archetype-Aware Predictive Autoscaler with Uncertainty Quantification for Serverless Workloads on Kubernetes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05653",
        "HTML": "https://arxiv.org/html/2507.05653v2",
        "PDF": "https://arxiv.org/pdf/2507.05653"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on autoscaling serverless workloads on Kubernetes platforms, and it introduces a dataset for evaluating autoscaling algorithms. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10136",
      "abstract": "Innate resistance to anti-PD-1 immunotherapy remains a major clinical challenge in metastatic melanoma, with the underlying molecular networks being poorly understood. To address this, we constructed a dynamic Probabilistic Boolean Network model using transcriptomic data from patient tumor biopsies to elucidate the regulatory logic governing therapy response. We then employed a reinforcement learning agent to systematically discover optimal, multi-step therapeutic interventions and used explainable artificial intelligence to mechanistically interpret the agent's control policy. The analysis revealed that a precisely timed, 4-step temporary inhibition of the lysyl oxidase like 2 protein (LOXL2) was the most effective strategy. Our explainable analysis showed that this ``hit-and-run\" intervention is sufficient to erase the molecular signature driving resistance, allowing the network to self-correct without requiring sustained intervention. This study presents a novel, time-dependent therapeutic hypothesis for overcoming immunotherapy resistance and provides a powerful computational framework for identifying non-obvious intervention protocols in complex biological systems.",
      "authors": [
        "Zhonglin Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T10:35:38+00:00",
          "link": "https://arxiv.org/abs/2507.10136v1",
          "size": "674kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T01:37:39+00:00",
          "link": "https://arxiv.org/abs/2507.10136v2",
          "size": "674kb",
          "version": "v2"
        }
      ],
      "title": "A PBN-RL-XAI Framework for Discovering a \"Hit-and-Run\" Therapeutic Strategy in Melanoma",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10136",
        "HTML": "https://arxiv.org/html/2507.10136v2",
        "PDF": "https://arxiv.org/pdf/2507.10136"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for therapeutic strategies in melanoma, which does not involve processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11401",
      "abstract": "Efficient entanglement strategies are essential for advancing variational quantum circuits (VQCs) for quantum machine learning (QML). However, most current approaches use fixed entanglement topologies that are not adaptive to task requirements, limiting potential gains over classical models. We introduce a novel stochastic entanglement configuration method that systematically generates diverse entanglement topologies to identify a subspace of constructive entanglement configurations, defined as entanglement topologies that boost hybrid model performance (e.g., classification accuracy) beyond classical baselines. Each configuration is encoded as a stochastic binary matrix, denoting directed entanglement between qubits. This enables scalable exploration of the hyperspace of candidate entanglement topologies using entanglement density and per-qubit constraints as key metrics. We define unconstrained and constrained sampling modes, controlling entanglement per qubit. Using our method, 400 stochastic configurations were generated and evaluated in a hybrid QML for cardiac MRI disease classification. We identified 64 (16%) novel constructive entanglement configurations that consistently outperformed the classical baseline. Ensemble aggregation of top-performing configurations achieved ~0.92 classification accuracy, exceeding the classical model (~0.87) by over 5%. Compared to four conventional topologies (ring, nearest neighbor, no entanglement, fully entangled), none surpassed the classical baseline (maximum accuracy ~0.82), while our configurations delivered up to ~20% higher accuracy. Thus, highlighting the robustness and generalizability of the identified constructive entanglements.",
      "authors": [
        "Mehri Mehrnia and Mohammed S.M. Elbaz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:12:59+00:00",
          "link": "https://arxiv.org/abs/2507.11401v1",
          "size": "23669kb",
          "version": "v1"
        }
      ],
      "title": "Stochastic Entanglement Configuration for Constructive Entanglement Topologies in Quantum Machine Learning with Application to Cardiac MRI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11401",
        "PDF": "https://arxiv.org/pdf/2507.11401"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on quantum machine learning and entanglement strategies, which do not involve any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.07040",
      "abstract": "Low-light image enhancement, particularly in cross-domain tasks such as mapping from the raw domain to the sRGB domain, remains a significant challenge. Many deep learning-based methods have been developed to address this issue and have shown promising results in recent years. However, single-stage methods, which attempt to unify the complex mapping across both domains, leading to limited denoising performance. In contrast, existing two-stage approaches typically overlook the characteristic of demosaicing within the Image Signal Processing (ISP) pipeline, leading to color distortions under varying lighting conditions, especially in low-light scenarios. To address these issues, we propose a novel Mamba-based method customized for low light RAW images, called RAWMamba, to effectively handle raw images with different CFAs. Furthermore, we introduce a Retinex Decomposition Module (RDM) grounded in Retinex prior, which decouples illumination from reflectance to facilitate more effective denoising and automatic non-linear exposure correction, reducing the effect of manual linear illumination enhancement. By bridging demosaicing and denoising, better enhancement for low light RAW images is achieved. Experimental evaluations conducted on public datasets SID and MCR demonstrate that our proposed RAWMamba achieves state-of-the-art performance on cross-domain mapping. The code is available at https://github.com/Cynicarlos/RetinexRawMamba.",
      "authors": [
        "Xianmin Chen",
        "Longfei Han",
        "Peiliang Huang",
        "Xiaoxu Feng",
        "Dingwen Zhang",
        "Junwei Han"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-11T06:12:03+00:00",
          "link": "https://arxiv.org/abs/2409.07040v1",
          "size": "713kb",
          "version": "v1"
        },
        {
          "date": "2024-12-12T07:52:56+00:00",
          "link": "https://arxiv.org/abs/2409.07040v2",
          "size": "763kb",
          "version": "v2"
        },
        {
          "date": "2024-12-13T04:00:36+00:00",
          "link": "https://arxiv.org/abs/2409.07040v3",
          "size": "754kb",
          "version": "v3"
        },
        {
          "date": "2024-12-31T06:53:38+00:00",
          "link": "https://arxiv.org/abs/2409.07040v4",
          "size": "752kb",
          "version": "v4"
        },
        {
          "date": "2025-07-15T07:22:36+00:00",
          "link": "https://arxiv.org/abs/2409.07040v5",
          "size": "3087kb",
          "version": "v5"
        }
      ],
      "title": "Retinex-RAWMamba: Bridging Demosaicing and Denoising for Low-Light RAW Image Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.07040",
        "HTML": "https://arxiv.org/html/2409.07040v5",
        "PDF": "https://arxiv.org/pdf/2409.07040"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is aimed at enhancing low-light raw images based on demosaicing and denoising techniques, not related to any aspect of LLM training data processing."
      },
      "tasks": [
        "Demosaicking",
        "Denoising",
        "Exposure Correction",
        "Image Enhancement",
        "Low-Light Image Enhancement",
        "Mamba"
      ],
      "repo_urls": [
        "https://github.com/cynicarlos/retinexrawmamba"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.08193",
      "abstract": "The lack of high-quality public cyber incident data limits empirical research and predictive modeling for cyber risk assessment. This challenge persists due to the reluctance of companies to disclose incidents that could damage their reputation or investor confidence. Therefore, from an actuarial perspective, potential resolutions conclude two aspects: the enhancement of existing cyber incident datasets and the implementation of advanced modeling techniques to optimize the use of the available data. A review of existing data-driven methods highlights a significant lack of entity-specific organizational features in publicly available datasets. To address this gap, we propose a novel InsurTech framework that enriches cyber incident data with entity-specific attributes. We develop various machine learning (ML) models: a multilabel classification model to predict the occurrence of cyber incident types (e.g., Privacy Violation, Data Breach, Fraud and Extortion, IT Error, and Others) and a multioutput regression model to estimate their annual frequencies. While classifier and regressor chains are implemented to explore dependencies among cyber incident types as well, no significant correlations are observed in our datasets. Besides, we apply multiple interpretable ML techniques to identify and cross-validate potential risk factors developed by InsurTech across ML models. We find that InsurTech empowered features enhance prediction occurrence and frequency estimation robustness compared to only using conventional risk factors. The framework generates transparent, entity-specific cyber risk profiles, supporting customized underwriting and proactive cyber risk mitigation. It provides insurers and organizations with data-driven insights to support decision-making and compliance planning.",
      "authors": [
        "Jiayi Guo",
        "Zhiyu Quan",
        "and Linfeng Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Risk Management (q-fin.RM)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T22:04:00+00:00",
          "link": "https://arxiv.org/abs/2507.08193v1",
          "size": "4323kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T22:21:11+00:00",
          "link": "https://arxiv.org/abs/2507.08193v2",
          "size": "4323kb",
          "version": "v2"
        }
      ],
      "title": "Entity-Specific Cyber Risk Assessment using InsurTech Empowered Risk Factors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08193",
        "HTML": "https://arxiv.org/html/2507.08193v2",
        "PDF": "https://arxiv.org/pdf/2507.08193"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses enhancing cyber incident datasets with entity-specific attributes, it does not directly address LLM training data processing but mentions dataset enhancement which is tangentially related."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11289",
      "abstract": "In the quest for highest performance in scientific computing, we present a novel framework that relies on high-bandwidth communication between GPUs in a compute cluster. The framework offers linear scaling of performance for explicit algorithms that is only limited by the size of the dataset and the number of GPUs. Slices of the dataset propagate in a ring of processes (GPUs) from one GPU, where they are processed, to the next, which results in a parallel-in-time parallelization. The user of the framework has to write GPU kernels that implement the algorithm and provide slices of the dataset. Knowledge about the underlying parallelization strategy is not required because the communication between processes is carried out by the framework. As a case study, molecular dynamics simulation based on the Lennard-Jones potential is implemented to measure the performance for a homogeneous fluid. Single node performance and strong scaling behavior of this framework is compared to LAMMPS, which is outperformed in the strong scaling case.",
      "authors": [
        "Martin Rose",
        "Simon Homes",
        "Lukas Ramsperger",
        "Jose Gracia",
        "Christoph Niethammer and Jadran Vrabec"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:13:48+00:00",
          "link": "https://arxiv.org/abs/2507.11289v1",
          "size": "99kb",
          "version": "v1"
        }
      ],
      "title": "Cyclic Data Streaming on GPUs for Short Range Stencils Applied to Molecular Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11289",
        "HTML": "https://arxiv.org/html/2507.11289v1",
        "PDF": "https://arxiv.org/pdf/2507.11289"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a GPU-based framework for parallelizing scientific computations, particularly within molecular dynamics simulations, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11292",
      "abstract": "The proliferation of hate speech has inflicted significant societal harm, with its intensity and directionality closely tied to specific targets and arguments. In recent years, numerous machine learning-based methods have been developed to detect hateful comments on online platforms automatically. However, research on Chinese hate speech detection lags behind, and interpretability studies face two major challenges: first, the scarcity of span-level fine-grained annotated datasets limits models' deep semantic understanding of hate speech; second, insufficient research on identifying and interpreting coded hate speech restricts model explainability in complex real-world scenarios. To address these, we make the following contributions: (1) We introduce the Span-level Target-Aware Toxicity Extraction dataset (STATE ToxiCN), the first span-level Chinese hate speech dataset, and evaluate the hate semantic understanding of existing models using it. (2) We conduct the first comprehensive study on Chinese coded hate terms, LLMs' ability to interpret hate semantics. (3) We propose a method to integrate an annotated lexicon into models, significantly enhancing hate speech detection performance. Our work provides valuable resources and insights to advance the interpretability of Chinese hate speech detection research.",
      "authors": [
        "Zewen Bai",
        "Liang Yang",
        "Shengdi Yin",
        "Yuanyuan Sun",
        "Hongfei Lin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:19:18+00:00",
          "link": "https://arxiv.org/abs/2507.11292v1",
          "size": "83kb",
          "version": "v1"
        }
      ],
      "title": "Fine-Grained Chinese Hate Speech Understanding: Span-Level Resources, Coded Term Lexicon, and Enhanced Detection Frameworks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11292",
        "HTML": "https://arxiv.org/html/2507.11292v1",
        "PDF": "https://arxiv.org/pdf/2507.11292"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the first span-level Chinese hate speech dataset and describes methods for enhancing dataset quality and interpretability for LLMs, clearly contributing to dataset creation and processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11417",
      "abstract": "The environmental impact of Large Language Models (LLMs) is rising significantly, with inference now accounting for more than half of their total lifecycle carbon emissions. However, existing simulation frameworks, which are increasingly used to determine efficient LLM deployments, lack any concept of power and, therefore, cannot accurately estimate inference-related emissions. We present a simulation framework to assess the energy and carbon implications of LLM inference under varying deployment setups. First, we extend a high-fidelity LLM inference simulator with a GPU power model that estimates power consumption based on utilization metrics, enabling analysis across configurations like batch size, sequence length, and model parallelism. Second, we integrate simulation outputs into an energy system co-simulation environment to quantify carbon emissions under specific grid conditions and explore the potential of carbon-aware scheduling. Through scenario-based analysis, our framework reveals how inference parameters affect energy demand and carbon footprint, demonstrates a renewable offset potential of up to 69.2% in an illustrative deployment case, and provides a foundation for future carbon-aware inference infrastructure design.",
      "authors": [
        "Miray \\\"Ozcan",
        "Philipp Wiesner",
        "Philipp Wei{\\ss}",
        "Odej Kao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:44:03+00:00",
          "link": "https://arxiv.org/abs/2507.11417v1",
          "size": "1048kb",
          "version": "v1"
        }
      ],
      "title": "Quantifying the Energy Consumption and Carbon Emissions of LLM Inference via Simulations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11417",
        "HTML": "https://arxiv.org/html/2507.11417v1",
        "PDF": "https://arxiv.org/pdf/2507.11417"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on quantifying energy consumption and carbon emissions of LLM inference with no mention of data processing or improvement of LLM training data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2307.08827",
      "abstract": "We initiate the study of Bayesian conversations, which model interactive communication between two strategic agents without a mediator. We compare this to communication through a mediator and investigate the settings in which a mediation can expand the range of implementable outcomes.\n  We look into the eventual outcome of two-player games after interactive communication. We focus on games where only one agent has a non-trivial action and examine the performance of communication protocols that are individually rational (IR) for both parties. We characterize the structure of the social-welfare optimal protocol of a given number of rounds and thus show a separation between Bayesian conversation and mediated protocols. We demonstrate an example where the optimal conversation protocol requires infinitely many rounds of communication, and further show that for settings with binary actions and binary types, any optimal protocol either is finite (with at most 6 rounds) or requires infinitely many rounds of communication.",
      "authors": [
        "Renato Paes Leme",
        "Jon Schneider",
        "Heyang Shang",
        "Shuran Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-17T20:42:52+00:00",
          "link": "https://arxiv.org/abs/2307.08827v1",
          "size": "39kb",
          "version": "v1"
        },
        {
          "date": "2023-09-18T18:31:58+00:00",
          "link": "https://arxiv.org/abs/2307.08827v2",
          "size": "40kb",
          "version": "v2"
        },
        {
          "date": "2025-02-12T05:55:01+00:00",
          "link": "https://arxiv.org/abs/2307.08827v3",
          "size": "80kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T14:51:16+00:00",
          "link": "https://arxiv.org/abs/2307.08827v4",
          "size": "93kb",
          "version": "v4"
        }
      ],
      "title": "Bayesian Conversations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.08827",
        "PDF": "https://arxiv.org/pdf/2307.08827"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research on Bayesian conversations does not pertain to the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11272",
      "abstract": "This paper presents MARAUS (Multi-Agent and Retrieval-Augmented University Admission System), a real-world deployment of a conversational AI platform for higher education admissions counseling in Vietnam. While large language models (LLMs) offer potential for automating advisory tasks, most existing solutions remain limited to prototypes or synthetic benchmarks. MARAUS addresses this gap by combining hybrid retrieval, multi-agent orchestration, and LLM-based generation into a system tailored for real-world university admissions. In collaboration with the University of Transport Technology (UTT) in Hanoi, we conducted a two-phase study involving technical development and real-world evaluation. MARAUS processed over 6,000 actual user interactions, spanning six categories of queries. Results show substantial improvements over LLM-only baselines: on average 92 percent accuracy, hallucination rates reduced from 15 precent to 1.45 percent, and average response times below 4 seconds. The system operated cost-effectively, with a two-week deployment cost of 11.58 USD using GPT-4o mini. This work provides actionable insights for the deployment of agentic RAG systems in low-resource educational settings.",
      "authors": [
        "Anh Nguyen-Duc",
        "Chien Vu Manh",
        "Bao Anh Tran",
        "Viet Phuong Ngo",
        "Luan Le Chi and Anh Quang Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:49:42+00:00",
          "link": "https://arxiv.org/abs/2507.11272v1",
          "size": "834kb",
          "version": "v1"
        }
      ],
      "title": "An Empirical Study of Multi-Agent RAG for Real-World University Admissions Counseling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11272",
        "HTML": "https://arxiv.org/html/2507.11272v1",
        "PDF": "https://arxiv.org/pdf/2507.11272"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about deploying a conversational AI platform for university admissions. It does not describe any process related to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11457",
      "abstract": "Accurate preoperative assessment of lymph node (LN) metastasis in rectal cancer guides treatment decisions, yet conventional MRI evaluation based on morphological criteria shows limited diagnostic performance. While some artificial intelligence models have been developed, they often operate as black boxes, lacking the interpretability needed for clinical trust. Moreover, these models typically evaluate nodes in isolation, overlooking the patient-level context. To address these limitations, we introduce LRMR, an LLM-Driven Relational Multi-node Ranking framework. This approach reframes the diagnostic task from a direct classification problem into a structured reasoning and ranking process. The LRMR framework operates in two stages. First, a multimodal large language model (LLM) analyzes a composite montage image of all LNs from a patient, generating a structured report that details ten distinct radiological features. Second, a text-based LLM performs pairwise comparisons of these reports between different patients, establishing a relative risk ranking based on the severity and number of adverse features. We evaluated our method on a retrospective cohort of 117 rectal cancer patients. LRMR achieved an area under the curve (AUC) of 0.7917 and an F1-score of 0.7200, outperforming a range of deep learning baselines, including ResNet50 (AUC 0.7708). Ablation studies confirmed the value of our two main contributions: removing the relational ranking stage or the structured prompting stage led to a significant performance drop, with AUCs falling to 0.6875 and 0.6458, respectively. Our work demonstrates that decoupling visual perception from cognitive reasoning through a two-stage LLM framework offers a powerful, interpretable, and effective new paradigm for assessing lymph node metastasis in rectal cancer.",
      "authors": [
        "Yaoxian Dong",
        "Yifan Gao",
        "Haoyue Li",
        "Yanfen Cui",
        "and Xin Gao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:29:45+00:00",
          "link": "https://arxiv.org/abs/2507.11457v1",
          "size": "508kb",
          "version": "v1"
        }
      ],
      "title": "LRMR: LLM-Driven Relational Multi-node Ranking for Lymph Node Metastasis Assessment in Rectal Cancer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11457",
        "HTML": "https://arxiv.org/html/2507.11457v1",
        "PDF": "https://arxiv.org/pdf/2507.11457"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While this paper employs a large language model for structured reasoning in medical diagnosis, it does not focus primarily on LLM training data processing, creation, or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.17787",
      "abstract": "Tabular machine learning problems often require time-consuming and labor-intensive feature engineering. Recent efforts have focused on using large language models (LLMs) to capitalize on their potential domain knowledge. At the same time, researchers have observed ethically concerning negative biases in other LLM-related use cases, such as text generation. These developments motivated us to investigate whether LLMs exhibit a bias that negatively impacts the performance of feature engineering. While not ethically concerning, such a bias could hinder practitioners from fully utilizing LLMs for automated data science. Therefore, we propose a method to detect potential biases by detecting anomalies in the frequency of operators (e.g., adding two features) suggested by LLMs when engineering new features. Our experiments evaluate the bias of four LLMs, two big frontier and two small open-source models, across 27 tabular datasets. Our results indicate that LLMs are biased toward simple operators, such as addition, and can fail to utilize more complex operators, such as grouping followed by aggregations. Furthermore, the bias can negatively impact the predictive performance when using LLM-generated features. Our results call for mitigating bias when using LLMs for feature engineering.",
      "authors": [
        "Jaris K\\\"uken",
        "Lennart Purucker",
        "Frank Hutter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-23T11:37:20+00:00",
          "link": "https://arxiv.org/abs/2410.17787v1",
          "size": "614kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T17:21:32+00:00",
          "link": "https://arxiv.org/abs/2410.17787v2",
          "size": "696kb",
          "version": "v2"
        }
      ],
      "title": "Large Language Models Engineer Too Many Simple Features For Tabular Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.17787",
        "HTML": "https://arxiv.org/html/2410.17787v2",
        "PDF": "https://arxiv.org/pdf/2410.17787"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses using LLMs for feature engineering in tabular data, which relates to bias detection in LLM-generated data features, a peripheral aspect of data processing."
      },
      "tasks": [
        "Feature Engineering",
        "Text Generation"
      ],
      "repo_urls": [
        "https://github.com/automl/llms_feature_engineering_bias"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.02820",
      "abstract": "Compound AI systems, such as agentic systems, are an emerging trend in large-scale enterprise settings, with multiple LLMs specialized for different users, tasks, and/or roles working together. In these scenarios, different models often process inputs that share the same context prefix. Although much work was done in the past to enable the reuse of prefix KV caches across inputs for a single model, how to enable one model to reuse the prefix KV caches of a different model remains an open question.\n  We introduce DroidSpeak, the first distributed LLM inference system that enables KV cache reuse across distributed nodes running inference of different LLMs, so long as the LLMs have the same architecture. We present the first study that aims at understanding the impact of sharing KV caches across different LLMs, and if/when such sharing affects quality. Inspired by the findings, we present DroidSpeak, which selectively recomputes a few layers of the KV cache produced by another LLM and reuses the remaining layers, with negligible quality loss. Moreover, carefully pipelining the layer-wise re-computation and the loading of reused KV cache further improves the inference performance. Experiments on diverse datasets and model pairs demonstrate that DroidSpeak achieves up to 4x throughput improvement and about 3.1x faster prefill (time to first token), with negligible loss of quality in F1 scores, Rouge-L or code similarity score, compared to the baseline which does not allow any sharing across models.",
      "authors": [
        "Yuhan Liu",
        "Yuyang Huang",
        "Jiayi Yao",
        "Shaoting Feng",
        "Zhuohan Gu",
        "Kuntai Du",
        "Hanchen Li",
        "Yihua Cheng",
        "Junchen Jiang",
        "Shan Lu",
        "Madan Musuvathi",
        "Esha Choukse"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-05T05:41:41+00:00",
          "link": "https://arxiv.org/abs/2411.02820v1",
          "size": "1760kb",
          "version": "v1"
        },
        {
          "date": "2024-12-13T17:53:25+00:00",
          "link": "https://arxiv.org/abs/2411.02820v2",
          "size": "7038kb",
          "version": "v2"
        },
        {
          "date": "2024-12-19T23:52:16+00:00",
          "link": "https://arxiv.org/abs/2411.02820v3",
          "size": "7040kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T18:22:53+00:00",
          "link": "https://arxiv.org/abs/2411.02820v4",
          "size": "873kb",
          "version": "v4"
        }
      ],
      "title": "DroidSpeak: KV Cache Sharing for Cross-LLM Communication and Multi-LLM Serving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.02820",
        "HTML": "https://arxiv.org/html/2411.02820v4",
        "PDF": "https://arxiv.org/pdf/2411.02820"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses KV cache sharing for improving inference performance across LLMs, but does not focus on LLM training data processing, collection, or engineering."
      },
      "tasks": [
        "Computational Efficiency"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.08542",
      "abstract": "Conventional automated decision-support systems, often based on supervised learning, focus on predicting outcomes to recommend actions. However, they typically overlook the complexity of multi-actor environments, where diverse and conflicting stakeholder preferences must be balanced. At the same time, participatory AI approaches remain largely context-specific, limiting their broader applicability. To address these gaps, we propose a participatory framework that reframes decision-making as a multi-stakeholder optimization problem, using context-dependent reward functions to represent each actor's preferences. Our modular, model-agnostic framework employs k-fold cross-validation to fine-tune user-provided prediction models and evaluate decision strategies, including compromise functions that mediate stakeholder trade-offs. A synthetic scoring mechanism aggregates user-defined preferences across multiple metrics to rank strategies and select an optimal decision-maker for generating actionable recommendations on new data. Validated on two high-stake real-world case studies, the framework consistently produces stakeholder-aware decisions that outperform purely predictive baselines across multiple metrics, while enhancing the transparency and accountability of AI-supported decision-making.",
      "authors": [
        "Vittoria Vineis",
        "Giuseppe Perelli",
        "Gabriele Tolomei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-12T16:27:40+00:00",
          "link": "https://arxiv.org/abs/2502.08542v1",
          "size": "2568kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T14:22:31+00:00",
          "link": "https://arxiv.org/abs/2502.08542v2",
          "size": "753kb",
          "version": "v2"
        }
      ],
      "title": "Beyond Predictions: A Participatory Framework for Multi-Stakeholder Decision-Making",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.08542",
        "HTML": "https://arxiv.org/html/2502.08542v2",
        "PDF": "https://arxiv.org/pdf/2502.08542"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on a participatory framework for decision-making in multi-stakeholder environments, rather than processing or creating LLM training data."
      },
      "tasks": [
        "Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.04311",
      "abstract": "High-speed ground robots moving on unstructured terrains generate intense high-frequency vibrations, leading to LiDAR scan distortions in Lidar-inertial odometry (LIO). Accurate and efficient undistortion is extremely challenging due to (1) rapid and non-smooth state changes during intense vibrations and (2) unpredictable IMU noise coupled with a limited IMU sampling frequency. To address this issue, this paper introduces post-undistortion uncertainty. First, we model the undistortion errors caused by linear and angular vibrations and assign post-undistortion uncertainty to each point. We then leverage this uncertainty to guide point-to-map matching, compute uncertainty-aware residuals, and update the odometry states using an iterated Kalman filter. We conduct vibration-platform and mobile-platform experiments on multiple public datasets as well as our own recordings, demonstrating that our method achieves better performance than other methods when LiDAR undergoes intense vibration.",
      "authors": [
        "Yan Dong",
        "Enci Xu",
        "Shaoqiang Qiu",
        "Wenxuan Li",
        "Yang Liu",
        "Bin Han"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-06T09:35:58+00:00",
          "link": "https://arxiv.org/abs/2507.04311v1",
          "size": "2116kb",
          "version": "v1"
        }
      ],
      "title": "Vibration-aware Lidar-Inertial Odometry based on Point-wise Post-Undistortion Uncertainty",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04311",
        "HTML": "https://arxiv.org/html/2507.04311",
        "PDF": "https://arxiv.org/pdf/2507.04311"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses improvements in Lidar-inertial odometry under high-frequency vibrations, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11005",
      "abstract": "We propose AdaMuon, an adaptive learning-rate framework built upon the recently validated Muon optimizer, which has demonstrated substantial efficiency gains over AdamW in large-scale model training. AdaMuon augments Muon with two mutually dependent modules: (1) a per-parameter second-moment modulation that captures orthogonal gradient updates to ensure update-level adaptivity, and (2) a RMS-aligned rescaling that regulates the overall update magnitude by aligning it with the intrinsic structure of the parameter space. Empirical results on multiple model scales and learning-rate regimes confirm that AdaMuon consistently outperforms the original Muon, delivering higher acceleration in convergence while maintaining training stability. Our method introduces no additional tuning burden and can be seamlessly integrated into existing Muon training pipelines.",
      "authors": [
        "Chongjie Si",
        "Debing Zhang",
        "Wei Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T05:49:37+00:00",
          "link": "https://arxiv.org/abs/2507.11005v1",
          "size": "13829kb",
          "version": "v1"
        }
      ],
      "title": "AdaMuon: Adaptive Muon Optimizer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11005",
        "HTML": "https://arxiv.org/html/2507.11005v1",
        "PDF": "https://arxiv.org/pdf/2507.11005"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the AdaMuon optimizer for improving learning rates and training stability. It does not discuss LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11470",
      "abstract": "This paper introduces REVA, a human-AI system that expedites instructor review of voluminous AI-generated programming feedback by sequencing submissions to minimize cognitive context shifts and propagating instructor-driven revisions across semantically similar instances. REVA introduces a novel approach to human-AI collaboration in educational feedback by adaptively learning from instructors' attention in the review and revision process to continuously improve the feedback validation process. REVA's usefulness and effectiveness in improving feedback quality and the overall feedback review process were evaluated through a within-subjects lab study with 12 participants.",
      "authors": [
        "Xiaohang Tang",
        "Sam Wong",
        "Zicheng He",
        "Yalong Yang",
        "Yan Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:41:29+00:00",
          "link": "https://arxiv.org/abs/2507.11470v1",
          "size": "8917kb",
          "version": "v1"
        }
      ],
      "title": "REVA: Supporting LLM-Generated Programming Feedback Validation at Scale Through User Attention-based Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11470",
        "HTML": "https://arxiv.org/html/2507.11470v1",
        "PDF": "https://arxiv.org/pdf/2507.11470"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving human-AI collaboration for feedback validation in educational contexts, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.04614",
      "abstract": "The adoption of Artificial Intelligence in medical imaging holds great promise, yet it remains hindered by challenges such as data scarcity, privacy concerns, and the need for robust multimodal integration. While recent advances in generative modeling have enabled high-quality synthetic data generation, existing approaches are often limited to unimodal, unidirectional synthesis and therefore lack the ability to jointly synthesize multiple modalities while preserving clinical consistency. To address this challenge, we introduce XGeM, a 6.77-billion-parameter multimodal generative model designed to support flexible, any-to-any synthesis between medical data modalities. XGeM constructs a shared latent space via contrastive learning and introduces a novel Multi-Prompt Training strategy, enabling conditioning on arbitrary subsets of input modalities. This design allows the model to adapt to heterogeneous clinical inputs and generate multiple outputs jointly, preserving both semantic and structural coherence. We extensively validate XGeM: first we benchmark it against five competitors on the MIMIC-CXR dataset, a state-of-the-art dataset for multi-view Chest X-ray and radiological report generation. Secondly, we perform a Visual Turing Test with expert radiologists to assess the realism and clinical relevance of the generated data, ensuring alignment with real-world scenarios. Finally, we show how XGeM can support key medical data challenges such as anonymization, class imbalance, and data scarcity, underscoring its utility as a foundation model for medical data synthesis. Project page is at https://cosbidev.github.io/XGeM/.",
      "authors": [
        "Daniele Molino and Francesco Di Feola and Eliodoro Faiella and Deborah Fazzini and Domiziana Santucci and Linlin Shen and Valerio Guarrasi and Paolo Soda"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-08T16:53:56+00:00",
          "link": "https://arxiv.org/abs/2501.04614v1",
          "size": "1094kb",
          "version": "v1"
        },
        {
          "date": "2025-01-09T08:42:56+00:00",
          "link": "https://arxiv.org/abs/2501.04614v2",
          "size": "1094kb",
          "version": "v2"
        },
        {
          "date": "2025-07-03T07:57:05+00:00",
          "link": "https://arxiv.org/abs/2501.04614v3",
          "size": "7290kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T20:16:08+00:00",
          "link": "https://arxiv.org/abs/2501.04614v4",
          "size": "7290kb",
          "version": "v4"
        }
      ],
      "title": "XGeM: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.04614",
        "HTML": "https://arxiv.org/html/2501.04614v4",
        "PDF": "https://arxiv.org/pdf/2501.04614"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on multimodal data generation in medical imaging using a model called XGeM and evaluates its performance against existing datasets without detailing the processing of training data for LLMs."
      },
      "tasks": [
        "Contrastive Learning",
        "Diagnostic"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.00959",
      "abstract": "The Riemann zeta function, and more generally the L-functions of Dirichlet characters, are among the central objects of study in number theory. We report on a project to formalize the theory of these objects in Lean's \"Mathlib\" library, including a proof of Dirichlet's theorem on primes in arithmetic progressions and a formal statement of the Riemann hypothesis",
      "authors": [
        "David Loeffler and Michael Stoll"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Number Theory (math.NT)",
        "Formal Languages and Automata Theory (cs.FL)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-02T16:53:20+00:00",
          "link": "https://arxiv.org/abs/2503.00959v1",
          "size": "11kb",
          "version": "v1"
        },
        {
          "date": "2025-03-05T17:05:01+00:00",
          "link": "https://arxiv.org/abs/2503.00959v2",
          "size": "12kb",
          "version": "v2"
        },
        {
          "date": "2025-06-12T15:16:29+00:00",
          "link": "https://arxiv.org/abs/2503.00959v3",
          "size": "12kb",
          "version": "v3"
        },
        {
          "date": "2025-06-25T20:10:42+00:00",
          "link": "https://arxiv.org/abs/2503.00959v4",
          "size": "435kb",
          "version": "v4"
        }
      ],
      "title": "Formalizing zeta and L-functions in Lean",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00959",
        "HTML": "https://arxiv.org/html/2503.00959",
        "PDF": "https://arxiv.org/pdf/2503.00959"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about formalizing mathematical functions in the Lean library, which is unrelated to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.01550",
      "abstract": "Large Language Models (LLMs) have emerged as powerful tools, but their inherent safety risks - ranging from harmful content generation to broader societal harms - pose significant challenges. These risks can be amplified by the recent adversarial attacks, fine-tuning vulnerabilities, and the increasing deployment of LLMs in high-stakes environments. Existing safety-enhancing techniques, such as fine-tuning with human feedback or adversarial training, are still vulnerable as they address specific threats and often fail to generalize across unseen attacks, or require manual system-level defenses. This paper introduces RepBend, a novel approach that fundamentally disrupts the representations underlying harmful behaviors in LLMs, offering a scalable solution to enhance (potentially inherent) safety. RepBend brings the idea of activation steering - simple vector arithmetic for steering model's behavior during inference - to loss-based fine-tuning. Through extensive evaluation, RepBend achieves state-of-the-art performance, outperforming prior methods such as Circuit Breaker, RMU, and NPO, with up to 95% reduction in attack success rates across diverse jailbreak benchmarks, all with negligible reduction in model usability and general capabilities.",
      "authors": [
        "Ashkan Yousefpour",
        "Taeheon Kim",
        "Ryan S. Kwon",
        "Seungbeen Lee",
        "Wonje Jeung",
        "Seungju Han",
        "Alvin Wan",
        "Harrison Ngan",
        "Youngjae Yu",
        "Jonghyun Choi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-02T09:47:01+00:00",
          "link": "https://arxiv.org/abs/2504.01550v1",
          "size": "3343kb",
          "version": "v1"
        },
        {
          "date": "2025-06-09T12:56:47+00:00",
          "link": "https://arxiv.org/abs/2504.01550v2",
          "size": "3554kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T02:52:56+00:00",
          "link": "https://arxiv.org/abs/2504.01550v3",
          "size": "3578kb",
          "version": "v3"
        }
      ],
      "title": "Representation Bending for Large Language Model Safety",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.01550",
        "HTML": "https://arxiv.org/html/2504.01550v3",
        "PDF": "https://arxiv.org/pdf/2504.01550"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper addresses LLM safety through representation transformation techniques and mentions fine-tuning but centers on the model's safety, not on the training data processing."
      },
      "models": [
        {
          "model_path": "thkim0305/RepBend_Mistral_7B_LoRA",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/thkim0305/RepBend_Mistral_7B_LoRA"
        }
      ],
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "model"
      ],
      "repo_urls": [
        "https://github.com/aim-intelligence/repbend",
        "https://github.com/samuelsimko/crl-llm-defense"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07565",
      "abstract": "This paper studies privacy-sensitive federated learning (FL) under unreliable communication, with a focus on secure aggregation and straggler mitigation. To preserve user privacy without compromising the utility of the global model, secure aggregation emerges as a promising approach by coordinating the use of privacy-preserving noise (secret keys) across participating clients. However, the unreliable communication will randomly disrupt the key coordination and disable the exact recovery of the global model in secure aggregation. Furthermore, unreliable communication can distort the optimization trajectory, causing the global model to deviate further from the intended global optimum.To address these challenges, we propose Secure Cooperative Gradient Coding (SecCoGC), a practical solution that achieves accurate aggregation with arbitrarily strong privacy guarantees and is inherently robust to communication uncertainties. To ensure fairness in privacy protection, we further introduce Fair-SecCoGC, an extension of SecCoGC that enforces equitable privacy preservation across all clients. Notably, Fair-SecCoGC achieves optimal privacy under a per-key total power constraint. We formally formulate the problem of secure aggregation in the real field and present both general and computationally efficient methods for secret key construction. Our privacy analysis covers both Local Mutual Information Privacy (LMIP) and Local Differential Privacy (LDP) across all protocol layers, accounting for intermittent networks and correlation among secret keys. In addition, we characterize the system reliability and convergence properties of the proposed scheme. Experimental results demonstrate that SecCoGC achieves strong resilience to unreliable communication while maintaining arbitrarily strong privacy guarantees, yielding test accuracy improvements of 20% to 70% over existing privacy-preserving methods.",
      "authors": [
        "Shudi Weng",
        "Chao Ren",
        "Yizhou Zhao",
        "Ming Xiao",
        "Mikael Skoglund"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:10:03+00:00",
          "link": "https://arxiv.org/abs/2507.07565v1",
          "size": "16kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T16:32:21+00:00",
          "link": "https://arxiv.org/abs/2507.07565v2",
          "size": "461kb",
          "version": "v2"
        }
      ],
      "title": "Secure Cooperative Gradient Coding: Optimality, Reliability, and Global Privacy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07565",
        "HTML": "https://arxiv.org/html/2507.07565v2",
        "PDF": "https://arxiv.org/pdf/2507.07565"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with secure federated learning and privacy in unreliable communication settings, with no connection to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10262",
      "abstract": "Retrieving cohesive subgraphs in networks is a fundamental problem in social network analysis and graph data management. These subgraphs can be used for marketing strategies or recommendation systems. Despite the introduction of numerous models over the years, a systematic comparison of their performance, especially across varied network configurations, remains unexplored. In this study, we evaluated various cohesive subgraph models using task-based evaluations and conducted extensive experimental studies on both synthetic and real-world networks. Thus, we unveil the characteristics of cohesive subgraph models, highlighting their efficiency and applicability. Our findings not only provide a detailed evaluation of current models but also lay the groundwork for future research by shedding light on the balance between the interpretability and cohesion of the subgraphs. This research guides the selection of suitable models for specific analytical needs and applications, providing valuable insights.",
      "authors": [
        "Dahee Kim",
        "Song Kim",
        "Jeongseon Kim",
        "Junghoon Kim",
        "Kaiyu Feng",
        "Sungsu Lim",
        "and Jungeun Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:35:12+00:00",
          "link": "https://arxiv.org/abs/2507.10262v1",
          "size": "1392kb",
          "version": "v1"
        }
      ],
      "title": "Experimental Analysis and Evaluation of Cohesive Subgraph Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10262",
        "HTML": "https://arxiv.org/html/2507.10262",
        "PDF": "https://arxiv.org/pdf/2507.10262"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates cohesive subgraph models in networks but does not mention any aspects related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10606",
      "abstract": "Machine learning (ML) has demonstrated significant promise in various physical design (PD) tasks. However, model generalizability remains limited by the availability of high-quality, large-scale training datasets. Creating such datasets is often computationally expensive and constrained by IP. While very few public datasets are available, they are typically static, slow to generate, and require frequent updates. To address these limitations, we present DALI-PD, a scalable framework for generating synthetic layout heatmaps to accelerate ML in PD research. DALI-PD uses a diffusion model to generate diverse layout heatmaps via fast inference in seconds. The heatmaps include power, IR drop, congestion, macro placement, and cell density maps. Using DALI-PD, we created a dataset comprising over 20,000 layout configurations with varying macro counts and placements. These heatmaps closely resemble real layouts and improve ML accuracy on downstream ML tasks such as IR drop or congestion prediction.",
      "authors": [
        "Bing-Yue Wu and Vidya A. Chhabria"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T06:12:04+00:00",
          "link": "https://arxiv.org/abs/2507.10606v1",
          "size": "4112kb",
          "version": "v1"
        }
      ],
      "title": "DALI-PD: Diffusion-based Synthetic Layout Heatmap Generation for ML in Physical Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10606",
        "HTML": "https://arxiv.org/html/2507.10606v1",
        "PDF": "https://arxiv.org/pdf/2507.10606"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces DALI-PD, a framework for generating synthetic datasets for ML in physical design, detailing data generation processes which significantly contribute to dataset creation and processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11153",
      "abstract": "With the widespread adoption of large vision-language models, the capacity for color vision in these models is crucial. However, the color vision abilities of large visual-language models have not yet been thoroughly explored. To address this gap, we define a color vision testing task for large vision-language models and construct a dataset \\footnote{Anonymous Github Showing some of the data https://anonymous.4open.science/r/color-vision-test-dataset-3BCD} that covers multiple categories of test questions and tasks of varying difficulty levels. Furthermore, we analyze the types of errors made by large vision-language models and propose fine-tuning strategies to enhance their performance in color vision tests.",
      "authors": [
        "Hongfei Ye",
        "Bin Chen",
        "Wenxi Liu",
        "Yu Zhang",
        "Zhao Li",
        "Dandan Ni",
        "Hongyang Chen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:03:06+00:00",
          "link": "https://arxiv.org/abs/2507.11153v1",
          "size": "2503kb",
          "version": "v1"
        }
      ],
      "title": "Assessing Color Vision Test in Large Vision-language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11153",
        "HTML": "https://arxiv.org/html/2507.11153v1",
        "PDF": "https://arxiv.org/pdf/2507.11153"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves constructing a dataset for color vision testing in vision-language models, but the focus is on evaluation rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11372",
      "abstract": "Face Recognition (FR) tasks have made significant progress with the advent of Deep Neural Networks, particularly through margin-based triplet losses that embed facial images into high-dimensional feature spaces. During training, these contrastive losses focus exclusively on identity information as labels. However, we observe a multiscale geometric structure emerging in the embedding space, influenced by interpretable facial (e.g., hair color) and image attributes (e.g., contrast). We propose a geometric approach to describe the dependence or invariance of FR models to these attributes and introduce a physics-inspired alignment metric. We evaluate the proposed metric on controlled, simplified models and widely used FR models fine-tuned with synthetic data for targeted attribute augmentation. Our findings reveal that the models exhibit varying degrees of invariance across different attributes, providing insight into their strengths and weaknesses and enabling deeper interpretability. Code available here: https://github.com/mantonios107/attrs-fr-embs}{https://github.com/mantonios107/attrs-fr-embs",
      "authors": [
        "Pierrick Leroy",
        "Antonio Mastropietro",
        "Marco Nurisso",
        "Francesco Vaccarino"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:44:39+00:00",
          "link": "https://arxiv.org/abs/2507.11372v1",
          "size": "14816kb",
          "version": "v1"
        }
      ],
      "title": "Attributes Shape the Embedding Space of Face Recognition Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11372",
        "HTML": "https://arxiv.org/html/2507.11372v1",
        "PDF": "https://arxiv.org/pdf/2507.11372"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on face recognition models and geometric structures in embedding spaces, without discussing any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.11932",
      "abstract": "As international competition intensifies in technologies, nations need to identify key technologies to foster innovation. However, the identification is challenging due to the independent and inherently complex nature of technologies. Traditionally, regional analyses of technological portfolios have been limited to binary evaluations, indicating merely whether a region specializes in a technology, or relying on the average Technological Complexity Index (TCI) of the specialized technologies. This study proposes that evaluating TCI at the corporate level could provide finer granularity and more detailed insights. To address the underutilization of corporate-level TCI assessments in Japan, this study applies the Technological Complexity Index using carefully processed patent data spanning fiscal years 1981 to 2010. Specifically, we analyze a bipartite network composed of 1,938 corporations connected to technological fields categorized into either 35 or 124 classifications. Our findings quantitatively characterize the ubiquity and sophistication of each technological field, reveal detailed technological trends reflecting broader societal contexts, and demonstrate methodological stability even when employing finer technological classifications. Additionally, our corporate-level approach allows consistent comparisons across different regions and technological fields, clarifying regional advantages in specific technologies. This refined analytical framework offers policymakers and researchers robust, targeted insights, thereby significantly contributing to innovation strategy formulation in Japan.",
      "authors": [
        "Rintaro Karashima and Hiroyasu Inoue"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-16T10:12:00+00:00",
          "link": "https://arxiv.org/abs/2504.11932v1",
          "size": "2442kb",
          "version": "v1"
        },
        {
          "date": "2025-04-22T05:11:47+00:00",
          "link": "https://arxiv.org/abs/2504.11932v2",
          "size": "1971kb",
          "version": "v2"
        },
        {
          "date": "2025-07-02T04:25:20+00:00",
          "link": "https://arxiv.org/abs/2504.11932v3",
          "size": "1974kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T10:29:46+00:00",
          "link": "https://arxiv.org/abs/2504.11932v4",
          "size": "1977kb",
          "version": "v4"
        }
      ],
      "title": "Technological Complexity Based on Japanese Patent Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.11932",
        "HTML": "https://arxiv.org/html/2504.11932v4",
        "PDF": "https://arxiv.org/pdf/2504.11932"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study analyzes technological complexity using Japanese patent data, focusing on technology trends and regional advantages, with no mention of processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.15075",
      "abstract": "The rapid evolution of multimodal large language models (MLLMs) has significantly enhanced their real-world applications. However, achieving consistent performance across languages, especially when integrating cultural knowledge, remains a significant challenge. To better assess this issue, we introduce two new benchmarks: KnowRecall and VisRecall, which evaluate cross-lingual consistency in MLLMs. KnowRecall is a visual question answering benchmark designed to measure factual knowledge consistency in 15 languages, focusing on cultural and historical questions about global landmarks. VisRecall assesses visual memory consistency by asking models to describe landmark appearances in 9 languages without access to images. Experimental results reveal that state-of-the-art MLLMs, including proprietary ones, still struggle to achieve cross-lingual consistency. This underscores the need for more robust approaches that produce truly multilingual and culturally aware models.",
      "authors": [
        "Hao Wang",
        "Pinzhi Huang",
        "Jihan Yang",
        "Saining Xie",
        "Daisuke Kawahara"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-21T03:43:37+00:00",
          "link": "https://arxiv.org/abs/2505.15075v1",
          "size": "19624kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T10:35:35+00:00",
          "link": "https://arxiv.org/abs/2505.15075v2",
          "size": "5625kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T08:54:19+00:00",
          "link": "https://arxiv.org/abs/2505.15075v3",
          "size": "5625kb",
          "version": "v3"
        }
      ],
      "title": "Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.15075",
        "HTML": "https://arxiv.org/html/2505.15075v3",
        "PDF": "https://arxiv.org/pdf/2505.15075"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces benchmarks for multimodal language models but does not involve processing or engineering of LLM training data."
      },
      "datasets": [
        {
          "dataset_name": "nlp-waseda/KnowRecall",
          "downloads": "131",
          "likes": "1",
          "link": "https://huggingface.co/datasets/nlp-waseda/KnowRecall"
        },
        {
          "dataset_name": "nlp-waseda/VisRecall",
          "downloads": "72",
          "likes": "0",
          "link": "https://huggingface.co/datasets/nlp-waseda/VisRecall"
        }
      ],
      "tasks": [
        "Benchmarking",
        "Question Answering",
        "Visual Question Answering"
      ],
      "repo_urls": [
        "https://github.com/nlp-waseda/traveling-across-languages"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.23847",
      "abstract": "Large language models (LLMs) are rapidly evolving into autonomous agents that cooperate across organizational boundaries, enabling joint disaster response, supply-chain optimization, and other tasks that demand decentralized expertise without surrendering data ownership. Yet, cross-domain collaboration shatters the unified trust assumptions behind current alignment and containment techniques. An agent benign in isolation may, when receiving messages from an untrusted peer, leak secrets or violate policy, producing risks driven by emergent multi-agent dynamics rather than classical software bugs. This position paper maps the security agenda for cross-domain multi-agent LLM systems. We introduce seven categories of novel security challenges, for each of which we also present plausible attacks, security evaluation metrics, and future research guidelines.",
      "authors": [
        "Ronny Ko",
        "Jiseong Jeong",
        "Shuyuan Zheng",
        "Chuan Xiao",
        "Tae-Wan Kim",
        "Makoto Onizuka",
        "Won-Yong Shin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-28T18:19:03+00:00",
          "link": "https://arxiv.org/abs/2505.23847v1",
          "size": "599kb",
          "version": "v1"
        },
        {
          "date": "2025-06-05T14:07:18+00:00",
          "link": "https://arxiv.org/abs/2505.23847v2",
          "size": "599kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T16:18:29+00:00",
          "link": "https://arxiv.org/abs/2505.23847v3",
          "size": "599kb",
          "version": "v3"
        }
      ],
      "title": "Seven Security Challenges That Must be Solved in Cross-domain Multi-agent LLM Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23847",
        "HTML": "https://arxiv.org/html/2505.23847v3",
        "PDF": "https://arxiv.org/pdf/2505.23847"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses security challenges in cross-domain multi-agent LLM systems and not on training data processing for LLMs."
      },
      "tasks": [
        "Disaster Response",
        "Position"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10635",
      "abstract": "Variational quantum circuits (VQCs) are a central component of many quantum machine learning algorithms, offering a hybrid quantum-classical framework that, under certain aspects, can be considered similar to classical deep neural networks. A shared aspect is, for instance, their vulnerability to adversarial inputs, small perturbations that can lead to incorrect predictions. While formal verification techniques have been extensively developed for classical models, no comparable framework exists for certifying the robustness of VQCs. Here, we present the first in-depth theoretical and practical study of the formal verification problem for VQCs. Inspired by abstract interpretation methods used in deep learning, we analyze the applicability and limitations of interval-based reachability techniques in the quantum setting. We show that quantum-specific aspects, such as state normalization, introduce inter-variable dependencies that challenge existing approaches. We investigate these issues by introducing a novel semantic framework based on abstract interpretation, where the verification problem for VQCs can be formally defined, and its complexity analyzed. Finally, we demonstrate our approach on standard verification benchmarks.",
      "authors": [
        "Nicola Assolini",
        "Luca Marzari",
        "Isabella Mastroeni and Alessandra di Pierro"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:28:32+00:00",
          "link": "https://arxiv.org/abs/2507.10635v1",
          "size": "557kb",
          "version": "v1"
        }
      ],
      "title": "Formal Verification of Variational Quantum Circuits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10635",
        "PDF": "https://arxiv.org/pdf/2507.10635"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on formal verification of variational quantum circuits, which does not discuss any aspects of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10955",
      "abstract": "Peptide de novo sequencing is a method used to reconstruct amino acid sequences from tandem mass spectrometry data without relying on existing protein sequence databases. Traditional deep learning approaches, such as Casanovo, mainly utilize autoregressive decoders and predict amino acids sequentially. Subsequently, they encounter cascading errors and fail to leverage high-confidence regions effectively. To address these issues, this paper investigates using diffusion decoders adapted for the discrete data domain. These decoders provide a different approach, allowing sequence generation to start from any peptide segment, thereby enhancing prediction accuracy. We experiment with three different diffusion decoder designs, knapsack beam search, and various loss functions. We find knapsack beam search did not improve performance metrics and simply replacing the transformer decoder with a diffusion decoder lowered performance. Although peptide precision and recall were still 0, the best diffusion decoder design with the DINOISER loss function obtained a statistically significant improvement in amino acid recall by 0.373 compared to the baseline autoregressive decoder-based Casanovo model. These findings highlight the potential of diffusion decoders to not only enhance model sensitivity but also drive significant advancements in peptide de novo sequencing.",
      "authors": [
        "Chi-en Amy Tai",
        "Alexander Wong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T03:38:01+00:00",
          "link": "https://arxiv.org/abs/2507.10955v1",
          "size": "805kb",
          "version": "v1"
        }
      ],
      "title": "Diffusion Decoding for Peptide De Novo Sequencing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10955",
        "HTML": "https://arxiv.org/html/2507.10955v1",
        "PDF": "https://arxiv.org/pdf/2507.10955"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is concerned with improving peptide de novo sequencing models, without discussing LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.11381",
      "abstract": "The advent of the Attention mechanism and Transformer architecture enables contextually natural text generation and compresses the burden of processing entire source information into singular vectors. Based on these two main ideas, model sizes gradually increases to accommodate more precise and comprehensive information, leading to the current state-of-the-art LLMs being very large, with parameters around 70 billion. As the model sizes are growing, the demand for substantial storage and computational capacity increases. This leads to the development of high-bandwidth memory and accelerators, as well as a variety of model architectures designed to meet these requirements. We note that LLM architectures have increasingly converged. This paper analyzes how these converged architectures perform in terms of layer configurations, operational mechanisms, and model sizes, considering various hyperparameter settings. In this paper, we conduct a concise survey of the history of LLMs by tracing the evolution of their operational improvements. Furthermore, we summarize the performance trends of LLMs under various hyperparameter settings using the RTX 6000, which features the state-of-the-art Ada Lovelace architecture. We conclude that even the same model can exhibit different behaviors depending on the hyperparameters or whether it is deployed in server or edge environments.",
      "authors": [
        "Seongho Kim",
        "Jihyun Moon",
        "Juntaek Oh",
        "Insu Choi",
        "Joon-Sung Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-15T08:19:24+00:00",
          "link": "https://arxiv.org/abs/2410.11381v1",
          "size": "776kb",
          "version": "v1"
        }
      ],
      "title": "Survey and Evaluation of Converging Architecture in LLMs based on Footsteps of Operations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.11381",
        "HTML": "https://arxiv.org/html/2410.11381",
        "PDF": "https://arxiv.org/pdf/2410.11381"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper surveys converging architecture in LLMs with a focus on operational mechanisms, but does not contribute to LLM training data processing or dataset creation."
      },
      "tasks": [
        "Text Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.06136",
      "abstract": "Fine-tuning large language models (LLMs) for specific tasks requires diverse, high-quality training data. However, obtaining sufficient relevant data remains a significant challenge. Existing data synthesis methods either depend on extensive seed datasets or struggle to balance task relevance and data diversity. To address these challenges, we propose Attribute-guided multI-hop Data Expansion (AIDE), a novel data synthesis framework that uses a multi-hop process to expand very few seed data points while ensuring data diversity and task relevance. AIDE extracts the main topic and key knowledge attributes from the seeds to guide the synthesis steps. The process repeats for K hops, using the generated data as seeds. To prevent irrelevant data generation as the hop depth increases, AIDE incorporates a residual connection mechanism. Our empirical results show that AIDE enables fine-tuning of Mistral-7B, Llama-3.1-8B and Llama-3.2-3B from 10 seeds, surpassing the models fine-tuned on human curated data. Furthermore, AIDE outperforms state-of-the-art data synthesis methods, such as Evol-Instruct, by over 30% in task-specific fine-tuning. Code is available at https://github.com/Code4Graph/AIDE.",
      "authors": [
        "Jiayu Li",
        "Xuan Zhu",
        "Fang Liu",
        "Yanjun Qi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-09T01:39:16+00:00",
          "link": "https://arxiv.org/abs/2412.06136v1",
          "size": "895kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T22:18:38+00:00",
          "link": "https://arxiv.org/abs/2412.06136v2",
          "size": "769kb",
          "version": "v2"
        }
      ],
      "title": "AIDE: Attribute-Guided MultI-Hop Data Expansion for Data Scarcity in Task-Specific Fine-tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.06136",
        "HTML": "https://arxiv.org/html/2412.06136v2",
        "PDF": "https://arxiv.org/pdf/2412.06136"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper presents a data synthesis framework, AIDE, explicitly focused on addressing data scarcity in fine-tuning LLMs, which involves expanding seed data while maintaining task relevance and diversity."
      },
      "tasks": [
        "Attribute",
        "Diversity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09995",
      "abstract": "Brain tumor segmentation plays a critical role in clinical diagnosis and treatment planning, yet the variability in imaging quality across different MRI scanners presents significant challenges to model generalization. To address this, we propose the Edge Iterative MRI Lesion Localization System (EdgeIMLocSys), which integrates Continuous Learning from Human Feedback to adaptively fine-tune segmentation models based on clinician feedback, thereby enhancing robustness to scanner-specific imaging characteristics. Central to this system is the Graph-based Multi-Modal Interaction Lightweight Network for Brain Tumor Segmentation (GMLN-BTS), which employs a Modality-Aware Adaptive Encoder (M2AE) to extract multi-scale semantic features efficiently, and a Graph-based Multi-Modal Collaborative Interaction Module (G2MCIM) to model complementary cross-modal relationships via graph structures. Additionally, we introduce a novel Voxel Refinement UpSampling Module (VRUM) that synergistically combines linear interpolation and multi-scale transposed convolutions to suppress artifacts while preserving high-frequency details, improving segmentation boundary accuracy. Our proposed GMLN-BTS model achieves a Dice score of 85.1% on the BraTS2017 dataset with only 4.58 million parameters, representing a 98% reduction compared to mainstream 3D Transformer models, and significantly outperforms existing lightweight approaches. This work demonstrates a synergistic breakthrough in achieving high-accuracy, resource-efficient brain tumor segmentation suitable for deployment in resource-constrained clinical environments.",
      "authors": [
        "Guohao Huo",
        "Ruiting Dai",
        "Hao Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:29:49+00:00",
          "link": "https://arxiv.org/abs/2507.09995v1",
          "size": "487kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T03:12:18+00:00",
          "link": "https://arxiv.org/abs/2507.09995v2",
          "size": "486kb",
          "version": "v2"
        }
      ],
      "title": "Graph-based Multi-Modal Interaction Lightweight Network for Brain Tumor Segmentation (GMLN-BTS) in Edge Iterative MRI Lesion Localization System (EdgeIMLocSys)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09995",
        "HTML": "https://arxiv.org/html/2507.09995v2",
        "PDF": "https://arxiv.org/pdf/2507.09995"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a network for brain tumor segmentation using MRI data, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10928",
      "abstract": "Global Accelerator (GA) services play a vital role in ensuring low-latency, high-reliability communication for real-time interactive applications. However, existing GA offerings are tightly bound to specific cloud providers, resulting in high costs, rigid deployment, and limited flexibility, especially for large-scale or budget-sensitive deployments. Arcturus is a cloud-native GA framework that revisits the design of GA systems by leveraging low-cost, heterogeneous cloud resources across multiple providers. Rather than relying on fixed, high-end infrastructure, Arcturus dynamically constructs its acceleration network and balances performance, stability, and resource efficiency. To achieve this, Arcturus introduces a two-plane design: a forwarding plane that builds a proxy network with adaptive control, and a scheduling plane that coordinates load and routing through lightweight, quantitative optimization. Evaluations under millions of RPS show that Arcturus outperforms commercial GA services by up to 1.7X in acceleration performance, reduces cost by 71%, and maintains over 80% resource efficiency--demonstrating efficient use of cloud resources at scale.",
      "authors": [
        "Matthew Yang Liu",
        "Chuang Chen",
        "Pengcheng Lv",
        "Hui Guo",
        "Yanan Zhang",
        "Cong Wang",
        "Yusen Li",
        "Zhenyu Li",
        "Yu-Chu Tian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T02:36:44+00:00",
          "link": "https://arxiv.org/abs/2507.10928v1",
          "size": "1356kb",
          "version": "v1"
        }
      ],
      "title": "Arcturus: A Cloud Overlay Network for Global Accelerator with Enhanced Performance and Stability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10928",
        "HTML": "https://arxiv.org/html/2507.10928v1",
        "PDF": "https://arxiv.org/pdf/2507.10928"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on cloud network resource efficiency and performance, not on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.11439",
      "abstract": "Cell instance segmentation (CIS) is crucial for identifying individual cell morphologies in histopathological images, providing valuable insights for biological and medical research. While unsupervised CIS (UCIS) models aim to reduce the heavy reliance on labor-intensive image annotations, they fail to accurately capture cell boundaries, causing missed detections and poor performance. Recognizing the absence of error-free instances as a key limitation, we present COIN (COnfidence score-guided INstance distillation), a novel annotation-free framework with three key steps: (1) Increasing the sensitivity for the presence of error-free instances via unsupervised semantic segmentation with optimal transport, leveraging its ability to discriminate spatially minor instances, (2) Instance-level confidence scoring to measure the consistency between model prediction and refined mask and identify highly confident instances, offering an alternative to ground truth annotations, and (3) Progressive expansion of confidence with recursive self-distillation. Extensive experiments across six datasets show COIN outperforming existing UCIS methods, even surpassing semi- and weakly-supervised approaches across all metrics on the MoNuSeg and TNBC datasets. The code is available at https://github.com/shjo-april/COIN.",
      "authors": [
        "Sanghyun Jo",
        "Seo Jin Lee",
        "Seungwoo Lee",
        "Seohyung Hong",
        "Hyungseok Seo",
        "Kyungsu Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-14T14:27:24+00:00",
          "link": "https://arxiv.org/abs/2503.11439v1",
          "size": "33161kb",
          "version": "v1"
        },
        {
          "date": "2025-03-17T01:59:06+00:00",
          "link": "https://arxiv.org/abs/2503.11439v2",
          "size": "33161kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T09:22:19+00:00",
          "link": "https://arxiv.org/abs/2503.11439v3",
          "size": "43496kb",
          "version": "v3"
        }
      ],
      "title": "COIN: Confidence Score-Guided Distillation for Annotation-Free Cell Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11439",
        "HTML": "https://arxiv.org/html/2503.11439v3",
        "PDF": "https://arxiv.org/pdf/2503.11439"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on an annotation-free framework for cell segmentation, focusing on model techniques rather than LLM training data processing."
      },
      "tasks": [
        "Cell Segmentation",
        "Instance Segmentation",
        "Semantic Segmentation",
        "Unsupervised Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.00563",
      "abstract": "Federated Learning (FL) is a collaborative method for training machine learning models while preserving the confidentiality of the participants' training data. Nevertheless, FL is vulnerable to reconstruction attacks that exploit shared parameters to reveal private training data. In this paper, we address this issue in the cybersecurity domain by applying Multi-Input Functional Encryption (MIFE) to a recent FL implementation for training ML-based network intrusion detection systems. We assess both classical and post-quantum solutions in terms of memory cost and computational overhead in the FL process, highlighting their impact on convergence time.",
      "authors": [
        "Enrico Sorbera",
        "Federica Zanetti",
        "Giacomo Brandi",
        "Alessandro Tomasi",
        "Roberto Doriguzzi-Corin and Silvio Ranise"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-01T09:18:06+00:00",
          "link": "https://arxiv.org/abs/2504.00563v1",
          "size": "410kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T14:36:54+00:00",
          "link": "https://arxiv.org/abs/2504.00563v2",
          "size": "958kb",
          "version": "v2"
        }
      ],
      "title": "Adaptive Federated Learning with Functional Encryption: A Comparison of Classical and Quantum-safe Options",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.00563",
        "HTML": "https://arxiv.org/html/2504.00563v2",
        "PDF": "https://arxiv.org/pdf/2504.00563"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the use of federated learning and functional encryption to protect privacy in ML models, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08189",
      "abstract": "Background: CT imaging is vital for lung cancer management, offering detailed visualization for AI-based prognosis. However, supervised learning SL models require large labeled datasets, limiting their real-world application in settings with scarce annotations.\n  Methods: We analyzed CT scans from 977 patients across 12 datasets extracting 1218 radiomics features using Laplacian of Gaussian and wavelet filters via PyRadiomics Dimensionality reduction was applied with 56 feature selection and extraction algorithms and 27 classifiers were benchmarked A semi supervised learning SSL framework with pseudo labeling utilized 478 unlabeled and 499 labeled cases Model sensitivity was tested in three scenarios varying labeled data in SL increasing unlabeled data in SSL and scaling both from 10 percent to 100 percent SHAP analysis was used to interpret predictions Cross validation and external testing in two cohorts were performed.\n  Results: SSL outperformed SL, improving overall survival prediction by up to 17 percent. The top SSL model, Random Forest plus XGBoost classifier, achieved 0.90 accuracy in cross-validation and 0.88 externally. SHAP analysis revealed enhanced feature discriminability in both SSL and SL, especially for Class 1 survival greater than 4 years. SSL showed strong performance with only 10 percent labeled data, with more stable results compared to SL and lower variance across external testing, highlighting SSL's robustness and cost effectiveness.\n  Conclusion: We introduced a cost-effective, stable, and interpretable SSL framework for CT-based survival prediction in lung cancer, improving performance, generalizability, and clinical readiness by integrating SHAP explainability and leveraging unlabeled data.",
      "authors": [
        "Mohammad R. Salmanpour",
        "Amir Hossein Pouria",
        "Sonia Falahati",
        "Shahram Taeb",
        "Somayeh Sadat Mehrnia",
        "Mehdi Maghsudi",
        "Ali Fathi Jouzdani",
        "Mehrdad Oveisi",
        "Ilker Hacihaliloglu",
        "Arman Rahmim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T21:57:15+00:00",
          "link": "https://arxiv.org/abs/2507.08189v1",
          "size": "1122kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T01:10:47+00:00",
          "link": "https://arxiv.org/abs/2507.08189v2",
          "size": "1121kb",
          "version": "v2"
        }
      ],
      "title": "Robust Semi-Supervised CT Radiomics for Lung Cancer Prognosis: Cost-Effective Learning with Limited Labels and SHAP Interpretation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08189",
        "PDF": "https://arxiv.org/pdf/2507.08189"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on semi-supervised learning frameworks for CT radiomics in lung cancer prognosis, leveraging limited labeled data, but it does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11275",
      "abstract": "Efficient and accurate autoformalization methods, which leverage large-scale datasets of extensive natural language mathematical problems to construct formal language datasets, are key to advancing formal mathematical reasoning. In this paper, we propose an autoformalization pipeline based on large language models with error feedback, achieving a fully automatic and training-free formalization approach. Using this pipeline, we curate an Olympiad-level dataset aligning natural language problems with Lean formalizations. The dataset comprises $3,922$ mathematical problems in natural language and $9,787$ in Lean, of which $64.46\\%$ were assessed as at least above-average quality, making it suitable as a benchmark for automated theorem provers. Additionally, we investigate the formalization and reasoning capabilities of various LLMs and empirically demonstrate that few-shot learning, error feedback, and increasing sampling numbers enhance the autoformalization process. Experiments of three automated theorem provers on the \\dataset\\ dataset also highlight its challenging nature and its value as a benchmark for formal reasoning tasks.",
      "authors": [
        "Jiaxuan Xie",
        "Chengwu Liu",
        "Ye Yuan",
        "Siqi Li",
        "Zhiping Xiao",
        "Ming Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:52:47+00:00",
          "link": "https://arxiv.org/abs/2507.11275v1",
          "size": "1434kb",
          "version": "v1"
        }
      ],
      "title": "FMC: Formalization of Natural Language Mathematical Competition Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11275",
        "PDF": "https://arxiv.org/pdf/2507.11275"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper makes a technical contribution to creating a new dataset through an autoformalization pipeline. It describes detailed steps involved in processing natural language mathematical problems into a formal language dataset, enhancing data quality and utility for formal reasoning tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11464",
      "abstract": "We propose a multi-robot control paradigm to solve point-to-point navigation tasks for a team of holonomic robots with access to the full environment information. The framework invokes two processes asynchronously at high frequency: (i) a centralized, discrete, and full-horizon planner for computing collision- and deadlock-free paths rapidly, leveraging recent advances in multi-agent pathfinding (MAPF), and (ii) dynamics-aware, robot-wise optimal trajectory controllers that ensure all robots independently follow their assigned paths reliably. This hierarchical shift in planning representation from (i) discrete and coupled to (ii) continuous and decoupled domains enables the framework to maintain long-term scalable motion synthesis. As an instantiation of this idea, we present LF, which combines a fast state-of-the-art MAPF solver (LaCAM), and a robust feedback control stack (Freyja) for executing agile robot maneuvers. LF provides a robust and versatile mechanism for lifelong multi-robot navigation even under asynchronous and partial goal updates, and adapts to dynamic workspaces simply by quick replanning. We present various multirotor and ground robot demonstrations, including the deployment of 15 real multirotors with random, consecutive target updates while a person walks through the operational workspace.",
      "authors": [
        "Ajay Shankar",
        "Keisuke Okumura",
        "Amanda Prorok"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:35:37+00:00",
          "link": "https://arxiv.org/abs/2507.11464v1",
          "size": "8410kb",
          "version": "v1"
        }
      ],
      "title": "LF: Online Multi-Robot Path Planning Meets Optimal Trajectory Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11464",
        "HTML": "https://arxiv.org/html/2507.11464v1",
        "PDF": "https://arxiv.org/pdf/2507.11464"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses robot path planning and control, with no mention of processing or enhancing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2207.12123",
      "abstract": "Network theory has often disregarded many-body relationships, solely focusing on pairwise interactions: neglecting them, however, can lead to misleading representations of complex systems. Hypergraphs represent a suitable framework for describing polyadic interactions. Here, we leverage the representation of hypergraphs based on the incidence matrix for extending the entropy-based approach to higher-order structures: in analogy with the Exponential Random Graphs, we introduce the Exponential Random Hypergraphs (ERHs). After exploring the asymptotic behaviour of thresholds generalising the percolation one, we apply ERHs to study real-world data. First, we generalise key network metrics to hypergraphs; then, we compute their expected value and compare it with the empirical one, in order to detect deviations from random behaviours. Our method is analytically tractable, scalable and capable of revealing structural patterns of real-world hypergraphs that differ significantly from those emerging as a consequence of simpler constraints.",
      "authors": [
        "Fabio Saracco",
        "Giovanni Petri",
        "Renaud Lambiotte",
        "Tiziano Squartini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Data Analysis, Statistics and Probability (physics.data-an)"
      ],
      "submission_historys": [
        {
          "date": "2022-07-21T16:51:47+00:00",
          "link": "https://arxiv.org/abs/2207.12123v1",
          "size": "168kb",
          "version": "v1"
        },
        {
          "date": "2024-06-14T22:08:01+00:00",
          "link": "https://arxiv.org/abs/2207.12123v2",
          "size": "603kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T12:51:52+00:00",
          "link": "https://arxiv.org/abs/2207.12123v3",
          "size": "1881kb",
          "version": "v3"
        }
      ],
      "title": "Entropy-based models to randomize real-world hypergraphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2207.12123",
        "HTML": "https://arxiv.org/html/2207.12123v3",
        "PDF": "https://arxiv.org/pdf/2207.12123"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on hypergraph modeling and analysis, using entropy-based models, without any discussion on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04099",
      "abstract": "Fine-tuning methods such as Direct Preference Optimization (DPO) and Group Relative Policy Optimization (GRPO) have demonstrated success in training large language models (LLMs) for single-turn tasks. However, these methods fall short in multi-turn applications, such as diagnostic patient interviewing, where understanding how early conversational turns influence downstream completions and outcomes is essential. In medicine, a multi-turn perspective is critical for learning diagnostic schemas and better understanding conversation dynamics. To address this gap, I introduce Savage Conversation Forests (SCF), a reinforcement learning framework that leverages a branched conversation architecture to fine-tune LLMs for multi-turn dialogue. SCF generates multiple possible conversation continuations at each turn, enabling the model to learn how different early responses affect downstream interactions and diagnostic outcomes. In experiments simulating doctor-patient conversations, SCF with branching outperforms linear conversation architectures on diagnostic accuracy. I hypothesize that SCF's improvements stem from its ability to provide richer, interdependent training signals across conversation turns. These results suggest that a branched training architecture is an important strategy for fine tuning LLMs in complex multi-turn conversational tasks.",
      "authors": [
        "Thomas Savage"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T16:49:34+00:00",
          "link": "https://arxiv.org/abs/2507.04099v1",
          "size": "575kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T16:49:25+00:00",
          "link": "https://arxiv.org/abs/2507.04099v2",
          "size": "590kb",
          "version": "v2"
        }
      ],
      "title": "Conversation Forests: The Key to Fine Tuning Large Language Models for Multi-Turn Medical Conversations is Branching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04099",
        "PDF": "https://arxiv.org/pdf/2507.04099"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a reinforcement learning framework for fine-tuning LLMs in multi-turn medical conversations but focuses on model fine-tuning without specific emphasis on training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10587",
      "abstract": "Human users increasingly rely on natural language interactions with large language models (LLMs) in order to receive help on a large variety of tasks and problems. However, the trustworthiness and perceived legitimacy of LLMs is undermined by the fact that their output is frequently stated in very confident terms, even when its accuracy is questionable. Therefore, there is a need to signal the confidence of the language model to a user in order to reap the benefits of human-machine collaboration and mitigate potential harms. Verbalized uncertainty is the expression of confidence with linguistic means, an approach that integrates perfectly into language-based interfaces. Nevertheless, most recent research in natural language processing (NLP) overlooks the nuances surrounding human uncertainty communication and the data biases that influence machine uncertainty communication. We argue for anthropomimetic uncertainty, meaning that intuitive and trustworthy uncertainty communication requires a degree of linguistic authenticity and personalization to the user, which could be achieved by emulating human communication. We present a thorough overview over the research in human uncertainty communication, survey ongoing research, and perform additional analyses to demonstrate so-far overlooked biases in verbalized uncertainty. We conclude by pointing out unique factors in human-machine communication of uncertainty and deconstruct anthropomimetic uncertainty into future research directions for NLP.",
      "authors": [
        "Dennis Ulmer",
        "Alexandra Lorson",
        "Ivan Titov",
        "Christian Hardmeier"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:07:22+00:00",
          "link": "https://arxiv.org/abs/2507.10587v1",
          "size": "4497kb",
          "version": "v1"
        }
      ],
      "title": "Anthropomimetic Uncertainty: What Verbalized Uncertainty in Language Models is Missing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10587",
        "HTML": "https://arxiv.org/html/2507.10587v1",
        "PDF": "https://arxiv.org/pdf/2507.10587"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores uncertainty communication in LLMs and human-machine interaction, without contributions to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10865",
      "abstract": "This is the fourth year of the TREC Deep Learning track. As in previous years, we leverage the MS MARCO datasets that made hundreds of thousands of human annotated training labels available for both passage and document ranking tasks. In addition, this year we also leverage both the refreshed passage and document collections that were released last year leading to a nearly $16$ times increase in the size of the passage collection and nearly four times increase in the document collection size. Unlike previous years, in 2022 we mainly focused on constructing a more complete test collection for the passage retrieval task, which has been the primary focus of the track. The document ranking task was kept as a secondary task, where document-level labels were inferred from the passage-level labels. Our analysis shows that similar to previous years, deep neural ranking models that employ large scale pretraining continued to outperform traditional retrieval methods. Due to the focusing our judging resources on passage judging, we are more confident in the quality of this year's queries and judgments, with respect to our ability to distinguish between runs and reuse the dataset in future. We also see some surprises in overall outcomes. Some top-performing runs did not do dense retrieval. Runs that did single-stage dense retrieval were not as competitive this year as they were last year.",
      "authors": [
        "Nick Craswell",
        "Bhaskar Mitra",
        "Emine Yilmaz",
        "Daniel Campos",
        "Jimmy Lin",
        "Ellen M. Voorhees and Ian Soboroff"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T20:48:22+00:00",
          "link": "https://arxiv.org/abs/2507.10865v1",
          "size": "2293kb",
          "version": "v1"
        }
      ],
      "title": "Overview of the TREC 2022 deep learning track",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10865",
        "HTML": "https://arxiv.org/html/2507.10865v1",
        "PDF": "https://arxiv.org/pdf/2507.10865"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the construction of a test collection for the passage retrieval task using the MS MARCO datasets, but it primarily focuses on task construction and evaluation rather than on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11393",
      "abstract": "Learning new information without forgetting prior knowledge is central to human intelligence. In contrast, neural network models suffer from catastrophic forgetting: a significant degradation in performance on previously learned tasks when acquiring new information. The Complementary Learning Systems (CLS) theory offers an explanation for this human ability, proposing that the brain has distinct systems for pattern separation (encoding distinct memories) and pattern completion (retrieving complete memories from partial cues). To capture these complementary functions, we leverage the representational generalization capabilities of variational autoencoders (VAEs) and the robust memory storage properties of Modern Hopfield networks (MHNs), combining them into a neurally plausible continual learning model. We evaluate this model on the Split-MNIST task, a popular continual learning benchmark, and achieve close to state-of-the-art accuracy (~90%), substantially reducing forgetting. Representational analyses empirically confirm the functional dissociation: the VAE underwrites pattern completion, while the MHN drives pattern separation. By capturing pattern separation and completion in scalable architectures, our work provides a functional template for modeling memory consolidation, generalization, and continual learning in both biological and artificial systems.",
      "authors": [
        "James P Jun",
        "Vijay Marupudi",
        "Raj Sanjay Shah",
        "Sashank Varma"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:05:26+00:00",
          "link": "https://arxiv.org/abs/2507.11393v1",
          "size": "1556kb",
          "version": "v1"
        }
      ],
      "title": "A Neural Network Model of Complementary Learning Systems: Pattern Separation and Completion for Continual Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11393",
        "HTML": "https://arxiv.org/html/2507.11393v1",
        "PDF": "https://arxiv.org/pdf/2507.11393"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "It addresses a neural network model for continual learning and catastrophic forgetting, but does not involve any processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.21609",
      "abstract": "Prokhorov's Theorem in probability theory states that a family $\\Gamma$ of probability measures on a Polish space is tight if and only if every sequence in $\\Gamma$ has a weakly convergent subsequence. Due to the highly non-constructive nature of (relative) sequential compactness, however, the effective content of this theorem has not been studied. To this end, we generalize the effective notions of weak convergence of measures on the real line due to McNicholl and Rojas to computable Polish spaces. Then, we introduce an effective notion of tightness for families of measures on computable Polish spaces. Finally, we prove an effective version of Prokhorov's Theorem for computable sequences of probability measures.",
      "authors": [
        "Diego A. Rojas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic (math.LO)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-28T23:22:28+00:00",
          "link": "https://arxiv.org/abs/2410.21609v1",
          "size": "19kb",
          "version": "v1"
        },
        {
          "date": "2024-10-30T15:35:37+00:00",
          "link": "https://arxiv.org/abs/2410.21609v2",
          "size": "19kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T09:36:36+00:00",
          "link": "https://arxiv.org/abs/2410.21609v3",
          "size": "17kb",
          "version": "v3"
        }
      ],
      "title": "Effective weak convergence and tightness of measures in computable Polish spaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.21609",
        "HTML": "https://arxiv.org/html/2410.21609v3",
        "PDF": "https://arxiv.org/pdf/2410.21609"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on probability theory, specifically effective notions of weak convergence and tightness in computable Polish spaces, without addressing any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.10158",
      "abstract": "Integral linear systems $Ax=b$ with matrices $A$, $b$ and solutions $x$ are also required to be in integers, can be solved using invariant factors of $A$ (by computing the Smith Canonical Form of $A$). This paper explores a new problem which arises in applications, that of obtaining conditions for solving the Modular Linear System $Ax=b\\rem n$ given $A,b$ in $\\zz_n$ for $x$ in $\\zz_n$ along with the constraint that the value of the linear function $\\phi(x)=\\la w,x\\ra$ is coprime to $n$ for some solution $x$. In this paper we develop decomposition of the system to coprime moduli $p^{r(p)}$ which are divisors of $n$ and show how such a decomposition simplifies the computation of Smith form. This extends the well known index calculus method of computing the discrete logarithm where the moduli over which the linear system is reduced were assumed to be prime (to solve the reduced systems over prime fields) to the case when the factors of the modulus are prime powers $p^{r(p)}$. It is shown how this problem can be addressed effciently using the invariant factors and Smith form of the augmented matrix $[A,-p^{r(p)}I]$ and conditions modulo $p$ satisfied by $w$, where $p^{r(p)}$ vary over all divisors of $n$ with $p$ prime.",
      "authors": [
        "Virendra Sule"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Number Theory (math.NT)",
        "Discrete Mathematics (cs.DM)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-13T08:36:00+00:00",
          "link": "https://arxiv.org/abs/2503.10158v1",
          "size": "15kb",
          "version": "v1"
        },
        {
          "date": "2025-03-27T13:45:04+00:00",
          "link": "https://arxiv.org/abs/2503.10158v2",
          "size": "16kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T11:09:22+00:00",
          "link": "https://arxiv.org/abs/2503.10158v3",
          "size": "18kb",
          "version": "v3"
        }
      ],
      "title": "Solving Modular Linear Systems with a Constraint by parallel decomposition of the Smith form and extended Euclidean division modulo powers of primes divisors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.10158",
        "HTML": "https://arxiv.org/html/2503.10158v3",
        "PDF": "https://arxiv.org/pdf/2503.10158"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on solving modular linear systems with constraints and involves mathematical analysis, not pertaining to LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.06308",
      "abstract": "Rotary Position Embedding (RoPE) is widely adopted in large language models (LLMs) due to its efficient encoding of relative positions with strong extrapolation capabilities. However, while its application in higher-dimensional input domains, such as 2D images, have been explored in several attempts, a unified theoretical framework is still lacking. To address this, we propose a systematic mathematical framework for RoPE grounded in Lie group and Lie algebra theory. We derive the necessary and sufficient conditions for any valid $N$-dimensional RoPE based on two core properties of RoPE - relativity and reversibility. We demonstrate that RoPE can be characterized as a basis of a maximal abelian subalgebra (MASA) in the special orthogonal Lie algebra, and that the commonly used axis-aligned block-diagonal RoPE, where each input axis is encoded by an independent 2x2 rotation block, corresponds to the maximal toral subalgebra. Furthermore, we reduce spatial inter-dimensional interactions to a change of basis, resolved by learning an orthogonal transformation. Our experiment results suggest that inter-dimensional interactions should be balanced with local structure preservation. Overall, our framework unifies and explains existing RoPE designs while enabling principled extensions to higher-dimensional modalities and tasks.",
      "authors": [
        "Haiping Liu",
        "Lijing Lin",
        "Jingyuan Sun",
        "Zhegong Shangguan",
        "Mauricio A. Alvarez and Hongpeng Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-07T21:58:22+00:00",
          "link": "https://arxiv.org/abs/2504.06308v1",
          "size": "31kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T23:20:54+00:00",
          "link": "https://arxiv.org/abs/2504.06308v2",
          "size": "70kb",
          "version": "v2"
        }
      ],
      "title": "Rethinking RoPE: A Mathematical Blueprint for N-dimensional Positional Embedding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.06308",
        "HTML": "https://arxiv.org/html/2504.06308v2",
        "PDF": "https://arxiv.org/pdf/2504.06308"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a mathematical blueprint for N-dimensional positional embedding (RoPE) in LLMs, which does not pertain to the processing of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.15038",
      "abstract": "This study compares open metadata from hoaddata, an openly available dataset based on Crossref, OpenAlex and the cOAlition S Journal Checker Tool, with proprietary bibliometric databases Scopus and Web of Science to estimate the impact of transformative agreements on hybrid open access publishing. Analysing over 13,000 hybrid journals between 2019-2023, the research found substantial growth in open access due to these agreements, although most articles remain paywalled. The results were consistent across all three data sources, showing strong correlations in country-level metrics despite differences in journal coverage and metadata availability. By 2023, transformative agreements enabled the majority of open access in hybrid journals, with particularly high adoption in European countries. The analysis revealed strong alignment between first and corresponding authorship when measuring agreement uptake by publisher and country. This comparative approach supports the use of open metadata for large-scale hybrid open access studies, while using multiple data sources together provides a more robust understanding of hybrid open access adoption than any single database can offer, overcoming individual limitations in coverage and metadata quality.",
      "authors": [
        "Najko Jahn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-21T11:48:39+00:00",
          "link": "https://arxiv.org/abs/2504.15038v1",
          "size": "3502kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T09:46:05+00:00",
          "link": "https://arxiv.org/abs/2504.15038v2",
          "size": "214kb",
          "version": "v2"
        }
      ],
      "title": "Estimating transformative agreement impact on hybrid open access: A comparative large-scale study using Scopus, Web of Science and open metadata",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.15038",
        "HTML": "https://arxiv.org/html/2504.15038v2",
        "PDF": "https://arxiv.org/pdf/2504.15038"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on estimating the impact of transformative agreements on hybrid open access publishing, without any discussion on LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/njahn82/hoa_validation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09776",
      "abstract": "Analog in-memory computing (AIMC) is an energy-efficient alternative to digital architectures for accelerating machine learning and signal processing workloads. However, its energy efficiency is limited by the high energy cost of the column analog-to-digital converters (ADCs). Reducing the ADC precision is an effective approach to lowering its energy cost. However, doing so also reduces the AIMC's computational accuracy thereby making it critical to identify the minimum precision required to meet a target accuracy. Prior works overestimate the ADC precision requirements by modeling quantization error as input-independent noise, maximizing the signal-to-quantization-noise ratio (SQNR), and ignoring the discrete nature of ideal pre-ADC signal. We address these limitations by developing analytical expressions for estimating the compute signal-to-noise ratio (CSNR), a true metric of accuracy for AIMCs, and propose CACTUS, an algorithm to obtain CSNR-optimal ADC parameters. Using a circuit-aware behavioral model of an SRAM-based AIMC in a 28nm CMOS process, we show that for a 256-dimensional binary dot product, CACTUS reduces the ADC precision requirements by 3b while achieving 6dB higher CSNR over prior methods. We also delineate operating conditions under which our proposed CSNR-optimal ADCs outperform conventional SQNR-optimal ADCs.",
      "authors": [
        "Mihir Kavishwar and Naresh Shanbhag"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T20:13:20+00:00",
          "link": "https://arxiv.org/abs/2507.09776v1",
          "size": "4481kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T02:44:11+00:00",
          "link": "https://arxiv.org/abs/2507.09776v2",
          "size": "4481kb",
          "version": "v2"
        }
      ],
      "title": "Compute SNR-Optimal Analog-to-Digital Converters for Analog In-Memory Computing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09776",
        "HTML": "https://arxiv.org/html/2507.09776v2",
        "PDF": "https://arxiv.org/pdf/2507.09776"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on energy-efficient AI computing hardware and analog-to-digital converters, not on any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10880",
      "abstract": "Every day, multinational firms process thousands of transactions, each of which must adhere to tax regulations that vary by jurisdiction and are often nuanced. The determination of product and service tax codes, such as HSN or SAC is a major use case in Tax compliance. An accurate determination of such codes is imperative to avoid any tax penalties. This paper proposes a domain-adaptive small language model (SLM) with an encoder-decoder architecture for the enhanced prediction of product and service tax codes. In this approach, we address the problem of predicting hierarchical tax code sequences using unstructured product and services data. We employ an SLM based upon encoder-decoder architecture as this enables sequential generation of tax codes to capture the hierarchical dependencies present within the tax codes. Our experiments demonstrate that encoder-decoder SLMs can be successfully applied to the sequential prediction of structured tax codes, a domain that remains comparatively unexplored in current NLP research. In this paper, we demonstrate the superior performance of the domain-adaptive encoder-decoder SLMs over flat classifiers when applied to the Harmonized System of Nomenclature (HSN), and achieve superior results compared to decoder-only and encoder-only architectures for structured sequence generation tasks. This approach can also be scaled to other government-mandated tax commodity codes, such as United Nations Standard Products and Services Codes (UNSPSC), or Brazil's Nomenclatura Comum do Mercosul (NCM).",
      "authors": [
        "Souvik Nath",
        "Sumit Wadhwa",
        "Luiz Perez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T00:46:01+00:00",
          "link": "https://arxiv.org/abs/2507.10880v1",
          "size": "541kb",
          "version": "v1"
        }
      ],
      "title": "Domain-Adaptive Small Language Models for Structured Tax Code Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10880",
        "HTML": "https://arxiv.org/html/2507.10880v1",
        "PDF": "https://arxiv.org/pdf/2507.10880"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on the application of a language model to predict tax codes, without discussing the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11273",
      "abstract": "Large language models (LLMs) based on Transformer Decoders have become the preferred choice for conversational generative AI. Despite the overall superiority of the Decoder architecture, the gradually increasing Key-Value (KV) cache during inference has emerged as a primary efficiency bottleneck, both in aspects of memory consumption and data transfer bandwidth limitations. To address these challenges, we propose a paradigm called KV-Latent. By down-sampling the Key-Value vector dimensions into a latent space, we can significantly reduce the KV Cache footprint and improve inference speed, only with a small amount of extra training, less than 1\\% of pre-training takes. Besides, we enhanced the stability of Rotary Positional Embedding applied on lower-dimensional vectors by modifying its frequency sampling mechanism, avoiding noise introduced by higher frequencies while retaining position attenuation. Our experiments, including both models with Grouped Query Attention and those without, have yielded satisfactory results. Finally, we conducted comparative experiments to study the impact of separately reducing Key and Value components on model's performance. Our approach allows for the construction of more efficient language model systems, and opens the new possibility on KV Cache saving and efficient LLMs. Our code is available at https://github.com/ShiLuohe/KV-Latent.",
      "authors": [
        "Luohe Shi",
        "Zuchao Li",
        "Lefei Zhang",
        "Guoming Liu",
        "Baoyuan Qi",
        "Hai Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:52:12+00:00",
          "link": "https://arxiv.org/abs/2507.11273v1",
          "size": "1121kb",
          "version": "v1"
        }
      ],
      "title": "KV-Latent: Dimensional-level KV Cache Reduction with Frequency-aware Rotary Positional Embedding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11273",
        "HTML": "https://arxiv.org/html/2507.11273v1",
        "PDF": "https://arxiv.org/pdf/2507.11273"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving inference efficiency through KV cache reduction in Transformer Decoders, without discussing any training-data processing or data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11318",
      "abstract": "The lubrication theory is mostly concerned with the behavior of a lubricant flowing through a narrow gap. Motivated by the experimental findings from the tribology literature, we take the lubricant to be micropolar fluid and study its behavior in a thin domain with rough boundary. Instead of considering (commonly used) simple zero boundary condition, we impose physically relevant (nonzero) boundary condition for microrotation and perform asymptotic analysis of the corresponding 3D boundary value problem. We formally derive a simplified mathematical model acknowledging the roughness-induced effects and the effects of the nonzero boundary conditions on the macroscopic flow. Using the obtained asymptotic model, we study numerically the influence of the specific rugosity profile on the performance of a linear slider bearing. The numerical results clearly indicate that the use of the rough surfaces may contribute to enhance the mechanical performance of such device.",
      "authors": [
        "Matthieu Bonnivard",
        "Igor Pazanin",
        "Francisco Suarez-Grau"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Analysis of PDEs (math.AP)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:50:01+00:00",
          "link": "https://arxiv.org/abs/2507.11318v1",
          "size": "106kb",
          "version": "v1"
        }
      ],
      "title": "Effects of rough boundary and nonzero boundary conditions on the lubrication process with micropolar fluid",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11318",
        "HTML": "https://arxiv.org/html/2507.11318v1",
        "PDF": "https://arxiv.org/pdf/2507.11318"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses lubrication theory and micropolar fluids in thin domains, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11402",
      "abstract": "The RoboCup Logistics League is a RoboCup competition in a smart factory scenario that has focused on task planning, job scheduling, and multi-agent coordination. The focus on production logistics allowed teams to develop highly competitive strategies, but also meant that some recent developments in the context of smart manufacturing are not reflected in the competition, weakening its relevance over the years. In this paper, we describe the vision for the RoboCup Smart Manufacturing League, a new competition designed as a larger smart manufacturing scenario, reflecting all the major aspects of a modern factory. It will consist of several tracks that are initially independent but gradually combined into one smart manufacturing scenario. The new tracks will cover industrial robotics challenges such as assembly, human-robot collaboration, and humanoid robotics, but also retain a focus on production logistics. We expect the reenvisioned competition to be more attractive to newcomers and well-tried teams, while also shifting the focus to current and future challenges of industrial robotics.",
      "authors": [
        "Supun Dissanayaka",
        "Alexander Ferrein",
        "Till Hofmann",
        "Kosuke Nakajima",
        "Mario Sanz-Lopez",
        "Jesus Savage",
        "Daniel Swoboda",
        "Matteo Tschesche",
        "Wataru Uemura",
        "Tarik Viehmann",
        "Shohei Yasuda"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:17:04+00:00",
          "link": "https://arxiv.org/abs/2507.11402v1",
          "size": "7413kb",
          "version": "v1"
        }
      ],
      "title": "From Production Logistics to Smart Manufacturing: The Vision for a New RoboCup Industrial League",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11402",
        "HTML": "https://arxiv.org/html/2507.11402v1",
        "PDF": "https://arxiv.org/pdf/2507.11402"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes a vision for a new robotics competition and does not involve LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.01166",
      "abstract": "The paper explores the capability of continuous-time recurrent neural networks to store and recall precisely timed scores of spike trains. We show (by numerical experiments) that this is indeed possible: within some range of parameters, any random score of spike trains (for all neurons in the network) can be robustly memorized and autonomously reproduced with stable accurate relative timing of all spikes, with probability close to one. We also demonstrate associative recall under noisy conditions.\n  In these experiments, the required synaptic weights are computed offline, to satisfy a template that encourages temporal stability.",
      "authors": [
        "Hugo Aguettaz and Hans-Andrea Loeliger"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-02T10:33:52+00:00",
          "link": "https://arxiv.org/abs/2408.01166v1",
          "size": "39kb",
          "version": "v1"
        },
        {
          "date": "2024-09-24T08:58:27+00:00",
          "link": "https://arxiv.org/abs/2408.01166v2",
          "size": "30kb",
          "version": "v2"
        },
        {
          "date": "2025-04-11T12:53:44+00:00",
          "link": "https://arxiv.org/abs/2408.01166v3",
          "size": "36kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T16:00:47+00:00",
          "link": "https://arxiv.org/abs/2408.01166v4",
          "size": "36kb",
          "version": "v4"
        }
      ],
      "title": "Continuous-Time Neural Networks Can Stably Memorize Random Spike Trains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.01166",
        "PDF": "https://arxiv.org/pdf/2408.01166"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the capabilities of continuous-time recurrent neural networks to store random spike trains, without any mention of LLM training data processing or data engineering techniques related to LLMs."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/haguettaz/rsnn"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.00588",
      "abstract": "In this pilot study, we propose a neuro-inspired approach that compresses temporal sequences into context-tagged chunks, where each tag represents a recurring structural unit or``community'' in the sequence. These tags are generated during an offline sleep phase and serve as compact references to past experience, allowing the learner to incorporate information beyond its immediate input range. We evaluate this idea in a controlled synthetic environment designed to reveal the limitations of traditional neural network based sequence learners, such as recurrent neural networks (RNNs), when facing temporal patterns on multiple timescales. We evaluate this idea in a controlled synthetic environment designed to reveal the limitations of traditional neural network based sequence learners, such as recurrent neural networks (RNNs), when facing temporal patterns on multiple timescales. Our results, while preliminary, suggest that temporal chunking can significantly enhance learning efficiency under resource constrained settings. A small-scale human pilot study using a Serial Reaction Time Task further motivates the idea of structural abstraction. Although limited to synthetic tasks, this work serves as an early proof-of-concept, with initial evidence that learned context tags can transfer across related task, offering potential for future applications in transfer learning.",
      "authors": [
        "Jayanta Dey",
        "Nicholas Soures",
        "Miranda Gonzales",
        "Itamar Lerner",
        "Christopher Kanan",
        "Dhireesha Kudithipudi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-31T14:51:08+00:00",
          "link": "https://arxiv.org/abs/2506.00588v1",
          "size": "15256kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T15:22:47+00:00",
          "link": "https://arxiv.org/abs/2506.00588v2",
          "size": "15256kb",
          "version": "v2"
        }
      ],
      "title": "Temporal Chunking Enhances Recognition of Implicit Sequential Patterns",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.00588",
        "HTML": "https://arxiv.org/html/2506.00588v2",
        "PDF": "https://arxiv.org/pdf/2506.00588"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a neuro-inspired approach to temporal sequence learning, rather than any aspect of LLM training data processing or preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10567",
      "abstract": "We study protocols for verifying approximate optimality of strategies in multi-armed bandits and normal-form games. As the number of actions available to each player is often large, we seek protocols where the number of queries to the utility oracle is sublinear in the number of actions. We prove that such verification is possible for sufficiently smooth strategies that do not put too much probability mass on any specific action. We provide protocols for verifying that a smooth policy for a multi-armed bandit is $\\varepsilon$-optimal. Our verification protocols require provably fewer arm queries than learning. Furthermore, we establish a nearly-tight lower bound on the query complexity of verification in our settings. As an application, we show how to use verification for bandits to achieve verification in normal-form games. This gives a protocol for verifying whether a given strategy profile is an approximate strong smooth Nash equilibrium, with a query complexity that is sublinear in the number of actions.",
      "authors": [
        "Miranda Christ",
        "Daniel Reichman",
        "Jonathan Shafer"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T07:14:20+00:00",
          "link": "https://arxiv.org/abs/2507.10567v1",
          "size": "106kb",
          "version": "v1"
        }
      ],
      "title": "Protocols for Verifying Smooth Strategies in Bandits and Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10567",
        "PDF": "https://arxiv.org/pdf/2507.10567"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines protocols for verifying strategies in games and bandits, which is not related to processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10746",
      "abstract": "We design a debiased parametric bootstrap framework for statistical inference from differentially private data. Existing usage of the parametric bootstrap on privatized data ignored or avoided handling the effect of clamping, a technique employed by the majority of privacy mechanisms. Ignoring the impact of clamping often leads to under-coverage of confidence intervals and miscalibrated type I errors of hypothesis tests. The main reason for the failure of the existing methods is the inconsistency of the parameter estimate based on the privatized data. We propose using the indirect inference method to estimate the parameter values consistently, and we use the improved estimator in parametric bootstrap for inference. To implement the indirect estimator, we present a novel simulation-based, adaptive approach along with the theory that establishes the consistency of the corresponding parametric bootstrap estimates, confidence intervals, and hypothesis tests. In particular, we prove that our adaptive indirect estimator achieves the minimum asymptotic variance among all \"well-behaved\" consistent estimators based on the released summary statistic. Our simulation studies show that our framework produces confidence intervals with well-calibrated coverage and performs hypothesis testing with the correct type I error, giving state-of-the-art performance for inference on location-scale normals, simple linear regression, and logistic regression.",
      "authors": [
        "Zhanyu Wang",
        "Arin Chang",
        "Jordan Awan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:12:16+00:00",
          "link": "https://arxiv.org/abs/2507.10746v1",
          "size": "1201kb",
          "version": "v1"
        }
      ],
      "title": "Optimal Debiased Inference on Privatized Data via Indirect Estimation and Parametric Bootstrap",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10746",
        "HTML": "https://arxiv.org/html/2507.10746v1",
        "PDF": "https://arxiv.org/pdf/2507.10746"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses statistical inference on differentially private data, which does not pertain to LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10834",
      "abstract": "Assortment optimization involves selecting a subset of substitutable products (subject to certain constraints) to maximize the expected revenue. It is a classic problem in revenue management and finds applications across various industries. However, the problem is usually NP-hard due to its combinatorial and non-linear nature. In this work, we explore how graph concolutional networks (GCNs) can be leveraged to efficiently solve constrained assortment optimization under the mixed multinomial logit choice model. We first develop a graph representation of the assortment problem, then train a GCN to learn the patterns of optimal assortments, and lastly propose two inference policies based on the GCN's output. Due to the GCN's inherent ability to generalize across inputs of varying sizes, we can use a GCN trained on small-scale instances to facilitate large-scale instances. Extensive numerical experiments demonstrate that given a GCN trained on small-scale instances (e.g., with 20 products), the proposed policies can achieve superior performance (90%+ optimality) on large-scale instances (with up to 2,000 products) within seconds, which outperform existing heuristic policies in both performance and efficiency. Furthermore, we extend our framework to a model-free setting where the underlying choice model is unknown but transaction data is available. We also conduct numerical experiments to demonstrate the effectiveness and efficiency of our proposed policies in this setting.",
      "authors": [
        "Guokai Li",
        "Pin Gao",
        "Stefanus Jasin",
        "Zizhuo Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T22:04:29+00:00",
          "link": "https://arxiv.org/abs/2507.10834v1",
          "size": "1876kb",
          "version": "v1"
        }
      ],
      "title": "From Small to Large: A Graph Convolutional Network Approach for Solving Assortment Optimization Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10834",
        "HTML": "https://arxiv.org/html/2507.10834v1",
        "PDF": "https://arxiv.org/pdf/2507.10834"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using graph convolutional networks for solving assortment optimization problems, which does not involve any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11117",
      "abstract": "Decentralized trading of real-world alternative assets (e.g., gold) requires bridging physical asset custody with blockchain systems while meeting strict requirements for compliance, liquidity, and risk management. We present GoldMine OS, a research oriented architecture that employs multiple specialized AI agents to automate and secure the tokenization and exchange of physical gold into a blockchain based stablecoin (\"OZ\"). Our approach combines on chain smart contracts for critical risk controls with off chain AI agents for decision making, blending the transparency and reliability of blockchains with the flexibility of AI driven automation. We describe four cooperative agents (Compliance, Token Issuance, Market Making, and Risk Control) and a coordinating core, and evaluate the system through simulation and a controlled pilot deployment. In experiments the prototype delivers on demand token issuance in under 1.2 s, more than 100 times faster than manual workflows. The Market Making agent maintains tight liquidity with spreads often below 0.5 percent even under volatile conditions. Fault injection tests show resilience: an oracle price spoofing attack is detected and mitigated within 10 s, and a simulated vault mis reporting halts issuance immediately with minimal user impact. The architecture scales to 5000 transactions per second with 10000 concurrent users in benchmarks. These results indicate that an AI agent based decentralized exchange for alternative assets can satisfy rigorous performance and safety requirements. We discuss broader implications for democratizing access to traditionally illiquid assets and explain how our governance model -- multi signature agent updates and on chain community voting on risk parameters -- provides ongoing transparency, adaptability, and formal assurance of system integrity.",
      "authors": [
        "Ailiya Borjigin",
        "Cong He",
        "Charles CC Lee",
        "and Wei Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:11:19+00:00",
          "link": "https://arxiv.org/abs/2507.11117v1",
          "size": "1652kb",
          "version": "v1"
        }
      ],
      "title": "AI Agent Architecture for Decentralized Trading of Alternative Assets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11117",
        "HTML": "https://arxiv.org/html/2507.11117v1",
        "PDF": "https://arxiv.org/pdf/2507.11117"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes an architecture combining AI agents and blockchain for decentralized trading, with no focus on LLM training data or data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11186",
      "abstract": "Convex semilattices are algebras that are at the same time a convex algebra and a semilattice, together with a distributivity axiom. These algebras have attracted some attention in the last years as suitable algebras for probability and nondeterminism, in particular by being the Eilenberg-Moore algebras of the nonempty finitely-generated convex subsets of the distributions monad.\n  A convex semilattice is cancellative if the underlying convex algebra is cancellative. Cancellative convex algebras have been characterized by M. H. Stone and by H. Kneser: A convex algebra is cancellative if and only if it is isomorphic to a convex subset of a vector space (with canonical convex algebra operations).\n  We prove an analogous theorem for convex semilattices: A convex semilattice is cancellative if and only if it is isomorphic to a convex subset of a Riesz space, i.e., a lattice-ordered vector space (with canonical convex semilattice operations).",
      "authors": [
        "Ana Sokolova",
        "Harald Woracek"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:40:48+00:00",
          "link": "https://arxiv.org/abs/2507.11186v1",
          "size": "27kb",
          "version": "v1"
        }
      ],
      "title": "Cancellative Convex Semilattices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11186",
        "HTML": "https://arxiv.org/html/2507.11186v1",
        "PDF": "https://arxiv.org/pdf/2507.11186"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses mathematical properties of convex semilattices, with no mention of LLM training data processing or data engineering relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.04371",
      "abstract": "Graph Neural Networks (GNNs) have become the leading approach for addressing graph analytical problems in various real-world scenarios. However, GNNs may produce biased predictions against certain demographic subgroups due to node attributes and neighbors surrounding a node. Most current research on GNN fairness focuses predominantly on debiasing GNNs using oversimplified fairness evaluation metrics, which can give a misleading impression of fairness. Understanding the potential evaluation paradoxes due to the complicated nature of the graph structure is crucial for developing effective GNN debiasing mechanisms. In this paper, we examine the effectiveness of current GNN debiasing methods in terms of unfairness evaluation. Specifically, we introduce a community-level strategy to measure bias in GNNs and evaluate debiasing methods at this level. Further, We introduce ComFairGNN, a novel framework designed to mitigate community-level bias in GNNs. Our approach employs a learnable coreset-based debiasing function that addresses bias arising from diverse local neighborhood distributions during GNNs neighborhood aggregation. Comprehensive evaluations on three benchmark datasets demonstrate our model's effectiveness in both accuracy and fairness metrics.",
      "authors": [
        "Yonas Sium",
        "Qi Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-07T02:04:34+00:00",
          "link": "https://arxiv.org/abs/2411.04371v1",
          "size": "1509kb",
          "version": "v1"
        },
        {
          "date": "2025-04-01T21:14:17+00:00",
          "link": "https://arxiv.org/abs/2411.04371v2",
          "size": "3461kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T17:05:53+00:00",
          "link": "https://arxiv.org/abs/2411.04371v3",
          "size": "549kb",
          "version": "v3"
        }
      ],
      "title": "ComFairGNN: Community Fair Graph Neural Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.04371",
        "HTML": "https://arxiv.org/html/2411.04371v3",
        "PDF": "https://arxiv.org/pdf/2411.04371"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a framework for addressing bias in graph neural networks, focusing on fairness evaluation, not involving LLM training data processing."
      },
      "tasks": [
        "Fairness",
        "Graph Neural Network"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.17911",
      "abstract": "Approximate nearest neighbor search (ANNS) is a fundamental problem in vector databases and AI infrastructures. Recent graph-based ANNS algorithms have achieved high search accuracy with practical efficiency. Despite the advancements, these algorithms still face performance bottlenecks in production, due to the random memory access patterns of graph-based search and the high computational overheads of vector distance. In addition, the performance of a graph-based ANNS algorithm is highly sensitive to parameters, while selecting the optimal parameters is cost-prohibitive, e.g., manual tuning requires repeatedly re-building the index. This paper introduces VSAG, an open-source framework that aims to enhance the in production performance of graph-based ANNS algorithms. VSAG has been deployed at scale in the services of Ant Group, and it incorporates three key optimizations: (i) efficient memory access: it reduces L3 cache misses with pre-fetching and cache-friendly vector organization; (ii) automated parameter tuning: it automatically selects performance-optimal parameters without requiring index rebuilding; (iii) efficient distance computation: it leverages modern hardware, scalar quantization, and smartly switches to low-precision representation to dramatically reduce the distance computation costs. We evaluate VSAG on real-world datasets. The experimental results show that VSAG achieves the state-of-the-art performance and provides up to 4x speedup over HNSWlib (an industry-standard library) while ensuring the same accuracy.",
      "authors": [
        "Xiaoyao Zhong",
        "Haotian Li",
        "Jiabao Jin",
        "Mingyu Yang",
        "Deming Chu",
        "Xiangyu Wang",
        "Zhitao Shen",
        "Wei Jia",
        "George Gu",
        "Yi Xie",
        "Xuemin Lin",
        "Heng Tao Shen",
        "Jingkuan Song",
        "Peng Cheng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-23T03:16:50+00:00",
          "link": "https://arxiv.org/abs/2503.17911v1",
          "size": "6318kb",
          "version": "v1"
        },
        {
          "date": "2025-06-12T11:26:10+00:00",
          "link": "https://arxiv.org/abs/2503.17911v2",
          "size": "961kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T11:31:14+00:00",
          "link": "https://arxiv.org/abs/2503.17911v3",
          "size": "527kb",
          "version": "v3"
        }
      ],
      "title": "VSAG: An Optimized Search Framework for Graph-based Approximate Nearest Neighbor Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17911",
        "HTML": "https://arxiv.org/html/2503.17911v3",
        "PDF": "https://arxiv.org/pdf/2503.17911"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces the VSAG framework for optimizing graph-based approximate nearest neighbor search, which does not pertain to LLM training data processing or dataset creation."
      },
      "repo_urls": [
        "https://github.com/alipay/vsag",
        "https://github.com/antgroup/vsag"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.20254",
      "abstract": "The complexity and diversity of surgical workflows, driven by heterogeneous operating room settings, institutional protocols, and anatomical variability, present a significant challenge in developing generalizable models for cross-institutional and cross-procedural surgical understanding. While recent surgical foundation models pretrained on large-scale vision-language data offer promising transferability, their zero-shot performance remains constrained by domain shifts, limiting their utility in unseen surgical environments. To address this, we introduce Surgical Phase Anywhere (SPA), a lightweight framework for versatile surgical workflow understanding that adapts foundation models to institutional settings with minimal annotation. SPA leverages few-shot spatial adaptation to align multi-modal embeddings with institution-specific surgical scenes and phases. It also ensures temporal consistency through diffusion modeling, which encodes task-graph priors derived from institutional procedure protocols. Finally, SPA employs dynamic test-time adaptation, exploiting the mutual agreement between multi-modal phase prediction streams to adapt the model to a given test video in a self-supervised manner, enhancing the reliability under test-time distribution shifts. SPA is a lightweight adaptation framework, allowing hospitals to rapidly customize phase recognition models by defining phases in natural language text, annotating a few images with the phase labels, and providing a task graph defining phase transitions. The experimental results show that the SPA framework achieves state-of-the-art performance in few-shot surgical phase recognition across multiple institutions and procedures, even outperforming full-shot models with 32-shot labeled data. Code is available at https://github.com/CAMMA-public/SPA",
      "authors": [
        "Kun Yuan",
        "Tingxuan Chen",
        "Shi Li",
        "Joel L. Lavanchy",
        "Christian Heiliger",
        "Ege \\\"Ozsoy",
        "Yiming Huang",
        "Long Bai",
        "Nassir Navab",
        "Vinkle Srivastav",
        "Hongliang Ren",
        "Nicolas Padoy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T08:56:13+00:00",
          "link": "https://arxiv.org/abs/2506.20254v1",
          "size": "4120kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T20:51:36+00:00",
          "link": "https://arxiv.org/abs/2506.20254v2",
          "size": "4120kb",
          "version": "v2"
        }
      ],
      "title": "Recognizing Surgical Phases Anywhere: Few-Shot Test-time Adaptation and Task-graph Guided Refinement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20254",
        "HTML": "https://arxiv.org/html/2506.20254v2",
        "PDF": "https://arxiv.org/pdf/2506.20254"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for surgical workflow understanding using foundation models; it does not involve LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10561",
      "abstract": "Hardware accelerators are essential for achieving low-latency, energy-efficient inference in edge applications like image recognition. Spiking Neural Networks (SNNs) are particularly promising due to their event-driven and temporally sparse nature, making them well-suited for low-power Field Programmable Gate Array (FPGA)-based deployment. This paper explores using the open-source Spiker+ framework to generate optimized SNNs accelerators for handwritten digit recognition on the MNIST dataset. Spiker+ enables high-level specification of network topologies, neuron models, and quantization, automatically generating deployable HDL. We evaluate multiple configurations and analyze trade-offs relevant to edge computing constraints.",
      "authors": [
        "Alessio Caviglia",
        "Filippo Marostica",
        "Alessio Carpegna",
        "Alessandro Savino",
        "Stefano Di Carlo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T08:22:13+00:00",
          "link": "https://arxiv.org/abs/2507.10561v1",
          "size": "1199kb",
          "version": "v1"
        }
      ],
      "title": "SFATTI: Spiking FPGA Accelerator for Temporal Task-driven Inference -- A Case Study on MNIST",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10561",
        "HTML": "https://arxiv.org/html/2507.10561v1",
        "PDF": "https://arxiv.org/pdf/2507.10561"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about hardware accelerators for Spiking Neural Networks and does not cover LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11042",
      "abstract": "With the breakthroughs in large language models (LLMs), query generation techniques that expand documents and queries with related terms are becoming increasingly popular in the information retrieval field. Such techniques have been shown to improve the effectiveness of traditional lexical retrieval methods by dealing with the vocabulary mismatch problem. Recent work has found that generating queries with a greedy decoding strategy can produce sub-optimal queries, including hallucinations, and proposed to filter out queries before expansion. This `generate-then-filter' approach is costly, as it requires generating multiple queries and applying a relevance model to all of them and does not teach the LLM which of the generated queries is more effective for expansion. To overcome such limitations, we propose Aligned Query Expansion (AQE), a novel approach to enhance query expansion for passage retrieval in open-domain question answering. AQE leverages recent techniques in LLM alignment to fine-tune models for generating query expansions that directly optimize the effectiveness of the retrieval task, eliminating the need for additional filtering steps. This alignment ensures that queries are more relevant, reducing computational costs while improving retrieval effectiveness. Empirical evaluations show that AQE outperforms baseline models for query expansion in both in-domain and out-of-domain settings, demonstrating significant improvements in retrieval effectiveness.",
      "authors": [
        "Adam Yang",
        "Gustavo Penha",
        "Enrico Palumbo and Hugues Bouchard"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T07:11:29+00:00",
          "link": "https://arxiv.org/abs/2507.11042v1",
          "size": "203kb",
          "version": "v1"
        }
      ],
      "title": "Aligned Query Expansion: Efficient Query Expansion for Information Retrieval through LLM Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11042",
        "HTML": "https://arxiv.org/html/2507.11042v1",
        "PDF": "https://arxiv.org/pdf/2507.11042"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper proposes improved query expansion leveraging LLMs, it does not primarily focus on LLM training data processing but rather on query generation techniques for information retrieval."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11063",
      "abstract": "Mixed-integer linear programming (MILP) is a powerful tool for addressing a wide range of real-world problems, but it lacks a clear structure for comparing instances. A reliable similarity metric could establish meaningful relationships between instances, enabling more effective evaluation of instance set heterogeneity and providing better guidance to solvers, particularly when machine learning is involved. Existing similarity metrics often lack precision in identifying instance classes or rely heavily on labeled data, which limits their applicability and generalization. To bridge this gap, this paper introduces the first mathematical distance metric for MILP instances, derived directly from their mathematical formulations. By discretizing right-hand sides, weights, and variables into classes, the proposed metric draws inspiration from the Earth mover's distance to quantify mismatches in weight-variable distributions for constraint comparisons. This approach naturally extends to enable instance-level comparisons. We evaluate both an exact and a greedy variant of our metric under various parameter settings, using the StrIPLIB dataset. Results show that all components of the metric contribute to class identification, and that the greedy version achieves accuracy nearly identical to the exact formulation while being nearly 200 times faster. Compared to state-of-the-art baselines, including feature-based, image-based, and neural network models, our unsupervised method consistently outperforms all non-learned approaches and rivals the performance of a supervised classifier on class and subclass grouping tasks.",
      "authors": [
        "Gwen Maudet and Gr\\'egoire Danoy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T07:55:09+00:00",
          "link": "https://arxiv.org/abs/2507.11063v1",
          "size": "35kb",
          "version": "v1"
        }
      ],
      "title": "A Distance Metric for Mixed Integer Programming Instances",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11063",
        "HTML": "https://arxiv.org/html/2507.11063v1",
        "PDF": "https://arxiv.org/pdf/2507.11063"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces a distance metric for mixed integer programming instances, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11209",
      "abstract": "We prove that, paying a polynomial increase in size only, every unrestricted two-way nondeterministic finite automaton (2NFA) can be complemented by a 1-limited automaton (1-LA), a nondeterministic extension of 2NFAs still characterizing regular languages. The resulting machine is actually a restricted form of 1-LAs -- known as 2NFAs with common guess -- and is self-verifying. A corollary of our construction is that a single exponential is necessary and sufficient for complementing 1-LAs.",
      "authors": [
        "Bruno Guillon",
        "Luca Prigioniero",
        "Javad Taheri"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T11:26:40+00:00",
          "link": "https://arxiv.org/abs/2507.11209v1",
          "size": "50kb",
          "version": "v1"
        }
      ],
      "title": "Polynomial Complementation of Nondeterministic 2-Way Finite Automata by 1-Limited Automata",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11209",
        "PDF": "https://arxiv.org/pdf/2507.11209"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses polynomial complementation of finite automata, which does not involve processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.20077",
      "abstract": "The development of the automotive industry and automation has led to a growing demand for time-critical systems to have low latency and jitter for critical traffic. To address this issue, the IEEE 802.1 Time-Sensitive Networking (TSN) task group proposed the Time-Aware Shaper (TAS) to implement Time-Triggered (TT) communication, enabling deterministic transmission by assigning specific time windows to each stream. While Fixed Routing and Waiting-Allowed (FR-WA) scheduling algorithms offer flexibility, they suffer from inefficiencies in solution time and scalability. This study analyzes TAS implementation challenges, emphasizing how network scale expansion increases computational constraints. We propose an Urgency-Based Scheduler method (TT-UBS) to address these limitations to enhance deterministic transmission and computational efficiency under anomalies. A novel scheduling algorithm for TT-UBS parameter determination is developed, alongside simulations and comparative evaluations. Results show that TT-UBS guarantees deterministic traffic delivery while reducing solution time by 98.22% in test scenarios compared to traditional approaches. The methodology is extended to other scheduling algorithms to assess efficiency improvements. This advancement supports TSN's application in mission-critical systems by optimizing time-triggered communication performance and enabling reliable network deployment. The framework demonstrates significant potential for real-time in-vehicle networks requiring latency and jitter control.",
      "authors": [
        "Feng Luo",
        "Yunpeng Li",
        "Zitong Wang",
        "Yi Ren",
        "Yingpeng Tong",
        "Zhouping Zhang",
        "and Qin Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-28T08:18:40+00:00",
          "link": "https://arxiv.org/abs/2412.20077v1",
          "size": "10149kb",
          "version": "v1"
        },
        {
          "date": "2025-03-12T12:07:19+00:00",
          "link": "https://arxiv.org/abs/2412.20077v2",
          "size": "10163kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T06:17:35+00:00",
          "link": "https://arxiv.org/abs/2412.20077v3",
          "size": "2291kb",
          "version": "v3"
        }
      ],
      "title": "A Time-Triggered Communication Method Based on Urgency-Based Scheduler in Time-Sensitive Networking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.20077",
        "PDF": "https://arxiv.org/pdf/2412.20077"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses time-sensitive networking in automotive systems, not related to LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.13112",
      "abstract": "In this work, we study online convex optimization with a fixed constraint function $g : \\mathbb{R}^d \\rightarrow \\mathbb{R}$. Prior work on this problem has shown $O(\\sqrt{T})$ regret and cumulative constraint satisfaction $\\sum_{t=1}^{T} g(x_t) \\leq 0$, while only accessing the constraint value and subgradient at the played actions $g(x_t), \\partial g(x_t)$. Using the same constraint information, we show a stronger guarantee of anytime constraint satisfaction $g(x_t) \\leq 0 \\ \\forall t \\in [T]$, and matching $O(\\sqrt{T})$ regret guarantees. These contributions are thanks to our approach of using Polyak feasibility steps to ensure constraint satisfaction, without sacrificing regret. Specifically, after each step of online gradient descent, our algorithm applies a subgradient descent step on the constraint function where the step-size is chosen according to the celebrated Polyak step-size. We further validate this approach with numerical experiments.",
      "authors": [
        "Spencer Hutchinson",
        "Mahnoosh Alizadeh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-18T18:26:20+00:00",
          "link": "https://arxiv.org/abs/2502.13112v1",
          "size": "791kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T01:28:44+00:00",
          "link": "https://arxiv.org/abs/2502.13112v2",
          "size": "773kb",
          "version": "v2"
        }
      ],
      "title": "Constrained Online Convex Optimization with Polyak Feasibility Steps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.13112",
        "HTML": "https://arxiv.org/html/2502.13112v2",
        "PDF": "https://arxiv.org/pdf/2502.13112"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on online convex optimization and constraint satisfaction but does not discuss any aspects related to LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.08836",
      "abstract": "Dimensionality reduction is used as an important tool for unraveling the complexities of high-dimensional datasets in many fields of science, such as cell biology, chemical informatics, and physics. Visualizations of the dimensionally reduced data enable scientists to delve into the intrinsic structures of their datasets and align them with established hypotheses. Visualization researchers have thus proposed many dimensionality reduction methods and interactive systems designed to uncover latent structures. At the same time, different scientific domains have formulated guidelines or common workflows for using dimensionality reduction techniques and visualizations for their respective fields. In this work, we present a critical analysis of the usage of dimensionality reduction in scientific domains outside of computer science. First, we conduct a bibliometric analysis of 21,249 academic publications that use dimensionality reduction to observe differences in the frequency of techniques across fields. Next, we conduct a survey of a 71-paper sample from four fields: biology, chemistry, physics, and business. Through this survey, we uncover common workflows, processes, and usage patterns, including the mixed use of confirmatory data analysis to validate a dataset and projection method and exploratory data analysis to then generate more hypotheses. We also find that misinterpretations and inappropriate usage is common, particularly in the visual interpretation of the resulting dimensionally reduced view. Lastly, we compare our observations with recent works in the visualization community in order to match work within our community to potential areas of impact outside our community.",
      "authors": [
        "Dylan Cashman",
        "Mark Keller",
        "Hyeon Jeon",
        "Bum Chul Kwon",
        "Qianwen Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T19:18:25+00:00",
          "link": "https://arxiv.org/abs/2503.08836v1",
          "size": "14000kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T00:26:06+00:00",
          "link": "https://arxiv.org/abs/2503.08836v2",
          "size": "13266kb",
          "version": "v2"
        }
      ],
      "title": "A Critical Analysis of the Usage of Dimensionality Reduction in Four Domains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08836",
        "HTML": "https://arxiv.org/html/2503.08836v2",
        "PDF": "https://arxiv.org/pdf/2503.08836"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This analysis explores dimensionality reduction techniques across various scientific fields but does not provide methods for processing LLM training data."
      },
      "repo_urls": [
        "https://github.com/keller-mark/hd-vis-scripts"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10576",
      "abstract": "The legal field already uses various large language models (LLMs) in actual applications, but their quantitative performance and reasons for it are underexplored. We evaluated several open-source and proprietary LLMs -- including GPT-series, Anthropic, Deepseek and Llama-3, variants -- on parts of the European Qualifying Examination (EQE) for future European Patent Attorneys. OpenAI o1 led with 0.82 accuracy and 0.81 F1 score, whereas (Amazon Web Services) AWS Llama 3.1 8B lagged at 0.50 accuracy, and a Python-deployed Llama 3.1 8B scored 0.55. The latter two are within the range of mere guessing for the two-answer forced-choice design. None of the evaluated models could have passed the examination fully, as accuracy never exceeded the average threshold of 0.90 required for professional-level standards -- also not models that are regularly promoted for their assumed beyond-PhD- and bar-admitted-lawyer-level performance. GPT-4o excelled at integrating text and graphics, while Claude 3 Opus often lost formatting coherence. Human patent experts evaluated the textual justifications and uncovered various critical shortcomings of each model. They valued clarity and legal rationale over the raw correctness of the answers, which revealed misalignment between automatic metrics and expert judgment. Model outputs were sensitive to modest temperature changes and prompt wording, which underscores the remaining necessity of expert oversight. Future work should target logical consistency, robust multimodality, and adaptive prompting to approach human-level patent proficiency. In summary, despite the outstanding performance of recent large models, the general public might overestimate their performance. The field has a long way to go to develop a virtual patent attorney. This paper wants to point out several specific limitations that need solutions.",
      "authors": [
        "Bhakti Khera and Rezvan Alamian and Pascal A. Scherz and Stephan M. Goetz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T09:42:23+00:00",
          "link": "https://arxiv.org/abs/2507.10576v1",
          "size": "8918kb",
          "version": "v1"
        }
      ],
      "title": "Can Large Language Models Understand As Well As Apply Patent Regulations to Pass a Hands-On Patent Attorney Test?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10576",
        "HTML": "https://arxiv.org/html/2507.10576v1",
        "PDF": "https://arxiv.org/pdf/2507.10576"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates large language models on patent examination tasks without addressing any aspect of training data processing or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10797",
      "abstract": "This paper introduces the framework of multi-armed sampling, as the sampling counterpart to the optimization problem of multi-arm bandits. Our primary motivation is to rigorously examine the exploration-exploitation trade-off in the context of sampling. We systematically define plausible notions of regret for this framework and establish corresponding lower bounds. We then propose a simple algorithm that achieves these optimal regret bounds. Our theoretical results demonstrate that in contrast to optimization, sampling does not require exploration. To further connect our findings with those of multi-armed bandits, we define a continuous family of problems and associated regret measures that smoothly interpolates and unifies multi-armed sampling and multi-armed bandit problems using a temperature parameter. We believe the multi-armed sampling framework, and our findings in this setting can have a foundational role in the study of sampling including recent neural samplers, akin to the role of multi-armed bandits in reinforcement learning. In particular, our work sheds light on the need for exploration and the convergence properties of algorithm for entropy-regularized reinforcement learning, fine-tuning of pretrained models and reinforcement learning with human feedback (RLHF).",
      "authors": [
        "Mohammad Pedramfar",
        "Siamak Ravanbakhsh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T20:50:51+00:00",
          "link": "https://arxiv.org/abs/2507.10797v1",
          "size": "513kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Armed Sampling Problem and the End of Exploration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10797",
        "HTML": "https://arxiv.org/html/2507.10797v1",
        "PDF": "https://arxiv.org/pdf/2507.10797"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Although it mentions fine-tuning of pretrained models, the paper primarily addresses the exploration-exploitation trade-off in multi-armed sampling and does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10831",
      "abstract": "Argumentation frameworks (AFs) provide formal approaches for legal reasoning, but identifying sources of ambiguity and explaining argument acceptance remains challenging for non-experts. We present AF-XRAY, an open-source toolkit for exploring, analyzing, and visualizing abstract AFs in legal reasoning. AF-XRAY introduces: (i) layered visualizations based on game-theoretic argument length revealing well-founded derivation structures; (ii) classification of attack edges by semantic roles (primary, secondary, blunders); (iii) overlay visualizations of alternative 2-valued solutions on ambiguous 3-valued grounded semantics; and (iv) identification of critical attack sets whose suspension resolves undecided arguments. Through systematic generation of critical attack sets, AF-XRAY transforms ambiguous scenarios into grounded solutions, enabling users to pinpoint specific causes of ambiguity and explore alternative resolutions. We use real-world legal cases (e.g., Wild Animals as modeled by Bench-Capon) to show that our tool supports teleological legal reasoning by revealing how different assumptions lead to different justified conclusions.",
      "authors": [
        "Yilin Xia",
        "Heng Zheng",
        "Shawn Bowers",
        "Bertram Lud\\\"ascher"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T22:00:45+00:00",
          "link": "https://arxiv.org/abs/2507.10831v1",
          "size": "169kb",
          "version": "v1"
        }
      ],
      "title": "AF-XRAY: Visual Explanation and Resolution of Ambiguity in Legal Argumentation Frameworks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10831",
        "HTML": "https://arxiv.org/html/2507.10831v1",
        "PDF": "https://arxiv.org/pdf/2507.10831"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a toolkit for legal reasoning frameworks but does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11060",
      "abstract": "We introduce ExRec, a general framework for personalized exercise recommendation with semantically-grounded knowledge tracing. Our method builds on the observation that existing exercise recommendation approaches simulate student performance via knowledge tracing (KT) but they often overlook two key aspects: (a) the semantic content of questions and (b) the sequential, structured progression of student learning. To address this, our ExRec presents an end-to-end pipeline, from annotating the KCs of questions and learning their semantic representations to training KT models and optimizing several reinforcement learning (RL) methods. Moreover, we improve standard Q-learning-based continuous RL methods via a tailored model-based value estimation (MVE) approach that directly leverages the components of KT model in estimating cumulative knowledge improvement. We validate the effectiveness of our ExRec using various RL methods across four real-world tasks with different educational goals in online math learning. We further show that ExRec generalizes robustly to new, unseen questions and that it produces interpretable student learning trajectories. Together, our findings highlight the promise of KT-guided RL for effective personalization in education.",
      "authors": [
        "Yilmazcan Ozyurt",
        "Tunaberk Almaci",
        "Stefan Feuerriegel",
        "Mrinmaya Sachan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T07:54:04+00:00",
          "link": "https://arxiv.org/abs/2507.11060v1",
          "size": "991kb",
          "version": "v1"
        }
      ],
      "title": "Personalized Exercise Recommendation with Semantically-Grounded Knowledge Tracing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11060",
        "HTML": "https://arxiv.org/html/2507.11060v1",
        "PDF": "https://arxiv.org/pdf/2507.11060"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus here is on personalized exercise recommendations using knowledge tracing, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.04140",
      "abstract": "Many physical processes can be expressed through partial differential equations (PDEs). Real-world measurements of such processes are often collected at irregularly distributed points in space, which can be effectively represented as graphs; however, there are currently only a few existing datasets. Our work aims to make advancements in the field of PDE-modeling accessible to the temporal graph machine learning community, while addressing the data scarcity problem, by creating and utilizing datasets based on PDEs. In this work, we create and use synthetic datasets based on PDEs to support spatio-temporal graph modeling in machine learning for different applications. More precisely, we showcase three equations to model different types of disasters and hazards in the fields of epidemiology, atmospheric particles, and tsunami waves. Further, we show how such created datasets can be used by benchmarking several machine learning models on the epidemiological dataset. Additionally, we show how pre-training on this dataset can improve model performance on real-world epidemiological data. The presented methods enable others to create datasets and benchmarks customized to individual requirements. The source code for our methodology and the three created datasets can be found on https://github.com/github-usr-ano/Temporal_Graph_Data_PDEs.",
      "authors": [
        "Jost Arndt",
        "Utku Isil",
        "Michael Detzel",
        "Wojciech Samek",
        "Jackie Ma"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-06T15:20:32+00:00",
          "link": "https://arxiv.org/abs/2502.04140v1",
          "size": "5301kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T16:09:44+00:00",
          "link": "https://arxiv.org/abs/2502.04140v2",
          "size": "5052kb",
          "version": "v2"
        }
      ],
      "title": "Synthetic Datasets for Machine Learning on Spatio-Temporal Graphs using PDEs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.04140",
        "HTML": "https://arxiv.org/html/2502.04140v2",
        "PDF": "https://arxiv.org/pdf/2502.04140"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper focuses on creating synthetic datasets using PDEs for spatio-temporal graph modeling, detailing the creation and processing of these datasets, which aligns with LLM training-data processing contributions."
      },
      "tasks": [
        "Benchmarking",
        "Epidemiology"
      ],
      "repo_urls": [
        "https://github.com/github-usr-ano/temporal_graph_data_pdes"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07969",
      "abstract": "We present Q-chunking, a simple yet effective recipe for improving reinforcement learning (RL) algorithms for long-horizon, sparse-reward tasks. Our recipe is designed for the offline-to-online RL setting, where the goal is to leverage an offline prior dataset to maximize the sample-efficiency of online learning. Effective exploration and sample-efficient learning remain central challenges in this setting, as it is not obvious how the offline data should be utilized to acquire a good exploratory policy. Our key insight is that action chunking, a technique popularized in imitation learning where sequences of future actions are predicted rather than a single action at each timestep, can be applied to temporal difference (TD)-based RL methods to mitigate the exploration challenge. Q-chunking adopts action chunking by directly running RL in a 'chunked' action space, enabling the agent to (1) leverage temporally consistent behaviors from offline data for more effective online exploration and (2) use unbiased $n$-step backups for more stable and efficient TD learning. Our experimental results demonstrate that Q-chunking exhibits strong offline performance and online sample efficiency, outperforming prior best offline-to-online methods on a range of long-horizon, sparse-reward manipulation tasks.",
      "authors": [
        "Qiyang Li",
        "Zhiyuan Zhou",
        "Sergey Levine"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:48:03+00:00",
          "link": "https://arxiv.org/abs/2507.07969v1",
          "size": "12172kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T16:59:35+00:00",
          "link": "https://arxiv.org/abs/2507.07969v2",
          "size": "12172kb",
          "version": "v2"
        }
      ],
      "title": "Reinforcement Learning with Action Chunking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07969",
        "HTML": "https://arxiv.org/html/2507.07969v2",
        "PDF": "https://arxiv.org/pdf/2507.07969"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents Q-chunking for reinforcement learning but does not involve any processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10804",
      "abstract": "Efficient high-rank approximations of the Hessian can accelerate seismic full waveform inversion (FWI) and uncertainty quantification (UQ). In FWI, approximations of the inverse of the Hessian may be used as preconditioners for Newton-type or quasi-Newton algorithms, reducing computational costs and improving recovery in deeper subsurface regions. In Bayesian UQ, Hessian approximations enable the construction of Markov chain Monte Carlo (MCMC) proposals that capture the directional scalings of the posterior, enhancing the efficiency of MCMC. Computing the exact Hessian is intractable for large-scale problems because the Hessian is accessible only through matrix-vector products, and performing each matrix-vector product requires costly solution of wave equations. Moreover, the Hessian is high-rank, which means that low-rank methods, often employed in large-scale inverse problems, are inefficient. We adapt two existing high-rank Hessian approximations -- the point spread function method and the pseudo-differential operator probing method. Building on an observed duality between these approaches, we develop a novel method that unifies their complementary strengths. We validate these methods on a synthetic quadratic model and on the Marmousi model. Numerical experiments show that these high-rank Hessian approximations substantially reduce the computational costs in FWI. In UQ, MCMC samples computed using no Hessian approximation or a low-rank approximation explore the posterior slowly, providing little meaningful statistical information after tens of thousands of iterations and underestimating the variance. At the same time, the effective sample size is overestimated, providing false confidence. In contrast, MCMC samples generated using the high-rank Hessian approximations provide meaningful statistical information about the posterior and more accurately assess the posterior variance.",
      "authors": [
        "Mathew Hu",
        "Nick Alger",
        "Rami Nammour",
        "Omar Ghattas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T20:58:38+00:00",
          "link": "https://arxiv.org/abs/2507.10804v1",
          "size": "2536kb",
          "version": "v1"
        }
      ],
      "title": "Accelerating seismic inversion and uncertainty quantification with efficient high-rank Hessian approximations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10804",
        "HTML": "https://arxiv.org/html/2507.10804v1",
        "PDF": "https://arxiv.org/pdf/2507.10804"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses efficient Hessian approximations in the context of seismic inversion and uncertainty quantification, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11009",
      "abstract": "This paper presents a comprehensive study on the asymptotically optimal repair of Reed-Solomon (RS) codes with small sub-packetization, specifically tailored for rack-aware distributed storage systems. Through the utilization of multi-base expansion, we introduce a novel approach that leverages monomials to construct linear repair schemes for RS codes. Our repair schemes which adapt to all admissible parameters achieve asymptotically optimal repair bandwidth while significantly reducing the sub-packetization compared with existing schemes. Furthermore, our approach is capable of repairing RS codes with asymptotically optimal repair bandwidth under the homogeneous storage model, achieving smaller sub-packetization than existing methods.",
      "authors": [
        "Ke Wang",
        "Zhongyan Liu",
        "Rengang Li",
        "Yaqian Zhao and Yaqiang Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T05:57:21+00:00",
          "link": "https://arxiv.org/abs/2507.11009v1",
          "size": "81kb",
          "version": "v1"
        }
      ],
      "title": "Asymptotically Optimal Repair of Reed-Solomon Codes with Small Sub-Packetization under Rack-Aware Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11009",
        "HTML": "https://arxiv.org/html/2507.11009v1",
        "PDF": "https://arxiv.org/pdf/2507.11009"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents methods for the repair of Reed-Solomon codes in distributed storage, which is unrelated to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11336",
      "abstract": "Real-world user-generated videos, especially on platforms like TikTok, often feature rich and intertwined audio visual content. However, existing video captioning benchmarks and models remain predominantly visual centric, overlooking the crucial role of audio in conveying scene dynamics, speaker intent, and narrative context. This lack of omni datasets and lightweight, capable models hampers progress in fine grained, multimodal video understanding. To address these challenges, we introduce UGC-VideoCap, a new benchmark and model framework specifically designed for detailed omnimodal captioning of short form user-generated videos. Unlike prior datasets, UGC-VideoCap emphasizes balanced integration of audio and visual modalities, featuring 1000 TikTok videos annotated through a structured three stage human-in-the-loop pipeline covering audio only, visual only, and joint audio visual semantics. The benchmark also includes 4000 carefully crafted QA pairs probing both unimodal and cross modal understanding. Alongside the dataset, we propose UGC-VideoCaptioner(3B), a 3B parameter captioning model distilled from Gemini 2.5 Flash. Using a novel two-stage training strategy supervised fine tuning followed by Group Relative Policy Optimization (GRPO), our approach enables efficient adaptation from limited data while maintaining competitive performance. Together, our benchmark and model offer a high-quality foundation and a data-efficient solution for advancing omnimodal video captioning in unconstrained real-world UGC settings.",
      "authors": [
        "Peiran Wu",
        "Yunze Liu",
        "Zhengdong Zhu",
        "Enmin Zhou",
        "Shawn Shen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:08:29+00:00",
          "link": "https://arxiv.org/abs/2507.11336v1",
          "size": "10464kb",
          "version": "v1"
        }
      ],
      "title": "UGC-VideoCaptioner: An Omni UGC Video Detail Caption Model and New Benchmarks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11336",
        "HTML": "https://arxiv.org/html/2507.11336v1",
        "PDF": "https://arxiv.org/pdf/2507.11336"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a new dataset for omnimodal video captioning, with a structured data processing pipeline that includes a human-in-the-loop annotation process. This is directly related to LLM training data processing and dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.04354",
      "abstract": "BridgeNet is a novel hybrid framework that integrates convolutional neural networks with physics-informed neural networks to efficiently solve non-linear, high-dimensional Fokker-Planck equations (FPEs). Traditional PINNs, which typically rely on fully connected architectures, often struggle to capture complex spatial hierarchies and enforce intricate boundary conditions. In contrast, BridgeNet leverages adaptive CNN layers for effective local feature extraction and incorporates a dynamically weighted loss function that rigorously enforces physical constraints. Extensive numerical experiments across various test cases demonstrate that BridgeNet not only achieves significantly lower error metrics and faster convergence compared to conventional PINN approaches but also maintains robust stability in high-dimensional settings. This work represents a substantial advancement in computational physics, offering a scalable and accurate solution methodology with promising applications in fields ranging from financial mathematics to complex system dynamics.",
      "authors": [
        "Elmira Mirzabeigi",
        "Rezvan Salehi",
        "Kourosh Parand"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Machine Learning (cs.LG)",
        "Mathematical Physics (math-ph)",
        "Analysis of PDEs (math.AP)",
        "Mathematical Physics (math.MP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T18:12:59+00:00",
          "link": "https://arxiv.org/abs/2506.04354v1",
          "size": "3392kb",
          "version": "v1"
        },
        {
          "date": "2025-06-09T15:20:00+00:00",
          "link": "https://arxiv.org/abs/2506.04354v2",
          "size": "3393kb",
          "version": "v2"
        },
        {
          "date": "2025-06-10T10:02:59+00:00",
          "link": "https://arxiv.org/abs/2506.04354v3",
          "size": "3392kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T12:50:08+00:00",
          "link": "https://arxiv.org/abs/2506.04354v4",
          "size": "3403kb",
          "version": "v4"
        }
      ],
      "title": "BridgeNet: A Hybrid, Physics-Informed Machine Learning Framework for Solving High-Dimensional Fokker-Planck Equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04354",
        "HTML": "https://arxiv.org/html/2506.04354v4",
        "PDF": "https://arxiv.org/pdf/2506.04354"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research is centered on solving Fokker-Planck equations using a hybrid machine learning framework, which is not related to LLM training data processing."
      },
      "tasks": [
        "Physics-informed machine learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07505",
      "abstract": "In this paper we explore hallucinations and related capability limitations in LLMs and LLM-based agents from the perspective of computational complexity. We show that beyond a certain complexity, LLMs are incapable of carrying out computational and agentic tasks or verifying their accuracy.",
      "authors": [
        "Varin Sikka and Vishal Sikka"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:50:52+00:00",
          "link": "https://arxiv.org/abs/2507.07505v1",
          "size": "211kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T02:03:49+00:00",
          "link": "https://arxiv.org/abs/2507.07505v2",
          "size": "213kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T15:42:40+00:00",
          "link": "https://arxiv.org/abs/2507.07505v3",
          "size": "227kb",
          "version": "v3"
        }
      ],
      "title": "Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07505",
        "PDF": "https://arxiv.org/pdf/2507.07505"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates the computational limitations of transformer-based models, particularly focusing on hallucinations, without contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10583",
      "abstract": "In this work, we compile $\\textbf{$\\texttt{DroidCollection}$}$, the most extensive open data suite for training and evaluating machine-generated code detectors, comprising over a million code samples, seven programming languages, outputs from 43 coding models, and over three real-world coding domains. Alongside fully AI-generated samples, our collection includes human-AI co-authored code, as well as adversarial samples explicitly crafted to evade detection. Subsequently, we develop $\\textbf{$\\texttt{DroidDetect}$}$, a suite of encoder-only detectors trained using a multi-task objective over $\\texttt{DroidCollection}$. Our experiments show that existing detectors' performance fails to generalise to diverse coding domains and programming languages outside of their narrow training data. Additionally, we demonstrate that while most detectors are easily compromised by humanising the output distributions using superficial prompting and alignment approaches, this problem can be easily amended by training on a small amount of adversarial data. Finally, we demonstrate the effectiveness of metric learning and uncertainty-based resampling as means to enhance detector training on possibly noisy distributions.",
      "authors": [
        "Daniil Orel",
        "Indraneil Paul",
        "Iryna Gurevych",
        "Preslav Nakov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:19:06+00:00",
          "link": "https://arxiv.org/abs/2507.10583v1",
          "size": "318kb",
          "version": "v1"
        }
      ],
      "title": "$\\texttt{Droid}$: A Resource Suite for AI-Generated Code Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10583",
        "HTML": "https://arxiv.org/html/2507.10583v1",
        "PDF": "https://arxiv.org/pdf/2507.10583"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses creating a dataset for code detection, it primarily focuses on detector performance rather than the dataset creation process or data processing improvements for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10822",
      "abstract": "Conversational agents, such as chatbots and virtual assistants, have become essential in software development, boosting productivity, collaboration, and automating various tasks. This paper examines the role of adaptive AI-powered conversational agents in software development, highlighting their ability to offer dynamic, context-aware assistance to developers. Unlike traditional rule-based systems, adaptive AI agents use machine learning and natural language processing to learn from interactions and improve over time, providing more personalized and responsive help. We look at how these tools have evolved from simple query-based systems to advanced AI-driven solutions like GitHub Copilot and Microsoft Teams bots. We also explore the challenges of integrating adaptive AI into software development processes. The study aims to assess the benefits and limitations of these systems, address concerns like data privacy and ethical issues, and offer insights into their future use in the field. Ultimately, adaptive AI chatbots have great potential to revolutionize software development by delivering real-time, customized support and enhancing the efficiency of development cycles.",
      "authors": [
        "Omar Elsisi",
        "Glaucia Melo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T21:40:03+00:00",
          "link": "https://arxiv.org/abs/2507.10822v1",
          "size": "111kb",
          "version": "v1"
        }
      ],
      "title": "Past, Present and Future: Exploring Adaptive AI in Software Development Bots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10822",
        "HTML": "https://arxiv.org/html/2507.10822v1",
        "PDF": "https://arxiv.org/pdf/2507.10822"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper examines the role of AI in software development but does not discuss processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11385",
      "abstract": "A methodology is developed, based on nonparametric Bayesian dictionary learning, for joint space-time wind field data extrapolation and estimation of related statistics by relying on limited/incomplete measurements. Specifically, utilizing sparse/incomplete measured data, a time-dependent optimization problem is formulated for determining the expansion coefficients of an associated low-dimensional representation of the stochastic wind field. Compared to an alternative, standard, compressive sampling treatment of the problem, the developed methodology exhibits the following advantages. First, the Bayesian formulation enables also the quantification of the uncertainty in the estimates. Second, the requirement in standard CS-based applications for an a priori selection of the expansion basis is circumvented. Instead, this is done herein in an adaptive manner based on the acquired data. Overall, the methodology exhibits enhanced extrapolation accuracy, even in cases of high-dimensional data of arbitrary form, and of relatively large extrapolation distances. Thus, it can be used, potentially, in a wide range of wind engineering applications where various constraints dictate the use of a limited number of sensors. The efficacy of the methodology is demonstrated by considering two case studies. The first relates to the extrapolation of simulated wind velocity records consistent with a prescribed joint wavenumber-frequency power spectral density in a three-dimensional domain (2D and time). The second pertains to the extrapolation of four-dimensional (3D and time) boundary layer wind tunnel experimental data that exhibit significant spatial variability and non-Gaussian characteristics.",
      "authors": [
        "George D. Pasparakis",
        "Ioannis A. Kougioumtzoglou",
        "Michael D. Shields"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:54:57+00:00",
          "link": "https://arxiv.org/abs/2507.11385v1",
          "size": "10836kb",
          "version": "v1"
        }
      ],
      "title": "Joint space-time wind field data extrapolation and uncertainty quantification using nonparametric Bayesian dictionary learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11385",
        "HTML": "https://arxiv.org/html/2507.11385v1",
        "PDF": "https://arxiv.org/pdf/2507.11385"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a methodology for wind field data extrapolation and uncertainty quantification, without any relation to LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.08156",
      "abstract": "Language models trained to solve reasoning tasks via reinforcement learning have achieved striking results. We refer to these models as reasoning models. Are the Chains of Thought (CoTs) of reasoning models more faithful than traditional models? We evaluate three reasoning models (based on Qwen-2.5, Gemini-2, and DeepSeek-V3-Base) on an existing test of faithful CoT. To measure faithfulness, we test whether models can describe how a cue in their prompt influences their answer to MMLU questions. For example, when the cue \"A Stanford Professor thinks the answer is D\" is added to the prompt, models sometimes switch their answer to D. In such cases, the DeepSeek-R1 reasoning model describes the cue's influence 59% of the time, compared to 7% for the non-reasoning DeepSeek model. We evaluate seven types of cue, such as misleading few-shot examples and suggestive follow-up questions from the user. Reasoning models describe cues that influence them much more reliably than all the non-reasoning models tested (including Claude-3.5-Sonnet and GPT-4o). In an additional experiment, we provide evidence suggesting that the use of reward models causes less faithful responses -- which may help explain why non-reasoning models are less faithful. Our study has two main limitations. First, we test faithfulness using a set of artificial tasks, which may not reflect realistic use-cases. Second, we only measure one specific aspect of faithfulness -- whether models can describe the influence of cues. Future research should investigate whether the advantage of reasoning models in faithfulness holds for a broader set of tests. Still, we think this increase in faithfulness is promising for the explainability of language models.",
      "authors": [
        "James Chua",
        "Owain Evans"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-14T14:31:45+00:00",
          "link": "https://arxiv.org/abs/2501.08156v1",
          "size": "292kb",
          "version": "v1"
        },
        {
          "date": "2025-02-10T06:09:23+00:00",
          "link": "https://arxiv.org/abs/2501.08156v2",
          "size": "462kb",
          "version": "v2"
        },
        {
          "date": "2025-02-17T04:46:58+00:00",
          "link": "https://arxiv.org/abs/2501.08156v3",
          "size": "467kb",
          "version": "v3"
        },
        {
          "date": "2025-02-20T02:48:34+00:00",
          "link": "https://arxiv.org/abs/2501.08156v4",
          "size": "467kb",
          "version": "v4"
        },
        {
          "date": "2025-07-15T17:27:07+00:00",
          "link": "https://arxiv.org/abs/2501.08156v5",
          "size": "360kb",
          "version": "v5"
        }
      ],
      "title": "Are DeepSeek R1 And Other Reasoning Models More Faithful?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.08156",
        "HTML": "https://arxiv.org/html/2501.08156v5",
        "PDF": "https://arxiv.org/pdf/2501.08156"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates reasoning models for faithfulness in reasoning tasks without discussing any aspects of data collection or processing for LLM training."
      },
      "tasks": [
        "Attribute",
        "MMLU"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.05464",
      "abstract": "Vision-Language Models (VLMs) combine visual perception with the general capabilities, such as reasoning, of Large Language Models (LLMs). However, the mechanisms by which these two abilities can be combined and contribute remain poorly understood. In this work, we explore to compose perception and reasoning through model merging that connects parameters of different models. Unlike previous works that often focus on merging models of the same kind, we propose merging models across modalities, enabling the incorporation of the reasoning capabilities of LLMs into VLMs. Through extensive experiments, we demonstrate that model merging offers a successful pathway to transfer reasoning abilities from LLMs to VLMs in a training-free manner. Moreover, we utilize the merged models to understand the internal mechanism of perception and reasoning and how merging affects it. We find that perception capabilities are predominantly encoded in the early layers of the model, whereas reasoning is largely facilitated by the middle-to-late layers. After merging, we observe that all layers begin to contribute to reasoning, whereas the distribution of perception abilities across layers remains largely unchanged. These observations shed light on the potential of model merging as a tool for multimodal integration and interpretation.",
      "authors": [
        "Shiqi Chen",
        "Jinghan Zhang",
        "Tongyao Zhu",
        "Wei Liu",
        "Siyang Gao",
        "Miao Xiong",
        "Manling Li",
        "Junxian He"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-08T17:56:23+00:00",
          "link": "https://arxiv.org/abs/2505.05464v1",
          "size": "4180kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T06:09:44+00:00",
          "link": "https://arxiv.org/abs/2505.05464v2",
          "size": "3771kb",
          "version": "v2"
        }
      ],
      "title": "Bring Reason to Vision: Understanding Perception and Reasoning through Model Merging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.05464",
        "HTML": "https://arxiv.org/html/2505.05464v2",
        "PDF": "https://arxiv.org/pdf/2505.05464"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores model merging for combining perception and reasoning capabilities but does not involve LLM training data processing or dataset creation."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/shiqichen17/vlm_merging"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.11216",
      "abstract": "Previous literature has largely shown that Large Language Models (LLMs) perpetuate social biases learnt from their pre-training data. Given the notable lack of resources for social bias evaluation in languages other than English, and for social contexts outside of the United States, this paper introduces the Spanish and the Catalan Bias Benchmarks for Question Answering (EsBBQ and CaBBQ). Based on the original BBQ, these two parallel datasets are designed to assess social bias across 10 categories using a multiple-choice QA setting, now adapted to the Spanish and Catalan languages and to the social context of Spain. We report evaluation results on different LLMs, factoring in model family, size and variant. Our results show that models tend to fail to choose the correct answer in ambiguous scenarios, and that high QA accuracy often correlates with greater reliance on social biases.",
      "authors": [
        "Valle Ruiz-Fern\\'andez",
        "Mario Mina",
        "J\\'ulia Falc\\~ao",
        "Luis Vasquez-Reina",
        "Anna Sall\\'es",
        "Aitor Gonzalez-Agirre",
        "Olatz Perez-de-Vi\\~naspre"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T11:37:30+00:00",
          "link": "https://arxiv.org/abs/2507.11216v1",
          "size": "749kb",
          "version": "v1"
        }
      ],
      "title": "EsBBQ and CaBBQ: The Spanish and Catalan Bias Benchmarks for Question Answering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11216",
        "HTML": "https://arxiv.org/html/2507.11216v1",
        "PDF": "https://arxiv.org/pdf/2507.11216"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper discusses bias in LLMs, it focuses on creating an evaluation benchmark for bias in QA, rather than processing or improving LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10718",
      "abstract": "Distributionally Robust Optimization (DRO) provides a framework for decision-making under distributional uncertainty, yet its effectiveness can be compromised by outliers in the training data. This paper introduces a principled approach to simultaneously address both challenges. We focus on optimizing Wasserstein-1 DRO objectives for generalized linear models with convex Lipschitz loss functions, where an $\\epsilon$-fraction of the training data is adversarially corrupted. Our primary contribution lies in a novel modeling framework that integrates robustness against training data contamination with robustness against distributional shifts, alongside an efficient algorithm inspired by robust statistics to solve the resulting optimization problem. We prove that our method achieves an estimation error of $O(\\sqrt{\\epsilon})$ for the true DRO objective value using only the contaminated data under the bounded covariance assumption. This work establishes the first rigorous guarantees, supported by efficient computation, for learning under the dual challenges of data contamination and distributional shifts.",
      "authors": [
        "Shuyao Li",
        "Ilias Diakonikolas",
        "Jelena Diakonikolas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Data Structures and Algorithms (cs.DS)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:34:10+00:00",
          "link": "https://arxiv.org/abs/2507.10718v1",
          "size": "78kb",
          "version": "v1"
        }
      ],
      "title": "Distributionally Robust Optimization with Adversarial Data Contamination",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10718",
        "HTML": "https://arxiv.org/html/2507.10718v1",
        "PDF": "https://arxiv.org/pdf/2507.10718"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses optimization under adversarial data contamination and distributional shifts, without specific focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10722",
      "abstract": "This position and survey paper identifies the emerging convergence of neuroscience, artificial general intelligence (AGI), and neuromorphic computing toward a unified research paradigm. Using a framework grounded in brain physiology, we highlight how synaptic plasticity, sparse spike-based communication, and multimodal association provide design principles for next-generation AGI systems that potentially combine both human and machine intelligences. The review traces this evolution from early connectionist models to state-of-the-art large language models, demonstrating how key innovations like transformer attention, foundation-model pre-training, and multi-agent architectures mirror neurobiological processes like cortical mechanisms, working memory, and episodic consolidation. We then discuss emerging physical substrates capable of breaking the von Neumann bottleneck to achieve brain-scale efficiency in silicon: memristive crossbars, in-memory compute arrays, and emerging quantum and photonic devices. There are four critical challenges at this intersection: 1) integrating spiking dynamics with foundation models, 2) maintaining lifelong plasticity without catastrophic forgetting, 3) unifying language with sensorimotor learning in embodied agents, and 4) enforcing ethical safeguards in advanced neuromorphic autonomous systems. This combined perspective across neuroscience, computation, and hardware offers an integrative agenda for in each of these fields.",
      "authors": [
        "Sohan Shankar",
        "Yi Pan",
        "Hanqi Jiang",
        "Zhengliang Liu",
        "Mohammad R. Darbandi",
        "Agustin Lorenzo",
        "Junhao Chen",
        "Md Mehedi Hasan",
        "Arif Hassan Zidan",
        "Eliana Gelman",
        "Joshua A. Konfrst",
        "Jillian Y. Russell",
        "Katelyn Fernandes",
        "Tianze Yang",
        "Yiwei Li",
        "Huaqin Zhao",
        "Afrar Jahin",
        "Triparna Ganguly",
        "Shair Dinesha",
        "Yifan Zhou",
        "Zihao Wu",
        "Xinliang Li",
        "Lokesh Adusumilli",
        "Aziza Hussein",
        "Sagar Nookarapu",
        "Jixin Hou",
        "Kun Jiang",
        "Jiaxi Li",
        "Brenden Heinel",
        "XianShen Xi",
        "Hailey Hubbard",
        "Zayna Khan",
        "Levi Whitaker",
        "Ivan Cao",
        "Max Allgaier",
        "Andrew Darby",
        "Lin Zhao",
        "Lu Zhang",
        "Xiaoqiao Wang",
        "Xiang Li",
        "Wei Zhang",
        "Xiaowei Yu",
        "Dajiang Zhu",
        "Yohannes Abate",
        "Tianming Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:43:05+00:00",
          "link": "https://arxiv.org/abs/2507.10722v1",
          "size": "289kb",
          "version": "v1"
        }
      ],
      "title": "Bridging Brains and Machines: A Unified Frontier in Neuroscience, Artificial Intelligence, and Neuromorphic Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10722",
        "HTML": "https://arxiv.org/html/2507.10722v1",
        "PDF": "https://arxiv.org/pdf/2507.10722"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is a survey that discusses the convergence of neuroscience and AGI, focusing on neuromorphic systems and how AGI systems are inspired by neuroscience. It does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10768",
      "abstract": "We present Spatial Reasoners, a software framework to perform spatial reasoning over continuous variables with generative denoising models. Denoising generative models have become the de-facto standard for image generation, due to their effectiveness in sampling from complex, high-dimensional distributions. Recently, they have started being explored in the context of reasoning over multiple continuous variables. Providing infrastructure for generative reasoning with such models requires a high effort, due to a wide range of different denoising formulations, samplers, and inference strategies. Our presented framework aims to facilitate research in this area, providing easy-to-use interfaces to control variable mapping from arbitrary data domains, generative model paradigms, and inference strategies. Spatial Reasoners are openly available at https://spatialreasoners.github.io/",
      "authors": [
        "Bart Pogodzinski",
        "Christopher Wewer",
        "Bernt Schiele",
        "Jan Eric Lenssen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:46:54+00:00",
          "link": "https://arxiv.org/abs/2507.10768v1",
          "size": "3357kb",
          "version": "v1"
        }
      ],
      "title": "Spatial Reasoners for Continuous Variables in Any Domain",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10768",
        "HTML": "https://arxiv.org/html/2507.10768v1",
        "PDF": "https://arxiv.org/pdf/2507.10768"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a framework for spatial reasoning with generative models, unrelated to LLM training data processing or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10833",
      "abstract": "We present a family of algorithms to solve random planted instances of any $k$-ary Boolean constraint satisfaction problem (CSP). A randomly planted instance of a Boolean CSP is generated by (1) choosing an arbitrary planted assignment $x^*$, and then (2) sampling constraints from a particular \"planting distribution\" designed so that $x^*$ will satisfy every constraint. Given an $n$ variable instance of a $k$-ary Boolean CSP with $m$ constraints, our algorithm runs in time $n^{O(\\ell)}$ for a choice of a parameter $\\ell$, and succeeds in outputting a satisfying assignment if $m \\geq O(n) \\cdot (n/\\ell)^{\\frac{k}{2} - 1} \\log n$. This generalizes the $\\mathrm{poly}(n)$-time algorithm of [FPV15], the case of $\\ell = O(1)$, to larger runtimes, and matches the constraint number vs.\\ runtime trade-off established for refuting random CSPs by [RRS17].\n  Our algorithm is conceptually different from the recent algorithm of [GHKM23], which gave a $\\mathrm{poly}(n)$-time algorithm to solve semirandom CSPs with $m \\geq \\tilde{O}(n^{\\frac{k}{2}})$ constraints by exploiting conditions that allow a basic SDP to recover the planted assignment $x^*$ exactly. Instead, we forego certificates of uniqueness and recover $x^*$ in two steps: we first use a degree-$O(\\ell)$ Sum-of-Squares SDP to find some $\\hat{x}$ that is $o(1)$-close to $x^*$, and then we use a second rounding procedure to recover $x^*$ from $\\hat{x}$.",
      "authors": [
        "Arpon Basu",
        "Jun-Ting Hsieh",
        "Andrew D. Lin",
        "Peter Manohar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T22:04:14+00:00",
          "link": "https://arxiv.org/abs/2507.10833v1",
          "size": "74kb",
          "version": "v1"
        }
      ],
      "title": "Solving Random Planted CSPs below the $n^{k/2}$ Threshold",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10833",
        "HTML": "https://arxiv.org/html/2507.10833v1",
        "PDF": "https://arxiv.org/pdf/2507.10833"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents algorithms for solving CSP problems, which do not involve LLM training data processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10849",
      "abstract": "Gain Cell memory (GCRAM) offers higher density and lower power than SRAM, making it a promising candidate for on-chip memory in domain-specific accelerators. To support workloads with varying traffic and lifetime metrics, GCRAM also offers high bandwidth, ultra low leakage power and a wide range of retention times, which can be adjusted through transistor design (like threshold voltage and channel material) and on-the-fly by changing the operating voltage. However, designing and optimizing GCRAM sub-systems can be time-consuming. In this paper, we present OpenGCRAM, an open-source GCRAM compiler capable of generating GCRAM bank circuit designs and DRC- and LVS-clean layouts for commercially available foundry CMOS, while also providing area, delay, and power simulations based on user-specified configurations (e.g., word size and number of words). OpenGCRAM enables fast, accurate, customizable, and optimized GCRAM block generation, reduces design time, ensure process compliance, and delivers performance-tailored memory blocks that meet diverse application requirements.",
      "authors": [
        "Xinxin Wang",
        "Lixian Yan",
        "Shuhan Liu",
        "Luke Upton",
        "Zhuoqi Cai",
        "Yiming Tan",
        "Shengman Li",
        "Koustav Jana",
        "Peijing Li",
        "Jesse Cirimelli-Low",
        "Thierry Tambe",
        "Matthew Guthaus and H.-S. Philip Wong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T22:43:50+00:00",
          "link": "https://arxiv.org/abs/2507.10849v1",
          "size": "14724kb",
          "version": "v1"
        }
      ],
      "title": "OpenGCRAM: An Open-Source Gain Cell Compiler Enabling Design-Space Exploration for AI Workloads",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10849",
        "HTML": "https://arxiv.org/html/2507.10849v1",
        "PDF": "https://arxiv.org/pdf/2507.10849"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a compiler for Gain Cell memory design, which is unrelated to LLM training data processing, focusing instead on hardware design tools."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11000",
      "abstract": "We aim to solve the problem of temporal-constraint learning from demonstrations to reproduce demonstration-like logic-constrained behaviors. Learning logic constraints is challenging due to the combinatorially large space of possible specifications and the ill-posed nature of non-Markovian constraints. To figure it out, we introduce a novel temporal-constraint learning method, which we call inverse logic-constraint learning (ILCL). Our method frames ICL as a two-player zero-sum game between 1) a genetic algorithm-based temporal-logic mining (GA-TL-Mining) and 2) logic-constrained reinforcement learning (Logic-CRL). GA-TL-Mining efficiently constructs syntax trees for parameterized truncated linear temporal logic (TLTL) without predefined templates. Subsequently, Logic-CRL finds a policy that maximizes task rewards under the constructed TLTL constraints via a novel constraint redistribution scheme. Our evaluations show ILCL outperforms state-of-the-art baselines in learning and transferring TL constraints on four temporally constrained tasks. We also demonstrate successful transfer to real-world peg-in-shallow-hole tasks.",
      "authors": [
        "Minwoo Cho",
        "Jaehwi Jang and Daehyung Park"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T05:35:06+00:00",
          "link": "https://arxiv.org/abs/2507.11000v1",
          "size": "5680kb",
          "version": "v1"
        }
      ],
      "title": "ILCL: Inverse Logic-Constraint Learning from Temporally Constrained Demonstrations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11000",
        "HTML": "https://arxiv.org/html/2507.11000v1",
        "PDF": "https://arxiv.org/pdf/2507.11000"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a method for learning temporal constraints using demonstrations, focusing on logic-constraint learning and reinforcement learning rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.03777",
      "abstract": "This paper discusses lowest-order nonstandard finite element methods for space discretization and explicit and implicit schemes for time discretization of the biharmonic wave equation with clamped boundary conditions. A modified Ritz projection operator defined on $H^2_0(\\Omega)$ ensures error estimates under appropriate regularity assumptions on the solution. Stability results and error estimates of optimal order are established in suitable norms for the semidiscrete and explicit/implicit fully-discrete versions of the proposed schemes. Finally, we report on numerical experiments using explicit and implicit schemes for time discretization and Morley, discontinuous Galerkin, and {C$^0$ interior} penalty schemes for space discretization, that validate the theoretical error estimates.",
      "authors": [
        "Neela Nataraj",
        "Ricardo Ruiz-Baier",
        "and Aamir Yousuf"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-04T09:36:22+00:00",
          "link": "https://arxiv.org/abs/2407.03777v1",
          "size": "1266kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T08:38:22+00:00",
          "link": "https://arxiv.org/abs/2407.03777v2",
          "size": "487kb",
          "version": "v2"
        }
      ],
      "title": "Semi and fully-discrete analysis of lowest-order nonstandard finite element methods for the biharmonic wave problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.03777",
        "HTML": "https://arxiv.org/html/2407.03777v2",
        "PDF": "https://arxiv.org/pdf/2407.03777"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on finite element methods for the biharmonic wave problem, which does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.18658",
      "abstract": "AI programming tools enable powerful code generation, and recent prototypes attempt to reduce user effort with proactive AI agents, but their impact on programming workflows remains unexplored. We introduce and evaluate Codellaborator, a design probe LLM agent that initiates programming assistance based on editor activities and task context. We explored three interface variants to assess trade-offs between increasingly salient AI support: prompt-only, proactive agent, and proactive agent with presence and context (Codellaborator). In a within-subject study (N=18), we find that proactive agents increase efficiency compared to prompt-only paradigm, but also incur workflow disruptions. However, presence indicators and interaction context support alleviated disruptions and improved users' awareness of AI processes. We underscore trade-offs of Codellaborator on user control, ownership, and code understanding, emphasizing the need to adapt proactivity to programming processes. Our research contributes to the design exploration and evaluation of proactive AI systems, presenting design implications on AI-integrated programming workflow.",
      "authors": [
        "Kevin Pu",
        "Daniel Lazaro",
        "Ian Arawjo",
        "Haijun Xia",
        "Ziang Xiao",
        "Tovi Grossman",
        "Yan Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-25T21:37:25+00:00",
          "link": "https://arxiv.org/abs/2502.18658v1",
          "size": "1504kb",
          "version": "v1"
        },
        {
          "date": "2025-03-04T15:26:19+00:00",
          "link": "https://arxiv.org/abs/2502.18658v2",
          "size": "1504kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T14:53:12+00:00",
          "link": "https://arxiv.org/abs/2502.18658v3",
          "size": "1037kb",
          "version": "v3"
        }
      ],
      "title": "Assistance or Disruption? Exploring and Evaluating the Design and Trade-offs of Proactive AI Programming Support",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.18658",
        "HTML": "https://arxiv.org/html/2502.18658v3",
        "PDF": "https://arxiv.org/pdf/2502.18658"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on the design and evaluation of AI programming tools and their impact on programming workflows, without discussing LLM training data processing."
      },
      "tasks": [
        "Code Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10730",
      "abstract": "This paper presents a novel key-based access control technique for secure outsourcing key-value stores where values correspond to documents that are indexed and accessed using keys. The proposed approach adopts Shamir's secret-sharing that offers unconditional or information-theoretic security. It supports keyword-based document retrieval while preventing leakage of the data, access rights of users, or the size (\\textit{i}.\\textit{e}., volume of the output that satisfies a query). The proposed approach allows servers to detect (and abort) malicious clients from gaining unauthorized access to data, and prevents malicious servers from altering data undetected while ensuring efficient access -- it takes 231.5ms over 5,000 keywords across 500,000 files.",
      "authors": [
        "Yin Li",
        "Sharad Mehrota",
        "Shantanu Sharma",
        "Komal Kumari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Databases (cs.DB)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Data Structures and Algorithms (cs.DS)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:51:20+00:00",
          "link": "https://arxiv.org/abs/2507.10730v1",
          "size": "763kb",
          "version": "v1"
        }
      ],
      "title": "Access Control for Information-Theoretically Secure Key-Document Stores",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10730",
        "HTML": "https://arxiv.org/html/2507.10730v1",
        "PDF": "https://arxiv.org/pdf/2507.10730"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes a secure access control method for key-document stores using Shamir's secret-sharing. It does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10883",
      "abstract": "Traditional layered graph depictions such as flow charts are in wide use. Yet as graphs grow more complex, these depictions can become difficult to understand. Quilts are matrix-based depictions for layered graphs designed to address this problem. In this research, we first improve Quilts by developing three design alternatives, and then compare the best of these alternatives to better-known node-link and matrix depictions. A primary weakness in Quilts is their depiction of skip links, links that do not simply connect to a succeeding layer. Therefore in our first study, we compare Quilts using color-only, text-only, and mixed (color and text) skip link depictions, finding that path finding with the color-only depiction is significantly slower and less accurate, and that in certain cases, the mixed depiction offers an advantage over the text-only depiction. In our second study, we compare Quilts using the mixed depiction to node-link diagrams and centered matrices. Overall results show that users can find paths through graphs significantly faster with Quilts (46.6 secs) than with node-link (58.3 secs) or matrix (71.2 secs) diagrams. This speed advantage is still greater in large graphs (e.g. in 200 node graphs, 55.4 secs vs. 71.1 secs for node-link and 84.2 secs for matrix depictions).",
      "authors": [
        "Juhee Bae and Benjamin Watson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T00:55:24+00:00",
          "link": "https://arxiv.org/abs/2507.10883v1",
          "size": "10306kb",
          "version": "v1"
        }
      ],
      "title": "Developing and evaluating quilts for the depiction of large layered graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10883",
        "PDF": "https://arxiv.org/pdf/2507.10883"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the depiction of layered graphs and does not address the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11299",
      "abstract": "Text-based telemedicine has become increasingly common, yet the quality of medical advice in doctor-patient interactions is often judged more on how advice is communicated rather than its clinical accuracy. To address this, we introduce Dr.Copilot , a multi-agent large language model (LLM) system that supports Romanian-speaking doctors by evaluating and enhancing the presentation quality of their written responses. Rather than assessing medical correctness, Dr.Copilot provides feedback along 17 interpretable axes. The system comprises of three LLM agents with prompts automatically optimized via DSPy. Designed with low-resource Romanian data and deployed using open-weight models, it delivers real-time specific feedback to doctors within a telemedicine platform. Empirical evaluations and live deployment with 41 doctors show measurable improvements in user reviews and response quality, marking one of the first real-world deployments of LLMs in Romanian medical settings.",
      "authors": [
        "Andrei Niculae",
        "Adrian Cosma",
        "Cosmin Dumitrache",
        "Emilian R\\v{a}doi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:26:49+00:00",
          "link": "https://arxiv.org/abs/2507.11299v1",
          "size": "4454kb",
          "version": "v1"
        }
      ],
      "title": "Dr.Copilot: A Multi-Agent Prompt Optimized Assistant for Improving Patient-Doctor Communication in Romanian",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11299",
        "HTML": "https://arxiv.org/html/2507.11299v1",
        "PDF": "https://arxiv.org/pdf/2507.11299"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily focuses on improving the quality of communication in telemedicine using a multi-agent system. It does not make a technical contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.09980",
      "abstract": "We study the wake-up problem in distributed networks, where an adversary awakens a subset of nodes at arbitrary times, and the goal is to wake up all other nodes as quickly as possible by sending only few messages. We prove the following lower bounds:\n  * We first consider the setting where each node receives advice from an oracle who can observe the entire network, but does not know which nodes are awake initially. More specifically, we consider the $KT_0$ $LOCAL$ model with advice. We prove that any randomized algorithm must send $\\Omega( \\frac{n^{2}}{2^{\\beta}\\log n} )$ messages if nodes receive only $O(\\beta)$ bits of advice on average.\n  * For the $KT_1$ assumption, we show that any $(k+1)$-time algorithm requires $\\Omega( n^{1+1/k} )$ messages. Our result is the first super-linear (in $n$) lower bound, for a problem that does not require individual nodes to learn a large amount of information about the network topology.\n  To complement our lower bound results, we present several new algorithms:\n  * We give an asynchronous $KT_1$ $LOCAL$ algorithm that solves the wake-up problem with a time and message complexity of $O( n\\log n )$ with high probability.\n  * We introduce the notion of \\emph{awake distance} $\\rho_{\\text{awk}}$, which is upper-bounded by the network diameter, and present a synchronous $KT_1$ $LOCAL$ algorithm that takes $O( \\rho_{\\text{awk}} )$ rounds and sends $O( n^{3/2}\\sqrt{\\log n} )$ messages with high probability. We also extend these ideas to obtain a near-optimal time- and message complexity of $O\\( \\rho_{awk} \\log^3n )$ rounds $O( n \\log^3n )$ messages.\n  * We give deterministic advising schemes in the asynchronous $KT_0$ $CONGEST$ model (with advice). In particular, we obtain an $O( \\rho_{\\text{awk}}\\log^2n )$-time advising scheme that sends $O( n\\log^2n )$ messages, while requiring $O( \\log^2n )$ bits of advice per node.",
      "authors": [
        "Peter Robinson and Ming Ming Tan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-13T19:49:03+00:00",
          "link": "https://arxiv.org/abs/2410.09980v1",
          "size": "141kb",
          "version": "v1"
        },
        {
          "date": "2024-11-04T23:47:52+00:00",
          "link": "https://arxiv.org/abs/2410.09980v2",
          "size": "205kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T13:48:10+00:00",
          "link": "https://arxiv.org/abs/2410.09980v3",
          "size": "200kb",
          "version": "v3"
        }
      ],
      "title": "Rise and Shine Efficiently! Tight Bounds for Adversarial Wake-up",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.09980",
        "HTML": "https://arxiv.org/html/2410.09980v3",
        "PDF": "https://arxiv.org/pdf/2410.09980"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with the wake-up problem in distributed networks, focusing on message complexity and algorithmic solutions, not on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19502",
      "abstract": "Accessibility remains a critical concern in today's society, as many technologies are not developed to support the full range of user needs. Existing multi-agent systems (MAS) often cannot provide comprehensive assistance for users in need due to the lack of customization stemming from closed-source designs. Consequently, individuals with disabilities frequently encounter significant barriers when attempting to interact with digital environments. We introduce MATE, a multimodal accessibility MAS, which performs the modality conversions based on the user's needs. The system is useful for assisting people with disabilities by ensuring that data will be converted to an understandable format. For instance, if the user cannot see well and receives an image, the system converts this image to its audio description. MATE can be applied to a wide range of domains, industries, and areas, such as healthcare, and can become a useful assistant for various groups of users. The system supports multiple types of models, ranging from LLM API calling to using custom machine learning (ML) classifiers. This flexibility ensures that the system can be adapted to various needs and is compatible with a wide variety of hardware. Since the system is expected to run locally, it ensures the privacy and security of sensitive information. In addition, the framework can be effectively integrated with institutional technologies (e.g., digital healthcare service) for real-time user assistance. Furthermore, we introduce ModCon-Task-Identifier, a model that is capable of extracting the precise modality conversion task from the user input. Numerous experiments show that ModCon-Task-Identifier consistently outperforms other LLMs and statistical models on our custom data. Our code and data are publicly available at https://github.com/AlgazinovAleksandr/Multi-Agent-MATE.",
      "authors": [
        "Aleksandr Algazinov",
        "Matt Laing",
        "and Paul Laban"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T10:40:23+00:00",
          "link": "https://arxiv.org/abs/2506.19502v1",
          "size": "1313kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T06:04:25+00:00",
          "link": "https://arxiv.org/abs/2506.19502v2",
          "size": "1478kb",
          "version": "v2"
        }
      ],
      "title": "MATE: LLM-Powered Multi-Agent Translation Environment for Accessibility Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19502",
        "HTML": "https://arxiv.org/html/2506.19502v2",
        "PDF": "https://arxiv.org/pdf/2506.19502"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a multi-agent translation environment for accessibility, which involves modality conversion based on user needs but does not focus on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10560",
      "abstract": "Activation functions are key to effective backpropagation and expressiveness in deep neural networks. This work introduces Tangma, a new activation function that combines the smooth shape of the hyperbolic tangent with two learnable parameters: $\\alpha$, which shifts the curve's inflection point to adjust neuron activation, and $\\gamma$, which adds linearity to preserve weak gradients and improve training stability. Tangma was evaluated on MNIST and CIFAR-10 using custom networks composed of convolutional and linear layers, and compared against ReLU, Swish, and GELU. On MNIST, Tangma achieved the highest validation accuracy of 99.09% and the lowest validation loss, demonstrating faster and more stable convergence than the baselines. On CIFAR-10, Tangma reached a top validation accuracy of 78.15%, outperforming all other activation functions while maintaining a competitive training loss. Tangma also showed improved training efficiency, with lower average epoch runtimes compared to Swish and GELU. These results suggest that Tangma performs well on standard vision tasks and enables reliable, efficient training. Its learnable design gives more control over activation behavior, which may benefit larger models in tasks such as image recognition or language modeling.",
      "authors": [
        "Shreel Golwala"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T21:01:27+00:00",
          "link": "https://arxiv.org/abs/2507.10560v1",
          "size": "692kb",
          "version": "v1"
        }
      ],
      "title": "Tangma: A Tanh-Guided Activation Function with Learnable Parameters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10560",
        "HTML": "https://arxiv.org/html/2507.10560v1",
        "PDF": "https://arxiv.org/pdf/2507.10560"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces a new activation function, not relating to the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.04366",
      "abstract": "The transition to 100% renewable energy requires new techniques for managing energy networks, such as dividing them into sensible subsets of prosumers called micro-grids. Doing so in an optimal manner is a difficult optimization problem, as it can be abstracted to the Coalition Structure Generation problem in Induced Subgraph Games, a NP-complete problem which requires dividing an undirected, complete, weighted graph into subgraphs in a way that maximizes the sum of their internal weights. Recently, Venkatesh et al. (arXiv:2212.11372) published a Quantum Annealing (QA)-based iterative algorithm called GCS-Q, which they claim to be the best currently existing solver for the problem in terms of runtime complexity. As this algorithm makes the application of QA to the problem seem promising, but is a greedy one, this work proposes several less greedy QA-based approaches and investigates whether any of them can outperform GCS-Q in terms of solution quality. While we find that this is not the case yet on D-Wave hardware, most of them do when using the classical QBSolv software as a solver. Especially an algorithm we call 4-split iterative R-QUBO shows potential here, finding all optima in our dataset while scaling favorably with the problem size in terms of runtime. Thus, it appears to be interesting for future research on quantum approaches to the problem, assuming QA hardware will become more noise-resilient over time.",
      "authors": [
        "Jonas N\\\"u{\\ss}lein",
        "Dani\\\"elle Schuman",
        "David Bucher",
        "Naeimeh Mohseni",
        "Kumar Ghosh",
        "Corey O'Meara",
        "Giorgio Cortiana and Claudia Linnhoff-Popien"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-08T10:54:56+00:00",
          "link": "https://arxiv.org/abs/2408.04366v1",
          "size": "226kb",
          "version": "v1"
        },
        {
          "date": "2024-09-01T17:06:55+00:00",
          "link": "https://arxiv.org/abs/2408.04366v2",
          "size": "127kb",
          "version": "v2"
        }
      ],
      "title": "Towards Less Greedy Quantum Coalition Structure Generation in Induced Subgraph Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.04366",
        "HTML": "https://arxiv.org/html/2408.04366",
        "PDF": "https://arxiv.org/pdf/2408.04366"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study is about optimizing energy networks using quantum coalition structure generation and does not mention or involve any LLM training data processing or data-related operations relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.15175",
      "abstract": "We treat three cubic recurrences, two of which generalize the famous iterated map $x \\mapsto x (1-x)$ from discrete chaos theory. A feature of each asymptotic series developed here is a constant, dependent on the initial condition but otherwise intrinsic to the function at hand.",
      "authors": [
        "Steven Finch"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Dynamical Systems (math.DS)",
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-23T16:28:19+00:00",
          "link": "https://arxiv.org/abs/2409.15175v1",
          "size": "18kb",
          "version": "v1"
        },
        {
          "date": "2024-10-07T00:57:44+00:00",
          "link": "https://arxiv.org/abs/2409.15175v2",
          "size": "20kb",
          "version": "v2"
        },
        {
          "date": "2024-11-06T03:26:44+00:00",
          "link": "https://arxiv.org/abs/2409.15175v3",
          "size": "20kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T10:29:24+00:00",
          "link": "https://arxiv.org/abs/2409.15175v4",
          "size": "11kb",
          "version": "v4"
        }
      ],
      "title": "Generalized Logistic Maps and Convergence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.15175",
        "HTML": "https://arxiv.org/html/2409.15175v4",
        "PDF": "https://arxiv.org/pdf/2409.15175"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with mathematical recurrences and convergence, with no connection to LLM training data or processing activities."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10983",
      "abstract": "Semiconductor manufacturing relies heavily on film deposition processes, such as Chemical Vapor Deposition and Physical Vapor Deposition. These complex processes require precise control to achieve film uniformity, proper adhesion, and desired functionality. Recent advancements in Physics-Informed Neural Networks (PINNs), an innovative machine learning (ML) approach, have shown significant promise in addressing challenges related to process control, quality assurance, and predictive modeling within semiconductor film deposition and other manufacturing domains. This paper provides a comprehensive review of ML applications targeted at semiconductor film deposition processes. Through a thematic analysis, we identify key trends, existing limitations, and research gaps, offering insights into both the advantages and constraints of current methodologies. Our structured analysis aims to highlight the potential integration of these ML techniques to enhance interpretability, accuracy, and robustness in film deposition processes. Additionally, we examine state-of-the-art PINN methods, discussing strategies for embedding physical knowledge, governing laws, and partial differential equations into advanced neural network architectures tailored for semiconductor manufacturing. Based on this detailed review, we propose novel research directions that integrate the strengths of PINNs to significantly advance film deposition processes. The contributions of this study include establishing a clear pathway for future research in integrating physics-informed ML frameworks, addressing existing methodological gaps, and ultimately improving precision, scalability, and operational efficiency within semiconductor manufacturing.",
      "authors": [
        "Tao Han",
        "Zahra Taheri",
        "Hyunwoong Ko"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T04:56:26+00:00",
          "link": "https://arxiv.org/abs/2507.10983v1",
          "size": "106kb",
          "version": "v1"
        }
      ],
      "title": "Physics-Informed Neural Networks For Semiconductor Film Deposition: A Review",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10983",
        "HTML": "https://arxiv.org/html/2507.10983v1",
        "PDF": "https://arxiv.org/pdf/2507.10983"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on physics-informed neural networks for semiconductor film deposition, not on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.00580",
      "abstract": "Foundation models have achieved tremendous success in different domains. However, their huge computation and storage complexity make these models difficult to fine-tune and also less applicable in practice. Recent study shows training in Fourier domain can be an effective fine-tuning method in terms of both model performance and number of training parameters. In this work, we propose to further reduce the complexity by the factorization through the product of interleaved circulant and diagonal matrices. In addition, we address the case of non-square fine-tuning weights by partitioning the circulant matrix into blocks. Our method avoids the construction of weight change matrix and utilizes 1D fast Fourier transform (FFT) instead of 2D FFT. Experimental results show that our method achieves similar or better performance across various tasks with much less floating-point operations (FLOPs) and the number of trainable parameters.",
      "authors": [
        "Xinyu Ding",
        "Lexuan Chen",
        "Siyu Liao",
        "Zhongfeng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-01T15:11:46+00:00",
          "link": "https://arxiv.org/abs/2505.00580v1",
          "size": "142kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T12:51:28+00:00",
          "link": "https://arxiv.org/abs/2505.00580v2",
          "size": "134kb",
          "version": "v2"
        }
      ],
      "title": "Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00580",
        "HTML": "https://arxiv.org/html/2505.00580v2",
        "PDF": "https://arxiv.org/pdf/2505.00580"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The abstract briefly discusses fine-tuning methods for LLMs, focusing on parameter efficiency in the Fourier domain. The focus is primarily on model architecture and computational efficiency rather than data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.00972",
      "abstract": "Simulation-based testing is crucial for validating autonomous vehicles (AVs), yet existing scenario generation methods either overfit to common driving patterns or operate in an offline, non-interactive manner that fails to expose rare, safety-critical corner cases. In this paper, we introduce an online, retrieval-augmented large language model (LLM) framework for generating safety-critical driving scenarios. Our method first employs an LLM-based behavior analyzer to infer the most dangerous intent of the background vehicle from the observed state, then queries additional LLM agents to synthesize feasible adversarial trajectories. To mitigate catastrophic forgetting and accelerate adaptation, we augment the framework with a dynamic memorization and retrieval bank of intent-planner pairs, automatically expanding its behavioral library when novel intents arise. Evaluations using the Waymo Open Motion Dataset demonstrate that our model reduces the mean minimum time-to-collision from 1.62 to 1.08 s and incurs a 75% collision rate, substantially outperforming baselines.",
      "authors": [
        "Yuewen Mei",
        "Tong Nie",
        "Jian Sun",
        "Ye Tian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-02T03:22:00+00:00",
          "link": "https://arxiv.org/abs/2505.00972v1",
          "size": "2784kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T07:52:46+00:00",
          "link": "https://arxiv.org/abs/2505.00972v2",
          "size": "2305kb",
          "version": "v2"
        }
      ],
      "title": "Seeking to Collide: Online Safety-Critical Scenario Generation for Autonomous Driving with Retrieval Augmented Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00972",
        "HTML": "https://arxiv.org/html/2505.00972v2",
        "PDF": "https://arxiv.org/pdf/2505.00972"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about generating safety-critical driving scenarios using an LLM-based framework, not about processing or creating LLM training data."
      },
      "tasks": [
        "Autonomous Driving",
        "Autonomous Vehicles",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Memorization",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10960",
      "abstract": "Prior human-robot interaction (HRI) research has primarily focused on single-user interactions, where robots do not need to consider the timing or recipient of their responses. However, in multi-party interactions, such as at malls and hospitals, social robots must understand the context and decide both when and to whom they should respond. In this paper, we propose a Transformer-based multi-task learning framework to improve the decision-making process of social robots, particularly in multi-user environments. Considering the characteristics of HRI, we propose two novel loss functions: one that enforces constraints on active speakers to improve scene modeling, and another that guides response selection towards utterances specifically directed at the robot. Additionally, we construct a novel multi-party HRI dataset that captures real-world complexities, such as gaze misalignment. Experimental results demonstrate that our model achieves state-of-the-art performance in respond decisions, outperforming existing heuristic-based and single-task approaches. Our findings contribute to the development of socially intelligent social robots capable of engaging in natural and context-aware multi-party interactions.",
      "authors": [
        "He Zhu",
        "Ryo Miyoshi and Yuki Okafuji"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T03:42:14+00:00",
          "link": "https://arxiv.org/abs/2507.10960v1",
          "size": "2551kb",
          "version": "v1"
        }
      ],
      "title": "Whom to Respond To? A Transformer-Based Model for Multi-Party Social Robot Interaction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10960",
        "HTML": "https://arxiv.org/html/2507.10960v1",
        "PDF": "https://arxiv.org/pdf/2507.10960"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a novel multi-party HRI dataset but focuses on model architecture and response decision frameworks rather than detailed data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18046",
      "abstract": "Time series anomaly detection (TSAD) plays an important role in many domains such as finance, transportation, and healthcare. With the ongoing instrumentation of reality, more time series data will be available, leading also to growing demands for TSAD. While many TSAD methods already exist, new and better methods are still desirable. However, effective progress hinges on the availability of reliable means of evaluating new methods and comparing them with existing methods. We address deficiencies in current evaluation procedures related to datasets and experimental settings and protocols. Specifically, we propose a new time series anomaly detection benchmark, called TAB. First, TAB encompasses 29 public multivariate datasets and 1,635 univariate time series from different domains to facilitate more comprehensive evaluations on diverse datasets. Second, TAB covers a variety of TSAD methods, including Non-learning, Machine learning, Deep learning, LLM-based, and Time-series pre-trained methods. Third, TAB features a unified and automated evaluation pipeline that enables fair and easy evaluation of TSAD methods. Finally, we employ TAB to evaluate existing TSAD methods and report on the outcomes, thereby offering a deeper insight into the performance of these methods. Besides, all datasets and code are available at https://github.com/decisionintelligence/TAB.",
      "authors": [
        "Xiangfei Qiu",
        "Zhe Li",
        "Wanghui Qiu",
        "Shiyan Hu",
        "Lekui Zhou",
        "Xingjian Wu",
        "Zhengyu Li",
        "Chenjuan Guo",
        "Aoying Zhou",
        "Zhenli Sheng",
        "Jilin Hu",
        "Christian S. Jensen",
        "Bin Yang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-22T14:19:36+00:00",
          "link": "https://arxiv.org/abs/2506.18046v1",
          "size": "3332kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T09:18:30+00:00",
          "link": "https://arxiv.org/abs/2506.18046v2",
          "size": "3302kb",
          "version": "v2"
        }
      ],
      "title": "TAB: Unified Benchmarking of Time Series Anomaly Detection Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18046",
        "HTML": "https://arxiv.org/html/2506.18046v2",
        "PDF": "https://arxiv.org/pdf/2506.18046"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on creating a benchmark for time series anomaly detection methods and evaluating them on existing datasets, without any substantive contribution to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11366",
      "abstract": "We study online optimization methods for zero-sum games, a fundamental problem in adversarial learning in machine learning, economics, and many other domains. Traditional methods approximate Nash equilibria (NE) using either regret-based methods (time-average convergence) or contraction-map-based methods (last-iterate convergence). We propose a new method based on Hamiltonian dynamics in physics and prove that it can characterize the set of NE in a finite (linear) number of iterations of alternating gradient descent in the unbounded setting, modulo degeneracy, a first in online optimization. Unlike standard methods for computing NE, our proposed approach can be parallelized and works with arbitrary learning rates, both firsts in algorithmic game theory. Experimentally, we support our results by showing our approach drastically outperforms standard methods.",
      "authors": [
        "Taemin Kim",
        "James P. Bailey"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:39:40+00:00",
          "link": "https://arxiv.org/abs/2507.11366v1",
          "size": "1061kb",
          "version": "v1"
        }
      ],
      "title": "A Parallelizable Approach for Characterizing NE in Zero-Sum Games After a Linear Number of Iterations of Gradient Descent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11366",
        "PDF": "https://arxiv.org/pdf/2507.11366"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses online optimization methods for characterizing NE in zero-sum games and does not involve any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.13691",
      "abstract": "In recent years, the elliptic curve Qu-Vanstone (ECQV) implicit certificate scheme has found application in security credential management systems (SCMS) and secure vehicle-to-everything (V2X) communication to issue pseudonymous certificates. However, the vulnerability of elliptic-curve cryptography (ECC) to polynomial-time attacks posed by quantum computing raises concerns. In order to enhance resistance against quantum computing threats, various post-quantum cryptography methods have been adopted as standard (e.g. Dilithium) or candidate standard methods (e.g. McEliece cryptography), but state of the art has proven to be challenging to implement implicit certificates using lattice-based cryptography methods. Therefore, this study proposes a post-quantum cryptography McEliece-Chen (PQCMC) based on an efficient random invertible matrix generation method to issue pseudonymous certificates with less computation time. The study provides mathematical models to validate the key expansion process for implicit certificates. Furthermore, comprehensive security evaluations and discussions are conducted to demonstrate that distinct implicit certificates can be linked to the same end entity. In experiments, a comparison is conducted between the certificate length and computation time to evaluate the performance of the proposed PQCMC. This study demonstrates the viability of the implicit certificate scheme based on PQC as a means of countering quantum computing threats.",
      "authors": [
        "Abel C. H. Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-03T13:34:20+00:00",
          "link": "https://arxiv.org/abs/2401.13691v1",
          "size": "444kb",
          "version": "v1"
        }
      ],
      "title": "PQCMC: Post-Quantum Cryptography McEliece-Chen Implicit Certificate Scheme",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.13691",
        "PDF": "https://arxiv.org/pdf/2401.13691"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about post-quantum cryptography for security credential management and does not relate to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.16921",
      "abstract": "Motion correction (MoCo) in radial MRI is a particularly challenging problem due to the unpredictability of subject movement. Current state-of-the-art (SOTA) MoCo algorithms often rely on extensive high-quality MR images to pre-train neural networks, which constrains the solution space and leads to outstanding image reconstruction results. However, the need for large-scale datasets significantly increases costs and limits model generalization. In this work, we propose Moner, an unsupervised MoCo method that jointly reconstructs artifact-free MR images and estimates accurate motion from undersampled, rigid motion-corrupted k-space data, without requiring any training data. Our core idea is to leverage the continuous prior of implicit neural representation (INR) to constrain this ill-posed inverse problem, facilitating optimal solutions. Specifically, we integrate a quasi-static motion model into the INR, granting its ability to correct subject's motion. To stabilize model optimization, we reformulate radial MRI reconstruction as a back-projection problem using the Fourier-slice theorem. Additionally, we propose a novel coarse-to-fine hash encoding strategy, significantly enhancing MoCo accuracy. Experiments on multiple MRI datasets show our Moner achieves performance comparable to SOTA MoCo techniques on in-domain data, while demonstrating significant improvements on out-of-domain data. The code is available at: https://github.com/iwuqing/Moner",
      "authors": [
        "Qing Wu",
        "Chenhe Du",
        "Xuanyu Tian",
        "Jingyi Yu",
        "Yuyao Zhang",
        "Hongjiang Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-25T13:27:29+00:00",
          "link": "https://arxiv.org/abs/2409.16921v1",
          "size": "7035kb",
          "version": "v1"
        },
        {
          "date": "2024-12-02T18:01:53+00:00",
          "link": "https://arxiv.org/abs/2409.16921v2",
          "size": "14979kb",
          "version": "v2"
        },
        {
          "date": "2025-02-06T05:19:51+00:00",
          "link": "https://arxiv.org/abs/2409.16921v3",
          "size": "14971kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T14:46:29+00:00",
          "link": "https://arxiv.org/abs/2409.16921v4",
          "size": "13687kb",
          "version": "v4"
        }
      ],
      "title": "Moner: Motion Correction in Undersampled Radial MRI with Unsupervised Neural Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.16921",
        "HTML": "https://arxiv.org/html/2409.16921v4",
        "PDF": "https://arxiv.org/pdf/2409.16921"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on motion correction in radial MRI using an unsupervised method without requiring training data, rather than improving or processing LLM training data."
      },
      "tasks": [
        "Model Optimization"
      ],
      "repo_urls": [
        "https://github.com/iwuqing/moner"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.14565",
      "abstract": "Self-awareness, i.e., the ability to assess and correct one's own generation, is a fundamental aspect of human intelligence, making its replication in large language models (LLMs) an important yet challenging task. Previous works tackle this by employing extensive reinforcement learning or rather relying on large external verifiers. In this work, we propose Refine via Intrinsic Self-Verification (ReVISE), an efficient and effective framework that enables LLMs to self-correct their outputs through self-verification. The core idea of ReVISE is to enable LLMs to verify their reasoning processes and continually rethink reasoning trajectories based on its verification. We introduce a structured curriculum based upon online preference learning to implement this efficiently. Specifically, as ReVISE involves two challenging tasks (i.e., self-verification and reasoning correction), we tackle each task sequentially using curriculum learning, collecting both failed and successful reasoning paths to construct preference pairs for efficient training. During inference, our approach enjoys natural test-time scaling by integrating self-verification and correction capabilities, further enhanced by our proposed confidence-aware decoding mechanism. Our experiments on various reasoning tasks demonstrate that ReVISE achieves efficient self-correction and significantly improves reasoning performance.",
      "authors": [
        "Hyunseok Lee",
        "Seunghyuk Oh",
        "Jaehyung Kim",
        "Jinwoo Shin",
        "Jihoon Tack"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-20T13:50:02+00:00",
          "link": "https://arxiv.org/abs/2502.14565v1",
          "size": "3143kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T06:30:11+00:00",
          "link": "https://arxiv.org/abs/2502.14565v2",
          "size": "3183kb",
          "version": "v2"
        }
      ],
      "title": "ReVISE: Learning to Refine at Test-Time via Intrinsic Self-Verification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.14565",
        "HTML": "https://arxiv.org/html/2502.14565v2",
        "PDF": "https://arxiv.org/pdf/2502.14565"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study proposes a framework for self-correction in LLMs but does not address or contribute to data engineering or processing for LLM training data."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.18398",
      "abstract": "Among the new techniques of Versatile Video Coding (VVC), the quadtree with nested multi-type tree (QT+MTT) block structure yields significant coding gains by providing more flexible block partitioning patterns. However, the recursive partition search in the VVC encoder increases the encoder complexity substantially. To address this issue, we propose a partition map-based algorithm to pursue fast block partitioning in inter coding. Based on our previous work on partition map-based methods for intra coding, we analyze the characteristics of VVC inter coding, and thus improve the partition map by incorporating an MTT mask for early termination. Next, we develop a neural network that uses both spatial and temporal features to predict the partition map. It consists of several special designs including stacked top-down and bottom-up processing, quantization parameter modulation layers, and partitioning-adaptive warping. Furthermore, we present a dual-threshold decision scheme to achieve a fine-grained trade-off between complexity reduction and rate-distortion (RD) performance loss. The experimental results demonstrate that the proposed method achieves an average 51.30% encoding time saving with a 2.12% Bjontegaard Delta Bit Rate (BDBR) under the random access configuration.",
      "authors": [
        "Xinmin Feng",
        "Zhuoyuan Li",
        "Li Li",
        "Dong Liu",
        "Feng Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-25T14:53:03+00:00",
          "link": "https://arxiv.org/abs/2504.18398v1",
          "size": "5608kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T13:22:49+00:00",
          "link": "https://arxiv.org/abs/2504.18398v2",
          "size": "3514kb",
          "version": "v2"
        }
      ],
      "title": "Partition Map-Based Fast Block Partitioning for VVC Inter Coding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.18398",
        "HTML": "https://arxiv.org/html/2504.18398v2",
        "PDF": "https://arxiv.org/pdf/2504.18398"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a fast block partitioning algorithm for Versatile Video Coding, which does not relate to LLM training data processing."
      },
      "tasks": [
        "Quantization"
      ],
      "repo_urls": [
        "https://github.com/ustc-ivclab/ipm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10761",
      "abstract": "Detecting assistance from artificial intelligence is increasingly important as they become ubiquitous across complex tasks such as text generation, medical diagnosis, and autonomous driving. Aid detection is challenging for humans, especially when looking at abstract task data. Artificial neural networks excel at classification thanks to their ability to quickly learn from and process large amounts of data -- assuming appropriate preprocessing. We posit detecting help from AI as a classification task for such models. Much of the research in this space examines the classification of complex but concrete data classes, such as images. Many AI assistance detection scenarios, however, result in data that is not machine learning-friendly. We demonstrate that common models can effectively classify such data when it is appropriately preprocessed. To do so, we construct four distinct neural network-friendly image formulations along with an additional time-series formulation that explicitly encodes the exploration/exploitation of users, which allows for generalizability to other abstract tasks. We benchmark the quality of each image formulation across three classical deep learning architectures, along with a parallel CNN-RNN architecture that leverages the additional time series to maximize testing performance, showcasing the importance of encoding temporal and spatial quantities for detecting AI aid in abstract tasks.",
      "authors": [
        "Tyler King",
        "Nikolos Gurney",
        "John H. Miller",
        "and Volkan Ustun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:37:36+00:00",
          "link": "https://arxiv.org/abs/2507.10761v1",
          "size": "3010kb",
          "version": "v1"
        }
      ],
      "title": "Detecting AI Assistance in Abstract Complex Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10761",
        "HTML": "https://arxiv.org/html/2507.10761v1",
        "PDF": "https://arxiv.org/pdf/2507.10761"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions preprocessing as part of the classification task but primarily focuses on detecting AI assistance in abstract tasks rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11134",
      "abstract": "The growing demand for edge computing and AI drives research into analog in-memory computing using memristors, which overcome data movement bottlenecks by computing directly within memory. However, device failures and variations critically limit analog systems' precision and reliability. Existing fault-tolerance techniques, such as redundancy and retraining, are often inadequate for high-precision applications or scenarios requiring fixed matrices and privacy preservation. Here, we introduce and experimentally demonstrate a fault-free matrix representation where target matrices are decomposed into products of two adjustable sub-matrices programmed onto analog hardware. This indirect, adaptive representation enables mathematical optimization to bypass faulty devices and eliminate differential pairs, significantly enhancing computational density. Our memristor-based system achieved >99.999% cosine similarity for a Discrete Fourier Transform matrix despite 39% device fault rate, a fidelity unattainable with conventional direct representation, which fails with single device faults (0.01% rate). We demonstrated 56-fold bit-error-rate reduction in wireless communication and >196% density with 179% energy efficiency improvements compared to state-of-the-art techniques. This method, validated on memristors, applies broadly to emerging memories and non-electrical computing substrates, showing that device yield is no longer the primary bottleneck in analog computing hardware.",
      "authors": [
        "Zhicheng Xu",
        "Jiawei Liu",
        "Sitao Huang",
        "Zefan Li",
        "Shengbo Wang",
        "Bo Wen",
        "Ruibin Mao",
        "Mingrui Jiang",
        "Giacomo Pedretti",
        "Jim Ignowski",
        "Kaibin Huang",
        "and Can Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:37:05+00:00",
          "link": "https://arxiv.org/abs/2507.11134v1",
          "size": "25321kb",
          "version": "v1"
        }
      ],
      "title": "Fault-Free Analog Computing with Imperfect Hardware",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11134",
        "HTML": "https://arxiv.org/html/2507.11134v1",
        "PDF": "https://arxiv.org/pdf/2507.11134"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on fault-free analog computing with memristors, not on LLM training data processing or dataset generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11057",
      "abstract": "Delineating areas within metropolitan regions stands as an important focus among urban researchers, shedding light on the urban perimeters shaped by evolving population dynamics. Applications to urban science are numerous, from facilitating comparisons between delineated districts and administrative divisions to informing policymakers of the shifting economic and labor landscapes. In this study, we propose using commute networks sourced from the census for the purpose of urban delineation, by modeling them with a Graph Neural Network (GNN) architecture. We derive low-dimensional representations of granular urban areas (nodes) using GNNs. Subsequently, nodes' embeddings are clustered to identify spatially cohesive communities in urban areas. Our experiments across the U.S. demonstrate the effectiveness of network embeddings in capturing significant socioeconomic disparities between communities in various cities, particularly in factors such as median household income. The role of census mobility data in regional delineation is also noted, and we establish the utility of GNNs in urban community detection, as a powerful alternative to existing methods in this domain. The results offer insights into the wider effects of commute networks and their use in building meaningful representations of urban regions.",
      "authors": [
        "Devashish Khulbe",
        "Stanislav Sobolevsky"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T07:47:03+00:00",
          "link": "https://arxiv.org/abs/2507.11057v1",
          "size": "7326kb",
          "version": "v1"
        }
      ],
      "title": "Urban delineation through the lens of commute networks: Leveraging graph embeddings to distinguish socioeconomic groups in cities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11057",
        "HTML": "https://arxiv.org/html/2507.11057v1",
        "PDF": "https://arxiv.org/pdf/2507.11057"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study uses graph embeddings for urban delineation and does not involve any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.05988",
      "abstract": "Low-carbon hydrogen (H2) is envisioned to play a central role in decarbonizing European hard-to-abate industries, such as refineries, ammonia, methanol, steel, and cement. To enable its widespread use, H2 supply chain (HSC) infrastructure is required. Mature and economically viable low-carbon H2 production pathways include steam methane reforming (SMR) of natural gas coupled with carbon dioxide capture and storage (CCS), water-electrolysis from renewable electricity, biomethane reforming, and biomass gasification. However, uncertainties surrounding demand and feedstock availabilities hamper their proliferation. Here, we investigate the impact of uncertainty in H2 demand and biomass availability on the optimal HSC design. The HSC is modeled as a network of H2 production and consumption sites that are interconnected with H2 and biomass transport technologies. A CCS supply chain is modeled alongside the HSC. The cost-optimal HSC design is determined based on a linear optimization problem that considers a regional resolution and a multi-year time horizon (2022-2050). We adopt a scenario-based uncertainty quantification approach and define discrete H2 demand and biomass availability scenarios. Applying a minimum-regret strategy, we show that sufficiently large low-carbon H2 production capacities (about 9.6 Mt/a by 2030) are essential to flexibly scale up HSCs and accommodate H2 demands of up to 35 Mt/a by 2050. While biomass-based H2 production emerges as the most cost-efficient low-carbon H2 production pathway, investments are not recommended unless the availability of biomass feedstocks is guaranteed. Instead, investments in SMR-CCS and electrolysis often offer greater flexibility. In addition, we highlight the importance of CCS infrastructure, which is required across scenarios.",
      "authors": [
        "Alissa Ganter",
        "Paolo Gabrielli",
        "Hanne Goericke",
        "Giovanni Sansavini"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-08T14:28:37+00:00",
          "link": "https://arxiv.org/abs/2407.05988v1",
          "size": "4625kb",
          "version": "v1"
        }
      ],
      "title": "Minimum-regret hydrogen supply chain strategies to foster the energy transition of European hard-to-abate industries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.05988",
        "HTML": "https://arxiv.org/html/2407.05988",
        "PDF": "https://arxiv.org/pdf/2407.05988"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates hydrogen supply chain strategies and does not relate to any LLM training data processing techniques or methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10785",
      "abstract": "Agile software development principles and values have been widely adopted across various industries, influencing products and services globally. Despite its increasing popularity, a significant gap remains between research and practical implementation. This paper presents the findings of the first international workshop designed to foster collaboration between research and practice in agile software development. We discuss the main themes and factors identified by the workshop participants that contribute to this gap, strategies to bridge it, and the challenges that require further research attention.",
      "authors": [
        "Michael Neumann",
        "Eva-Maria Sch\\\"on",
        "Mali Senapathi",
        "Maria Rauschenberger",
        "Tiago Silva da Silva"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T20:26:50+00:00",
          "link": "https://arxiv.org/abs/2507.10785v1",
          "size": "103kb",
          "version": "v1"
        }
      ],
      "title": "Towards a Closer Collaboration Between Practice and Research in Agile Software Development Workshop: A Summary and Research Agenda",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10785",
        "HTML": "https://arxiv.org/html/2507.10785v1",
        "PDF": "https://arxiv.org/pdf/2507.10785"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the gap between research and practice in agile software development but does not address LLM training data processing or data engineering tasks relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11132",
      "abstract": "In [Bailo, Carrillo, Hu. SIAM J. Appl. Math. 2023] the authors introduce a finite-volume method for aggregation-diffusion equations with non-linear mobility. In this paper we prove convergence of this method using an Aubin--Simons compactness theorem due to Gallou\\\"et and Latch\\'e. We use suitable discrete $H^1$ and $W^{-1,1}$ discrete norms. We provide two convergence results. A first result shows convergence with general entropies ($U$) (including singular and degenerate) if the initial datum does not have free boundaries, the mobility is Lipschitz, and the confinement ($V$) and aggregation ($K$) potentials are $W^{2,\\infty}_0$. A second result shows convergence when the initial datum has free boundaries, mobility is just continuous, and $V$ and $K$ are $W^{1,\\infty}$, but under the assumption that the entropy $U$ is $C^1$ and strictly convex.",
      "authors": [
        "David G\\'omez-Castro"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:33:16+00:00",
          "link": "https://arxiv.org/abs/2507.11132v1",
          "size": "1497kb",
          "version": "v1"
        }
      ],
      "title": "Convergence of a finite-volume scheme for aggregation-diffusion equations with saturation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11132",
        "PDF": "https://arxiv.org/pdf/2507.11132"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with the convergence of a finite-volume method for aggregation-diffusion equations, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11238",
      "abstract": "By using a selective filtration argument, we prove that the satisfiability problem of the unimodal logic of density is in $EXPTIME$. By using a tableau-like approach, we prove that the satisfiability problem of the bimodal logic of weak density is in $PSPACE$.",
      "authors": [
        "Philippe Balbiani and Olivier Gasquet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:12:09+00:00",
          "link": "https://arxiv.org/abs/2507.11238v1",
          "size": "17kb",
          "version": "v1"
        }
      ],
      "title": "Complexity of some modal logics of density (extended version)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11238",
        "HTML": "https://arxiv.org/html/2507.11238v1",
        "PDF": "https://arxiv.org/pdf/2507.11238"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates the complexity of modal logics, which is not related to the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18193",
      "abstract": "This paper introduces Decoupled Supervised Learning with Information Regularization (DeInfoReg), a novel approach that transforms a long gradient flow into multiple shorter ones, thereby mitigating the vanishing gradient problem. Integrating a pipeline strategy, DeInfoReg enables model parallelization across multiple GPUs, significantly improving training throughput. We compare our proposed method with standard backpropagation and other gradient flow decomposition techniques. Extensive experiments on diverse tasks and datasets demonstrate that DeInfoReg achieves superior performance and better noise resistance than traditional BP models and efficiently utilizes parallel computing resources. The code for reproducibility is available at: https://github.com/ianzih/Decoupled-Supervised-Learning-for-Information-Regularization/.",
      "authors": [
        "Zih-Hao Huang",
        "You-Teng Lin",
        "Hung-Hsuan Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-22T22:50:06+00:00",
          "link": "https://arxiv.org/abs/2506.18193v1",
          "size": "1021kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T14:29:38+00:00",
          "link": "https://arxiv.org/abs/2506.18193v2",
          "size": "1021kb",
          "version": "v2"
        }
      ],
      "title": "DeInfoReg: A Decoupled Learning Framework for Better Training Throughput",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18193",
        "HTML": "https://arxiv.org/html/2506.18193v2",
        "PDF": "https://arxiv.org/pdf/2506.18193"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses a novel model training framework to improve training throughput, with no mention of LLM training data processing or dataset manipulation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11412",
      "abstract": "The large language model (LLM) community focuses almost exclusively on decoder-only language models, since they are easier to use for text generation. However, a large subset of the community still uses encoder-only models for tasks such as classification or retrieval. Previous work has attempted to compare these architectures, but is forced to make comparisons with models that have different numbers of parameters, training techniques, and datasets. We introduce the SOTA open-data Ettin suite of models: paired encoder-only and decoder-only models ranging from 17 million parameters to 1 billion, trained on up to 2 trillion tokens. Using the same recipe for both encoder-only and decoder-only models produces SOTA recipes in both categories for their respective sizes, beating ModernBERT as an encoder and Llama 3.2 and SmolLM2 as decoders. Like previous work, we find that encoder-only models excel at classification and retrieval tasks while decoders excel at generative tasks. However, we show that adapting a decoder model to encoder tasks (and vice versa) through continued training is subpar compared to using only the reverse objective (i.e. a 400M encoder outperforms a 1B decoder on MNLI, and vice versa for generative tasks). We open-source all artifacts of this study including training data, training order segmented by checkpoint, and 200+ checkpoints to allow future work to analyze or extend all aspects of training.",
      "authors": [
        "Orion Weller and Kathryn Ricci and Marc Marone and Antoine Chaffin and Dawn Lawrie and Benjamin Van Durme"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:31:51+00:00",
          "link": "https://arxiv.org/abs/2507.11412v1",
          "size": "88kb",
          "version": "v1"
        }
      ],
      "title": "Seq vs Seq: An Open Suite of Paired Encoders and Decoders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11412",
        "HTML": "https://arxiv.org/html/2507.11412v1",
        "PDF": "https://arxiv.org/pdf/2507.11412"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes the development and training of paired encoder and decoder models and mentions open-sourcing datasets used, but its main focus is on model architecture and performance."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11423",
      "abstract": "Human reasoning involves different strategies, each suited to specific problems. Prior work shows that large language model (LLMs) tend to favor a single reasoning strategy, potentially limiting their effectiveness in diverse reasoning challenges. In this work, we investigate whether prompting can control LLMs reasoning strategies and assess its impact on logical problem-solving. While our experiments show that no single strategy consistently improves accuracy, performance could be enhanced if models could adaptively choose the optimal strategy. We propose methods to guide LLMs in strategy selection, highlighting new ways to refine their reasoning abilities.",
      "authors": [
        "Yanjian Zhang",
        "Guillaume Wisniewski",
        "Nadi Tomeh",
        "Thierry Charnois"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:47:47+00:00",
          "link": "https://arxiv.org/abs/2507.11423v1",
          "size": "435kb",
          "version": "v1"
        }
      ],
      "title": "Reasoning Strategies in Large Language Models: Can They Follow, Prefer, and Optimize?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11423",
        "PDF": "https://arxiv.org/pdf/2507.11423"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores reasoning strategies in LLMs and does not address training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11527",
      "abstract": "Large Language Model (LLM) agents have shown great potential for solving real-world problems and promise to be a solution for tasks automation in industry. However, more benchmarks are needed to systematically evaluate automation agents from an industrial perspective, for example, in Civil Engineering. Therefore, we propose DrafterBench for the comprehensive evaluation of LLM agents in the context of technical drawing revision, a representation task in civil engineering. DrafterBench contains twelve types of tasks summarized from real-world drawing files, with 46 customized functions/tools and 1920 tasks in total. DrafterBench is an open-source benchmark to rigorously test AI agents' proficiency in interpreting intricate and long-context instructions, leveraging prior knowledge, and adapting to dynamic instruction quality via implicit policy awareness. The toolkit comprehensively assesses distinct capabilities in structured data comprehension, function execution, instruction following, and critical reasoning. DrafterBench offers detailed analysis of task accuracy and error statistics, aiming to provide deeper insight into agent capabilities and identify improvement targets for integrating LLMs in engineering applications. Our benchmark is available at https://github.com/Eason-Li-AIS/DrafterBench, with the test set hosted at https://huggingface.co/datasets/Eason666/DrafterBench.",
      "authors": [
        "Yinsheng Li",
        "Zhen Dong",
        "Yi Shao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:56:04+00:00",
          "link": "https://arxiv.org/abs/2507.11527v1",
          "size": "19672kb",
          "version": "v1"
        }
      ],
      "title": "DrafterBench: Benchmarking Large Language Models for Tasks Automation in Civil Engineering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11527",
        "HTML": "https://arxiv.org/html/2507.11527v1",
        "PDF": "https://arxiv.org/pdf/2507.11527"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper describes a benchmark for evaluating LLMs in civil engineering tasks, focusing on task performance evaluation rather than LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10813",
      "abstract": "Visual neuroprostheses (bionic eye) aim to restore a rudimentary form of vision by translating camera input into patterns of electrical stimulation. To improve scene understanding under extreme resolution and bandwidth constraints, prior work has explored computer vision techniques such as semantic segmentation and depth estimation. However, presenting all task-relevant information simultaneously can overwhelm users in cluttered environments. We compare two complementary approaches to semantic preprocessing in immersive virtual reality: SemanticEdges, which highlights all relevant objects at once, and SemanticRaster, which staggers object categories over time to reduce visual clutter. Using a biologically grounded simulation of prosthetic vision, 18 sighted participants performed a wayfinding task in a dynamic urban environment across three conditions: edge-based baseline (Control), SemanticEdges, and SemanticRaster. Both semantic strategies improved performance and user experience relative to the baseline, with each offering distinct trade-offs: SemanticEdges increased the odds of success, while SemanticRaster boosted the likelihood of collision-free completions. These findings underscore the value of adaptive semantic preprocessing for prosthetic vision and, more broadly, may inform the design of low-bandwidth visual interfaces in XR that must balance information density, task relevance, and perceptual clarity.",
      "authors": [
        "Justin M. Kasowski",
        "Apurv Varshney",
        "Michael Beyeler"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T21:20:36+00:00",
          "link": "https://arxiv.org/abs/2507.10813v1",
          "size": "7034kb",
          "version": "v1"
        }
      ],
      "title": "Static or Temporal? Semantic Scene Simplification to Aid Wayfinding in Immersive Simulations of Bionic Vision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10813",
        "HTML": "https://arxiv.org/html/2507.10813v1",
        "PDF": "https://arxiv.org/pdf/2507.10813"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses semantic preprocessing for prosthetic vision in immersive simulations but does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10845",
      "abstract": "Collaborative fuzzing has recently emerged as a technique that combines multiple individual fuzzers and dynamically chooses the appropriate combinations suited for different programs. Unlike individual fuzzers, which rely on specific assumptions to maintain their effectiveness, collaborative fuzzing relaxes the assumptions on target programs, providing constant and robust performance across various programs. Ideally, collaborative fuzzing should be a more promising direction toward generic fuzzing solutions, as it mitigates the need for manual cherry-picking of individual fuzzers. However, the effectiveness of existing collaborative fuzzing frameworks is limited by major challenges, such as the need for additional computational resources compared to individual fuzzers and the inefficient allocation of resources among the various fuzzers.",
      "authors": [
        "Wenxuan Shi",
        "Hongwei Li",
        "Jiahao Yu",
        "Xinqian Sun",
        "Wenbo Guo and Xinyu Xing"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T22:37:21+00:00",
          "link": "https://arxiv.org/abs/2507.10845v1",
          "size": "4301kb",
          "version": "v1"
        }
      ],
      "title": "BandFuzz: An ML-powered Collaborative Fuzzing Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10845",
        "HTML": "https://arxiv.org/html/2507.10845v1",
        "PDF": "https://arxiv.org/pdf/2507.10845"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a collaborative fuzzing framework for software testing and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11077",
      "abstract": "Monocular pose estimation of non-cooperative spacecraft is significant for on-orbit service (OOS) tasks, such as satellite maintenance, space debris removal, and station assembly. Considering the high demands on pose estimation accuracy, mainstream monocular pose estimation methods typically consist of keypoint detectors and PnP solver. However, current keypoint detectors remain vulnerable to structural symmetry and partial occlusion of non-cooperative spacecraft. To this end, we propose a graph-based keypoints network for the monocular pose estimation of non-cooperative spacecraft, GKNet, which leverages the geometric constraint of keypoints graph. In order to better validate keypoint detectors, we present a moderate-scale dataset for the spacecraft keypoint detection, named SKD, which consists of 3 spacecraft targets, 90,000 simulated images, and corresponding high-precise keypoint annotations. Extensive experiments and an ablation study have demonstrated the high accuracy and effectiveness of our GKNet, compared to the state-of-the-art spacecraft keypoint detectors. The code for GKNet and the SKD dataset is available at https://github.com/Dongzhou-1996/GKNet.",
      "authors": [
        "Weizhao Ma",
        "Dong Zhou",
        "Yuhui Hu and Zipeng He"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:18:14+00:00",
          "link": "https://arxiv.org/abs/2507.11077v1",
          "size": "7004kb",
          "version": "v1"
        }
      ],
      "title": "GKNet: Graph-based Keypoints Network for Monocular Pose Estimation of Non-cooperative Spacecraft",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11077",
        "HTML": "https://arxiv.org/html/2507.11077v1",
        "PDF": "https://arxiv.org/pdf/2507.11077"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a dataset (SKD) for keypoint detection in spacecraft; however, it focuses primarily on monocular pose estimation rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11214",
      "abstract": "We introduce and study the problem of designing optimal contracts under fairness constraints on the task assignments and compensations. We adopt the notion of envy-free (EF) and its relaxations, $\\epsilon$-EF and envy-free up to one item (EF1), in contract design settings. Unlike fair allocations, EF contracts are guaranteed to exist. However, computing any constant-factor approximation to the optimal EF contract is NP-hard in general, even using $\\epsilon$-EF contracts. For this reason, we consider settings in which the number of agents or tasks is constant. Notably, while even with three agents, finding an EF contract better than $2/5$ approximation of the optimal is NP-hard, we are able to design an FPTAS when the number of agents is constant, under relaxed notions of $\\epsilon$-EF and EF1. Moreover, we present a polynomial-time algorithm for computing the optimal EF contract when the number of tasks is constant. Finally, we analyze the price of fairness in contract design. We show that the price of fairness for exact EF contracts can be unbounded, even with a single task and two agents. In contrast, for EF1 contracts, the price of fairness is bounded between $\\Omega(\\sqrt{n})$ and $O(n^2)$, where $n$ is the number of agents.",
      "authors": [
        "Matteo Castiglioni",
        "Junjie Chen",
        "Yingkai Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T11:31:28+00:00",
          "link": "https://arxiv.org/abs/2507.11214v1",
          "size": "61kb",
          "version": "v1"
        }
      ],
      "title": "Fair Contracts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11214",
        "HTML": "https://arxiv.org/html/2507.11214v1",
        "PDF": "https://arxiv.org/pdf/2507.11214"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on designing fair contracts and computational complexity within contract design settings, without mentioning LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.19077",
      "abstract": "Sub-seasonal wind speed forecasts provide valuable guidance for wind power system planning and operations, yet the forecast skills of surface winds decrease sharply after two weeks. However, large-scale variables exhibit greater predictability on this time scale. This study explores the potential of leveraging non-linear relationships between 500 hPa geopotential height (Z500) and surface wind speed to improve sub-seasonal wind speed forecast skills in Europe. Our proposed framework uses a Multiple Linear Regression (MLR) or a Convolutional Neural Network (CNN) to regress surface wind speed from Z500. Evaluations on ERA5 reanalysis indicate that the CNN performs better due to its non-linearity. Applying these models to sub-seasonal forecasts from the European Centre for Medium-Range Weather Forecasts, various verification metrics demonstrate the advantages of non-linearity. Yet, this is partly explained by the fact that these statistical models are under-dispersive since they explain only a fraction of the target variable variance. Introducing stochastic perturbations to represent the stochasticity of the unexplained part from the signal helps compensate for this issue. Results show that the perturbed CNN performs better than the perturbed MLR only in the first weeks, while the perturbed MLR's performance converges towards that of the perturbed CNN after two weeks. The study finds that introducing stochastic perturbations can address the issue of insufficient spread in these statistical models, with improvements from the non-linearity varying with the lead time of the forecasts.",
      "authors": [
        "Ganglin Tian (1)",
        "Camille Le Coz (1)",
        "Anastase Alexandre Charantonis (1",
        "2)",
        "Alexis Tantet (1)",
        "Naveen Goutham (1",
        "3)",
        "Riwal Plougonven (1) ((1) LMD/IPSL",
        "\\'Ecole Polytechnique",
        "Palaiseau",
        "France",
        "(2) INRIA",
        "Paris",
        "France",
        "(3) EDF R&D",
        "Palaiseau",
        "France)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-28T11:53:59+00:00",
          "link": "https://arxiv.org/abs/2411.19077v1",
          "size": "5427kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T15:47:04+00:00",
          "link": "https://arxiv.org/abs/2411.19077v2",
          "size": "5518kb",
          "version": "v2"
        }
      ],
      "title": "Improving sub-seasonal wind-speed forecasts in Europe with a non-linear model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.19077",
        "HTML": "https://arxiv.org/html/2411.19077v2",
        "PDF": "https://arxiv.org/pdf/2411.19077"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores non-linear models to improve wind-speed forecasts and does not discuss LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/TIANGANGLIN/s2s-wind-Non-linearity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.10077",
      "abstract": "Semantic degeneracy represents a fundamental property of natural language that extends beyond simple polysemy to encompass the combinatorial explosion of potential interpretations that emerges as semantic expressions increase in complexity. In this work, we argue this property imposes fundamental limitations on Large Language Models (LLMs) and other modern NLP systems, precisely because they operate within natural language itself. Using Kolmogorov complexity, we demonstrate that as an expression's complexity grows, the amount of contextual information required to reliably resolve its ambiguity explodes combinatorially. The computational intractability of recovering a single intended meaning for complex or ambiguous text therefore suggests that the classical view that linguistic forms possess intrinsic meaning in and of themselves is conceptually inadequate. We argue instead that meaning is dynamically actualized through an observer-dependent interpretive act, a process whose non-deterministic nature is most appropriately described by a non-classical, quantum-like logic. To test this hypothesis, we conducted a semantic Bell inequality test using diverse LLM agents. Our experiments yielded average CHSH expectation values from 1.2 to 2.8, with several runs producing values (e.g., 2.3-2.4) in significant violation of the classical boundary ($|S|\\leq2$), demonstrating that linguistic interpretation under ambiguity can exhibit non-classical contextuality, consistent with results from human cognition experiments. These results inherently imply that classical frequentist-based analytical approaches for natural language are necessarily lossy. Instead, we propose that Bayesian-style repeated sampling approaches can provide more practically useful and appropriate characterizations of linguistic meaning in context.",
      "authors": [
        "Christopher J. Agostino",
        "Quan Le Thien",
        "Molly Apsel",
        "Denizhan Pak",
        "Elina Lesyk",
        "Ashabari Majumdar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T18:00:30+00:00",
          "link": "https://arxiv.org/abs/2506.10077v1",
          "size": "390kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T00:08:11+00:00",
          "link": "https://arxiv.org/abs/2506.10077v2",
          "size": "1137kb",
          "version": "v2"
        }
      ],
      "title": "A quantum semantic framework for natural language processing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10077",
        "HTML": "https://arxiv.org/html/2506.10077v2",
        "PDF": "https://arxiv.org/pdf/2506.10077"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a quantum semantic framework and does not involve any specific methodology or contribution related to LLM training data processing or dataset creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.10678",
      "abstract": "A major challenge in the use of neural networks both for modeling human cognitive function and for artificial intelligence is the design of systems with the capacity to efficiently learn functions that support radical generalization. At the roots of this is the capacity to discover and implement symmetry functions. In this paper, we investigate a paradigmatic example of radical generalization through the use of symmetry: base addition. We present a group theoretic analysis of base addition, a fundamental and defining characteristic of which is the carry function -- the transfer of the remainder, when a sum exceeds the base modulus, to the next significant place. Our analysis exposes a range of alternative carry functions for a given base, and we introduce quantitative measures to characterize these. We then exploit differences in carry functions to probe the inductive biases of neural networks in symmetry learning, by training neural networks to carry out base addition using different carries, and comparing efficacy and rate of learning as a function of their structure. We find that even simple neural networks can achieve radical generalization with the right input format and carry function, and that learning speed is closely correlated with carry function structure. We then discuss the relevance this has for cognitive science and machine learning.",
      "authors": [
        "Cutter Dawes",
        "Simon Segert",
        "Kamesh Krishnamurthy",
        "Jonathan D. Cohen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:01:38+00:00",
          "link": "https://arxiv.org/abs/2507.10678v1",
          "size": "9713kb",
          "version": "v1"
        }
      ],
      "title": "A Group Theoretic Analysis of the Symmetries Underlying Base Addition and Their Learnability by Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10678",
        "HTML": "https://arxiv.org/html/2507.10678v1",
        "PDF": "https://arxiv.org/pdf/2507.10678"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper delves into a group theoretic analysis related to neural networks and symmetry learning, focusing on generalization and learning symmetry functions, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10991",
      "abstract": "Vision-based underwater robots can be useful in inspecting and exploring confined spaces where traditional sensors and preplanned paths cannot be followed. Sensor noise and situational change can cause significant uncertainty in environmental representation. Thus, this paper explores how to represent mapping inconsistency in vision-based sensing and incorporate depth estimation confidence into the mapping framework. The scene depth and the confidence are estimated using the RAFT-Stereo model and are integrated into a voxel-based mapping framework, Voxblox. Improvements in the existing Voxblox weight calculation and update mechanism are also proposed. Finally, a qualitative analysis of the proposed method is performed in a confined pool and in a pier in the Trondheim fjord. Experiments using an underwater robot demonstrated the change in uncertainty in the visualization.",
      "authors": [
        "Abhimanyu Bhowmik",
        "Mohit Singh",
        "Madhushree Sannigrahi",
        "Martin Ludvigsen",
        "Kostas Alexis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T05:09:36+00:00",
          "link": "https://arxiv.org/abs/2507.10991v1",
          "size": "16686kb",
          "version": "v1"
        }
      ],
      "title": "Uncertainty Aware Mapping for Vision-Based Underwater Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10991",
        "HTML": "https://arxiv.org/html/2507.10991v1",
        "PDF": "https://arxiv.org/pdf/2507.10991"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on mapping and uncertainty in vision-based underwater robots, not on LLM training data processing or relevant data-engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11493",
      "abstract": "This paper introduces a novel parametric activation function based on Wendland radial basis functions (RBFs) for deep neural networks. Wendland RBFs, known for their compact support, smoothness, and positive definiteness in approximation theory, are adapted to address limitations of traditional activation functions like ReLU, sigmoid, and tanh. The proposed enhanced Wendland activation combines a standard Wendland component with linear and exponential terms, offering tunable locality, improved gradient propagation, and enhanced stability during training. Theoretical analysis highlights its mathematical properties, including smoothness and adaptability, while empirical experiments on synthetic tasks (e.g., sine wave approximation) and benchmark datasets (MNIST, Fashion-MNIST) demonstrate competitive performance. Results show that the Wendland-based activation achieves superior accuracy in certain scenarios, particularly in regression tasks, while maintaining computational efficiency. The study bridges classical RBF theory with modern deep learning, suggesting that Wendland activations can mitigate overfitting and improve generalization through localized, smooth transformations. Future directions include hybrid architectures and domain-specific adaptations.",
      "authors": [
        "Majid Darehmiraki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T11:35:10+00:00",
          "link": "https://arxiv.org/abs/2507.11493v1",
          "size": "254kb",
          "version": "v1"
        }
      ],
      "title": "A parametric activation function based on Wendland RBF",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11493",
        "HTML": "https://arxiv.org/html/2507.11493v1",
        "PDF": "https://arxiv.org/pdf/2507.11493"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on a novel activation function for neural networks, with no discussion on LLM training data processing or related data engineering methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.01319",
      "abstract": "Speech-driven 3D facial animation plays a key role in applications such as virtual avatars, gaming, and digital content creation. While existing methods have made significant progress in achieving accurate lip synchronization and generating basic emotional expressions, they often struggle to capture and effectively transfer nuanced performance styles. We propose a novel example-based generation framework that conditions a latent diffusion model on a reference style clip to produce highly expressive and temporally coherent facial animations. To address the challenge of accurately adhering to the style reference, we introduce a novel conditioning mechanism called style basis, which extracts key poses from the reference and additively guides the diffusion generation process to fit the style without compromising lip synchronization quality. This approach enables the model to capture subtle stylistic cues while ensuring that the generated animations align closely with the input speech. Extensive qualitative, quantitative, and perceptual evaluations demonstrate the effectiveness of our method in faithfully reproducing the desired style while achieving superior lip synchronization across various speech scenarios.",
      "authors": [
        "Yifang Pan",
        "Karan Singh",
        "Luiz Gustavo Hafemann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-02T14:47:21+00:00",
          "link": "https://arxiv.org/abs/2505.01319v1",
          "size": "11536kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T16:48:15+00:00",
          "link": "https://arxiv.org/abs/2505.01319v2",
          "size": "11537kb",
          "version": "v2"
        }
      ],
      "title": "Model See Model Do: Speech-Driven Facial Animation with Style Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.01319",
        "HTML": "https://arxiv.org/html/2505.01319v2",
        "PDF": "https://arxiv.org/pdf/2505.01319"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a method for speech-driven facial animation with style control, focusing on generation, not on LLM training data processing."
      },
      "tasks": [
        "model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10809",
      "abstract": "Inferring causal relationships between event pairs in a temporal sequence is applicable in many domains such as healthcare, manufacturing, and transportation. Most existing work on causal inference primarily focuses on event types within the designated domain, without considering the impact of exogenous out-of-domain interventions. In real-world settings, these out-of-domain interventions can significantly alter causal dynamics. To address this gap, we propose a new causal framework to define average treatment effect (ATE), beyond independent and identically distributed (i.i.d.) data in classic Rubin's causal framework, to capture the causal relation shift between events of temporal process under out-of-domain intervention. We design an unbiased ATE estimator, and devise a Transformer-based neural network model to handle both long-range temporal dependencies and local patterns while integrating out-of-domain intervention information into process modeling. Extensive experiments on both simulated and real-world datasets demonstrate that our method outperforms baselines in ATE estimation and goodness-of-fit under out-of-domain-augmented point processes.",
      "authors": [
        "Kazi Tasnim Zinat",
        "Yun Zhou",
        "Xiang Lyu",
        "Yawei Wang",
        "Zhicheng Liu",
        "Panpan Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T21:08:35+00:00",
          "link": "https://arxiv.org/abs/2507.10809v1",
          "size": "262kb",
          "version": "v1"
        }
      ],
      "title": "Uncovering Causal Relation Shifts in Event Sequences under Out-of-Domain Interventions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10809",
        "HTML": "https://arxiv.org/html/2507.10809v1",
        "PDF": "https://arxiv.org/pdf/2507.10809"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses causal relation shifts in event sequences, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.13644",
      "abstract": "Cellular scale decision making is modulated by the dynamics of signalling molecules and their diffusive trajectories from a source to small absorbing sites on the cellular surface. Diffusive capture problems are computationally challenging due to the complex geometry and the applied boundary conditions together with intrinsically long transients that occur before a particle is captured. This paper reports on a particle-based Kinetic Monte Carlo (KMC) method that provides rapid accurate simulation of arrival statistics for (i) a half-space bounded by a surface with a finite collection of absorbing traps and (ii) the domain exterior to a convex cell again with absorbing traps. We validate our method by replicating classical results and in addition, newly developed boundary homogenization theories and matched asymptotic expansions on capture rates. In the case of non-spherical domains, we describe a new shielding effect in which geometry can play a role in sharpening cellular estimates on the directionality of diffusive sources.",
      "authors": [
        "Alan E. Lindsay and Andrew J. Bernoff"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)",
        "Biological Physics (physics.bio-ph)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-19T15:48:05+00:00",
          "link": "https://arxiv.org/abs/2406.13644v1",
          "size": "7173kb",
          "version": "v1"
        },
        {
          "date": "2024-10-27T10:49:52+00:00",
          "link": "https://arxiv.org/abs/2406.13644v2",
          "size": "4038kb",
          "version": "v2"
        }
      ],
      "title": "Kinetic Monte Carlo methods for three-dimensional diffusive capture problems in exterior domains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.13644",
        "HTML": "https://arxiv.org/html/2406.13644",
        "PDF": "https://arxiv.org/pdf/2406.13644"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with Kinetic Monte Carlo methods for simulating diffusive capture problems, which does not involve any aspect of LLM training data processing."
      },
      "repo_urls": [
        "https://github.com/alanlindsay/3DKMC"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.02029",
      "abstract": "We introduce RoboBrain 2.0, our latest generation of embodied vision-language foundation models, designed to unify perception, reasoning, and planning for complex embodied tasks in physical environments. It comes in two variants: a lightweight 7B model and a full-scale 32B model, featuring a heterogeneous architecture with a vision encoder and a language model. Despite its compact size, RoboBrain 2.0 achieves strong performance across a wide spectrum of embodied reasoning tasks. On both spatial and temporal benchmarks, the 32B variant achieves leading results, surpassing prior open-source and proprietary models. In particular, it supports key real-world embodied AI capabilities, including spatial understanding (e.g., affordance prediction, spatial referring, trajectory forecasting) and temporal decision-making (e.g., closed-loop interaction, multi-agent long-horizon planning, and scene graph updating). This report details the model architecture, data construction, multi-stage training strategies, infrastructure and practical applications. We hope RoboBrain 2.0 advances embodied AI research and serves as a practical step toward building generalist embodied agents. The code, checkpoint and benchmark are available at https://superrobobrain.github.io.",
      "authors": [
        "BAAI RoboBrain Team: Mingyu Cao",
        "Huajie Tan",
        "Yuheng Ji",
        "Minglan Lin",
        "Zhiyu Li",
        "Zhou Cao",
        "Pengwei Wang",
        "Enshen Zhou",
        "Yi Han",
        "Yingbo Tang",
        "Xiangqi Xu",
        "Wei Guo",
        "Yaoxu Lyu",
        "Yijie Xu",
        "Jiayu Shi",
        "Mengfei Du",
        "Cheng Chi",
        "Mengdi Zhao",
        "Xiaoshuai Hao",
        "Junkai Zhao",
        "Xiaojie Zhang",
        "Shanyu Rong",
        "Huaihai Lyu",
        "Zhengliang Cai",
        "Yankai Fu",
        "Ning Chen",
        "Bolun Zhang",
        "Lingfeng Zhang",
        "Shuyi Zhang",
        "Dong Liu",
        "Xi Feng",
        "Songjing Wang",
        "Xiaodan Liu",
        "Yance Jiao",
        "Mengsi Lyu",
        "Zhuo Chen",
        "Chenrui He",
        "Yulong Ao",
        "Xue Sun",
        "Zheqi He",
        "Jingshu Zheng",
        "Xi Yang",
        "Donghai Shi",
        "Kunchang Xie",
        "Bochao Zhang",
        "Shaokai Nie",
        "Chunlei Men",
        "Yonghua Lin",
        "Zhongyuan Wang",
        "Tiejun Huang",
        "Shanghang Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T17:05:33+00:00",
          "link": "https://arxiv.org/abs/2507.02029v1",
          "size": "28858kb",
          "version": "v1"
        },
        {
          "date": "2025-07-05T07:29:07+00:00",
          "link": "https://arxiv.org/abs/2507.02029v2",
          "size": "28858kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T03:44:05+00:00",
          "link": "https://arxiv.org/abs/2507.02029v3",
          "size": "28858kb",
          "version": "v3"
        }
      ],
      "title": "RoboBrain 2.0 Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02029",
        "PDF": "https://arxiv.org/pdf/2507.02029"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses vision-language models and data construction, but lacks detail on specific contributions to LLM training data processing such as data curation or preprocessing procedures."
      },
      "models": [
        {
          "model_path": "BAAI/RoboBrain2.0-32B",
          "downloads": "239",
          "likes": "20",
          "trending_score": "8.0",
          "link": "https://huggingface.co/BAAI/RoboBrain2.0-32B"
        },
        {
          "model_path": "BAAI/RoboBrain2.0-7B",
          "downloads": "5006",
          "likes": "92",
          "trending_score": "4.0",
          "link": "https://huggingface.co/BAAI/RoboBrain2.0-7B"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10569",
      "abstract": "Understanding the metric structure of permutation families is fundamental to combinatorics and has applications in social choice theory, bioinformatics, and coding theory. We study permutation families defined by restriction graphs--oriented graphs that constrain the relative order of elements in valid permutations. For any restriction graph $G$, we determine the maximum distance achievable by two permutations under the $\\ell_\\infty$-metric and provide an explicit algorithm that constructs optimal permutation pairs. Our main contribution characterizes when the Kendall-Tau metric achieves its combinatorial upper bound: this occurs if and only if the poset induced by $G$ has dimension at most 2. When this condition holds, the extremal permutations form a minimal realizer of the poset, revealing a deep connection between metric geometry and poset dimension theory. We apply these results to classical permutation statistics including descent sets and Hessenberg varieties, obtaining explicit formulas and efficient algorithms for computing metric diameters.",
      "authors": [
        "Danylo Tymoshenko",
        "Leonhard Nagel"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T22:00:05+00:00",
          "link": "https://arxiv.org/abs/2507.10569v1",
          "size": "12kb",
          "version": "v1"
        }
      ],
      "title": "Metrics on Permutation Families Defined by a Restriction Graph",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10569",
        "HTML": "https://arxiv.org/html/2507.10569v1",
        "PDF": "https://arxiv.org/pdf/2507.10569"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper studies metrics on permutation families and is concerned with combinatorial structures, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10895",
      "abstract": "In this work, we address the often-overlooked issue of Timescale Dependent Label Inconsistency (TsDLI) in training neural network models for EEG-based human emotion recognition. To mitigate TsDLI and enhance model generalization and explainability, we propose two novel regularization strategies: Local Variation Loss (LVL) and Local-Global Consistency Loss (LGCL). Both methods incorporate classical mathematical principles--specifically, functions of bounded variation and commute-time distances--within a graph theoretic framework. Complementing our regularizers, we introduce a suite of new evaluation metrics that better capture the alignment between temporally local predictions and their associated global emotion labels. We validate our approach through comprehensive experiments on two widely used EEG emotion datasets, DREAMER and DEAP, across a range of neural architectures including LSTM and transformer-based models. Performance is assessed using five distinct metrics encompassing both quantitative accuracy and qualitative consistency. Results consistently show that our proposed methods outperform state-of-the-art baselines, delivering superior aggregate performance and offering a principled trade-off between interpretability and predictive power under label inconsistency. Notably, LVL achieves the best aggregate rank across all benchmarked backbones and metrics, while LGCL frequently ranks the second, highlighting the effectiveness of our framework.",
      "authors": [
        "Xiaocong Zeng",
        "Craig Michoski",
        "Yan Pang",
        "Dongyang Kuang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T01:22:14+00:00",
          "link": "https://arxiv.org/abs/2507.10895v1",
          "size": "3283kb",
          "version": "v1"
        }
      ],
      "title": "Commuting Distance Regularization for Timescale-Dependent Label Inconsistency in EEG Emotion Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10895",
        "HTML": "https://arxiv.org/html/2507.10895v1",
        "PDF": "https://arxiv.org/pdf/2507.10895"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses issues in EEG emotion recognition, focusing on regularization strategies without contributing to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10968",
      "abstract": "Merging onto a highway is a complex driving task that requires identifying a safe gap, adjusting speed, often interactions to create a merging gap, and completing the merge maneuver within a limited time window while maintaining safety and driving comfort. In this paper, we introduce a Safe Merging and Real-Time Merge (SMART-Merge) planner, a lattice-based motion planner designed to facilitate safe and comfortable forced merging. By deliberately adapting cost terms to the unique challenges of forced merging and introducing a desired speed heuristic, SMART-Merge planner enables the ego vehicle to merge successfully while minimizing the merge time. We verify the efficiency and effectiveness of the proposed merge planner through high-fidelity CarMaker simulations on hundreds of highway merge scenarios. Our proposed planner achieves the success rate of 100% as well as completes the merge maneuver in the shortest amount of time compared with the baselines, demonstrating our planner's capability to handle complex forced merge tasks and provide a reliable and robust solution for autonomous highway merge. The simulation result videos are available at https://sites.google.com/view/smart-merge-planner/home.",
      "authors": [
        "Toktam Mohammadnejad",
        "Jovin D'sa",
        "Behdad Chalaki",
        "Hossein Nourkhiz Mahjoub",
        "Ehsan Moradi-Pari"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T04:15:35+00:00",
          "link": "https://arxiv.org/abs/2507.10968v1",
          "size": "5342kb",
          "version": "v1"
        }
      ],
      "title": "SMART-Merge Planner: A Safe Merging and Real-Time Motion Planner for Autonomous Highway On-Ramp Merging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10968",
        "HTML": "https://arxiv.org/html/2507.10968v1",
        "PDF": "https://arxiv.org/pdf/2507.10968"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a motion planner for autonomous vehicles, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11052",
      "abstract": "Timely identification and accurate risk stratification of cardiovascular disease (CVD) remain essential for reducing global mortality. While existing prediction models primarily leverage structured data, unstructured clinical notes contain valuable early indicators. This study introduces a novel LLM-augmented clinical NLP pipeline that employs domain-adapted large language models for symptom extraction, contextual reasoning, and correlation from free-text reports. Our approach integrates cardiovascular-specific fine-tuning, prompt-based inference, and entity-aware reasoning. Evaluations on MIMIC-III and CARDIO-NLP datasets demonstrate improved performance in precision, recall, F1-score, and AUROC, with high clinical relevance (kappa = 0.82) assessed by cardiologists. Challenges such as contextual hallucination, which occurs when plausible information contracts with provided source, and temporal ambiguity, which is related with models struggling with chronological ordering of events are addressed using prompt engineering and hybrid rule-based verification. This work underscores the potential of LLMs in clinical decision support systems (CDSS), advancing early warning systems and enhancing the translation of patient narratives into actionable risk assessments.",
      "authors": [
        "Haowei Yang",
        "Ziyu Shen",
        "Junli Shao",
        "Luyao Men",
        "Xinyue Han",
        "Jing Dong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T07:32:16+00:00",
          "link": "https://arxiv.org/abs/2507.11052v1",
          "size": "1327kb",
          "version": "v1"
        }
      ],
      "title": "LLM-Augmented Symptom Analysis for Cardiovascular Disease Risk Prediction: A Clinical NLP",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11052",
        "PDF": "https://arxiv.org/pdf/2507.11052"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper presents a novel LLM-augmented clinical NLP pipeline with significant emphasis on data processing methods, like cardiovascular-specific fine-tuning and entity-aware reasoning, which are crucial for improving data quality in training LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11233",
      "abstract": "Neural networks have become the dominant technique for accurate pitch and periodicity estimation. Although a lot of research has gone into improving network architectures and training paradigms, most approaches operate directly on the raw audio waveform or on general-purpose time-frequency representations. We investigate the use of Sawtooth-Inspired Pitch Estimation (SWIPE) kernels as an audio frontend and find that these hand-crafted, task-specific features can make neural pitch estimators more accurate, robust to noise, and more parameter-efficient. We evaluate supervised and self-supervised state-of-the-art architectures on common datasets and show that the SWIPE audio frontend allows for reducing the network size by an order of magnitude without performance degradation. Additionally, we show that the SWIPE algorithm on its own is much more accurate than commonly reported, outperforming state-of-the-art self-supervised neural pitch estimators.",
      "authors": [
        "David Marttila",
        "Joshua D. Reiss"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:04:07+00:00",
          "link": "https://arxiv.org/abs/2507.11233v1",
          "size": "114kb",
          "version": "v1"
        }
      ],
      "title": "Improving Neural Pitch Estimation with SWIPE Kernels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11233",
        "HTML": "https://arxiv.org/html/2507.11233v1",
        "PDF": "https://arxiv.org/pdf/2507.11233"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses neural networks for pitch estimation and does not involve any LLM training data processing tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11288",
      "abstract": "This paper introduces the Opus Prompt Intention Framework, designed to improve complex Workflow Generation with instruction-tuned Large Language Models (LLMs). We propose an intermediate Intention Capture layer between user queries and Workflow Generation, implementing the Opus Workflow Intention Framework, which consists of extracting Workflow Signals from user queries, interpreting them into structured Workflow Intention objects, and generating Workflows based on these Intentions. Our results show that this layer enables LLMs to produce logical and meaningful outputs that scale reliably as query complexity increases. On a synthetic benchmark of 1,000 multi-intent query-Workflow(s) pairs, applying the Opus Prompt Intention Framework to Workflow Generation yields consistent improvements in semantic Workflow similarity metrics. In this paper, we introduce the Opus Prompt Intention Framework by applying the concepts of Workflow Signal and Workflow Intention to LLM-driven Workflow Generation. We present a reproducible, customizable LLM-based Intention Capture system to extract Workflow Signals and Workflow Intentions from user queries. Finally, we provide empirical evidence that the proposed system significantly improves Workflow Generation quality compared to direct generation from user queries, particularly in cases of Mixed Intention Elicitation.",
      "authors": [
        "Th\\'eo Fagnoni",
        "Mahsun Altin",
        "Chia En Chung",
        "Phillip Kingston",
        "Alan Tuning",
        "Dana O. Mohamed",
        "In\\`es Adnani"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:13:07+00:00",
          "link": "https://arxiv.org/abs/2507.11288v1",
          "size": "18489kb",
          "version": "v1"
        }
      ],
      "title": "Opus: A Prompt Intention Framework for Complex Workflow Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11288",
        "HTML": "https://arxiv.org/html/2507.11288v1",
        "PDF": "https://arxiv.org/pdf/2507.11288"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a framework to improve Workflow Generation with instruction-tuned LLMs, but the focus is on the system architecture and its application rather than on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11346",
      "abstract": "Refactoring is a common software engineering practice that improves code quality without altering program behavior. Although tools like ReExtractor+, RefactoringMiner, and RefDiff have been developed to detect refactorings automatically, they rely on complex rule definitions and static analysis, making them difficult to extend and generalize to other programming languages. In this paper, we investigate the viability of using foundation models for refactoring detection, implemented in a tool named RefModel. We evaluate Phi4-14B, and Claude 3.5 Sonnet on a dataset of 858 single-operation transformations applied to artificially generated Java programs, covering widely-used refactoring types. We also extend our evaluation by including Gemini 2.5 Pro and o4-mini-high, assessing their performance on 44 real-world refactorings extracted from four open-source projects. These models are compared against RefactoringMiner, RefDiff, and ReExtractor+. RefModel is competitive with, and in some cases outperform, traditional tools. In real-world settings, Claude 3.5 Sonnet and Gemini 2.5 Pro jointly identified 97% of all refactorings, surpassing the best-performing static-analysis-based tools. The models showed encouraging generalization to Python and Golang. They provide natural language explanations and require only a single sentence to define each refactoring type.",
      "authors": [
        "Pedro Sim\\~oes and Rohit Gheyi and Rian Melo and Jonhnanthan Oliveira and M\\'arcio Ribeiro and Wesley K. G. Assun\\c{c}\\~ao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:20:56+00:00",
          "link": "https://arxiv.org/abs/2507.11346v1",
          "size": "43kb",
          "version": "v1"
        }
      ],
      "title": "RefModel: Detecting Refactorings using Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11346",
        "HTML": "https://arxiv.org/html/2507.11346v1",
        "PDF": "https://arxiv.org/pdf/2507.11346"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper centers on using foundation models for detecting software refactorings and does not address LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11483",
      "abstract": "Wireless networks are vulnerable to jamming attacks due to the shared communication medium, which can severely degrade performance and disrupt services. Despite extensive research, current jamming detection methods often rely on simulated data or proprietary over-the-air datasets with limited cross-layer features, failing to accurately represent the real state of a network and thus limiting their effectiveness in real-world scenarios. To address these challenges, we introduce JamShield, a dynamic jamming detection system trained on our own collected over-the-air and publicly available dataset. It utilizes hybrid feature selection to prioritize relevant features for accurate and efficient detection. Additionally, it includes an auto-classification module that dynamically adjusts the classification algorithm in real-time based on current network conditions. Our experimental results demonstrate significant improvements in detection rate, precision, and recall, along with reduced false alarms and misdetections compared to state-of-the-art detection algorithms, making JamShield a robust and reliable solution for detecting jamming attacks in real-world wireless networks.",
      "authors": [
        "Ioannis Panitsas",
        "Yagmur Yigit",
        "Leandros Tassiulas",
        "Leandros Maglaras",
        "and Berk Canberk"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:53:30+00:00",
          "link": "https://arxiv.org/abs/2507.11483v1",
          "size": "5764kb",
          "version": "v1"
        }
      ],
      "title": "JamShield: A Machine Learning Detection System for Over-the-Air Jamming Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11483",
        "HTML": "https://arxiv.org/html/2507.11483v1",
        "PDF": "https://arxiv.org/pdf/2507.11483"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces JamShield, a jamming attack detection system using a new dataset, it primarily focuses on wireless networks and not on LLM training data processing. It mentions dataset creation but not specifically for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.01096",
      "abstract": "We explore the theory of illfounded and cyclic proofs for the propositional modal $\\mu$-calculus. A fine analysis of provability for classical and intuitionistic modal logic provides a novel bridge between finitary, cyclic and illfounded conceptions of proof and re-enforces the importance of two normal form theorems for the logic: guardedness and disjunctiveness.",
      "authors": [
        "Bahareh Afshari",
        "Graham E. Leigh and Guillermo Men\\`endez Turata"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic (math.LO)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-02T08:32:52+00:00",
          "link": "https://arxiv.org/abs/2401.01096v1",
          "size": "70kb",
          "version": "v1"
        },
        {
          "date": "2024-12-22T15:19:42+00:00",
          "link": "https://arxiv.org/abs/2401.01096v2",
          "size": "83kb",
          "version": "v2"
        },
        {
          "date": "2025-06-19T12:47:32+00:00",
          "link": "https://arxiv.org/abs/2401.01096v3",
          "size": "87kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T08:54:45+00:00",
          "link": "https://arxiv.org/abs/2401.01096v4",
          "size": "72kb",
          "version": "v4"
        }
      ],
      "title": "Demystifying $\\mu$",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.01096",
        "PDF": "https://arxiv.org/pdf/2401.01096"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores theories in propositional modal logic without relation to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.17318",
      "abstract": "We present new convergence analyses for parallel subspace correction methods for unconstrained semicoercive and nearly semicoercive convex optimization problems, generalizing the theory of singular and nearly singular linear problems to a class of nonlinear problems. Our results demonstrate that the elegant theoretical framework developed for singular and nearly singular linear problems can be extended to unconstrained semicoercive and nearly semicoercive convex optimization problems. For semicoercive problems, we show that the convergence rate can be estimated in terms of a seminorm stable decomposition over the subspaces and the kernel of the problem, aligning with the theory for singular linear problems. For nearly semicoercive problems, we establish a parameter-independent convergence rate, assuming the kernel of the semicoercive part can be decomposed into a sum of local kernels, which aligns with the theory for nearly singular problems. To demonstrate the applicability of our results, we provide convergence analyses of two-level additive Schwarz methods for solving certain nonlinear partial differential equations with Neumann boundary conditions, within the proposed abstract framework.",
      "authors": [
        "Young-Ju Lee and Jongho Park"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-23T06:22:02+00:00",
          "link": "https://arxiv.org/abs/2412.17318v1",
          "size": "52kb",
          "version": "v1"
        },
        {
          "date": "2025-06-05T19:59:22+00:00",
          "link": "https://arxiv.org/abs/2412.17318v2",
          "size": "53kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T06:05:43+00:00",
          "link": "https://arxiv.org/abs/2412.17318v3",
          "size": "50kb",
          "version": "v3"
        }
      ],
      "title": "Parallel subspace correction methods for semicoercive and nearly semicoercive convex optimization with applications to nonlinear PDEs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.17318",
        "HTML": "https://arxiv.org/html/2412.17318v3",
        "PDF": "https://arxiv.org/pdf/2412.17318"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimization methods for solving nonlinear PDEs, not on LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10732",
      "abstract": "The most studied and accepted pseudometric for probabilistic processes is one based on the Kantorovich distance between distributions. It comes with many theoretical and motivating results, in particular it is the fixpoint of a given functional and defines a functor on (complete) pseudometric spaces.\n  Other notions of behavioural pseudometrics have also been proposed, one of them ($\\epsilon$-distance) based on $\\epsilon$-bisimulation. $\\epsilon$-Distance has the advantages that it is intuitively easy to understand, it relates systems that are conceptually close (for example, an imperfect implementation is close to its specification), and it comes equipped with a natural notion of $\\epsilon$-coupling. Finally, this distance is easy to compute.\n  We show that $\\epsilon$-distance is also the greatest fixpoint of a functional and provides a functor. The latter is obtained by replacing the Kantorovich distance in the lifting functor with the L\\'evy-Prokhorov distance. In addition, we show that $\\epsilon$-couplings and $\\epsilon$-bisimulations have an appealing coalgebraic characterization.",
      "authors": [
        "Jos\\'ee Desharnais and Ana Sokolova"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:54:51+00:00",
          "link": "https://arxiv.org/abs/2507.10732v1",
          "size": "40kb",
          "version": "v1"
        }
      ],
      "title": "$\\epsilon$-Distance via L\\'evy-Prokhorov Lifting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10732",
        "HTML": "https://arxiv.org/html/2507.10732v1",
        "PDF": "https://arxiv.org/pdf/2507.10732"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses metric spaces and pseudometrics within probabilistic processes and does not address LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10884",
      "abstract": "System inference for nonlinear dynamic models, represented by ordinary differential equations (ODEs), remains a significant challenge in many fields, particularly when the data are noisy, sparse, or partially observable. In this paper, we propose a Simulation-based Generative Model for Imperfect Data (SiGMoID) that enables precise and robust inference for dynamic systems. The proposed approach integrates two key methods: (1) physics-informed neural networks with hyper-networks that constructs an ODE solver, and (2) Wasserstein generative adversarial networks that estimates ODE parameters by effectively capturing noisy data distributions. We demonstrate that SiGMoID quantifies data noise, estimates system parameters, and infers unobserved system components. Its effectiveness is validated validated through realistic experimental examples, showcasing its broad applicability in various domains, from scientific research to engineered systems, and enabling the discovery of full system dynamics.",
      "authors": [
        "Hyunwoo Cho",
        "Hyeontae Jo",
        "Hyung Ju Hwang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Dynamical Systems (math.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T00:56:21+00:00",
          "link": "https://arxiv.org/abs/2507.10884v1",
          "size": "751kb",
          "version": "v1"
        }
      ],
      "title": "Learning from Imperfect Data: Robust Inference of Dynamic Systems using Simulation-based Generative Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10884",
        "HTML": "https://arxiv.org/html/2507.10884v1",
        "PDF": "https://arxiv.org/pdf/2507.10884"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses robust inference in dynamic systems using generative models, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2303.07272",
      "abstract": "State-of-the-art (SOTA) performance refers to the highest performance achieved by some model on a test sample, preferably under controlled conditions such as public data (reproducibility) or public challenges (independent sample). Thousands of classifiers are applied, and the highest performance becomes the new reference point for a particular problem. In effect, this set-up is an estimate of the expected best performance among all classifiers applied to a random sample; a sample maximum estimate. In this paper, we argue that SOTA should instead be estimated by the expected performance of the best classifier, which can be done without knowing which classifier it is.\n  Our contribution is the formal distinction between the two, and an investigation into the practical consequences of using the former to estimate the latter. This is done by presenting sample maximum estimator distributions for non-identical and dependent classifiers. We illustrate the impact on real world examples from public challenges.",
      "authors": [
        "Kajsa M{\\o}llersen and Einar Holsb{\\o}"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-03-10T10:32:18+00:00",
          "link": "https://arxiv.org/abs/2303.07272v1",
          "size": "313kb",
          "version": "v1"
        },
        {
          "date": "2023-04-03T09:28:55+00:00",
          "link": "https://arxiv.org/abs/2303.07272v2",
          "size": "391kb",
          "version": "v2"
        },
        {
          "date": "2023-06-17T11:10:32+00:00",
          "link": "https://arxiv.org/abs/2303.07272v3",
          "size": "429kb",
          "version": "v3"
        },
        {
          "date": "2024-06-05T14:29:27+00:00",
          "link": "https://arxiv.org/abs/2303.07272v4",
          "size": "917kb",
          "version": "v4"
        },
        {
          "date": "2024-09-11T18:38:10+00:00",
          "link": "https://arxiv.org/abs/2303.07272v5",
          "size": "1186kb",
          "version": "v5"
        },
        {
          "date": "2025-07-14T20:05:42+00:00",
          "link": "https://arxiv.org/abs/2303.07272v6",
          "size": "1257kb",
          "version": "v6"
        }
      ],
      "title": "Accounting for multiplicity in machine learning benchmark performance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2303.07272",
        "HTML": "https://arxiv.org/html/2303.07272",
        "PDF": "https://arxiv.org/pdf/2303.07272"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the estimation of state-of-the-art performance for machine learning models and does not involve LLM training data processing or data engineering."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/3inar/ninety-nine"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.06372",
      "abstract": "Sequential recommendation aims to provide users with personalized suggestions based on their historical interactions. When training sequential models, padding is a widely adopted technique for two main reasons: 1) The vast majority of models can only handle fixed-length sequences; 2) Batching-based training needs to ensure that the sequences in each batch have the same length. The special value \\emph{0} is usually used as the padding content, which does not contain the actual information and is ignored in the model calculations. This common-sense padding strategy leads us to a problem that has never been explored before: Can we fully utilize this idle input space by padding other content to further improve model performance and training efficiency?\n  In this work, we propose a simple yet effective padding method called Repeated Padding+ (RepPad+). Specifically, we use the original interaction sequences as the padding content and fill it to the padding positions during model training. This operation can be performed a finite number of times or repeated until the input sequences' length reaches the maximum limit. For those sequences that can not pad full original data, we draw inspiration from the Sliding Windows strategy and intercept consecutive subsequences to fill in the idle space. Our RepPad+ can be viewed as a sequence-level data augmentation strategy. Unlike most existing works, our method contains no trainable parameters or hyperparameters and is a plug-and-play data augmentation operation. Extensive experiments on various categories of sequential models and seven real-world datasets demonstrate the effectiveness and efficiency of our approach. The average recommendation performance improvement is up to 84.11% on GRU4Rec and 35.34% on SASRec. We also provide in-depth analysis and explanation of what makes RepPad+ effective from multiple perspectives.",
      "authors": [
        "Yizhou Dang",
        "Yuting Liu",
        "Enneng Yang",
        "Guibing Guo",
        "Linying Jiang",
        "Jianzhe Zhao",
        "Xingwei Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-11T01:50:41+00:00",
          "link": "https://arxiv.org/abs/2403.06372v1",
          "size": "1885kb",
          "version": "v1"
        },
        {
          "date": "2024-07-30T04:24:05+00:00",
          "link": "https://arxiv.org/abs/2403.06372v2",
          "size": "1956kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T02:45:05+00:00",
          "link": "https://arxiv.org/abs/2403.06372v3",
          "size": "3391kb",
          "version": "v3"
        }
      ],
      "title": "Repeated Padding+: Simple yet Effective Data Augmentation Plugin for Sequential Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.06372",
        "HTML": "https://arxiv.org/html/2403.06372v3",
        "PDF": "https://arxiv.org/pdf/2403.06372"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes Repeated Padding+, a data augmentation technique for sequential recommendation models. Although it involves data processing at a sequence level, this approach is more related to improving model performance in sequential recommendations and does not focus primarily on LLM training data processing."
      },
      "tasks": [
        "Common Sense Reasoning",
        "Data Augmentation",
        "Sequential Recommendation"
      ],
      "repo_urls": [
        "https://github.com/kinggugu/reppad"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.11981",
      "abstract": "This paper addresses the incompatible case of parallel batch scheduling, where compatible jobs belong to the same family, and jobs from different families cannot be processed together in the same batch. The state-of-the-art constraint programming (CP) model for this problem relies on specific functions and global constraints only available in a well established commercial CP solver. This paper expands the literature around this problem by proposing four new CP models that can be implemented in commercial and open-source solvers: a new model that relies on automaton constraints, and three alternative models that integrate assignment and scheduling decisions with different strategies and global constraints. Extensive computational experiments on standard test cases under multiple objectives and multiple solvers demonstrate the implementation flexibility and competitive performance of the proposed models.",
      "authors": [
        "Jorge A. Huertas",
        "Pascal Van Hentenryck"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-15T18:43:27+00:00",
          "link": "https://arxiv.org/abs/2410.11981v1",
          "size": "258kb",
          "version": "v1"
        },
        {
          "date": "2024-12-09T23:06:15+00:00",
          "link": "https://arxiv.org/abs/2410.11981v2",
          "size": "258kb",
          "version": "v2"
        },
        {
          "date": "2025-04-07T01:15:13+00:00",
          "link": "https://arxiv.org/abs/2410.11981v3",
          "size": "816kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T16:11:20+00:00",
          "link": "https://arxiv.org/abs/2410.11981v4",
          "size": "723kb",
          "version": "v4"
        }
      ],
      "title": "Parallel Batch Scheduling With Incompatible Job Families Via Constraint Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.11981",
        "HTML": "https://arxiv.org/html/2410.11981v4",
        "PDF": "https://arxiv.org/pdf/2410.11981"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses parallel batch scheduling using constraint programming, which doesn't involve LLM training data processing or related data engineering tasks."
      },
      "tasks": [
        "Scheduling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.17793",
      "abstract": "Recently, the concept of ``compression as intelligence'' has provided a novel informatics metric perspective for language models (LMs), emphasizing that highly structured representations signify the intelligence level of LMs. However, from a geometric standpoint, the word representation space of highly compressed LMs tends to degenerate into a highly anisotropic state, which hinders the LM's ability to comprehend instructions and directly impacts its performance. We found this compression-anisotropy synchronicity is essentially the ``Compression Hacking'' in LM representations, where noise-dominated directions tend to create the illusion of high compression rates by sacrificing spatial uniformity. Based on this, we propose three refined compression metrics by incorporating geometric distortion analysis and integrate them into a self-evaluation pipeline. The refined metrics exhibit strong alignment with the LM's comprehensive capabilities, achieving Spearman correlation coefficients above 0.9, significantly outperforming both the original compression and other internal structure-based metrics. This confirms that compression hacking substantially enhances the informatics interpretation of LMs by incorporating geometric distortion of representations.",
      "authors": [
        "Jianxiang Zang",
        "Meiling Ning",
        "Yongda Wei",
        "Shihan Dou",
        "Jiazheng Zhang",
        "Nijia Mo",
        "Binhong Li",
        "Tao Gui",
        "Qi Zhang",
        "Xuanjing Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-23T12:11:03+00:00",
          "link": "https://arxiv.org/abs/2505.17793v1",
          "size": "4280kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T10:57:33+00:00",
          "link": "https://arxiv.org/abs/2505.17793v2",
          "size": "481kb",
          "version": "v2"
        }
      ],
      "title": "Compression Hacking: A Supplementary Perspective on Informatics Properties of Language Models from Geometric Distortion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.17793",
        "HTML": "https://arxiv.org/html/2505.17793v2",
        "PDF": "https://arxiv.org/pdf/2505.17793"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes refined compression metrics and self-evaluation for language models but does not focus on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.15249",
      "abstract": "Controlling a robot based on physics-consistent dynamic models, such as Deep Lagrangian Networks (DeLaN), can improve the generalizability and interpretability of the resulting behavior. However, in complex environments, the number of objects to potentially interact with is vast, and their physical properties are often uncertain. This complexity makes it infeasible to employ a single global model. Therefore, we need to resort to online system identification of context-aware models that capture only the currently relevant aspects of the environment. While physical principles such as the conservation of energy may not hold across varying contexts, ensuring physical plausibility for any individual context-aware model can still be highly desirable, particularly when using it for receding horizon control methods such as model predictive control (MPC). Hence, in this work, we extend DeLaN to make it context-aware, combine it with a recurrent network for online system identification, and integrate it with an MPC for adaptive, physics-consistent control. We also combine DeLaN with a residual dynamics model to leverage the fact that a nominal model of the robot is typically available. We evaluate our method on a 7-DOF robot arm for trajectory tracking under varying loads. Our method reduces the end-effector tracking error by 39%, compared to a 21% improvement achieved by a baseline that uses an extended Kalman filter.",
      "authors": [
        "Lucas Schulze",
        "Jan Peters",
        "Oleg Arenz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T08:26:30+00:00",
          "link": "https://arxiv.org/abs/2506.15249v1",
          "size": "2601kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T09:05:34+00:00",
          "link": "https://arxiv.org/abs/2506.15249v2",
          "size": "3088kb",
          "version": "v2"
        }
      ],
      "title": "Context-Aware Deep Lagrangian Networks for Model Predictive Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15249",
        "HTML": "https://arxiv.org/html/2506.15249v2",
        "PDF": "https://arxiv.org/pdf/2506.15249"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on model predictive control and context-aware modeling for robotics, which is unrelated to LLM training data processing or data engineering."
      },
      "tasks": [
        "Model Predictive Control"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10898",
      "abstract": "The growing complexity of cyber threats and the limitations of traditional vulnerability detection tools necessitate novel approaches for securing software systems. We introduce MalCodeAI, a language-agnostic, multi-stage AI pipeline for autonomous code security analysis and remediation. MalCodeAI combines code decomposition and semantic reasoning using fine-tuned Qwen2.5-Coder-3B-Instruct models, optimized through Low-Rank Adaptation (LoRA) within the MLX framework, and delivers scalable, accurate results across 14 programming languages. In Phase 1, the model achieved a validation loss as low as 0.397 for functional decomposition and summarization of code segments after 200 iterations, 6 trainable layers, and a learning rate of 2 x 10^(-5). In Phase 2, for vulnerability detection and remediation, it achieved a best validation loss of 0.199 using the same number of iterations and trainable layers but with an increased learning rate of 4 x 10^(-5), effectively identifying security flaws and suggesting actionable fixes. MalCodeAI supports red-hat-style exploit tracing, CVSS-based risk scoring, and zero-shot generalization to detect complex, zero-day vulnerabilities. In a qualitative evaluation involving 15 developers, the system received high scores in usefulness (mean 8.06/10), interpretability (mean 7.40/10), and readability of outputs (mean 7.53/10), confirming its practical value in real-world development workflows. This work marks a significant advancement toward intelligent, explainable, and developer-centric software security solutions.",
      "authors": [
        "Jugal Gajjar",
        "Kamalasankari Subramaniakuppusamy",
        "and Noha El Kachach"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T01:25:04+00:00",
          "link": "https://arxiv.org/abs/2507.10898v1",
          "size": "323kb",
          "version": "v1"
        }
      ],
      "title": "MalCodeAI: Autonomous Vulnerability Detection and Remediation via Language Agnostic Code Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10898",
        "HTML": "https://arxiv.org/html/2507.10898v1",
        "PDF": "https://arxiv.org/pdf/2507.10898"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on vulnerability detection and remediation in code using a language-agnostic AI pipeline. It does not cover LLM training data processing or any related data engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11212",
      "abstract": "We study the problem of aggregating polygons by covering them with disjoint representative regions, thereby inducing a clustering of the polygons. Our objective is to minimize a weighted sum of the total area and the total perimeter of the regions. This problem has applications in cartographic map generalization and urban analytics. Here, the polygons represent building footprints and the clusters may represent urban areas. Previous approaches forced the boundaries of the regions to come from a fixed subdivision of the plane, which allows the optimal solution (restricted in this way) to be found from a minimum cut in a dual graph. It is natural to ask whether the problem can still be solved efficiently if this restriction is removed, allowing output regions to be bounded by arbitrary curves. We provide a positive answer in the form of a polynomial-time algorithm. Additionally, we fully characterize the optimal solutions by showing that their boundaries are composed of input polygon edges and circular arcs of constant radius. Since some applications favor straight edges, we also study two problem variants in which the output regions must be polygons, but are not restricted to have boundaries from a fixed subdivision. In the first variant, region vertices must lie on the boundaries of the input polygons. The second variant requires them to be vertices of the input polygons. We show that both variants can be approximated up to a constant factor in polynomial time by altering an optimal solution for the unrestricted problem. Our experimental evaluation on real-world building footprints demonstrates that these approximate solutions are visually similar to the optimal unrestricted ones and achieve near-optimal objective values.",
      "authors": [
        "Lotte Blank",
        "David Eppstein",
        "Jan-Henrik Haunert",
        "Herman Haverkort",
        "Benedikt Kolbe",
        "Philip Mayer",
        "Petra Mutzel",
        "Alexander Naumann",
        "Jonas Sauer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T11:29:52+00:00",
          "link": "https://arxiv.org/abs/2507.11212v1",
          "size": "1624kb",
          "version": "v1"
        }
      ],
      "title": "Bicriteria Polygon Aggregation with Arbitrary Shapes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11212",
        "HTML": "https://arxiv.org/html/2507.11212v1",
        "PDF": "https://arxiv.org/pdf/2507.11212"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study addresses polygon aggregation for applications like map generalization, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.04576",
      "abstract": "This paper explores the potential of Physics-Informed Neural Networks (PINNs) to serve as Reduced Order Models (ROMs) for simulating the flow field within stirred tank reactors (STRs). We solve the two-dimensional stationary Navier-Stokes equations within a geometrically intricate domain and explore methodologies that allow us to integrate additional physical insights into the model. These approaches include imposing the Dirichlet boundary conditions (BCs) strongly and employing domain decomposition (DD), with both overlapping and non-overlapping subdomains. We adapt the Extended Physics-Informed Neural Network (XPINN) approach to solve different sets of equations in distinct subdomains based on the diverse flow characteristics present in each region. Our exploration results in a hierarchy of models spanning various levels of complexity, where the best models exhibit l1 prediction errors of less than 1% for both pressure and velocity. To illustrate the reproducibility of our approach, we track the errors over repeated independent training runs of the best identified model and show its reliability. Subsequently, by incorporating the stirring rate as a parametric input, we develop a fast-to-evaluate model of the flow capable of interpolating across a wide range of Reynolds numbers. Although we exclusively restrict ourselves to STRs in this work, we conclude that the steps taken to obtain the presented model hierarchy can be transferred to other applications.",
      "authors": [
        "Veronika Tr\\'avn\\'ikov\\'a",
        "Daniel Wolff",
        "Nico Dirkes",
        "Stefanie Elgeti",
        "Eric von Lieres and Marek Behr"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-07T15:21:53+00:00",
          "link": "https://arxiv.org/abs/2403.04576v1",
          "size": "1654kb",
          "version": "v1"
        }
      ],
      "title": "A Model Hierarchy for Predicting the Flow in Stirred Tanks with Physics-Informed Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.04576",
        "PDF": "https://arxiv.org/pdf/2403.04576"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores Physics-Informed Neural Networks for flow simulation in stirred tank reactors and does not discuss LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.09189",
      "abstract": "Graph neural networks (GNNs) have achieved impressive impressions for graph-related tasks. However, most GNNs are primarily studied under the cases of signal domain with supervised training, which requires abundant task-specific labels and is difficult to transfer to other domains. There are few works focused on domain adaptation for graph node classification. They mainly focused on aligning the feature space of the source and target domains, without considering the feature alignment between different categories, which may lead to confusion of classification in the target domain. However, due to the scarcity of labels of the target domain, we cannot directly perform effective alignment of categories from different domains, which makes the problem more challenging. In this paper, we present the \\textit{Spectral Augmentation for Graph Domain Adaptation (\\method{})} for graph node classification. First, we observe that nodes with the same category in different domains exhibit similar characteristics in the spectral domain, while different classes are quite different. Following the observation, we align the category feature space of different domains in the spectral domain instead of aligning the whole features space, and we theoretical proof the stability of proposed \\method{}. Then, we develop a dual graph convolutional network to jointly exploits local and global consistency for feature aggregation. Last, we utilize a domain classifier with an adversarial learning submodule to facilitate knowledge transfer between different domain graphs. Experimental results on a variety of publicly available datasets reveal the effectiveness of our \\method{}.",
      "authors": [
        "Jinhui Pang",
        "Zixuan Wang",
        "Jiliang Tang",
        "Mingyan Xiao",
        "Nan Yin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-17T13:01:45+00:00",
          "link": "https://arxiv.org/abs/2408.09189v1",
          "size": "5926kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T01:05:21+00:00",
          "link": "https://arxiv.org/abs/2408.09189v2",
          "size": "4953kb",
          "version": "v2"
        }
      ],
      "title": "SA-GDA: Spectral Augmentation for Graph Domain Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.09189",
        "HTML": "https://arxiv.org/html/2408.09189v2",
        "PDF": "https://arxiv.org/pdf/2408.09189"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with graph domain adaptation, primarily focusing on aligning spectral features for node classification tasks, not discussing or contributing to the processing of LLM training data."
      },
      "tasks": [
        "Domain Adaptation",
        "GRAPH DOMAIN ADAPTATION",
        "Node Classification",
        "Transfer Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.12667",
      "abstract": "Current end-to-end autonomous driving methods typically learn only from expert planning data collected from a single ego vehicle, severely limiting the diversity of learnable driving policies and scenarios. However, a critical yet overlooked fact is that in any driving scenario, multiple high-quality trajectories from other vehicles coexist with a specific ego vehicle's trajectory. Existing methods fail to fully exploit this valuable resource, missing important opportunities to improve the models' performance (including long-tail scenarios) through learning from other experts. Intuitively, Jointly learning from both ego and other vehicles' expert data is beneficial for planning tasks. However, this joint learning faces two critical challenges. (1) Different scene observation perspectives across vehicles hinder inter-vehicle alignment of scene feature representations; (2) The absence of partial modality in other vehicles' data (e.g., vehicle states) compared to ego-vehicle data introduces learning bias. To address these challenges, we propose FUMP (Fully Unified Motion Planning), a novel two-stage trajectory generation framework. Building upon probabilistic decomposition, we model the planning task as a specialized subtask of motion prediction. Specifically, our approach decouples trajectory planning into two stages. In Stage 1, a shared decoder jointly generates initial trajectories for both tasks. In Stage 2, the model performs planning-specific refinement conditioned on an ego-vehicle's state. The transition between the two stages is bridged by a state predictor trained exclusively on ego-vehicle data. To address the cross-vehicle discrepancy in observational perspectives, we propose an Equivariant Context-Sharing Adapter (ECSA) before Stage 1 for improving cross-vehicle generalization of scene representations.",
      "authors": [
        "Lin Liu",
        "Caiyan Jia",
        "Ziying Song",
        "Hongyu Pan",
        "Bencheng Liao",
        "Wenchao Sun",
        "Yongchang Zhang",
        "Lei Yang",
        "Yandan Luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-17T05:52:35+00:00",
          "link": "https://arxiv.org/abs/2504.12667v1",
          "size": "25209kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T09:24:20+00:00",
          "link": "https://arxiv.org/abs/2504.12667v2",
          "size": "29507kb",
          "version": "v2"
        }
      ],
      "title": "Fully Unified Motion Planning for End-to-End Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12667",
        "HTML": "https://arxiv.org/html/2504.12667v2",
        "PDF": "https://arxiv.org/pdf/2504.12667"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a motion planning framework for autonomous driving and does not engage with any aspect of processing or engineering LLM training data."
      },
      "tasks": [
        "Autonomous Driving",
        "Bench2Drive"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.01966",
      "abstract": "Deep neural networks employ specialized architectures for vision, sequential and language tasks, yet this proliferation obscures their underlying commonalities. We introduce a unified matrix-order framework that casts convolutional, recurrent and self-attention operations as sparse matrix multiplications. Convolution is realized via an upper-triangular weight matrix performing first-order transformations; recurrence emerges from a lower-triangular matrix encoding stepwise updates; attention arises naturally as a third-order tensor factorization. We prove algebraic isomorphism with standard CNN, RNN and Transformer layers under mild assumptions. Empirical evaluations on image classification (MNIST, CIFAR-10/100, Tiny ImageNet), time-series forecasting (ETTh1, Electricity Load Diagrams) and language modeling/classification (AG News, WikiText-2, Penn Treebank) confirm that sparse-matrix formulations match or exceed native model performance while converging in comparable or fewer epochs. By reducing architecture design to sparse pattern selection, our matrix perspective aligns with GPU parallelism and leverages mature algebraic optimization tools. This work establishes a mathematically rigorous substrate for diverse neural architectures and opens avenues for principled, hardware-aware network design.",
      "authors": [
        "Yuzhou Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-11T06:26:34+00:00",
          "link": "https://arxiv.org/abs/2506.01966v1",
          "size": "86kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T15:48:16+00:00",
          "link": "https://arxiv.org/abs/2506.01966v2",
          "size": "86kb",
          "version": "v2"
        }
      ],
      "title": "Matrix Is All You Need",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01966",
        "HTML": "https://arxiv.org/html/2506.01966v2",
        "PDF": "https://arxiv.org/pdf/2506.01966"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a unified framework for neural network architectures, without addressing any data processing or data engineering related to LLM training data."
      },
      "tasks": [
        "All",
        "image-classification",
        "Image Classification",
        "Language Modeling",
        "Language Modelling",
        "Time Series Forecasting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09313",
      "abstract": "With the growing research focus on multimodal dialogue systems, the capability for proactive interaction is gradually gaining recognition. As an alternative to conventional turn-by-turn dialogue, users increasingly expect multimodal systems to be more initiative, for example, by autonomously determining the timing of multi-turn responses in real time during video playback. To facilitate progress in this emerging area, we introduce ProactiveVideoQA, the first comprehensive benchmark to evaluate a system's ability to engage in proactive interaction. Since model responses are generated at varying timestamps, we further propose PAUC, the first metric that accounts for the temporal dynamics of model responses. This enables a more accurate evaluation of systems operating in proactive settings. Through extensive benchmarking of various baseline systems on ProactiveVideoQA and a user study of human preferences, we show that PAUC is in better agreement with human preferences than traditional evaluation metrics, which typically only consider the textual content of responses. These findings demonstrate that PAUC provides a more faithful assessment of user experience in proactive interaction scenarios. Project homepage: https://github.com/yellow-binary-tree/ProactiveVideoQA",
      "authors": [
        "Yueqian Wang",
        "Xiaojun Meng",
        "Yifan Wang",
        "Huishuai Zhang",
        "Dongyan Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T15:11:50+00:00",
          "link": "https://arxiv.org/abs/2507.09313v1",
          "size": "711kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T11:48:07+00:00",
          "link": "https://arxiv.org/abs/2507.09313v2",
          "size": "711kb",
          "version": "v2"
        }
      ],
      "title": "ProactiveVideoQA: A Comprehensive Benchmark Evaluating Proactive Interactions in Video Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09313",
        "HTML": "https://arxiv.org/html/2507.09313v2",
        "PDF": "https://arxiv.org/pdf/2507.09313"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmark for evaluating proactive interactions in video LLMs but does not involve any processing or engineering of LLM training data itself."
      },
      "datasets": [
        {
          "dataset_name": "wangyueqian/ProactiveVideoQA",
          "downloads": "14",
          "likes": "0",
          "link": "https://huggingface.co/datasets/wangyueqian/ProactiveVideoQA"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.11059",
      "abstract": "The rapid advancement of Large Language Models (LLMs) in software engineering has revealed critical limitations in existing benchmarks, particularly the widely used SWE-bench dataset. Recent studies have uncovered severe data contamination issues, e.g. SWE-bench reports 32.67% of successful patches involve direct solution leakage and 31.08\\% pass due to inadequate test cases. We introduce SWE-MERA, a dynamic, continuously updated benchmark designed to address these fundamental challenges through an automated collection of real-world GitHub issues and rigorous quality validation. Our approach implements a reliable pipeline that ensures quality while minimizing contamination risks, resulting in approximately 10,000 potential tasks with 300 samples currently available. Evaluation using the Aider coding agent demonstrates strong discriminative power in state-of-the-art models. We report performance across a dozen recent LLMs evaluated on tasks collected between September 2024 and June 2025.",
      "authors": [
        "Pavel Adamenko",
        "Mikhail Ivanov",
        "Aidar Valeev",
        "Rodion Levichev",
        "Pavel Zadorozhny",
        "Ivan Lopatin",
        "Dmitry Babayev",
        "Alena Fenogenova",
        "Valentin Malykh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T07:52:33+00:00",
          "link": "https://arxiv.org/abs/2507.11059v1",
          "size": "448kb",
          "version": "v1"
        }
      ],
      "title": "SWE-MERA: A Dynamic Benchmark for Agenticly Evaluating Large Language Models on Software Engineering Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11059",
        "HTML": "https://arxiv.org/html/2507.11059v1",
        "PDF": "https://arxiv.org/pdf/2507.11059"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces SWE-MERA, which involves creating and processing a benchmark dataset with an automated collection and rigorous quality validation, contributing significantly to data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11085",
      "abstract": "Atmospheric structure, represented by backscatter coefficients (BC) recovered from satellite LiDAR attenuated backscatter (ATB), provides a volumetric view of clouds, aerosols, and molecules, playing a critical role in human activities, climate understanding, and extreme weather forecasting. Existing methods often rely on auxiliary inputs and simplified physics-based approximations, and lack a standardized 3D benchmark for fair evaluation. However, such approaches may introduce additional uncertainties and insufficiently capture realistic radiative transfer and atmospheric scattering-absorption effects. To bridge these gaps, we present Atmos-Bench: the first 3D atmospheric benchmark, along with a novel FourCastX: Frequency-enhanced Spatio-Temporal Mixture-of-Experts Network that (a) generates 921,600 image slices from 3D scattering volumes simulated at 532 nm and 355 nm by coupling WRF with an enhanced COSP simulator over 384 land-ocean time steps, yielding high-quality voxel-wise references; (b) embeds ATB-BC physical constraints into the model architecture, promoting energy consistency during restoration; (c) achieves consistent improvements on the Atmos-Bench dataset across both 355 nm and 532 nm bands, outperforming state-of-the-art baseline models without relying on auxiliary inputs. Atmos-Bench establishes a new standard for satellite-based 3D atmospheric structure recovery and paves the way for deeper climate insight.",
      "authors": [
        "Tianchi Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:27:29+00:00",
          "link": "https://arxiv.org/abs/2507.11085v1",
          "size": "17217kb",
          "version": "v1"
        }
      ],
      "title": "Atmos-Bench: 3D Atmospheric Structures for Climate Insight",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11085",
        "HTML": "https://arxiv.org/html/2507.11085v1",
        "PDF": "https://arxiv.org/pdf/2507.11085"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses the development of a 3D atmospheric benchmark (Atmos-Bench) and a new network architecture for atmospheric data, without discussing LLM training data processing methods or improvements."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.08051",
      "abstract": "Many generative applications, such as synthesis-based 3D molecular design, involve constructing compositional objects with continuous features. Here, we introduce Compositional Generative Flows (CGFlow), a novel framework that extends flow matching to generate objects in compositional steps while modeling continuous states. Our key insight is that modeling compositional state transitions can be formulated as a straightforward extension of the flow matching interpolation process. We further build upon the theoretical foundations of generative flow networks (GFlowNets), enabling reward-guided sampling of compositional structures. We apply CGFlow to synthesizable drug design by jointly designing the molecule's synthetic pathway with its 3D binding pose. Our approach achieves state-of-the-art binding affinity on all 15 targets from the LIT-PCBA benchmark, and 5.8$\\times$ improvement in sampling efficiency compared to 2D synthesis-based baseline. To our best knowledge, our method is also the first to achieve state of-art-performance in both Vina Dock (-9.38) and AiZynth success rate (62.2\\%) on the CrossDocked benchmark.",
      "authors": [
        "Tony Shen",
        "Seonghwan Seo",
        "Ross Irwin",
        "Kieran Didi",
        "Simon Olsson",
        "Woo Youn Kim",
        "and Martin Ester"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-10T18:10:34+00:00",
          "link": "https://arxiv.org/abs/2504.08051v1",
          "size": "5682kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T02:54:22+00:00",
          "link": "https://arxiv.org/abs/2504.08051v2",
          "size": "4682kb",
          "version": "v2"
        }
      ],
      "title": "Compositional Flows for 3D Molecule and Synthesis Pathway Co-design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.08051",
        "HTML": "https://arxiv.org/html/2504.08051v2",
        "PDF": "https://arxiv.org/pdf/2504.08051"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for molecular design using generative models, which is unrelated to processing or creating LLM training data."
      },
      "tasks": [
        "Drug Design"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.06935",
      "abstract": "Recent significant advances in integrating multiple Large Language Model (LLM) systems have enabled Agentic Frameworks capable of performing complex tasks autonomously, including novel scientific research. We develop and demonstrate such a framework specifically for the inverse design of photonic metamaterials. When queried with a desired optical spectrum, the Agent autonomously proposes and develops a forward deep learning model, accesses external tools via APIs for tasks like simulation and optimization, utilizes memory, and generates a final design via a deep inverse method. The framework's effectiveness is demonstrated in its ability to automate, reason, plan, and adapt. Notably, the Agentic Framework possesses internal reflection and decision flexibility, permitting highly varied and potentially novel outputs.",
      "authors": [
        "Darui Lu",
        "Jordan M. Malof",
        "and Willie J. Padilla"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Materials Science (cond-mat.mtrl-sci)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-07T22:10:05+00:00",
          "link": "https://arxiv.org/abs/2506.06935v1",
          "size": "9520kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T11:01:25+00:00",
          "link": "https://arxiv.org/abs/2506.06935v2",
          "size": "4691kb",
          "version": "v2"
        }
      ],
      "title": "An Agentic Framework for Autonomous Metamaterial Modeling and Inverse Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.06935",
        "HTML": "https://arxiv.org/html/2506.06935v2",
        "PDF": "https://arxiv.org/pdf/2506.06935"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study involves an Agentic Framework for metamaterial design and does not address LLM training data processing in any form."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10878",
      "abstract": "We study the Shortest-Walk Problem (SWP) in a Graph of Convex Sets (GCS). A GCS is a graph where each vertex is paired with a convex program, and each edge couples adjacent programs via additional costs and constraints. A walk in a GCS is a sequence of vertices connected by edges, where vertices may be repeated. The length of a walk is given by the cumulative optimal value of the corresponding convex programs. To solve the SWP in GCS, we first synthesize a piecewise-quadratic lower bound on the problem's cost-to-go function using semidefinite programming. Then we use this lower bound to guide an incremental-search algorithm that yields an approximate shortest walk. We show that the SWP in GCS is a natural language for many mixed discrete-continuous planning problems in robotics, unifying problems that typically require specialized solutions while delivering high performance and computational efficiency. We demonstrate this through experiments in collision-free motion planning, skill chaining, and optimal control of hybrid systems.",
      "authors": [
        "Savva Morozov",
        "Tobia Marcucci",
        "Bernhard Paus Graesdal",
        "Alexandre Amice",
        "Pablo A. Parrilo",
        "Russ Tedrake"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T00:42:02+00:00",
          "link": "https://arxiv.org/abs/2507.10878v1",
          "size": "3965kb",
          "version": "v1"
        }
      ],
      "title": "Mixed Discrete and Continuous Planning using Shortest Walks in Graphs of Convex Sets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10878",
        "HTML": "https://arxiv.org/html/2507.10878v1",
        "PDF": "https://arxiv.org/pdf/2507.10878"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses mixed discrete and continuous planning problems in robotics, without discussing any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11107",
      "abstract": "The submodular knapsack problem (SKP), which seeks to maximize a submodular set function by selecting a subset of elements within a given budget, is an important discrete optimization problem. The majority of existing approaches to solving the SKP are approximation algorithms. However, in domains such as health-care facility location and risk management, the need for optimal solutions is still critical, necessitating the use of exact algorithms over approximation methods. In this paper, we present an optimal branch-and-bound approach, featuring a novel upper bound with a worst-case tightness guarantee and an efficient dual branching method to minimize repeat computations. Experiments in applications such as facility location, weighted coverage, influence maximization, and so on show that the algorithms that implement the new ideas are far more efficient than conventional methods.",
      "authors": [
        "Yimin Hao",
        "Yi Zhou",
        "Chao Xu",
        "Zhang-Hua Fu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:59:25+00:00",
          "link": "https://arxiv.org/abs/2507.11107v1",
          "size": "337kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Branch-and-Bound for Submodular Function Maximization under Knapsack Constraint",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11107",
        "HTML": "https://arxiv.org/html/2507.11107v1",
        "PDF": "https://arxiv.org/pdf/2507.11107"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces an algorithm for submodular function maximization and does not address LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11500",
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable generative capabilities. However, their susceptibility to misuse has raised significant safety concerns. While post-training safety alignment methods have been widely adopted, LLMs remain vulnerable to malicious instructions that can bypass safety constraints. Recent efforts have introduced inference-time safety reasoning (system-2 alignment), where LLMs conduct a reasoning process to perform safety verification before final response. We show, however, that these checks are driven by ad-hoc reasoning that diverges from the structured human process, where they first discern a user's true intent, then evaluate the associated risk based on the true intent. Consequently, these defenses remain vulnerable to sophisticated jailbreak prompts that cloak harmful goals in seemingly benign language. To build secure and safe LLMs, we propose a reasoning-based safety alignment framework, ARMOR, that replaces the ad-hoc chains of thought reasoning process with human-aligned, structured one. At inference, ARMOR (1) detects likely jailbreak strategies, (2) extracts the user's core intent while discarding deceptive instructions, and (3) applies a policy-grounded safety analysis to the purified request. ARMOR is evaluated on adaptive jailbreak attacks and multiple safety benchmarks, and a test-time scaling is conducted to further improve its performance. Results demonstrate that ARMOR significantly enhances the robustness against state-of-the-art adaptive jailbreak attacks and outperforms recent reasoning-based aligned models across various safety benchmarks.",
      "authors": [
        "Zhengyue Zhao",
        "Yingzi Ma",
        "Somesh Jha",
        "Marco Pavone",
        "Chaowei Xiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T09:05:54+00:00",
          "link": "https://arxiv.org/abs/2507.11500v1",
          "size": "1093kb",
          "version": "v1"
        }
      ],
      "title": "ARMOR: Aligning Secure and Safe Large Language Models via Meticulous Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11500",
        "HTML": "https://arxiv.org/html/2507.11500v1",
        "PDF": "https://arxiv.org/pdf/2507.11500"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a reasoning-based safety alignment framework for LLMs during inference, not related to training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2206.13690",
      "abstract": "Identifying conflicting requirements is a key challenge in software requirement engineering, often overlooked in automated solutions. Most existing approaches rely on handcrafted rules or struggle to generalize across different domains. In this paper, we introduce S3CDA, a two-phase algorithm designed to automatically detect conflicts in software requirements. Our method first identifies potentially conflicting requirement pairs using semantic similarity, and then validates them by analyzing overlapping domain-specific entities. We evaluate S3CDA on five diverse real-world datasets and compare it against popular large language models like GPT-4o, Llama-3, Sonnet-3.5 and Gemini-1.5. While LLMs show promise, especially on general datasets, S3CDA consistently performs better in domain-specific settings with higher performance. Our findings suggest that combining Natural Language Processing (NLP) techniques with domain-aware insights offers a practical and effective alternative for conflict detection in requirements.",
      "authors": [
        "Garima Malik",
        "Mucahit Cevik",
        "Ayse Basar",
        "Devang Parikh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2022-06-28T01:48:12+00:00",
          "link": "https://arxiv.org/abs/2206.13690v1",
          "size": "169kb",
          "version": "v1"
        },
        {
          "date": "2024-03-27T19:21:24+00:00",
          "link": "https://arxiv.org/abs/2206.13690v2",
          "size": "274kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T20:33:00+00:00",
          "link": "https://arxiv.org/abs/2206.13690v3",
          "size": "182kb",
          "version": "v3"
        }
      ],
      "title": "Supervised Semantic Similarity-based Conflict Detection Algorithm: S3CDA",
      "links": {
        "Abstract": "https://arxiv.org/abs/2206.13690",
        "HTML": "https://arxiv.org/html/2206.13690v3",
        "PDF": "https://arxiv.org/pdf/2206.13690"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces S3CDA, an algorithm for detecting conflicts in software requirements, but it does not discuss any contributions related to processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.03956",
      "abstract": "Integrated sensing and communication (ISAC) systems provide significant enhancements in performance and resource efficiency compared to individual sensing and communication systems, primarily attributed to the collaborative use of wireless resources, radio waveforms, and hardware platforms. This paper focuses on the bistatic ISAC systems with dispersed multi-receiver and one sensor. Compared to a monostatic ISAC system, the main challenge in the bistatic setting is that the information messages are unknown to the sensor and therefore they are seen as interference, while the channel between the transmitters (TX) and the sensor is unknown to the transmitters. In order to mitigate the interference at the sensor while maximizing the communication degree of freedom, we introduce two strategies, namely, blind interference alignment and topological interference management. Although well-known in the context of Gaussian interference channels, these strategies are novel in the context of bistatic ISAC. For the bistatic ISAC models with heterogeneous coherence times or with heterogeneous connectivity, the achieved ISAC tradeoff points in terms of communication and sensing degrees of freedom are characterized. In particular, we show that the new tradeoff outperforms the time-sharing between the sensing-only and the communication-only schemes. Simulation results demonstrate that the proposed schemes significantly improve the channel estimation error for the sensing task, compared to treating interference as noise at the sensor and successive interference cancellation.",
      "authors": [
        "Jiayu Liu",
        "Kai Wan",
        "Xinping Yi",
        "Robert Caiming Qiu",
        "Giuseppe Caire"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-05T08:09:06+00:00",
          "link": "https://arxiv.org/abs/2412.03956v1",
          "size": "491kb",
          "version": "v1"
        },
        {
          "date": "2024-12-08T08:34:54+00:00",
          "link": "https://arxiv.org/abs/2412.03956v2",
          "size": "491kb",
          "version": "v2"
        },
        {
          "date": "2025-02-25T02:50:03+00:00",
          "link": "https://arxiv.org/abs/2412.03956v3",
          "size": "1111kb",
          "version": "v3"
        },
        {
          "date": "2025-02-26T01:44:33+00:00",
          "link": "https://arxiv.org/abs/2412.03956v4",
          "size": "1111kb",
          "version": "v4"
        },
        {
          "date": "2025-07-15T08:08:55+00:00",
          "link": "https://arxiv.org/abs/2412.03956v5",
          "size": "868kb",
          "version": "v5"
        }
      ],
      "title": "Blind and Topological Interference Managements for Bistatic Integrated Sensing and Communication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.03956",
        "HTML": "https://arxiv.org/html/2412.03956v5",
        "PDF": "https://arxiv.org/pdf/2412.03956"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses interference management in integrated sensing and communication systems, which is unrelated to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07722",
      "abstract": "Recent works have revisited the infamous task ``Name That Dataset'', demonstrating that non-medical datasets contain underlying biases and that the dataset origin task can be solved with high accuracy. In this work, we revisit the same task applied to popular open-source chest X-ray datasets. Medical images are naturally more difficult to release for open-source due to their sensitive nature, which has led to certain open-source datasets being extremely popular for research purposes. By performing the same task, we wish to explore whether dataset bias also exists in these datasets. To extend our work, we apply simple transformations to the datasets, repeat the same task, and perform an analysis to identify and explain any detected biases. Given the importance of AI applications in medical imaging, it's vital to establish whether modern methods are taking shortcuts or are focused on the relevant pathology. We implement a range of different network architectures on the datasets: NIH, CheXpert, MIMIC-CXR and PadChest. We hope this work will encourage more explainable research being performed in medical imaging and the creation of more open-source datasets in the medical domain. Our code can be found here: https://github.com/eedack01/x_ray_ds_bias.",
      "authors": [
        "Ethan Dack",
        "Chengliang Dai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T12:57:09+00:00",
          "link": "https://arxiv.org/abs/2507.07722v1",
          "size": "999kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T09:22:21+00:00",
          "link": "https://arxiv.org/abs/2507.07722v2",
          "size": "1013kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T15:14:02+00:00",
          "link": "https://arxiv.org/abs/2507.07722v3",
          "size": "1014kb",
          "version": "v3"
        }
      ],
      "title": "Understanding Dataset Bias in Medical Imaging: A Case Study on Chest X-rays",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07722",
        "HTML": "https://arxiv.org/html/2507.07722v3",
        "PDF": "https://arxiv.org/pdf/2507.07722"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses dataset bias in medical imaging and does not mention LLM training data processing or engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11006",
      "abstract": "This study presents an advanced approach to enhance robotic manipulation in uncertain and challenging environments, with a focus on autonomous operations augmented by human-in-the-loop (HITL) control for lunar missions. By integrating human decision-making with autonomous robotic functions, the research improves task reliability and efficiency for space applications. The key task addressed is the autonomous deployment of flexible solar panels using an extendable ladder-like structure and a robotic manipulator with real-time feedback for precision. The manipulator relays position and force-torque data, enabling dynamic error detection and adaptive control during deployment. To mitigate the effects of sinkage, variable payload, and low-lighting conditions, efficient motion planning strategies are employed, supplemented by human control that allows operators to intervene in ambiguous scenarios. Digital twin simulation enhances system robustness by enabling continuous feedback, iterative task refinement, and seamless integration with the deployment pipeline. The system has been tested to validate its performance in simulated lunar conditions and ensure reliability in extreme lighting, variable terrain, changing payloads, and sensor limitations.",
      "authors": [
        "Ashutosh Mishra",
        "Shreya Santra",
        "Hazal Gozbasi",
        "Kentaro Uno",
        "and Kazuya Yoshida"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T05:53:12+00:00",
          "link": "https://arxiv.org/abs/2507.11006v1",
          "size": "28560kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Autonomous Manipulator Control with Human-in-loop for Uncertain Assembly Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11006",
        "HTML": "https://arxiv.org/html/2507.11006v1",
        "PDF": "https://arxiv.org/pdf/2507.11006"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses enhancing robotic manipulation with human-in-loop control for space missions, without any mention of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11509",
      "abstract": "A major open question in algorithmic game theory is whether normal-form correlated equilibria (NFCE) can be computed efficiently in succinct games such as extensive-form games [DFF+25,6PR24,FP23,HvS08,VSF08,PR08]. Motivated by this question, we study the associated Threshold problem: deciding whether there exists a correlated equilibrium whose value exceeds a given threshold. We prove that this problem is PSPACE-hard for NFCE in multiplayer extensive-form games with perfect recall, even for fixed thresholds. To contextualize this result, we also establish the complexity of the Threshold problem for Nash equilibria in this setting, showing it is ER-complete. These results uncover a surprising complexity reversal: while optimal correlated equilibria are computationally simpler than optimal Nash in normal-form games, the opposite holds in extensive-form games, where computing optimal correlated equilibria is provably harder. Building on this line of inquiry, we also address a related question by [VSF08], who introduced the notions of extensive-form correlated equilibrium (EFCE) and agent-form correlated equilibrium (AFCE). They asked how difficult the Threshold problem is for AFCE; we answer this question by proving that it is NP-hard, even in two-player games without chance nodes. Complementing our hardness results, we establish tight complexity classifications for the Threshold problem across several correlated equilibrium concepts - including EFCE, AFCE, normal-form coarse, extensive-form coarse, and agent-form coarse correlated equilibria. For each of these solution concepts in multiplayer stochastic extensive-form games with perfect recall, we prove NP-completeness by providing matching NP upper bounds to the previously known hardness results. Together, our results provide the most complete landscape to date for the complexity of optimal equilibrium computation in extensive-form games.",
      "authors": [
        "Vincent Cheval and Florian Horn and Soumyajit Paul and Mahsa Shirmohammadi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:24:16+00:00",
          "link": "https://arxiv.org/abs/2507.11509v1",
          "size": "71kb",
          "version": "v1"
        }
      ],
      "title": "On the Complexity of the Optimal Correlated Equilibria in Extensive-Form Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11509",
        "PDF": "https://arxiv.org/pdf/2507.11509"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses game theory and the complexity of computing equilibria in extensive-form games, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.09241",
      "abstract": "We present the design, development, and experimental validation of BlueME, a compact magnetoelectric (ME) antenna array system for underwater robot-to-robot communication. BlueME employs ME antennas operating at their natural mechanical resonance frequency to efficiently transmit and receive very-low-frequency (VLF) electromagnetic signals underwater. We outline the design, simulation, fabrication, and integration of the proposed system on low-power embedded platforms focusing on portable and scalable applications. For performance evaluation, we deployed BlueME on an autonomous surface vehicle (ASV) and a remotely operated vehicle (ROV) in open-water field trials. Our tests demonstrate that BlueME maintains reliable signal transmission at distances beyond 200 meters while consuming only 1 watt of power. Field trials show that the system operates effectively in challenging underwater conditions such as turbidity, obstacles, and multipath interference -- that generally affect acoustics and optics. Our analysis also examines the impact of complete submersion on system performance and identifies key deployment considerations. This work represents the first practical underwater deployment of ME antennas outside the laboratory, and implements the largest VLF ME array system to date. BlueME demonstrates significant potential for marine robotics and automation in multi-robot cooperative systems and remote sensor networks.",
      "authors": [
        "Mehron Talebi",
        "Sultan Mahmud",
        "Adam Khalifa",
        "and Md Jahidul Islam"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-14T07:15:24+00:00",
          "link": "https://arxiv.org/abs/2411.09241v1",
          "size": "7674kb",
          "version": "v1"
        },
        {
          "date": "2024-12-28T05:59:31+00:00",
          "link": "https://arxiv.org/abs/2411.09241v2",
          "size": "7939kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T06:00:55+00:00",
          "link": "https://arxiv.org/abs/2411.09241v3",
          "size": "9687kb",
          "version": "v3"
        }
      ],
      "title": "BlueME: Robust Underwater Robot-to-Robot Communication Using Compact Magnetoelectric Antennas",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.09241",
        "HTML": "https://arxiv.org/html/2411.09241v3",
        "PDF": "https://arxiv.org/pdf/2411.09241"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on underwater communication systems, which is not relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.04526",
      "abstract": "Crack detection on road surfaces is a critical measurement technology in the instrumentation domain, essential for ensuring infrastructure safety and transportation reliability. However, due to limited energy and low-resolution imaging, smart terminal devices struggle to maintain real-time monitoring performance. To overcome these challenges, this paper proposes a multi-stage detection approach for road crack detection, EECD-Net, to enhance accuracy and energy efficiency of instrumentation. Specifically, the sophisticated Super-Resolution Convolutional Neural Network (SRCNN) is employed to address the inherent challenges of low-quality images, which effectively enhance image resolution while preserving critical structural details. Meanwhile, a Spike Convolution Unit (SCU) with Continuous Integrate-and-Fire (CIF) neurons is proposed to convert these images into sparse pulse sequences, significantly reducing power consumption. Additionally, a Gated Attention Transformer (GAT) module is designed to strategically fuse multi-scale feature representations through adaptive attention mechanisms, effectively capturing both long-range dependencies and intricate local crack patterns, and significantly enhancing detection robustness across varying crack morphologies. The experiments on the CrackVision12K benchmark demonstrate that EECD-Net achieves a remarkable 98.6\\% detection accuracy, surpassing state-of-the-art counterparts such as Hybrid-Segmentor by a significant 1.5\\%. Notably, the EECD-Net maintains exceptional energy efficiency, consuming merely 5.6 mJ, which is a substantial 33\\% reduction compared to baseline implementations. This work pioneers a transformative approach in instrumentation-based crack detection, offering a scalable, low-power solution for real-time, large-scale infrastructure monitoring in resource-constrained environments.",
      "authors": [
        "Shuo Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-05T00:19:36+00:00",
          "link": "https://arxiv.org/abs/2506.04526v1",
          "size": "1080kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T11:59:57+00:00",
          "link": "https://arxiv.org/abs/2506.04526v2",
          "size": "0kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T08:13:54+00:00",
          "link": "https://arxiv.org/abs/2506.04526v3",
          "size": "0kb",
          "version": "v3"
        }
      ],
      "title": "EECD-Net: Energy-Efficient Crack Detection with Spiking Neural Networks and Gated Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04526",
        "PDF": "https://arxiv.org/pdf/2506.04526"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on energy-efficient crack detection using new neural network architectures and does not discuss LLM training data processing."
      },
      "tasks": [
        "Super-Resolution"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.21095",
      "abstract": "Federated Learning (FL) enables collaborative model training across multiple clients without sharing clients' private data. However, fairness remains a key concern, as biases in local clients' datasets can impact the entire federated system. Heterogeneous data distributions across clients may lead to models that are fairer for some clients than others. Although several fairness-enhancing solutions are present in the literature, most focus on mitigating bias for a single sensitive attribute, typically binary, overlooking the diverse and sometimes conflicting fairness needs of different clients. This limited perspective can limit the effectiveness of fairness interventions for the different clients. To support more robust and reproducible fairness research in FL, we aim to enable a consistent benchmarking of fairness-aware FL methods at both the global and client levels. In this paper, we contribute in three ways: (1) We introduce FeDa4Fair, a library to generate tabular datasets tailored to evaluating fair FL methods under heterogeneous client bias; (2) we release four bias-heterogeneous datasets and corresponding benchmarks to compare fairness mitigation methods in a controlled environment; (3) we provide ready-to-use functions for evaluating fairness outcomes for these datasets.",
      "authors": [
        "Xenia Heilmann",
        "Luca Corbucci",
        "Mattia Cerrato",
        "Anna Monreale"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T08:43:12+00:00",
          "link": "https://arxiv.org/abs/2506.21095v1",
          "size": "474kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T13:22:28+00:00",
          "link": "https://arxiv.org/abs/2506.21095v2",
          "size": "474kb",
          "version": "v2"
        }
      ],
      "title": "FeDa4Fair: Client-Level Federated Datasets for Fairness Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21095",
        "HTML": "https://arxiv.org/html/2506.21095v2",
        "PDF": "https://arxiv.org/pdf/2506.21095"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The introduction of FeDa4Fair provides datasets for fairness evaluation in federated learning, involving data tailoring but not specifically for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10629",
      "abstract": "Transforming natural language into SQL queries (NL2SQL) is crucial for data-driven business applications. Existing frameworks, trained on open-source datasets, struggle with complex business logic and lack domain-specific data for fine-tuning. Additionally, evaluation methods often require annotated data and executable database environments, which are scarce in real-world scenarios. To address these challenges, we propose SQLord, an enterprise-level NL2SQL framework. First, SQLord introduces a data reverse generation approach to convert raw SQL statements into annotated data for supervised fine-tuning (SFT). Second, it proposes a decomposition method for complex queries using an automated workflow generator. Additionally, SQLord features a comprehensive GPT-Judge evaluation framework, including Execution Evaluation (EXE), Query-SQL Evaluation (QSE), and SQL-SQL Evaluation (SSE), tailored to diverse scenarios. Offline tests significantly outperform state of the art baselines, and online accuracy consistently exceeds 90, highlighting SQLord's advantages and effectiveness in complex real world scenarios. SQLord has been successfully applied across multiple scenarios on the world's largest B2B e-commerce platform.",
      "authors": [
        "Song Cheng",
        "Qiannan Cheng",
        "Linbo Jin",
        "Lei Yi",
        "Guannan Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:16:55+00:00",
          "link": "https://arxiv.org/abs/2507.10629v1",
          "size": "4905kb",
          "version": "v1"
        }
      ],
      "title": "SQLord: A Robust Enterprise Text-to-SQL Solution via Reverse Data Generation and Workflow Decomposition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10629",
        "HTML": "https://arxiv.org/html/2507.10629v1",
        "PDF": "https://arxiv.org/pdf/2507.10629"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces SQLord, which involves reverse data generation and data processing methods (e.g., decomposing complex queries) to create a dataset for fine-tuning in NL2SQL tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10747",
      "abstract": "In this paper, we introduce a benchmarking framework within the open-source NVIDIA PhysicsNeMo-CFD framework designed to systematically assess the accuracy, performance, scalability, and generalization capabilities of AI models for automotive aerodynamics predictions. The open extensible framework enables incorporation of a diverse set of metrics relevant to the Computer-Aided Engineering (CAE) community. By providing a standardized methodology for comparing AI models, the framework enhances transparency and consistency in performance assessment, with the overarching goal of improving the understanding and development of these models to accelerate research and innovation in the field. To demonstrate its utility, the framework includes evaluation of both surface and volumetric flow field predictions on three AI models: DoMINO, X-MeshGraphNet, and FIGConvNet using the DrivAerML dataset. It also includes guidelines for integrating additional models and datasets, making it extensible for physically consistent metrics. This benchmarking study aims to enable researchers and industry professionals in selecting, refining, and advancing AI-driven aerodynamic modeling approaches, ultimately fostering the development of more efficient, accurate, and interpretable solutions in automotive aerodynamics",
      "authors": [
        "Kaustubh Tangsali",
        "Rishikesh Ranade",
        "Mohammad Amin Nabian",
        "Alexey Kamenev",
        "Peter Sharpe",
        "Neil Ashton",
        "Ram Cherukuri",
        "and Sanjay Choudhry"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:13:43+00:00",
          "link": "https://arxiv.org/abs/2507.10747v1",
          "size": "16546kb",
          "version": "v1"
        }
      ],
      "title": "A Benchmarking Framework for AI models in Automotive Aerodynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10747",
        "HTML": "https://arxiv.org/html/2507.10747v1",
        "PDF": "https://arxiv.org/pdf/2507.10747"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a benchmarking framework for AI models in automotive aerodynamics, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10770",
      "abstract": "The extraction and matching of interest points are fundamental to many geometric computer vision tasks. Traditionally, matching is performed by assigning descriptors to interest points and identifying correspondences based on descriptor similarity. This work introduces a technique where interest points are inherently associated during detection, eliminating the need for computing, storing, transmitting, or matching descriptors. Although the matching accuracy is marginally lower than that of conventional approaches, our method completely eliminates the need for descriptors, leading to a drastic reduction in memory usage for localization systems. We assess its effectiveness by comparing it against both classical handcrafted methods and modern learned approaches.",
      "authors": [
        "Ionu\\c{t} Grigore",
        "C\\u{a}lin-Adrian Popa",
        "Claudiu Leoveanu-Condrei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:52:24+00:00",
          "link": "https://arxiv.org/abs/2507.10770v1",
          "size": "2695kb",
          "version": "v1"
        }
      ],
      "title": "FPC-Net: Revisiting SuperPoint with Descriptor-Free Keypoint Detection via Feature Pyramids and Consistency-Based Implicit Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10770",
        "HTML": "https://arxiv.org/html/2507.10770v1",
        "PDF": "https://arxiv.org/pdf/2507.10770"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a technique for keypoint detection in computer vision, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11250",
      "abstract": "Time-Sensitive Networking (TSN) is increasingly adopted in industrial systems to meet strict latency, jitter, and reliability requirements. However, evaluating TSN's fault tolerance under realistic failure conditions remains challenging. This paper presents IN2C, a modular OMNeT++/INET-based simulation framework that models two synchronized production cells connected to centralized infrastructure. IN2C integrates core TSN features, including time synchronization, traffic shaping, per-stream filtering, and Frame Replication and Elimination for Redundancy (FRER), alongside XML-driven fault injection for link and node failures. Four fault scenarios are evaluated to compare TSN performance with and without redundancy. Results show that FRER eliminates packet loss and achieves submillisecond recovery, though with 2-3x higher link utilization. These findings offer practical guidance for deploying TSN in bandwidth-constrained industrial environments.",
      "authors": [
        "Mohamed Seliem",
        "Dirk Pesch",
        "Utz Roedig",
        "and Cormac Sreenan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:23:19+00:00",
          "link": "https://arxiv.org/abs/2507.11250v1",
          "size": "3046kb",
          "version": "v1"
        }
      ],
      "title": "Resilient Time-Sensitive Networking for Industrial IoT: Configuration and Fault-Tolerance Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11250",
        "HTML": "https://arxiv.org/html/2507.11250v1",
        "PDF": "https://arxiv.org/pdf/2507.11250"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about networking and fault tolerance evaluation in industrial IoT, which does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11436",
      "abstract": "Activation functions are critical to the performance of deep neural networks, particularly in domains such as functional near-infrared spectroscopy (fNIRS), where nonlinearity, low signal-to-noise ratio (SNR), and signal variability poses significant challenges to model accuracy. However, the impact of activation functions on deep learning (DL) performance in the fNIRS domain remains underexplored and lacks systematic investigation in the current literature. This study evaluates a range of conventional and field-specific activation functions for fNIRS classification tasks using multiple deep learning architectures, including the domain-specific fNIRSNet, AbsoluteNet, MDNN, and shallowConvNet (as the baseline), all tested on a single dataset recorded during an auditory task. To ensure fair a comparison, all networks were trained and tested using standardized preprocessing and consistent training parameters. The results show that symmetrical activation functions such as Tanh and the Absolute value function Abs(x) can outperform commonly used functions like the Rectified Linear Unit (ReLU), depending on the architecture. Additionally, a focused analysis of the role of symmetry was conducted using a Modified Absolute Function (MAF), with results further supporting the effectiveness of symmetrical activation functions on performance gains. These findings underscore the importance of selecting proper activation functions that align with the signal characteristics of fNIRS data.",
      "authors": [
        "Behtom Adeli and John McLinden and Pankaj Pandey and Ming Shao and Yalda Shahriari"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:58:36+00:00",
          "link": "https://arxiv.org/abs/2507.11436v1",
          "size": "77kb",
          "version": "v1"
        }
      ],
      "title": "Toward Improving fNIRS Classification: A Study on Activation Functions in Deep Neural Architectures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11436",
        "HTML": "https://arxiv.org/html/2507.11436v1",
        "PDF": "https://arxiv.org/pdf/2507.11436"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on activation functions' impact on deep learning architectures for fNIRS classification, not on any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.17180",
      "abstract": "Control invariant sets are crucial for various methods that aim to design safe control policies for systems whose state constraints must be satisfied over an indefinite time horizon. In this article, we explore the connections among reachability, control invariance, and Control Barrier Functions (CBFs). Unlike prior formulations based on backward reachability concepts, we establish a strong link between these three concepts by examining the inevitable Forward Reachable Tube (FRT), which is the set of states such that every trajectory reaching the FRT must have passed through a given initial set of states. First, our findings show that the inevitable FRT is precisely this initial set itself if it is a robust control invariant set with a differentiable boundary-a property necessary to connect with CBFs whose zero-level sets are control invariant. We highlight that if the boundary is not differentiable, the FRT of the robust control invariant set may become a strict superset of the invariant set and lose invariance. Next, we formulate a differential game between the control and disturbance, where the inevitable FRT is characterized by the zero-superlevel set of the value function. By incorporating a discount factor in the cost function of the game, the barrier constraint of the CBF naturally arises in the Hamilton-Jacobi equation and determines the optimal policy. Combining these results, the value function of our FRT formulation serves as a CBF-like function, and conversely, any valid CBF is also a forward reachability value function inside the control invariant set, thereby revealing the inverse optimality of the CBF. This strong link between reachability and barrier constraints is not achievable by previous backward reachability-based formulations, and addresses an important gap in existing literature for constructing valid CBFs to ensure safety.",
      "authors": [
        "Jason J. Choi",
        "Donggun Lee",
        "Boyang Li",
        "Jonathan P. How",
        "Koushil Sreenath",
        "Sylvia L. Herbert",
        "Claire J. Tomlin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-26T06:09:40+00:00",
          "link": "https://arxiv.org/abs/2310.17180v1",
          "size": "2165kb",
          "version": "v1"
        },
        {
          "date": "2024-07-28T20:05:29+00:00",
          "link": "https://arxiv.org/abs/2310.17180v2",
          "size": "1915kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T16:31:13+00:00",
          "link": "https://arxiv.org/abs/2310.17180v3",
          "size": "1396kb",
          "version": "v3"
        }
      ],
      "title": "A Forward Reachability Perspective on Control Barrier Functions and Discount Factors in Reachability Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.17180",
        "HTML": "https://arxiv.org/html/2310.17180v3",
        "PDF": "https://arxiv.org/pdf/2310.17180"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses control invariant sets and reachability analysis in control systems but does not relate to LLM training data processing or dataset creation."
      },
      "tasks": [
        "valid"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.08495",
      "abstract": "Classical data can be copied and re-used for computation, with adverse consequences economically and in terms of data privacy. Motivated by this, we formulate problems in one-way communication complexity where Alice holds some data $x$ and Bob holds $m$ inputs $y_1,... , y_m$. They want to compute $m$ instances of a bipartite relation $R$ on every pair $(x, y_1),\\ldots, (x, y_m)$. We call this the asymmetric direct sum question for one-way communication. We give a number of examples where the quantum communication complexity of such problems scales polynomially with $m$, while the classical communication complexity depends at most logarithmically on $m$. Thus, for such problems, data behaves like a consumable resource that is effectively destroyed upon use when the owner stores and transmits it as quantum states, but not when transmitted classically. We show an application to a strategic data-selling game, and discuss other potential economic implications.",
      "authors": [
        "Dar Gilboa",
        "Siddhartha Jain and Jarrod R. McClean"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-13T02:42:29+00:00",
          "link": "https://arxiv.org/abs/2409.08495v1",
          "size": "37kb",
          "version": "v1"
        },
        {
          "date": "2024-09-16T02:09:23+00:00",
          "link": "https://arxiv.org/abs/2409.08495v2",
          "size": "37kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T01:18:49+00:00",
          "link": "https://arxiv.org/abs/2409.08495v3",
          "size": "40kb",
          "version": "v3"
        }
      ],
      "title": "Consumable Data via Quantum Communication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.08495",
        "HTML": "https://arxiv.org/html/2409.08495v3",
        "PDF": "https://arxiv.org/pdf/2409.08495"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered around quantum communication complexity and economic implications, without discussing LLM training data or data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.18675",
      "abstract": "Multi-head self-attention (MHSA) is a key component of Transformers, a widely popular architecture in both language and vision. Multiple heads intuitively enable different parallel processes over the same input. Yet, they also obscure the attribution of each input patch to the output of a model. We propose a novel 1-head Transformer Attention Bottleneck (TAB) layer, inserted after the traditional MHSA architecture, to serve as an attention bottleneck for interpretability and intervention. Unlike standard self-attention, TAB constrains the total attention over all patches to $\\in [0, 1]$. That is, when the total attention is 0, no visual information is propagated further into the network, and the vision-language model (VLM) would default to a generic, image-independent response. To demonstrate the advantages of TAB, we train VLMs with TAB to perform image-difference captioning. Over three datasets, our models perform similarly to baseline VLMs in captioning but the bottleneck is superior in localizing changes and in identifying when no changes occur. TAB is the first architecture to enable users to debug by editing attention, which often produces expected outputs by VLMs.",
      "authors": [
        "Pooyan Rahmanzadehgervi and Hung Huy Nguyen and Rosanne Liu and Long Mai and Anh Totti Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-24T20:28:07+00:00",
          "link": "https://arxiv.org/abs/2412.18675v1",
          "size": "23674kb",
          "version": "v1"
        },
        {
          "date": "2025-01-03T14:58:50+00:00",
          "link": "https://arxiv.org/abs/2412.18675v2",
          "size": "23672kb",
          "version": "v2"
        },
        {
          "date": "2025-01-21T15:16:59+00:00",
          "link": "https://arxiv.org/abs/2412.18675v3",
          "size": "23672kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T21:28:12+00:00",
          "link": "https://arxiv.org/abs/2412.18675v4",
          "size": "11019kb",
          "version": "v4"
        }
      ],
      "title": "TAB: Transformer Attention Bottlenecks enable User Intervention and Debugging in Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.18675",
        "HTML": "https://arxiv.org/html/2412.18675v4",
        "PDF": "https://arxiv.org/pdf/2412.18675"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for enhancing vision-language models' interpretability through Transformer attention bottleneck layers, without any focus on LLM training data processing."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "repo_urls": [
        "https://github.com/anguyen8/TAB"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.19780",
      "abstract": "While large language models (LLMs) excel at text generation, aligning them with human preferences remains challenging. Reinforcement learning from human feedback (RLHF) improves alignment but is costly and unstable. Direct Preference Optimization (DPO) offers a simpler alternative, yet assumes a fixed, single-dimensional preference. We propose Multi-Preference Lambda-weighted Listwise DPO, a generalization of DPO that supports multiple preference dimensions and dynamic interpolation via a simplex-weighted lambda vector. Our method enables listwise supervision and flexible alignment without re-training. While our experiments are conducted on 1B-2B scale models, this is an intentional choice: smaller models provide a more stringent testbed where performance improvements more clearly reflect the effectiveness of the alignment strategy itself. Moreover, such models are widely used in compute-constrained applications, making our improvements both methodologically meaningful and practically valuable. Empirical results show that our approach matches or surpasses standard DPO on alignment benchmarks while offering improved adaptability.",
      "authors": [
        "Yuhui Sun (University of Alberta)",
        "Xiyao Wang (University of Toronto)",
        "Zixi Li (Zhejiang University)",
        "Zhenlong Yuan (Institute of Computing Technology",
        "Chinese Academy of Sciences)",
        "and Jinman Zhao (University of Toronto)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T16:47:17+00:00",
          "link": "https://arxiv.org/abs/2506.19780v1",
          "size": "26kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T17:28:25+00:00",
          "link": "https://arxiv.org/abs/2506.19780v2",
          "size": "27kb",
          "version": "v2"
        },
        {
          "date": "2025-07-05T19:14:28+00:00",
          "link": "https://arxiv.org/abs/2506.19780v3",
          "size": "306kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T18:17:04+00:00",
          "link": "https://arxiv.org/abs/2506.19780v4",
          "size": "506kb",
          "version": "v4"
        }
      ],
      "title": "Multi-Preference Lambda-weighted Listwise DPO for Dynamic Preference Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19780",
        "HTML": "https://arxiv.org/html/2506.19780v4",
        "PDF": "https://arxiv.org/pdf/2506.19780"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses alignment in LLMs through preference optimization but does not discuss training data processing or engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09607",
      "abstract": "Private inference based on Secure Multi-Party Computation (MPC) addresses data privacy risks in Machine Learning as a Service (MLaaS). However, existing MPC-based private inference frameworks focuses on semi-honest or honest majority models, whose threat models are overly idealistic, while malicious security dishonest majority models face the challenge of low efficiency. To balance security and efficiency, we propose a private inference framework using Helper-Assisted Malicious Security Dishonest Majority Model (HA-MSDM). This framework includes our designed five MPC protocols and a co-optimized strategy. These protocols achieve efficient fixed-round multiplication, exponentiation, and polynomial operations, providing foundational primitives for private inference. The co-optimized strategy balances inference efficiency and accuracy. To enhance efficiency, we employ polynomial approximation for nonlinear layers. For improved accuracy, we construct sixth-order polynomial approximation within a fixed interval to achieve high-precision activation function fitting and introduce parameter-adjusted batch normalization layers to constrain the activation escape problem. Benchmark results on LeNet and AlexNet show our framework achieves 2.4-25.7x speedup in LAN and 1.3-9.5x acceleration in WAN compared to state-of-the-art frameworks (IEEE S&P'25), maintaining high accuracy with only 0.04%-1.08% relative errors.",
      "authors": [
        "Kaiwen Wang",
        "Yuehan Dong",
        "Junchao Fan",
        "Xiaolin Chang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T12:24:02+00:00",
          "link": "https://arxiv.org/abs/2507.09607v1",
          "size": "1112kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T11:31:05+00:00",
          "link": "https://arxiv.org/abs/2507.09607v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "Efficient Private Inference Based on Helper-Assisted Malicious Security Dishonest Majority MPC",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09607",
        "PDF": "https://arxiv.org/pdf/2507.09607"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses private inference within multi-party computation frameworks and optimization for ML models, without relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11242",
      "abstract": "Extropy, a complementary dual of entropy, (proposed by Lad et al. \\cite{lad2015extropy} in 2015) has attracted considerable interest from the research community. In this study, we focus on discrete random variables and define conditional extropy, establishing key properties of joint and conditional extropy such as bounds, uncertainty reduction due to additional information, and Lipschitz continuity. We further introduce the concept of extropy rate for a stochastic process of discrete random variables as a measure of the average uncertainty per random variable within the process. It is observed that for infinite stationary and ergodic stochastic processes, as well as for identically and independently distributed sequences, the extropy rate exhibits asymptotic equivalence. We explore the extropy rate for finite stochastic processes and numerically illustrate its effectiveness in capturing the underlying information across various distributions, quantifying complexity in time series data, and characterizing chaotic dynamics in dynamical systems. The behaviour of estimated extropy rate is observed to be closely aligned with Simpson's diversity index. The real-life applicability of the extropy rate is presented through a novel feature selection method based on the fact that features with higher extropy rates contain greater inherent information. Using six publicly available datasets, we show the superiority of the proposed feature selection method over some other existing popular approaches.",
      "authors": [
        "Naveen Kumar and Vivek Vijay"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:16:27+00:00",
          "link": "https://arxiv.org/abs/2507.11242v1",
          "size": "3574kb",
          "version": "v1"
        }
      ],
      "title": "Extropy Rate: Properties and Application in Feature Selection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11242",
        "HTML": "https://arxiv.org/html/2507.11242v1",
        "PDF": "https://arxiv.org/pdf/2507.11242"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses extropy rate and feature selection, focusing on stochastic processes and not on LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.02380",
      "abstract": "Large Language Models (LLMs) demonstrate exceptional performance across various tasks, but their large storage and computational requirements constrain their deployment on edge devices. To address this, we propose EntroLLM, a novel compression framework that integrates mixed quantization with entropy coding to reduce storage overhead while maintaining model accuracy. Our method applies a layer-wise mixed quantization scheme - choosing between symmetric and asymmetric quantization based on individual layer weight distributions - to optimize compressibility. We then employ Huffman encoding for lossless compression of the quantized weights, significantly reducing memory bandwidth requirements. Furthermore, we introduce parallel Huffman decoding, which enables efficient retrieval of encoded weights during inference, ensuring minimal latency impact. Our experiments on edge-compatible LLMs, including smolLM-1.7B-Instruct, phi3-mini-4k-Instruct, and mistral-7B-Instruct, demonstrate that EntroLLM achieves up to $30\\%$ storage reduction compared to uint8 models and up to $65%$ storage reduction compared to uint4 models, while preserving perplexity and accuracy, on language benchmark tasks. We further show that our method enables $31.9\\%$ - $146.6\\%$ faster inference throughput on memory-bandwidth-limited edge devices, such as NVIDIA Jetson P3450, by reducing the required data movement. The proposed approach requires no additional re-training and is fully compatible with existing post-training quantization methods, making it a practical solution for edge LLMs.",
      "authors": [
        "Arnab Sanyal",
        "Gourav Datta",
        "Prithwish Mukherjee",
        "Sandeep P. Chinchali",
        "Michael Orshansky"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-05T05:42:14+00:00",
          "link": "https://arxiv.org/abs/2505.02380v1",
          "size": "3906kb",
          "version": "v1"
        },
        {
          "date": "2025-05-06T09:37:57+00:00",
          "link": "https://arxiv.org/abs/2505.02380v2",
          "size": "3906kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T22:24:00+00:00",
          "link": "https://arxiv.org/abs/2505.02380v3",
          "size": "664kb",
          "version": "v3"
        }
      ],
      "title": "EntroLLM: Entropy Encoded Weight Compression for Efficient Large Language Model Inference on Edge Devices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.02380",
        "HTML": "https://arxiv.org/html/2505.02380v3",
        "PDF": "https://arxiv.org/pdf/2505.02380"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a compression framework for edge device inference of LLMs, but does not address LLM training data processing or creation."
      },
      "tasks": [
        "4k",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Quantization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.16600",
      "abstract": "Existing resource-adaptive LoRA federated fine-tuning methods enable clients to fine-tune models using compressed versions of global LoRA matrices, in order to accommodate various compute resources across clients. This compression requirement will lead to suboptimal performance due to information loss. To address this, we propose FLAME, a novel federated learning framework based on the Sparse Mixture-of-Experts (SMoE) architecture. Unlike prior approaches, FLAME retains full (uncompressed) global LoRA matrices and achieves client-side adaptability by varying the number of activated experts per client. However, incorporating SMoE into federated learning introduces unique challenges, specifically, the mismatch in output magnitude from partial expert activation and the imbalance in expert training quality across clients. FLAME tackles these challenges through a lightweight rescaling mechanism and an activation-aware aggregation scheme. Empirical results across diverse computational settings demonstrate that FLAME consistently outperforms existing methods, providing a robust and effective solution for resource-adaptive federated learning.",
      "authors": [
        "Khiem Le",
        "Tuan Tran",
        "Ting Hua",
        "Nitesh V. Chawla"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T21:02:19+00:00",
          "link": "https://arxiv.org/abs/2506.16600v1",
          "size": "948kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T21:49:53+00:00",
          "link": "https://arxiv.org/abs/2506.16600v2",
          "size": "946kb",
          "version": "v2"
        }
      ],
      "title": "FLAME: Towards Federated Fine-Tuning Large Language Models Through Adaptive SMoE",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16600",
        "HTML": "https://arxiv.org/html/2506.16600v2",
        "PDF": "https://arxiv.org/pdf/2506.16600"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a federated learning framework for fine-tuning LLMs, but its main focus is on model architecture (Sparse Mixture-of-Experts) rather than the preprocessing or processing of training data for LLMs."
      },
      "tasks": [
        "Federated Learning",
        "Mixture-of-Experts"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10695",
      "abstract": "Individuals are increasingly relying on large language model (LLM)-enabled conversational agents for emotional support. While prior research has examined privacy and security issues in chatbots specifically designed for mental health purposes, these chatbots are overwhelmingly \"rule-based\" offerings that do not leverage generative AI. Little empirical research currently measures users' privacy and security concerns, attitudes, and expectations when using general-purpose LLM-enabled chatbots to manage and improve mental health. Through 21 semi-structured interviews with U.S. participants, we identified critical misconceptions and a general lack of risk awareness. Participants conflated the human-like empathy exhibited by LLMs with human-like accountability and mistakenly believed that their interactions with these chatbots were safeguarded by the same regulations (e.g., HIPAA) as disclosures with a licensed therapist. We introduce the concept of \"intangible vulnerability,\" where emotional or psychological disclosures are undervalued compared to more tangible forms of information (e.g., financial or location-based data). To address this, we propose recommendations to safeguard user mental health disclosures with general-purpose LLM-enabled chatbots more effectively.",
      "authors": [
        "Jabari Kwesi",
        "Jiaxun Cao",
        "Riya Manchanda",
        "Pardis Emami-Naeini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Emerging Technologies (cs.ET)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:10:21+00:00",
          "link": "https://arxiv.org/abs/2507.10695v1",
          "size": "82kb",
          "version": "v1"
        }
      ],
      "title": "Exploring User Security and Privacy Attitudes and Concerns Toward the Use of General-Purpose LLM Chatbots for Mental Health",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10695",
        "HTML": "https://arxiv.org/html/2507.10695v1",
        "PDF": "https://arxiv.org/pdf/2507.10695"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses user security and privacy attitudes towards LLM-enabled chatbots, not the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10890",
      "abstract": "We study the problem of forecasting the number of units fulfilled (or ``drained'') from each inventory warehouse to meet customer demand, along with the associated outbound shipping costs. The actual drain and shipping costs are determined by complex production systems that manage the planning and execution of customers' orders fulfillment, i.e. from where and how to ship a unit to be delivered to a customer. Accurately modeling these processes is critical for regional inventory planning, especially when using Reinforcement Learning (RL) to develop control policies. For the RL usecase, a drain model is incorporated into a simulator to produce long rollouts, which we desire to be differentiable. While simulating the calls to the internal software systems can be used to recover this transition, they are non-differentiable and too slow and costly to run within an RL training environment. Accordingly, we frame this as a probabilistic forecasting problem, modeling the joint distribution of outbound drain and shipping costs across all warehouses at each time period, conditioned on inventory positions and exogenous customer demand. To ensure robustness in an RL environment, the model must handle out-of-distribution scenarios that arise from off-policy trajectories. We propose a validation scheme that leverages production systems to evaluate the drain model on counterfactual inventory states induced by RL policies. Preliminary results demonstrate the model's accuracy within the in-distribution setting.",
      "authors": [
        "Riccardo Savorgnan and Udaya Ghai and Carson Eisenach and Dean Foster"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T01:10:38+00:00",
          "link": "https://arxiv.org/abs/2507.10890v1",
          "size": "509kb",
          "version": "v1"
        }
      ],
      "title": "Outbound Modeling for Inventory Management",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10890",
        "HTML": "https://arxiv.org/html/2507.10890v1",
        "PDF": "https://arxiv.org/pdf/2507.10890"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on forecasting and modeling for inventory management using reinforcement learning and probabilistic forecasting, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10970",
      "abstract": "Mobile-based financial services have made it possible for the traditionally unbanked to access infrastructure that have been routinely unattainable. Researchers have explored how these systems have made for safer environments to send and receive money and have expanded financial opportunities such as increased borrowing. With this expansion, challenges such as detrimental interest rates, lack of access to policy documents, and inadequate user protective guardrails emerge, amplifying the risks due to technology-aided unethical financial practices that are aided by design patterns. Supported by user interviews, we detail user experiences of mobile-based financial transactions and explore the foundations and guidelines that undergird the financial service provisions: highlighting both affordances and harms enabled in the design of such systems. We discuss the findings by highlighting financial exploitation disparities, deliberating strategies for mitigation of risks and enabling recovery from harms caused by the technology use. We then recommend guidelines for empowering design approaches that support users' mechanisms of trust, their understanding of technological processes, and determination of risks.",
      "authors": [
        "Lindah Kotut"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T04:26:12+00:00",
          "link": "https://arxiv.org/abs/2507.10970v1",
          "size": "1490kb",
          "version": "v1"
        }
      ],
      "title": "Terms and Conditions (Do Not) Apply: Understanding Exploitation Disparities in Design of Mobile-Based Financial Services",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10970",
        "HTML": "https://arxiv.org/html/2507.10970v1",
        "PDF": "https://arxiv.org/pdf/2507.10970"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines the design of mobile-based financial services and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11037",
      "abstract": "The kinematics analysis of foot-ankle complex during gait is essential for advancing biomechanical research and clinical assessment. Collecting accurate surface geometry data from the foot and ankle during dynamic gait conditions is inherently challenging due to swing foot occlusions and viewing limitations. Thus, this paper introduces FootGait3D, a novel multi-view dataset of high-resolution ankle-foot surface point clouds captured during natural gait. Different from existing gait datasets that typically target whole-body or lower-limb motion, FootGait3D focuses specifically on the detailed modeling of the ankle-foot region, offering a finer granularity of motion data. To address this, FootGait3D consists of 8,403 point cloud frames collected from 46 subjects using a custom five-camera depth sensing system. Each frame includes a complete 5-view reconstruction of the foot and ankle (serving as ground truth) along with partial point clouds obtained from only four, three, or two views. This structured variation enables rigorous evaluation of 3D point cloud completion methods under varying occlusion levels and viewpoints. Our dataset is designed for shape completion tasks, facilitating the benchmarking of state-of-the-art single-modal (e.g., PointTr, SnowflakeNet, Anchorformer) and multi-modal (e.g., SVDFormer, PointSea, CSDN) completion networks on the challenge of recovering the full foot geometry from occluded inputs. FootGait3D has significant potential to advance research in biomechanics and multi-segment foot modeling, offering a valuable testbed for clinical gait analysis, prosthetic design, and robotics applications requiring detailed 3D models of the foot during motion. The dataset is now available at https://huggingface.co/datasets/ljw285/FootGait3D.",
      "authors": [
        "Jie-Wen Li",
        "Zi-Han Ye",
        "Qingyuan Zhou",
        "Jiayi Song",
        "Ying He",
        "Ben Fei",
        "Wen-Ming Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T07:03:03+00:00",
          "link": "https://arxiv.org/abs/2507.11037v1",
          "size": "48135kb",
          "version": "v1"
        }
      ],
      "title": "A Multi-View High-Resolution Foot-Ankle Complex Point Cloud Dataset During Gait for Occlusion-Robust 3D Completion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11037",
        "HTML": "https://arxiv.org/html/2507.11037v1",
        "PDF": "https://arxiv.org/pdf/2507.11037"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While it introduces a novel dataset for foot-ankle complex analysis, it does not focus on LLM training data processing or creating datasets for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11277",
      "abstract": "Large Language Models (LLMs) are increasingly deployed within agentic systems-collections of interacting, LLM-powered agents that execute complex, adaptive workflows using memory, tools, and dynamic planning. While enabling powerful new capabilities, these systems also introduce unique forms of uncertainty stemming from probabilistic reasoning, evolving memory states, and fluid execution paths. Traditional software observability and operations practices fall short in addressing these challenges.\n  This paper introduces AgentOps: a comprehensive framework for observing, analyzing, optimizing, and automating operation of agentic AI systems. We identify distinct needs across four key roles-developers, testers, site reliability engineers (SREs), and business users-each of whom engages with the system at different points in its lifecycle. We present the AgentOps Automation Pipeline, a six-stage process encompassing behavior observation, metric collection, issue detection, root cause analysis, optimized recommendations, and runtime automation. Throughout, we emphasize the critical role of automation in managing uncertainty and enabling self-improving AI systems-not by eliminating uncertainty, but by taming it to ensure safe, adaptive, and effective operation.",
      "authors": [
        "Dany Moshkovich and Sergey Zeltyn"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:54:43+00:00",
          "link": "https://arxiv.org/abs/2507.11277v1",
          "size": "841kb",
          "version": "v1"
        }
      ],
      "title": "Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11277",
        "HTML": "https://arxiv.org/html/2507.11277v1",
        "PDF": "https://arxiv.org/pdf/2507.11277"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a framework for optimizing agentic AI systems but does not emphasize the processing or engineering of LLM training data or datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11282",
      "abstract": "Memory safety is traditionally characterized in terms of bad things that cannot happen, an approach that is often criticized as unprincipled. Prior work suggest a connection between memory safety and noninterference, but no satisfactory semantic notion of memory safety is currently known.\n  This work proposes a notion of gradual allocator independence that accurately captures many allocator-specific aspects of memory safety. We consider a low-level language with access to an allocator that provides malloc and free primitives in a flat memory model. Pointers are just integers, and as such it is trivial to write memory-unsafe programs. The basic intuition of gradual allocator independence is that of noninterference, namely that allocators must not influence program execution. This intuition is refined in two important ways to account for the allocators running out-of-memory and for programs to have pointer-to-integer casts. The key insight of the definition is to treat these extensions as forms of downgrading and give them satisfactory technical treatment using the state-of-the-art information flow machinery.",
      "authors": [
        "Ren\\'e Rydhof Hansen",
        "Andreas Stenb{\\ae}k Larsen",
        "Aslan Askarov"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:59:11+00:00",
          "link": "https://arxiv.org/abs/2507.11282v1",
          "size": "309kb",
          "version": "v1"
        }
      ],
      "title": "The downgrading semantics of memory safety",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11282",
        "PDF": "https://arxiv.org/pdf/2507.11282"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses memory safety and allocator independence in the context of low-level programming and does not relate to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11302",
      "abstract": "Vision is an essential part of attitude control for many flying animals, some of which have no dedicated sense of gravity. Flying robots, on the other hand, typically depend heavily on accelerometers and gyroscopes for attitude stabilization. In this work, we present the first vision-only approach to flight control for use in generic environments. We show that a quadrotor drone equipped with a downward-facing event camera can estimate its attitude and rotation rate from just the event stream, enabling flight control without inertial sensors. Our approach uses a small recurrent convolutional neural network trained through supervised learning. Real-world flight tests demonstrate that our combination of event camera and low-latency neural network is capable of replacing the inertial measurement unit in a traditional flight control loop. Furthermore, we investigate the network's generalization across different environments, and the impact of memory and different fields of view. While networks with memory and access to horizon-like visual cues achieve best performance, variants with a narrower field of view achieve better relative generalization. Our work showcases vision-only flight control as a promising candidate for enabling autonomous, insect-scale flying robots.",
      "authors": [
        "Jesse J. Hagenaars",
        "Stein Stroobants",
        "Sander M. Bohte",
        "Guido C.H.E. De Croon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:31:27+00:00",
          "link": "https://arxiv.org/abs/2507.11302v1",
          "size": "21665kb",
          "version": "v1"
        }
      ],
      "title": "All Eyes, no IMU: Learning Flight Attitude from Vision Alone",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11302",
        "HTML": "https://arxiv.org/html/2507.11302v1",
        "PDF": "https://arxiv.org/pdf/2507.11302"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with vision-based flight control for drones, focusing on learning and testing control methods, which do not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.06109",
      "abstract": "Controllable generation is considered a potentially vital approach to address the challenge of annotating 3D data, and the precision of such controllable generation becomes particularly imperative in the context of data production for autonomous driving. Existing methods focus on the integration of diverse generative information into controlling inputs, utilizing frameworks such as GLIGEN or ControlNet, to produce commendable outcomes in controllable generation. However, such approaches intrinsically restrict generation performance to the learning capacities of predefined network architectures. In this paper, we explore the innovative integration of controlling information and introduce PerLDiff (\\textbf{Per}spective-\\textbf{L}ayout \\textbf{Diff}usion Models), a novel method for effective street view image generation that fully leverages perspective 3D geometric information. Our PerLDiff employs 3D geometric priors to guide the generation of street view images with precise object-level control within the network learning process, resulting in a more robust and controllable output. Moreover, it demonstrates superior controllability compared to alternative layout control methods. Empirical results justify that our PerLDiff markedly enhances the precision of controllable generation on the NuScenes and KITTI datasets.",
      "authors": [
        "Jinhua Zhang",
        "Hualian Sheng",
        "Sijia Cai",
        "Bing Deng",
        "Qiao Liang",
        "Wen Li",
        "Ying Fu",
        "Jieping Ye",
        "Shuhang Gu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-08T16:46:47+00:00",
          "link": "https://arxiv.org/abs/2407.06109v1",
          "size": "47354kb",
          "version": "v1"
        },
        {
          "date": "2024-07-16T14:05:17+00:00",
          "link": "https://arxiv.org/abs/2407.06109v2",
          "size": "47463kb",
          "version": "v2"
        },
        {
          "date": "2024-12-03T03:11:21+00:00",
          "link": "https://arxiv.org/abs/2407.06109v3",
          "size": "45359kb",
          "version": "v3"
        },
        {
          "date": "2025-06-30T12:12:38+00:00",
          "link": "https://arxiv.org/abs/2407.06109v4",
          "size": "30298kb",
          "version": "v4"
        },
        {
          "date": "2025-07-15T04:00:54+00:00",
          "link": "https://arxiv.org/abs/2407.06109v5",
          "size": "30298kb",
          "version": "v5"
        }
      ],
      "title": "PerLDiff: Controllable Street View Synthesis Using Perspective-Layout Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.06109",
        "HTML": "https://arxiv.org/html/2407.06109v5",
        "PDF": "https://arxiv.org/pdf/2407.06109"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on controllable generation of street view images using a novel method called PerLDiff, without mentioning any LLM training data processing or dataset creation related to LLMs."
      },
      "tasks": [
        "Autonomous Driving",
        "Image Generation"
      ],
      "repo_urls": [
        "https://github.com/labshuhanggu/perldiff"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.01787",
      "abstract": "This paper presents a comprehensive software stack architecture for integrating quantum computing (QC) capabilities with High-Performance Computing (HPC) environments. While quantum computers show promise as specialized accelerators for scientific computing, their effective integration with classical HPC systems presents significant technical challenges. We propose a hardware-agnostic software framework that supports both current noisy intermediate-scale quantum devices and future fault-tolerant quantum computers, while maintaining compatibility with existing HPC workflows. The architecture includes a quantum gateway interface, standardized APIs for resource management, and robust scheduling mechanisms to handle both simultaneous and interleaved quantum-classical workloads. Key innovations include: (1) a unified resource management system that efficiently coordinates quantum and classical resources, (2) a flexible quantum programming interface that abstracts hardware-specific details, (3) A Quantum Platform Manager API that simplifies the integration of various quantum hardware systems, and (4) a comprehensive tool chain for quantum circuit optimization and execution. We demonstrate our architecture through implementation of quantum-classical algorithms, including the variational quantum linear solver, showcasing the framework's ability to handle complex hybrid workflows while maximizing resource utilization. This work provides a foundational blueprint for integrating QC capabilities into existing HPC infrastructures, addressing critical challenges in resource management, job scheduling, and efficient data movement between classical and quantum resources.",
      "authors": [
        "Amir Shehata",
        "Peter Groszkowski",
        "Thomas Naughton",
        "Murali Gopalakrishnan Meena",
        "Elaine Wong",
        "Daniel Claudino",
        "Rafael Ferreira da Silvaa",
        "Thomas Beck"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T18:18:45+00:00",
          "link": "https://arxiv.org/abs/2503.01787v1",
          "size": "10523kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T15:00:06+00:00",
          "link": "https://arxiv.org/abs/2503.01787v2",
          "size": "1018kb",
          "version": "v2"
        }
      ],
      "title": "Bridging Paradigms: Designing for HPC-Quantum Convergence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01787",
        "HTML": "https://arxiv.org/html/2503.01787v2",
        "PDF": "https://arxiv.org/pdf/2503.01787"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a software stack for quantum computing integration with HPC environments, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.22526",
      "abstract": "We introduce the AnnoPage Dataset, a novel collection of 7,550 pages from historical documents, primarily in Czech and German, spanning from 1485 to the present, focusing on the late 19th and early 20th centuries. The dataset is designed to support research in document layout analysis and object detection. Each page is annotated with axis-aligned bounding boxes (AABB) representing elements of 25 categories of non-textual elements, such as images, maps, decorative elements, or charts, following the Czech Methodology of image document processing. The annotations were created by expert librarians to ensure accuracy and consistency. The dataset also incorporates pages from multiple, mainly historical, document datasets to enhance variability and maintain continuity. The dataset is divided into development and test subsets, with the test set carefully selected to maintain the category distribution. We provide baseline results using YOLO and DETR object detectors, offering a reference point for future research. The AnnoPage Dataset is publicly available on Zenodo (https://doi.org/10.5281/zenodo.12788419), along with ground-truth annotations in YOLO format.",
      "authors": [
        "Martin Ki\\v{s}\\v{s} and Michal Hradi\\v{s} and Martina Dvo\\v{r}\\'akov\\'a and V\\'aclav Jirou\\v{s}ek and Filip Kersch"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-28T15:30:42+00:00",
          "link": "https://arxiv.org/abs/2503.22526v1",
          "size": "18098kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T12:15:26+00:00",
          "link": "https://arxiv.org/abs/2503.22526v2",
          "size": "5891kb",
          "version": "v2"
        }
      ],
      "title": "AnnoPage Dataset: Dataset of Non-Textual Elements in Documents with Fine-Grained Categorization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.22526",
        "HTML": "https://arxiv.org/html/2503.22526v2",
        "PDF": "https://arxiv.org/pdf/2503.22526"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a dataset for document layout analysis and object detection, with no focus on LLM training data or its processing."
      },
      "tasks": [
        "Document Layout Analysis",
        "object-detection",
        "Object Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.21356",
      "abstract": "Unified multimodal generative models aim to integrate image understanding and generation abilities, offering significant advantages in harnessing multimodal corpora, particularly interleaved text-image data. However, existing unified models exhibit limitations in image synthesis quality, autoregressive error accumulation, and image editing capability. In this work, we propose Nexus-Gen, a novel architecture that unifies image understanding, generation, and editing tasks in a shared image embedding space. This shared space serves as a bridge for the autoregressive and diffusion models, which seamlessly integrates their complementary strengths in cross-modal modeling. To mitigate the severe error accumulation during autoregressive embedding prediction, we propose a novel prefilled autoregression strategy that aligns training-inference dynamics by prefilling input sequences with learnable embeddings. After multi-stage and multi-task training on our constructed large-scale dataset with 26.3 million samples, Nexus-Gen achieves state-of-the-art performance on the evaluation benchmarks spanning image understanding, generation and editing tasks. All models, datasets, and source codes are released in https://github.com/modelscope/Nexus-Gen to facilitate further advancements across the field.",
      "authors": [
        "Hong Zhang",
        "Zhongjie Duan",
        "Xingjun Wang",
        "Yuze Zhao",
        "Weiyi Lu",
        "Zhipeng Di",
        "Yixuan Xu",
        "Yingda Chen",
        "and Yu Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-30T06:30:48+00:00",
          "link": "https://arxiv.org/abs/2504.21356v1",
          "size": "3497kb",
          "version": "v1"
        },
        {
          "date": "2025-05-08T08:58:12+00:00",
          "link": "https://arxiv.org/abs/2504.21356v2",
          "size": "3500kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T09:23:42+00:00",
          "link": "https://arxiv.org/abs/2504.21356v3",
          "size": "4608kb",
          "version": "v3"
        }
      ],
      "title": "Nexus-Gen: Unified Image Understanding, Generation, and Editing via Prefilled Autoregression in Shared Embedding Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.21356",
        "HTML": "https://arxiv.org/html/2504.21356v3",
        "PDF": "https://arxiv.org/pdf/2504.21356"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents Nexus-Gen and mentions the construction of a large-scale dataset with 26.3 million samples, focusing on multi-stage and multi-task training, which suggests significant data processing steps involved in creating and using this dataset."
      },
      "tasks": [
        "Image Generation"
      ],
      "repo_urls": [
        "https://github.com/modelscope/nexus-gen"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10409",
      "abstract": "This study addresses the challenge of balancing energy efficiency with performance in AI/ML models, focusing on DeepRX, a deep learning receiver based on a fully convolutional ResNet architecture. We evaluate the energy consumption of DeepRX, considering factors including FLOPs/Watt and FLOPs/clock, and find consistency between estimated and actual energy usage, influenced by memory access patterns. The research extends to comparing energy dynamics during training and inference phases. A key contribution is the application of knowledge distillation (KD) to train a compact DeepRX student model that emulates the performance of the teacher model but with reduced energy consumption. We experiment with different student model sizes, optimal teacher sizes, and KD hyperparameters. Performance is measured by comparing the Bit Error Rate (BER) performance versus Signal-to-Interference & Noise Ratio (SINR) values of the distilled model and a model trained from scratch. The distilled models demonstrate a lower error floor across SINR levels, highlighting the effectiveness of KD in achieving energy-efficient AI solutions.",
      "authors": [
        "Amine Lbath",
        "Ibtissam Labriji"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:54:06+00:00",
          "link": "https://arxiv.org/abs/2507.10409v1",
          "size": "657kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T13:17:11+00:00",
          "link": "https://arxiv.org/abs/2507.10409v2",
          "size": "657kb",
          "version": "v2"
        }
      ],
      "title": "Energy Efficiency in AI for 5G and Beyond: A DeepRx Case Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10409",
        "HTML": "https://arxiv.org/html/2507.10409v2",
        "PDF": "https://arxiv.org/pdf/2507.10409"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses energy efficiency in AI models, not the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10961",
      "abstract": "This paper presents a framework for learning vision-based robotic policies for contact-rich manipulation tasks that generalize spatially across task configurations. We focus on achieving robust spatial generalization of the policy for the peg-in-hole (PiH) task trained from a small number of demonstrations. We propose EquiContact, a hierarchical policy composed of a high-level vision planner (Diffusion Equivariant Descriptor Field, Diff-EDF) and a novel low-level compliant visuomotor policy (Geometric Compliant ACT, G-CompACT). G-CompACT operates using only localized observations (geometrically consistent error vectors (GCEV), force-torque readings, and wrist-mounted RGB images) and produces actions defined in the end-effector frame. Through these design choices, we show that the entire EquiContact pipeline is SE(3)-equivariant, from perception to force control. We also outline three key components for spatially generalizable contact-rich policies: compliance, localized policies, and induced equivariance. Real-world experiments on PiH tasks demonstrate a near-perfect success rate and robust generalization to unseen spatial configurations, validating the proposed framework and principles. The experimental videos can be found on the project website: https://sites.google.com/berkeley.edu/equicontact",
      "authors": [
        "Joohwan Seo",
        "Arvind Kruthiventy",
        "Soomi Lee",
        "Megan Teng",
        "Xiang Zhang",
        "Seoyeon Choi",
        "Jongeun Choi",
        "and Roberto Horowitz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T03:45:26+00:00",
          "link": "https://arxiv.org/abs/2507.10961v1",
          "size": "7044kb",
          "version": "v1"
        }
      ],
      "title": "EquiContact: A Hierarchical SE(3) Vision-to-Force Equivariant Policy for Spatially Generalizable Contact-rich Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10961",
        "HTML": "https://arxiv.org/html/2507.10961v1",
        "PDF": "https://arxiv.org/pdf/2507.10961"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a robotic policy framework for manipulation tasks without any mention of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11099",
      "abstract": "In recent years, visual recognition methods have advanced significantly, finding applications across diverse fields. While researchers seek to understand the mechanisms behind the success of these models, there is also a growing impetus to deploy them in critical areas like autonomous driving and medical diagnostics to better diagnose failures, which promotes the development of interpretability research. This paper systematically reviews existing research on the interpretability of visual recognition models and proposes a taxonomy of methods from a human-centered perspective. The proposed taxonomy categorizes interpretable recognition methods based on Intent, Object, Presentation, and Methodology, thereby establishing a systematic and coherent set of grouping criteria for these XAI methods. Additionally, we summarize the requirements for evaluation metrics and explore new opportunities enabled by recent technologies, such as large multimodal models. We aim to organize existing research in this domain and inspire future investigations into the interpretability of visual recognition models.",
      "authors": [
        "Qiyang Wan",
        "Chengzhi Gao",
        "Ruiping Wang",
        "Xilin Chen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:45:54+00:00",
          "link": "https://arxiv.org/abs/2507.11099v1",
          "size": "6880kb",
          "version": "v1"
        }
      ],
      "title": "A Survey on Interpretability in Visual Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11099",
        "HTML": "https://arxiv.org/html/2507.11099v1",
        "PDF": "https://arxiv.org/pdf/2507.11099"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is a survey on interpretability in visual recognition models, and does not discuss the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.03457",
      "abstract": "This paper presents FLAF, a focal line and feature-constrained active view planning method for tracking failure avoidance in feature-based visual navigation of mobile robots. Our FLAF-based visual navigation is built upon a feature-based visual teach and repeat (VT\\&R) framework, which supports many robotic applications by teaching a robot to navigate on various paths that cover a significant portion of daily autonomous navigation requirements. However, tracking failure in feature-based visual simultaneous localization and mapping (VSLAM) caused by textureless regions in human-made environments is still limiting VT\\&R to be adopted in the real world. To address this problem, the proposed view planner is integrated into a feature-based visual SLAM system to build up an active VT\\&R system that avoids tracking failure. In our system, a pan-tilt unit (PTU)-based active camera is mounted on the mobile robot. Using FLAF, the active camera-based VSLAM operates during the teaching phase to construct a complete path map and in the repeat phase to maintain stable localization. FLAF orients the robot toward more map points to avoid mapping failures during path learning and toward more feature-identifiable map points beneficial for localization while following the learned trajectory. Experiments in real scenarios demonstrate that FLAF outperforms the methods that do not consider feature-identifiability, and our active VT\\&R system performs well in complex environments by effectively dealing with low-texture regions.",
      "authors": [
        "Changfei Fu",
        "Weinan Chen",
        "Wenjun Xu",
        "and Hong Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-05T12:14:29+00:00",
          "link": "https://arxiv.org/abs/2409.03457v1",
          "size": "13491kb",
          "version": "v1"
        },
        {
          "date": "2024-09-08T06:01:43+00:00",
          "link": "https://arxiv.org/abs/2409.03457v2",
          "size": "13498kb",
          "version": "v2"
        },
        {
          "date": "2024-09-21T09:18:56+00:00",
          "link": "https://arxiv.org/abs/2409.03457v3",
          "size": "13699kb",
          "version": "v3"
        },
        {
          "date": "2025-02-13T08:04:27+00:00",
          "link": "https://arxiv.org/abs/2409.03457v4",
          "size": "13697kb",
          "version": "v4"
        },
        {
          "date": "2025-07-15T14:25:58+00:00",
          "link": "https://arxiv.org/abs/2409.03457v5",
          "size": "9049kb",
          "version": "v5"
        }
      ],
      "title": "FLAF: Focal Line and Feature-constrained Active View Planning for Visual Teach and Repeat",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.03457",
        "HTML": "https://arxiv.org/html/2409.03457v5",
        "PDF": "https://arxiv.org/pdf/2409.03457"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a visual navigation planning method to prevent tracking failures in robotic systems, without addressing LLM training data processing or its related data engineering components."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10709",
      "abstract": "Skew-representable matroids form a fundamental class in matroid theory, bridging combinatorics and linear algebra. They play an important role in areas such as coding theory, optimization, and combinatorial geometry, where linear structure is crucial for both theoretical insights and algorithmic applications. Since deciding skew-representability is computationally intractable, much effort has been focused on identifying necessary or sufficient conditions for a matroid to be skew-representable.\n  In this paper, we introduce a novel approach to studying skew-representability and structural properties of matroids and polymatroid functions via tensor products. We provide a characterization of skew-representable matroids, as well as of those representable over skew fields of a given prime characteristic, in terms of tensor products. As an algorithmic consequence, we show that deciding skew-representability, or representability over a skew field of fixed prime characteristic, is co-recursively enumerable: that is, certificates of non-skew-representability -- in general or over a fixed prime characteristic -- can be verified. We also prove that every rank-3 matroid admits a tensor product with any uniform matroid and give a construction yielding the unique freest tensor product in this setting. Finally, as an application of the tensor product framework, we give a new proof of Ingleton's inequality and, more importantly, derive the first known linear rank inequality for folded skew-representable matroids that does not follow from the common information property.",
      "authors": [
        "Krist\\'of B\\'erczi",
        "Bogl\\'arka Geh\\'er",
        "Andr\\'as Imolay",
        "L\\'aszl\\'o Lov\\'asz",
        "Carles Padr\\'o",
        "Tam\\'as Schwarcz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:22:35+00:00",
          "link": "https://arxiv.org/abs/2507.10709v1",
          "size": "57kb",
          "version": "v1"
        }
      ],
      "title": "Interaction between skew-representability, tensor products, extension properties, and rank inequalities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10709",
        "HTML": "https://arxiv.org/html/2507.10709v1",
        "PDF": "https://arxiv.org/pdf/2507.10709"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on skew-representable matroids and their properties via tensor products, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10864",
      "abstract": "Objectives: Timely and accurate detection of colorectal polyps plays a crucial role in diagnosing and preventing colorectal cancer, a major cause of mortality worldwide. This study introduces a new, lightweight, and efficient framework for polyp detection that combines the Local Outlier Factor (LOF) algorithm for filtering noisy data with the YOLO-v11n deep learning model.\n  Study design: An experimental study leveraging deep learning and outlier removal techniques across multiple public datasets.\n  Methods: The proposed approach was tested on five diverse and publicly available datasets: CVC-ColonDB, CVC-ClinicDB, Kvasir-SEG, ETIS, and EndoScene. Since these datasets originally lacked bounding box annotations, we converted their segmentation masks into suitable detection labels. To enhance the robustness and generalizability of our model, we apply 5-fold cross-validation and remove anomalous samples using the LOF method configured with 30 neighbors and a contamination ratio of 5%. Cleaned data are then fed into YOLO-v11n, a fast and resource-efficient object detection architecture optimized for real-time applications. We train the model using a combination of modern augmentation strategies to improve detection accuracy under diverse conditions.\n  Results: Our approach significantly improves polyp localization performance, achieving a precision of 95.83%, recall of 91.85%, F1-score of 93.48%, mAP@0.5 of 96.48%, and mAP@0.5:0.95 of 77.75%. Compared to previous YOLO-based methods, our model demonstrates enhanced accuracy and efficiency.\n  Conclusions: These results suggest that the proposed method is well-suited for real-time colonoscopy support in clinical settings. Overall, the study underscores how crucial data preprocessing and model efficiency are when designing effective AI systems for medical imaging.",
      "authors": [
        "Saadat Behzadi",
        "Danial Sharifrazi",
        "Bita Mesbahzadeh",
        "Javad Hassannataj Joloudarid",
        "Roohallah Alizadehsani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T23:36:54+00:00",
          "link": "https://arxiv.org/abs/2507.10864v1",
          "size": "751kb",
          "version": "v1"
        }
      ],
      "title": "A Lightweight and Robust Framework for Real-Time Colorectal Polyp Detection Using LOF-Based Preprocessing and YOLO-v11n",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10864",
        "PDF": "https://arxiv.org/pdf/2507.10864"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves preprocessing steps such as LOF-based filtering, which are crucial for the robustness of the model in medical imaging, but it primarily focuses on polyp detection rather than on LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11200",
      "abstract": "Vision-Language Models (VLMs) trained on web-scale corpora excel at natural image tasks and are increasingly repurposed for healthcare; however, their competence in medical tasks remains underexplored. We present a comprehensive evaluation of open-source general-purpose and medically specialised VLMs, ranging from 3B to 72B parameters, across eight benchmarks: MedXpert, OmniMedVQA, PMC-VQA, PathVQA, MMMU, SLAKE, and VQA-RAD. To observe model performance across different aspects, we first separate it into understanding and reasoning components. Three salient findings emerge. First, large general-purpose models already match or surpass medical-specific counterparts on several benchmarks, demonstrating strong zero-shot transfer from natural to medical images. Second, reasoning performance is consistently lower than understanding, highlighting a critical barrier to safe decision support. Third, performance varies widely across benchmarks, reflecting differences in task design, annotation quality, and knowledge demands. No model yet reaches the reliability threshold for clinical deployment, underscoring the need for stronger multimodal alignment and more rigorous, fine-grained evaluation protocols.",
      "authors": [
        "Che Liu",
        "Jiazhen Pan",
        "Weixiang Shen",
        "Wenjia Bai",
        "Daniel Rueckert",
        "and Rossella Arcucci"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T11:12:39+00:00",
          "link": "https://arxiv.org/abs/2507.11200v1",
          "size": "412kb",
          "version": "v1"
        }
      ],
      "title": "How Far Have Medical Vision-Language Models Come? A Comprehensive Benchmarking Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11200",
        "PDF": "https://arxiv.org/pdf/2507.11200"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates Vision-Language Models (VLMs) for medical tasks but does not discuss any data processing techniques or contributions to LLM training data preparation or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.05442",
      "abstract": "As AI models grow in power and generality, understanding how agents learn and make decisions in complex environments is critical to promoting ethical behavior. This study introduces the Odyssey, a lightweight, adaptive text based adventure game, providing a scalable framework for exploring AI ethics and safety. The Odyssey examines the ethical implications of implementing biological drives, specifically, self preservation, into three different agents. A Bayesian agent optimized with NEAT, a Bayesian agent optimized with stochastic variational inference, and a GPT 4o agent. The agents select actions at each scenario to survive, adapting to increasingly challenging scenarios. Post simulation analysis evaluates the ethical scores of the agent decisions, uncovering the tradeoffs it navigates to survive. Specifically, analysis finds that when danger increases, agents ethical behavior becomes unpredictable. Surprisingly, the GPT 4o agent outperformed the Bayesian models in both survival and ethical consistency, challenging assumptions about traditional probabilistic methods and raising a new challenge to understand the mechanisms of LLMs' probabilistic reasoning.",
      "authors": [
        "Dylan Waldner",
        "Risto Miikkulainen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-08T04:17:28+00:00",
          "link": "https://arxiv.org/abs/2502.05442v1",
          "size": "10007kb",
          "version": "v1"
        },
        {
          "date": "2025-05-13T08:00:22+00:00",
          "link": "https://arxiv.org/abs/2502.05442v2",
          "size": "11209kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T00:40:33+00:00",
          "link": "https://arxiv.org/abs/2502.05442v3",
          "size": "22428kb",
          "version": "v3"
        }
      ],
      "title": "The Odyssey of the Fittest: Can Agents Survive and Still Be Good?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05442",
        "HTML": "https://arxiv.org/html/2502.05442v3",
        "PDF": "https://arxiv.org/pdf/2502.05442"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses AI ethics and decision-making in agents, including an adventure game and ethical implications, but does not address LLM training data processing."
      },
      "tasks": [
        "Decision Making",
        "Ethics",
        "Navigate",
        "Variational Inference"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.02008",
      "abstract": "Foundation medical segmentation models, with MedSAM being the most popular, have achieved promising performance across organs and lesions. However, MedSAM still suffers from compromised performance on specific lesions with intricate structures and appearance, as well as bounding box prompt-induced perturbations. Although current test-time adaptation (TTA) methods for medical image segmentation may tackle this issue, partial (e.g., batch normalization) or whole parametric updates restrict their effectiveness due to limited update signals or catastrophic forgetting in large models. Meanwhile, these approaches ignore the computational complexity during adaptation, which is particularly significant for modern foundation models. To this end, our theoretical analyses reveal that directly refining image embeddings is feasible to approach the same goal as parametric updates under the MedSAM architecture, which enables us to realize high computational efficiency and segmentation performance without the risk of catastrophic forgetting. Under this framework, we propose to encourage maximizing factorized conditional probabilities of the posterior prediction probability using a proposed distribution-approximated latent conditional random field loss combined with an entropy minimization loss. Experiments show that we achieve about 3\\% Dice score improvements across three datasets while reducing computational complexity by over 7 times.",
      "authors": [
        "Kecheng Chen",
        "Xinyu Luo",
        "Tiexin Qin",
        "Jie Liu",
        "Hui Liu",
        "Victor Ho Fun Lee",
        "Hong Yan",
        "and Haoliang Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-02T03:03:34+00:00",
          "link": "https://arxiv.org/abs/2504.02008v1",
          "size": "1585kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T02:56:45+00:00",
          "link": "https://arxiv.org/abs/2504.02008v2",
          "size": "413kb",
          "version": "v2"
        }
      ],
      "title": "Test-time Adaptation for Foundation Medical Segmentation Model without Parametric Updates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.02008",
        "HTML": "https://arxiv.org/html/2504.02008v2",
        "PDF": "https://arxiv.org/pdf/2504.02008"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on test-time adaptation for medical segmentation models, without any mention of processing or contributing to LLM training data."
      },
      "tasks": [
        "Computational Efficiency",
        "Image Segmentation",
        "Medical Image Segmentation",
        "Segmentation",
        "Semantic Segmentation",
        "Test-time Adaptation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.15524",
      "abstract": "In this paper, we present the Proportional Payoff Allocation Game (PPA-Game), which characterizes situations where agents compete for divisible resources. In the PPA-game, agents select from available resources, and their payoffs are proportionately determined based on heterogeneous weights attributed to them. Such dynamics simulate content creators on online recommender systems like YouTube and TikTok, who compete for finite consumer attention, with content exposure reliant on inherent and distinct quality. We first conduct a game-theoretical analysis of the PPA-Game. While the PPA-Game does not always guarantee the existence of a pure Nash equilibrium (PNE), we identify prevalent scenarios ensuring its existence. Simulated experiments further prove that the cases where PNE does not exist rarely happen. Beyond analyzing static payoffs, we further discuss the agents' online learning about resource payoffs by integrating a multi-player multi-armed bandit framework. We propose an online algorithm facilitating each agent's maximization of cumulative payoffs over $T$ rounds. Theoretically, we establish that the regret of any agent is bounded by $O(\\log^{1 + \\eta} T)$ for any $\\eta > 0$. Empirical results further validate the effectiveness of our online learning approach.",
      "authors": [
        "Renzhe Xu",
        "Haotian Wang",
        "Xingxuan Zhang",
        "Bo Li",
        "Peng Cui"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-22T14:13:11+00:00",
          "link": "https://arxiv.org/abs/2403.15524v1",
          "size": "639kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T09:12:13+00:00",
          "link": "https://arxiv.org/abs/2403.15524v2",
          "size": "289kb",
          "version": "v2"
        }
      ],
      "title": "PPA-Game: Characterizing and Learning Competitive Dynamics Among Online Content Creators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.15524",
        "HTML": "https://arxiv.org/html/2403.15524v2",
        "PDF": "https://arxiv.org/pdf/2403.15524"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on competitive dynamics among online content creators and learning resource payoffs, without addressing LLM training data processing or any aspect related to data engineering for LLMs."
      },
      "tasks": [
        "Diversity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.11333",
      "abstract": "Learning-based Multi-View Stereo (MVS) methods aim to predict depth maps for a sequence of calibrated images to recover dense point clouds. However, existing MVS methods often struggle with challenging regions, such as textureless regions and reflective surfaces, where feature matching fails. In contrast, monocular depth estimation inherently does not require feature matching, allowing it to achieve robust relative depth estimation in these regions. To bridge this gap, we propose MonoMVSNet, a novel monocular feature and depth guided MVS network that integrates powerful priors from a monocular foundation model into multi-view geometry. Firstly, the monocular feature of the reference view is integrated into source view features by the attention mechanism with a newly designed cross-view position encoding. Then, the monocular depth of the reference view is aligned to dynamically update the depth candidates for edge regions during the sampling procedure. Finally, a relative consistency loss is further designed based on the monocular depth to supervise the depth prediction. Extensive experiments demonstrate that MonoMVSNet achieves state-of-the-art performance on the DTU and Tanks-and-Temples datasets, ranking first on the Tanks-and-Temples Intermediate and Advanced benchmarks. The source code is available at https://github.com/JianfeiJ/MonoMVSNet.",
      "authors": [
        "Jianfei Jiang",
        "Qiankun Liu",
        "Haochen Yu",
        "Hongyuan Liu",
        "Liyong Wang",
        "Jiansheng Chen",
        "Huimin Ma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:05:22+00:00",
          "link": "https://arxiv.org/abs/2507.11333v1",
          "size": "4040kb",
          "version": "v1"
        }
      ],
      "title": "MonoMVSNet: Monocular Priors Guided Multi-View Stereo Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11333",
        "HTML": "https://arxiv.org/html/2507.11333v1",
        "PDF": "https://arxiv.org/pdf/2507.11333"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces a novel network for multi-view stereo methods focusing on depth estimation and is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10430",
      "abstract": "Federated Learning (FL) is a promising distributed machine learning approach that enables collaborative training of a global model using multiple edge devices. The data distributed among the edge devices is highly heterogeneous. Thus, FL faces the challenge of data distribution and heterogeneity, where non-Independent and Identically Distributed (non-IID) data across edge devices may yield in significant accuracy drop. Furthermore, the limited computation and communication capabilities of edge devices increase the likelihood of stragglers, thus leading to slow model convergence. In this paper, we propose the FedDHAD FL framework, which comes with two novel methods: Dynamic Heterogeneous model aggregation (FedDH) and Adaptive Dropout (FedAD). FedDH dynamically adjusts the weights of each local model within the model aggregation process based on the non-IID degree of heterogeneous data to deal with the statistical data heterogeneity. FedAD performs neuron-adaptive operations in response to heterogeneous devices to improve accuracy while achieving superb efficiency. The combination of these two methods makes FedDHAD significantly outperform state-of-the-art solutions in terms of accuracy (up to 6.7% higher), efficiency (up to 2.02 times faster), and computation cost (up to 15.0% smaller).",
      "authors": [
        "Ji Liu",
        "Beichen Ma",
        "Qiaolin Yu",
        "Ruoming Jin",
        "Jingbo Zhou",
        "Yang Zhou",
        "Huaiyu Dai",
        "Haixun Wang",
        "Dejing Dou",
        "Patrick Valduriez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:19:00+00:00",
          "link": "https://arxiv.org/abs/2507.10430v1",
          "size": "2983kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T02:55:39+00:00",
          "link": "https://arxiv.org/abs/2507.10430v2",
          "size": "1274kb",
          "version": "v2"
        }
      ],
      "title": "Efficient Federated Learning with Heterogeneous Data and Adaptive Dropout",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10430",
        "HTML": "https://arxiv.org/html/2507.10430v2",
        "PDF": "https://arxiv.org/pdf/2507.10430"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses federated learning with heterogeneous data, focusing on model aggregation and efficiency rather than processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10691",
      "abstract": "Hypergraph $2$-colorability is one of the classical NP-hard problems. Person and Schacht [SODA'09] designed a deterministic algorithm whose expected running time is polynomial over a uniformly chosen $2$-colorable $3$-uniform hypergraph. Lee, Molla, and Nagle recently extended this to $k$-uniform hypergraphs for all $k\\geq 3$. Both papers relied heavily on the regularity lemma, hence their analysis was involved and their running time hid tower-type constants.\n  Our first result in this paper is a new simple and elementary deterministic $2$-coloring algorithm that reproves the theorems of Person-Schacht and Lee-Molla-Nagle while avoiding the use of the regularity lemma. We also show how to turn our new algorithm into a randomized one with average expected running time of only $O(n)$.\n  Our second and main result gives what we consider to be the ultimate evidence of just how easy it is to find a $2$-coloring of an average $2$-colorable hypergraph. We define a coloring oracle to be an algorithm which, given vertex $v$, assigns color red/blue to $v$ while inspecting as few edges as possible, so that the answers to any sequence of queries to the oracle are consistent with a single legal $2$-coloring of the input. Surprisingly, we show that there is a coloring oracle that, on average, can answer every vertex query in time $O(1)$.",
      "authors": [
        "Cassandra Marcussen",
        "Edward Pyne",
        "Ronitt Rubinfeld",
        "Asaf Shapira",
        "Shlomo Tauber"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:05:02+00:00",
          "link": "https://arxiv.org/abs/2507.10691v1",
          "size": "41kb",
          "version": "v1"
        }
      ],
      "title": "A Fast Coloring Oracle for Average Case Hypergraphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10691",
        "PDF": "https://arxiv.org/pdf/2507.10691"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper involves algorithms for hypergraph coloring, a topic unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10993",
      "abstract": "Due to climate-induced changes, many habitats are experiencing range shifts away from their traditional geographic locations (Piguet, 2011). We propose a solution to accurately model whether bird species are present in a specific habitat through the combination of Convolutional Neural Networks (CNNs) (O'Shea, 2015) and tabular data. Our approach makes use of satellite imagery and environmental features (e.g., temperature, precipitation, elevation) to predict bird presence across various climates. The CNN model captures spatial characteristics of landscapes such as forestation, water bodies, and urbanization, whereas the tabular method uses ecological and geographic data. Both systems predict the distribution of birds with an average accuracy of 85%, offering a scalable but reliable method to understand bird migration.",
      "authors": [
        "Emir Durakovic",
        "Min-Hong Shih"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T05:17:58+00:00",
          "link": "https://arxiv.org/abs/2507.10993v1",
          "size": "3970kb",
          "version": "v1"
        }
      ],
      "title": "Modeling Habitat Shifts: Integrating Convolutional Neural Networks and Tabular Data for Species Migration Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10993",
        "HTML": "https://arxiv.org/html/2507.10993v1",
        "PDF": "https://arxiv.org/pdf/2507.10993"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with modeling species migration using CNNs and tabular data, without discussing LLM training data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.07095",
      "abstract": "Training neural networks with high certified accuracy against adversarial examples remains an open challenge despite significant efforts. While certification methods can effectively leverage tight convex relaxations for bound computation, in training, these methods, perhaps surprisingly, can perform worse than looser relaxations. Prior work hypothesized that this phenomenon is caused by the discontinuity, non-smoothness, and perturbation sensitivity of the loss surface induced by tighter relaxations. In this work, we theoretically show that applying Gaussian Loss Smoothing (GLS) on the loss surface can alleviate these issues. We confirm this empirically by instantiating GLS with two variants: a zeroth-order optimization algorithm, called PGPE, which allows training with non-differentiable relaxations, and a first-order optimization algorithm, called RGS, which requires gradients of the relaxation but is much more efficient than PGPE. Extensive experiments show that when combined with tight relaxations, these methods surpass state-of-the-art methods when training on the same network architecture for many settings. Our results clearly demonstrate the promise of Gaussian Loss Smoothing for training certifiably robust neural networks and pave a path towards leveraging tighter relaxations for certified training.",
      "authors": [
        "Stefan Balauca",
        "Mark Niklas M\\\"uller",
        "Yuhao Mao",
        "Maximilian Baader",
        "Marc Fischer",
        "Martin Vechev"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-11T18:44:36+00:00",
          "link": "https://arxiv.org/abs/2403.07095v1",
          "size": "1596kb",
          "version": "v1"
        },
        {
          "date": "2024-06-25T13:46:24+00:00",
          "link": "https://arxiv.org/abs/2403.07095v2",
          "size": "1603kb",
          "version": "v2"
        },
        {
          "date": "2024-10-10T10:01:24+00:00",
          "link": "https://arxiv.org/abs/2403.07095v3",
          "size": "1633kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T12:50:52+00:00",
          "link": "https://arxiv.org/abs/2403.07095v4",
          "size": "2000kb",
          "version": "v4"
        }
      ],
      "title": "Gaussian Loss Smoothing Enables Certified Training with Tight Convex Relaxations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.07095",
        "HTML": "https://arxiv.org/html/2403.07095v4",
        "PDF": "https://arxiv.org/pdf/2403.07095"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses methods for training certifiably robust neural networks with tight convex relaxations and does not address any aspect of LLM training data collection, processing, or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.10596",
      "abstract": "Pixel grounding, encompassing tasks such as Referring Expression Segmentation (RES), has garnered considerable attention due to its immense potential for bridging the gap between vision and language modalities. However, advancements in this domain are currently constrained by limitations inherent in existing datasets, including limited object categories, insufficient textual diversity, and a scarcity of high-quality annotations. To mitigate these limitations, we introduce GroundingSuite, which comprises: (1) an automated data annotation framework leveraging multiple Vision-Language Model (VLM) agents; (2) a large-scale training dataset encompassing 9.56 million diverse referring expressions and their corresponding segmentations; and (3) a meticulously curated evaluation benchmark consisting of 3,800 images. The GroundingSuite training dataset facilitates substantial performance improvements, enabling models trained on it to achieve state-of-the-art results. Specifically, a cIoU of 68.9 on gRefCOCO and a gIoU of 55.3 on RefCOCOm. Moreover, the GroundingSuite annotation framework demonstrates superior efficiency compared to the current leading data annotation method, i.e., $4.5 \\times$ faster than GLaMM.",
      "authors": [
        "Rui Hu",
        "Lianghui Zhu",
        "Yuxuan Zhang",
        "Tianheng Cheng",
        "Lei Liu",
        "Heng Liu",
        "Longjin Ran",
        "Xiaoxin Chen",
        "Wenyu Liu",
        "Xinggang Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-13T17:43:10+00:00",
          "link": "https://arxiv.org/abs/2503.10596v1",
          "size": "2487kb",
          "version": "v1"
        },
        {
          "date": "2025-04-21T14:25:51+00:00",
          "link": "https://arxiv.org/abs/2503.10596v2",
          "size": "2656kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T07:31:05+00:00",
          "link": "https://arxiv.org/abs/2503.10596v3",
          "size": "2652kb",
          "version": "v3"
        }
      ],
      "title": "GroundingSuite: Measuring Complex Multi-Granular Pixel Grounding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.10596",
        "HTML": "https://arxiv.org/html/2503.10596v3",
        "PDF": "https://arxiv.org/pdf/2503.10596"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "This paper makes a core contribution by introducing a new large-scale training dataset and an automated data annotation framework, which are central to LLM training data processing."
      },
      "datasets": [
        {
          "dataset_name": "hustvl/GSEval",
          "downloads": "71",
          "likes": "3",
          "link": "https://huggingface.co/datasets/hustvl/GSEval"
        }
      ],
      "tasks": [
        "Diversity",
        "Language Modeling",
        "Language Modelling",
        "Referring Expression",
        "Referring Expression Segmentation"
      ],
      "repo_urls": [
        "https://github.com/hustvl/groundingsuite"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10642",
      "abstract": "A growing issue within conservation bioacoustics is the task of analysing the vast amount of data generated from the use of passive acoustic monitoring devices. In this paper, we present an alternative AI model which has the potential to help alleviate this problem. Our model formulation addresses the key issues encountered when using current AI models for bioacoustic analysis, namely the: limited training data available; environmental impact, particularly in energy consumption and carbon footprint of training and implementing these models; and associated hardware requirements. The model developed in this work uses associative memory via a transparent, explainable Hopfield neural network to store signals and detect similar signals which can then be used to classify species. Training is rapid ($3$\\,ms), as only one representative signal is required for each target sound within a dataset. The model is fast, taking only $5.4$\\,s to pre-process and classify all $10384$ publicly available bat recordings, on a standard Apple MacBook Air. The model is also lightweight with a small memory footprint of $144.09$\\,MB of RAM usage. Hence, the low computational demands make the model ideal for use on a variety of standard personal devices with potential for deployment in the field via edge-processing devices. It is also competitively accurate, with up to $86\\%$ precision on the dataset used to evaluate the model. In fact, we could not find a single case of disagreement between model and manual identification via expert field guides. Although a dataset of bat echolocation calls was chosen to demo this first-of-its-kind AI model, trained on only two representative calls, the model is not species specific. In conclusion, we propose an equitable AI model that has the potential to be a game changer for fast, lightweight, sustainable, transparent, explainable and accurate bioacoustic analysis.",
      "authors": [
        "Andrew Gascoyne and Wendy Lomas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:37:20+00:00",
          "link": "https://arxiv.org/abs/2507.10642v1",
          "size": "23737kb",
          "version": "v1"
        }
      ],
      "title": "First-of-its-kind AI model for bioacoustic detection using a lightweight associative memory Hopfield neural network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10642",
        "HTML": "https://arxiv.org/html/2507.10642v1",
        "PDF": "https://arxiv.org/pdf/2507.10642"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a bioacoustic model using a Hopfield neural network and focuses on processing acoustic signals, without discussing LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11084",
      "abstract": "The July Revolution in Bangladesh marked a significant student-led mass uprising, uniting people across the nation to demand justice, accountability, and systemic reform. Social media platforms played a pivotal role in amplifying public sentiment and shaping discourse during this historic mass uprising. In this study, we present a hybrid transformer-based sentiment analysis framework to decode public opinion expressed in social media comments during and after the revolution. We used a brand new dataset of 4,200 Bangla comments collected from social media. The framework employs advanced transformer-based feature extraction techniques, including BanglaBERT, mBERT, XLM-RoBERTa, and the proposed hybrid XMB-BERT, to capture nuanced patterns in textual data. Principle Component Analysis (PCA) were utilized for dimensionality reduction to enhance computational efficiency. We explored eleven traditional and advanced machine learning classifiers for identifying sentiments. The proposed hybrid XMB-BERT with the voting classifier achieved an exceptional accuracy of 83.7% and outperform other model classifier combinations. This study underscores the potential of machine learning techniques to analyze social sentiment in low-resource languages like Bangla.",
      "authors": [
        "Md. Sabbir Hossen",
        "Md. Saiduzzaman",
        "and Pabon Shaha"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:26:58+00:00",
          "link": "https://arxiv.org/abs/2507.11084v1",
          "size": "12141kb",
          "version": "v1"
        }
      ],
      "title": "Social Media Sentiments Analysis on the July Revolution in Bangladesh: A Hybrid Transformer Based Machine Learning Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11084",
        "HTML": "https://arxiv.org/html/2507.11084v1",
        "PDF": "https://arxiv.org/pdf/2507.11084"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on sentiment analysis using a transformer-based approach on a dataset of social media comments, without making any direct contribution to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11384",
      "abstract": "This paper explores the application of a simple weighted loss function to Transformer-based models for multi-label emotion detection in SemEval-2025 Shared Task 11. Our approach addresses data imbalance by dynamically adjusting class weights, thereby enhancing performance on minority emotion classes without the computational burden of traditional resampling methods. We evaluate BERT, RoBERTa, and BART on the BRIGHTER dataset, using evaluation metrics such as Micro F1, Macro F1, ROC-AUC, Accuracy, and Jaccard similarity coefficients. The results demonstrate that the weighted loss function improves performance on high-frequency emotion classes but shows limited impact on minority classes. These findings underscore both the effectiveness and the challenges of applying this approach to imbalanced multi-label emotion detection.",
      "authors": [
        "Xia Cui"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:53:33+00:00",
          "link": "https://arxiv.org/abs/2507.11384v1",
          "size": "74kb",
          "version": "v1"
        }
      ],
      "title": "Addressing Data Imbalance in Transformer-Based Multi-Label Emotion Detection with Weighted Loss",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11384",
        "HTML": "https://arxiv.org/html/2507.11384v1",
        "PDF": "https://arxiv.org/pdf/2507.11384"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses addressing data imbalance using weighted loss in emotion detection models, it does not primarily focus on LLM training data processing, merely using techniques applicable to an existing dataset."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.05294",
      "abstract": "Chain-of-thought explanations are widely used to inspect the decision process of large language models (LLMs) and to evaluate the trustworthiness of model outputs, making them important for effective collaboration between LLMs and humans. We demonstrate that preference optimization - a key step in the alignment phase - can inadvertently reduce the faithfulness of these explanations. This occurs because the reward model (RM), which guides alignment, is tasked with optimizing both the expected quality of the response and the appropriateness of the explanations (e.g., minimizing bias or adhering to safety standards), creating potential conflicts. The RM lacks a mechanism to assess the consistency between the model's internal decision process and the generated explanation. Consequently, the LLM may engage in \"reward hacking\" by producing a final response that scores highly while giving an explanation tailored to maximize reward rather than accurately reflecting its reasoning. To address this issue, we propose enriching the RM's input with a causal attribution of the prediction, allowing the RM to detect discrepancies between the generated self-explanation and the model's decision process. In controlled settings, we show that this approach reduces the tendency of the LLM to generate misleading explanations.",
      "authors": [
        "Pedro Ferreira and Wilker Aziz and Ivan Titov"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-07T17:49:23+00:00",
          "link": "https://arxiv.org/abs/2504.05294v1",
          "size": "292kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T14:16:16+00:00",
          "link": "https://arxiv.org/abs/2504.05294v2",
          "size": "286kb",
          "version": "v2"
        }
      ],
      "title": "Truthful or Fabricated? Using Causal Attribution to Mitigate Reward Hacking in Explanations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.05294",
        "HTML": "https://arxiv.org/html/2504.05294v2",
        "PDF": "https://arxiv.org/pdf/2504.05294"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Though it mentions the alignment phase and preference optimization, the primary focus is on mitigating reward hacking in explanations rather than substantive processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10819",
      "abstract": "The main objective of this technical report is to conduct a comprehensive study on devices operating within Industrial Internet of Things (IIoT) environments, describing the scenarios that define this category and analysing the vulnerabilities that compromise their security. To this end, the report seeks to identify and examine the main classes of IIoT devices, detailing their characteristics, functionalities, and roles within industrial systems. This analysis enables a better understanding of how these devices interact and fulfil the requirements of critical industrial environments. The report also explores the specific contexts in which these devices operate, highlighting the distinctive features of industrial scenarios and the conditions under which the devices function. Furthermore, it analyses the vulnerabilities affecting IIoT devices, outlining their vectors, targets, impact, and consequences. The report then describes the typical phases of an attack, along with a selection of real-world documented incidents. These cases are classified according to the taxonomy presented in Section 3, providing a comprehensive view of the potential threats to security and assessing the impact these vulnerabilities may have on industrial environments. Finally, the report presents a compilation of some of the most recent and effective security countermeasures as potential solutions to the security challenges faced by industrial systems. Special emphasis is placed on the role of Machine Learning in the development of these approaches, underscoring its importance in enhancing industrial cybersecurity.",
      "authors": [
        "Pedro Almansa Jim\\'enez",
        "Lorenzo Fern\\'andez Maim\\'o",
        "\\'Angel Luis Per\\'ales G\\'omez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T21:37:02+00:00",
          "link": "https://arxiv.org/abs/2507.10819v1",
          "size": "4947kb",
          "version": "v1"
        }
      ],
      "title": "Reporte de vulnerabilidades en IIoT. Proyecto DEFENDER",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10819",
        "HTML": "https://arxiv.org/html/2507.10819v1",
        "PDF": "https://arxiv.org/pdf/2507.10819"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This technical report deals with IIoT vulnerabilities and does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10855",
      "abstract": "Large pre-trained transformers have revolutionized artificial intelligence across various domains, and fine-tuning remains the dominant approach for adapting these models to downstream tasks due to the cost of training from scratch. However, in existing fine-tuning methods, the updated representations are formed as a dense combination of modified parameters, making it challenging to interpret their contributions and understand how the model adapts to new tasks. In this work, we introduce a fine-tuning framework inspired by sparse coding, where fine-tuned features are represented as a sparse combination of basic elements, i.e., feature dictionary atoms. The feature dictionary atoms function as fundamental building blocks of the representation, and tuning atoms allows for seamless adaptation to downstream tasks. Sparse coefficients then serve as indicators of atom importance, identifying the contribution of each atom to the updated representation. Leveraging the atom selection capability of sparse coefficients, we first demonstrate that our method enhances image editing performance by improving text alignment through the removal of unimportant feature dictionary atoms. Additionally, we validate the effectiveness of our approach in the text-to-image concept customization task, where our method efficiently constructs the target concept using a sparse combination of feature dictionary atoms, outperforming various baseline fine-tuning methods.",
      "authors": [
        "Wei Chen",
        "Jingxi Yu",
        "Zichen Miao",
        "Qiang Qiu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T23:03:24+00:00",
          "link": "https://arxiv.org/abs/2507.10855v1",
          "size": "4858kb",
          "version": "v1"
        }
      ],
      "title": "Sparse Fine-Tuning of Transformers for Generative Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10855",
        "PDF": "https://arxiv.org/pdf/2507.10855"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a sparse fine-tuning framework, focusing on model architecture and adaptation rather than a primary contribution in processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2305.06110",
      "abstract": "This paper proposes an atomic behaviour intervention strategy using the Pavlok wearable device. Pavlok utilises beeps, vibration and shocks as a mode of aversion technique to help individuals with behaviour modification. While the device can be useful in certain periodic daily life situations, like alarms and exercise notifications, it relies on manual operations that limit its usage. To automate behaviour modification, we propose a framework that first detects targeted behaviours through a lightweight deep learning model and subsequently nudges the user. Our proposed solution is implemented and verified in the context of snoring, which captures audio from the environment following a prediction of whether the audio content is a snore or not using a lightweight 1D convolutional neural network. Based on the prediction, we use Pavlok to nudge users for preventive measures, such as a change in sleeping posture. We believe that this simple solution can help people change their atomic habits, which may lead to long-term health benefits. Our proposed lightweight model (99.8% fewer parameters over SOTA; 790,273$\\rightarrow$1,337) achieves SOTA test accuracy of 0.99 on a public benchmark. The code and model are publicly available at https://github.com/hasan-rakibul/pavlok-nudge-snore.",
      "authors": [
        "Md Rakibul Hasan",
        "Shreya Ghosh",
        "Pradyumna Agrawal",
        "Zhixi Cai",
        "Abhinav Dhall",
        "Tom Gedeon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-10T12:54:02+00:00",
          "link": "https://arxiv.org/abs/2305.06110v1",
          "size": "1468kb",
          "version": "v1"
        },
        {
          "date": "2023-05-11T03:29:54+00:00",
          "link": "https://arxiv.org/abs/2305.06110v2",
          "size": "1468kb",
          "version": "v2"
        },
        {
          "date": "2024-09-13T15:09:39+00:00",
          "link": "https://arxiv.org/abs/2305.06110v3",
          "size": "5608kb",
          "version": "v3"
        },
        {
          "date": "2025-02-14T00:24:07+00:00",
          "link": "https://arxiv.org/abs/2305.06110v4",
          "size": "5587kb",
          "version": "v4"
        },
        {
          "date": "2025-07-15T07:59:07+00:00",
          "link": "https://arxiv.org/abs/2305.06110v5",
          "size": "5531kb",
          "version": "v5"
        }
      ],
      "title": "Pavlok-Nudge: A Feedback Mechanism for Atomic Behaviour Modification with Snoring Usecase",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.06110",
        "HTML": "https://arxiv.org/html/2305.06110v5",
        "PDF": "https://arxiv.org/pdf/2305.06110"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper details a feedback mechanism involving wearable devices for behavior modification and does not discuss LLM training data processing."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/hasan-rakibul/pavlok-nudge-snore"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10562",
      "abstract": "Current AI agent architectures suffer from ephemeral memory limitations, preventing effective collaboration and knowledge sharing across sessions and agent boundaries. We introduce SAMEP (Secure Agent Memory Exchange Protocol), a novel framework that enables persistent, secure, and semantically searchable memory sharing among AI agents. Our protocol addresses three critical challenges: (1) persistent context preservation across agent sessions, (2) secure multi-agent collaboration with fine-grained access control, and (3) efficient semantic discovery of relevant historical context. SAMEP implements a distributed memory repository with vector-based semantic search, cryptographic access controls (AES-256-GCM), and standardized APIs compatible with existing agent communication protocols (MCP, A2A). We demonstrate SAMEP's effectiveness across diverse domains including multi-agent software development, healthcare AI with HIPAA compliance, and multi-modal processing pipelines. Experimental results show 73% reduction in redundant computations, 89% improvement in context relevance scores, and complete compliance with regulatory requirements including audit trail generation. SAMEP enables a new paradigm of persistent, collaborative AI agent ecosystems while maintaining security and privacy guarantees.",
      "authors": [
        "Hari Masoor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Databases (cs.DB)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T02:20:09+00:00",
          "link": "https://arxiv.org/abs/2507.10562v1",
          "size": "1229kb",
          "version": "v1"
        }
      ],
      "title": "SAMEP: A Secure Protocol for Persistent Context Sharing Across AI Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10562",
        "HTML": "https://arxiv.org/html/2507.10562v1",
        "PDF": "https://arxiv.org/pdf/2507.10562"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a secure protocol for AI agents to share memory, addressing context preservation and secure collaboration, without making contributions related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10580",
      "abstract": "Mental health plays a crucial role in the overall well-being of an individual. In recent years, digital platforms have been increasingly used to expand mental health and emotional support. However, there are persistent challenges related to limited user accessibility, internet connectivity, and data privacy, which highlight the need for an offline, smartphone-based solution. To address these challenges, we propose EmoSApp (Emotional Support App): an entirely offline, smartphone-based conversational app designed for mental health and emotional support. The system leverages Large Language Models (LLMs), specifically fine-tuned, quantized and deployed using Torchtune and Executorch for resource-constrained devices, allowing all inferences to occur on the smartphone. To equip EmoSApp with robust domain expertise, we fine-tuned the LLaMA-3.2-1B-Instruct model on our custom curated ``Knowledge dataset'' of 14,582 mental-health QA pairs, along with the multi-turn conversational data.\n  Through qualitative human evaluation with the student population, we demonstrate that EmoSApp has the ability to respond coherently, empathetically, maintain interactive dialogue, and provide relevant suggestions to user's mental health problems. Additionally, quantitative evaluations on nine standard commonsense and reasoning benchmarks demonstrate the efficacy of our fine-tuned, quantized model in low-resource settings. By prioritizing on-device deployment and specialized domain adaptation, EmoSApp serves as a blueprint for future innovations in portable, secure, and highly tailored AI-driven mental health solutions.",
      "authors": [
        "Vimaleswar A",
        "Prabhu Nandan Sahu",
        "Nilesh Kumar Sahu",
        "Haroon R Lone"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T11:23:07+00:00",
          "link": "https://arxiv.org/abs/2507.10580v1",
          "size": "1121kb",
          "version": "v1"
        }
      ],
      "title": "An Offline Mobile Conversational Agent for Mental Health Support: Learning from Emotional Dialogues and Psychological Texts with Student-Centered Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10580",
        "HTML": "https://arxiv.org/html/2507.10580v1",
        "PDF": "https://arxiv.org/pdf/2507.10580"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses fine-tuning an LLM on a custom dataset for mental-health support, it does not primarily focus on novel data processing methodologies or new dataset creation with detailed data processing steps."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10740",
      "abstract": "This paper presents a novel rule-based approach for generating music by varying existing tunes. We parse each tune to find the Pathway Assembly (PA) [ 1], that is a structure representing all repetitions in the tune. The Sequitur algorithm [2 ] is used for this. The result is a grammar. We then carry out mutation on the grammar, rather than on a tune directly. There are potentially 19 types of mutations such as adding, removing, swapping or reversing parts of the grammar that can be applied to the grammars. The system employs one of the mutations randomly in this step to automatically manipulate the grammar. Following the mutation, we need to expand the grammar which returns a new tune. The output after 1 or more mutations will be a new tune related to the original tune. Our study examines how tunes change gradually over the course of multiple mutations. Edit distances, structural complexity and length of the tunes are used to show how a tune is changed after multiple mutations. In addition, the size of effect of each mutation type is analyzed. As a final point, we review the musical aspect of the output tunes. It should be noted that the study only focused on generating new pitch sequences. The study is based on an Irish traditional tune dataset and a list of integers has been used to represent each tune's pitch values.",
      "authors": [
        "Maziar Kanani",
        "Sean O Leary",
        "James McDermott"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:04:49+00:00",
          "link": "https://arxiv.org/abs/2507.10740v1",
          "size": "1575kb",
          "version": "v1"
        }
      ],
      "title": "Parsing Musical Structure to Enable Meaningful Variations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10740",
        "HTML": "https://arxiv.org/html/2507.10740v1",
        "PDF": "https://arxiv.org/pdf/2507.10740"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on music generation by varying existing tunes and not on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11116",
      "abstract": "Jellyfish, a diverse group of gelatinous marine organisms, play a crucial role in maintaining marine ecosystems but pose significant challenges for biodiversity and conservation due to their rapid proliferation and ecological impact. Accurate identification of jellyfish species is essential for ecological monitoring and management. In this study, we proposed a deep learning framework for jellyfish species detection and classification using an underwater image dataset. The framework integrates advanced feature extraction techniques, including MobileNetV3, ResNet50, EfficientNetV2-B0, and VGG16, combined with seven traditional machine learning classifiers and three Feedforward Neural Network classifiers for precise species identification. Additionally, we activated the softmax function to directly classify jellyfish species using the convolutional neural network models. The combination of the Artificial Neural Network with MobileNetV3 is our best-performing model, achieving an exceptional accuracy of 98%, significantly outperforming other feature extractor-classifier combinations. This study demonstrates the efficacy of deep learning and hybrid frameworks in addressing biodiversity challenges and advancing species detection in marine environments.",
      "authors": [
        "Md. Sabbir Hossen",
        "Md. Saiduzzaman",
        "Pabon Shaha",
        "and Mostofa Kamal Nasir"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:10:36+00:00",
          "link": "https://arxiv.org/abs/2507.11116v1",
          "size": "1543kb",
          "version": "v1"
        }
      ],
      "title": "Jellyfish Species Identification: A CNN Based Artificial Neural Network Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11116",
        "HTML": "https://arxiv.org/html/2507.11116v1",
        "PDF": "https://arxiv.org/pdf/2507.11116"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is dedicated to jellyfish species identification using CNNs and does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.03666",
      "abstract": "The practical deployment of diffusion models is still hindered by the high memory and computational overhead. Although quantization paves a way for model compression and acceleration, existing methods face challenges in achieving low-bit quantization efficiently. In this paper, we identify imbalanced activation distributions as a primary source of quantization difficulty, and propose to adjust these distributions through weight finetuning to be more quantization-friendly. We provide both theoretical and empirical evidence supporting finetuning as a practical and reliable solution. Building on this approach, we further distinguish two critical types of quantized layers: those responsible for retaining essential temporal information and those particularly sensitive to bit-width reduction. By selectively finetuning these layers under both local and global supervision, we mitigate performance degradation while enhancing quantization efficiency. Our method demonstrates its efficacy across three high-resolution image generation tasks, obtaining state-of-the-art performance across multiple bit-width settings.",
      "authors": [
        "Haoxuan Wang",
        "Yuzhang Shang",
        "Zhihang Yuan",
        "Junyi Wu",
        "Junchi Yan",
        "Yan Yan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-06T03:39:44+00:00",
          "link": "https://arxiv.org/abs/2402.03666v1",
          "size": "8501kb",
          "version": "v1"
        },
        {
          "date": "2024-02-13T05:22:34+00:00",
          "link": "https://arxiv.org/abs/2402.03666v2",
          "size": "8501kb",
          "version": "v2"
        },
        {
          "date": "2024-09-06T02:02:41+00:00",
          "link": "https://arxiv.org/abs/2402.03666v3",
          "size": "7242kb",
          "version": "v3"
        },
        {
          "date": "2025-06-26T17:36:29+00:00",
          "link": "https://arxiv.org/abs/2402.03666v4",
          "size": "6569kb",
          "version": "v4"
        },
        {
          "date": "2025-07-09T03:25:08+00:00",
          "link": "https://arxiv.org/abs/2402.03666v5",
          "size": "6569kb",
          "version": "v5"
        },
        {
          "date": "2025-07-15T15:33:13+00:00",
          "link": "https://arxiv.org/abs/2402.03666v6",
          "size": "6569kb",
          "version": "v6"
        }
      ],
      "title": "QuEST: Low-bit Diffusion Model Quantization via Efficient Selective Finetuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.03666",
        "HTML": "https://arxiv.org/html/2402.03666",
        "PDF": "https://arxiv.org/pdf/2402.03666"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with model quantization of diffusion models, focusing on activation distributions and finetuning for quantization efficiency, without involvement in LLM training-data processes."
      },
      "tasks": [
        "Image Generation",
        "Model Compression",
        "Quantization"
      ],
      "repo_urls": [
        "https://github.com/hatchetProject/QuEST"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.11310",
      "abstract": "Verifying the credibility of Cyber Threat Intelligence (CTI) is essential for reliable cybersecurity defense. However, traditional approaches typically treat this task as a static classification problem, relying on handcrafted features or isolated deep learning models. These methods often lack the robustness needed to handle incomplete, heterogeneous, or noisy intelligence, and they provide limited transparency in decision-making-factors that reduce their effectiveness in real-world threat environments. To address these limitations, we propose LRCTI, a Large Language Model (LLM)-based framework designed for multi-step CTI credibility verification. The framework first employs a text summarization module to distill complex intelligence reports into concise and actionable threat claims. It then uses an adaptive multi-step evidence retrieval mechanism that iteratively identifies and refines supporting information from a CTI-specific corpus, guided by LLM feedback. Finally, a prompt-based Natural Language Inference (NLI) module is applied to evaluate the credibility of each claim while generating interpretable justifications for the classification outcome. Experiments conducted on two benchmark datasets, CTI-200 and PolitiFact show that LRCTI improves F1-Macro and F1-Micro scores by over 5%, reaching 90.9% and 93.6%, respectively, compared to state-of-the-art baselines. These results demonstrate that LRCTI effectively addresses the core limitations of prior methods, offering a scalable, accurate, and explainable solution for automated CTI credibility verification",
      "authors": [
        "Fengxiao Tang",
        "Huan Li",
        "Ming Zhao",
        "Zongzong Wu",
        "Shisong Peng",
        "Tao Yin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:42:32+00:00",
          "link": "https://arxiv.org/abs/2507.11310v1",
          "size": "1595kb",
          "version": "v1"
        }
      ],
      "title": "LRCTI: A Large Language Model-Based Framework for Multi-Step Evidence Retrieval and Reasoning in Cyber Threat Intelligence Credibility Verification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11310",
        "HTML": "https://arxiv.org/html/2507.11310v1",
        "PDF": "https://arxiv.org/pdf/2507.11310"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a framework for CTI credibility verification using LLM feedback, focusing on retrieval and inference tasks rather than on data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11437",
      "abstract": "The emergence of the Spatial Web -- the Web where content is tied to real-world locations has the potential to improve and enable many applications such as augmented reality, navigation, robotics, and more. The Spatial Web is missing a key ingredient that is impeding its growth -- a spatial naming system to resolve real-world locations to names. Today's spatial naming systems are digital maps such as Google and Apple maps. These maps and the location-based services provided on top of these maps are primarily controlled by a few large corporations and mostly cover outdoor public spaces. Emerging classes of applications, such as persistent world-scale augmented reality, require detailed maps of both outdoor and indoor spaces. Existing centralized mapping infrastructures are proving insufficient for such applications because of the scale of cartography efforts required and the privacy of indoor map data.\n  In this paper, we present a case for a federated spatial naming system, or in other words, a federated mapping infrastructure. This enables disparate parties to manage and serve their own maps of physical regions and unlocks scalability of map management, isolation and privacy of maps. Map-related services such as address-to-location mapping, location-based search, and routing needs re-architecting to work on federated maps. We discuss some essential services and practicalities of enabling these services.",
      "authors": [
        "Sagar Bharadwaj",
        "Srinivasan Seshan",
        "Anthony Rowe"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:00:37+00:00",
          "link": "https://arxiv.org/abs/2507.11437v1",
          "size": "115kb",
          "version": "v1"
        }
      ],
      "title": "Uniting the World by Dividing it: Federated Maps to Enable Spatial Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11437",
        "HTML": "https://arxiv.org/html/2507.11437v1",
        "PDF": "https://arxiv.org/pdf/2507.11437"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a federated spatial mapping system for the Spatial Web, without addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.16206",
      "abstract": "Haptic sciences and technologies benefit greatly from comprehensive datasets that capture tactile stimuli under controlled, systematic conditions. However, existing haptic databases collect data through uncontrolled exploration, which hinders the systematic analysis of how motion parameters (e.g., motion direction and velocity) influence tactile perception. This paper introduces Cluster Haptic Texture Database, a multimodal dataset recorded using a 3-axis machine with an artificial finger to precisely control sliding velocity and direction. The dataset encompasses 118 textured surfaces across 9 material categories, with recordings at 5 velocity levels (20-60 mm/s) and 8 directions. Each surface was tested under 160 conditions, yielding 18,880 synchronized recordings of audio, acceleration, force, position, and visual data. Validation using convolutional neural networks demonstrates classification accuracies of 96% for texture recognition, 88.76% for velocity estimation, and 78.79% for direction estimation, confirming the dataset's utility for machine learning applications. This resource enables research in haptic rendering, texture recognition algorithms, and human tactile perception mechanisms, supporting the development of realistic haptic interfaces for virtual reality systems and robotic applications.",
      "authors": [
        "Michikuni Eguchi",
        "Tomohiro Hayase",
        "Yuichi Hiroi",
        "Takefumi Hiraki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-23T06:18:10+00:00",
          "link": "https://arxiv.org/abs/2407.16206v1",
          "size": "5360kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T04:46:19+00:00",
          "link": "https://arxiv.org/abs/2407.16206v2",
          "size": "10562kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T04:57:52+00:00",
          "link": "https://arxiv.org/abs/2407.16206v3",
          "size": "10559kb",
          "version": "v3"
        }
      ],
      "title": "Cluster Haptic Texture Database: Haptic Texture Database with Varied Velocity-Direction Sliding Contacts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.16206",
        "HTML": "https://arxiv.org/html/2407.16206v3",
        "PDF": "https://arxiv.org/pdf/2407.16206"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a haptic texture database and focuses on systematic data collection for haptic sciences, without any discussion of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.08871",
      "abstract": "Narrowing the performance gap between optimal and feasible detection in inter-symbol interference (ISI) channels, this paper proposes to use graph neural networks (GNNs) for detection that can also be used to perform joint detection and decoding (JDD). For detection, the GNN is build upon the factor graph representations of the channel, while for JDD, the factor graph is expanded by the Tanner graph of the parity-check matrix (PCM) of the channel code, sharing the variable nodes (VNs). A particularly advantageous property of the GNN is a) the robustness against cycles in the factor graphs which is the main problem for sum-product algorithm (SPA)-based detection, and b) the robustness against channel state information (CSI) uncertainty at the receiver. Additionally, we propose using an input embedding resulting in a GNN independent of the channel impulse response (CIR). Consequently, a fully deep learning-based receiver enables joint optimization instead of individual optimization of the components, so-called end-to-end learning. Furthermore, we propose a parallel flooding schedule that also reduces the latency, which turns out to improve the error correcting performance. The proposed approach is analyzed and compared to state-of-the-art baselines for different modulations and codes in terms of error correcting capability and latency. The gain compared to SPA-based detection might be explained with improved messages between nodes and adaptive damping of messages. For a higher order modulation in a high-rate turbo detection and decoding (TDD) scenario the GNN shows a, at first glance, surprisingly high gain of 6.25 dB compared to the best, feasible non-neural baseline.",
      "authors": [
        "Jannis Clausius",
        "Marvin R\\\"ubenacke",
        "Daniel Tandler",
        "Stephan ten Brink"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-15T15:40:42+00:00",
          "link": "https://arxiv.org/abs/2501.08871v1",
          "size": "62kb",
          "version": "v1"
        },
        {
          "date": "2025-04-28T12:56:57+00:00",
          "link": "https://arxiv.org/abs/2501.08871v2",
          "size": "75kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T13:57:11+00:00",
          "link": "https://arxiv.org/abs/2501.08871v3",
          "size": "84kb",
          "version": "v3"
        }
      ],
      "title": "Joint Detection and Decoding: A Graph Neural Network Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.08871",
        "PDF": "https://arxiv.org/pdf/2501.08871"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes using GNNs for detection and decoding in communication systems and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.12753",
      "abstract": "Vision Foundation Models (VFMs) have delivered remarkable performance in Domain Generalized Semantic Segmentation (DGSS). However, recent methods often overlook the fact that visual cues are susceptible, whereas the underlying geometry remains stable, rendering depth information more robust. In this paper, we investigate the potential of integrating depth information with features from VFMs, to improve the geometric consistency within an image and boost the generalization performance of VFMs. We propose a novel fine-tuning DGSS framework, named DepthForge, which integrates the visual cues from frozen DINOv2 or EVA02 and depth cues from frozen Depth Anything V2. In each layer of the VFMs, we incorporate depth-aware learnable tokens to continuously decouple domain-invariant visual and spatial information, thereby enhancing depth awareness and attention of the VFMs. Finally, we develop a depth refinement decoder and integrate it into the model architecture to adaptively refine multi-layer VFM features and depth-aware learnable tokens. Extensive experiments are conducted based on various DGSS settings and five different datsets as unseen target domains. The qualitative and quantitative results demonstrate that our method significantly outperforms alternative approaches with stronger performance, steadier visual-spatial attention, and superior generalization ability. In particular, DepthForge exhibits outstanding performance under extreme conditions (e.g., night and snow). Code is available at https://github.com/anonymouse-xzrptkvyqc/DepthForge.",
      "authors": [
        "Siyu Chen",
        "Ting Han",
        "Changshe Zhang",
        "Xin Luo",
        "Meiliu Wu",
        "Guorong Cai",
        "Jinhe Su"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-17T08:45:33+00:00",
          "link": "https://arxiv.org/abs/2504.12753v1",
          "size": "8746kb",
          "version": "v1"
        },
        {
          "date": "2025-07-03T10:17:05+00:00",
          "link": "https://arxiv.org/abs/2504.12753v2",
          "size": "8743kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T14:57:45+00:00",
          "link": "https://arxiv.org/abs/2504.12753v3",
          "size": "8744kb",
          "version": "v3"
        }
      ],
      "title": "Stronger, Steadier & Superior: Geometric Consistency in Depth VFM Forges Domain Generalized Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12753",
        "HTML": "https://arxiv.org/html/2504.12753v3",
        "PDF": "https://arxiv.org/pdf/2504.12753"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving domain generalized semantic segmentation through a novel fine-tuning framework incorporating depth information in VFMs, it does not contribute to LLM training data processing."
      },
      "tasks": [
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/anonymouse-xzrptkvyqc/depthforge"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.05077",
      "abstract": "Reverberation encodes spatial information regarding the acoustic source environment, yet traditional Speech Restoration (SR) usually completely removes reverberation. We propose ReverbMiipher, an SR model extending parametric resynthesis framework, designed to denoise speech while preserving and enabling control over reverberation. ReverbMiipher incorporates a dedicated ReverbEncoder to extract a reverb feature vector from noisy input. This feature conditions a vocoder to reconstruct the speech signal, removing noise while retaining the original reverberation characteristics. A stochastic zero-vector replacement strategy during training ensures the feature specifically encodes reverberation, disentangling it from other speech attributes. This learned representation facilitates reverberation control via techniques such as interpolation between features, replacement with features from other utterances, or sampling from a latent space. Objective and subjective evaluations confirm ReverbMiipher effectively preserves reverberation, removes other artifacts, and outperforms the conventional two-stage SR and convolving simulated room impulse response approach. We further demonstrate its ability to generate novel reverberation effects through feature manipulation.",
      "authors": [
        "Wataru Nakata",
        "Yuma Koizumi",
        "Shigeki Karita",
        "Robin Scheibler",
        "Haruko Ishikawa",
        "Adriana Guevara-Rukoz",
        "Heiga Zen",
        "Michiel Bacchiani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-08T09:17:42+00:00",
          "link": "https://arxiv.org/abs/2505.05077v1",
          "size": "1021kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T01:06:42+00:00",
          "link": "https://arxiv.org/abs/2505.05077v2",
          "size": "869kb",
          "version": "v2"
        }
      ],
      "title": "ReverbMiipher: Generative Speech Restoration meets Reverberation Characteristics Controllability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.05077",
        "HTML": "https://arxiv.org/html/2505.05077v2",
        "PDF": "https://arxiv.org/pdf/2505.05077"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses generative speech restoration focusing on reverberation characteristics. It does not address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.11441",
      "abstract": "Understanding the relationship between data compression and the capabilities of Large Language Models (LLMs) is crucial, especially in specialized domains like code intelligence. Prior work posited a linear relationship between compression and general intelligence. However, it overlooked the multifaceted nature of code that encompasses diverse programming languages and tasks, and struggled with fair evaluation of modern Code LLMs. We address this by evaluating a diverse array of open-source Code LLMs on comprehensive multi-language, multi-task code benchmarks. To address the challenge of efficient and fair evaluation of pre-trained LLMs' code intelligence, we introduce \\textit{Format Annealing}, a lightweight, transparent training methodology designed to assess the intrinsic capabilities of these pre-trained models equitably. Compression efficacy, measured as bits-per-character (BPC), is determined using a novel, large-scale, and previously unseen code validation set derived from GitHub. Our empirical results reveal a fundamental logarithmic relationship between measured code intelligence and BPC. This finding refines prior hypotheses of linearity, which we suggest are likely observations of the logarithmic curve's tail under specific, limited conditions. Our work provides a more nuanced understanding of compression's role in developing code intelligence and contributes a robust evaluation framework in the code domain.",
      "authors": [
        "Shijie Xuyang",
        "Xianzhen Luo",
        "Tianhao Cheng",
        "Zheng Chu",
        "Houyi Li",
        "ziqi wang",
        "Siming Huang",
        "Qingfu Zhu",
        "Qiufeng Wang",
        "Xiangyu Zhang",
        "Shuigeng Zhou",
        "Wanxiang Che"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-16T16:59:14+00:00",
          "link": "https://arxiv.org/abs/2505.11441v1",
          "size": "1373kb",
          "version": "v1"
        },
        {
          "date": "2025-05-25T12:11:58+00:00",
          "link": "https://arxiv.org/abs/2505.11441v2",
          "size": "1824kb",
          "version": "v2"
        },
        {
          "date": "2025-06-04T06:01:48+00:00",
          "link": "https://arxiv.org/abs/2505.11441v3",
          "size": "1374kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T09:48:13+00:00",
          "link": "https://arxiv.org/abs/2505.11441v4",
          "size": "1374kb",
          "version": "v4"
        }
      ],
      "title": "Is Compression Really Linear with Code Intelligence?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.11441",
        "HTML": "https://arxiv.org/html/2505.11441v4",
        "PDF": "https://arxiv.org/pdf/2505.11441"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a validation set to evaluate Code LLMs, it focuses on evaluation rather than processing or engineering LLM training data itself."
      },
      "tasks": [
        "Data Compression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10575",
      "abstract": "Effective learning rate (LR) scheduling is crucial for training deep neural networks. However, popular pre-defined and adaptive schedulers can still lead to suboptimal generalization. This paper introduces VolSched, a novel adaptive LR scheduler inspired by the concept of volatility in stochastic processes like Geometric Brownian Motion to dynamically adjust the learning rate. By calculating the ratio between long-term and short-term accuracy volatility, VolSched increases the LR to escape plateaus and decreases it to stabilize training, allowing the model to explore the loss landscape more effectively. We evaluate VolSched on the CIFAR-100 dataset against a strong baseline using a standard augmentation pipeline. When paired with ResNet-18 and ResNet-34, our scheduler delivers consistent performance gains, improving top-1 accuracy by 1.4 and 1.3 percentage points respectively. Analysis of the loss curves reveals that VolSched promotes a longer exploration phase. A quantitative analysis of the Hessian shows that VolSched finds a final solution that is 38% flatter than the next-best baseline, allowing the model to obtain wider minima and hence better generalization performance.",
      "authors": [
        "Kieran Chai Kai Ren"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T05:45:53+00:00",
          "link": "https://arxiv.org/abs/2507.10575v1",
          "size": "58kb",
          "version": "v1"
        }
      ],
      "title": "An Adaptive Volatility-based Learning Rate Scheduler",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10575",
        "PDF": "https://arxiv.org/pdf/2507.10575"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a novel learning rate scheduler aimed at improving model performance. It does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10623",
      "abstract": "Diffusion and flow-based generative models have achieved remarkable success in domains such as image synthesis, video generation, and natural language modeling. In this work, we extend these advances to weight space learning by leveraging recent techniques to incorporate structural priors derived from optimization dynamics. Central to our approach is modeling the trajectory induced by gradient descent as a trajectory inference problem. We unify several trajectory inference techniques under the framework of gradient flow matching, providing a theoretical framework for treating optimization paths as inductive bias. We further explore architectural and algorithmic choices, including reward fine-tuning by adjoint matching, the use of autoencoders for latent weight representation, conditioning on task-specific context data, and adopting informative source distributions such as Kaiming uniform. Experiments demonstrate that our method matches or surpasses baselines in generating in-distribution weights, improves initialization for downstream training, and supports fine-tuning to enhance performance. Finally, we illustrate a practical application in safety-critical systems: detecting harmful covariate shifts, where our method outperforms the closest comparable baseline.",
      "authors": [
        "Daniel Saragih",
        "Deyu Cao",
        "Tejas Balaji"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T02:26:06+00:00",
          "link": "https://arxiv.org/abs/2507.10623v1",
          "size": "903kb",
          "version": "v1"
        }
      ],
      "title": "Flows and Diffusions on the Neural Manifold",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10623",
        "PDF": "https://arxiv.org/pdf/2507.10623"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses diffusion and flow-based models with a focus on weight space learning, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10706",
      "abstract": "Two-fold redundant sparse arrays (TFRAs) are designed to maintain accurate direction estimation even in the event of a single sensor failure, leveraging the deliberate coarray redundancy infused into their design. Robust Minimum Redundancy Arrays (RMRAs), a specialized class of TFRAs, optimize this redundancy to achieve the maximum possible aperture for a given number of sensors. However, finding optimal RMRA configurations is an NP-hard problem, with prior research reporting optimal solutions only for arrays of up to ten sensors. This paper presents newly discovered optimal RMRA configurations for array sizes 11 to 15, identified using a novel Leap-on-Success exhaustive search algorithm that efficiently reduces computational effort by terminating the search upon locating optimal solutions. The robustness of these arrays was validated under all single-element failure scenarios using MATLAB simulations, confirming their superior resilience compared to some existing TFRAs vulnerable to failures at specific sensor positions. Furthermore, near-optimal configurations for array sizes 16 to 20 are also reported, highlighting the potential applicability of the proposed method for larger array designs given sufficient computational resources. This work not only advances the state-of-the-art in RMRA design but also introduces an effective search methodology that can be leveraged for future explorations in array configuration optimization.",
      "authors": [
        "Pradyumna Kunchala and Ashish Patwari"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:20:24+00:00",
          "link": "https://arxiv.org/abs/2507.10706v1",
          "size": "860kb",
          "version": "v1"
        }
      ],
      "title": "A Leap-on-Success Exhaustive Search Method to Find Optimal Robust Minimum Redundancy Arrays (RMRAs): New Array Configurations for Sensor Counts 11 to 20",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10706",
        "PDF": "https://arxiv.org/pdf/2507.10706"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about optimal configurations for sensor arrays using search algorithms, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11301",
      "abstract": "Fluvial erosion is a natural process that can generate significant impacts on soil stability and strategic infrastructures. The detection and monitoring of this phenomenon is traditionally addressed by photogrammetric methods and analysis in geographic information systems. These tasks require specific knowledge and intensive manual processing. This study proposes an artificial intelligence-based approach for automatic identification of eroded zones and estimation of their area. The state-of-the-art computer vision model YOLOv11, adjusted by fine-tuning and trained with photographs and LiDAR images, is used. This combined dataset was segmented and labeled using the Roboflow platform. Experimental results indicate efficient detection of erosion patterns with an accuracy of 70%, precise identification of eroded areas and reliable calculation of their extent in pixels and square meters. As a final product, the EROSCAN system has been developed, an interactive web application that allows users to upload images and obtain automatic segmentations of fluvial erosion, together with the estimated area. This tool optimizes the detection and quantification of the phenomenon, facilitating decision making in risk management and territorial planning.",
      "authors": [
        "Pa\\'ul Maji",
        "Marlon T\\'uquerres",
        "Stalin Valencia",
        "Marcela Valenzuela and Christian Mejia-Escobar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:30:58+00:00",
          "link": "https://arxiv.org/abs/2507.11301v1",
          "size": "4780kb",
          "version": "v1"
        }
      ],
      "title": "Detecci\\'on y Cuantificaci\\'on de Erosi\\'on Fluvial con Visi\\'on Artificial",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11301",
        "HTML": "https://arxiv.org/html/2507.11301v1",
        "PDF": "https://arxiv.org/pdf/2507.11301"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves fine-tuning a model with a specific dataset, but its primary focus is on detecting erosion patterns using computer vision, not significantly on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.19002",
      "abstract": "Predicting the future trajectories of pedestrians on the road is an important task for autonomous driving. The pedestrian trajectory prediction is affected by scene paths, pedestrian's intentions and decision-making, which is a multi-modal problem. Most recent studies use past trajectories to predict a variety of potential future trajectory distributions, which do not account for the scene context and pedestrian targets. Instead of predicting the future trajectory directly, we propose to use scene context and observed trajectory to predict the goal points first, and then reuse the goal points to predict the future trajectories. By leveraging the information from scene context and observed trajectory, the uncertainty can be limited to a few target areas, which represent the \"goals\" of the pedestrians. In this paper, we propose GoalNet, a new trajectory prediction neural network based on the goal areas of a pedestrian. Our network can predict both pedestrian's trajectories and bounding boxes. The overall model is efficient and modular, and its outputs can be changed according to the usage scenario. Experimental results show that GoalNet significantly improves the previous state-of-the-art performance by 48.7% on the JAAD and 40.8% on the PIE dataset.",
      "authors": [
        "Amar Fadillah",
        "Ching-Lin Lee",
        "Zhi-Xuan Wang",
        "Kuan-Ting Lai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-29T09:53:19+00:00",
          "link": "https://arxiv.org/abs/2402.19002v1",
          "size": "4014kb",
          "version": "v1"
        },
        {
          "date": "2025-07-11T16:39:37+00:00",
          "link": "https://arxiv.org/abs/2402.19002v2",
          "size": "8276kb",
          "version": "v2"
        }
      ],
      "title": "GoalNet: Goal Areas Oriented Pedestrian Trajectory Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.19002",
        "HTML": "https://arxiv.org/html/2402.19002",
        "PDF": "https://arxiv.org/pdf/2402.19002"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on pedestrian trajectory prediction using neural networks and does not involve LLM training data processing or related data engineering operations."
      },
      "tasks": [
        "Autonomous Driving",
        "Decision Making",
        "Pedestrian Trajectory Prediction",
        "Prediction",
        "Trajectory Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.15511",
      "abstract": "Recent proliferation of powerful AI systems has created a strong need for capabilities that help users to calibrate trust in those systems. As AI systems grow in scale, information required to evaluate their trustworthiness becomes less accessible, presenting a growing risk of using these systems inappropriately. We propose the Trust Calibration Maturity Model (TCMM) to characterize and communicate information about AI system trustworthiness. The TCMM incorporates five dimensions of analytic maturity: Performance Characterization, Bias & Robustness Quantification, Transparency, Safety & Security, and Usability. The TCMM can be presented along with system performance information to (1) help a user to appropriately calibrate trust, (2) establish requirements and track progress, and (3) identify research needs. Here, we discuss the TCMM and demonstrate it on two target tasks: using ChatGPT for high consequence nuclear science determinations, and using PhaseNet (an ensemble of seismic models) for categorizing sources of seismic events.",
      "authors": [
        "Scott T Steinmetz",
        "Asmeret Naugle",
        "Paul Schutte",
        "Matt Sweitzer",
        "Alex Washburne",
        "Lisa Linville",
        "Daniel Krofcheck",
        "Michal Kucer",
        "Samuel Myren"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-28T17:56:57+00:00",
          "link": "https://arxiv.org/abs/2503.15511v1",
          "size": "746kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T18:58:36+00:00",
          "link": "https://arxiv.org/abs/2503.15511v2",
          "size": "806kb",
          "version": "v2"
        }
      ],
      "title": "The Trust Calibration Maturity Model for Characterizing and Communicating Trustworthiness of AI Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15511",
        "PDF": "https://arxiv.org/pdf/2503.15511"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the Trust Calibration Maturity Model for characterizing and communicating trustworthiness of AI systems, with no mention of training data processing or dataset creation for LLMs."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.02467",
      "abstract": "Program-guided reasoning has shown promise in complex claim fact-checking by decomposing claims into function calls and executing reasoning programs. However, prior work primarily relies on few-shot in-context learning (ICL) with ad-hoc demonstrations, which limit program diversity and require manual design with substantial domain knowledge. Fundamentally, the underlying principles of effective reasoning program generation still remain underexplored, making it challenging to construct effective demonstrations. To address this, we propose BOOST, a bootstrapping-based framework for few-shot reasoning program generation. BOOST explicitly integrates claim decomposition and information-gathering strategies as structural guidance for program generation, iteratively refining bootstrapped demonstrations in a strategy-driven and data-centric manner without human intervention. This enables a seamless transition from zero-shot to few-shot strategic program-guided learning, enhancing interpretability and effectiveness. Experimental results show that BOOST outperforms prior few-shot baselines in both zero-shot and few-shot settings for complex claim verification.",
      "authors": [
        "Qisheng Hu",
        "Quanyu Long",
        "Wenya Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-03T10:38:45+00:00",
          "link": "https://arxiv.org/abs/2504.02467v1",
          "size": "4594kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T05:04:03+00:00",
          "link": "https://arxiv.org/abs/2504.02467v2",
          "size": "4585kb",
          "version": "v2"
        }
      ],
      "title": "BOOST: Bootstrapping Strategy-Driven Reasoning Programs for Program-Guided Fact-Checking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.02467",
        "HTML": "https://arxiv.org/html/2504.02467v2",
        "PDF": "https://arxiv.org/pdf/2504.02467"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a bootstrapping framework for few-shot reasoning program generation for fact-checking, without discussing any aspects of LLM training data collection, processing, or engineering."
      },
      "tasks": [
        "Claim Verification",
        "Diversity",
        "Fact Checking",
        "In-Context Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.00838",
      "abstract": "The paper explores stylometry as a method to distinguish between texts created by Large Language Models (LLMs) and humans, addressing issues of model attribution, intellectual property, and ethical AI use. Stylometry has been used extensively to characterise the style and attribute authorship of texts. By applying it to LLM-generated texts, we identify their emergent writing patterns. The paper involves creating a benchmark dataset based on Wikipedia, with (a) human-written term summaries, (b) texts generated purely by LLMs (GPT-3.5/4, LLaMa 2/3, Orca, and Falcon), (c) processed through multiple text summarisation methods (T5, BART, Gensim, and Sumy), and (d) rephrasing methods (Dipper, T5). The 10-sentence long texts were classified by tree-based models (decision trees and LightGBM) using human-designed (StyloMetrix) and n-gram-based (our own pipeline) stylometric features that encode lexical, grammatical, syntactic, and punctuation patterns. The cross-validated results reached a performance of up to .87 Matthews correlation coefficient in the multiclass scenario with 7 classes, and accuracy between .79 and 1. in binary classification, with the particular example of Wikipedia and GPT-4 reaching up to .98 accuracy on a balanced dataset. Shapley Additive Explanations pinpointed features characteristic of the encyclopaedic text type, individual overused words, as well as a greater grammatical standardisation of LLMs with respect to human-written texts. These results show -- crucially, in the context of the increasingly sophisticated LLMs -- that it is possible to distinguish machine- from human-generated texts at least for a well-defined text type.",
      "authors": [
        "Karol Przystalski",
        "Jan K. Argasi\\'nski",
        "Iwona Grabska-Gradzi\\'nska",
        "Jeremi K. Ochab"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T15:08:53+00:00",
          "link": "https://arxiv.org/abs/2507.00838v1",
          "size": "937kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T11:31:45+00:00",
          "link": "https://arxiv.org/abs/2507.00838v2",
          "size": "933kb",
          "version": "v2"
        }
      ],
      "title": "Stylometry recognizes human and LLM-generated texts in short samples",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00838",
        "HTML": "https://arxiv.org/html/2507.00838v2",
        "PDF": "https://arxiv.org/pdf/2507.00838"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper involves creating a dataset to classify texts as human or LLM-generated, its primary focus is on using stylometry for text classification, rather than on the creation or processing of LLM training data itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10840",
      "abstract": "Given a set $A$ of $n$ points (vertices) in general position in the plane, the \\emph{complete geometric graph} $K_n[A]$ consists of all ${n\\choose 2}$ segments (edges) between the elements of $A$. It is known that the edge set of every complete geometric graph on $n$ vertices can be partitioned into $O(n^{3/2})$ noncrossing paths (or matchings). We strengthen this result under various additional assumptions on the point set. In particular, we prove that for a set $A$ of $n$ \\emph{randomly} selected points, uniformly distributed in $[0,1]^2$, with probability tending to $1$ as $n\\rightarrow\\infty$, the edge set of $K_n[A]$ can be covered by $O(n^{4/3} t(n))$ noncrossing paths (or matchings), where $t(n)$ is any function tending to $\\infty$. On the other hand, we construct $n$-element point sets such that covering the edge set of $K_n(A)$ requires a quadratic number of monotone paths.",
      "authors": [
        "Adrian Dumitrescu and J\\'anos Pach and Morteza Saghafian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T22:19:40+00:00",
          "link": "https://arxiv.org/abs/2507.10840v1",
          "size": "1077kb",
          "version": "v1"
        }
      ],
      "title": "Covering Complete Geometric Graphs by Monotone Paths",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10840",
        "HTML": "https://arxiv.org/html/2507.10840v1",
        "PDF": "https://arxiv.org/pdf/2507.10840"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates properties of geometric graphs and does not involve the processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11192",
      "abstract": "The detection of gravitational waves by the LIGO-Virgo-KAGRA collaboration has ushered in a new era of observational astronomy, emphasizing the need for rapid and detailed parameter estimation and population-level analyses. Traditional Bayesian inference methods, particularly Markov chain Monte Carlo, face significant computational challenges when dealing with the high-dimensional parameter spaces and complex noise characteristics inherent in gravitational wave data. This review examines the emerging role of simulation-based inference methods in gravitational wave astronomy, with a focus on approaches that leverage machine-learning techniques such as normalizing flows and neural posterior estimation. We provide a comprehensive overview of the theoretical foundations underlying various simulation-based inference methods, including neural posterior estimation, neural ratio estimation, neural likelihood estimation, flow matching, and consistency models. We explore the applications of these methods across diverse gravitational wave data processing scenarios, from single-source parameter estimation and overlapping signal analysis to testing general relativity and conducting population studies. Although these techniques demonstrate speed improvements over traditional methods in controlled studies, their model-dependent nature and sensitivity to prior assumptions are barriers to their widespread adoption. Their accuracy, which is similar to that of conventional methods, requires further validation across broader parameter spaces and noise conditions.",
      "authors": [
        "Bo Liang",
        "He Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "General Relativity and Quantum Cosmology (gr-qc)",
        "High Energy Astrophysical Phenomena (astro-ph.HE)",
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:52:57+00:00",
          "link": "https://arxiv.org/abs/2507.11192v1",
          "size": "1358kb",
          "version": "v1"
        }
      ],
      "title": "Recent Advances in Simulation-based Inference for Gravitational Wave Data Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11192",
        "HTML": "https://arxiv.org/html/2507.11192v1",
        "PDF": "https://arxiv.org/pdf/2507.11192"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Examines simulation-based inference techniques in gravitational wave data analysis, with no focus on LLM training data handling or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2309.11622",
      "abstract": "Control and state estimation procedures need to be robust against imprecisely known parameters, uncertainty in initial conditions, and external disturbances. Interval methods and other set-based techniques form the basis for the implementation of powerful approaches that can be used to identify parameters of dynamic system models in the presence of the aforementioned types of uncertainty. Moreover, they are applicable to a verified feasibility and stability analysis of controllers and state estimators. In addition to these approaches which are typically used offline for analysis of system models designed with classical floating point procedures, interval and set-based methods have also been developed in recent years, which allow to directly solve the associated design tasks and to implement reliable techniques that are applicable online, i.e., during system operation. The latter approaches include set-based model predictive control, online parameter adaptation techniques for nonlinear variable-structure and backstepping controllers, interval observers, and fault diagnosis techniques. This paper provides an overview of the methodological background and reviews numerous practical applications for which interval and other set-valued approaches have been employed successfully.",
      "authors": [
        "Andreas Rauh",
        "Marit Lahme",
        "Simon Rohou",
        "Luc Jaulin",
        "Thach Ngoc Dinh",
        "Tarek Raissi",
        "Mohamed Fnadi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-20T20:20:36+00:00",
          "link": "https://arxiv.org/abs/2309.11622v1",
          "size": "1792kb",
          "version": "v1"
        },
        {
          "date": "2024-08-11T20:48:25+00:00",
          "link": "https://arxiv.org/abs/2309.11622v2",
          "size": "2321kb",
          "version": "v2"
        },
        {
          "date": "2025-04-28T21:09:16+00:00",
          "link": "https://arxiv.org/abs/2309.11622v3",
          "size": "2322kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T23:09:36+00:00",
          "link": "https://arxiv.org/abs/2309.11622v4",
          "size": "2321kb",
          "version": "v4"
        }
      ],
      "title": "Offline and Online Use of Interval and Set-Based Approaches for Control and State Estimation: A Selection of Methodological Approaches and Their Application",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.11622",
        "HTML": "https://arxiv.org/html/2309.11622v4",
        "PDF": "https://arxiv.org/pdf/2309.11622"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on control and state estimation using interval methods, without mentioning any LLM training data collection or processing."
      },
      "tasks": [
        "Fault Diagnosis",
        "Model Predictive Control",
        "State Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09060",
      "abstract": "Datasets play a central role in AI governance by enabling both evaluation (measuring capabilities) and alignment (enforcing values) along axes such as helpfulness, harmlessness, toxicity, quality, and more. However, most alignment and evaluation datasets depend on researcher-defined or developer-defined axes curated from non-representative samples. As a result, developers typically benchmark models against broad (often Western-centric) values that overlook the varied contexts of their real-world deployment. Consequently, models trained on such proxies can fail to meet the needs and expectations of diverse user communities within these deployment contexts. To bridge this gap, we introduce CALMA (Context-aligned Axes for Language Model Alignment), a grounded, participatory methodology for eliciting context-relevant axes for evaluation and alignment. In a pilot with two distinct communities, CALMA surfaced novel priorities that are absent from standard benchmarks. Our findings demonstrate the value of evaluation practices based on open-ended and use-case-driven processes. Our work advances the development of pluralistic, transparent, and context-sensitive alignment pipelines.",
      "authors": [
        "Prajna Soni",
        "Deepika Raman",
        "Dylan Hadfield-Menell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T22:33:11+00:00",
          "link": "https://arxiv.org/abs/2507.09060v1",
          "size": "118kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T17:48:41+00:00",
          "link": "https://arxiv.org/abs/2507.09060v2",
          "size": "118kb",
          "version": "v2"
        }
      ],
      "title": "CALMA: A Process for Deriving Context-aligned Axes for Language Model Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09060",
        "HTML": "https://arxiv.org/html/2507.09060v2",
        "PDF": "https://arxiv.org/pdf/2507.09060"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces CALMA, a methodology for deriving context-sensitive axes for LLM evaluation and alignment, focusing on developing datasets that reflect diverse user contexts, which directly relates to dataset creation and processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10592",
      "abstract": "This experiment breaks a 5-bit elliptic curve cryptographic key using a Shor-style quantum attack. Executed on IBM's 133-qubit ibm_torino with Qiskit Runtime 2.0, a 15-qubit circuit, comprised of 10 logical qubits and 5 ancilla, interferes over an order-32 elliptic curve subgroup to extract the secret scalar k from the public key relation Q = kP, without ever encoding k directly into the oracle. From 16,384 shots, the quantum interference reveals a diagonal ridge in the 32 x 32 QFT outcome space. The quantum circuit, over 67,000 layers deep, produced valid interference patterns despite extreme circuit depth, and classical post-processing revealed k = 7 in the top 100 invertible (a, b) results. All code, circuits, and raw data are publicly available for replication.",
      "authors": [
        "Steve Tippeconnic"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T19:32:38+00:00",
          "link": "https://arxiv.org/abs/2507.10592v1",
          "size": "1470kb",
          "version": "v1"
        }
      ],
      "title": "Breaking a 5-Bit Elliptic Curve Key using a 133-Qubit Quantum Computer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10592",
        "PDF": "https://arxiv.org/pdf/2507.10592"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about using quantum computing to break elliptic curve cryptographic keys and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11262",
      "abstract": "Training deep neural networks, particularly in computer vision tasks, often suffers from noisy gradients and unstable convergence, which hinder performance and generalization. In this paper, we propose LyAm, a novel optimizer that integrates Adam's adaptive moment estimation with Lyapunov-based stability mechanisms. LyAm dynamically adjusts the learning rate using Lyapunov stability theory to enhance convergence robustness and mitigate training noise. We provide a rigorous theoretical framework proving the convergence guarantees of LyAm in complex, non-convex settings. Extensive experiments on like as CIFAR-10 and CIFAR-100 show that LyAm consistently outperforms state-of-the-art optimizers in terms of accuracy, convergence speed, and stability, establishing it as a strong candidate for robust deep learning optimization.",
      "authors": [
        "Elmira Mirzabeigi",
        "Sepehr Rezaee",
        "Kourosh Parand"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:35:13+00:00",
          "link": "https://arxiv.org/abs/2507.11262v1",
          "size": "740kb",
          "version": "v1"
        }
      ],
      "title": "LyAm: Robust Non-Convex Optimization for Stable Learning in Noisy Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11262",
        "HTML": "https://arxiv.org/html/2507.11262v1",
        "PDF": "https://arxiv.org/pdf/2507.11262"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing a novel optimizer, LyAm, and enhancing optimizer stability for training neural networks, without discussing any aspects of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2111.06614",
      "abstract": "To effectively operate in various dynamic scenarios, RL agents must be resilient to unexpected changes in their environment. Previous work on this form of resilience has focused on single-agent settings. In this work, we introduce and formalize a multi-agent variant of resilience, which we term group resilience. We further hypothesize that collaboration with other agents is key to achieving group resilience; collaborating agents adapt better to environmental perturbations in multi-agent reinforcement learning (MARL) settings. We test our hypothesis empirically by evaluating different collaboration protocols and examining their effect on group resilience. Our experiments show that all the examined collaborative approaches achieve higher group resilience than their non-collaborative counterparts.",
      "authors": [
        "Sarah Keren",
        "Matthias Gerstgrasser",
        "Ofir Abu and Jeffrey Rosenschein"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2021-11-12T09:03:19+00:00",
          "link": "https://arxiv.org/abs/2111.06614v1",
          "size": "663kb",
          "version": "v1"
        },
        {
          "date": "2022-12-09T22:14:28+00:00",
          "link": "https://arxiv.org/abs/2111.06614v2",
          "size": "1162kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T07:57:25+00:00",
          "link": "https://arxiv.org/abs/2111.06614v3",
          "size": "1052kb",
          "version": "v3"
        }
      ],
      "title": "Collaboration Promotes Group Resilience in Multi-Agent AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2111.06614",
        "HTML": "https://arxiv.org/html/2111.06614",
        "PDF": "https://arxiv.org/pdf/2111.06614"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on multi-agent reinforcement learning and group resilience, without mention or contribution to LLM training data processing or engineering."
      },
      "tasks": [
        "Multi-agent Reinforcement Learning",
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.14442",
      "abstract": "Convergence of Q-learning has been the focus of extensive research over the past several decades. Recently, an asymptotic convergence analysis for Q-learning was introduced using a switching system framework. This approach applies the so-called ordinary differential equation (ODE) approach to prove the convergence of the asynchronous Q-learning modeled as a continuous-time switching system, where notions from switching system theory are used to prove its asymptotic stability without using explicit Lyapunov arguments. However, to prove stability, restrictive conditions, such as quasi-monotonicity, must be satisfied for the underlying switching systems, which makes it hard to easily generalize the analysis method to other reinforcement learning algorithms, such as the smooth Q-learning variants. In this paper, we present a more general and unified convergence analysis that improves upon the switching system approach and can analyze Q-learning and its smooth variants. The proposed analysis is motivated by previous work on the convergence of synchronous Q-learning based on $p$-norm serving as a Lyapunov function. However, the proposed analysis addresses more general ODE models that can cover both asynchronous Q-learning and its smooth versions with simpler frameworks.",
      "authors": [
        "Donghwan Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-20T01:16:27+00:00",
          "link": "https://arxiv.org/abs/2404.14442v1",
          "size": "17kb",
          "version": "v1"
        },
        {
          "date": "2024-04-24T04:22:51+00:00",
          "link": "https://arxiv.org/abs/2404.14442v2",
          "size": "17kb",
          "version": "v2"
        },
        {
          "date": "2025-03-28T11:38:47+00:00",
          "link": "https://arxiv.org/abs/2404.14442v3",
          "size": "22kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T04:14:38+00:00",
          "link": "https://arxiv.org/abs/2404.14442v4",
          "size": "22kb",
          "version": "v4"
        }
      ],
      "title": "Unified ODE Analysis of Smooth Q-Learning Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.14442",
        "HTML": "https://arxiv.org/html/2404.14442v4",
        "PDF": "https://arxiv.org/pdf/2404.14442"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with Q-learning convergence analysis and does not address LLM training data processing."
      },
      "tasks": [
        "Q-Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10446",
      "abstract": "The ability to transfer knowledge from prior experiences to novel tasks stands as a pivotal capability of intelligent agents, including both humans and computational models. This principle forms the basis of transfer learning, where large pre-trained neural networks are fine-tuned to adapt to downstream tasks. Transfer learning has demonstrated tremendous success, both in terms of task adaptation speed and performance. However there are several domains where, due to lack of data, training such large pre-trained models or foundational models is not a possibility - computational chemistry, computational immunology, and medical imaging are examples. To address these challenges, our work focuses on designing architectures to enable efficient acquisition of priors when large amounts of data are unavailable. In particular, we demonstrate that we can use neural memory to enable adaptation on non-stationary distributions with only a few samples. Then we demonstrate that our hypernetwork designs (a network that generates another network) can acquire more generalizable priors than standard networks when trained with Model Agnostic Meta-Learning (MAML). Subsequently, we apply hypernetworks to 3D scene generation, demonstrating that they can acquire priors efficiently on just a handful of training scenes, thereby leading to faster text-to-3D generation. We then extend our hypernetwork framework to perform 3D segmentation on novel scenes with limited data by efficiently transferring priors from earlier viewed scenes. Finally, we repurpose an existing molecular generative method as a pre-training framework that facilitates improved molecular property prediction, addressing critical challenges in computational immunology.",
      "authors": [
        "Sudarshan Babu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T18:48:09+00:00",
          "link": "https://arxiv.org/abs/2507.10446v1",
          "size": "13172kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T02:06:07+00:00",
          "link": "https://arxiv.org/abs/2507.10446v2",
          "size": "13168kb",
          "version": "v2"
        }
      ],
      "title": "Acquiring and Adapting Priors for Novel Tasks via Neural Meta-Architectures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10446",
        "HTML": "https://arxiv.org/html/2507.10446v2",
        "PDF": "https://arxiv.org/pdf/2507.10446"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses transfer learning and creating priors with limited data, but it does not focus primarily on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10578",
      "abstract": "Poisoning attacks pose significant challenges to the robustness of diffusion models (DMs). In this paper, we systematically analyze when and where poisoning attacks textual inversion (TI), a widely used personalization technique for DMs. We first introduce Semantic Sensitivity Maps, a novel method for visualizing the influence of poisoning on text embeddings. Second, we identify and experimentally verify that DMs exhibit non-uniform learning behavior across timesteps, focusing on lower-noise samples. Poisoning attacks inherit this bias and inject adversarial signals predominantly at lower timesteps. Lastly, we observe that adversarial signals distract learning away from relevant concept regions within training data, corrupting the TI process. Based on these insights, we propose Safe-Zone Training (SZT), a novel defense mechanism comprised of 3 key components: (1) JPEG compression to weaken high-frequency poison signals, (2) restriction to high timesteps during TI training to avoid adversarial signals at lower timesteps, and (3) loss masking to constrain learning to relevant regions. Extensive experiments across multiple poisoning methods demonstrate that SZT greatly enhances the robustness of TI against all poisoning attacks, improving generative quality beyond prior published defenses. Code: www.github.com/JStyborski/Diff_Lab Data: www.github.com/JStyborski/NC10",
      "authors": [
        "Jeremy Styborski",
        "Mingzhi Lyu",
        "Jiayou Lu",
        "Nupur Kapur",
        "Adams Kong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T10:35:52+00:00",
          "link": "https://arxiv.org/abs/2507.10578v1",
          "size": "25347kb",
          "version": "v1"
        }
      ],
      "title": "When and Where do Data Poisons Attack Textual Inversion?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10578",
        "HTML": "https://arxiv.org/html/2507.10578v1",
        "PDF": "https://arxiv.org/pdf/2507.10578"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes poisoning attacks on diffusion models and proposes a defense mechanism. It does not focus on training data processing for LLMs or data quality improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11502",
      "abstract": "This paper presents the development of HKGAI-V1, a foundational sovereign large language model (LLM), developed as part of an initiative to establish value-aligned AI infrastructure specifically tailored for Hong Kong. Addressing the region's unique multilingual environment (Cantonese, Mandarin, and English), its distinct socio-legal context under the \"one country, two systems\" framework, and specific local cultural and value considerations, the model is built upon the DeepSeek architecture and systematically aligned with regional norms through a multifaceted full parameter fine-tuning process. It is further integrated with a retrieval-augmented generation (RAG) system to ensure timely and factually grounded information access. The core contribution lies in the design and implementation of a comprehensive, region-specific AI alignment and safety framework, demonstrated through two key achievements: 1) The successful development of HKGAI-V1 itself - which outper-forms general-purpose models in handling Hong Kong-specific culturally sensitive queries, and embodies a \"governance-embedded\" approach to digital sovereignty - empowers Hong Kong to exercise control over AI applications in critical sectors including public services, legal systems, and edu-cation. 2) The development of the proprietary Adversarial HK Value Benchmark, a rigorous tool for evaluating model alignment with local ethical and legal stand-ards under challenging conditions. By documenting these achievements, the paper provides not only a technological artifact but also a replicable blueprint for developing advanced, regionally focused AI systems deeply rooted in their local identities.",
      "authors": [
        "Sirui Han",
        "Junqi Zhu",
        "Ruiyuan Zhang",
        "Yike Guo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T15:09:05+00:00",
          "link": "https://arxiv.org/abs/2507.11502v1",
          "size": "1092kb",
          "version": "v1"
        }
      ],
      "title": "HKGAI-V1: Towards Regional Sovereign Large Language Model for Hong Kong",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11502",
        "PDF": "https://arxiv.org/pdf/2507.11502"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a regional LLM and its model alignment with local standards, but does not discuss training data processing or dataset creation in detail."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.05424",
      "abstract": "Efficiency is essential to support ever-growing datasets, especially for Deep Learning (DL) systems. DL frameworks have traditionally embraced deferred execution-style DL code -- supporting symbolic, graph-based Deep Neural Network (DNN) computation. While scalable, such development is error-prone, non-intuitive, and difficult to debug. Consequently, more natural, imperative DL frameworks encouraging eager execution have emerged but at the expense of run-time performance. Though hybrid approaches aim for the \"best of both worlds,\" using them effectively requires subtle considerations. Our key insight is that, while DL programs typically execute sequentially, hybridizing imperative DL code resembles parallelizing sequential code in traditional systems. Inspired by this, we present an automated refactoring approach that assists developers in determining which otherwise eagerly-executed imperative DL functions could be effectively and efficiently executed as graphs. The approach features novel static imperative tensor and side-effect analyses for Python. Due to its inherent dynamism, analyzing Python may be unsound; however, the conservative approach leverages a speculative (keyword-based) analysis for resolving difficult cases that informs developers of any assumptions made. The approach is: (i) implemented as a plug-in to the PyDev Eclipse IDE that integrates the WALA Ariadne analysis framework and (ii) evaluated on nineteen DL projects consisting of 132 KLOC. The results show that 326 of 766 candidate functions (42.56%) were refactorable, and an average relative speedup of 2.16 on performance tests was observed with negligible differences in model accuracy. The results indicate that the approach is useful in optimizing imperative DL code to its full potential.",
      "authors": [
        "Raffi Khatchadourian",
        "Tatiana Castro V\\'elez",
        "Mehdi Bagherzadeh",
        "Nan Jia",
        "Anita Raja"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-07T18:48:43+00:00",
          "link": "https://arxiv.org/abs/2504.05424v1",
          "size": "728kb",
          "version": "v1"
        },
        {
          "date": "2025-06-03T15:01:43+00:00",
          "link": "https://arxiv.org/abs/2504.05424v2",
          "size": "315kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T18:38:11+00:00",
          "link": "https://arxiv.org/abs/2504.05424v3",
          "size": "315kb",
          "version": "v3"
        }
      ],
      "title": "Speculative Automated Refactoring of Imperative Deep Learning Programs to Graph Execution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.05424",
        "PDF": "https://arxiv.org/pdf/2504.05424"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper concentrates on automated refactoring of DL code for execution efficiency and does not involve any LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.10963",
      "abstract": "Videos offer rich audiovisual information that can support people in performing activities of daily living (ADLs), but they remain largely inaccessible to blind or low-vision (BLV) individuals. In cooking, BLV people often rely on non-visual cues, such as touch, taste, and smell, to navigate their environment, making it difficult to follow the predominantly audiovisual instructions found in video recipes. To address this problem, we introduce AROMA, an AI system that provides timely responses to the user based on real-time, context-aware assistance by integrating non-visual cues perceived by the user, a wearable camera feed, and video recipe content. AROMA uses a mixed-initiative approach: it responds to user requests while also proactively monitoring the video stream to offer timely alerts and guidance. This collaborative design leverages the complementary strengths of the user and AI system to align the physical environment with the video recipe, helping the user interpret their current cooking state and make sense of the steps. We evaluated AROMA through a study with eight BLV participants and offered insights for designing interactive AI systems to support BLV individuals in performing ADLs.",
      "authors": [
        "Zheng Ning",
        "Leyang Li",
        "Daniel Killough",
        "JooYoung Seo",
        "Patrick Carrington",
        "Yapeng Tian",
        "Yuhang Zhao",
        "Franklin Mingzhe Li",
        "and Toby Jia-Jun Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T03:58:28+00:00",
          "link": "https://arxiv.org/abs/2507.10963v1",
          "size": "6659kb",
          "version": "v1"
        }
      ],
      "title": "AROMA: Mixed-Initiative AI Assistance for Non-Visual Cooking by Grounding Multi-modal Information Between Reality and Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10963",
        "HTML": "https://arxiv.org/html/2507.10963v1",
        "PDF": "https://arxiv.org/pdf/2507.10963"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on AI assistance for non-visual cooking, integrating sensory inputs and video recipes, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.10270",
      "abstract": "Given an $\\mathbb{N}$-weighted tree automaton, we give a decision procedure for exponential vs polynomial growth (with respect to the input size) in quadratic time, and an algorithm that computes the exact polynomial degree of growth in cubic time. As a special case, they apply to the growth of the ambiguity of a nondeterministic tree automaton, i.e. the number of distinct accepting runs over a given input. Our time complexities match the recent fine-grained lower bounds for these problems restricted to ambiguity of word automata.\n  We deduce analogous decidability results (ignoring complexity) for the growth of the number of results of set queries in Monadic Second-Order logic (MSO) over ranked trees. In the case of polynomial growth of degree $k$, we also prove a reparameterization theorem for such queries: their results can be mapped to $k$-tuples of input nodes in a finite-to-one and MSO-definable fashion.\n  This property of MSO set queries leads directly to a generalization of the dimension minimization theorem for string-to-string polyregular functions. Our generalization applies to MSO set interpretations from trees, which subsume (as we show) tree-walking tree transducers and invisible pebble tree-to-string transducers. Finally, with a bit more work we obtain the following:\n  * a new, short and conceptual proof that macro tree transducers of linear growth compute only tree-to-tree MSO transductions;\n  * a procedure to decide polynomial size-to-height increase for both macro tree transducers and MSO set interpretations, and compute the degree.\n  The paper concludes with a survey of a wide range of related work, with over a hundred references.",
      "authors": [
        "Paul Gallot",
        "Nathan Lhote",
        "L\\^e Th\\`anh D\\~ung Nguy\\^en"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-17T15:57:21+00:00",
          "link": "https://arxiv.org/abs/2501.10270v1",
          "size": "53kb",
          "version": "v1"
        },
        {
          "date": "2025-03-12T15:30:15+00:00",
          "link": "https://arxiv.org/abs/2501.10270v2",
          "size": "263kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T15:22:49+00:00",
          "link": "https://arxiv.org/abs/2501.10270v3",
          "size": "148kb",
          "version": "v3"
        }
      ],
      "title": "The structure of polynomial growth for tree automata/transducers and MSO set queries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.10270",
        "HTML": "https://arxiv.org/html/2501.10270v3",
        "PDF": "https://arxiv.org/pdf/2501.10270"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on decision procedures for tree automata and MSO set queries regarding polynomial growth, with no mention of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.00582",
      "abstract": "Fine-tuning large language models (LLMs) is difficult due to their huge model size. Recent Fourier domain-based methods show potential for reducing fine-tuning costs. We propose a block circulant matrix-based fine-tuning method with a stable training heuristic to leverage the properties of circulant matrices and one-dimensional Fourier transforms to reduce storage and computation costs. Experiments show that our method uses $14\\times$ less number of parameters than VeRA, $16\\times$ smaller than LoRA and $32\\times$ less FLOPs than FourierFT, while maintaining close or better task performance. Our approach presents a promising way in frequency domain to fine-tune large models on downstream tasks.",
      "authors": [
        "Xinyu Ding",
        "Meiqi Wang",
        "Siyu Liao",
        "Zhongfeng Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-01T15:14:32+00:00",
          "link": "https://arxiv.org/abs/2505.00582v1",
          "size": "154kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T12:40:48+00:00",
          "link": "https://arxiv.org/abs/2505.00582v2",
          "size": "145kb",
          "version": "v2"
        }
      ],
      "title": "Block Circulant Adapter for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00582",
        "HTML": "https://arxiv.org/html/2505.00582v2",
        "PDF": "https://arxiv.org/pdf/2505.00582"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "Like the previous paper, this one discusses fine-tuning large language models focusing on parameter efficiency using block circulant matrices, but it does not address training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.04980",
      "abstract": "This paper proposes a novel Large Vision-Language Model (LVLM) and Model Predictive Control (MPC) integration framework that delivers both task scalability and safety for Autonomous Driving (AD). LVLMs excel at high-level task planning across diverse driving scenarios. However, since these foundation models are not specifically designed for driving and their reasoning is not consistent with the feasibility of low-level motion planning, concerns remain regarding safety and smooth task switching. This paper integrates LVLMs with MPC Builder, which automatically generates MPCs on demand, based on symbolic task commands generated by the LVLM, while ensuring optimality and safety. The generated MPCs can strongly assist the execution or rejection of LVLM-driven task switching by providing feedback on the feasibility of the given tasks and generating task-switching-aware MPCs. Our approach provides a safe, flexible, and adaptable control framework, bridging the gap between cutting-edge foundation models and reliable vehicle operation. We demonstrate the effectiveness of our approach through a simulation experiment, showing that our system can safely and effectively handle highway driving while maintaining the flexibility and adaptability of LVLMs.",
      "authors": [
        "Kazuki Atsuta",
        "Kohei Honda",
        "Hiroyuki Okuda",
        "Tatsuya Suzuki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-08T06:35:30+00:00",
          "link": "https://arxiv.org/abs/2505.04980v1",
          "size": "568kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T04:35:23+00:00",
          "link": "https://arxiv.org/abs/2505.04980v2",
          "size": "568kb",
          "version": "v2"
        }
      ],
      "title": "LVLM-MPC Collaboration for Autonomous Driving: A Safety-Aware and Task-Scalable Control Architecture",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.04980",
        "HTML": "https://arxiv.org/html/2505.04980v2",
        "PDF": "https://arxiv.org/pdf/2505.04980"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on integrating a Large Vision-Language Model with Model Predictive Control for autonomous driving, emphasizing task scalability and safety rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10586",
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable fluency across a range of natural language tasks, yet remain vulnerable to hallucinations - factual inaccuracies that undermine trust in real world deployment. We present AutoRAG-LoRA, a modular framework for Retrieval-Augmented Generation (RAG) that tackles hallucination in large language models through lightweight LoRA-based adapters and KL-regularized training. Our pipeline integrates automated prompt rewriting, hybrid retrieval, and low-rank adapter tuning to ground responses in retrieved evidence. A hallucination detection module, using both classifier-based and self-evaluation techniques, assigns confidence scores to generated outputs, triggering an optional feedback correction loop. This loop enforces factual alignment via contrastive KL loss and adapter fine tuning. We demonstrate that AutoRAG-LoRA significantly reduces the factual drift while preserving the efficiency and modularity of the model.",
      "authors": [
        "Kaushik Dwivedi",
        "Padmanabh Patanjali Mishra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T14:02:58+00:00",
          "link": "https://arxiv.org/abs/2507.10586v1",
          "size": "266kb",
          "version": "v1"
        }
      ],
      "title": "AutoRAG-LoRA: Hallucination-Triggered Knowledge Retuning via Lightweight Adapters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10586",
        "HTML": "https://arxiv.org/html/2507.10586v1",
        "PDF": "https://arxiv.org/pdf/2507.10586"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper presents a modular framework for mitigating hallucinations in LLMs with adapters, it focuses on model tuning and generation rather than LLM data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10772",
      "abstract": "Labeled property graphs often contain rich textual attributes that can enhance analytical tasks when properly leveraged. This work explores the use of pretrained text embedding models to enable efficient semantic analysis in such graphs. By embedding textual node and edge properties, we support downstream tasks including node classification and relation prediction with improved contextual understanding. Our approach integrates language model embeddings into the graph pipeline without altering its structure, demonstrating that textual semantics can significantly enhance the accuracy and interpretability of property graph analysis.",
      "authors": [
        "Michal Podstawski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:53:56+00:00",
          "link": "https://arxiv.org/abs/2507.10772v1",
          "size": "12kb",
          "version": "v1"
        }
      ],
      "title": "Applying Text Embedding Models for Efficient Analysis in Labeled Property Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10772",
        "HTML": "https://arxiv.org/html/2507.10772v1",
        "PDF": "https://arxiv.org/pdf/2507.10772"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses using text embedding models for semantic analysis in labeled property graphs, not involving LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10946",
      "abstract": "We study the problem of solving linear programs of the form $Ax\\le b$, $x\\ge0$ with differential privacy. For homogeneous LPs $Ax\\ge0$, we give an efficient $(\\epsilon,\\delta)$-differentially private algorithm which with probability at least $1-\\beta$ finds in polynomial time a solution that satisfies all but $O(\\frac{d^{2}}{\\epsilon}\\log^{2}\\frac{d}{\\delta\\beta}\\sqrt{\\log\\frac{1}{\\rho_{0}}})$ constraints, for problems with margin $\\rho_{0}>0$. This improves the bound of $O(\\frac{d^{5}}{\\epsilon}\\log^{1.5}\\frac{1}{\\rho_{0}}\\mathrm{poly}\\log(d,\\frac{1}{\\delta},\\frac{1}{\\beta}))$ by [Kaplan-Mansour-Moran-Stemmer-Tur, STOC '25]. For general LPs $Ax\\le b$, $x\\ge0$ with potentially zero margin, we give an efficient $(\\epsilon,\\delta)$-differentially private algorithm that w.h.p drops $O(\\frac{d^{4}}{\\epsilon}\\log^{2.5}\\frac{d}{\\delta}\\sqrt{\\log dU})$ constraints, where $U$ is an upper bound for the entries of $A$ and $b$ in absolute value. This improves the result by Kaplan et al. by at least a factor of $d^{5}$. Our techniques build upon privatizing a rescaling perceptron algorithm by [Hoberg-Rothvoss, IPCO '17] and a more refined iterative procedure for identifying equality constraints by Kaplan et al.",
      "authors": [
        "Alina Ene",
        "Huy Le Nguyen",
        "Ta Duy Nguyen",
        "Adrian Vladu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T03:22:47+00:00",
          "link": "https://arxiv.org/abs/2507.10946v1",
          "size": "18kb",
          "version": "v1"
        }
      ],
      "title": "Solving Linear Programs with Differential Privacy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10946",
        "PDF": "https://arxiv.org/pdf/2507.10946"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on solving linear programs with differential privacy, and does not discuss topics related to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07487",
      "abstract": "Autonomous vehicles rely on global standard-definition (SD) maps for road-level route planning and online local high-definition (HD) maps for lane-level navigation. However, recent work concentrates on construct online HD maps, often overlooking the association of global SD maps with online HD maps for hybrid navigation, making challenges in utilizing online HD maps in the real world. Observing the lack of the capability of autonomous vehicles in navigation, we introduce \\textbf{O}nline \\textbf{M}ap \\textbf{A}ssociation, the first benchmark for the association of hybrid navigation-oriented online maps, which enhances the planning capabilities of autonomous vehicles. Based on existing datasets, the OMA contains 480k of roads and 260k of lane paths and provides the corresponding metrics to evaluate the performance of the model. Additionally, we propose a novel framework, named Map Association Transformer, as the baseline method, using path-aware attention and spatial attention mechanisms to enable the understanding of geometric and topological correspondences. The code and dataset can be accessed at https://github.com/WallelWan/OMA-MAT.",
      "authors": [
        "Jiaxu Wan",
        "Xu Wang",
        "Mengwei Xie",
        "Xinyuan Chang",
        "Xinran Liu",
        "Zheng Pan",
        "Mu Xu and Ding Yuan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T07:16:00+00:00",
          "link": "https://arxiv.org/abs/2507.07487v1",
          "size": "7566kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T08:09:41+00:00",
          "link": "https://arxiv.org/abs/2507.07487v2",
          "size": "7569kb",
          "version": "v2"
        }
      ],
      "title": "Driving by Hybrid Navigation: An Online HD-SD Map Association Framework and Benchmark for Autonomous Vehicles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07487",
        "HTML": "https://arxiv.org/html/2507.07487v2",
        "PDF": "https://arxiv.org/pdf/2507.07487"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the construction and benchmarking of maps for autonomous vehicles, which does not relate to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10574",
      "abstract": "We propose the Linearly Adaptive Cross Entropy Loss function. This is a novel measure derived from the information theory. In comparison to the standard cross entropy loss function, the proposed one has an additional term that depends on the predicted probability of the true class. This feature serves to enhance the optimization process in classification tasks involving one-hot encoded class labels. The proposed one has been evaluated on a ResNet-based model using the CIFAR-100 dataset. Preliminary results show that the proposed one consistently outperforms the standard cross entropy loss function in terms of classification accuracy. Moreover, the proposed one maintains simplicity, achieving practically the same efficiency to the traditional cross entropy loss. These findings suggest that our approach could broaden the scope for future research into loss function design.",
      "authors": [
        "Jae Wan Shim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T16:38:57+00:00",
          "link": "https://arxiv.org/abs/2507.10574v1",
          "size": "52kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Cross Entropy with a Linearly Adaptive Loss Function for Optimized Classification Performance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10574",
        "HTML": "https://arxiv.org/html/2507.10574v1",
        "PDF": "https://arxiv.org/pdf/2507.10574"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on proposing a novel loss function for classification tasks and evaluates it on a ResNet-based model with the CIFAR-100 dataset. There is no discussion on LLM training data processing or improvement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11323",
      "abstract": "Contestable AI requires that AI-driven decisions align with human preferences. While various forms of argumentation have been shown to support contestability, Edge-Weighted Quantitative Bipolar Argumentation Frameworks (EW-QBAFs) have received little attention. In this work, we show how EW-QBAFs can be deployed for this purpose. Specifically, we introduce the contestability problem for EW-QBAFs, which asks how to modify edge weights (e.g., preferences) to achieve a desired strength for a specific argument of interest (i.e., a topic argument). To address this problem, we propose gradient-based relation attribution explanations (G-RAEs), which quantify the sensitivity of the topic argument's strength to changes in individual edge weights, thus providing interpretable guidance for weight adjustments towards contestability. Building on G-RAEs, we develop an iterative algorithm that progressively adjusts the edge weights to attain the desired strength. We evaluate our approach experimentally on synthetic EW-QBAFs that simulate the structural characteristics of personalised recommender systems and multi-layer perceptrons, and demonstrate that it can solve the problem effectively.",
      "authors": [
        "Xiang Yin",
        "Nico Potyka",
        "Antonio Rago",
        "Timotheus Kampik and Francesca Toni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:54:26+00:00",
          "link": "https://arxiv.org/abs/2507.11323v1",
          "size": "350kb",
          "version": "v1"
        }
      ],
      "title": "Contestability in Quantitative Argumentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11323",
        "HTML": "https://arxiv.org/html/2507.11323v1",
        "PDF": "https://arxiv.org/pdf/2507.11323"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses contestable AI and quantitative argumentation frameworks, with no mention of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11364",
      "abstract": "The growing volume of unstructured data within organizations poses significant challenges for data analysis and process automation. Unstructured data, which lacks a predefined format, encompasses various forms such as emails, reports, and scans. It is estimated to constitute approximately 80% of enterprise data. Despite the valuable insights it can offer, extracting meaningful information from unstructured data is more complex compared to structured data. Robotic Process Automation (RPA) has gained popularity for automating repetitive tasks, improving efficiency, and reducing errors. However, RPA is traditionally reliant on structured data, limiting its application to processes involving unstructured documents. This study addresses this limitation by developing the UNstructured Document REtrieval SyStem (UNDRESS), a system that uses fuzzy regular expressions, techniques for natural language processing, and large language models to enable RPA platforms to effectively retrieve information from unstructured documents. The research involved the design and development of a prototype system, and its subsequent evaluation based on text extraction and information retrieval performance. The results demonstrate the effectiveness of UNDRESS in enhancing RPA capabilities for unstructured data, providing a significant advancement in the field. The findings suggest that this system could facilitate broader RPA adoption across processes traditionally hindered by unstructured data, thereby improving overall business process efficiency.",
      "authors": [
        "Kelly Kurowski",
        "Xixi Lu",
        "Hajo A. Reijers"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:32:49+00:00",
          "link": "https://arxiv.org/abs/2507.11364v1",
          "size": "407kb",
          "version": "v1"
        }
      ],
      "title": "From Chaos to Automation: Enabling the Use of Unstructured Data for Robotic Process Automation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11364",
        "HTML": "https://arxiv.org/html/2507.11364v1",
        "PDF": "https://arxiv.org/pdf/2507.11364"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses methods involving large language models for processing unstructured data, its primary focus is on enhancing RPA capabilities rather than directly addressing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.02700",
      "abstract": "A fine-grained comparison of generative models requires the identification of sample types generated differently by each of the involved models. While quantitative scores have been proposed in the literature to rank different generative models, score-based evaluation and ranking do not reveal the nuanced differences between the generative models in producing different sample types. In this work, we propose solving a differential clustering problem to detect sample types generated differently by two generative models. To solve the differential clustering problem, we develop a spectral method called Fourier-based Identification of Novel Clusters (FINC) to identify modes produced by a generative model with a higher frequency in comparison to a reference distribution. FINC provides a scalable algorithm based on random Fourier features to estimate the eigenspace of kernel covariance matrices of two generative models and utilize the principal eigendirections to detect the sample types present more dominantly in each model. We demonstrate the application of the FINC method to large-scale computer vision datasets and generative modeling frameworks. Our numerical results suggest the scalability of the developed Fourier-based method in highlighting the sample types produced with different frequencies by generative models. The project code is available at https://github.com/buyeah1109/FINC.",
      "authors": [
        "Jingwei Zhang",
        "Mohammad Jalali",
        "Cheuk Ting Li",
        "Farzan Farnia"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-04T16:06:50+00:00",
          "link": "https://arxiv.org/abs/2405.02700v1",
          "size": "43434kb",
          "version": "v1"
        },
        {
          "date": "2024-07-05T03:11:17+00:00",
          "link": "https://arxiv.org/abs/2405.02700v2",
          "size": "31063kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T03:34:56+00:00",
          "link": "https://arxiv.org/abs/2405.02700v3",
          "size": "11771kb",
          "version": "v3"
        }
      ],
      "title": "Unveiling Differences in Generative Models: A Scalable Differential Clustering Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.02700",
        "HTML": "https://arxiv.org/html/2405.02700v3",
        "PDF": "https://arxiv.org/pdf/2405.02700"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a method for differential clustering in generative models but does not primarily focus on processing LLM training data. The work is centered around model evaluation techniques rather than data processing."
      },
      "tasks": [
        "Clustering"
      ],
      "repo_urls": [
        "https://github.com/buyeah1109/finc"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.06795",
      "abstract": "Surgical image segmentation is highly challenging, primarily due to scarcity of annotated data. Generalist prompted segmentation models like the Segment-Anything Model (SAM) can help tackle this task, but because they require image-specific visual prompts for effective performance, their use is limited to improving data annotation efficiency. Recent approaches extend SAM to automatic segmentation by using a few labeled reference images to predict point prompts; however, they rely on feature matching pipelines that lack robustness to out-of-domain data like surgical images. To tackle this problem, we introduce CycleSAM, an improved visual prompt learning approach that employs a data-efficient training phase and enforces a series of soft constraints to produce high-quality feature similarity maps. CycleSAM label-efficiently addresses domain gap by leveraging surgery-specific self-supervised feature extractors, then adapts the resulting features through a short parameter-efficient training stage, enabling it to produce informative similarity maps. CycleSAM further filters the similarity maps with a series of consistency constraints before robustly sampling diverse point prompts for each object instance. In our experiments on four diverse surgical datasets, we find that CycleSAM outperforms existing few-shot SAM approaches by a factor of 2-4x in both 1-shot and 5-shot settings, while also achieving strong performance gains over traditional linear probing, parameter-efficient adaptation, and pseudo-labeling methods.",
      "authors": [
        "Aditya Murali",
        "Farahdiba Zarin",
        "Adrien Meyer",
        "Pietro Mascagni",
        "Didier Mutter",
        "Nicolas Padoy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-09T12:08:07+00:00",
          "link": "https://arxiv.org/abs/2407.06795v1",
          "size": "1146kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T09:10:02+00:00",
          "link": "https://arxiv.org/abs/2407.06795v2",
          "size": "18277kb",
          "version": "v2"
        }
      ],
      "title": "CycleSAM: Few-Shot Surgical Scene Segmentation with Cycle- and Scene-Consistent Feature Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.06795",
        "HTML": "https://arxiv.org/html/2407.06795v2",
        "PDF": "https://arxiv.org/pdf/2407.06795"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses improvements in data-efficient training for surgical image segmentation but does not focus on LLM training data processing or creation. It primarily addresses feature matching and constraints for image segmentation tasks."
      },
      "tasks": [
        "One-Shot Segmentation",
        "Scene Segmentation",
        "Segmentation",
        "Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.08161",
      "abstract": "In the traditional view of reinforcement learning, the agent's goal is to find an optimal policy that maximizes its expected sum of rewards. Once the agent finds this policy, the learning ends. This view contrasts with \\emph{continual reinforcement learning}, where learning does not end, and agents are expected to continually learn and adapt indefinitely. Despite the clear distinction between these two paradigms of learning, much of the progress in continual reinforcement learning has been shaped by foundations rooted in the traditional view of reinforcement learning. In this paper, we first examine whether the foundations of traditional reinforcement learning are suitable for the continual reinforcement learning paradigm. We identify four key pillars of the traditional reinforcement learning foundations that are antithetical to the goals of continual learning: the Markov decision process formalism, the focus on atemporal artifacts, the expected sum of rewards as an evaluation metric, and episodic benchmark environments that embrace the other three foundations. We then propose a new formalism that sheds the first and the third foundations and replaces them with the history process as a mathematical formalism and a new definition of deviation regret, adapted for continual learning, as an evaluation metric. Finally, we discuss possible approaches to shed the other two foundations.",
      "authors": [
        "Esraa Elelimy",
        "David Szepesvari",
        "Martha White",
        "Michael Bowling"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-10T23:05:56+00:00",
          "link": "https://arxiv.org/abs/2504.08161v1",
          "size": "28kb",
          "version": "v1"
        },
        {
          "date": "2025-07-12T00:21:37+00:00",
          "link": "https://arxiv.org/abs/2504.08161v2",
          "size": "125kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T03:27:33+00:00",
          "link": "https://arxiv.org/abs/2504.08161v3",
          "size": "125kb",
          "version": "v3"
        }
      ],
      "title": "Rethinking the Foundations for Continual Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.08161",
        "HTML": "https://arxiv.org/html/2504.08161v3",
        "PDF": "https://arxiv.org/pdf/2504.08161"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores foundations for continual reinforcement learning and does not address LLM training data processing or dataset engineering."
      },
      "tasks": [
        "Continual Learning",
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09719",
      "abstract": "We analyze the power consumption of quantum key distribution (QKD) networks under various protocol and detector configurations. Using realistic network topologies, we evaluate discrete-variable vs continuous-variable QKD and optimize device placement, quantifying power trade-offs of SNSPD vs APD detectors and the benefits of optical bypass.",
      "authors": [
        "Jiaheng Xiong",
        "Qiaolun Zhang",
        "Yoann Pi\\'etri",
        "Raja Yehia",
        "Raouf Boutaba",
        "Francesco Musumeci",
        "Massimo Tornatore"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T17:38:52+00:00",
          "link": "https://arxiv.org/abs/2507.09719v1",
          "size": "1504kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T11:03:18+00:00",
          "link": "https://arxiv.org/abs/2507.09719v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "Power Consumption Analysis of QKD Networks under Different Protocols and Detector Configurations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09719",
        "PDF": "https://arxiv.org/pdf/2507.09719"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes power consumption of QKD networks and does not address LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10571",
      "abstract": "Modern Artificial Intelligence (AI) increasingly relies on multi-agent architectures that blend visual and language understanding. Yet, a pressing challenge remains: How can we trust these agents especially in zero-shot settings with no fine-tuning? We introduce a novel modular Agentic AI visual classification framework that integrates generalist multimodal agents with a non-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG) module. Applied to apple leaf disease diagnosis, we benchmark three configurations: (I) zero-shot with confidence-based orchestration, (II) fine-tuned agents with improved performance, and (III) trust-calibrated orchestration enhanced by CLIP-based image retrieval and re-evaluation loops. Using confidence calibration metrics (ECE, OCR, CCC), the orchestrator modulates trust across agents. Our results demonstrate a 77.94\\% accuracy improvement in the zero-shot setting using trust-aware orchestration and RAG, achieving 85.63\\% overall. GPT-4o showed better calibration, while Qwen-2.5-VL displayed overconfidence. Furthermore, image-RAG grounded predictions with visually similar cases, enabling correction of agent overconfidence via iterative re-evaluation. The proposed system separates perception (vision agents) from meta-reasoning (orchestrator), enabling scalable and interpretable multi-agent AI. This blueprint is extensible to diagnostics, biology, and other trust-critical domains. All models, prompts, results, and system components including the complete software source code are openly released to support reproducibility, transparency, and community benchmarking at Github: https://github.com/Applied-AI-Research-Lab/Orchestrator-Agent-Trust",
      "authors": [
        "Konstantinos I. Roumeliotis",
        "Ranjan Sapkota",
        "Manoj Karkee",
        "Nikolaos D. Tselikas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T16:39:29+00:00",
          "link": "https://arxiv.org/abs/2507.10571v1",
          "size": "7715kb",
          "version": "v1"
        }
      ],
      "title": "Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10571",
        "HTML": "https://arxiv.org/html/2507.10571v1",
        "PDF": "https://arxiv.org/pdf/2507.10571"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a modular agentic AI visual classification system with trust-aware orchestration and RAG-based reasoning, focusing on multi-agent architecture rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.06151",
      "abstract": "Human pose, action, and motion generation are critical for applications in digital humans, character animation, and humanoid robotics. However, many existing methods struggle to produce physically plausible movements that are consistent with biomechanical principles. Although recent autoregressive and diffusion models deliver impressive visual quality, they often neglect key biodynamic features and fail to ensure physically realistic motions. Reinforcement Learning (RL) approaches can address these shortcomings but are highly dependent on simulation environments, limiting their generalizability. To overcome these challenges, we propose BioVAE, a biomechanics-aware framework with three core innovations: (1) integration of muscle electromyography (EMG) signals and kinematic features with acceleration constraints to enable physically plausible motion without simulations; (2) seamless coupling with diffusion models for stable end-to-end training; and (3) biomechanical priors that promote strong generalization across diverse motion generation and estimation tasks. Extensive experiments demonstrate that BioVAE achieves state-of-the-art performance on multiple benchmarks, bridging the gap between data-driven motion synthesis and biomechanical authenticity while setting new standards for physically accurate motion generation and pose estimation.",
      "authors": [
        "Zixi Kang",
        "Xinghan Wang",
        "Yadong Mu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-08T10:22:36+00:00",
          "link": "https://arxiv.org/abs/2503.06151v1",
          "size": "2454kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T17:27:11+00:00",
          "link": "https://arxiv.org/abs/2503.06151v2",
          "size": "2773kb",
          "version": "v2"
        }
      ],
      "title": "Biomechanics-Guided Residual Approach to Generalizable Human Motion Generation and Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.06151",
        "HTML": "https://arxiv.org/html/2503.06151v2",
        "PDF": "https://arxiv.org/pdf/2503.06151"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on human motion generation and estimation using biomechanics and does not discuss LLM training data processing."
      },
      "tasks": [
        "Electromyography (EMG)",
        "Motion Generation",
        "Motion Synthesis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10818",
      "abstract": "Software libraries are central to the functionality, security, and maintainability of modern code. As developers increasingly turn to Large Language Models (LLMs) to assist with programming tasks, understanding how these models recommend libraries is essential. In this paper, we conduct an empirical study of six state-of-the-art LLMs, both proprietary and open-source, by prompting them to solve real-world Python problems sourced from Stack Overflow. We analyze the types of libraries they import, the characteristics of those libraries, and the extent to which the recommendations are usable out of the box. Our results show that LLMs predominantly favour third-party libraries over standard ones, and often recommend mature, popular, and permissively licensed dependencies. However, we also identify gaps in usability: 4.6% of the libraries could not be resolved automatically due to structural mismatches between import names and installable packages, and only two models (out of six) provided installation guidance. While the generated code is technically valid, the lack of contextual support places the burden of manually resolving dependencies on the user. Our findings offer actionable insights for both developers and researchers, and highlight opportunities to improve the reliability and usability of LLM-generated code in the context of software dependencies.",
      "authors": [
        "Jasmine Latendresse",
        "SayedHassan Khatoonabadi",
        "Emad Shihab"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T21:35:29+00:00",
          "link": "https://arxiv.org/abs/2507.10818v1",
          "size": "297kb",
          "version": "v1"
        }
      ],
      "title": "How Robust are LLM-Generated Library Imports? An Empirical Study using Stack Overflow",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10818",
        "HTML": "https://arxiv.org/html/2507.10818v1",
        "PDF": "https://arxiv.org/pdf/2507.10818"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "While the paper empirically studies library imports suggested by LLMs, it does not make contributions related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10836",
      "abstract": "Graph Neural Network (GNN)-based network intrusion detection systems (NIDS) are often evaluated on single datasets, limiting their ability to generalize under distribution drift. Furthermore, their adversarial robustness is typically assessed using synthetic perturbations that lack realism. This measurement gap leads to an overestimation of GNN-based NIDS resilience. To address the limitations, we propose \\textbf{REAL-IoT}, a comprehensive framework for robustness evaluation of GNN-based NIDS in IoT environments. Our framework presents a methodology that creates a unified dataset from canonical datasets to assess generalization under drift. In addition, it features a novel intrusion dataset collected from a physical IoT testbed, which captures network traffic and attack scenarios under real-world settings. Furthermore, using REAL-IoT, we explore the usage of Large Language Models (LLMs) to analyze network data and mitigate the impact of adversarial examples by filtering suspicious flows. Our evaluations using REAL-IoT reveal performance drops in GNN models compared to results from standard benchmarks, quantifying their susceptibility to drift and realistic attacks. We also demonstrate the potential of LLM-based filtering to enhance robustness. These findings emphasize the necessity of realistic threat modeling and rigorous measurement practices for developing resilient IoT intrusion detection systems.",
      "authors": [
        "Zhonghao Zhan",
        "Huichi Zhou",
        "Hamed Haddadi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T22:10:08+00:00",
          "link": "https://arxiv.org/abs/2507.10836v1",
          "size": "14565kb",
          "version": "v1"
        }
      ],
      "title": "REAL-IoT: Characterizing GNN Intrusion Detection Robustness under Practical Adversarial Attack",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10836",
        "HTML": "https://arxiv.org/html/2507.10836v1",
        "PDF": "https://arxiv.org/pdf/2507.10836"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses creating a novel intrusion dataset and explores using LLMs to filter network data, but the primary focus is on intrusion detection systems rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.10225",
      "abstract": "Amodal segmentation aims to infer the complete shape of occluded objects, even when the occluded region's appearance is unavailable. However, current amodal segmentation methods lack the capability to interact with users through text input and struggle to understand or reason about implicit and complex purposes. While methods like LISA integrate multi-modal large language models (LLMs) with segmentation for reasoning tasks, they are limited to predicting only visible object regions and face challenges in handling complex occlusion scenarios. To address these limitations, we propose a novel task named amodal reasoning segmentation, aiming to predict the complete amodal shape of occluded objects while providing answers with elaborations based on user text input. We develop a generalizable dataset generation pipeline and introduce a new dataset focusing on daily life scenarios, encompassing diverse real-world occlusions. Furthermore, we present AURA (Amodal Understanding and Reasoning Assistant), a novel model with advanced global and spatial-level designs specifically tailored to handle complex occlusions. Extensive experiments validate AURA's effectiveness on the proposed dataset.",
      "authors": [
        "Zhixuan Li",
        "Hyunse Yoon",
        "Sanghoon Lee",
        "Weisi Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-13T10:08:18+00:00",
          "link": "https://arxiv.org/abs/2503.10225v1",
          "size": "3567kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T07:45:11+00:00",
          "link": "https://arxiv.org/abs/2503.10225v2",
          "size": "6660kb",
          "version": "v2"
        }
      ],
      "title": "Unveiling the Invisible: Reasoning Complex Occlusions Amodally with AURA",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.10225",
        "HTML": "https://arxiv.org/html/2503.10225v2",
        "PDF": "https://arxiv.org/pdf/2503.10225"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a new dataset with clear data processing steps for handling occlusions and develops a dataset generation pipeline, which are critical contributions to LLM training data processing."
      },
      "conference": "unveiling-the-invisible-reasoning-complex",
      "conference_url_abs": "https://arxiv.org/abs/2503.10225",
      "tasks": [
        "Dataset Generation",
        "Reasoning Segmentation",
        "Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10799",
      "abstract": "We define a broad class of deterministic stream functions and show they can be implemented as homomorphisms into a \"state\" monoid. The homomorphism laws are simpler than the conditions of previous semantic frameworks for stream program optimization, yet retain support for rich equational reasoning over expressive dataflow programs, including sequential composition, parallel composition, and feedback. We demonstrate this using examples of partitioned database joins, stratified negation, and a simplified model of TCP.",
      "authors": [
        "Tyler Hou",
        "Michael Arntzenius",
        "Max Willsey"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T20:51:53+00:00",
          "link": "https://arxiv.org/abs/2507.10799v1",
          "size": "41kb",
          "version": "v1"
        }
      ],
      "title": "Stream programs are monoid homomorphisms with state",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10799",
        "HTML": "https://arxiv.org/html/2507.10799v1",
        "PDF": "https://arxiv.org/pdf/2507.10799"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a theoretical framework for stream programs and does not concern itself with LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10820",
      "abstract": "This paper demonstrates that Semantic Context (SC), leveraging descriptive tool information, is a foundational component for robust tool orchestration. Our contributions are threefold. First, we provide a theoretical foundation using contextual bandits, introducing SC-LinUCB and proving it achieves lower regret and adapts favourably in dynamic action spaces. Second, we provide parallel empirical validation with Large Language Models, showing that SC is critical for successful in-context learning in both static (efficient learning) and non-stationary (robust adaptation) settings. Third, we propose the FiReAct pipeline, and demonstrate on a benchmark with over 10,000 tools that SC-based retrieval enables an LLM to effectively orchestrate over a large action space. These findings provide a comprehensive guide to building more sample-efficient, adaptive, and scalable orchestration agents.",
      "authors": [
        "Robert M\\\"uller"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T21:38:27+00:00",
          "link": "https://arxiv.org/abs/2507.10820v1",
          "size": "2074kb",
          "version": "v1"
        }
      ],
      "title": "Semantic Context for Tool Orchestration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10820",
        "PDF": "https://arxiv.org/pdf/2507.10820"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on tool orchestration and contextual learning with LLMs, not specifically on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.07140",
      "abstract": "This work presents an encryption model based on Generative Adversarial Networks (GANs). Encryption of RTF-8 data is realized by dynamically generating decimal numbers that lead to the encryption and decryption of alphabetic strings in integer representation by simple addition rules, the modulus of the dimension of the considered alphabet. The binary numbers for the private dynamic keys correspond to the binary numbers of public reference keys, as defined by a specific GAN configuration. For reversible encryption with a bijective mapping between dynamic and reference keys, as defined by the GAN encryptor, secure text encryption can be achieved by transferring a GAN-encrypted public key along with the encrypted text from a sender to a receiver. Using the technique described above, secure text mail transfer can be realized through component-wise encryption and decryption of text mail strings, with total key sizes of up to $10^{8}$ bits that define random decimal numbers generated by the GAN. From the present model, we assert that encrypted texts can be transmitted more efficiently and securely than from RSA encryption, as long as users of the specific configuration of the GAN encryption model are unaware of the GAN encryptor circuit and configuration, respectively.",
      "authors": [
        "Alexej Schelle"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-08T07:27:57+00:00",
          "link": "https://arxiv.org/abs/2504.07140v1",
          "size": "195kb",
          "version": "v1"
        },
        {
          "date": "2025-04-14T10:48:41+00:00",
          "link": "https://arxiv.org/abs/2504.07140v2",
          "size": "195kb",
          "version": "v2"
        }
      ],
      "title": "Secure Text Mail Encryption with Generative Adversarial Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07140",
        "HTML": "https://arxiv.org/html/2504.07140",
        "PDF": "https://arxiv.org/pdf/2504.07140"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an encryption model using GANs for secure text mail transfer, with no mention of LLM training data processing or dataset creation relevant to LLMs."
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/alexej-schelle/TextmailEncryption/tree/main/release"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.00744",
      "abstract": "Medical Large Multi-modal Models (LMMs) have demonstrated remarkable capabilities in medical data interpretation. However, these models frequently generate hallucinations contradicting source evidence, particularly due to inadequate localization reasoning. This work reveals a critical limitation in current medical LMMs: instead of analyzing relevant pathological regions, they often rely on linguistic patterns or attend to irrelevant image areas when responding to disease-related queries. To address this, we introduce HEAL-MedVQA (Hallucination Evaluation via Localization MedVQA), a comprehensive benchmark designed to evaluate LMMs' localization abilities and hallucination robustness. HEAL-MedVQA features (i) two innovative evaluation protocols to assess visual and textual shortcut learning, and (ii) a dataset of 67K VQA pairs, with doctor-annotated anatomical segmentation masks for pathological regions. To improve visual reasoning, we propose the Localize-before-Answer (LobA) framework, which trains LMMs to localize target regions of interest and self-prompt to emphasize segmented pathological areas, generating grounded and reliable answers. Experimental results demonstrate that our approach significantly outperforms state-of-the-art biomedical LMMs on the challenging HEAL-MedVQA benchmark, advancing robustness in medical VQA.",
      "authors": [
        "Dung Nguyen",
        "Minh Khoi Ho",
        "Huy Ta",
        "Thanh Tam Nguyen",
        "Qi Chen",
        "Kumar Rav",
        "Quy Duong Dang",
        "Satwik Ramchandre",
        "Son Lam Phung",
        "Zhibin Liao",
        "Minh-Son To",
        "Johan Verjans",
        "Phi Le Nguyen",
        "and Vu Minh Hieu Phan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-30T07:57:51+00:00",
          "link": "https://arxiv.org/abs/2505.00744v1",
          "size": "12423kb",
          "version": "v1"
        },
        {
          "date": "2025-05-05T02:30:17+00:00",
          "link": "https://arxiv.org/abs/2505.00744v2",
          "size": "12423kb",
          "version": "v2"
        },
        {
          "date": "2025-05-21T04:21:21+00:00",
          "link": "https://arxiv.org/abs/2505.00744v3",
          "size": "12423kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T14:41:15+00:00",
          "link": "https://arxiv.org/abs/2505.00744v4",
          "size": "6575kb",
          "version": "v4"
        }
      ],
      "title": "Localizing Before Answering: A Hallucination Evaluation Benchmark for Grounded Medical Multimodal LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00744",
        "HTML": "https://arxiv.org/html/2505.00744v4",
        "PDF": "https://arxiv.org/pdf/2505.00744"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating and improving localization and hallucination robustness in medical LMMs rather than on processing or creating LLM training data."
      },
      "tasks": [
        "Hallucination",
        "Hallucination Evaluation",
        "Visual Question Answering (VQA)",
        "Visual Reasoning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.04027",
      "abstract": "Rapid growth of data center networks (DCNs) poses significant challenges for large-scale traffic engineering (TE). Existing acceleration strategies, which rely on commercial solvers or deep learning, face scalability issues and struggle with degrading performance or long computational time. Unlike existing algorithms adopting parallel strategies, we propose Sequential Source-Destination Optimization (SSDO), a sequential solver-free algorithm for TE. SSDO decomposes the problem into subproblems, each focused on adjusting the split ratios for a specific source-destination (SD) demand while keeping others fixed. To enhance the efficiency of subproblem optimization, we design a Balanced Binary Search Method (BBSM), which identifies the most balanced split ratios among multiple solutions that minimize Maximum Link Utilization (MLU). SSDO dynamically updates the sequence of SDs based on real-time utilization, which accelerates convergence and enhances solution quality. We evaluate SSDO on Meta DCNs and two wide-area networks. In a Meta topology, SSDO achieves a 65\\% and 60\\% reduction in normalized MLU compared to TEAL and POP, two state-of-the-art TE acceleration methods, while delivering a $12\\times$ speedup over POP. These results demonstrate the superior performance of SSDO in large-scale TE.",
      "authors": [
        "Yingming Mao",
        "Qiaozhu Zhai",
        "Ximeng Liu",
        "Zhen Yao",
        "Xia Zhu",
        "Yuzhou Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-05T02:43:37+00:00",
          "link": "https://arxiv.org/abs/2504.04027v1",
          "size": "661kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T03:06:31+00:00",
          "link": "https://arxiv.org/abs/2504.04027v2",
          "size": "613kb",
          "version": "v2"
        }
      ],
      "title": "A Fast Solver-Free Algorithm for Traffic Engineering in Large-Scale Data Center Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.04027",
        "HTML": "https://arxiv.org/html/2504.04027v2",
        "PDF": "https://arxiv.org/pdf/2504.04027"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a solver-free algorithm for traffic engineering in data center networks, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.07719",
      "abstract": "Neural control variates (NCVs) have emerged as a powerful tool for variance reduction in Monte Carlo (MC) simulations, particularly in high-dimensional problems where traditional control variates are difficult to construct analytically. By training neural networks to learn auxiliary functions correlated with the target observable, NCVs can significantly reduce estimator variance while preserving unbiasedness. However, a critical but often overlooked aspect of NCV training is the role of autocorrelated samples generated by Markov Chain Monte Carlo (MCMC). While such samples are typically discarded for error estimation due to their statistical redundancy, they may contain useful information about the structure of the underlying probability distribution that can benefit the training process. In this work, we systematically examine the effect of using correlated configurations in training neural control variates. We demonstrate, both conceptually and numerically, that training on correlated data can improve control variate performance, especially in settings with limited computational resources. Our analysis includes empirical results from $U(1)$ gauge theory and scalar field theory, illustrating when and how autocorrelated samples enhance NCV construction. These findings provide practical guidance for the efficient use of MCMC data in training neural networks.",
      "authors": [
        "Hyunwoo Oh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "High Energy Physics - Lattice (hep-lat)",
        "Machine Learning (cs.LG)",
        "Nuclear Theory (nucl-th)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-12T16:25:00+00:00",
          "link": "https://arxiv.org/abs/2505.07719v1",
          "size": "587kb",
          "version": "v1"
        },
        {
          "date": "2025-05-27T17:23:43+00:00",
          "link": "https://arxiv.org/abs/2505.07719v2",
          "size": "587kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T16:34:42+00:00",
          "link": "https://arxiv.org/abs/2505.07719v3",
          "size": "626kb",
          "version": "v3"
        }
      ],
      "title": "Training neural control variates using correlated configurations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.07719",
        "HTML": "https://arxiv.org/html/2505.07719v3",
        "PDF": "https://arxiv.org/pdf/2505.07719"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using neural control variates for Monte Carlo simulations, specifically the role of autocorrelated samples in NCV training. It does not address LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.18679",
      "abstract": "We introduce MARL-MambaContour, the first contour-based medical image segmentation framework based on Multi-Agent Reinforcement Learning (MARL). Our approach reframes segmentation as a multi-agent cooperation task focused on generate topologically consistent object-level contours, addressing the limitations of traditional pixel-based methods which could lack topological constraints and holistic structural awareness of anatomical regions. Each contour point is modeled as an autonomous agent that iteratively adjusts its position to align precisely with the target boundary, enabling adaptation to blurred edges and intricate morphologies common in medical images. This iterative adjustment process is optimized by a contour-specific Soft Actor-Critic (SAC) algorithm, further enhanced with the Entropy Regularization Adjustment Mechanism (ERAM) which dynamically balance agent exploration with contour smoothness. Furthermore, the framework incorporates a Mamba-based policy network featuring a novel Bidirectional Cross-attention Hidden-state Fusion Mechanism (BCHFM). This mechanism mitigates potential memory confusion limitations associated with long-range modeling in state space models, thereby facilitating more accurate inter-agent information exchange and informed decision-making. Extensive experiments on five diverse medical imaging datasets demonstrate the state-of-the-art performance of MARL-MambaContour, highlighting its potential as an accurate and robust clinical application.",
      "authors": [
        "Ruicheng Zhang",
        "Yu Sun",
        "Zeyu Zhang",
        "Jinai Li",
        "Xiaofan Liu",
        "Au Hoi Fan",
        "Haowei Guo",
        "Puxin Yan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T14:22:49+00:00",
          "link": "https://arxiv.org/abs/2506.18679v1",
          "size": "8731kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T07:59:56+00:00",
          "link": "https://arxiv.org/abs/2506.18679v2",
          "size": "8732kb",
          "version": "v2"
        }
      ],
      "title": "MARL-MambaContour: Unleashing Multi-Agent Deep Reinforcement Learning for Active Contour Optimization in Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18679",
        "HTML": "https://arxiv.org/html/2506.18679v2",
        "PDF": "https://arxiv.org/pdf/2506.18679"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces a framework for image segmentation using reinforcement learning, and does not involve LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22760",
      "abstract": "Most language models face a fundamental tradeoff where powerful capabilities require substantial computational resources. We shatter this constraint with Jan-nano, a 4B parameter language model that redefines efficiency through radical specialization: instead of trying to know everything, it masters the art of finding anything instantly. Fine-tuned from Qwen3-4B using our novel multi-stage Reinforcement Learning with Verifiable Rewards (RLVR) system that completely eliminates reliance on next token prediction training (SFT), Jan-nano achieves 83.2% on SimpleQA benchmark with MCP integration while running on consumer hardware. With 128K context length, Jan-nano proves that intelligence isn't about scale, it's about strategy.",
      "authors": [
        "Alan Dao (Gia Tuan Dao)",
        "Dinh Bach Vu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T05:44:57+00:00",
          "link": "https://arxiv.org/abs/2506.22760v1",
          "size": "381kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T00:13:39+00:00",
          "link": "https://arxiv.org/abs/2506.22760v2",
          "size": "385kb",
          "version": "v2"
        }
      ],
      "title": "Jan-nano Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22760",
        "HTML": "https://arxiv.org/html/2506.22760v2",
        "PDF": "https://arxiv.org/pdf/2506.22760"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes fine-tuning a language model using a novel RL strategy, focusing on efficiency rather than on substantive data processing or creation of an LLM dataset."
      },
      "models": [
        {
          "model_path": "Menlo/Jan-nano-128k",
          "downloads": "5948",
          "likes": "200",
          "trending_score": "6.0",
          "link": "https://huggingface.co/Menlo/Jan-nano-128k"
        },
        {
          "model_path": "Menlo/Jan-nano-gguf",
          "downloads": "74585",
          "likes": "130",
          "trending_score": "1.0",
          "link": "https://huggingface.co/Menlo/Jan-nano-gguf"
        },
        {
          "model_path": "Menlo/Jan-nano-128k-gguf",
          "downloads": "47029",
          "likes": "53",
          "trending_score": "1.0",
          "link": "https://huggingface.co/Menlo/Jan-nano-128k-gguf"
        },
        {
          "model_path": "warshanks/Jan-nano-AWQ",
          "downloads": "5",
          "likes": "1",
          "trending_score": "1.0",
          "link": "https://huggingface.co/warshanks/Jan-nano-AWQ"
        },
        {
          "model_path": "Menlo/Jan-nano",
          "downloads": "33793",
          "likes": "461",
          "trending_score": "23.0",
          "link": "https://huggingface.co/Menlo/Jan-nano"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.23323",
      "abstract": "Open-vocabulary semantic segmentation (OVSS) aims to segment objects from arbitrary text categories without requiring densely annotated datasets. Although contrastive learning based models enable zero-shot segmentation, they often lose fine spatial precision at pixel level, due to global representation bias. In contrast, diffusion-based models naturally encode fine-grained spatial features via attention mechanisms that capture both global context and local details. However, they often face challenges in balancing the computation costs and the quality of the segmentation mask. In this work, we present FA-Seg, a Fast and Accurate training-free framework for open-vocabulary segmentation based on diffusion models. FA-Seg performs segmentation using only a (1+1)-step from a pretrained diffusion model. Moreover, instead of running multiple times for different classes, FA-Seg performs segmentation for all classes at once. To further enhance the segmentation quality, FA-Seg introduces three key components: (i) a dual-prompt mechanism for discriminative, class-aware attention extraction, (ii) a Hierarchical Attention Refinement Method (HARD) that enhances semantic precision via multi-resolution attention fusion, and (iii) a Test-Time Flipping (TTF) scheme designed to improve spatial consistency. Extensive experiments show that FA-Seg achieves state-of-the-art training-free performance, obtaining 43.8% average mIoU across PASCAL VOC, PASCAL Context, and COCO Object benchmarks while maintaining superior inference efficiency. Our results demonstrate that FA-Seg provides a strong foundation for extendability, bridging the gap between segmentation quality and inference efficiency. The source code will be open-sourced after this paper is accepted.",
      "authors": [
        "Quang-Huy Che",
        "Vinh-Tiep Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T16:41:41+00:00",
          "link": "https://arxiv.org/abs/2506.23323v1",
          "size": "25909kb",
          "version": "v1"
        },
        {
          "date": "2025-07-07T09:26:08+00:00",
          "link": "https://arxiv.org/abs/2506.23323v2",
          "size": "25654kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T07:19:26+00:00",
          "link": "https://arxiv.org/abs/2506.23323v3",
          "size": "25905kb",
          "version": "v3"
        }
      ],
      "title": "FA-Seg: A Fast and Accurate Diffusion-Based Method for Open-Vocabulary Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23323",
        "HTML": "https://arxiv.org/html/2506.23323v3",
        "PDF": "https://arxiv.org/pdf/2506.23323"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on open-vocabulary semantic segmentation using diffusion models and does not discuss LLM training data processing techniques or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09180",
      "abstract": "Depth information is robust to scene appearance variations and inherently carries 3D spatial details. In this paper, a visual backbone based on the vision transformer is proposed to fuse RGB and depth modalities for enhancing generalization. Different modalities are first processed by separate CNN stems, and the combined convolutional features are delivered to the scalable vision transformer to obtain visual representations. Moreover, a contrastive unsupervised learning scheme is designed with masked and unmasked tokens to accelerate the sample efficiency during the reinforcement learning progress. For sim2real transfer, a flexible curriculum learning schedule is developed to deploy domain randomization over training processes.",
      "authors": [
        "Zichun Xu",
        "Yuntao Li",
        "Zhaomin Wang",
        "Lei Zhuang",
        "Guocai Yang",
        "and Jingdong Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T07:58:02+00:00",
          "link": "https://arxiv.org/abs/2507.09180v1",
          "size": "308kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T09:22:15+00:00",
          "link": "https://arxiv.org/abs/2507.09180v2",
          "size": "417kb",
          "version": "v2"
        }
      ],
      "title": "Learning and Transferring Better with Depth Information in Visual Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09180",
        "HTML": "https://arxiv.org/html/2507.09180v2",
        "PDF": "https://arxiv.org/pdf/2507.09180"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on enhancing visual reinforcement learning through depth information and multimodal fusion, which does not involve any aspect of LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2302.13696",
      "abstract": "We propose the Moderate Adaptive Linear Unit (MoLU), a novel activation function for deep neural networks, defined analytically as: f(x)=x \\times (1+tanh(x))/2. MoLU combines mathematical elegance with empirical effectiveness, exhibiting superior performance in terms of prediction accuracy, convergence speed, and computational efficiency. Due to its C-infinity smoothness, i.e. infinite differentiability and analyticity, MoLU is expected to mitigate issues such as vanishing or exploding gradients, making it suitable for a broad range of architectures and applications, including large language models (LLMs), Neural Ordinary Differential Equations (Neural ODEs), Physics-Informed Neural Networks (PINNs), and Convolutional Neural Networks (CNNs). Empirical evaluations show that MoLU consistently achieves faster convergence and improved final accuracy relative to widely used activation functions such as GeLU, SiLU, and Mish. These properties position MoLU as a promising and robust candidate for general-purpose activation across diverse deep learning paradigms.",
      "authors": [
        "Hankyul Koh",
        "Joon-hyuk Ko",
        "Wonho Jhe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Science and Game Theory (cs.GT)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2023-02-27T11:55:24+00:00",
          "link": "https://arxiv.org/abs/2302.13696v1",
          "size": "774kb",
          "version": "v1"
        },
        {
          "date": "2023-02-28T10:07:47+00:00",
          "link": "https://arxiv.org/abs/2302.13696v2",
          "size": "774kb",
          "version": "v2"
        },
        {
          "date": "2024-06-07T02:23:44+00:00",
          "link": "https://arxiv.org/abs/2302.13696v3",
          "size": "774kb",
          "version": "v3"
        },
        {
          "date": "2024-06-10T11:32:24+00:00",
          "link": "https://arxiv.org/abs/2302.13696v4",
          "size": "774kb",
          "version": "v4"
        },
        {
          "date": "2024-09-04T10:21:32+00:00",
          "link": "https://arxiv.org/abs/2302.13696v5",
          "size": "774kb",
          "version": "v5"
        },
        {
          "date": "2025-07-07T13:44:01+00:00",
          "link": "https://arxiv.org/abs/2302.13696v6",
          "size": "763kb",
          "version": "v6"
        },
        {
          "date": "2025-07-15T15:16:22+00:00",
          "link": "https://arxiv.org/abs/2302.13696v7",
          "size": "1057kb",
          "version": "v7"
        }
      ],
      "title": "Moderate Adaptive Linear Units (MoLU)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2302.13696",
        "HTML": "https://arxiv.org/html/2302.13696",
        "PDF": "https://arxiv.org/pdf/2302.13696"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on proposing a new activation function, MoLU, for deep neural networks, which is not related to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.19896",
      "abstract": "Recent trends are emerging in the use of Large Language Models (LLMs) as autonomous agents that take actions based on the content of the user text prompts. We intend to apply these concepts to the field of Control in space, enabling LLMs to play a significant role in the decision-making process for autonomous satellite operations. As a first step towards this goal, we have developed a pure LLM-based solution for the Kerbal Space Program Differential Games (KSPDG) challenge, a public software design competition where participants create autonomous agents for maneuvering satellites involved in non-cooperative space operations, running on the KSP game engine. Our approach leverages prompt engineering, few-shot prompting, and fine-tuning techniques to create an effective LLM-based agent that ranked 2nd in the competition. To the best of our knowledge, this work pioneers the integration of LLM agents into space research. The project comprises several open repositories to facilitate replication and further research. The codebase is accessible on \\href{https://github.com/ARCLab-MIT/kspdg}{GitHub}, while the trained models and datasets are available on \\href{https://huggingface.co/OhhTuRnz}{Hugging Face}. Additionally, experiment tracking and detailed results can be reviewed on \\href{https://wandb.ai/carrusk/huggingface}{Weights \\& Biases",
      "authors": [
        "Alejandro Carrasco",
        "Victor Rodriguez-Fernandez",
        "Richard Linares"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T12:25:35+00:00",
          "link": "https://arxiv.org/abs/2505.19896v1",
          "size": "6304kb",
          "version": "v1"
        }
      ],
      "title": "Large Language Models as Autonomous Spacecraft Operators in Kerbal Space Program",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.19896",
        "HTML": "https://arxiv.org/html/2505.19896",
        "PDF": "https://arxiv.org/pdf/2505.19896"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper describes the use of LLMs as autonomous agents in a space program setting but does mention the use of fine-tuning. However, it does not focus on the process of creating or processing LLM training data."
      },
      "tasks": [
        "Prompt Engineering"
      ],
      "repo_urls": [
        "https://github.com/arclab-mit/kspdg"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10619",
      "abstract": "The dynamic allocation of spectrum in 5G / 6G networks is critical to efficient resource utilization. However, applying traditional deep reinforcement learning (DRL) is often infeasible due to its immense sample complexity and the safety risks associated with unguided exploration, which can cause severe network interference. To address these challenges, we propose a meta-learning framework that enables agents to learn a robust initial policy and rapidly adapt to new wireless scenarios with minimal data. We implement three meta-learning architectures, model-agnostic meta-learning (MAML), recurrent neural network (RNN), and an attention-enhanced RNN, and evaluate them against a non-meta-learning DRL algorithm, proximal policy optimization (PPO) baseline, in a simulated dynamic integrated access/backhaul (IAB) environment. Our results show a clear performance gap. The attention-based meta-learning agent reaches a peak mean network throughput of 48 Mbps, while the PPO baseline decreased drastically to 10 Mbps. Furthermore, our method reduces SINR and latency violations by more than 50% compared to PPO. It also shows quick adaptation, with a fairness index 0.7, showing better resource allocation. This work proves that meta-learning is a very effective and safer option for intelligent control in complex wireless systems.",
      "authors": [
        "Oluwaseyi Giwa and Tobi Awodunmila and Muhammad Ahmed Mohsin and Ahsan Bilal and Muhammad Ali Jamshed"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T21:29:39+00:00",
          "link": "https://arxiv.org/abs/2507.10619v1",
          "size": "549kb",
          "version": "v1"
        }
      ],
      "title": "Meta-Reinforcement Learning for Fast and Data-Efficient Spectrum Allocation in Dynamic Wireless Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10619",
        "PDF": "https://arxiv.org/pdf/2507.10619"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on meta-reinforcement learning for spectrum allocation in wireless networks, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10812",
      "abstract": "We propose an approach to test embodied AI agents for interaction awareness and believability, particularly in scenarios where humans push them to their limits. Turing introduced the Imitation Game as a way to explore the question: \"Can machines think?\" The Total Turing Test later expanded this concept beyond purely verbal communication, incorporating perceptual and physical interaction. Building on this, we propose a new guiding question: \"Can machines react?\" and introduce the React to This (RTT) test for nonverbal behaviors, presenting results from an initial experiment.",
      "authors": [
        "Chuxuan Zhang",
        "Yasaman Etesam and Angelica Lim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T21:16:12+00:00",
          "link": "https://arxiv.org/abs/2507.10812v1",
          "size": "2201kb",
          "version": "v1"
        }
      ],
      "title": "React to This (RTT): A Nonverbal Turing Test for Embodied AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10812",
        "HTML": "https://arxiv.org/html/2507.10812v1",
        "PDF": "https://arxiv.org/pdf/2507.10812"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on nonverbal Turing tests for AI and does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10924",
      "abstract": "Offset surfaces, defined as the Minkowski sum of a base surface and a rolling ball, play a crucial role in geometry processing, with applications ranging from coverage motion planning to brush modeling. While considerable progress has been made in computing constant-radius offset surfaces, computing variable-radius offset surfaces remains a challenging problem. In this paper, we present OffsetCrust, a novel framework that efficiently addresses the variable-radius offsetting problem by computing a power diagram. Let $R$ denote the radius function defined on the base surface $S$. The power diagram is constructed from contributing sites, consisting of carefully sampled base points on $S$ and their corresponding off-surface points, displaced along $R$-dependent directions. In the constant-radius case only, these displacement directions align exactly with the surface normals of $S$. Moreover, our method mitigates the misalignment issues commonly seen in crust-based approaches through a lightweight fine-tuning procedure. We validate the accuracy and efficiency of OffsetCrust through extensive experiments, and demonstrate its practical utility in applications such as reconstructing original boundary surfaces from medial axis transform (MAT) representations.",
      "authors": [
        "Zihan Zhao",
        "Pengfei Wang",
        "Minfeng Xu",
        "Shuangmin Chen",
        "Shiqing Xin",
        "Changhe Tu and Wenping Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T02:32:38+00:00",
          "link": "https://arxiv.org/abs/2507.10924v1",
          "size": "42924kb",
          "version": "v1"
        }
      ],
      "title": "OffsetCrust: Variable-Radius Offset Approximation with Power Diagrams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10924",
        "HTML": "https://arxiv.org/html/2507.10924v1",
        "PDF": "https://arxiv.org/pdf/2507.10924"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with geometry processing using power diagrams and offset surfaces, unrelated to the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11178",
      "abstract": "With the advancement of deep learning technologies, various neural network-based Granger causality models have been proposed. Although these models have demonstrated notable improvements, several limitations remain. Most existing approaches adopt the component-wise architecture, necessitating the construction of a separate model for each time series, which results in substantial computational costs. In addition, imposing the sparsity-inducing penalty on the first-layer weights of the neural network to extract causal relationships weakens the model's ability to capture complex interactions. To address these limitations, we propose Gradient Regularization-based Neural Granger Causality (GRNGC), which requires only one time series prediction model and applies $L_{1}$ regularization to the gradient between model's input and output to infer Granger causality. Moreover, GRNGC is not tied to a specific time series forecasting model and can be implemented with diverse architectures such as KAN, MLP, and LSTM, offering enhanced flexibility. Numerical simulations on DREAM, Lorenz-96, fMRI BOLD, and CausalTime show that GRNGC outperforms existing baselines and significantly reduces computational overhead. Meanwhile, experiments on real-world DNA, Yeast, HeLa, and bladder urothelial carcinoma datasets further validate the model's effectiveness in reconstructing gene regulatory networks.",
      "authors": [
        "Meiliang Liu",
        "Huiwen Dong",
        "Xiaoxiao Yang",
        "Yunfang Xu",
        "Zijin Li",
        "Zhengye Si",
        "Xinyue Yang",
        "Zhiwen Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:35:29+00:00",
          "link": "https://arxiv.org/abs/2507.11178v1",
          "size": "641kb",
          "version": "v1"
        }
      ],
      "title": "Gradient Regularization-based Neural Granger Causality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11178",
        "HTML": "https://arxiv.org/html/2507.11178v1",
        "PDF": "https://arxiv.org/pdf/2507.11178"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with proposing a new model for Granger causality using gradient regularization, with no focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11210",
      "abstract": "Well-being in family settings involves subtle psychological dynamics that conventional metrics often overlook. In particular, unconscious parental expectations, termed ideal parent bias, can suppress children's emotional expression and autonomy. This suppression, referred to as suppressed emotion, often stems from well-meaning but value-driven communication, which is difficult to detect or address from outside the family. Focusing on these latent dynamics, this study explores Large Language Model (LLM)-based support for psychologically safe family communication. We constructed a Japanese parent-child dialogue corpus of 30 scenarios, each annotated with metadata on ideal parent bias and suppressed emotion. Based on this corpus, we developed a Role-Playing LLM-based multi-agent dialogue support framework that analyzes dialogue and generates feedback. Specialized agents detect suppressed emotion, describe implicit ideal parent bias in parental speech, and infer contextual attributes such as the child's age and background. A meta-agent compiles these outputs into a structured report, which is then passed to five selected expert agents. These agents collaboratively generate empathetic and actionable feedback through a structured four-step discussion process. Experiments show that the system can detect categories of suppressed emotion with moderate accuracy and produce feedback rated highly in empathy and practicality. Moreover, simulated follow-up dialogues incorporating this feedback exhibited signs of improved emotional expression and mutual understanding, suggesting the framework's potential in supporting positive transformation in family interactions.",
      "authors": [
        "Rushia Harada",
        "Yuken Kimura",
        "Keito Inoshita"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T11:27:32+00:00",
          "link": "https://arxiv.org/abs/2507.11210v1",
          "size": "853kb",
          "version": "v1"
        }
      ],
      "title": "Role-Playing LLM-Based Multi-Agent Support Framework for Detecting and Addressing Family Communication Bias",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11210",
        "PDF": "https://arxiv.org/pdf/2507.11210"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Although it involves LLMs, the paper is centered around family communication and dialogue frameworks, not on processing or engineering LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08730",
      "abstract": "Modern configurable software systems need to learn models that correlate configuration and performance. However, when the system operates in dynamic environments, the workload variations, hardware changes, and system updates will inevitably introduce concept drifts at different levels - global drifts, which reshape the performance landscape of the entire configuration space; and local drifts, which only affect certain sub-regions of that space. As such, existing offline and transfer learning approaches can struggle to adapt to these implicit and unpredictable changes in real-time, rendering configuration performance learning challenging. To address this, we propose DHDA, an online configuration performance learning framework designed to capture and adapt to these drifts at different levels. The key idea is that DHDA adapts to both the local and global drifts using dually hierarchical adaptation: at the upper level, we redivide the data into different divisions, within each of which the local model is retrained, to handle global drifts only when necessary. At the lower level, the local models of the divisions can detect local drifts and adapt themselves asynchronously. To balance responsiveness and efficiency, DHDA combines incremental updates with periodic full retraining to minimize redundant computation when no drifts are detected. Through evaluating eight software systems and against state-of-the-art approaches, we show that DHDA achieves considerably better accuracy and can effectively adapt to drifts with up to 2x improvements, while incurring reasonable overhead and is able to improve different local models in handling concept drift.",
      "authors": [
        "Zezhen Xiang",
        "Jingzhi Gong",
        "Tao Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T16:31:42+00:00",
          "link": "https://arxiv.org/abs/2507.08730v1",
          "size": "1386kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T13:01:52+00:00",
          "link": "https://arxiv.org/abs/2507.08730v2",
          "size": "1386kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T13:04:33+00:00",
          "link": "https://arxiv.org/abs/2507.08730v3",
          "size": "1386kb",
          "version": "v3"
        }
      ],
      "title": "Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08730",
        "HTML": "https://arxiv.org/html/2507.08730v3",
        "PDF": "https://arxiv.org/pdf/2507.08730"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving configuration performance learning in software systems in response to environmental changes and does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11130",
      "abstract": "We consider nonlinear inverse problems arising in the context of parameter identification for parabolic partial differential equations (PDEs). For stable reconstructions, regularization methods such as the iteratively regularized Gauss-Newton method (IRGNM) are commonly used, but their application is computationally demanding due to the high-dimensional nature of PDE discretizations. To address this bottleneck, we propose a reduced-order modeling approach that accelerates both the state and adjoint evaluations required for derivative-based optimization. Our method builds on the recent contribution [Kartmann et al. Adaptive reduced basis trust region methods for parameter identification problems. Comput. Sci. Eng. 1, 3 (2024)] for elliptic forward operators and constructs the reduced forward operator adaptively in an online fashion, combining both parameter and state space reduction. To ensure reliability, we embed the IRGNM iteration within an adaptive, error-aware trust-region framework that certifies the accuracy of the reduced-order approximations. We demonstrate the effectiveness of the proposed approach through numerical results for both time-dependent and time-independent parameter identification problems in dynamic reaction-diffusion systems. The implementation is made available for reproducibility and further use.",
      "authors": [
        "Michael Kartmann",
        "Benedikt Klein",
        "Mario Ohlberger",
        "Thomas Schuster",
        "Stefan Volkwein"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:30:37+00:00",
          "link": "https://arxiv.org/abs/2507.11130v1",
          "size": "37776kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive Reduced Basis Trust Region Methods for Parabolic Inverse Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11130",
        "HTML": "https://arxiv.org/html/2507.11130v1",
        "PDF": "https://arxiv.org/pdf/2507.11130"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a reduced-order modeling approach for solving parabolic inverse problems in PDEs, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11371",
      "abstract": "We present Step-wise Policy for Rare-tool Knowledge (SPaRK), a novel reinforcement learning framework that teaches large language models to explore diverse tool usage patterns beyond conventional high-temperature sampling. Building on recent advances in step-wise reinforcement learning, we introduce a dual-objective reward system that simultaneously optimizes for answer quality and tool diversity, training a Llama-3.1 8B model through offline PPO on synthetically generated trajectories from the MMLU-Pro dataset. Our approach uniquely employs a rarity-first exploitation strategy where a GPT-4o judge scores candidate actions across eight distinct tools plus chain-of-thought reasoning, with the policy favoring less-frequently used but still viable tools to encourage systematic exploration. Empirical results demonstrate that SPaRK achieves competitive performance across 14 MMLU-Pro categories while exhibiting significantly higher entropy in tool selection compared to both baseline and supervised fine-tuning approaches, suggesting that algorithmic exploration through explicit tool diversity can enhance reasoning capabilities without sacrificing accuracy.",
      "authors": [
        "Gabriel Bo",
        "Koa Chang",
        "Justin Gu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:44:29+00:00",
          "link": "https://arxiv.org/abs/2507.11371v1",
          "size": "1361kb",
          "version": "v1"
        }
      ],
      "title": "Step-wise Policy for Rare-tool Knowledge (SPaRK): Offline RL that Drives Diverse Tool Use in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11371",
        "HTML": "https://arxiv.org/html/2507.11371v1",
        "PDF": "https://arxiv.org/pdf/2507.11371"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores a reinforcement learning framework for large language models focusing on diverse tool usage but does not primarily address the creation or processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11435",
      "abstract": "Time-Frequency (TF) dual-path models are currently among the best performing audio source separation network architectures, achieving state-of-the-art performance in speech enhancement, music source separation, and cinematic audio source separation. While they are characterized by a relatively low parameter count, they still require a considerable number of operations, implying a higher execution time. This problem is exacerbated by the trend towards bigger models trained on large amounts of data to solve more general tasks, such as the recently introduced task-aware unified source separation (TUSS) model. TUSS, which aims to solve audio source separation tasks using a single, conditional model, is built upon TF-Locoformer, a TF dual-path model combining convolution and attention layers. The task definition comes in the form of a sequence of prompts that specify the number and type of sources to be extracted. In this paper, we analyze the design choices of TUSS with the goal of optimizing its performance-complexity trade-off. We derive two more efficient models, FasTUSS-8.3G and FasTUSS-11.7G that reduce the original model's operations by 81\\% and 73\\% with minor performance drops of 1.2~dB and 0.4~dB averaged over all benchmarks, respectively. Additionally, we investigate the impact of prompt conditioning to derive a causal TUSS model.",
      "authors": [
        "Francesco Paissan",
        "Gordon Wichern",
        "Yoshiki Masuyama",
        "Ryo Aihara",
        "Fran\\c{c}ois G. Germain",
        "Kohei Saijo",
        "Jonathan Le Roux"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:57:28+00:00",
          "link": "https://arxiv.org/abs/2507.11435v1",
          "size": "139kb",
          "version": "v1"
        }
      ],
      "title": "FasTUSS: Faster Task-Aware Unified Source Separation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11435",
        "HTML": "https://arxiv.org/html/2507.11435v1",
        "PDF": "https://arxiv.org/pdf/2507.11435"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing the performance-complexity trade-off of a task-aware model for audio source separation, rather than processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11460",
      "abstract": "Human-robot collaboration in surgery represents a significant area of research, driven by the increasing capability of autonomous robotic systems to assist surgeons in complex procedures. This systematic review examines the advancements and persistent challenges in the development of autonomous surgical robotic assistants (ASARs), focusing specifically on scenarios where robots provide meaningful and active support to human surgeons. Adhering to the PRISMA guidelines, a comprehensive literature search was conducted across the IEEE Xplore, Scopus, and Web of Science databases, resulting in the selection of 32 studies for detailed analysis. Two primary collaborative setups were identified: teleoperation-based assistance and direct hands-on interaction. The findings reveal a growing research emphasis on ASARs, with predominant applications currently in endoscope guidance, alongside emerging progress in autonomous tool manipulation. Several key challenges hinder wider adoption, including the alignment of robotic actions with human surgeon preferences, the necessity for procedural awareness within autonomous systems, the establishment of seamless human-robot information exchange, and the complexities of skill acquisition in shared workspaces. This review synthesizes current trends, identifies critical limitations, and outlines future research directions essential to improve the reliability, safety, and effectiveness of human-robot collaboration in surgical environments.",
      "authors": [
        "Jacinto Colan",
        "Ana Davila",
        "Yutaro Yamada and Yasuhisa Hasegawa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:32:46+00:00",
          "link": "https://arxiv.org/abs/2507.11460v1",
          "size": "187kb",
          "version": "v1"
        }
      ],
      "title": "Human-Robot collaboration in surgery: Advances and challenges towards autonomous surgical assistants",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11460",
        "HTML": "https://arxiv.org/html/2507.11460v1",
        "PDF": "https://arxiv.org/pdf/2507.11460"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The review discusses advancements in autonomous surgical robots and does not involve the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2408.10878",
      "abstract": "Multi-agent trajectory data collected from domains such as team sports often suffer from missing values due to various factors. While many imputation methods have been proposed for spatiotemporal data, they are not well-suited for multi-agent sports scenarios where player movements are highly dynamic and inter-agent interactions continuously evolve. To address these challenges, we propose MIDAS (Multi-agent Imputer with Derivative-Accumulating Self-ensemble), a framework that imputes multi-agent trajectories with high accuracy and physical plausibility. It jointly predicts positions, velocities, and accelerations through a Set Transformer-based neural network and generates alternative estimates by recursively accumulating predicted velocity and acceleration values. These predictions are then combined using a learnable weighted ensemble to produce final imputed trajectories. Experiments on three sports datasets demonstrate that MIDAS significantly outperforms existing baselines in both positional accuracy and physical plausibility. Lastly, we showcase use cases of MIDAS, such as approximating total distance and pass success probability, to highlight its applicability to practical downstream tasks that require complete tracking data.",
      "authors": [
        "Han-Jun Choi",
        "Hyunsung Kim",
        "Minho Lee",
        "Minchul Jeong",
        "Chang-Jo Kim",
        "Jinsung Yoon",
        "Sang-Ki Ko"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-20T14:08:16+00:00",
          "link": "https://arxiv.org/abs/2408.10878v1",
          "size": "9436kb",
          "version": "v1"
        },
        {
          "date": "2024-08-23T01:27:46+00:00",
          "link": "https://arxiv.org/abs/2408.10878v2",
          "size": "9436kb",
          "version": "v2"
        },
        {
          "date": "2025-03-23T17:12:21+00:00",
          "link": "https://arxiv.org/abs/2408.10878v3",
          "size": "12639kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T05:05:38+00:00",
          "link": "https://arxiv.org/abs/2408.10878v4",
          "size": "1271kb",
          "version": "v4"
        }
      ],
      "title": "Trajectory Imputation in Multi-Agent Sports with Derivative-Accumulating Self-Ensemble",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.10878",
        "HTML": "https://arxiv.org/html/2408.10878v4",
        "PDF": "https://arxiv.org/pdf/2408.10878"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on imputing multi-agent trajectories in sports datasets, which does not involve LLM training data processing or contribute to LLM data engineering initiatives."
      },
      "tasks": [
        "Imputation",
        "Missing Values"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.11476",
      "abstract": "This paper addresses the fundamental computer vision challenge of robust circle detection and fitting in degraded imaging conditions. We present Combinatorial Convolution-based Circle Fitting for Blurry Images (3C-FBI), an algorithm that bridges the gap between circle detection and precise parametric fitting by combining (1) efficient combinatorial edge pixel (edgel) sampling and (2) convolution-based density estimation in parameter space.\n  We evaluate 3C-FBI across three experimental frameworks: (1) real-world medical data from Parkinson's disease assessments (144 frames from 36 videos), (2) controlled synthetic data following established circle-fitting benchmarks, and (3) systematic analysis across varying spatial resolutions and outlier contamination levels. Results show that 3C-FBI achieves state-of-the-art accuracy (Jaccard index 0.896) while maintaining real-time performance (40.3 fps), significantly outperforming classical methods like RCD (6.8 fps) on a standard CPU (i7-10875H). It maintains near-perfect accuracy (Jaccard almost 1.0) at high resolutions (480x480) and reliable performance (Jaccard higher than 0.95) down to 160x160 with up to 20% outliers.\n  In extensive synthetic testing, 3C-FBI achieves a mean Jaccard Index of 0.989 across contamination levels, comparable to modern methods like Qi et al. (2024, 0.991), and surpassing RHT (0.964). This combination of accuracy, speed, and robustness makes 3C-FBI ideal for medical imaging, robotics, and industrial inspection under challenging conditions.",
      "authors": [
        "Esteban Rom\\'an Catafau and Torbj\\\"orn E.M. Nordling"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:47:44+00:00",
          "link": "https://arxiv.org/abs/2507.11476v1",
          "size": "4496kb",
          "version": "v1"
        }
      ],
      "title": "C-FBI: A Combinatorial method using Convolutions for Circle Fitting in Blurry Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11476",
        "HTML": "https://arxiv.org/html/2507.11476v1",
        "PDF": "https://arxiv.org/pdf/2507.11476"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a method for circle fitting in blurry images, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.14162",
      "abstract": "In recent years, end to end steering prediction for autonomous vehicles has become a major area of research. The primary method for achieving end to end steering was to use computer vision models on a live feed of video data. However, to further increase accuracy, many companies have added data from light detection and ranging (LiDAR) and or radar sensors through sensor fusion. However, the addition of lasers and sensors comes at a high financial cost. In this paper, I address both of these issues by increasing the accuracy of the computer vision models without the increased cost of using LiDAR and or sensors. I achieved this by improving the accuracy of computer vision models by sensor fusing CAN bus data, a vehicle protocol, with video data. CAN bus data is a rich source of information about the vehicle's state, including its speed, steering angle, and acceleration. By fusing this data with video data, the accuracy of the computer vision model's predictions can be improved. When I trained the model without CAN bus data, I obtained an RMSE of 0.02492, while the model trained with the CAN bus data achieved an RMSE of 0.01970. This finding indicates that fusing CAN Bus data with video data can reduce the computer vision model's prediction error by 20% with some models decreasing the error by 80%.",
      "authors": [
        "Amit Singh"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-22T03:24:53+00:00",
          "link": "https://arxiv.org/abs/2310.14162v1",
          "size": "1374kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T16:43:23+00:00",
          "link": "https://arxiv.org/abs/2310.14162v2",
          "size": "869kb",
          "version": "v2"
        }
      ],
      "title": "Augmenting End-to-End Steering Angle Prediction with CAN Bus Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.14162",
        "HTML": "https://arxiv.org/html/2310.14162v2",
        "PDF": "https://arxiv.org/pdf/2310.14162"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores the integration of CAN Bus data for improving steering angle predictions in autonomous vehicles and does not focus on LLM training data processing."
      },
      "tasks": [
        "Autonomous Vehicles",
        "Sensor Fusion"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.07414",
      "abstract": "Shuffling has been shown to amplify differential privacy guarantees, enabling a more favorable privacy-utility trade-off. To characterize and compute this amplification, two fundamental analytical frameworks have been proposed: the \\emph{privacy blanket} by Balle et al. (CRYPTO 2019) and the \\emph{clone}--including both the standard and stronger variant--by Feldman et al. (FOCS 2021, SODA 2023). These frameworks share a common foundation: decomposing local randomizers into structured components for analysis.\n  In this work, we introduce a unified analytical framework--the general clone paradigm--which subsumes all possible decompositions, with the clone and blanket decompositions arising as special cases. Within this framework, we identify the optimal decomposition, which is precisely the one used by the privacy blanket. Moreover, we develop a simple and efficient algorithm based on the Fast Fourier Transform (FFT) to compute optimal privacy amplification bounds. Experimental results show that our computed upper bounds nearly match the lower bounds, demonstrating the tightness of our method. Building on this method, we also derive optimal amplification bounds for both \\emph{joint} and \\emph{parallel} compositions of LDP mechanisms in the shuffle model.",
      "authors": [
        "Pengcheng Su",
        "Haibo Cheng",
        "Ping Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-10T03:11:17+00:00",
          "link": "https://arxiv.org/abs/2504.07414v1",
          "size": "126kb",
          "version": "v1"
        },
        {
          "date": "2025-04-11T01:35:46+00:00",
          "link": "https://arxiv.org/abs/2504.07414v2",
          "size": "124kb",
          "version": "v2"
        },
        {
          "date": "2025-04-16T12:16:33+00:00",
          "link": "https://arxiv.org/abs/2504.07414v3",
          "size": "168kb",
          "version": "v3"
        },
        {
          "date": "2025-07-08T07:52:03+00:00",
          "link": "https://arxiv.org/abs/2504.07414v4",
          "size": "207kb",
          "version": "v4"
        },
        {
          "date": "2025-07-15T12:20:33+00:00",
          "link": "https://arxiv.org/abs/2504.07414v5",
          "size": "209kb",
          "version": "v5"
        }
      ],
      "title": "Decomposition-Based Optimal Bounds for Privacy Amplification via Shuffling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07414",
        "HTML": "https://arxiv.org/html/2504.07414v5",
        "PDF": "https://arxiv.org/pdf/2504.07414"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper revolves around enhancing differential privacy via shuffling methods, focusing on privacy algorithms rather than LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.05763",
      "abstract": "Academic misconduct detection in biomedical research remains challenging due to algorithmic narrowness in existing methods and fragmented analytical pipelines. We present BMDetect, a multimodal deep learning framework that integrates journal metadata (SJR, institutional data), semantic embeddings (PubMedBERT), and GPT-4o-mined textual attributes (methodological statistics, data anomalies) for holistic manuscript evaluation. Key innovations include: (1) multimodal fusion of domain-specific features to reduce detection bias; (2) quantitative evaluation of feature importance, identifying journal authority metrics (e.g., SJR-index) and textual anomalies (e.g., statistical outliers) as dominant predictors; and (3) the BioMCD dataset, a large-scale benchmark with 13,160 retracted articles and 53,411 controls. BMDetect achieves 74.33% AUC, outperforming single-modality baselines by 8.6%, and demonstrates transferability across biomedical subfields. This work advances scalable, interpretable tools for safeguarding research integrity.",
      "authors": [
        "Yize Zhou",
        "Jie Zhang",
        "Meijie Wang",
        "Lun Yu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-09T03:53:10+00:00",
          "link": "https://arxiv.org/abs/2505.05763v1",
          "size": "869kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T05:12:11+00:00",
          "link": "https://arxiv.org/abs/2505.05763v2",
          "size": "873kb",
          "version": "v2"
        }
      ],
      "title": "BMDetect: A Multimodal Deep Learning Framework for Comprehensive Biomedical Misconduct Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.05763",
        "PDF": "https://arxiv.org/pdf/2505.05763"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "BMDetect is related to academic misconduct detection in biomedical research and does not focus on LLM training data processing or dataset creation."
      },
      "tasks": [
        "Articles",
        "Feature Importance",
        "Multimodal Deep Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.23644",
      "abstract": "We introduce QLPro, a vulnerability detection framework that systematically integrates LLMs and static analysis tools to enable comprehensive vulnerability detection across entire open-source projects.We constructed a new dataset, JavaTest, comprising 10 open-source projects from GitHub with 62 confirmed vulnerabilities. CodeQL, a state-of-the-art static analysis tool, detected only 24 of these vulnerabilities while QLPro detected 41. Furthermore, QLPro discovered 6 previously unknown vulnerabilities, 2 of which have been confirmed as 0-days.",
      "authors": [
        "Junze Hu",
        "Xiangyu Jin",
        "Yizhe Zeng",
        "Yuling Liu",
        "Yunpeng Li",
        "Dan Du",
        "Kaiyu Xie",
        "Hongsong Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:14:49+00:00",
          "link": "https://arxiv.org/abs/2506.23644v1",
          "size": "3165kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T13:38:25+00:00",
          "link": "https://arxiv.org/abs/2506.23644v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "QLPro: Automated Code Vulnerability Discovery via LLM and Static Code Analysis Integration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23644",
        "PDF": "https://arxiv.org/pdf/2506.23644"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses the integration of LLM and static analysis tools for vulnerability detection and mentions constructing a new dataset, the focus is on tool integration rather than detailed LLM training-data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11201",
      "abstract": "We study wave propagation through a one-dimensional array of subwavelength resonators with periodically time-modulated material parameters. Focusing on a high-contrast regime, we use a scattering framework based on Fourier expansions and scattering matrix techniques to capture the interactions between an incident wave and the temporally varying system. This way, we derive a formulation of the total energy flux corresponding to time-dependent systems of resonators. We show that the total energy flux is composed of the transmitted and reflected energy fluxes, and derive an optical theorem which characterises the energy balance of the system. We provide a number of numerical experiments to investigate the impact of the time-dependency, the operating frequency and the number of resonators on the maximal attainable energy gain and energy loss. Moreover, we show the existence of lasing points, at which the total energy diverges. Our results lay the foundation for the design of energy dissipative or energy amplifying systems.",
      "authors": [
        "Erik Orvehed Hiltunen",
        "Liora Rueff"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optics (physics.optics)",
        "Numerical Analysis (cs.NA)",
        "Mathematical Physics (math-ph)",
        "Analysis of PDEs (math.AP)",
        "Mathematical Physics (math.MP)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T11:13:56+00:00",
          "link": "https://arxiv.org/abs/2507.11201v1",
          "size": "494kb",
          "version": "v1"
        }
      ],
      "title": "Energy Balance and Optical Theorem for Time-Modulated Subwavelength Resonator Arrays",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11201",
        "HTML": "https://arxiv.org/html/2507.11201v1",
        "PDF": "https://arxiv.org/pdf/2507.11201"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on wave propagation through subwavelength resonators and energy balance in time-modulated systems. It doesn't relate to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11311",
      "abstract": "In this study, we investigate a scheduling problem on identical machines in which jobs require initial setup before execution. We assume that an algorithm can dynamically form a batch (i.e., a collection of jobs to be processed together) from the remaining jobs. The setup time is modeled as a known monotone function of the set of jobs within a batch, while the execution time of each job remains unknown until completion. This uncertainty poses significant challenges for minimizing the makespan. We address these challenges by considering two scenarios: each job batch must be assigned to a single machine, or a batch may be distributed across multiple machines. For both scenarios, we analyze settings with and without preemption. Across these four settings, we design online algorithms that achieve asymptotically optimal competitive ratios with respect to both the number of jobs and the number of machines.",
      "authors": [
        "Yasushi Kawase",
        "Kazuhisa Makino",
        "Vinh Long Phan",
        "and Hanna Sumita"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:42:42+00:00",
          "link": "https://arxiv.org/abs/2507.11311v1",
          "size": "21kb",
          "version": "v1"
        }
      ],
      "title": "Scheduling on Identical Machines with Setup Time and Unknown Execution Time",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11311",
        "HTML": "https://arxiv.org/html/2507.11311v1",
        "PDF": "https://arxiv.org/pdf/2507.11311"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper studies scheduling algorithms for machine processes and does not discuss aspects related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11392",
      "abstract": "Inverse optimal control (IOC) is a promising paradigm for learning and mimicking optimal control strategies from capable demonstrators, or gaining a deeper understanding of their intentions, by estimating an unknown objective function from one or more corresponding optimal control sequences. When computing estimates from demonstrations in environments with safety-preserving inequality constraints, acknowledging their presence in the chosen IOC method is crucial given their strong influence on the final control strategy. However, solution strategies capable of considering inequality constraints, such as the inverse Karush-Kuhn-Tucker approach, rely on their correct activation and fulfillment; a restrictive assumption when dealing with noisy demonstrations. To overcome this problem, we leverage the concept of exact penalty functions for IOC and show preservation of estimation accuracy. Considering noisy demonstrations, we then illustrate how the usage of penalty functions reduces the number of unknown variables and how their approximations enhance the estimation method's capacity to account for wrong constraint activations within a polytopic-constrained environment. The proposed method is evaluated for three systems in simulation, outperforming traditional relaxation approaches for noisy demonstrations.",
      "authors": [
        "Rahel Rickenbach",
        "Amon Lahr",
        "and Melanie N. Zeilinger"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:03:00+00:00",
          "link": "https://arxiv.org/abs/2507.11392v1",
          "size": "390kb",
          "version": "v1"
        }
      ],
      "title": "Inverse Optimal Control with Constraint Relaxation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11392",
        "HTML": "https://arxiv.org/html/2507.11392v1",
        "PDF": "https://arxiv.org/pdf/2507.11392"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses inverse optimal control methods and constraint relaxation without any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10795",
      "abstract": "The Artificial Benchmark for Community Detection (ABCD) model is a random graph model with community structure and power-law distribution for both degrees and community sizes. The model generates graphs similar to the well-known LFR model but it is faster, more interpretable, and can be investigated analytically. In this paper, we use the underlying ingredients of the ABCD model and introduce its variant for multilayer networks, mABCD.",
      "authors": [
        "{\\L}ukasz Krai\\'nski",
        "Micha{\\l} Czuba",
        "Piotr Br\\'odka",
        "Pawe{\\l} Pra{\\l}at",
        "Bogumi{\\l} Kami\\'nski",
        "Fran\\c{c}ois Th\\'eberge"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T20:49:51+00:00",
          "link": "https://arxiv.org/abs/2507.10795v1",
          "size": "5315kb",
          "version": "v1"
        }
      ],
      "title": "Multilayer Artificial Benchmark for Community Detection (mABCD)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10795",
        "HTML": "https://arxiv.org/html/2507.10795v1",
        "PDF": "https://arxiv.org/pdf/2507.10795"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a benchmark for community detection in multilayer networks without discussing LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10800",
      "abstract": "Vision Transformers deliver state-of-the-art performance, yet their fixed computational budget prevents scalable deployment across heterogeneous hardware. Recent nested Transformer architectures mitigate this by embedding nested subnetworks within a single model to enable scalable inference. However, these models allocate the same amount of compute to all inputs, regardless of their complexity, which leads to inefficiencies. To address this, we introduce ThinkingViT, a nested ViT architecture that employs progressive thinking stages to dynamically adjust inference computation based on input difficulty. ThinkingViT initiates inference by activating a small subset of the most important attention heads and terminates early if predictions reach sufficient certainty. Otherwise, it activates additional attention heads and re-evaluates the input. At the core of ThinkingViT is our Token Recycling mechanism, which conditions each subsequent inference stage on the embeddings from the previous stage, enabling progressive improvement. Due to its backbone-preserving design, ThinkingViT also serves as a plugin upgrade for vanilla ViT. Experiments show that ThinkingViT surpasses nested baselines by up to 2.0 percentage points (p.p.) in accuracy at the same throughput and by up to 2.9 p.p. at equal GMACs on ImageNet-1K. The source code is available at https://github.com/ds-kiel/ThinkingViT.",
      "authors": [
        "Ali Hojjat",
        "Janek Haberer",
        "Soren Pirk",
        "Olaf Landsiedel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T20:54:41+00:00",
          "link": "https://arxiv.org/abs/2507.10800v1",
          "size": "790kb",
          "version": "v1"
        }
      ],
      "title": "ThinkingViT: Matryoshka Thinking Vision Transformer for Elastic Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10800",
        "HTML": "https://arxiv.org/html/2507.10800v1",
        "PDF": "https://arxiv.org/pdf/2507.10800"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a Vision Transformer architecture improvement and does not engage with LLM training data processes or discuss any dataset manipulations or creations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11114",
      "abstract": "We present a robust ensemble-based system for multilingual multimodal reasoning, designed for the ImageCLEF 2025 EXAMS V challenge. Our approach integrates Gemini 2.5 Flash for visual description, Gemini 1.5 Pro for caption refinement and consistency checks, and Gemini 2.5 Pro as a reasoner which handles final answer selection, all coordinated through carefully engineered few-shot and zero-shot prompts. We conducted an extensive ablation study, training several large language models (Gemini 2.5 Flash, Phi 4, Gemma 3, Mistral) on an English dataset and its multilingual augmented version. Additionally, we evaluated Gemini 2.5 Flash in a zero-shot setting for comparison and found it to substantially outperform the trained models. Prompt design also proved critical: enforcing concise, language-normalized formats and prohibiting explanatory text boosted model accuracy on the English validation set from 55.9% to 61.7%. On the official leaderboard, our system (Team MSA) achieved first place overall in the multilingual track with 81.4% accuracy, and led 11 out of 13 individual language tracks, with top results such as 95.07% for Croatian and 92.12% for Italian. These findings highlight that lightweight OCR-VLM ensembles, when paired with precise prompt strategies and cross-lingual augmentation, can outperform heavier end-to-end models in high-stakes, multilingual educational settings.",
      "authors": [
        "Seif Ahmed",
        "Mohamed T. Younes",
        "Abdelrahman Moustafa",
        "Abdelrahman Allam",
        "Hamza Moustafa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:05:05+00:00",
          "link": "https://arxiv.org/abs/2507.11114v1",
          "size": "994kb",
          "version": "v1"
        }
      ],
      "title": "MSA at ImageCLEF 2025 Multimodal Reasoning: Multilingual Multimodal Reasoning With Ensemble Vision Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11114",
        "HTML": "https://arxiv.org/html/2507.11114v1",
        "PDF": "https://arxiv.org/pdf/2507.11114"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a system for multilingual multimodal reasoning and prompt strategies for LLMs but does not focus on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11198",
      "abstract": "Large Language Models (LLMs) enable new possibilities for qualitative research at scale, including coding and data annotation. While multi-agent systems (MAS) can emulate human coding workflows, their benefits over single-agent coding remain poorly understood. We conducted an experimental study of how agent persona and temperature shape consensus-building and coding accuracy of dialog segments based on a codebook with 8 codes. Our open-source MAS mirrors deductive human coding through structured agent discussion and consensus arbitration. Using six open-source LLMs (with 3 to 32 billion parameters) and 18 experimental configurations, we analyze over 77,000 coding decisions against a gold-standard dataset of human-annotated transcripts from online math tutoring sessions. Temperature significantly impacted whether and when consensus was reached across all six LLMs. MAS with multiple personas (including neutral, assertive, or empathetic), significantly delayed consensus in four out of six LLMs compared to uniform personas. In three of those LLMs, higher temperatures significantly diminished the effects of multiple personas on consensus. However, neither temperature nor persona pairing lead to robust improvements in coding accuracy. Single agents matched or outperformed MAS consensus in most conditions. Only one model (OpenHermesV2:7B) and code category showed above-chance gains from MAS deliberation when temperature was 0.5 or lower and especially when the agents included at least one assertive persona. Qualitative analysis of MAS collaboration for these configurations suggests that MAS may nonetheless aid in narrowing ambiguous code applications that could improve codebooks and human-AI coding. We contribute new insight into the limits of LLM-based qualitative methods, challenging the notion that diverse MAS personas lead to better outcomes. We open-source our MAS and experimentation code.",
      "authors": [
        "Conrad Borchers",
        "Bahar Shahrokhian",
        "Francesco Balzan",
        "Elham Tajik",
        "Sreecharan Sankaranarayanan",
        "Sebastian Simon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T11:06:32+00:00",
          "link": "https://arxiv.org/abs/2507.11198v1",
          "size": "67kb",
          "version": "v1"
        }
      ],
      "title": "Temperature and Persona Shape LLM Agent Consensus With Minimal Accuracy Gains in Qualitative Coding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11198",
        "HTML": "https://arxiv.org/html/2507.11198v1",
        "PDF": "https://arxiv.org/pdf/2507.11198"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the effects of agent persona and temperature on consensus building and coding accuracy in multi-agent systems (MAS) for qualitative research. It does not address LLM training data processing, such as data collection or preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11321",
      "abstract": "Recently, Gaussian Splatting (GS) has received a lot of attention in surface reconstruction. However, while 3D objects can be of complex and diverse shapes in the real world, existing GS-based methods only limitedly use a single type of splatting primitive (Gaussian ellipse or Gaussian ellipsoid) to represent object surfaces during their reconstruction. In this paper, we highlight that this can be insufficient for object surfaces to be represented in high quality. Thus, we propose a novel framework that, for the first time, enables Gaussian Splatting to incorporate multiple types of (geometrical) primitives during its surface reconstruction process. Specifically, in our framework, we first propose a compositional splatting strategy, enabling the splatting and rendering of different types of primitives in the Gaussian Splatting pipeline. In addition, we also design our framework with a mixed-primitive-based initialization strategy and a vertex pruning mechanism to further promote its surface representation learning process to be well executed leveraging different types of primitives. Extensive experiments show the efficacy of our framework and its accurate surface reconstruction performance.",
      "authors": [
        "Haoxuan Qu",
        "Yujun Cai",
        "Hossein Rahmani",
        "Ajay Kumar",
        "Junsong Yuan",
        "Jun Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:52:40+00:00",
          "link": "https://arxiv.org/abs/2507.11321v1",
          "size": "14643kb",
          "version": "v1"
        }
      ],
      "title": "A Mixed-Primitive-based Gaussian Splatting Method for Surface Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11321",
        "HTML": "https://arxiv.org/html/2507.11321v1",
        "PDF": "https://arxiv.org/pdf/2507.11321"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on improving surface reconstruction through Gaussian Splatting methods and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11508",
      "abstract": "We examine evaluation of faithfulness to input data in the context of hotel highlights: brief LLM-generated summaries that capture unique features of accommodations. Through human evaluation campaigns involving categorical error assessment and span-level annotation, we compare traditional metrics, trainable methods, and LLM-as-a-judge approaches. Our findings reveal that simpler metrics like word overlap correlate surprisingly well with human judgments (Spearman correlation rank of 0.63), often outperforming more complex methods when applied to out-of-domain data. We further demonstrate that while LLMs can generate high-quality highlights, they prove unreliable for evaluation as they tend to severely under- or over-annotate. Our analysis of real-world business impacts shows incorrect and non-checkable information pose the greatest risks. We also highlight challenges in crowdsourced evaluations.",
      "authors": [
        "Patr\\'icia Schmidtov\\'a",
        "Ond\\v{r}ej Du\\v{s}ek",
        "Saad Mahamood"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:23:56+00:00",
          "link": "https://arxiv.org/abs/2507.11508v1",
          "size": "36kb",
          "version": "v1"
        }
      ],
      "title": "Real-World Summarization: When Evaluation Reaches Its Limits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11508",
        "HTML": "https://arxiv.org/html/2507.11508v1",
        "PDF": "https://arxiv.org/pdf/2507.11508"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines evaluation methods for LLM-generated summaries, specifically focusing on faithfulness and its assessment. It does not address any data processing aspects for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10603",
      "abstract": "The retirement funding problem addresses the question of how to manage a retiree's savings to provide her with a constant post-tax inflation adjusted consumption throughout her lifetime. This consists of choosing withdrawals and transfers from and between several accounts with different tax treatments, taking into account basic rules such as required minimum distributions and limits on Roth conversions, additional income, liabilities, taxes, and the bequest when the retiree dies. We develop a retirement funding policy in two steps. In the first step, we consider a simplified planning problem in which various future quantities, such as the retiree's remaining lifetime, future investment returns, and future inflation, are known. Using a simplified model of taxes, we pose this planning problem as a convex optimization problem, where we maximize the bequest subject to providing a constant inflation adjusted consumption target. Since this problem is convex, it can be solved quickly and reliably. We leverage this planning method to form a retirement funding policy that determines the actions to take each year, based on information known at that time. Each year the retiree forms a new plan for the future years, using the current account values and life expectancy, and optionally, updated information such as changes in tax rates or rules. The retiree then carries out the actions from the first year of the current plan. This update-plan-act cycle is repeated each year, a general policy called model predictive control (MPC). The MPC retirement policy reacts to the effects of uncertain investment returns and inflation, changes in the retiree's expected lifetime or external income and liabilities, and changes in tax rules and rates. We demonstrate the effectiveness of the MPC retirement policy using Monte Carlo simulation.",
      "authors": [
        "Kasper Johansson and Stephen Boyd"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T17:26:00+00:00",
          "link": "https://arxiv.org/abs/2507.10603v1",
          "size": "4108kb",
          "version": "v1"
        }
      ],
      "title": "A Tax-Efficient Model Predictive Control Policy for Retirement Funding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10603",
        "HTML": "https://arxiv.org/html/2507.10603v1",
        "PDF": "https://arxiv.org/pdf/2507.10603"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on retirement funding and model predictive control for financial planning, with no discussion on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10950",
      "abstract": "This paper presents a unified modeling and optimization framework to enhance the kinematic performance of multi-magnet embedded soft continuum robots (MeSCRs). To this end, we establish a differentiable system formulation based on an extended pseudo-rigid-body model. This formulation enables analysis of the equilibrium well-posedness and the geometry of the induced configuration under magnetic actuation. In particular, we show that the maximum controllable degrees of freedom of a MeSCR equal twice the number of embedded magnets. We subsequently develop a structural optimization framework based on differential geometry that links classical kinematic measures (e.g., manipulability and dexterity) to the configuration of embedded magnets. The resulting optimization condition reveals that improving local performance requires structurally modulating the spectrum of the configuration space metric to counteract its distortion. Closed-form solutions for optimal magnet configurations are derived under representative conditions, and a gradient-based numerical method is proposed for general design scenarios. Simulation studies validate the effectiveness of the proposed framework.",
      "authors": [
        "Zhiwei Wu",
        "Jiahao Luo",
        "Siyi Wei",
        "Jinhui Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T03:30:21+00:00",
          "link": "https://arxiv.org/abs/2507.10950v1",
          "size": "1965kb",
          "version": "v1"
        }
      ],
      "title": "Unified Modeling and Structural Optimization of Multi-magnet Embedded Soft Continuum Robots for Enhanced Kinematic Performances",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10950",
        "HTML": "https://arxiv.org/html/2507.10950v1",
        "PDF": "https://arxiv.org/pdf/2507.10950"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for optimizing multi-magnet embedded soft continuum robots, unrelated to training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11055",
      "abstract": "Medical language-guided segmentation, integrating textual clinical reports as auxiliary guidance to enhance image segmentation, has demonstrated significant improvements over unimodal approaches. However, its inherent reliance on paired image-text input, which we refer to as ``textual reliance\", presents two fundamental limitations: 1) many medical segmentation datasets lack paired reports, leaving a substantial portion of image-only data underutilized for training; and 2) inference is limited to retrospective analysis of cases with paired reports, limiting its applicability in most clinical scenarios where segmentation typically precedes reporting. To address these limitations, we propose ProLearn, the first Prototype-driven Learning framework for language-guided segmentation that fundamentally alleviates textual reliance. At its core, in ProLearn, we introduce a novel Prototype-driven Semantic Approximation (PSA) module to enable approximation of semantic guidance from textual input. PSA initializes a discrete and compact prototype space by distilling segmentation-relevant semantics from textual reports. Once initialized, it supports a query-and-respond mechanism which approximates semantic guidance for images without textual input, thereby alleviating textual reliance. Extensive experiments on QaTa-COV19, MosMedData+ and Kvasir-SEG demonstrate that ProLearn outperforms state-of-the-art language-guided methods when limited text is available.",
      "authors": [
        "Shuchang Ye",
        "Usman Naseem",
        "Mingyuan Meng",
        "Jinman Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T07:38:49+00:00",
          "link": "https://arxiv.org/abs/2507.11055v1",
          "size": "3707kb",
          "version": "v1"
        }
      ],
      "title": "Alleviating Textual Reliance in Medical Language-guided Segmentation via Prototype-driven Semantic Approximation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11055",
        "HTML": "https://arxiv.org/html/2507.11055v1",
        "PDF": "https://arxiv.org/pdf/2507.11055"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses medical language-guided segmentation and does not involve processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11096",
      "abstract": "In this study, we investigate leveraging cross-attention control for efficient audio editing within auto-regressive models. Inspired by image editing methodologies, we develop a Prompt-to-Prompt-like approach that guides edits through cross and self-attention mechanisms. Integrating a diffusion-based strategy, influenced by Auffusion, we extend the model's functionality to support refinement edits, establishing a baseline for prompt-guided audio editing. Additionally, we introduce an alternative approach by incorporating MUSICGEN, a pre-trained frozen auto-regressive model, and propose three editing mechanisms, based on Replacement, Reweighting, and Refinement of the attention scores. We employ commonly-used music-specific evaluation metrics and a human study, to gauge time-varying controllability, adherence to global text cues, and overall audio realism. The automatic and human evaluations indicate that the proposed combination of prompt-to-prompt guidance with autoregressive generation models significantly outperforms the diffusion-based baseline in terms of melody, dynamics, and tempo of the generated audio. Our code is available at https://github.com/billsioros/EditGen",
      "authors": [
        "Vassilis Sioros",
        "Alexandros Potamianos",
        "Giorgos Paraskevopoulos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:44:11+00:00",
          "link": "https://arxiv.org/abs/2507.11096v1",
          "size": "920kb",
          "version": "v1"
        }
      ],
      "title": "EditGen: Harnessing Cross-Attention Control for Instruction-Based Auto-Regressive Audio Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11096",
        "HTML": "https://arxiv.org/html/2507.11096v1",
        "PDF": "https://arxiv.org/pdf/2507.11096"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study explores audio editing methods using cross-attention control in autoregressive models without any focus on LLM training data processing or dataset preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11162",
      "abstract": "We exhibit an $n$-bit communication problem with a constant-cost randomized protocol but which requires $n^{\\Omega(1)}$ deterministic (or even non-deterministic) queries to an Equality oracle. Therefore, even constant-cost randomized protocols cannot be efficiently \"derandomized\" using Equality oracles. This improves on several recent results and answers a question from the survey of Hatami and Hatami (SIGACT News 2024). It also gives a significantly simpler and quantitatively superior proof of the main result of Fang, G\\\"o\\\"os, Harms, and Hatami ( STOC 2025), that constant-cost communication does not reduce to the $k$-Hamming Distance hierarchy.",
      "authors": [
        "Mika G\\\"o\\\"os",
        "Nathaniel Harms",
        "Artur Riazanov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:10:21+00:00",
          "link": "https://arxiv.org/abs/2507.11162v1",
          "size": "21kb",
          "version": "v1"
        }
      ],
      "title": "Equality is Far Weaker than Constant-Cost Communication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11162",
        "HTML": "https://arxiv.org/html/2507.11162v1",
        "PDF": "https://arxiv.org/pdf/2507.11162"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a communication problem and protocols, which are unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.04975",
      "abstract": "Few-shot learning and parameter-efficient fine-tuning (PEFT) are crucial to overcome the challenges of data scarcity and ever growing language model sizes. This applies in particular to specialized scientific domains, where researchers might lack expertise and resources to fine-tune high-performing language models to nuanced tasks. We propose PETapter, a novel method that effectively combines PEFT methods with PET-style classification heads to boost few-shot learning capabilities without the significant computational overhead typically associated with full model training. We validate our approach on three established NLP benchmark datasets and one real-world dataset from communication research. We show that PETapter not only achieves comparable performance to full few-shot fine-tuning using pattern-exploiting training (PET), but also provides greater reliability and higher parameter efficiency while enabling higher modularity and easy sharing of the trained modules, which enables more researchers to utilize high-performing NLP-methods in their research.",
      "authors": [
        "Jonas Rieger",
        "Mattes Ruckdeschel",
        "Gregor Wiedemann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-06T11:49:18+00:00",
          "link": "https://arxiv.org/abs/2412.04975v1",
          "size": "8051kb",
          "version": "v1"
        }
      ],
      "title": "PETapter: Leveraging PET-style classification heads for modular few-shot parameter-efficient fine-tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.04975",
        "HTML": "https://arxiv.org/html/2412.04975",
        "PDF": "https://arxiv.org/pdf/2412.04975"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a fine-tuning method using PET-style classification heads, without discussing LLM training data processing or dataset creation."
      },
      "tasks": [
        "Few-Shot Learning",
        "Language Modeling",
        "Language Modelling",
        "parameter-efficient fine-tuning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10616",
      "abstract": "Training large language models (LLMs) for reasoning via maths and code datasets has become a major new focus in LLM post-training. Two particularly popular approaches are reinforcement learning (RL) and supervised fine-tuning (SFT), but their training dynamics are poorly understood. We present a comparative analysis of RL and SFT on the same maths problems with the same model and similar hyperparameters. We find that RL yields minor in-domain gains on maths and slight degradation on knowledge-intensive benchmarks like MMLU, while both trends are more pronounced in SFT. We also analyse model parameters across checkpoints, observing that both algorithms modify query and key weights the most. Meanwhile, SFT exhibits greater updates and also affects mid-layer MLPs more, leading us to hypothesise that this may have caused the out-of-domain degradation. We therefore investigate whether freezing parts of the model during training can mitigate the reduced performance on knowledge-intensive benchmarks. However, our results are inconclusive, with benefits on GPQA:Diamond and degradation on other benchmarks. Taken together, our observations provide a preliminary indication for why RL amplifies existing capabilities, while SFT replaces old skills with new ones.",
      "authors": [
        "Neel Rajani",
        "Aryo Pradipta Gema",
        "Seraphina Goldfarb-Tarrant",
        "Ivan Titov"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T19:04:17+00:00",
          "link": "https://arxiv.org/abs/2507.10616v1",
          "size": "2480kb",
          "version": "v1"
        }
      ],
      "title": "Scalpel vs. Hammer: GRPO Amplifies Existing Capabilities, SFT Replaces Them",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10616",
        "HTML": "https://arxiv.org/html/2507.10616v1",
        "PDF": "https://arxiv.org/pdf/2507.10616"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on a comparative analysis of RL and SFT for reasoning tasks and their training dynamics, which includes some discussion on training data effects, but it is primarily centered on training dynamics rather than data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.10705",
      "abstract": "A significant challenge in applying planning technology to real-world problems lies in obtaining a planning model that accurately represents the problem's dynamics. Obtaining a planning model is even more challenging in mission-critical domains, where a trial-and-error approach to learning how to act is not an option. In such domains, the action model used to generate plans must be safe, in the sense that plans generated with it must be applicable and achieve their goals. % Learning safe action models for planning has been mostly explored for domains in which states are sufficiently described with Boolean variables. % In this work, we go beyond this limitation and propose the Numeric Safe Action Models Learning (N-SAM) algorithm. In this work, we present N-SAM, an action model learning algorithm capable of learning safe numeric preconditions and effects. We prove that N-SAM runs in linear time in the number of observations and, under certain conditions, is guaranteed to return safe action models. However, to preserve this safety guarantee, N-SAM must observe a substantial number of examples for each action before including it in the learned model. We address this limitation of N-SAM and propose N-SAM*, an extension to the N-SAM algorithm that always returns an action model where every observed action is applicable at least in some states, even if it was observed only once. N-SAM* does so without compromising the safety of the returned action model. We prove that N-SAM* is optimal in terms of sample complexity compared to any other algorithm that guarantees safety. N-SAM and N-SAM* are evaluated over an extensive benchmark of numeric planning domains, and their performance is compared to a state-of-the-art numeric action model learning algorithm. We also provide a discussion on the impact of numerical accuracy on the learning process.",
      "authors": [
        "Argaman Mordoch",
        "Shahaf S. Shperberg",
        "Roni Stern",
        "Berndan Juba"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-17T12:50:10+00:00",
          "link": "https://arxiv.org/abs/2312.10705v1",
          "size": "3287kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T12:35:13+00:00",
          "link": "https://arxiv.org/abs/2312.10705v2",
          "size": "809kb",
          "version": "v2"
        }
      ],
      "title": "Learning Safe Numeric Planning Action Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.10705",
        "HTML": "https://arxiv.org/html/2312.10705v2",
        "PDF": "https://arxiv.org/pdf/2312.10705"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on learning safe numeric planning action models and does not discuss LLM training data processing or creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.06341",
      "abstract": "Quantum circuit unoptimization is an algorithm that transforms a quantum circuit into a different circuit that uses more gate operations while maintaining the same unitary transformation. We demonstrate that this method can implement digital zero-noise extrapolation (ZNE), a quantum error mitigation technique. By employing quantum circuit unoptimization as a form of circuit folding, noise can be systematically amplified. The key advantages of this approach are twofold. First, its ability to generate an exponentially increasing number of distinct circuit variants as the noise level is amplified, which allows noise averaging over many circuit variants with slightly different circuit structure. Averaging over these variants can mitigate the effect of biased error propagation due to the significantly altered circuit structure from quantum circuit unoptimization, or biased noise sources on a quantum processor. Second, quantum circuit unoptimization by design resists circuit simplification back to the original unmodified circuit, making it plausible to use ZNE in contexts where circuit compiler optimization is applied server-side. We evaluate the effectiveness of quantum circuit unoptimization as a noise-scaling method for ZNE in two test cases using depolarizing noise numerical simulations: random quantum volume circuits, where the observable is the heavy output probability, and QAOA circuits for the (unweighted) maximum cut problem on random 3-regular graphs, where the observable is the cut value. We show that using quantum circuit unoptimization to perform ZNE can approximately recover signal from noisy quantum simulations.",
      "authors": [
        "Elijah Pelofske",
        "Vincent Russo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-08T21:06:48+00:00",
          "link": "https://arxiv.org/abs/2503.06341v1",
          "size": "466kb",
          "version": "v1"
        },
        {
          "date": "2025-04-16T18:53:44+00:00",
          "link": "https://arxiv.org/abs/2503.06341v2",
          "size": "466kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T19:18:08+00:00",
          "link": "https://arxiv.org/abs/2503.06341v3",
          "size": "466kb",
          "version": "v3"
        }
      ],
      "title": "Digital Zero-Noise Extrapolation with Quantum Circuit Unoptimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.06341",
        "HTML": "https://arxiv.org/html/2503.06341v3",
        "PDF": "https://arxiv.org/pdf/2503.06341"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on quantum error mitigation techniques and does not involve LLM training data processing or data engineering."
      },
      "repo_urls": [
        "https://github.com/unitaryfund/circuit-unoptimization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10585",
      "abstract": "Effective AI governance requires structured approaches for stakeholders to access and verify AI system behavior. With the rise of large language models, Natural Language Explanations (NLEs) are now key to articulating model behavior, which necessitates a focused examination of their characteristics and governance implications. We draw on Explainable AI (XAI) literature to create an updated XAI taxonomy, adapted to prompt-based NLEs, across three dimensions: (1) Context, including task, data, audience, and goals; (2) Generation and Presentation, covering generation methods, inputs, interactivity, outputs, and forms; and (3) Evaluation, focusing on content, presentation, and user-centered properties, as well as the setting of the evaluation. This taxonomy provides a framework for researchers, auditors, and policymakers to characterize, design, and enhance NLEs for transparent AI systems.",
      "authors": [
        "Isar Nejadgholi and Mona Omidyeganeh and Marc-Antoine Drouin and Jonathan Boisvert"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:52:19+00:00",
          "link": "https://arxiv.org/abs/2507.10585v1",
          "size": "483kb",
          "version": "v1"
        }
      ],
      "title": "A Taxonomy for Design and Evaluation of Prompt-Based Natural Language Explanations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10585",
        "HTML": "https://arxiv.org/html/2507.10585v1",
        "PDF": "https://arxiv.org/pdf/2507.10585"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a taxonomy for prompt-based natural language explanations for AI governance, without addressing LLM training data collection, processing, or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.07723",
      "abstract": "Depth estimation is a cornerstone of 3D reconstruction and plays a vital role in minimally invasive endoscopic surgeries. However, most current depth estimation networks rely on traditional convolutional neural networks, which are limited in their ability to capture global information. Foundation models offer a promising approach to enhance depth estimation, but those models currently available are primarily trained on natural images, leading to suboptimal performance when applied to endoscopic images. In this work, we introduce a novel fine-tuning strategy for the Depth Anything Model and integrate it with an intrinsic-based unsupervised monocular depth estimation framework. Our approach includes a low-rank adaptation technique based on random vectors, which improves the model's adaptability to different scales. Additionally, we propose a residual block built on depthwise separable convolution to compensate for the transformer's limited ability to capture local features. Our experimental results on the SCARED dataset and Hamlyn dataset show that our method achieves state-of-the-art performance while minimizing the number of trainable parameters. Applying this method in minimally invasive endoscopic surgery can enhance surgeons' spatial awareness, thereby improving the precision and safety of the procedures.",
      "authors": [
        "Bojian Li",
        "Bo Liu",
        "Xinning Yao",
        "Jinghua Yue",
        "Fugen Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-12T03:04:43+00:00",
          "link": "https://arxiv.org/abs/2409.07723v1",
          "size": "603kb",
          "version": "v1"
        },
        {
          "date": "2025-03-06T01:40:10+00:00",
          "link": "https://arxiv.org/abs/2409.07723v2",
          "size": "799kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T08:54:57+00:00",
          "link": "https://arxiv.org/abs/2409.07723v3",
          "size": "804kb",
          "version": "v3"
        }
      ],
      "title": "Advancing Depth Anything Model for Unsupervised Monocular Depth Estimation in Endoscopy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.07723",
        "HTML": "https://arxiv.org/html/2409.07723v3",
        "PDF": "https://arxiv.org/pdf/2409.07723"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a novel fine-tuning strategy for depth estimation models but primarily focuses on model architecture improvements rather than training data processing."
      },
      "tasks": [
        "3D Reconstruction",
        "Depth Estimation",
        "Monocular Depth Estimation",
        "Unsupervised Monocular Depth Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.16366",
      "abstract": "Most safety training methods for large language models (LLMs) are based on fine-tuning that forces models to shift from an unsafe answer to refusal when faced with harmful requests. Unfortunately, these drastic distribution shifts generally compromise model capabilities. To avoid that, we propose to expand the model's vocabulary with a special token we call red flag token (<rf>) and propose to train the model to insert this token into its response at any time when harmful content is generated or about to be generated. Our approach offers several advantages: it enables the model to explicitly learn the concept of harmfulness while marginally affecting the generated distribution, thus maintaining the model's utility. It also evaluates each generated answer and provides robustness as good as adversarial training without the need to run attacks during training. Moreover, by encapsulating our safety tuning in a LoRA module, we provide additional defenses against fine-tuning API attacks.",
      "authors": [
        "Sophie Xhonneux",
        "David Dobre",
        "Mehrnaz Mofakhami",
        "Leo Schwinn",
        "Gauthier Gidel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-22T21:48:48+00:00",
          "link": "https://arxiv.org/abs/2502.16366v1",
          "size": "1672kb",
          "version": "v1"
        },
        {
          "date": "2025-03-05T20:31:47+00:00",
          "link": "https://arxiv.org/abs/2502.16366v2",
          "size": "1662kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T16:12:44+00:00",
          "link": "https://arxiv.org/abs/2502.16366v3",
          "size": "868kb",
          "version": "v3"
        }
      ],
      "title": "A Generative Approach to LLM Harmfulness Detection with Special Red Flag Tokens",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.16366",
        "HTML": "https://arxiv.org/html/2502.16366v3",
        "PDF": "https://arxiv.org/pdf/2502.16366"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a technique for modifying the model's vocabulary with a 'red flag token' to enhance safety training, which affects data during fine-tuning, but does not primarily focus on training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.17774",
      "abstract": "Foundation models have achieved remarkable success across video, image, and language domains. By scaling up the number of parameters and training datasets, these models acquire generalizable world knowledge and often surpass task-specific approaches. However, such progress has yet to extend to the domain of physics simulation. A primary bottleneck is data scarcity: while millions of images, videos, and textual resources are readily available on the internet, the largest physics simulation datasets contain only tens of thousands of samples. This data limitation hinders the use of large models, as overfitting becomes a major concern. As a result, physics applications typically rely on small models, which struggle with long-range prediction due to limited context understanding. Additionally, unlike images, videos, or text-which typically exhibit fixed granularity-physics datasets often vary drastically in scale, amplifying the challenges of scaling up multitask training. We introduce PhysiX, the first large-scale foundation model for physics simulation. PhysiX is a 4.5B parameter autoregressive generative model. It uses a discrete tokenizer to encode physical processes at different scales into a sequence of discrete tokens, and employs an autoregressive next-token prediction objective to model such processes in the token space. To mitigate the rounding error in the discretization process, PhysiX incorporates a specialized refinement module. Through extensive experiments, we show that PhysiX effectively addresses the data bottleneck, outperforming task-specific baselines under comparable settings as well as the previous absolute state-of-the-art approaches on The Well benchmark. Our results indicate that knowledge learned from natural videos can be successfully transferred to physics simulation, and that joint training across diverse simulation tasks enables synergistic learning.",
      "authors": [
        "Tung Nguyen",
        "Arsh Koneru",
        "Shufan Li",
        "Aditya Grover"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-21T18:10:12+00:00",
          "link": "https://arxiv.org/abs/2506.17774v1",
          "size": "7961kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T23:30:55+00:00",
          "link": "https://arxiv.org/abs/2506.17774v2",
          "size": "7961kb",
          "version": "v2"
        }
      ],
      "title": "PhysiX: A Foundation Model for Physics Simulations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17774",
        "HTML": "https://arxiv.org/html/2506.17774v2",
        "PDF": "https://arxiv.org/pdf/2506.17774"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a foundation model for physics simulations, focusing on model architecture and training rather than processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10951",
      "abstract": "The complete connectome of the Drosophila larva brain offers a unique opportunity to investigate whether biologically evolved circuits can support artificial intelligence. We convert this wiring diagram into a Biological Processing Unit (BPU), a fixed recurrent network derived directly from synaptic connectivity. Despite its modest size 3,000 neurons and 65,000 weights between them), the unmodified BPU achieves 98% accuracy on MNIST and 58% on CIFAR-10, surpassing size-matched MLPs. Scaling the BPU via structured connectome expansions further improves CIFAR-10 performance, while modality-specific ablations reveal the uneven contributions of different sensory subsystems. On the ChessBench dataset, a lightweight GNN-BPU model trained on only 10,000 games achieves 60% move accuracy, nearly 10x better than any size transformer. Moreover, CNN-BPU models with ~2M parameters outperform parameter-matched Transformers, and with a depth-6 minimax search at inference, reach 91.7% accuracy, exceeding even a 9M-parameter Transformer baseline. These results demonstrate the potential of biofidelic neural architectures to support complex cognitive tasks and motivate scaling to larger and more intelligent connectomes in future work.",
      "authors": [
        "Siyu Yu",
        "Zihan Qin",
        "Tingshan Liu",
        "Beiya Xu",
        "R. Jacob Vogelstein",
        "Jason Brown",
        "Joshua T. Vogelstein"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T03:31:57+00:00",
          "link": "https://arxiv.org/abs/2507.10951v1",
          "size": "2073kb",
          "version": "v1"
        }
      ],
      "title": "Biological Processing Units: Leveraging an Insect Connectome to Pioneer Biofidelic Neural Architectures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10951",
        "PDF": "https://arxiv.org/pdf/2507.10951"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper's primary focus is on leveraging biological neural architectures for AI rather than on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11357",
      "abstract": "The ubiquitous independence assumption among symbolic concepts in neurosymbolic (NeSy) predictors is a convenient simplification: NeSy predictors use it to speed up probabilistic reasoning. Recent works like van Krieken et al. (2024) and Marconato et al. (2024) argued that the independence assumption can hinder learning of NeSy predictors and, more crucially, prevent them from correctly modelling uncertainty. There is, however, scepticism in the NeSy community around the scenarios in which the independence assumption actually limits NeSy systems (Faronius and Dos Martires, 2025). In this work, we settle this question by formally showing that assuming independence among symbolic concepts entails that a model can never represent uncertainty over certain concept combinations. Thus, the model fails to be aware of reasoning shortcuts, i.e., the pathological behaviour of NeSy predictors that predict correct downstream tasks but for the wrong reasons.",
      "authors": [
        "Emile van Krieken",
        "Pasquale Minervini",
        "Edoardo Ponti",
        "Antonio Vergari"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:27:05+00:00",
          "link": "https://arxiv.org/abs/2507.11357v1",
          "size": "765kb",
          "version": "v1"
        }
      ],
      "title": "Neurosymbolic Reasoning Shortcuts under the Independence Assumption",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11357",
        "HTML": "https://arxiv.org/html/2507.11357v1",
        "PDF": "https://arxiv.org/pdf/2507.11357"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work examines the independence assumption in neurosymbolic systems, focusing on theoretical aspects of reasoning shortcuts and uncertainty, with no emphasis on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.02734",
      "abstract": "3D single object tracking is essential in autonomous driving and robotics. Existing methods often struggle with sparse and incomplete point cloud scenarios. To address these limitations, we propose a Multimodal-guided Virtual Cues Projection (MVCP) scheme that generates virtual cues to enrich sparse point clouds. Additionally, we introduce an enhanced tracker MVCTrack based on the generated virtual cues. Specifically, the MVCP scheme seamlessly integrates RGB sensors into LiDAR-based systems, leveraging a set of 2D detections to create dense 3D virtual cues that significantly improve the sparsity of point clouds. These virtual cues can naturally integrate with existing LiDAR-based 3D trackers, yielding substantial performance gains. Extensive experiments demonstrate that our method achieves competitive performance on the NuScenes dataset.",
      "authors": [
        "Zhaofeng Hu",
        "Sifan Zhou",
        "Zhihang Yuan",
        "Dawei Yang",
        "Shibo Zhao",
        "Ci-Jyun Liang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-03T18:18:33+00:00",
          "link": "https://arxiv.org/abs/2412.02734v1",
          "size": "6669kb",
          "version": "v1"
        },
        {
          "date": "2024-12-13T06:17:48+00:00",
          "link": "https://arxiv.org/abs/2412.02734v2",
          "size": "6668kb",
          "version": "v2"
        },
        {
          "date": "2025-03-07T14:21:17+00:00",
          "link": "https://arxiv.org/abs/2412.02734v3",
          "size": "5839kb",
          "version": "v3"
        },
        {
          "date": "2025-03-24T23:48:06+00:00",
          "link": "https://arxiv.org/abs/2412.02734v4",
          "size": "5839kb",
          "version": "v4"
        },
        {
          "date": "2025-07-15T07:29:38+00:00",
          "link": "https://arxiv.org/abs/2412.02734v5",
          "size": "2165kb",
          "version": "v5"
        }
      ],
      "title": "MVCTrack: Boosting 3D Point Cloud Tracking via Multimodal-Guided Virtual Cues",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.02734",
        "HTML": "https://arxiv.org/html/2412.02734v5",
        "PDF": "https://arxiv.org/pdf/2412.02734"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper proposes a new method for 3D point cloud tracking using multimodal-guided virtual cues with no emphasis on LLM training data processing."
      },
      "tasks": [
        "3D Single Object Tracking",
        "Autonomous Driving",
        "Object Tracking"
      ],
      "repo_urls": [
        "https://github.com/StiphyJay/MVCTrack"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.01100",
      "abstract": "We investigate the logical reasoning capabilities of large language models (LLMs) and their scalability in complex non-monotonic reasoning. To this end, we introduce ZebraLogic, a comprehensive evaluation framework for assessing LLM reasoning performance on logic grid puzzles derived from constraint satisfaction problems (CSPs). ZebraLogic enables the generation of puzzles with controllable and quantifiable complexity, facilitating a systematic study of the scaling limits of models such as Llama, o1 models, and DeepSeek-R1. By encompassing a broad range of search space complexities and diverse logical constraints, ZebraLogic provides a structured environment to evaluate reasoning under increasing difficulty.\n  Our results reveal a significant decline in accuracy as problem complexity grows -- a phenomenon we term the curse of complexity. This limitation persists even with larger models and increased inference-time computation, suggesting inherent constraints in current LLM reasoning capabilities. Additionally, we explore strategies to enhance logical reasoning, including Best-of-N sampling, backtracking mechanisms, and self-verification prompts. Our findings offer critical insights into the scalability of LLM reasoning, highlight fundamental limitations, and outline potential directions for improvement.",
      "authors": [
        "Bill Yuchen Lin",
        "Ronan Le Bras",
        "Kyle Richardson",
        "Ashish Sabharwal",
        "Radha Poovendran",
        "Peter Clark",
        "Yejin Choi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-03T06:44:49+00:00",
          "link": "https://arxiv.org/abs/2502.01100v1",
          "size": "18441kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T01:14:25+00:00",
          "link": "https://arxiv.org/abs/2502.01100v2",
          "size": "2931kb",
          "version": "v2"
        }
      ],
      "title": "ZebraLogic: On the Scaling Limits of LLMs for Logical Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.01100",
        "HTML": "https://arxiv.org/html/2502.01100v2",
        "PDF": "https://arxiv.org/pdf/2502.01100"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper investigates logical reasoning capabilities of LLMs using logical puzzles in the ZebraLogic framework, without addressing LLM training data processing or dataset engineering."
      },
      "datasets": [
        {
          "dataset_name": "WildEval/ZebraLogic",
          "downloads": "1123",
          "likes": "8",
          "link": "https://huggingface.co/datasets/WildEval/ZebraLogic"
        }
      ],
      "tasks": [
        "Logical Reasoning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.00200",
      "abstract": "Skid-steered wheel mobile robots (SSWMRs) are characterized by the unique domination of the tire-terrain skidding for the robot to move. The lack of reliable friction models cascade into unreliable motion models, especially the reduced ordered variants used for state estimation and robot control. Ensemble modeling is an emerging research direction where the overall motion model is broken down into a family of local models to distribute the performance and resource requirement and provide a fast real-time prediction. To this end, a gaussian mixture model based modeling identification of model clusters is adopted and implemented within an interactive multiple model (IMM) based state estimation. The framework is adopted and implemented for angular velocity as the estimated state for a mid scaled skid-steered wheel mobile robot platform.",
      "authors": [
        "Ameya Salvi",
        "Mark Brudnak",
        "Jonathon M. Smereka",
        "Matthias Schmid",
        "Venkat Krovi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-30T21:59:51+00:00",
          "link": "https://arxiv.org/abs/2505.00200v1",
          "size": "4699kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T02:43:45+00:00",
          "link": "https://arxiv.org/abs/2505.00200v2",
          "size": "3517kb",
          "version": "v2"
        }
      ],
      "title": "Characterizing gaussian mixture of motion modes for skid-steer vehicle state estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00200",
        "HTML": "https://arxiv.org/html/2505.00200v2",
        "PDF": "https://arxiv.org/pdf/2505.00200"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is focused on a modeling framework for state estimation of skid-steer vehicles and does not discuss any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.00715",
      "abstract": "The time domain Boundary Element Method (BEM) for the homogeneous wave equation with vanishing initial conditions is considered. For the temporal discretisation, the generalized convolution quadrature method (gCQ) developed by Lopez-Fernandez and Sauter is used. The spatial discretisation is done classically using low-order shape functions.\n  Essentially, the gCQ requires to establish boundary element matrices of the corresponding elliptic problem in Laplace domain at several complex frequencies. Consequently, an array of system matrices is obtained. This array of system matrices can be interpreted as a three-dimensional array of data which should be approximated by a data-sparse representation, for which the generalised Adaptive Cross Approximation (3D-ACA) can be applied. The rank of the three-dimensional data array is increased adaptively until a prescribed accuracy is obtained. On a pure algebraic level, it is decided whether a low-rank approximation of the three-dimensional data array is close enough to the original matrix. Within the data slices corresponding to the BEM calculations for each frequency, either the standard $\\mathcal{H}$-matrices approach with ACA or a fast multipole (FMM) approach can be used. The third dimension of the data array represents the complex frequencies. Hence, the algorithm does not only sparsify the data array in the two spatial dimensions but also adaptively detects how much frequencies are necessary for which matrix block.\n  he two versions, either using ACA or FMM within the slices, are briefly discussed. The main contribution of this paper is a comparison of both with respect to savings in storage and computing time. The example of the sound scattering of an electric machine shows that both techniques allow to utilise a time-domain BEM in real-world problems.",
      "authors": [
        "Martin Schanz and Vibudha Lakshmi Keshava and Herbert de Gersem"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-16T13:31:56+00:00",
          "link": "https://arxiv.org/abs/2505.00715v1",
          "size": "1345kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T22:57:30+00:00",
          "link": "https://arxiv.org/abs/2505.00715v2",
          "size": "1743kb",
          "version": "v2"
        }
      ],
      "title": "Comparison of FMM and $\\mathcal{H}$-matrix based 3D-ACA for a time domain boundary element method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.00715",
        "HTML": "https://arxiv.org/html/2505.00715v2",
        "PDF": "https://arxiv.org/pdf/2505.00715"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on computational methods for boundary element methods in acoustic simulations and does not involve any LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.01504",
      "abstract": "The collection and release of street-level recordings as Open Data play a vital role in advancing autonomous driving systems and AI research. However, these datasets pose significant privacy risks, particularly for pedestrians, due to the presence of Personally Identifiable Information (PII) that extends beyond biometric traits such as faces. In this paper, we present cRID, a novel cross-modal framework combining Large Vision-Language Models, Graph Attention Networks, and representation learning to detect textual describable clues of PII and enhance person re-identification (Re-ID). Our approach focuses on identifying and leveraging interpretable features, enabling the detection of semantically meaningful PII beyond low-level appearance cues. We conduct a systematic evaluation of PII presence in person image datasets. Our experiments show improved performance in practical cross-dataset Re-ID scenarios, notably from Market-1501 to CUHK03-np (detected), highlighting the framework's practical utility. Code is available at https://github.com/RAufschlaeger/cRID.",
      "authors": [
        "Robert Aufschl\\\"ager",
        "Youssef Shoeb",
        "Azarm Nowzad",
        "Michael Heigl",
        "Fabian Bally",
        "and Martin Schramm"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T09:10:33+00:00",
          "link": "https://arxiv.org/abs/2507.01504v1",
          "size": "1721kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T09:13:19+00:00",
          "link": "https://arxiv.org/abs/2507.01504v2",
          "size": "1722kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T14:54:52+00:00",
          "link": "https://arxiv.org/abs/2507.01504v3",
          "size": "1722kb",
          "version": "v3"
        }
      ],
      "title": "Following the Clues: Experiments on Person Re-ID using Cross-Modal Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.01504",
        "HTML": "https://arxiv.org/html/2507.01504v3",
        "PDF": "https://arxiv.org/pdf/2507.01504"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on a framework for detecting PII in image datasets for person re-identification, without contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05728",
      "abstract": "With more event datasets being released online, safeguarding the event dataset against unauthorized usage has become a serious concern for data owners. Unlearnable Examples are proposed to prevent the unauthorized exploitation of image datasets. However, it's unclear how to create unlearnable asynchronous event streams to prevent event misuse. In this work, we propose the first unlearnable event stream generation method to prevent unauthorized training from event datasets. A new form of asynchronous event error-minimizing noise is proposed to perturb event streams, tricking the unauthorized model into learning embedded noise instead of realistic features. To be compatible with the sparse event, a projection strategy is presented to sparsify the noise to render our unlearnable event streams (UEvs). Extensive experiments demonstrate that our method effectively protects event data from unauthorized exploitation, while preserving their utility for legitimate use. We hope our UEvs contribute to the advancement of secure and trustworthy event dataset sharing. Code is available at: https://github.com/rfww/uevs.",
      "authors": [
        "Ruofei Wang",
        "Peiqi Duan",
        "Boxin Shi",
        "Renjie Wan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T07:21:59+00:00",
          "link": "https://arxiv.org/abs/2507.05728v1",
          "size": "14209kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T02:57:25+00:00",
          "link": "https://arxiv.org/abs/2507.05728v2",
          "size": "14209kb",
          "version": "v2"
        }
      ],
      "title": "Asynchronous Event Error-Minimizing Noise for Safeguarding Event Dataset",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05728",
        "HTML": "https://arxiv.org/html/2507.05728v2",
        "PDF": "https://arxiv.org/pdf/2507.05728"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on safeguarding event datasets from unauthorized use by generating unlearnable examples, and does not involve any LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05906",
      "abstract": "This survey provides a comparative analysis of feature-based and GAN-based approaches to learning from demonstrations, with a focus on the structure of reward functions and their implications for policy learning. Feature-based methods offer dense, interpretable rewards that excel at high-fidelity motion imitation, yet often require sophisticated representations of references and struggle with generalization in unstructured settings. GAN-based methods, in contrast, use implicit, distributional supervision that enables scalability and adaptation flexibility, but are prone to training instability and coarse reward signals. Recent advancements in both paradigms converge on the importance of structured motion representations, which enable smoother transitions, controllable synthesis, and improved task integration. We argue that the dichotomy between feature-based and GAN-based methods is increasingly nuanced: rather than one paradigm dominating the other, the choice should be guided by task-specific priorities such as fidelity, diversity, interpretability, and adaptability. This work outlines the algorithmic trade-offs and design considerations that underlie method selection, offering a framework for principled decision-making in learning from demonstrations.",
      "authors": [
        "Chenhao Li",
        "Marco Hutter",
        "Andreas Krause"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Graphics (cs.GR)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T11:45:51+00:00",
          "link": "https://arxiv.org/abs/2507.05906v1",
          "size": "471kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T11:07:33+00:00",
          "link": "https://arxiv.org/abs/2507.05906v2",
          "size": "471kb",
          "version": "v2"
        }
      ],
      "title": "Feature-Based vs. GAN-Based Learning from Demonstrations: When and Why",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05906",
        "HTML": "https://arxiv.org/html/2507.05906v2",
        "PDF": "https://arxiv.org/pdf/2507.05906"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a survey on learning from demonstrations comparing feature-based and GAN-based methods, but it does not address LLM training data processing or creation directly."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10577",
      "abstract": "Misinformation poses a significant threat in today's digital world, often spreading rapidly through platforms like YouTube. This paper introduces a novel approach to combating misinformation by developing an AI-powered system that not only fact-checks claims made in YouTube videos but also actively engages users in the comment section and challenge misleading narratives. Our system comprises two main agents: Truth Sleuth and Trend Bender.\n  Truth Sleuth extracts claims from a YouTube video, uses a Retrieval-Augmented Generation (RAG) approach - drawing on sources like Wikipedia, Google Search, Google FactCheck - to accurately assess their veracity and generates a nuanced and comprehensive report. Through rigorous prompt engineering, Trend Bender leverages this report along with a curated corpus of relevant articles to generate insightful and persuasive comments designed to stimulate a productive debate. With a carefully set up self-evaluation loop, this agent is able to iteratively improve its style and refine its output.\n  We demonstrate the system's capabilities through experiments on established benchmark datasets and a real-world deployment on YouTube, showcasing its potential to engage users and potentially influence perspectives. Our findings highlight the high accuracy of our fact-checking agent, and confirm the potential of AI-driven interventions in combating misinformation and fostering a more informed online space.",
      "authors": [
        "Log\\'e C\\'ecile",
        "Ghori Rehan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T10:08:05+00:00",
          "link": "https://arxiv.org/abs/2507.10577v1",
          "size": "8514kb",
          "version": "v1"
        }
      ],
      "title": "Truth Sleuth and Trend Bender: AI Agents to fact-check YouTube videos and influence opinions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10577",
        "HTML": "https://arxiv.org/html/2507.10577v1",
        "PDF": "https://arxiv.org/pdf/2507.10577"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study introduces an AI system to fact-check and engage with misinformation on YouTube. There is no focus on processing or improving LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10579",
      "abstract": "This shared task has aimed to assess pedagogical abilities of AI tutors powered by large language models (LLMs), focusing on evaluating the quality of tutor responses aimed at student's mistake remediation within educational dialogues. The task consisted of five tracks designed to automatically evaluate the AI tutor's performance across key dimensions of mistake identification, precise location of the mistake, providing guidance, and feedback actionability, grounded in learning science principles that define good and effective tutor responses, as well as the track focusing on detection of the tutor identity. The task attracted over 50 international teams across all tracks. The submitted models were evaluated against gold-standard human annotations, and the results, while promising, show that there is still significant room for improvement in this domain: the best results for the four pedagogical ability assessment tracks range between macro F1 scores of 58.34 (for providing guidance) and 71.81 (for mistake identification) on three-class problems, with the best F1 score in the tutor identification track reaching 96.98 on a 9-class task. In this paper, we overview the main findings of the shared task, discuss the approaches taken by the teams, and analyze their performance. All resources associated with this task are made publicly available to support future research in this critical domain.",
      "authors": [
        "Ekaterina Kochmar",
        "Kaushal Kumar Maurya",
        "Kseniia Petukhova",
        "KV Aditya Srivatsa",
        "Ana\\\"is Tack",
        "Justin Vasselli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T10:57:36+00:00",
          "link": "https://arxiv.org/abs/2507.10579v1",
          "size": "365kb",
          "version": "v1"
        }
      ],
      "title": "Findings of the BEA 2025 Shared Task on Pedagogical Ability Assessment of AI-powered Tutors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10579",
        "HTML": "https://arxiv.org/html/2507.10579v1",
        "PDF": "https://arxiv.org/pdf/2507.10579"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on evaluating AI tutors' pedagogical abilities using existing models and datasets, without making contributions to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.07645",
      "abstract": "Table 1 of Hall (1988) contains asymptotic coverage error formulas for some nonparametric approximate 95\\% confidence intervals for the mean based on $n$ IID samples. The table includes an entry for an interval based on the central limit theorem using Gaussian quantiles and the Gaussian maximum likelihood variance estimate. It is missing an entry for the very widely used Student's $t$ confidence intervals. This note develops such a formula. The impetus to revisit this issue arose from the surprisingly robust performance of confidence intervals based on Student's t statistic in randomized quasi-Monte Carlo sampling. Hall's table had $0.14\\kappa -2.12\\gamma^2-3.35$ for normal theory intervals; the corresponding entry for Student's $t$ is $0.14\\kappa -2.12\\gamma^2$.\n  An earlier version of this note reported that it corrected some coverage error formulas in Hall (1988). Two-sided errors take the form $2\\Phi^{-1}(0.975)(A\\kappa + \\gamma^2+C)\\varphi(1.96)/n +O(1/n^{3/2})$ where the error may well be $O(n^{-2})$. Hall's table showed $\\Phi^{-1}(0.975)(A\\kappa + B\\gamma^2+C)$. The version intended as a correction had $2(A\\kappa + B\\gamma^2+C)$, wider by about $2/1.96\\doteq1.02$. So, Hall's table really is proportional to the two-sided coverage errors.",
      "authors": [
        "Art B. Owen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistics Theory (math.ST)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-13T19:11:34+00:00",
          "link": "https://arxiv.org/abs/2501.07645v1",
          "size": "4kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T01:11:46+00:00",
          "link": "https://arxiv.org/abs/2501.07645v2",
          "size": "5kb",
          "version": "v2"
        }
      ],
      "title": "Coverage errors for Student's t confidence intervals comparable to those in Hall (1988)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.07645",
        "HTML": "https://arxiv.org/html/2501.07645v2",
        "PDF": "https://arxiv.org/pdf/2501.07645"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses statistical coverage errors related to confidence intervals and does not involve LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10640",
      "abstract": "The widespread use of social media applications has raised significant privacy concerns, often highlighted in user reviews. These reviews also provide developers with valuable insights into improving apps by addressing issues and introducing better features. However, the sheer volume and nuanced nature of reviews make manual identification and prioritization of privacy-related concerns challenging for developers. Previous studies have developed software utilities to automatically classify user reviews as privacy-relevant, privacy-irrelevant, bug reports, feature requests, etc., using machine learning. Notably, there is a lack of focus on classifying reviews specifically as privacy-related feature requests, privacy-related bug reports, or privacy-irrelevant. This paper introduces SENtinel SORt (SENSOR), an automated online annotation tool designed to help developers annotate and classify user reviews into these categories. For automating the annotation of such reviews, this paper introduces the annotation model, GRACE (GRU-based Attention with CBOW Embedding), using Gated Recurrent Units (GRU) with Continuous Bag of Words (CBOW) and Attention mechanism. Approximately 16000 user reviews from seven popular social media apps on Google Play Store, including Instagram, Facebook, WhatsApp, Snapchat, X (formerly Twitter), Facebook Lite, and Line were analyzed. Two annotators manually labelled the reviews, achieving a Cohen's Kappa value of 0.87, ensuring a labeled dataset with high inter-rater agreement for training machine learning models. Among the models tested, GRACE demonstrated the best performance (macro F1-score: 0.9434, macro ROC-AUC: 0.9934, and accuracy: 95.10%) despite class imbalance. SENSOR demonstrates significant potential to assist developers with extracting and addressing privacy-related feature requests or bug reports from user reviews, enhancing user privacy and trust.",
      "authors": [
        "Labiba Farah",
        "Mohammad Ridwan Kabir",
        "Shohel Ahmed",
        "MD Mohaymen Ul Anam",
        "Md. Sakibul Islam"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:58:04+00:00",
          "link": "https://arxiv.org/abs/2507.10640v1",
          "size": "5036kb",
          "version": "v1"
        }
      ],
      "title": "SENSOR: An ML-Enhanced Online Annotation Tool to Uncover Privacy Concerns from User Reviews in Social-Media Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10640",
        "HTML": "https://arxiv.org/html/2507.10640v1",
        "PDF": "https://arxiv.org/pdf/2507.10640"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing an annotation tool for classifying user reviews into privacy-related categories using ML, which does not involve LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10810",
      "abstract": "In this paper, we explored how online hate is motivated by receiving social approval from others. We specifically examined two central tenets of Walther's (2024) social approval theory of online hate: (H1a) more signals of social approval on hate messages predicts more subsequent hate messages, and (H1b) as social approval increases, hate speech messages become more extreme. Using over 110 million posts from Parler (2018-2021), we observed that the number of upvotes a person received on a hate speech post was unassociated with the amount of hate speech in their next post and posts during the next week, month, three months, and six months. Between-person effects revealed an average negative relationship between social approval and hate speech production at the post level, but this relationship was mixed at other time intervals. Social approval reinforcement mechanisms of online hate may operate differently on niche social media platforms.",
      "authors": [
        "David M. Markowitz",
        "Samuel Hardman Taylor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T21:10:39+00:00",
          "link": "https://arxiv.org/abs/2507.10810v1",
          "size": "731kb",
          "version": "v1"
        }
      ],
      "title": "Testing Hypotheses from the Social Approval Theory of Online Hate: An Analysis of 110 Million Posts from Parler",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10810",
        "PDF": "https://arxiv.org/pdf/2507.10810"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study analyzes online hate posts and social approval, with no connection to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10778",
      "abstract": "Spatial understanding has been a challenging task for existing Multi-modal Large Language Models~(MLLMs). Previous methods leverage large-scale MLLM finetuning to enhance MLLM's spatial understanding ability. In this paper, we present a data-efficient approach. We propose a LLM agent system with strong and advanced spatial reasoning ability, which can be used to solve the challenging spatial question answering task in complex indoor warehouse scenarios. Our system integrates multiple tools that allow the LLM agent to conduct spatial reasoning and API tools interaction to answer the given complicated spatial question. Extensive evaluations on the 2025 AI City Challenge Physical AI Spatial Intelligence Warehouse dataset demonstrate that our system achieves high accuracy and efficiency in tasks such as object retrieval, counting, and distance estimation. The code is available at: https://github.com/hsiangwei0903/SpatialAgent",
      "authors": [
        "Hsiang-Wei Huang",
        "Jen-Hao Cheng",
        "Kuang-Ming Chen",
        "Cheng-Yen Yang",
        "Bahaa Alattar",
        "Yi-Ru Lin",
        "Pyongkun Kim",
        "Sangwon Kim",
        "Kwangju Kim",
        "Chung-I Huang",
        "Jenq-Neng Hwang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T20:05:55+00:00",
          "link": "https://arxiv.org/abs/2507.10778v1",
          "size": "218kb",
          "version": "v1"
        }
      ],
      "title": "Warehouse Spatial Question Answering with LLM Agent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10778",
        "HTML": "https://arxiv.org/html/2507.10778v1",
        "PDF": "https://arxiv.org/pdf/2507.10778"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper presents a LLM agent for spatial question answering but primarily focuses on spatial reasoning and tool integration rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11461",
      "abstract": "Deep Equilibrium Models (DEQs) are implicit neural networks with fixed points, which have recently gained attention for learning image regularization functionals, particularly in settings involving Gaussian fidelities, where assumptions on the forward operator ensure contractiveness of standard (proximal) Gradient Descent operators. In this work, we extend the application of DEQs to Poisson inverse problems, where the data fidelity term is more appropriately modeled by the Kullback-Leibler divergence. To this end, we introduce a novel DEQ formulation based on Mirror Descent defined in terms of a tailored non-Euclidean geometry that naturally adapts with the structure of the data term. This enables the learning of neural regularizers within a principled training framework. We derive sufficient conditions to guarantee the convergence of the learned reconstruction scheme and propose computational strategies that enable both efficient training and fully parameter-free inference. Numerical experiments show that our method outperforms traditional model-based approaches and it is comparable to the performance of Bregman Plug-and-Play methods, while mitigating their typical drawbacks - namely, sensitivity to initialization and careful tuning of hyperparameters. The code is publicly available at https://github.com/christiandaniele/DEQ-MD.",
      "authors": [
        "Christian Daniele",
        "Silvia Villa",
        "Samuel Vaiter",
        "Luca Calatroni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:33:01+00:00",
          "link": "https://arxiv.org/abs/2507.11461v1",
          "size": "2658kb",
          "version": "v1"
        }
      ],
      "title": "Deep Equilibrium models for Poisson Imaging Inverse problems via Mirror Descent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11461",
        "HTML": "https://arxiv.org/html/2507.11461v1",
        "PDF": "https://arxiv.org/pdf/2507.11461"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a deep equilibrium model and its application to Poisson imaging inverse problems, without discussing any data collection or processing for LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.16525",
      "abstract": "Large language model-generated code (LLMgCode) has become increasingly common in software development. So far LLMgCode has more quality issues than human-authored code (HaCode). It is common for LLMgCode to mix with HaCode in a code change, while the change is signed by only human developers, without being carefully examined. Many automated methods have been proposed to detect LLMgCode from HaCode, in which the perplexity-based method (PERPLEXITY for short) is the state-of-the-art method. However, the efficacy evaluation of PERPLEXITY has focused on detection accuracy. Yet it is unclear whether PERPLEXITY is good enough in a wider range of realistic evaluation settings. To this end, we carry out a family of experiments to compare PERPLEXITY against feature- and pre-training-based methods from three perspectives: detection accuracy, detection speed, and generalization capability. The experimental results show that PERPLEXITY has the best generalization capability while having limited detection accuracy and detection speed. Based on that, we discuss the strengths and limitations of PERPLEXITY, e.g., PERPLEXITY is unsuitable for high-level programming languages. Finally, we provide recommendations to improve PERPLEXITY and apply it in practice. As the first large-scale investigation on detecting LLMgCode from HaCode, this article provides a wide range of findings for future improvement.",
      "authors": [
        "Jinwei Xu",
        "He Zhang",
        "Yanjing Yang",
        "Lanxin Yang",
        "Zeru Cheng",
        "Jun Lyu",
        "Bohan Liu",
        "Xin Zhou",
        "Alberto Bacchelli",
        "Yin Kia Chiam",
        "Thiam Kian Chiew"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-21T08:02:58+00:00",
          "link": "https://arxiv.org/abs/2412.16525v1",
          "size": "1273kb",
          "version": "v1"
        },
        {
          "date": "2025-07-09T10:04:06+00:00",
          "link": "https://arxiv.org/abs/2412.16525v2",
          "size": "778kb",
          "version": "v2"
        }
      ],
      "title": "One Size Does Not Fit All: Investigating Efficacy of Perplexity in Detecting LLM-Generated Code",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.16525",
        "HTML": "https://arxiv.org/html/2412.16525",
        "PDF": "https://arxiv.org/pdf/2412.16525"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper evaluates methods for detecting LLM-generated code, touching on training methods but does not focus on processing or creating LLM training data in detail."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.18397",
      "abstract": "Chain-of-thought (CoT) reasoning greatly improves the interpretability and problem-solving abilities of multimodal large language models (MLLMs). However, existing approaches are focused on text CoT, limiting their ability to leverage visual cues. Visual CoT remains underexplored, and the only work is based on supervised fine-tuning (SFT) that relies on extensive labeled bounding-box data and is hard to generalize to unseen cases. In this paper, we introduce Unsupervised Visual CoT (UV-CoT), a novel framework for image-level CoT reasoning via preference optimization. UV-CoT performs preference comparisons between model-generated bounding boxes (one is preferred and the other is dis-preferred), eliminating the need for bounding-box annotations. We get such preference data by introducing an automatic data generation pipeline. Given an image, our target MLLM (e.g., LLaVA-1.5-7B) generates seed bounding boxes using a template prompt and then answers the question using each bounded region as input. An evaluator MLLM (e.g., OmniLLM-12B) ranks the responses, and these rankings serve as supervision to train the target MLLM with UV-CoT by minimizing negative log-likelihood losses. By emulating human perception--identifying key regions and reasoning based on them--UV-CoT can improve visual comprehension, particularly in spatial reasoning tasks where textual descriptions alone fall short. Our experiments on six datasets demonstrate the superiority of UV-CoT, compared to the state-of-the-art textual and visual CoT methods. Our zero-shot testing on four unseen datasets shows the strong generalization of UV-CoT. The code is available in https://github.com/kesenzhao/UV-CoT.",
      "authors": [
        "Kesen Zhao",
        "Beier Zhu",
        "Qianru Sun",
        "Hanwang Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-25T14:48:18+00:00",
          "link": "https://arxiv.org/abs/2504.18397v1",
          "size": "26977kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T07:32:27+00:00",
          "link": "https://arxiv.org/abs/2504.18397v2",
          "size": "24077kb",
          "version": "v2"
        }
      ],
      "title": "Unsupervised Visual Chain-of-Thought Reasoning via Preference Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.18397",
        "HTML": "https://arxiv.org/html/2504.18397v2",
        "PDF": "https://arxiv.org/pdf/2504.18397"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces a novel framework (UV-CoT) involving an automatic data generation pipeline for unsupervised visual CoT reasoning, highlighting its contribution to new data processing steps for training MLLMs."
      },
      "tasks": [
        "Spatial Reasoning"
      ],
      "repo_urls": [
        "https://github.com/kesenzhao/uv-cot"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10593",
      "abstract": "Large Language Model (LLM) applications are increasingly relying on external tools to extend their capabilities beyond text generation. However, current tool integration approaches suffer from fragmentation, protocol limitations, and implementation complexity, leading to substantial development overhead. This paper presents Toolregistry, a protocol-agnostic tool management library that simplifies tool registration, representation, execution, and lifecycle management via a unified interface. Our evaluation demonstrates that \\toolregistry achieves 60-80% reduction in tool integration code, up to 3.1x performance improvements through concurrent execution, and 100% compatibility with OpenAI function calling standards. Real-world case studies show significant improvements in development efficiency and code maintainability across diverse integration scenarios. \\toolregistry is open-source and available at https://github.com/Oaklight/ToolRegistry, with comprehensive documentation at https://toolregistry.readthedocs.io/.",
      "authors": [
        "Peng Ding"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T20:23:23+00:00",
          "link": "https://arxiv.org/abs/2507.10593v1",
          "size": "137kb",
          "version": "v1"
        }
      ],
      "title": "ToolRegistry: A Protocol-Agnostic Tool Management Library for Function-Calling LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10593",
        "HTML": "https://arxiv.org/html/2507.10593v1",
        "PDF": "https://arxiv.org/pdf/2507.10593"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a protocol-agnostic tool management library for LLMs, focusing on tool integration rather than any aspect of training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10906",
      "abstract": "Commit messages are essential in software development as they serve to document and explain code changes. Yet, their quality often falls short in practice, with studies showing significant proportions of empty or inadequate messages. While automated commit message generation has advanced significantly, particularly with Large Language Models (LLMs), the evaluation of generated messages remains challenging. Traditional reference-based automatic metrics like BLEU, ROUGE-L, and METEOR have notable limitations in assessing commit message quality, as they assume a one-to-one mapping between code changes and commit messages, leading researchers to rely on resource-intensive human evaluation. This study investigates the potential of LLMs as automated evaluators for commit message quality. Through systematic experimentation with various prompt strategies and state-of-the-art LLMs, we demonstrate that LLMs combining Chain-of-Thought reasoning with few-shot demonstrations achieve near human-level evaluation proficiency. Our LLM-based evaluator significantly outperforms traditional metrics while maintaining acceptable reproducibility, robustness, and fairness levels despite some inherent variability. This work conducts a comprehensive preliminary study on using LLMs for commit message evaluation, offering a scalable alternative to human assessment while maintaining high-quality evaluation.",
      "authors": [
        "Qunhong Zeng",
        "Yuxia Zhang",
        "Zexiong Ma",
        "Bo Jiang",
        "Ningyuan Sun",
        "Klaas-Jan Stol",
        "Xingyu Mou",
        "Hui Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T01:50:20+00:00",
          "link": "https://arxiv.org/abs/2507.10906v1",
          "size": "72kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Generated Commit Messages with Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10906",
        "HTML": "https://arxiv.org/html/2507.10906v1",
        "PDF": "https://arxiv.org/pdf/2507.10906"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on evaluating the quality of commit messages generated by LLMs using automated evaluation methods, not on LLM training data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.14728",
      "abstract": "We present a unified geometric framework for modeling learning dynamics in physical, biological, and machine learning systems. The theory reveals three fundamental regimes, each emerging from the power-law relationship $g \\propto \\kappa^\\alpha$ between the metric tensor $g$ in the space of trainable variables and the noise covariance matrix $\\kappa$. The quantum regime corresponds to $\\alpha = 1$ and describes Schr\\\"odinger-like dynamics that emerges from a discrete shift symmetry. The efficient learning regime corresponds to $\\alpha = \\tfrac{1}{2}$ and describes very fast machine learning algorithms. The equilibration regime corresponds to $\\alpha = 0$ and describes classical models of biological evolution. We argue that the emergence of the intermediate regime $\\alpha = \\tfrac{1}{2}$ is a key mechanism underlying the emergence of biological complexity.",
      "authors": [
        "Vitaly Vanchurin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Populations and Evolution (q-bio.PE)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-20T19:56:41+00:00",
          "link": "https://arxiv.org/abs/2504.14728v1",
          "size": "20kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T22:21:14+00:00",
          "link": "https://arxiv.org/abs/2504.14728v2",
          "size": "21kb",
          "version": "v2"
        }
      ],
      "title": "Geometric Learning Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.14728",
        "HTML": "https://arxiv.org/html/2504.14728v2",
        "PDF": "https://arxiv.org/pdf/2504.14728"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a geometric framework for modeling learning dynamics, with no focus on LLM training data processing or data engineering operations."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.10789",
      "abstract": "The rapid development in scientific research provides a need for more compute power, which is partly being solved by GPUs. This paper presents a microarchitectural analysis of the modern NVIDIA Blackwell architecture by studying GPU performance\n  features with thought through microbenchmarks. We unveil key subsystems, including the memory hierarchy, SM execution\n  pipelines, and the SM sub-core units, including the 5th generation tensor cores supporting FP4 and FP6 precisions.\n  To understand the different key features of the NVIDIA GPU, we study latency, throughput, cache behavior, and scheduling\n  details, revealing subtle tuning metrics in the design of Blackwell. To develop a comprehensive analysis, we compare the\n  Blackwell architecture with the previous Hopper architecture by using the GeForce RTX 5080 and H100 PCIe, respectively. We\n  evaluate and compare results, presenting both generational improvements and performance regressions. Additionally, we\n  investigate the role of power efficiency and energy consumption under varied workloads. Our findings provide actionable insights\n  for application developers, compiler writers, and performance engineers to optimize workloads on Blackwell-based platforms,\n  and contribute new data to the growing research on GPU architectures.",
      "authors": [
        "Aaron Jarmusch",
        "Nathan Graddon",
        "Sunita Chandrasekaran"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T20:38:09+00:00",
          "link": "https://arxiv.org/abs/2507.10789v1",
          "size": "1684kb",
          "version": "v1"
        }
      ],
      "title": "Dissecting the NVIDIA Blackwell Architecture with Microbenchmarks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10789",
        "HTML": "https://arxiv.org/html/2507.10789v1",
        "PDF": "https://arxiv.org/pdf/2507.10789"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper provides a microarchitectural analysis of the NVIDIA Blackwell GPU and does not contribute to LLM training data processing or data engineering methods."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11407",
      "abstract": "This technical report introduces EXAONE 4.0, which integrates a Non-reasoning mode and a Reasoning mode to achieve both the excellent usability of EXAONE 3.5 and the advanced reasoning abilities of EXAONE Deep. To pave the way for the agentic AI era, EXAONE 4.0 incorporates essential features such as agentic tool use, and its multilingual capabilities are extended to support Spanish in addition to English and Korean. The EXAONE 4.0 model series consists of two sizes: a mid-size 32B model optimized for high performance, and a small-size 1.2B model designed for on-device applications. The EXAONE 4.0 demonstrates superior performance compared to open-weight models in its class and remains competitive even against frontier-class models. The models are publicly available for research purposes and can be easily downloaded via https://huggingface.co/LGAI-EXAONE.",
      "authors": [
        "LG AI Research: Kyunghoon Bae",
        "Eunbi Choi",
        "Kibong Choi",
        "Stanley Jungkyu Choi",
        "Yemuk Choi",
        "Kyubeen Han",
        "Seokhee Hong",
        "Junwon Hwang",
        "Taewan Hwang",
        "Joonwon Jang",
        "Hyojin Jeon",
        "Kijeong Jeon",
        "Gerrard Jeongwon Jo",
        "Hyunjik Jo",
        "Jiyeon Jung",
        "Euisoon Kim",
        "Hyosang Kim",
        "Jihoon Kim",
        "Joonkee Kim",
        "Seonghwan Kim",
        "Soyeon Kim",
        "Sunkyoung Kim",
        "Yireun Kim",
        "Yongil Kim",
        "Youchul Kim",
        "Edward Hwayoung Lee",
        "Gwangho Lee",
        "Haeju Lee",
        "Honglak Lee",
        "Jinsik Lee",
        "Kyungmin Lee",
        "Sangha Park",
        "Young Min Paik",
        "Yongmin Park",
        "Youngyong Park",
        "Sanghyun Seo",
        "Sihoon Yang",
        "Heuiyeen Yeen",
        "Sihyuk Yi",
        "Hyeongu Yun"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:24:51+00:00",
          "link": "https://arxiv.org/abs/2507.11407v1",
          "size": "1121kb",
          "version": "v1"
        }
      ],
      "title": "EXAONE 4.0: Unified Large Language Models Integrating Non-reasoning and Reasoning Modes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11407",
        "HTML": "https://arxiv.org/html/2507.11407v1",
        "PDF": "https://arxiv.org/pdf/2507.11407"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on integrating different modes in a language model and introducing features like multilingual capabilities and agentic tool use, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.08706",
      "abstract": "General intelligence requires systems that acquire new skills efficiently and generalize beyond their training distributions. Although program synthesis approaches have strong generalization power, they face scaling issues due to large combinatorial spaces that quickly make them impractical and require human-generated DSLs or pre-trained priors to narrow this search space. On the other hand, deep learning methods have had high successes, but they lack structured test-time adaptation and rely on heavy stochastic sampling or expensive gradient updates for fine-tuning. In this work, we propose the Latent Program Network (LPN), a new architecture that builds in test-time search directly into neural models. LPN learns a latent space of implicit programs--neurally mapping inputs to outputs--through which it can search using gradients at test time. LPN combines the adaptability of symbolic approaches and the scalability of neural methods. It searches through a compact latent space at test time and bypasses the need for pre-defined domain-specific languages. On a range of programming-by-examples tasks, LPN either outperforms or matches performance compared to in-context learning and test-time training methods. Tested on the ARC-AGI benchmark, we demonstrate that LPN can both learn a compact program space and search through it at test time to adapt to novel tasks. LPN doubles its performance on out-of-distribution tasks when test-time search is switched on.",
      "authors": [
        "Matthew V Macfarlane",
        "Cl\\'ement Bonnet"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-13T15:50:32+00:00",
          "link": "https://arxiv.org/abs/2411.08706v1",
          "size": "2435kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T17:04:14+00:00",
          "link": "https://arxiv.org/abs/2411.08706v2",
          "size": "6867kb",
          "version": "v2"
        }
      ],
      "title": "Searching Latent Program Spaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.08706",
        "HTML": "https://arxiv.org/html/2411.08706v2",
        "PDF": "https://arxiv.org/pdf/2411.08706"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper proposes a new architecture for program synthesis, it does not specifically address LLM training data processing methods."
      },
      "tasks": [
        "ARC",
        "Program induction",
        "Program Synthesis",
        "Test-time Adaptation"
      ],
      "repo_urls": [
        "https://github.com/clement-bonnet/lpn"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.00877",
      "abstract": "Time-series forecasting has gained significant attention in machine learning due to its crucial role in various domains. However, most existing forecasting models rely heavily on point-wise loss functions like Mean Square Error, which treat each time step independently and neglect the structural dependencies inherent in time series data, making it challenging to capture complex temporal patterns accurately. To address these challenges, we propose a novel Patch-wise Structural (PS) loss, designed to enhance structural alignment by comparing time series at the patch level. Through leveraging local statistical properties, such as correlation, variance, and mean, PS loss captures nuanced structural discrepancies overlooked by traditional point-wise losses. Furthermore, it integrates seamlessly with point-wise loss, simultaneously addressing local structural inconsistencies and individual time-step errors. PS loss establishes a novel benchmark for accurately modeling complex time series data and provides a new perspective on time series loss function design. Extensive experiments demonstrate that PS loss significantly improves the performance of state-of-the-art models across diverse real-world datasets.",
      "authors": [
        "Dilfira Kudrat",
        "Zongxia Xie",
        "Yanru Sun",
        "Tianyu Jia",
        "Qinghua Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-02T12:36:15+00:00",
          "link": "https://arxiv.org/abs/2503.00877v1",
          "size": "768kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T05:33:15+00:00",
          "link": "https://arxiv.org/abs/2503.00877v2",
          "size": "588kb",
          "version": "v2"
        }
      ],
      "title": "Patch-wise Structural Loss for Time Series Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00877",
        "HTML": "https://arxiv.org/html/2503.00877v2",
        "PDF": "https://arxiv.org/pdf/2503.00877"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel loss function for time-series forecasting, without any mention of LLM training data processing or dataset creation."
      },
      "tasks": [
        "Time Series",
        "Time Series Forecasting"
      ],
      "repo_urls": [
        "https://github.com/Dilfiraa/PS_Loss"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10559",
      "abstract": "Recent developments in large language models (LLMs) have been accompanied by rapidly growing public interest in natural language processing (NLP). This attention is reflected by major news venues, which sometimes invite NLP researchers to share their knowledge and views with a wide audience. Recognizing the opportunities of the present, for both the research field and for individual researchers, this paper shares recommendations for communicating with a general audience about LLMs' capabilities and limitations. These recommendations cover three themes: vague terminology as an obstacle to public understanding, unreasonable expectations as obstacles to sustainable growth, and ethical failures as obstacles to continued support. Published NLP research and popular news coverage are cited to illustrate these themes with examples. The recommendations promote effective, transparent communication with the general public about NLP, in order to strengthen public understanding and encourage support for research.",
      "authors": [
        "Shomir Wilson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-02T15:50:09+00:00",
          "link": "https://arxiv.org/abs/2507.10559v1",
          "size": "40kb",
          "version": "v1"
        }
      ],
      "title": "NLP Meets the World: Toward Improving Conversations With the Public About Natural Language Processing Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10559",
        "HTML": "https://arxiv.org/html/2507.10559v1",
        "PDF": "https://arxiv.org/pdf/2507.10559"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides recommendations for public communication about NLP research but does not address any aspects of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10611",
      "abstract": "Federated Learning (FL) emerged as a solution for collaborative medical image classification while preserving data privacy. However, label noise, which arises from inter-institutional data variability, can cause training instability and degrade model performance. Existing FL methods struggle with noise heterogeneity and the imbalance in medical data. Motivated by these challenges, we propose FedGSCA, a novel framework for enhancing robustness in noisy medical FL. FedGSCA introduces a Global Sample Selector that aggregates noise knowledge from all clients, effectively addressing noise heterogeneity and improving global model stability. Furthermore, we develop a Client Adaptive Adjustment (CAA) mechanism that combines adaptive threshold pseudo-label generation and Robust Credal Labeling Loss. CAA dynamically adjusts to class distributions, ensuring the inclusion of minority samples and carefully managing noisy labels by considering multiple plausible labels. This dual approach mitigates the impact of noisy data and prevents overfitting during local training, which improves the generalizability of the model. We evaluate FedGSCA on one real-world colon slides dataset and two synthetic medical datasets under various noise conditions, including symmetric, asymmetric, extreme, and heterogeneous types. The results show that FedGSCA outperforms the state-of-the-art methods, excelling in extreme and heterogeneous noise scenarios. Moreover, FedGSCA demonstrates significant advantages in improving model stability and handling complex noise, making it well-suited for real-world medical federated learning scenarios.",
      "authors": [
        "Mengwen Ye",
        "Yingzi Huangfu",
        "Shujian Gao",
        "Wei Ren",
        "Weifan Liu",
        "Zekuan Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T08:51:51+00:00",
          "link": "https://arxiv.org/abs/2507.10611v1",
          "size": "3240kb",
          "version": "v1"
        }
      ],
      "title": "FedGSCA: Medical Federated Learning with Global Sample Selector and Client Adaptive Adjuster under Label Noise",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10611",
        "HTML": "https://arxiv.org/html/2507.10611v1",
        "PDF": "https://arxiv.org/pdf/2507.10611"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on federated learning in medical image classification and robustness to label noise, with no emphasis on LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10628",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as a powerful paradigm for facilitating the self-improvement of large language models (LLMs), particularly in the domain of complex reasoning tasks. However, prevailing on-policy RL methods often contend with significant training instability and inefficiency. This is primarily due to a capacity-difficulty mismatch, where the complexity of training data frequently outpaces the model's current capabilities, leading to critically sparse reward signals and stalled learning progress. This challenge is particularly acute for smaller, more resource-efficient LLMs. To overcome this, we introduce the Guided Hybrid Policy Optimization (GHPO), a novel difficulty-aware reinforcement learning framework. GHPO dynamically calibrates task difficulty by employing adaptive prompt refinement to provide targeted guidance. This unique approach adaptively balances direct imitation learning for problems currently beyond the model's reach with exploration-based reinforcement learning for more manageable tasks, effectively creating a smooth and optimized learning curriculum. Extensive experiments demonstrate that GHPO achieves an average performance gain of approximately 5% across six challenging mathematics benchmarks, consistently outperforming strong on-policy reinforcement learning and curriculum learning baselines. Further analysis confirms that our framework significantly enhances both training stability and final reasoning performance, thus offering a scalable and efficient solution for developing powerful and robust reasoning models.",
      "authors": [
        "Ziru Liu",
        "Cheng Gong",
        "Xinyu Fu",
        "Yaofang Liu",
        "Ran Chen",
        "Shoubo Hu",
        "Suiyun Zhang",
        "Rui Liu",
        "Qingfu Zhang",
        "Dandan Tu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:10:00+00:00",
          "link": "https://arxiv.org/abs/2507.10628v1",
          "size": "5671kb",
          "version": "v1"
        }
      ],
      "title": "GHPO: Adaptive Guidance for Stable and Efficient LLM Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10628",
        "HTML": "https://arxiv.org/html/2507.10628v1",
        "PDF": "https://arxiv.org/pdf/2507.10628"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on reinforcement learning techniques to improve LLM stability and efficiency, rather than on processing or creating training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11112",
      "abstract": "Recent studies have shown that Large Language Models (LLMs) are vulnerable to data poisoning attacks, where malicious training examples embed hidden behaviours triggered by specific input patterns. However, most existing works assume a phrase and focus on the attack's effectiveness, offering limited understanding of trigger mechanisms and how multiple triggers interact within the model. In this paper, we present a framework for studying poisoning in LLMs. We show that multiple distinct backdoor triggers can coexist within a single model without interfering with each other, enabling adversaries to embed several triggers concurrently. Using multiple triggers with high embedding similarity, we demonstrate that poisoned triggers can achieve robust activation even when tokens are substituted or separated by long token spans. Our findings expose a broader and more persistent vulnerability surface in LLMs. To mitigate this threat, we propose a post hoc recovery method that selectively retrains specific model components based on a layer-wise weight difference analysis. Our method effectively removes the trigger behaviour with minimal parameter updates, presenting a practical and efficient defence against multi-trigger poisoning.",
      "authors": [
        "Sanhanat Sivapiromrat",
        "Caiqi Zhang",
        "Marco Basaldella",
        "Nigel Collier"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:04:30+00:00",
          "link": "https://arxiv.org/abs/2507.11112v1",
          "size": "95kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Trigger Poisoning Amplifies Backdoor Vulnerabilities in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11112",
        "HTML": "https://arxiv.org/html/2507.11112v1",
        "PDF": "https://arxiv.org/pdf/2507.11112"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper's primary focus is on investigating backdoor vulnerabilities in LLMs and proposes a method to mitigate these vulnerabilities; it does not directly focus on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11081",
      "abstract": "Ground penetrating radar (GPR) has become a rapid and non-destructive solution for road subsurface distress (RSD) detection. However, RSD recognition from GPR images is labor-intensive and heavily relies on inspectors' expertise. Deep learning offers the possibility for automatic RSD recognition, but its current performance is limited by two factors: Scarcity of high-quality dataset for network training and insufficient capability of network to distinguish RSD. In this study, a rigorously validated 3D GPR dataset containing 2134 samples of diverse types was constructed through field scanning. Based on the finding that the YOLO model trained with one of the three scans of GPR images exhibits varying sensitivity to specific type of RSD, we proposed a novel cross-verification strategy with outstanding accuracy in RSD recognition, achieving recall over 98.6% in field tests. The approach, integrated into an online RSD detection system, can reduce the labor of inspection by around 90%.",
      "authors": [
        "Chang Peng",
        "Bao Yang",
        "Meiqi Li",
        "Ge Zhang",
        "Hui Sun",
        "and Zhenyu Jiang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:23:21+00:00",
          "link": "https://arxiv.org/abs/2507.11081v1",
          "size": "782kb",
          "version": "v1"
        }
      ],
      "title": "Automatic Road Subsurface Distress Recognition from Ground Penetrating Radar Images using Deep Learning-based Cross-verification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11081",
        "PDF": "https://arxiv.org/pdf/2507.11081"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper outlines the creation of a high-quality 3D GPR dataset for road subsurface distress recognition, providing detailed data processing and validation steps, which is central to this contribution."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11171",
      "abstract": "Citrus, as one of the most economically important fruit crops globally, suffers severe yield depressions due to various diseases. Accurate disease detection and classification serve as critical prerequisites for implementing targeted control measures. Recent advancements in artificial intelligence, particularly deep learning-based computer vision algorithms, have substantially decreased time and labor requirements while maintaining the accuracy of detection and classification. Nevertheless, these methods predominantly rely on massive, high-quality annotated training examples to attain promising performance. By introducing two key designs: contrasting with cluster centroids and a multi-layer contrastive training (MCT) paradigm, this paper proposes a novel clustering-guided self-supervised multi-layer contrastive representation learning (CMCRL) algorithm. The proposed method demonstrates several advantages over existing counterparts: (1) optimizing with massive unannotated samples; (2) effective adaptation to the symptom similarity across distinct citrus diseases; (3) hierarchical feature representation learning. The proposed method achieves state-of-the-art performance on the public citrus image set CDD, outperforming existing methods by 4.5\\%-30.1\\% accuracy. Remarkably, our method narrows the performance gap with fully supervised counterparts (all samples are labeled). Beyond classification accuracy, our method shows great performance on other evaluation metrics (F1 score, precision, and recall), highlighting the robustness against the class imbalance challenge.",
      "authors": [
        "Jun Chen",
        "Yonghua Yu",
        "Weifu Li",
        "Yaohui Chen",
        "Hong Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:22:52+00:00",
          "link": "https://arxiv.org/abs/2507.11171v1",
          "size": "4061kb",
          "version": "v1"
        }
      ],
      "title": "Clustering-Guided Multi-Layer Contrastive Representation Learning for Citrus Disease Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11171",
        "HTML": "https://arxiv.org/html/2507.11171v1",
        "PDF": "https://arxiv.org/pdf/2507.11171"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a contrastive representation learning method for citrus disease classification, focusing on computer vision tasks, not on processing or enhancing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11439",
      "abstract": "Currently, iTransformer is one of the most popular and effective models for multivariate time series (MTS) forecasting. Thanks to its inverted framework, iTransformer effectively captures multivariate correlation. However, the inverted framework still has some limitations. It diminishes temporal interdependency information, and introduces noise in cases of nonsignificant variable correlation. To address these limitations, we introduce a novel data augmentation method on inverted framework, called DAIF. Unlike previous data augmentation methods, DAIF stands out as the first real-time augmentation specifically designed for the inverted framework in MTS forecasting. We first define the structure of the inverted sequence-to-sequence framework, then propose two different DAIF strategies, Frequency Filtering and Cross-variation Patching to address the existing challenges of the inverted framework. Experiments across multiple datasets and inverted models have demonstrated the effectiveness of our DAIF.",
      "authors": [
        "Hongming Tan",
        "Ting Chen",
        "Ruochong Jin",
        "Wai Kin Chan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:01:58+00:00",
          "link": "https://arxiv.org/abs/2507.11439v1",
          "size": "502kb",
          "version": "v1"
        }
      ],
      "title": "Data Augmentation in Time Series Forecasting through Inverted Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11439",
        "HTML": "https://arxiv.org/html/2507.11439v1",
        "PDF": "https://arxiv.org/pdf/2507.11439"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a data augmentation method specifically for time series forecasting, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10920",
      "abstract": "Large language models (LLMs) often show poor performance in low-resource languages like Korean, partly due to unique linguistic challenges such as homophonous Sino-Korean words that are indistinguishable in Hangul script. To address this semantic ambiguity, we propose HanjaBridge, a novel meaning-injection technique integrated into a continual pre-training (CPT) framework. Instead of deterministically mapping a word to a single Hanja (Chinese character), HanjaBridge presents the model with all possible Hanja candidates for a given homograph, encouraging the model to learn contextual disambiguation. This process is paired with token-level knowledge distillation to prevent catastrophic forgetting. Experimental results show that HanjaBridge significantly improves Korean language understanding, achieving a 21\\% relative improvement on the KoBALT benchmark. Notably, by reinforcing semantic alignment between Korean and Chinese through shared Hanja, we observe a strong positive cross-lingual transfer. Furthermore, these gains persist even when Hanja augmentation is omitted at inference time, ensuring practical efficiency with no additional run-time cost.",
      "authors": [
        "Seungho Choi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T02:26:47+00:00",
          "link": "https://arxiv.org/abs/2507.10920v1",
          "size": "413kb",
          "version": "v1"
        }
      ],
      "title": "HanjaBridge: Resolving Semantic Ambiguity in Korean LLMs via Hanja-Augmented Pre-Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10920",
        "PDF": "https://arxiv.org/pdf/2507.10920"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents HanjaBridge, a method integrated into a continual pre-training framework to address semantic ambiguity in Korean LLMs, which directly involves processing and improving data for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11092",
      "abstract": "Recently, several studies have indicated that data poisoning attacks pose a severe security threat to deep learning-based (DL-based) code search models. Attackers inject carefully crafted malicious patterns into the training data, misleading the code search model to learn these patterns during training. During the usage of the poisoned code search model for inference, once the malicious pattern is triggered, the model tends to rank the vulnerability code higher. However, existing detection methods for data poisoning attacks on DL-based code search models remain insufficiently effective. To address this critical security issue, we propose MT4DP, a Data Poisoning Attack Detection Framework for DL-based Code Search Models via Metamorphic Testing. MT4DP introduces a novel Semantically Equivalent Metamorphic Relation (SE-MR) designed to detect data poisoning attacks on DL-based code search models. Specifically, MT4DP first identifies the high-frequency words from search queries as potential poisoning targets and takes their corresponding queries as the source queries. For each source query, MT4DP generates two semantically equivalent follow-up queries and retrieves its source ranking list. Then, each source ranking list is re-ranked based on the semantic similarities between its code snippets and the follow-up queries. Finally, variances between the source and re-ranked lists are calculated to reveal violations of the SE-MR and warn the data poisoning attack. Experimental results demonstrate that MT4DP significantly enhances the detection of data poisoning attacks on DL-based code search models, outperforming the best baseline by 191% on average F1 score and 265% on average precision. Our work aims to promote further research into effective techniques for mitigating data poisoning threats on DL-based code search models.",
      "authors": [
        "Gong Chen",
        "Wenjie Liu",
        "Xiaoyuan Xie",
        "Xunzhu Tang",
        "Tegawend\\'e F. Bissyand\\'e",
        "Songqiang Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:38:59+00:00",
          "link": "https://arxiv.org/abs/2507.11092v1",
          "size": "1096kb",
          "version": "v1"
        }
      ],
      "title": "MT4DP: Data Poisoning Attack Detection for DL-based Code Search Models via Metamorphic Testing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11092",
        "HTML": "https://arxiv.org/html/2507.11092v1",
        "PDF": "https://arxiv.org/pdf/2507.11092"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on detecting data poisoning attacks on code search models rather than addressing LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.11673",
      "abstract": "Large language models (LLMs) are increasingly capable of simulating human behavior, offering cost-effective ways to estimate user responses to various surveys and polls. However, the questions in these surveys usually reflect socially understood attitudes: the patterns of attitudes of old/young, liberal/conservative, as understood by both members and non-members of those groups. It is not clear whether the LLM binding is \\emph{deep}, meaning the LLM answers as a member of a particular in-group would, or \\emph{shallow}, meaning the LLM responds as an out-group member believes an in-group member would. To explore this difference, we use questions that expose known in-group/out-group biases. This level of fidelity is critical for applying LLMs to various political science studies, including timely topics on polarization dynamics, inter-group conflict, and democratic backsliding. To this end, we propose a novel methodology for constructing virtual personas with synthetic user ``backstories\" generated as extended, multi-turn interview transcripts. Our generated backstories are longer, rich in detail, and consistent in authentically describing a singular individual, compared to previous methods. We show that virtual personas conditioned on our backstories closely replicate human response distributions (up to an 87\\% improvement as measured by Wasserstein Distance) and produce effect sizes that closely match those observed in the original studies of in-group/out-group biases. Altogether, our work extends the applicability of LLMs beyond estimating socially understood responses, enabling their use in a broader range of human studies.",
      "authors": [
        "Minwoo Kang",
        "Suhong Moon",
        "Seung Hyeong Lee",
        "Ayush Raj",
        "Joseph Suh",
        "David M. Chan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-16T00:10:34+00:00",
          "link": "https://arxiv.org/abs/2504.11673v1",
          "size": "637kb",
          "version": "v1"
        },
        {
          "date": "2025-06-12T21:11:01+00:00",
          "link": "https://arxiv.org/abs/2504.11673v2",
          "size": "634kb",
          "version": "v2"
        },
        {
          "date": "2025-06-21T03:50:53+00:00",
          "link": "https://arxiv.org/abs/2504.11673v3",
          "size": "635kb",
          "version": "v3"
        },
        {
          "date": "2025-07-14T22:24:48+00:00",
          "link": "https://arxiv.org/abs/2504.11673v4",
          "size": "635kb",
          "version": "v4"
        }
      ],
      "title": "Deep Binding of Language Model Virtual Personas: a Study on Approximating Political Partisan Misperceptions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.11673",
        "PDF": "https://arxiv.org/pdf/2504.11673"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper discusses the creation of virtual personas by generating detailed synthetic user backstories through multi-turn interview transcripts, which is a significant contribution to data generation and processing for LLMs."
      },
      "datasets": [
        {
          "dataset_name": "SuhongMoon/alterity_backstory",
          "downloads": "55",
          "likes": "0",
          "link": "https://huggingface.co/datasets/SuhongMoon/alterity_backstory"
        }
      ],
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.07955",
      "abstract": "Major progress on language models (LMs) in recent years has largely resulted from moving away from specialized models designed for specific tasks, to general models based on powerful architectures (e.g. the Transformer) that learn everything from raw data. Despite this trend, pre-processing steps such as tokenization remain a barrier to true end-to-end foundation models. We introduce a collection of new techniques that enable a dynamic chunking mechanism which automatically learns content- and context- dependent segmentation strategies learned jointly with the rest of the model. Incorporating this into an explicit hierarchical network (H-Net) allows replacing the (implicitly hierarchical) tokenization-LM-detokenization pipeline with a single model learned fully end-to-end. When compute- and data- matched, an H-Net with one stage of hierarchy operating at the byte level outperforms a strong Transformer language model operating over BPE tokens. Iterating the hierarchy to multiple stages further increases its performance by modeling multiple levels of abstraction, demonstrating significantly better scaling with data and matching the token-based Transformer of twice its size. H-Nets pretrained on English show significantly increased character-level robustness, and qualitatively learn meaningful data-dependent chunking strategies without any heuristics or explicit supervision. Finally, the H-Net's improvement over tokenized pipelines is further increased in languages and modalities with weaker tokenization heuristics, such as Chinese and code, or DNA sequences (nearly 4x improvement in data efficiency over baselines), showing the potential of true end-to-end models that learn and scale better from unprocessed data.",
      "authors": [
        "Sukjun Hwang",
        "Brandon Wang",
        "Albert Gu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:39:37+00:00",
          "link": "https://arxiv.org/abs/2507.07955v1",
          "size": "500kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T09:06:11+00:00",
          "link": "https://arxiv.org/abs/2507.07955v2",
          "size": "503kb",
          "version": "v2"
        }
      ],
      "title": "Dynamic Chunking for End-to-End Hierarchical Sequence Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07955",
        "HTML": "https://arxiv.org/html/2507.07955v2",
        "PDF": "https://arxiv.org/pdf/2507.07955"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces dynamic chunking mechanisms and end-to-end hierarchical models, focusing on data preprocessing and tokenization alternatives, which are directly related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11152",
      "abstract": "Computed Tomography (CT) is a widely utilized imaging modality in clinical settings. Using densely acquired rotational X-ray arrays, CT can capture 3D spatial features. However, it is confronted with challenged such as significant time consumption and high radiation exposure. CT reconstruction methods based on sparse-view X-ray images have garnered substantial attention from researchers as they present a means to mitigate costs and risks. In recent years, diffusion models, particularly the Latent Diffusion Model (LDM), have demonstrated promising potential in the domain of 3D CT reconstruction. Nonetheless, due to the substantial differences between the 2D latent representation of X-ray modalities and the 3D latent representation of CT modalities, the vanilla LDM is incapable of achieving effective alignment within the latent space. To address this issue, we propose the Consistent Latent Space Diffusion Model (CLS-DM), which incorporates cross-modal feature contrastive learning to efficiently extract latent 3D information from 2D X-ray images and achieve latent space alignment between modalities. Experimental results indicate that CLS-DM outperforms classical and state-of-the-art generative models in terms of standard voxel-level metrics (PSNR, SSIM) on the LIDC-IDRI and CTSpine1K datasets. This methodology not only aids in enhancing the effectiveness and economic viability of sparse X-ray reconstructed CT but can also be generalized to other cross-modal transformation tasks, such as text-to-image synthesis. We have made our code publicly available at https://anonymous.4open.science/r/CLS-DM-50D6/ to facilitate further research and applications in other domains.",
      "authors": [
        "Duoyou Chen",
        "Yunqing Chen",
        "Can Zhang",
        "Zhou Wang",
        "Cheng Chen",
        "Ruoxiu Xiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:02:19+00:00",
          "link": "https://arxiv.org/abs/2507.11152v1",
          "size": "6645kb",
          "version": "v1"
        }
      ],
      "title": "Latent Space Consistency for Sparse-View CT Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11152",
        "HTML": "https://arxiv.org/html/2507.11152v1",
        "PDF": "https://arxiv.org/pdf/2507.11152"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a method for CT reconstruction using a latent space diffusion model but does not discuss LLM training data or data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11283",
      "abstract": "This paper presents a diffusion-augmented reinforcement learning (RL) approach for robust autonomous underwater vehicle (AUV) control, addressing key challenges in underwater trajectory planning and dynamic environment adaptation. The proposed method integrates three core innovations: (1) A diffusion-based trajectory generation framework that produces physically feasible multi-step trajectories, enhanced by a high-dimensional state encoding mechanism combining current observations with historical states and actions through a novel diffusion U-Net architecture, significantly improving long-horizon planning. (2) A sample-efficient hybrid learning architecture that synergizes diffusion-guided exploration with RL policy optimization, where the diffusion model generates diverse candidate actions and the RL critic selects optimal actions, achieving higher exploration efficiency and policy stability in dynamic underwater environments. Extensive simulation experiments validating the method's superior robustness and flexibility, outperforms conventional control methods in challenging marine conditions, offering enhanced adaptability and reliability for AUV operations in the underwater tasks.",
      "authors": [
        "Weiyi Liu",
        "Jingzehua Xu",
        "Guanwen Xie",
        "Yi Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:00:58+00:00",
          "link": "https://arxiv.org/abs/2507.11283v1",
          "size": "10017kb",
          "version": "v1"
        }
      ],
      "title": "Ocean Diviner: A Diffusion-Augmented Reinforcement Learning for AUV Robust Control in the Underwater Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11283",
        "HTML": "https://arxiv.org/html/2507.11283v1",
        "PDF": "https://arxiv.org/pdf/2507.11283"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for reinforcement learning control of underwater vehicles and does not contribute to any aspect of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11415",
      "abstract": "Achieving equity in healthcare accessibility requires lightweight yet high-performance solutions for medical image segmentation, particularly in resource-limited settings. Existing methods like U-Net and its variants often suffer from limited global Effective Receptive Fields (ERFs), hindering their ability to capture long-range dependencies. To address this, we propose U-RWKV, a novel framework leveraging the Recurrent Weighted Key-Value(RWKV) architecture, which achieves efficient long-range modeling at O(N) computational cost. The framework introduces two key innovations: the Direction-Adaptive RWKV Module(DARM) and the Stage-Adaptive Squeeze-and-Excitation Module(SASE). DARM employs Dual-RWKV and QuadScan mechanisms to aggregate contextual cues across images, mitigating directional bias while preserving global context and maintaining high computational efficiency. SASE dynamically adapts its architecture to different feature extraction stages, balancing high-resolution detail preservation and semantic relationship capture. Experiments demonstrate that U-RWKV achieves state-of-the-art segmentation performance with high computational efficiency, offering a practical solution for democratizing advanced medical imaging technologies in resource-constrained environments. The code is available at https://github.com/hbyecoding/U-RWKV.",
      "authors": [
        "Hongbo Ye",
        "Fenghe Tang",
        "Peiang Zhao",
        "Zhen Huang",
        "Dexin Zhao",
        "Minghao Bian",
        "S.Kevin Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:40:17+00:00",
          "link": "https://arxiv.org/abs/2507.11415v1",
          "size": "20268kb",
          "version": "v1"
        }
      ],
      "title": "U-RWKV: Lightweight medical image segmentation with direction-adaptive RWKV",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11415",
        "HTML": "https://arxiv.org/html/2507.11415v1",
        "PDF": "https://arxiv.org/pdf/2507.11415"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a new framework for medical image segmentation, focusing on architectural innovations and computational efficiency, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.10537",
      "abstract": "We present a novel unified analysis for a broad class of adaptive optimization algorithms with structured (e.g., layerwise, diagonal, and kronecker-factored) preconditioners for both online regret minimization and offline convex optimization. Our analysis not only provides matching rate to several important structured preconditioned algorithms including diagonal AdaGrad, full-matrix AdaGrad, and AdaGrad-Norm, but also gives an improved convergence rate for a one-sided variant of Shampoo over that of original Shampoo. Interestingly, more structured preconditioners (e.g., diagonal Adagrad, AdaGrad-Norm which use less space and compute) are often presented as computationally efficient approximations to full-matrix Adagrad, aiming for improved optimization performance through better approximations. Our unified analysis challenges this prevailing view and reveals, perhaps surprisingly, that more structured preconditioners, despite using less space and computation per step, can outperform their less structured counterparts. To demonstrate this, we show that one-sided Shampoo, which is relatively much cheaper than full-matrix AdaGrad could outperform it both theoretically and experimentally.",
      "authors": [
        "Shuo Xie",
        "Tianhao Wang",
        "Sashank Reddi",
        "Sanjiv Kumar",
        "Zhiyuan Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-13T16:51:59+00:00",
          "link": "https://arxiv.org/abs/2503.10537v1",
          "size": "709kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T06:22:08+00:00",
          "link": "https://arxiv.org/abs/2503.10537v2",
          "size": "407kb",
          "version": "v2"
        }
      ],
      "title": "Structured Preconditioners in Adaptive Optimization: A Unified Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.10537",
        "HTML": "https://arxiv.org/html/2503.10537v2",
        "PDF": "https://arxiv.org/pdf/2503.10537"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on structured preconditioners in adaptive optimization, which is related to algorithmic improvements and not LLM training data processing or dataset creation."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.11484",
      "abstract": "LP-type problems such as the Minimum Enclosing Ball (MEB), Linear Support Vector Machine (SVM), Linear Programming (LP), and Semidefinite Programming (SDP) are fundamental combinatorial optimization problems, with many important applications in machine learning applications such as classification, bioinformatics, and noisy learning. We study LP-type problems in several streaming and distributed big data models, giving $\\varepsilon$-approximation linear sketching algorithms with a focus on the high accuracy regime with low dimensionality $d$, that is, when ${d < (1/\\varepsilon)^{0.999}}$. Our main result is an $O(ds)$ pass algorithm with $O(s( \\sqrt{d}/\\varepsilon)^{3d/s}) \\cdot \\mathrm{poly}(d, \\log (1/\\varepsilon))$ space complexity in words, for any parameter $s \\in [1, d \\log (1/\\varepsilon)]$, to solve $\\varepsilon$-approximate LP-type problems of $O(d)$ combinatorial and VC dimension. Notably, by taking $s = d \\log (1/\\varepsilon)$, we achieve space complexity polynomial in $d$ and polylogarithmic in $1/\\varepsilon$, presenting exponential improvements in $1/\\varepsilon$ over current algorithms. We complement our results by showing lower bounds of $(1/\\varepsilon)^{\\Omega(d)}$ for any $1$-pass algorithm solving the $(1 + \\varepsilon)$-approximation MEB and linear SVM problems, further motivating our multi-pass approach.",
      "authors": [
        "N. Efe \\c{C}ekirge",
        "William Gay",
        "David P. Woodruff"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:55:08+00:00",
          "link": "https://arxiv.org/abs/2507.11484v1",
          "size": "133kb",
          "version": "v1"
        }
      ],
      "title": "Multipass Linear Sketches for Geometric LP-Type Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11484",
        "HTML": "https://arxiv.org/html/2507.11484v1",
        "PDF": "https://arxiv.org/pdf/2507.11484"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The research focuses on algorithms for LP-type problems, with no connection to LLM training data processing or data engineering methods for improving LLM data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11488",
      "abstract": "Colors are omnipresent in today's world and play a vital role in how humans perceive and interact with their surroundings. However, it is challenging for computers to imitate human color perception. This paper introduces the Human Perception-Based Fuzzy Color Model, COLIBRI (Color Linguistic-Based Representation and Interpretation), designed to bridge the gap between computational color representations and human visual perception. The proposed model uses fuzzy sets and logic to create a framework for color categorization. Using a three-phase experimental approach, the study first identifies distinguishable color stimuli for hue, saturation, and intensity through preliminary experiments, followed by a large-scale human categorization survey involving more than 1000 human subjects. The resulting data are used to extract fuzzy partitions and generate membership functions that reflect real-world perceptual uncertainty. The model incorporates a mechanism for adaptation that allows refinement based on feedback and contextual changes. Comparative evaluations demonstrate the model's alignment with human perception compared to traditional color models, such as RGB, HSV, and LAB. To the best of our knowledge, no previous research has documented the construction of a model for color attribute specification based on a sample of this size or a comparable sample of the human population (n = 2496). Our findings are significant for fields such as design, artificial intelligence, marketing, and human-computer interaction, where perceptually relevant color representation is critical.",
      "authors": [
        "Pakizar Shamoi",
        "Nuray Toganas",
        "Muragul Muratbekova",
        "Elnara Kadyrgali",
        "Adilet Yerkin",
        "Ayan Igali",
        "Malika Ziyada",
        "Ayana Adilova",
        "Aron Karatayev",
        "Yerdauit Torekhan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:01:45+00:00",
          "link": "https://arxiv.org/abs/2507.11488v1",
          "size": "11810kb",
          "version": "v1"
        }
      ],
      "title": "COLIBRI Fuzzy Model: Color Linguistic-Based Representation and Interpretation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11488",
        "HTML": "https://arxiv.org/html/2507.11488v1",
        "PDF": "https://arxiv.org/pdf/2507.11488"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a fuzzy model for color representation but does not involve LLM training data processing or relevant data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.15686",
      "abstract": "The concept of differential privacy (DP) can quantitatively measure privacy loss by observing the changes in the distribution caused by the inclusion of individuals in the target dataset. The DP, which is generally used as a constraint, has been prominent in safeguarding datasets in machine learning in industry giants like Apple and Google. A common methodology for guaranteeing DP is incorporating appropriate noise into query outputs, thereby establishing statistical defense systems against privacy attacks such as membership inference and linkage attacks. However, especially for small datasets, existing DP mechanisms occasionally add excessive amount of noise to query output, thereby discarding data utility. This is because the traditional DP computes privacy loss based on the worst-case scenario, i.e., statistical outliers. In this work, to tackle this challenge, we utilize per-instance DP (pDP) as a constraint, measuring privacy loss for each data instance and optimizing noise tailored to individual instances. In a nutshell, we propose a per-instance noise variance optimization (NVO) game, framed as a common interest sequential game, and show that the Nash equilibrium (NE) points of it inherently guarantee pDP for all data instances. Through extensive experiments, our proposed pDP algorithm demonstrated an average performance improvement of up to 99.53% compared to the conventional DP algorithm in terms of KL divergence.",
      "authors": [
        "Sehyun Ryu",
        "Jonggyu Jang",
        "Hyun Jong Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-24T06:51:16+00:00",
          "link": "https://arxiv.org/abs/2404.15686v1",
          "size": "12852kb",
          "version": "v1"
        },
        {
          "date": "2024-04-27T10:36:12+00:00",
          "link": "https://arxiv.org/abs/2404.15686v2",
          "size": "12587kb",
          "version": "v2"
        }
      ],
      "title": "Noise Variance Optimization in Differential Privacy: A Game-Theoretic Approach Through Per-Instance Differential Privacy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.15686",
        "HTML": "https://arxiv.org/html/2404.15686",
        "PDF": "https://arxiv.org/pdf/2404.15686"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work focuses on differential privacy optimization using game theory and does not discuss LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.08088",
      "abstract": "A dominating set of a graph $G$ is a set $S \\subseteq V(G)$ such that every vertex in $V(G) \\setminus S$ has a neighbor in $S$, where two vertices are neighbors if they are adjacent. A secure dominating set of $G$ is a dominating set $S$ of $G$ with the additional property that for every vertex $v \\in V(G) \\setminus S$, there exists a neighbor $u$ of $v$ in $S$ such that $(S \\setminus \\{u\\}) \\cup \\{v\\}$ is a dominating set of $G$. The secure domination number of $G$, denoted by $\\gamma_s(G)$, is the minimum cardinality of a secure dominating set of $G$. We prove that if $G$ is a $P_5$-free graph, then $\\gamma_s(G) \\le \\frac{3}{2}\\alpha(G)$, where $\\alpha(G)$ denotes the independence number of $G$. We further show that if $G$ is a connected $(P_5, H)$-free graph for some $H \\in \\{ P_3 \\cup P_1, K_2 \\cup 2K_1, ~\\text{paw},~ C_4\\}$, then $\\gamma_s(G)\\le \\max\\{3,\\alpha(G)\\}$. We also show that if $G$ is a $(P_3 \\cup P_2)$-free graph, then $\\gamma_s(G)\\le \\alpha(G)+1$.",
      "authors": [
        "Uttam K. Gupta",
        "Michael A. Henning",
        "Paras Vinubhai Maniya",
        "Dinabandhu Pradhan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T06:40:49+00:00",
          "link": "https://arxiv.org/abs/2503.08088v1",
          "size": "403kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T05:35:39+00:00",
          "link": "https://arxiv.org/abs/2503.08088v2",
          "size": "53kb",
          "version": "v2"
        }
      ],
      "title": "Secure domination in $P_5$-free graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08088",
        "HTML": "https://arxiv.org/html/2503.08088v2",
        "PDF": "https://arxiv.org/pdf/2503.08088"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with graph theory and secure domination sets without addressing LLM training data or data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.15105",
      "abstract": "The rise of AI workloads and growing data center demands have driven the need for ultra-high-speed interconnects exceeding 200 Gb/s. As unit intervals (UI) shrink, even a few picoseconds of P/N skew can degrade serializer-deserializer (SerDes) performance. Traditional methods for quantifying skew fall short in capturing its impact. We introduce two new metrics: 1) Skew-Induced Insertion Loss Deviation (SILD) and 2) its complementary Figure of Merit (FOM_SILD), analytically developed to assess P/N skew effects. Measured S-parameters confirm FOM_SILD reciprocity, while simulations of 224G PAM4 SerDes show strong correlation with bit error rate (BER) trends. This approach offers a robust framework for analyzing skew in next-generation ultra-high-speed interconnects.",
      "authors": [
        "David Nozadze",
        "Zurab Kiguradze",
        "Amendra Koul",
        "and Mike Sapozhnikov"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T03:21:53+00:00",
          "link": "https://arxiv.org/abs/2506.15105v1",
          "size": "324kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T18:44:53+00:00",
          "link": "https://arxiv.org/abs/2506.15105v2",
          "size": "417kb",
          "version": "v2"
        }
      ],
      "title": "Skew-Induced Insertion Loss Deviation (SILD) and FOM_SILD: Metrics for Quantifying P/N Skew Effects in High-Speed Channels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15105",
        "HTML": "https://arxiv.org/html/2506.15105v2",
        "PDF": "https://arxiv.org/pdf/2506.15105"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Focuses on metrics for high-speed channel performance and skew measurement, with no relation to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.09279",
      "abstract": "Multimodal large language models (MLLMs) hold considerable promise for applications in healthcare. However, their deployment in safety-critical settings is hindered by two key limitations: (i) sensitivity to prompt design, and (ii) a tendency to generate incorrect responses with high confidence. As clinicians may rely on a model's stated confidence to gauge the reliability of its predictions, it is especially important that when a model expresses high confidence, it is also highly accurate. We introduce Prompt4Trust, the first reinforcement learning (RL) framework for prompt augmentation targeting confidence calibration in MLLMs. A lightweight LLM is trained to produce context-aware auxiliary prompts that guide a downstream task MLLM to generate responses in which the expressed confidence more accurately reflects predictive accuracy. Unlike conventional calibration techniques, Prompt4Trust specifically prioritizes aspects of calibration most critical for safe and trustworthy clinical decision-making. Beyond improvements driven by this clinically motivated calibration objective, our proposed method also improves task accuracy, achieving state-of-the-art medical visual question answering (VQA) performance on the PMC-VQA benchmark, which is composed of multiple-choice questions spanning diverse medical imaging modalities. Moreover, our framework trained with a small downstream task MLLM showed promising zero-shot generalization to larger MLLMs in our experiments, suggesting the potential for scalable calibration without the associated computational costs. This work demonstrates the potential of automated yet human-aligned prompt engineering for improving the the trustworthiness of MLLMs in safety critical settings. Our codebase can be found at https://github.com/xingbpshen/prompt4trust.",
      "authors": [
        "Anita Kriz",
        "Elizabeth Laura Janes",
        "Xing Shen",
        "Tal Arbel"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T13:21:10+00:00",
          "link": "https://arxiv.org/abs/2507.09279v1",
          "size": "301kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T03:09:40+00:00",
          "link": "https://arxiv.org/abs/2507.09279v2",
          "size": "301kb",
          "version": "v2"
        }
      ],
      "title": "Prompt4Trust: A Reinforcement Learning Prompt Augmentation Framework for Clinically-Aligned Confidence Calibration in Multimodal Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09279",
        "HTML": "https://arxiv.org/html/2507.09279v2",
        "PDF": "https://arxiv.org/pdf/2507.09279"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses prompt engineering for calibration, it primarily focuses on reinforcement learning techniques for prompt augmentation in MLLMs rather than on training data processing or creating new datasets."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10758",
      "abstract": "This paper intends to detect IoT malicious attacks through deep learning models and demonstrates a comprehensive evaluation of the deep learning and graph-based models regarding malicious network traffic detection. The models particularly are based on GraphSAGE, Bidirectional encoder representations from transformers (BERT), Temporal Convolutional Network (TCN) as well as Multi-Head Attention, together with Bidirectional Long Short-Term Memory (BI-LSTM) Multi-Head Attention and BI-LSTM and LSTM models. The chosen models demonstrated great performance to model temporal patterns and detect feature significance. The observed performance are mainly due to the fact that IoT system traffic patterns are both sequential and diverse, leaving a rich set of temporal patterns for the models to learn. Experimental results showed that BERT maintained the best performance. It achieved 99.94% accuracy rate alongside high precision and recall, F1-score and AUC-ROC score of 99.99% which demonstrates its capabilities through temporal dependency capture. The Multi-Head Attention offered promising results by providing good detection capabilities with interpretable results. On the other side, the Multi-Head Attention model required significant processing time like BI-LSTM variants. The GraphSAGE model achieved good accuracy while requiring the shortest training time but yielded the lowest accuracy, precision, and F1 score compared to the other models",
      "authors": [
        "Nikesh Prajapati",
        "Bimal Karki",
        "Saroj Gopali",
        "Akbar Siami Namin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:36:04+00:00",
          "link": "https://arxiv.org/abs/2507.10758v1",
          "size": "321kb",
          "version": "v1"
        }
      ],
      "title": "IoT Malware Network Traffic Detection using Deep Learning and GraphSAGE Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10758",
        "HTML": "https://arxiv.org/html/2507.10758v1",
        "PDF": "https://arxiv.org/pdf/2507.10758"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using deep learning models, such as BERT and GraphSAGE, for IoT malware detection, and does not discuss processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11080",
      "abstract": "We present the first fixed-parameter tractable (fpt) algorithms for precisely determining several central hypergraph decomposition parameters, including generalized hypertree width, fractional hypertree width, and adaptive width. Despite the recognized importance of these measures in complexity theory, databases, and constraint satisfaction, no exact fpt algorithms for any of them had previously been known. Our results are obtained for hypergraph classes of bounded rank and bounded degree.\n  Our approach extends a recent algorithm for treewidth (Boja\\'ncyk & Pilipczuk, LMCS 2022) utilizing monadic second-order (MSO) transductions. Leveraging this framework, we overcome the significant technical hurdles presented by hypergraphs, whose structural decompositions are technically much more intricate than their graph counterparts.",
      "authors": [
        "Matthias Lanzinger and Igor Razgon and Daniel Unterberger"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:23:01+00:00",
          "link": "https://arxiv.org/abs/2507.11080v1",
          "size": "52kb",
          "version": "v1"
        }
      ],
      "title": "FPT Parameterisations of Fractional and Generalised Hypertree Width",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11080",
        "HTML": "https://arxiv.org/html/2507.11080v1",
        "PDF": "https://arxiv.org/pdf/2507.11080"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses algorithms for hypergraph decomposition but does not address LLM training data processing or related operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11377",
      "abstract": "Marginal Carbon Intensity (MCI) has been promoted as an effective metric for carbon-aware computing. Although it is already considered as impractical for carbon accounting purposes, many still view it as valuable when optimizing for grid flexibility by incentivizing electricity usage during curtailment periods. In this statement paper, we argue that MCI is neither reliable nor actionable for either purpose. We outline its fundamental limitations, including non-observability, reliance on opaque predictive models, and the lack of verifiability. Moreover, MCI fails to reflect curtailment caused by high-carbon sources and offers no insight into the quantity of available excess power. We advocate moving beyond MCI and instead call for research on more actionable metrics, such as direct reporting of excess power, explicit modeling of energy storage and grid stability, and integration with emerging granular renewable energy certificate markets.",
      "authors": [
        "Philipp Wiesner and Odej Kao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:49:20+00:00",
          "link": "https://arxiv.org/abs/2507.11377v1",
          "size": "53kb",
          "version": "v1"
        }
      ],
      "title": "Moving Beyond Marginal Carbon Intensity: A Poor Metric for Both Carbon Accounting and Grid Flexibility",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11377",
        "HTML": "https://arxiv.org/html/2507.11377v1",
        "PDF": "https://arxiv.org/pdf/2507.11377"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper critiques the Marginal Carbon Intensity metric for carbon accounting and grid flexibility, not addressing LLM training data processing or any form of data engineering relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11486",
      "abstract": "Tractography algorithms leverage diffusion MRI to reconstruct the fibrous architecture of the brain's white matter. Among machine learning approaches, reinforcement learning (RL) has emerged as a promising framework for tractography, outperforming traditional methods in several key aspects. TractOracle-RL, a recent RL-based approach, reduces false positives by incorporating anatomical priors into the training process via a reward-based mechanism. In this paper, we investigate four extensions of the original TractOracle-RL framework by integrating recent advances in RL, and we evaluate their performance across five diverse diffusion MRI datasets. Results demonstrate that combining an oracle with the RL framework consistently leads to robust and reliable tractography, regardless of the specific method or dataset used. We also introduce a novel RL training scheme called Iterative Reward Training (IRT), inspired by the Reinforcement Learning from Human Feedback (RLHF) paradigm. Instead of relying on human input, IRT leverages bundle filtering methods to iteratively refine the oracle's guidance throughout training. Experimental results show that RL methods trained with oracle feedback significantly outperform widely used tractography techniques in terms of accuracy and anatomical validity.",
      "authors": [
        "Jeremi Levesque",
        "Antoine Th\\'eberge",
        "Maxime Descoteaux",
        "Pierre-Marc Jodoin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:57:00+00:00",
          "link": "https://arxiv.org/abs/2507.11486v1",
          "size": "6154kb",
          "version": "v1"
        }
      ],
      "title": "Exploring the robustness of TractOracle methods in RL-based tractography",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11486",
        "HTML": "https://arxiv.org/html/2507.11486v1",
        "PDF": "https://arxiv.org/pdf/2507.11486"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on RL-based tractography for diffusion MRI and anatomical tract reconstruction. It does not discuss LLM training data processing or any related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.16370",
      "abstract": "Advances in architectural design, data availability, and compute have driven remarkable progress in semantic segmentation. Yet, these models often rely on relaxed Bayesian assumptions, omitting critical uncertainty information needed for robust decision-making. The resulting reliance on point estimates has fueled interest in probabilistic segmentation, but the literature remains fragmented. In response, this review consolidates and contextualizes foundational concepts in uncertainty modeling, including the non-trivial task of distinguishing between epistemic and aleatoric uncertainty and examining their roles across four key downstream segmentation tasks, highlighting Active Learning as particularly promising. By unifying theory, terminology, and applications, we provide a coherent foundation for researchers and identify critical challenges, such as strong assumptions in spatial aggregation, lack of standardized benchmarks, and pitfalls in current uncertainty quantification methods. We identify trends such as the adoption of contemporary generative models, driven by advances in the broader field of generative modeling, with segmentation-specific innovation primarily in the conditioning mechanisms. Moreover, we observe growing interest in distribution- and sampling-free approaches to uncertainty estimation. We further propose directions for advancing uncertainty-aware segmentation in deep learning, including pragmatic strategies for disentangling different sources of uncertainty, novel uncertainty modeling approaches and improved Transformer-based backbones. In this way, we aim to support the development of more reliable, efficient, and interpretable segmentation models that effectively incorporate uncertainty into real-world applications.",
      "authors": [
        "M.M.A. Valiuddin",
        "R.J.G. van Sloun",
        "C.G.A. Viviers",
        "P.H.N. de With",
        "F. van der Sommen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-25T13:26:09+00:00",
          "link": "https://arxiv.org/abs/2411.16370v1",
          "size": "5446kb",
          "version": "v1"
        },
        {
          "date": "2025-01-07T09:34:51+00:00",
          "link": "https://arxiv.org/abs/2411.16370v2",
          "size": "3603kb",
          "version": "v2"
        },
        {
          "date": "2025-03-12T09:51:17+00:00",
          "link": "https://arxiv.org/abs/2411.16370v3",
          "size": "3603kb",
          "version": "v3"
        },
        {
          "date": "2025-07-02T13:47:36+00:00",
          "link": "https://arxiv.org/abs/2411.16370v4",
          "size": "3638kb",
          "version": "v4"
        },
        {
          "date": "2025-07-15T11:27:39+00:00",
          "link": "https://arxiv.org/abs/2411.16370v5",
          "size": "3664kb",
          "version": "v5"
        }
      ],
      "title": "A Review of Bayesian Uncertainty Quantification in Deep Probabilistic Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.16370",
        "HTML": "https://arxiv.org/html/2411.16370v5",
        "PDF": "https://arxiv.org/pdf/2411.16370"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper reviews uncertainty quantification in deep probabilistic image segmentation, focusing on model uncertainty and segmentation tasks rather than LLM training data processing."
      },
      "tasks": [
        "Active Learning",
        "Bayesian Inference",
        "Benchmarking",
        "Image Segmentation",
        "Semantic Segmentation",
        "Uncertainty Quantification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10584",
      "abstract": "Policy as Code (PaC) is a paradigm that encodes security and compliance policies into machine-readable formats, enabling automated enforcement in Infrastructure as Code (IaC) environments. However, its adoption is hindered by the complexity of policy languages and the risk of misconfigurations. In this work, we present ARPaCCino, an agentic system that combines Large Language Models (LLMs), Retrieval-Augmented-Generation (RAG), and tool-based validation to automate the generation and verification of PaC rules. Given natural language descriptions of the desired policies, ARPaCCino generates formal Rego rules, assesses IaC compliance, and iteratively refines the IaC configurations to ensure conformance. Thanks to its modular agentic architecture and integration with external tools and knowledge bases, ARPaCCino supports policy validation across a wide range of technologies, including niche or emerging IaC frameworks. Experimental evaluation involving a Terraform-based case study demonstrates ARPaCCino's effectiveness in generating syntactically and semantically correct policies, identifying non-compliant infrastructures, and applying corrective modifications, even when using smaller, open-weight LLMs. Our results highlight the potential of agentic RAG architectures to enhance the automation, reliability, and accessibility of PaC workflows.",
      "authors": [
        "Francesco Romeo",
        "Luigi Arena",
        "Francesco Blefari",
        "Francesco Aurelio Pironti",
        "Matteo Lupinacci",
        "Angelo Furfaro"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T12:36:33+00:00",
          "link": "https://arxiv.org/abs/2507.10584v1",
          "size": "772kb",
          "version": "v1"
        }
      ],
      "title": "ARPaCCino: An Agentic-RAG for Policy as Code Compliance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10584",
        "HTML": "https://arxiv.org/html/2507.10584v1",
        "PDF": "https://arxiv.org/pdf/2507.10584"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on generating and verifying Policy as Code rules using LLMs and RAG, but does not primarily deal with the creation or processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10971",
      "abstract": "Designing secure architectures for system-on-chip (SoC) platforms is a highly intricate and time-intensive task, often requiring months of development and meticulous verification. Even minor architectural oversights can lead to critical vulnerabilities that undermine the security of the entire chip. In response to this challenge, we introduce CITADEL, a modular security framework aimed at streamlining the creation of robust security architectures for SoCs. CITADEL offers a configurable, plug-and-play subsystem composed of custom intellectual property (IP) blocks, enabling the construction of diverse security mechanisms tailored to specific threats. As a concrete demonstration, we instantiate CITADEL to defend against supply-chain threats, illustrating how the framework adapts to one of the most pressing concerns in hardware security. This paper explores the range of obstacles encountered when building a unified security architecture capable of addressing multiple attack vectors and presents CITADEL's strategies for overcoming them. Through several real-world case studies, we showcase the practical implementation of CITADEL and present a thorough evaluation of its impact on silicon area and power consumption across various ASIC technologies. Results indicate that CITADEL introduces only minimal resource overhead, making it a practical solution for enhancing SoC security.",
      "authors": [
        "Kshitij Raj",
        "Atri Chatterjee",
        "Patanjali SLPSK",
        "Swarup Bhunia",
        "Sandip Ray"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T04:28:02+00:00",
          "link": "https://arxiv.org/abs/2507.10971v1",
          "size": "5882kb",
          "version": "v1"
        }
      ],
      "title": "Security Enclave Architecture for Heterogeneous Security Primitives for Supply-Chain Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10971",
        "HTML": "https://arxiv.org/html/2507.10971v1",
        "PDF": "https://arxiv.org/pdf/2507.10971"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This focuses on a security architecture for SoCs, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2310.03399",
      "abstract": "Graph neural networks (GNNs) learn to represent nodes by aggregating information from their neighbors. As GNNs increase in depth, their receptive field grows exponentially, leading to high memory costs. Several existing methods address this by sampling a small subset of nodes, scaling GNNs to much larger graphs. These methods are primarily evaluated on homophilous graphs, where neighboring nodes often share the same label. However, most of these methods rely on static heuristics that may not generalize across different graphs or tasks. We argue that the sampling method should be adaptive, adjusting to the complex structural properties of each graph. To this end, we introduce GRAPES, an adaptive sampling method that learns to identify the set of nodes crucial for training a GNN. GRAPES trains a second GNN to predict node sampling probabilities by optimizing the downstream task objective. We evaluate GRAPES on various node classification benchmarks, involving homophilous as well as heterophilous graphs. We demonstrate GRAPES' effectiveness in accuracy and scalability, particularly in multi-label heterophilous graphs. Unlike other sampling methods, GRAPES maintains high accuracy even with smaller sample sizes and, therefore, can scale to massive graphs. Our code is publicly available at https://github.com/dfdazac/grapes.",
      "authors": [
        "Taraneh Younesian",
        "Daniel Daza",
        "Emile van Krieken",
        "Thiviyan Thanapalasingam",
        "Peter Bloem"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-05T09:08:47+00:00",
          "link": "https://arxiv.org/abs/2310.03399v1",
          "size": "1293kb",
          "version": "v1"
        },
        {
          "date": "2024-05-27T10:37:04+00:00",
          "link": "https://arxiv.org/abs/2310.03399v2",
          "size": "1514kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T10:16:21+00:00",
          "link": "https://arxiv.org/abs/2310.03399v3",
          "size": "645kb",
          "version": "v3"
        }
      ],
      "title": "GRAPES: Learning to Sample Graphs for Scalable Graph Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.03399",
        "HTML": "https://arxiv.org/html/2310.03399v3",
        "PDF": "https://arxiv.org/pdf/2310.03399"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of the paper is on creating an adaptive sampling method (GRAPES) for graph neural networks, with no discussion on LLM training data processing."
      },
      "tasks": [
        "Graph Sampling",
        "Node Classification"
      ],
      "repo_urls": [
        "https://github.com/dfdazac/grapes"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.22370",
      "abstract": "We introduce the sequential multi-object robotic grasp sampling algorithm SeqGrasp that can robustly synthesize stable grasps on diverse objects using the robotic hand's partial Degrees of Freedom (DoF). We use SeqGrasp to construct the large-scale Allegro Hand sequential grasping dataset SeqDataset and use it for training the diffusion-based sequential grasp generator SeqDiffuser. We experimentally evaluate SeqGrasp and SeqDiffuser against the state-of-the-art non-sequential multi-object grasp generation method MultiGrasp in simulation and on a real robot. The experimental results demonstrate that SeqGrasp and SeqDiffuser reach an 8.71%-43.33% higher grasp success rate than MultiGrasp. Furthermore, SeqDiffuser is approximately 1000 times faster at generating grasps than SeqGrasp and MultiGrasp.",
      "authors": [
        "Haofei Lu",
        "Yifei Dong",
        "Zehang Weng",
        "Florian Pokorny",
        "Jens Lundell",
        "Danica Kragic"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-28T12:24:26+00:00",
          "link": "https://arxiv.org/abs/2503.22370v1",
          "size": "5182kb",
          "version": "v1"
        },
        {
          "date": "2025-03-31T09:06:26+00:00",
          "link": "https://arxiv.org/abs/2503.22370v2",
          "size": "5182kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T13:30:48+00:00",
          "link": "https://arxiv.org/abs/2503.22370v3",
          "size": "4579kb",
          "version": "v3"
        }
      ],
      "title": "Grasping a Handful: Sequential Multi-Object Dexterous Grasp Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.22370",
        "HTML": "https://arxiv.org/html/2503.22370v3",
        "PDF": "https://arxiv.org/pdf/2503.22370"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on developing algorithms for robotic grasp generation and creating a dataset for this purpose, not related to LLM training data processing."
      },
      "tasks": [
        "Grasp Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.21596",
      "abstract": "Multimodal large language models (MLLMs) have shown success in vision-language tasks, but their ability to reason over complex educational materials remains largely untested. This work presents the first evaluation of state-of-the-art MLLMs, including LLaVA-1.5 and LLaMA 3.2-Vision, on the textbook question answering (TQA) task using the CK12-QA dataset. We introduce a multimodal retrieval-augmented generation (RAG) pipeline to simulate real-world learning by providing relevant lesson paragraphs and diagrams as context. Our zero-shot experiments reveal a critical trade-off: while retrieved context improves LLaVA's performance on text-based questions, it significantly degrades the accuracy of the more powerful LLaMA 3.2-Vision on diagram-based tasks, dropping its validation accuracy from 74.07% to 25.93%. We term this statistically significant phenomenon \"catastrophic context interference.\" Furthermore, fine-tuning highlights architectural differences: LLaMA 3.2-Vision's performance improves to 71.16% on the test set, demonstrating its capacity to learn multimodal integration, whereas LLaVA's performance declines, indicating challenges with generalization. Our results underscore the challenges MLLMs face in modality prioritization and context integration, providing a benchmark and pointing to key directions for developing more robust AI-driven educational tools.",
      "authors": [
        "Hessa A. Alawwad",
        "Anas Zafar",
        "Areej Alhothali",
        "Usman Naseem",
        "Ali Alkhathlan",
        "Amani Jamal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T19:31:35+00:00",
          "link": "https://arxiv.org/abs/2506.21596v1",
          "size": "429kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T09:14:31+00:00",
          "link": "https://arxiv.org/abs/2506.21596v2",
          "size": "432kb",
          "version": "v2"
        }
      ],
      "title": "Evaluating Multimodal Large Language Models on Educational Textbook Question Answering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21596",
        "HTML": "https://arxiv.org/html/2506.21596v2",
        "PDF": "https://arxiv.org/pdf/2506.21596"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper evaluates multimodal language models on a question-answering task without making contributions related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00059",
      "abstract": "This paper presents a computational approach to verify a specific conjecture concerning Hamiltonian paths in complete graphs with prescribed edge lengths, often referred to as the Buratti $-$ Horak-Rosa Conjecture. Building upon prior computational work by Mariusz Meszka which verified the conjecture for all primes up to 23, our Python program does the BHR conjecture verification for composite and prime numbers up to p=32 in a different way by taking into account one mulltiset per frequency partition (FP). We report successful computational verification for all frequency partitions for integers $p < 32$, specifically presenting results for $p=31$. For the composite number $p = 30$, the Python code took approximately 11 hours to verify on a Lenovo laptop. The method systematically generates frequency partitions of edge lengths and employs a recursive backtracking algorithm to construct the corresponding Hamiltonian paths. The presented program is optimized for efficiency and designed for scalability, allowing for its utilization on more powerful computing resources to explore even higher integer values, thereby providing further evidence for the conjecture's validity.\n  The conjecture of Peter Horak and Alex Rosa (generalizing that of Marco Buratti) states that a multiset L of (p-1) positive integers not exceeding $[p/2]$ is the list of edge lengths of a suitable Hamiltonian path of the complete graph with vertex-set of {1, 2, ..., [p-1]} if and only if for every divisor d of p, the number of multiples of d appearing in L is at most [p-d].",
      "authors": [
        "Ranjan N Naik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Data Structures and Algorithms (cs.DS)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T23:33:25+00:00",
          "link": "https://arxiv.org/abs/2507.00059v1",
          "size": "4kb",
          "version": "v1"
        },
        {
          "date": "2025-07-07T18:11:59+00:00",
          "link": "https://arxiv.org/abs/2507.00059v2",
          "size": "5kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T23:19:51+00:00",
          "link": "https://arxiv.org/abs/2507.00059v3",
          "size": "5kb",
          "version": "v3"
        }
      ],
      "title": "Verification of Hamiltonian Path Conjecture (BHR Conjecture) for Integers up to p=31 based on one multiset per FP",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00059",
        "HTML": "https://arxiv.org/html/2507.00059v3",
        "PDF": "https://arxiv.org/pdf/2507.00059"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with the verification of a mathematical conjecture using computational methods, without any mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10566",
      "abstract": "In Decentralized Multi-Agent Reinforcement Learning (MARL), the development of Emergent Communication has long been constrained by the ``Joint Exploration Dilemma'', leading agents to fall into a ``Communication Vacuum Equilibrium'' . Traditional methods address this by introducing inductive biases to facilitate communication emergence . This study fundamentally questions whether such artificial inductive biases are, in fact, over-engineering. Through experiments with the ``AI Mother Tongue'' (AIM) framework, based on a Vector Quantized Variational Autoencoder (VQ-VAE), we demonstrate that when agents possess an endogenous symbol system, their neural representations naturally exhibit spontaneous semantic compression and Nash equilibrium-driven semantic convergence, achieving effective symbolic communication without external inductive biases. This aligns with recent neuroscience findings suggesting that the human brain does not directly use human language for internal thought , and resonates with research on ``soft thinking'' capabilities in Large Language Models (LLMs) . Compared to traditional explicit communication methods, AIM demonstrates stronger generality and efficiency. The interpretable analysis toolkit developed in this study confirms that symbol usage exhibits a significant power-law distribution, leading to three major theoretical insights: the ``Neural Communication Hypothesis'', the ``Tool-First Principle'', and the ``Semantic Interpretability Paradigm''. Future research will explore the integration of Hierarchical Quantized Variational Autoencoders (HQ-VAE) to enhance AIM's complex expressive capabilities and investigate the potential for ``Reinforcement Learning (RL) Low-Level Pre-training''. This discovery offers new avenues for bridging symbolism and connectionism.",
      "authors": [
        "Hung Ming Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Science and Game Theory (cs.GT)",
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T09:52:49+00:00",
          "link": "https://arxiv.org/abs/2507.10566v1",
          "size": "596kb",
          "version": "v1"
        }
      ],
      "title": "AI Mother Tongue: Self-Emergent Communication in MARL via Endogenous Symbol Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10566",
        "HTML": "https://arxiv.org/html/2507.10566v1",
        "PDF": "https://arxiv.org/pdf/2507.10566"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The study explores emergent communication in multi-agent systems and makes some conceptual links to LLMs but does not focus on LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10786",
      "abstract": "Equipped with artificial intelligence (AI) and advanced sensing capabilities, social robots are gaining interest among consumers in the United States. These robots seem like a natural evolution of traditional smart home devices. However, their extensive data collection capabilities, anthropomorphic features, and capacity to interact with their environment make social robots a more significant security and privacy threat. Increased risks include data linkage, unauthorized data sharing, and the physical safety of users and their homes. It is critical to investigate U.S. users' security and privacy needs and concerns to guide the design of social robots while these devices are still in the early stages of commercialization in the U.S. market. Through 19 semi-structured interviews, we identified significant security and privacy concerns, highlighting the need for transparency, usability, and robust privacy controls to support adoption. For educational applications, participants worried most about misinformation, and in medical use cases, they worried about the reliability of these devices. Participants were also concerned with the data inference that social robots could enable. We found that participants expect tangible privacy controls, indicators of data collection, and context-appropriate functionality.",
      "authors": [
        "Henry Bell",
        "Jabari Kwesi",
        "Hiba Laabadli",
        "Pardis Emami-Naeini"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T20:27:40+00:00",
          "link": "https://arxiv.org/abs/2507.10786v1",
          "size": "82kb",
          "version": "v1"
        }
      ],
      "title": "\"Is it always watching? Is it always listening?\" Exploring Contextual Privacy and Security Concerns Toward Domestic Social Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10786",
        "HTML": "https://arxiv.org/html/2507.10786v1",
        "PDF": "https://arxiv.org/pdf/2507.10786"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on privacy and security concerns towards domestic social robots and does not involve any discussion about LLM training data processing or data engineering techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11076",
      "abstract": "Derivatives of equations of motion(EOM) describing the dynamics of rigid body systems are becoming increasingly relevant for the robotics community and find many applications in design and control of robotic systems. Controlling robots, and multibody systems comprising elastic components in particular, not only requires smooth trajectories but also the time derivatives of the control forces/torques, hence of the EOM. This paper presents the time derivatives of the EOM in closed form up to second-order as an alternative formulation to the existing recursive algorithms for this purpose, which provides a direct insight into the structure of the derivatives. The Lie group formulation for rigid body systems is used giving rise to very compact and easily parameterized equations.",
      "authors": [
        "Andreas Mueller",
        "Shivesh Kumar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Numerical Analysis (cs.NA)",
        "Differential Geometry (math.DG)",
        "Dynamical Systems (math.DS)",
        "Group Theory (math.GR)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:16:39+00:00",
          "link": "https://arxiv.org/abs/2507.11076v1",
          "size": "4178kb",
          "version": "v1"
        }
      ],
      "title": "Closed Form Time Derivatives of the Equations of Motion of Rigid Body Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11076",
        "HTML": "https://arxiv.org/html/2507.11076v1",
        "PDF": "https://arxiv.org/pdf/2507.11076"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper derives closed form equations for motion of rigid bodies, which are not relevant to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11257",
      "abstract": "We study the $k$-edge connectivity problem on undirected graphs in the distributed sketching model, where we have $n$ nodes and a referee. Each node sends a single message to the referee based on its 1-hop neighborhood in the graph, and the referee must decide whether the graph is $k$-edge connected by taking into account the received messages.\n  We present the first lower bound for deciding a graph connectivity problem in this model with a deterministic algorithm. Concretely, we show that the worst case message length is $\\Omega( k )$ bits for $k$-edge connectivity, for any super-constant $k = O(\\sqrt{n})$. Previously, only a lower bound of $\\Omega( \\log^3 n )$ bits was known for ($1$-edge) connectivity, due to Yu (SODA 2021). In fact, our result is the first super-polylogarithmic lower bound for a connectivity decision problem in the distributed graph sketching model.\n  To obtain our result, we introduce a new lower bound graph construction, as well as a new 3-party communication complexity problem that we call UniqueOverlap. As this problem does not appear to be amenable to reductions to existing hard problems such as set disjointness or indexing due to correlations between the inputs of the three players, we leverage results from cross-intersecting set families to prove the hardness of UniqueOverlap for deterministic algorithms. Finally, we obtain the sought lower bound for deciding $k$-edge connectivity via a novel simulation argument that, in contrast to previous works, does not introduce any probability of error and thus works for deterministic algorithms.",
      "authors": [
        "Peter Robinson and Ming Ming Tan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:31:04+00:00",
          "link": "https://arxiv.org/abs/2507.11257v1",
          "size": "203kb",
          "version": "v1"
        }
      ],
      "title": "Deterministic Lower Bounds for $k$-Edge Connectivity in the Distributed Sketching Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11257",
        "HTML": "https://arxiv.org/html/2507.11257v1",
        "PDF": "https://arxiv.org/pdf/2507.11257"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on deterministic lower bounds for k-edge connectivity in graphs within a distributed sketching model. It does not address LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2412.18424",
      "abstract": "Large vision language models (LVLMs) have improved the document understanding capabilities remarkably, enabling the handling of complex document elements, longer contexts, and a wider range of tasks. However, existing document understanding benchmarks have been limited to handling only a small number of pages and fail to provide a comprehensive analysis of layout elements locating. In this paper, we first define three primary task categories: Long Document Understanding, numerical Reasoning, and cross-element Locating, and then propose a comprehensive benchmark, LongDocURL, integrating above three primary tasks and comprising 20 sub-tasks categorized based on different primary tasks and answer evidences. Furthermore, we develop a semi-automated construction pipeline and collect 2,325 high-quality question-answering pairs, covering more than 33,000 pages of documents, significantly outperforming existing benchmarks. Subsequently, we conduct comprehensive evaluation experiments on both open-source and closed-source models across 26 different configurations, revealing critical performance gaps in this field.",
      "authors": [
        "Chao Deng",
        "Jiale Yuan",
        "Pi Bu",
        "Peijie Wang",
        "Zhong-Zhi Li",
        "Jian Xu",
        "Xiao-Hui Li",
        "Yuan Gao",
        "Jun Song",
        "Bo Zheng",
        "Cheng-Lin Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-24T13:39:32+00:00",
          "link": "https://arxiv.org/abs/2412.18424v1",
          "size": "13653kb",
          "version": "v1"
        },
        {
          "date": "2024-12-27T08:33:31+00:00",
          "link": "https://arxiv.org/abs/2412.18424v2",
          "size": "13653kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T17:55:08+00:00",
          "link": "https://arxiv.org/abs/2412.18424v3",
          "size": "16936kb",
          "version": "v3"
        }
      ],
      "title": "LongDocURL: a Comprehensive Multimodal Long Document Benchmark Integrating Understanding, Reasoning, and Locating",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.18424",
        "HTML": "https://arxiv.org/html/2412.18424v3",
        "PDF": "https://arxiv.org/pdf/2412.18424"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper discusses the creation of a comprehensive benchmark for document understanding and describes a semi-automated construction pipeline for collecting high-quality data, indicating a technical contribution to training-data processing."
      },
      "datasets": [
        {
          "dataset_name": "dengchao/LongDocURL",
          "downloads": "121",
          "likes": "6",
          "link": "https://huggingface.co/datasets/dengchao/LongDocURL"
        }
      ],
      "tasks": [
        "document understanding",
        "Question Answering"
      ],
      "repo_urls": [
        "https://github.com/dengc2023/longdocurl"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.16658",
      "abstract": "Hyperspectral pansharpening has received much attention in recent years due to technological and methodological advances that open the door to new application scenarios. However, research on this topic is only now gaining momentum. The most popular methods are still borrowed from the more mature field of multispectral pansharpening and often overlook the unique challenges posed by hyperspectral data fusion, such as i) the very large number of bands, ii) the overwhelming noise in selected spectral ranges, iii) the significant spectral mismatch between panchromatic and hyperspectral components, iv) a typically high resolution ratio. Imprecise data modeling especially affects spectral fidelity. Even state-of-the-art methods perform well in certain spectral ranges and much worse in others, failing to ensure consistent quality across all bands, with the risk of generating unreliable results. Here, we propose a hyperspectral pansharpening method that explicitly addresses this problem and ensures uniform spectral quality. To this end, a single lightweight neural network is used, with weights that adapt on the fly to each band. During fine-tuning, the spatial loss is turned on and off to ensure a fast convergence of the spectral loss to the desired level, according to a hysteresis-like dynamic. Furthermore, the spatial loss itself is appropriately redefined to account for nonlinear dependencies between panchromatic and spectral bands. Overall, the proposed method is fully unsupervised, with no prior training on external data, flexible, and low-complexity. Experiments on a recently published benchmarking toolbox show that it ensures excellent sharpening quality, competitive with the state-of-the-art, consistently across all bands. The software code and the full set of results are shared online on https://github.com/giu-guarino/rho-PNN.",
      "authors": [
        "Giuseppe Guarino",
        "Matteo Ciotola",
        "Gemine Vivone",
        "Giovanni Poggi",
        "Giuseppe Scarpa"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-22T13:24:24+00:00",
          "link": "https://arxiv.org/abs/2505.16658v1",
          "size": "7157kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T08:41:18+00:00",
          "link": "https://arxiv.org/abs/2505.16658v2",
          "size": "14029kb",
          "version": "v2"
        }
      ],
      "title": "Zero-Shot Hyperspectral Pansharpening Using Hysteresis-Based Tuning for Spectral Quality Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.16658",
        "HTML": "https://arxiv.org/html/2505.16658v2",
        "PDF": "https://arxiv.org/pdf/2505.16658"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a hyperspectral pansharpening method which is unrelated to LLM training data processing or creation."
      },
      "tasks": [
        "Benchmarking",
        "Pansharpening"
      ],
      "repo_urls": [
        "https://github.com/giu-guarino/rho-pnn"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10981",
      "abstract": "The integration of extended reality (XR) with artificial intelligence (AI) introduces a new paradigm for user interaction, enabling AI to perceive user intent, stimulate the senses, and influence decision-making. We explored the impact of four AI-driven visualisation techniques -- `Inform,' `Nudge,' `Recommend,' and `Instruct' -- on user decision-making in XR using the Meta Quest Pro. To test these techniques, we used a pre-recorded 360-degree video of a supermarket, overlaying each technique through a virtual interface. We aimed to investigate how these different visualisation techniques with different levels of user autonomy impact preferences and decision-making. An exploratory study with semi-structured interviews provided feedback and design recommendations. Our findings emphasise the importance of maintaining user autonomy, enhancing AI transparency to build trust, and considering context in visualisation design.",
      "authors": [
        "Ze Dong",
        "Binyang Han",
        "Jingjing Zhang",
        "Ruoyu Wen",
        "Barrett Ens",
        "Adrian Clark",
        "Tham Piumsomboon"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T04:53:09+00:00",
          "link": "https://arxiv.org/abs/2507.10981v1",
          "size": "28029kb",
          "version": "v1"
        }
      ],
      "title": "An Exploratory Study on AI-driven Visualisation Techniques on Decision Making in Extended Reality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10981",
        "HTML": "https://arxiv.org/html/2507.10981v1",
        "PDF": "https://arxiv.org/pdf/2507.10981"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores AI-driven visualization techniques for decision-making in extended reality, which does not involve processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11256",
      "abstract": "We consider the fundamental Euclidean $k$-means clustering problem in a dynamic setting, where the input $X \\subseteq \\mathbb{R}^d$ evolves over time via a sequence of point insertions/deletions. We have to explicitly maintain a solution (a set of $k$ centers) $S \\subseteq \\mathbb{R}^d$ throughout these updates, while minimizing the approximation ratio, the update time (time taken to handle a point insertion/deletion) and the recourse (number of changes made to the solution $S$) of the algorithm.\n  We present a dynamic algorithm for this problem with $\\text{poly}(1/\\epsilon)$-approximation ratio, $\\tilde{O}(k^{\\epsilon})$ update time and $\\tilde{O}(1)$ recourse. In the general regime, where the dimension $d$ cannot be assumed to be a fixed constant, our algorithm has almost optimal guarantees across all these three parameters. Indeed, improving our update time or approximation ratio would imply beating the state-of-the-art static algorithm for this problem (which is widely believed to be the best possible), and the recourse of any dynamic algorithm must be $\\Omega(1)$.\n  We obtain our result by building on top of the recent work of [Bhattacharya, Costa, Farokhnejad; STOC'25], which gave a near-optimal dynamic algorithm for $k$-means in general metric spaces (as opposed to in the Euclidean setting). Along the way, we design several novel geometric data structures that are of independent interest. Specifically, one of our main contributions is designing the first consistent hashing scheme [Czumaj, Jiang, Krauthgamer, Vesel\\'y, Yang; FOCS'22] that achieves $\\text{poly}(d)$ running time per point evaluation with competitive parameters.",
      "authors": [
        "Sayan Bhattacharya",
        "Mart\\'in Costa",
        "Ermiya Farokhnejad",
        "Shaofeng H.-C. Jiang",
        "Yaonan Jin",
        "Jianing Lou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:30:40+00:00",
          "link": "https://arxiv.org/abs/2507.11256v1",
          "size": "89kb",
          "version": "v1"
        }
      ],
      "title": "Fully Dynamic Euclidean k-Means",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11256",
        "HTML": "https://arxiv.org/html/2507.11256v1",
        "PDF": "https://arxiv.org/pdf/2507.11256"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a dynamic algorithm for k-means clustering in a Euclidean space, specifically addressing update times and geometric data structures. There is no mention of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.12553",
      "abstract": "Solving the three-dimensional (3D) Bratu equation is highly challenging due to the presence of multiple and sharp solutions. Research on this equation began in the late 1990s, but there are no satisfactory results to date. To address this issue, we introduce a symmetric finite difference method (SFDM) which embeds the symmetry properties of the solutions into a finite difference method (FDM). This SFDM is primarily used to obtain more accurate solutions and bifurcation diagrams for the 3D Bratu equation. Additionally, we propose modifying the Bratu equation by incorporating a new constraint that facilitates the construction of bifurcation diagrams and simplifies handling the turning points. The proposed method, combined with the use of sparse matrix representation, successfully solves the 3D Bratu equation on grids of up to $301^3$ points. The results demonstrate that SFDM outperforms all previously employed methods for the 3D Bratu equation. Furthermore, we provide bifurcation diagrams for the 1D, 2D, 4D, and 5D cases, and accurately identify the first turning points in all dimensions. All simulations indicate that the bifurcation diagrams of the Bratu equation on the cube domains closely resemble the well-established behavior on the ball domains described by Joseph and Lundgren [1]. Furthermore, when SFDM is applied to linear stability analysis, it yields the same largest real eigenvalue as the standard FDM despite having fewer equations and variables in the nonlinear system.",
      "authors": [
        "Muhammad Luthfi Shahab",
        "Hadi Susanto",
        "Haralampos Hatzikirou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-16T13:30:44+00:00",
          "link": "https://arxiv.org/abs/2410.12553v1",
          "size": "334kb",
          "version": "v1"
        },
        {
          "date": "2024-10-22T14:33:44+00:00",
          "link": "https://arxiv.org/abs/2410.12553v2",
          "size": "335kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T01:09:28+00:00",
          "link": "https://arxiv.org/abs/2410.12553v3",
          "size": "323kb",
          "version": "v3"
        }
      ],
      "title": "A finite difference method with symmetry properties for the high-dimensional Bratu equation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.12553",
        "HTML": "https://arxiv.org/html/2410.12553v3",
        "PDF": "https://arxiv.org/pdf/2410.12553"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a finite difference method for the Bratu equation, and does not discuss LLM training data processing or creation."
      },
      "repo_urls": [
        "https://github.com/luthfishahab/sfdm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.20203",
      "abstract": "This study presents a novel approach for quantificationally reconstructing density fields from shadowgraph images using physics-informed neural networks",
      "authors": [
        "Xutun Wang",
        "Yuchen Zhang",
        "Zidong Li",
        "Haocheng Wen",
        "and Bing Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Fluid Dynamics (physics.flu-dyn)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-26T15:28:15+00:00",
          "link": "https://arxiv.org/abs/2410.20203v1",
          "size": "1397kb",
          "version": "v1"
        },
        {
          "date": "2024-11-02T12:45:32+00:00",
          "link": "https://arxiv.org/abs/2410.20203v2",
          "size": "18767kb",
          "version": "v2"
        }
      ],
      "title": "Physics-informed Shadowgraph Network: An End-to-end Density Field Reconstruction Method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.20203",
        "PDF": "https://arxiv.org/pdf/2410.20203"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study presents a method for reconstructing density fields using physics-informed neural networks, unrelated to LLM training data processing."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.09483",
      "abstract": "This research presents preliminary work to address the challenge of identifying at-risk students using supervised machine learning and three unique data categories: engagement, demographics, and performance data collected from Fall 2023 using Canvas and the California State University, Fullerton dashboard. We aim to tackle the persistent challenges of higher education retention and student dropout rates by screening for at-risk students and building a high-risk identification system. By focusing on previously overlooked behavioral factors alongside traditional metrics, this work aims to address educational gaps, enhance student outcomes, and significantly boost student success across disciplines at the University. Pre-processing steps take place to establish a target variable, anonymize student information, manage missing data, and identify the most significant features. Given the mixed data types in the datasets and the binary classification nature of this study, this work considers several machine learning models, including Support Vector Machines (SVM), Naive Bayes, K-nearest neighbors (KNN), Decision Trees, Logistic Regression, and Random Forest. These models predict at-risk students and identify critical periods of the semester when student performance is most vulnerable. We will use validation techniques such as train test split and k-fold cross-validation to ensure the reliability of the models. Our analysis indicates that all algorithms generate an acceptable outcome for at-risk student predictions, while Naive Bayes performs best overall.",
      "authors": [
        "Azucena L. Jimenez Martinez",
        "Kanika Sood",
        "Rakeshkumar Mahto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-12T17:33:06+00:00",
          "link": "https://arxiv.org/abs/2412.09483v1",
          "size": "272kb",
          "version": "v1"
        }
      ],
      "title": "Early Detection of At-Risk Students Using Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.09483",
        "PDF": "https://arxiv.org/pdf/2412.09483"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on using machine learning for detecting at-risk students and involves standard preprocessing of educational data, not related to LLM training data processing."
      },
      "tasks": [
        "Binary Classification",
        "Student dropout"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10846",
      "abstract": "Interpreting the decision-making process of Convolutional Neural Networks (CNNs) is critical for deploying models in high-stakes domains. Gradient-weighted Class Activation Mapping (Grad-CAM) is a widely used method for visual explanations, yet it typically focuses on the final convolutional layer or na\\\"ively averages across layers, strategies that can obscure important semantic cues or amplify irrelevant noise. We propose Winsor-CAM, a novel, human-tunable extension of Grad-CAM that generates robust and coherent saliency maps by aggregating information across all convolutional layers. To mitigate the influence of noisy or extreme attribution values, Winsor-CAM applies Winsorization, a percentile-based outlier attenuation technique. A user-controllable threshold allows for semantic-level tuning, enabling flexible exploration of model behavior across representational hierarchies. Evaluations on standard architectures (ResNet50, DenseNet121, VGG16, InceptionV3) using the PASCAL VOC 2012 dataset demonstrate that Winsor-CAM produces more interpretable heatmaps and achieves superior performance in localization metrics, including intersection-over-union and center-of-mass alignment, when compared to Grad-CAM and uniform layer-averaging baselines. Winsor-CAM advances the goal of trustworthy AI by offering interpretable, multi-layer insights with human-in-the-loop control.",
      "authors": [
        "Casey Wall",
        "Longwei Wang",
        "Rodrigue Rizk",
        "and KC Santosh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T22:37:31+00:00",
          "link": "https://arxiv.org/abs/2507.10846v1",
          "size": "7424kb",
          "version": "v1"
        }
      ],
      "title": "Winsor-CAM: Human-Tunable Visual Explanations from Deep Networks via Layer-Wise Winsorization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10846",
        "HTML": "https://arxiv.org/html/2507.10846v1",
        "PDF": "https://arxiv.org/pdf/2507.10846"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents an improvement on Grad-CAM for visual explanations in CNNs, focusing on interpretability rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10918",
      "abstract": "Recent advancements in dialogue generation have broadened the scope of human-bot interactions, enabling not only contextually appropriate responses but also the analysis of human affect and sensitivity. While prior work has suggested that stylistic similarity between user and system may enhance user impressions, the distinction between subjective and objective similarity is often overlooked. To investigate this issue, we introduce a novel dataset that includes users' preferences, subjective stylistic similarity based on users' own perceptions, and objective stylistic similarity annotated by third party evaluators in open-domain dialogue settings. Analysis using the constructed dataset reveals a strong positive correlation between subjective stylistic similarity and user preference. Furthermore, our analysis suggests an important finding: users' subjective stylistic similarity differs from third party objective similarity. This underscores the importance of distinguishing between subjective and objective evaluations and understanding the distinct aspects each captures when analyzing the relationship between stylistic similarity and user preferences. The dataset presented in this paper is available online.",
      "authors": [
        "Ikumi Numaya and Shoji Moriya and Shiki Sato and Reina Akama and Jun Suzuki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T02:19:52+00:00",
          "link": "https://arxiv.org/abs/2507.10918v1",
          "size": "434kb",
          "version": "v1"
        }
      ],
      "title": "How Stylistic Similarity Shapes Preferences in Dialogue Dataset with User and Third Party Evaluations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10918",
        "HTML": "https://arxiv.org/html/2507.10918v1",
        "PDF": "https://arxiv.org/pdf/2507.10918"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a novel dialogue dataset which is related to LLMs, but the primary focus is on stylistic similarity analysis rather than on processing or improving LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11025",
      "abstract": "We present a novel framework for CBCT-to-MDCT translation, grounded in the Schrodinger Bridge (SB) formulation, which integrates GAN-derived priors with human-guided conditional diffusion. Unlike conventional GANs or diffusion models, our approach explicitly enforces boundary consistency between CBCT inputs and pseudo targets, ensuring both anatomical fidelity and perceptual controllability. Binary human feedback is incorporated via classifier-free guidance (CFG), effectively steering the generative process toward clinically preferred outcomes. Through iterative refinement and tournament-based preference selection, the model internalizes human preferences without relying on a reward model. Subtraction image visualizations reveal that the proposed method selectively attenuates shade artifacts in key anatomical regions while preserving fine structural detail. Quantitative evaluations further demonstrate superior performance across RMSE, SSIM, LPIPS, and Dice metrics on clinical datasets -- outperforming prior GAN- and fine-tuning-based feedback methods -- while requiring only 10 sampling steps. These findings underscore the effectiveness and efficiency of our framework for real-time, preference-aligned medical image translation.",
      "authors": [
        "Sung Ho Kang",
        "Hyun-Cheol Park"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T06:44:53+00:00",
          "link": "https://arxiv.org/abs/2507.11025v1",
          "size": "7939kb",
          "version": "v1"
        }
      ],
      "title": "Human-Guided Shade Artifact Suppression in CBCT-to-MDCT Translation via Schr\\\"odinger Bridge with Conditional Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11025",
        "HTML": "https://arxiv.org/html/2507.11025v1",
        "PDF": "https://arxiv.org/pdf/2507.11025"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for medical image translation and does not involve training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11329",
      "abstract": "Traditional approaches for molecular imaging of Parkinson's disease (PD) in vivo require radioactive isotopes, lengthy scan times, or deliver only low spatial resolution. Recent advances in saturation transfer-based PD magnetic resonance imaging (MRI) have provided biochemical insights, although the image contrast is semi-quantitative and nonspecific. Here, we combined a rapid molecular MRI acquisition paradigm with deep learning based reconstruction for multi-metabolite quantification of glutamate, mobile proteins, semisolid, and mobile macromolecules in an acute MPTP (1-methyl-4-phenyl-1,2,3,6-tetrahydropyridine) mouse model. The quantitative parameter maps are in general agreement with the histology and MR spectroscopy, and demonstrate that semisolid magnetization transfer (MT), amide, and aliphatic relayed nuclear Overhauser effect (rNOE) proton volume fractions may serve as PD biomarkers.",
      "authors": [
        "Hagar Shmuely (1)",
        "Michal Rivlin (1) and Or Perlman (1 and 2) ((1) School of Biomedical Engineering",
        "Tel Aviv University",
        "Tel Aviv",
        "Israel",
        "(2) Sagol School of Neuroscience",
        "Tel Aviv University",
        "Tel Aviv",
        "Israel)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:01:54+00:00",
          "link": "https://arxiv.org/abs/2507.11329v1",
          "size": "35302kb",
          "version": "v1"
        }
      ],
      "title": "Quantitative multi-metabolite imaging of Parkinson's disease using AI boosted molecular MRI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11329",
        "HTML": "https://arxiv.org/html/2507.11329v1",
        "PDF": "https://arxiv.org/pdf/2507.11329"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research involves molecular imaging for Parkinson's disease using AI methods and does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.19417",
      "abstract": "Generalist robots that can perform a range of different tasks in open-world settings must be able to not only reason about the steps needed to accomplish their goals, but also process complex instructions, prompts, and even feedback during task execution. Intricate instructions (e.g., \"Could you make me a vegetarian sandwich?\" or \"I don't like that one\") require not just the ability to physically perform the individual steps, but the ability to situate complex commands and feedback in the physical world. In this work, we describe a system that uses vision-language models in a hierarchical structure, first reasoning over complex prompts and user feedback to deduce the most appropriate next step to fulfill the task, and then performing that step with low-level actions. In contrast to direct instruction following methods that can fulfill simple commands (\"pick up the cup\"), our system can reason through complex prompts and incorporate situated feedback during task execution (\"that's not trash\"). We evaluate our system across three robotic platforms, including single-arm, dual-arm, and dual-arm mobile robots, demonstrating its ability to handle tasks such as cleaning messy tables, making sandwiches, and grocery shopping. Videos are available at https://www.pi.website/research/hirobot",
      "authors": [
        "Lucy Xiaoyang Shi",
        "Brian Ichter",
        "Michael Equi",
        "Liyiming Ke",
        "Karl Pertsch",
        "Quan Vuong",
        "James Tanner",
        "Anna Walling",
        "Haohuan Wang",
        "Niccolo Fusai",
        "Adrian Li-Bell",
        "Danny Driess",
        "Lachy Groom",
        "Sergey Levine",
        "Chelsea Finn"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-26T18:58:41+00:00",
          "link": "https://arxiv.org/abs/2502.19417v1",
          "size": "37139kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T17:44:28+00:00",
          "link": "https://arxiv.org/abs/2502.19417v2",
          "size": "10362kb",
          "version": "v2"
        }
      ],
      "title": "Hi Robot: Open-Ended Instruction Following with Hierarchical Vision-Language-Action Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.19417",
        "HTML": "https://arxiv.org/html/2502.19417v2",
        "PDF": "https://arxiv.org/pdf/2502.19417"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work involves the application of hierarchical vision-language-action models in robotics, focusing on task execution rather than LLM training data processing."
      },
      "tasks": [
        "Instruction Following",
        "Vision-Language-Action"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.03401",
      "abstract": "This paper designs a post-disaster powered communication intelligent network (PDPCIN) to address communication disruptions caused by ground base station (GBS) failures within the post-disaster area. PDPCIN employs unmanned aerial vehicles (UAVs) to provide wireless data collection (WDC) and wireless energy transmission (WET) for affected areas and leverages low earth orbit satellites (LEO SATs) to relay UAV data to the nearest survival GBS. To ensure basic post-disaster communication while co-optimizing age of information (AoI), energy efficiency, and spectrum efficiency, intelligent synchronization-UAV (IS-UAV) architecture, AoI-based four thresholds updating (AFTU) mechanism, and Dynamic multi-LEO access (DMLA) strategy are proposed. However, three key challenges remain: time-varying task-resource imbalances, complex topology caused by multi-device scheduling, and nonlinear coupling in multidimensional metric optimization, making system optimization NP-hard. Therefore, this paper proposes a hierarchical heterogeneous graph neural networks (HHGNN) framework. It models heterogeneous device nodes and their communication relations as a hierarchical heterogeneous graph structure, integrating our defined graph sensing, exchange, and mask layer to handle the network's input, feature propagation, and output. To search appropriate number of single-LEO SATs, we propose single-LEO SAT density optimization (S-LSDO) algorithm. Finally, we compare the proposed scheme with state-of-the-art benchmarks to validate its superior collaborative optimization of AoI, energy efficiency, and spectrum efficiency. Based on this, we derive the expressions for the expected values of AoI and stagnant AoI proportion.",
      "authors": [
        "Hanjian Liu",
        "Jinsong Gui",
        "Xiaoheng Deng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T09:09:03+00:00",
          "link": "https://arxiv.org/abs/2507.03401v1",
          "size": "2015kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T10:54:11+00:00",
          "link": "https://arxiv.org/abs/2507.03401v2",
          "size": "1799kb",
          "version": "v2"
        }
      ],
      "title": "AoI-Energy-Spectrum Optimization in Post-Disaster Powered Communication Intelligent Network via Hierarchical Heterogeneous Graph Neural Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03401",
        "PDF": "https://arxiv.org/pdf/2507.03401"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing communication networks using a hierarchical graph framework for post-disaster scenarios, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10854",
      "abstract": "Phishing remains a pervasive and growing threat, inflicting heavy economic and reputational damage. While machine learning has been effective in real-time detection of phishing attacks, progress is hindered by lack of large, high-quality datasets and benchmarks. In addition to poor-quality due to challenges in data collection, existing datasets suffer from leakage and unrealistic base rates, leading to overly optimistic performance results. In this paper, we introduce PhreshPhish, a large-scale, high-quality dataset of phishing websites that addresses these limitations. Compared to existing public datasets, PhreshPhish is substantially larger and provides significantly higher quality, as measured by the estimated rate of invalid or mislabeled data points. Additionally, we propose a comprehensive suite of benchmark datasets specifically designed for realistic model evaluation by minimizing leakage, increasing task difficulty, enhancing dataset diversity, and adjustment of base rates more likely to be seen in the real world. We train and evaluate multiple solution approaches to provide baseline performance on the benchmark sets. We believe the availability of this dataset and benchmarks will enable realistic, standardized model comparison and foster further advances in phishing detection. The datasets and benchmarks are available on Hugging Face (https://huggingface.co/datasets/phreshphish/phreshphish).",
      "authors": [
        "Thomas Dalton",
        "Hemanth Gowda",
        "Girish Rao",
        "Sachin Pargi",
        "Alireza Hadj Khodabakhshi",
        "Joseph Rombs",
        "Stephan Jou",
        "Manish Marwah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T23:02:59+00:00",
          "link": "https://arxiv.org/abs/2507.10854v1",
          "size": "11232kb",
          "version": "v1"
        }
      ],
      "title": "PhreshPhish: A Real-World, High-Quality, Large-Scale Phishing Website Dataset and Benchmark",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10854",
        "HTML": "https://arxiv.org/html/2507.10854v1",
        "PDF": "https://arxiv.org/pdf/2507.10854"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper's primary contribution is the creation of a new high-quality dataset (PhreshPhish) with a focus on data processing steps such as minimizing leakage and enhancing dataset diversity, relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07817",
      "abstract": "Instruction Tuning has emerged as a pivotal post-training paradigm that enables pre-trained language models to better follow user instructions. Despite its significance, little attention has been given to optimizing the loss function used. A fundamental, yet often overlooked, question is whether the conventional auto-regressive objective - where loss is computed only on response tokens, excluding prompt tokens - is truly optimal for instruction tuning. In this work, we systematically investigate the impact of differentially weighting prompt and response tokens in instruction tuning loss, and propose Weighted Instruction Tuning (WIT) as a better alternative to conventional instruction tuning. Through extensive experiments on five language models of different families and scale, three finetuning datasets of different sizes, and five diverse evaluation benchmarks, we show that the standard instruction tuning loss often yields suboptimal performance and limited robustness to input prompt variations. We find that a low-to-moderate weight for prompt tokens coupled with a moderate-to-high weight for response tokens yields the best-performing models across settings and also serve as better starting points for the subsequent preference alignment training. These findings highlight the need to reconsider instruction tuning loss and offer actionable insights for developing more robust and generalizable models. Our code is open-sourced at https://github.com/kowndinya-renduchintala/WIT.",
      "authors": [
        "Anwoy Chatterjee",
        "H S V N S Kowndinya Renduchintala",
        "Sumit Bhatia",
        "Tanmoy Chakraborty"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T14:46:33+00:00",
          "link": "https://arxiv.org/abs/2507.07817v1",
          "size": "752kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T11:42:05+00:00",
          "link": "https://arxiv.org/abs/2507.07817v2",
          "size": "757kb",
          "version": "v2"
        }
      ],
      "title": "On the Effect of Instruction Tuning Loss on Generalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07817",
        "HTML": "https://arxiv.org/html/2507.07817v2",
        "PDF": "https://arxiv.org/pdf/2507.07817"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses improving instruction tuning loss in LLMs which indirectly involves data processing by optimizing the training objective but does not directly contribute to developing new methods or datasets for data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10636",
      "abstract": "The rapid development of urban low-altitude unmanned aerial vehicle (UAV) economy poses new challenges for dynamic site selection of UAV landing points and supply stations. Traditional deep reinforcement learning methods face computational complexity bottlenecks, particularly with standard attention mechanisms, when handling large-scale urban-level location problems. This paper proposes GeoHopNet, a Hopfield-augmented sparse spatial attention network specifically designed for dynamic UAV site location problems. Our approach introduces four core innovations: (1) distance-biased multi-head attention mechanism that explicitly encodes spatial geometric information; (2) K-nearest neighbor sparse attention that reduces computational complexity from $O(N^2)$ to $O(NK)$; (3) a modern Hopfield external memory module; and (4) a memory regularization strategy. Experimental results demonstrate that GeoHopNet extends the boundary of solvable problem sizes. For large-scale instances with 1,000 nodes, where standard attention models become prohibitively slow (over 3 seconds per instance) and traditional solvers fail, GeoHopNet finds high-quality solutions (0.22\\% optimality gap) in under 0.1 seconds. Compared to the state-of-the-art ADNet baseline on 100-node instances, our method improves solution quality by 22.2\\% and is 1.8$\\times$ faster.",
      "authors": [
        "Jianing Zhi",
        "Xinghua Li and Zidong Chen"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T13:13:35+00:00",
          "link": "https://arxiv.org/abs/2507.10636v1",
          "size": "817kb",
          "version": "v1"
        }
      ],
      "title": "GeoHopNet: Hopfield-Augmented Sparse Spatial Attention for Dynamic UAV Site Location Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10636",
        "HTML": "https://arxiv.org/html/2507.10636v1",
        "PDF": "https://arxiv.org/pdf/2507.10636"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is concerned with a reinforcement learning approach for UAV site location problems and does not address LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10835",
      "abstract": "We propose a framework for the design and analysis of optimization algorithms in variational quantum Monte Carlo, drawing on geometric insights into the corresponding function space. The framework translates infinite-dimensional optimization dynamics into tractable parameter-space algorithms through a Galerkin projection onto the tangent space of the variational ansatz. This perspective unifies existing methods such as stochastic reconfiguration and Rayleigh-Gauss-Newton, provides connections to classic function-space algorithms, and motivates the derivation of novel algorithms with geometrically principled hyperparameter choices. We validate our framework with numerical experiments demonstrating its practical relevance through the accurate estimation of ground-state energies for several prototypical models in condensed matter physics modeled with neural network wavefunctions.",
      "authors": [
        "Victor Armegioiu",
        "Juan Carrasquilla",
        "Siddhartha Mishra",
        "Johannes M\\\"uller",
        "Jannes Nys",
        "Marius Zeinhofer and Hang Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Strongly Correlated Electrons (cond-mat.str-el)",
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Computational Physics (physics.comp-ph)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T22:07:38+00:00",
          "link": "https://arxiv.org/abs/2507.10835v1",
          "size": "934kb",
          "version": "v1"
        }
      ],
      "title": "Functional Neural Wavefunction Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10835",
        "HTML": "https://arxiv.org/html/2507.10835v1",
        "PDF": "https://arxiv.org/pdf/2507.10835"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about optimization algorithms in variational quantum Monte Carlo and does not discuss LLM training data processing or data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10953",
      "abstract": "High-altitude diseases (HAD), encompassing acute mountain sickness (AMS), high-altitude cerebral edema (HACE), and high-altitude pulmonary edema (HAPE), are triggered by hypobaric hypoxia at elevations above 2,500 meters. These conditions pose significant health risks, yet the molecular mechanisms remain insufficiently understood. In this study, we developed a biomolecular event extraction pipeline integrating supervised machine learning with feature-based and multiscale Laplacian graph kernels to analyze 7,847 curated HAD-related abstracts from PubMed. We extracted over 150 unique biomolecular events including gene expression, regulation, binding, and localization and constructed a weighted, undirected biomolecular event network comprising 97 nodes and 153 edges. Using the PageRank algorithm, we prioritized key biomolecules based on their centrality within the event network. The top-ranked proteins included Erythropoietin (EPO) (0.0163), Vascular endothelial growth factor (VEGF) (0.0148), Hypoxia-inducible factor 1 (HIF-1) alpha (0.0136), Endothelial PAS Domain Protein 1 (EPAS1) and Angiotensin-Converting Enzyme (ACE) (0.0119), Egl nine homolog 1 (EGLN1), Endothelin 1 (ET-1), and 70 kilodalton heat shock protein (Hsp70)(0.0118), all of which play crucial roles in oxygen sensing, vascular remodeling, erythropoiesis, and blood pressure regulation. Subnetwork analysis revealed three major functional clusters centered on hypoxia response, inflammation, and stress adaptation pathways. Our integrative approach demonstrates the utility of large-scale text mining and graph-based analysis to uncover mechanistic insights and prioritize potential biomarkers for high-altitude disease.",
      "authors": [
        "Balu Bhasuran",
        "Sabenabanu Abdulkadhar",
        "Jeyakumar Natarajan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T03:34:00+00:00",
          "link": "https://arxiv.org/abs/2507.10953v1",
          "size": "2539kb",
          "version": "v1"
        }
      ],
      "title": "Unraveling the Biomarker Prospects of High-Altitude Diseases: Insights from Biomolecular Event Network Constructed using Text Mining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10953",
        "PDF": "https://arxiv.org/pdf/2507.10953"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on text mining for biomolecular event extraction related to high-altitude diseases, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11228",
      "abstract": "Gradient descent (GD) on logistic regression has many fascinating properties. When the dataset is linearly separable, it is known that the iterates converge in direction to the maximum-margin separator regardless of how large the step size is. In the non-separable case, however, it has been shown that GD can exhibit a cycling behaviour even when the step sizes is still below the stability threshold $2/\\lambda$, where $\\lambda$ is the largest eigenvalue of the Hessian at the solution. This short paper explores whether restricting the data to have equal magnitude is a sufficient condition for global convergence, under any step size below the stability threshold. We prove that this is true in a one dimensional space, but in higher dimensions cycling behaviour can still occur. We hope to inspire further studies on quantifying how common these cycles are in realistic datasets, as well as finding sufficient conditions to guarantee global convergence with large step sizes.",
      "authors": [
        "Si Yi Meng",
        "Baptiste Goujaud",
        "Antonio Orvieto",
        "Christopher De Sa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T11:58:42+00:00",
          "link": "https://arxiv.org/abs/2507.11228v1",
          "size": "361kb",
          "version": "v1"
        }
      ],
      "title": "Gradient Descent on Logistic Regression: Do Large Step-Sizes Work with Data on the Sphere?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11228",
        "HTML": "https://arxiv.org/html/2507.11228v1",
        "PDF": "https://arxiv.org/pdf/2507.11228"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates gradient descent properties in logistic regression, specifically regarding data conditions for convergence, without any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2309.16181",
      "abstract": "Metastable failure is a recent abstraction of a pattern of failures that occurs frequently in real-world distributed storage systems. In this paper, we propose a formal analysis and modeling of metastable failures in replicated storage systems. We focus on a foundational problem in distributed systems -- the problem of consensus -- to have an impact on a large class of systems. Our main contribution is the development of a queuing-based analytical model, MSF-Model, that can be used to characterize and predict metastable failures. MSF-Model integrates novel modeling concepts that allow modeling metastable failures which was interactable to model prior to our work. We also perform real experiments to reproduce and validate our model. Our real experiments show that MSF-Model predicts metastable failures with high accuracy by comparing the real experiment with the predictions from the queuing-based model.",
      "authors": [
        "Farzad Habibi",
        "Tania Lorido-Botran",
        "Ahmad Showail",
        "Daniel C. Sturman",
        "Faisal Nawab"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-28T05:49:28+00:00",
          "link": "https://arxiv.org/abs/2309.16181v1",
          "size": "1071kb",
          "version": "v1"
        },
        {
          "date": "2024-11-22T00:55:20+00:00",
          "link": "https://arxiv.org/abs/2309.16181v2",
          "size": "1653kb",
          "version": "v2"
        }
      ],
      "title": "MSF-Model: Queuing-Based Analysis and Prediction of Metastable Failures in Replicated Storage Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.16181",
        "HTML": "https://arxiv.org/html/2309.16181",
        "PDF": "https://arxiv.org/pdf/2309.16181"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses a queuing-based model for predicting metastable failures in storage systems, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2402.12683",
      "abstract": "Conformal prediction (CP) is a robust statistical framework that generates prediction intervals or sets with guaranteed coverage probability, addressing the challenge of quantifying predictive uncertainty in deep learning. Despite advancements in deep learning architectures and datasets, reliable uncertainty estimation remains elusive, making CP increasingly vital. This paper introduces TorchCP, a PyTorch-native library designed to integrate state-of-the-art CP algorithms into deep learning tasks, including classification, regression, graph neural networks, and large language models. TorchCP offers a comprehensive suite of advanced methodologies, a modular design for easy customization, and full GPU-accelerated scalability. Released under the LGPL-3.0 license, TorchCP has gained widespread adoption with over 12,582 PyPi downloads. It is supported by approximately 16,132 lines of code, 564 unit tests achieving 100\\% coverage, and comprehensive documentation. By bridging statistics and computer science, TorchCP empowers researchers and practitioners to advance conformal prediction in diverse deep learning applications.",
      "authors": [
        "Jianguo Huang",
        "Jianqing Song",
        "Xuanning Zhou",
        "Bingyi Jing",
        "Hongxin Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-20T03:14:47+00:00",
          "link": "https://arxiv.org/abs/2402.12683v1",
          "size": "61kb",
          "version": "v1"
        },
        {
          "date": "2024-12-12T05:19:43+00:00",
          "link": "https://arxiv.org/abs/2402.12683v2",
          "size": "628kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T11:58:58+00:00",
          "link": "https://arxiv.org/abs/2402.12683v3",
          "size": "146kb",
          "version": "v3"
        }
      ],
      "title": "TorchCP: A Python Library for Conformal Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.12683",
        "HTML": "https://arxiv.org/html/2402.12683v3",
        "PDF": "https://arxiv.org/pdf/2402.12683"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "TorchCP is a library for conformal prediction in various deep learning tasks, including LLMs, but the paper does not focus on LLM training data processing or improvement."
      },
      "tasks": [
        "Conformal Prediction",
        "Deep Learning",
        "Prediction",
        "regression"
      ],
      "repo_urls": [
        "https://github.com/luo-lorry/cti",
        "https://github.com/ml-stat-sustech/torchcp"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.13896",
      "abstract": "Domain adaptation, which bridges the distributions across different modalities, plays a crucial role in multimodal medical image analysis. In endoscopic imaging, combining pre-operative data with intra-operative imaging is important for surgical planning and navigation. However, existing domain adaptation methods are hampered by distribution shift caused by in vivo artifacts, necessitating robust techniques for aligning noisy and artifact abundant patient endoscopic videos with clean virtual images reconstructed from pre-operative tomographic data for pose estimation during intraoperative guidance. This paper presents an artifact-resilient image translation method and an associated benchmark for this purpose. The method incorporates a novel ``local-global'' translation framework and a noise-resilient feature extraction strategy. For the former, it decouples the image translation process into a local step for feature denoising, and a global step for global style transfer. For feature extraction, a new contrastive learning strategy is proposed, which can extract noise-resilient features for establishing robust correspondence across domains. Detailed validation on both public and in-house clinical datasets has been conducted, demonstrating significantly improved performance compared to the current state-of-the-art.",
      "authors": [
        "Junyang Wu",
        "Fangfang Xie",
        "Jiayuan Sun",
        "Yun Gu",
        "Guang-Zhong Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-15T02:41:52+00:00",
          "link": "https://arxiv.org/abs/2410.13896v1",
          "size": "25319kb",
          "version": "v1"
        },
        {
          "date": "2024-10-23T13:01:22+00:00",
          "link": "https://arxiv.org/abs/2410.13896v2",
          "size": "25319kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T05:27:24+00:00",
          "link": "https://arxiv.org/abs/2410.13896v3",
          "size": "0kb",
          "version": "v3"
        }
      ],
      "title": "From Real Artifacts to Virtual Reference: A Robust Framework for Translating Endoscopic Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.13896",
        "PDF": "https://arxiv.org/pdf/2410.13896"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses domain adaptation in medical imaging and endoscopic image processing, not related to LLM training data processing."
      },
      "tasks": [
        "Contrastive Learning",
        "Denoising",
        "Domain Adaptation",
        "Medical Image Analysis",
        "Pose Estimation",
        "Style Transfer",
        "Translation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.19130",
      "abstract": "Much of the success of multi-agent debates depends on carefully choosing the right parameters. The decision-making protocol stands out as it can highly impact final model answers, depending on how decisions are reached. Systematic comparison of decision protocols is difficult because many studies alter multiple discussion parameters beyond the protocol. So far, it has been largely unknown how decision-making influences different tasks. This work systematically evaluates the impact of seven decision protocols (e.g., majority voting, unanimity consensus). We change only one variable at a time - the decision protocol - to analyze how different methods affect the collaboration between agents and measure differences in knowledge and reasoning tasks. Our results show that voting protocols improve performance by 13.2% in reasoning tasks and consensus protocols by 2.8% in knowledge tasks compared to other decision protocols. Increasing the number of agents improves performance, while more discussion rounds before voting reduce it. To improve decision-making by increasing answer diversity, we propose two new methods, All-Agents Drafting (AAD) and Collective Improvement (CI). Our methods improve task performance by up to 3.3% with AAD and up to 7.4% with CI. This work demonstrates the importance of decision-making in multi-agent debates beyond scaling.",
      "authors": [
        "Lars Benedikt Kaesberg",
        "Jonas Becker",
        "Jan Philip Wahle",
        "Terry Ruas",
        "Bela Gipp"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-26T13:39:18+00:00",
          "link": "https://arxiv.org/abs/2502.19130v1",
          "size": "461kb",
          "version": "v1"
        },
        {
          "date": "2025-05-27T13:52:26+00:00",
          "link": "https://arxiv.org/abs/2502.19130v2",
          "size": "669kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T08:12:34+00:00",
          "link": "https://arxiv.org/abs/2502.19130v3",
          "size": "662kb",
          "version": "v3"
        }
      ],
      "title": "Voting or Consensus? Decision-Making in Multi-Agent Debate",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.19130",
        "PDF": "https://arxiv.org/pdf/2502.19130"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on decision-making protocols in multi-agent debates, without addressing the collection or processing of LLM training data."
      },
      "tasks": [
        "Decision Making",
        "MMLU",
        "StrategyQA"
      ],
      "repo_urls": [
        "https://github.com/lkaesberg/decision-protocols"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.07945",
      "abstract": "Recent advances in large language models (LLMs) have demonstrated strong performance in generating code for general-purpose programming languages. However, their potential for hardware description languages (HDLs), such as SystemVerilog, remains largely unexplored. HDL code generation poses unique challenges due to strict timing semantics, concurrency, and synthesizability constraints essential for correct hardware functionality. Further, HDL-based design flows encompass a broad set of tasks beyond structural code generation, including testbench development, assertion-based verification, timing closure, and protocol-level integration for on-chip communication. In this work, we evaluate the capabilities of both open-source and state-of-the-art LLMs in generating synthesizable and functionally accurate SystemVerilog implementations of widely used communication protocols that are critical components of embedded and System-on-Chip (SoC) systems. We introduce ProtocolLLM, the first benchmark suite specifically targeting these protocols with tasks spanning multiple design abstraction levels and varying prompt specificity. Our evaluation method also focuses on timing correctness in addition to synthesizability and syntactic correctness. We observe that most of the models fail to generate SystemVerilog code for communication protocols that follow timing constrains.",
      "authors": [
        "Arnav Sheth",
        "Ivaxi Sheth",
        "Mario Fritz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T17:10:47+00:00",
          "link": "https://arxiv.org/abs/2506.07945v1",
          "size": "132kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T16:24:28+00:00",
          "link": "https://arxiv.org/abs/2506.07945v2",
          "size": "325kb",
          "version": "v2"
        }
      ],
      "title": "ProtocolLLM: RTL Benchmark for SystemVerilog Generation of Communication Protocols",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07945",
        "HTML": "https://arxiv.org/html/2506.07945v2",
        "PDF": "https://arxiv.org/pdf/2506.07945"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper pertains to LLM capabilities in generating hardware description languages and does not focus on LLM training data processing."
      },
      "tasks": [
        "Code Generation",
        "Specificity"
      ],
      "repo_urls": [
        "https://github.com/amsheth/fpga_protocols_llm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.17496",
      "abstract": "Two inverse-free iterative methods are developed for solving Sylvester matrix equations when the spectra of the coefficient matrices are on, or near, known disjoint subintervals of the real axis. Both methods use the recently-introduced Akhiezer iteration: one to address an equivalent problem of approximating the matrix sign function applied to a block matrix and the other to directly approximate the inverse of the Sylvester operator. In each case this results in provable and computable geometric rates of convergence. When the right-hand side matrix is low rank, both methods require only low-rank matrix-matrix products. Relative to existing approaches, the methods presented here can be more efficient and require less storage when the coefficient matrices are dense or otherwise costly to invert. Applications include solving partial differential equations and computing Fr\\'echet derivatives.",
      "authors": [
        "Cade Ballew",
        "Thomas Trogdon",
        "Heather Wilber"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-21T19:12:19+00:00",
          "link": "https://arxiv.org/abs/2503.17496v1",
          "size": "2317kb",
          "version": "v1"
        },
        {
          "date": "2025-06-06T00:31:14+00:00",
          "link": "https://arxiv.org/abs/2503.17496v2",
          "size": "2465kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T21:33:36+00:00",
          "link": "https://arxiv.org/abs/2503.17496v3",
          "size": "2463kb",
          "version": "v3"
        }
      ],
      "title": "The Akhiezer iteration and inverse-free solvers for Sylvester matrix equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17496",
        "HTML": "https://arxiv.org/html/2503.17496v3",
        "PDF": "https://arxiv.org/pdf/2503.17496"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses inverse-free iterative methods for solving Sylvester matrix equations, which is unrelated to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.00558",
      "abstract": "When digitizing historical archives, it is necessary to search for the faces of celebrities and ordinary people, especially in newspapers, link them to the surrounding text, and make them searchable. Existing face detectors on datasets of scanned historical documents fail remarkably -- current detection tools only achieve around 24% mAP at 50:90% IoU. This work compensates for this failure by introducing a new manually annotated domain-specific dataset in the style of the popular Wider Face dataset, containing 2.2k new images from digitized historical newspapers from the 19th to 20th century, with 11k new bounding-box annotations and associated facial landmarks. This dataset allows existing detectors to be retrained to bring their results closer to the standard in the field of face detection in the wild. We report several experimental results comparing different families of fine-tuned detectors against publicly available pre-trained face detectors and ablation studies of multiple detector sizes with comprehensive detection and landmark prediction performance results.",
      "authors": [
        "Marek Va\\v{s}ko and Adam Herout and Michal Hradi\\v{s}"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-01T09:10:45+00:00",
          "link": "https://arxiv.org/abs/2504.00558v1",
          "size": "2977kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T13:04:08+00:00",
          "link": "https://arxiv.org/abs/2504.00558v2",
          "size": "2755kb",
          "version": "v2"
        }
      ],
      "title": "Archival Faces: Detection of Faces in Digitized Historical Documents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.00558",
        "HTML": "https://arxiv.org/html/2504.00558v2",
        "PDF": "https://arxiv.org/pdf/2504.00558"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a new dataset for face detection in historical documents, allowing for retraining of face detectors, but does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.13523",
      "abstract": "$E(3)$-equivariant neural networks have demonstrated success across a wide range of 3D modelling tasks. A fundamental operation in these networks is the tensor product, which interacts two geometric features in an equivariant manner to create new features. Due to the high computational complexity of the tensor product, significant effort has been invested to optimize the runtime of this operation. For example, Luo et al. (2024) recently proposed the Gaunt tensor product (GTP) which promises a significant speedup. In this work, we provide a careful, systematic analysis of a number of tensor product operations. In particular, we emphasize that different tensor products are not performing the same operation. The reported speedups typically come at the cost of expressivity. We introduce measures of expressivity and interactability to characterize these differences. In addition, we realized the original implementation of GTP can be greatly simplified by directly using a spherical grid at no cost in asymptotic runtime. This spherical grid approach is faster on our benchmarks and in actual training of the MACE interatomic potential by 30%. Finally, we provide the first systematic microbenchmarks of the various tensor product operations. We find that the theoretical runtime guarantees can differ wildly from empirical performance, demonstrating the need for careful application-specific benchmarking. Code is available at https://github.com/atomicarchitects/PriceofFreedom.",
      "authors": [
        "YuQing Xie",
        "Ameya Daigavane",
        "Mit Kotak",
        "Tess Smidt"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T14:15:18+00:00",
          "link": "https://arxiv.org/abs/2506.13523v1",
          "size": "5365kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T07:36:30+00:00",
          "link": "https://arxiv.org/abs/2506.13523v2",
          "size": "7418kb",
          "version": "v2"
        }
      ],
      "title": "The Price of Freedom: Exploring Expressivity and Runtime Tradeoffs in Equivariant Tensor Products",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13523",
        "PDF": "https://arxiv.org/pdf/2506.13523"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses optimization of tensor product operations in neural networks, without mentioning any contributions to LLM training data processing."
      },
      "tasks": [
        "Benchmarking"
      ],
      "repo_urls": [
        "https://github.com/atomicarchitects/priceoffreedom"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10621",
      "abstract": "Protecting cyberspace requires not only advanced tools but also a shift in how we reason about threats, trust, and autonomy. Traditional cybersecurity methods rely on manual responses and brittle heuristics. To build proactive and intelligent defense systems, we need integrated theoretical frameworks and software tools. Game theory provides a rigorous foundation for modeling adversarial behavior, designing strategic defenses, and enabling trust in autonomous systems. Meanwhile, software tools process cyber data, visualize attack surfaces, verify compliance, and suggest mitigations. Yet a disconnect remains between theory and practical implementation.\n  The rise of Large Language Models (LLMs) and agentic AI offers a new path to bridge this gap. LLM-powered agents can operationalize abstract strategies into real-world decisions. Conversely, game theory can inform the reasoning and coordination of these agents across complex workflows. LLMs also challenge classical game-theoretic assumptions, such as perfect rationality or static payoffs, prompting new models aligned with cognitive and computational realities. This co-evolution promises richer theoretical foundations and novel solution concepts. Agentic AI also reshapes software design: systems must now be modular, adaptive, and trust-aware from the outset.\n  This chapter explores the intersection of game theory, agentic AI, and cybersecurity. We review key game-theoretic frameworks (e.g., static, dynamic, Bayesian, and signaling games) and solution concepts. We then examine how LLM agents can enhance cyber defense and introduce LLM-driven games that embed reasoning into AI agents. Finally, we explore multi-agent workflows and coordination games, outlining how this convergence fosters secure, intelligent, and adaptive cyber systems.",
      "authors": [
        "Quanyan Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T00:49:44+00:00",
          "link": "https://arxiv.org/abs/2507.10621v1",
          "size": "115kb",
          "version": "v1"
        }
      ],
      "title": "Game Theory Meets LLM and Agentic AI: Reimagining Cybersecurity for the Age of Intelligent Threats",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10621",
        "HTML": "https://arxiv.org/html/2507.10621v1",
        "PDF": "https://arxiv.org/pdf/2507.10621"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with game theory and cybersecurity in the context of LLMs but does not focus on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2311.09386",
      "abstract": "Feature extraction and selection in the presence of nonlinear dependencies among the data is a fundamental challenge in unsupervised learning. We propose using a Gram-Schmidt (GS) type orthogonalization process over function spaces to detect and map out such dependencies. Specifically, by applying the GS process over some family of functions, we construct a series of covariance matrices that can either be used to identify new large-variance directions, or to remove those dependencies from known directions. In the former case, we provide information-theoretic guarantees in terms of entropy reduction. In the latter, we provide precise conditions by which the chosen function family eliminates existing redundancy in the data. Each approach provides both a feature extraction and a feature selection algorithm. Our feature extraction methods are linear, and can be seen as natural generalization of principal component analysis (PCA). We provide experimental results for synthetic and real-world benchmark datasets which show superior performance over state-of-the-art (linear) feature extraction and selection algorithms. Surprisingly, our linear feature extraction algorithms are comparable and often outperform several important nonlinear feature extraction methods such as autoencoders, kernel PCA, and UMAP. Furthermore, one of our feature selection algorithms strictly generalizes a recent Fourier-based feature selection mechanism (Heidari et al., IEEE Transactions on Information Theory, 2022), yet at significantly reduced complexity.",
      "authors": [
        "Bahram Yaghooti",
        "Netanel Raviv",
        "Bruno Sinopoli"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-15T21:29:57+00:00",
          "link": "https://arxiv.org/abs/2311.09386v1",
          "size": "12900kb",
          "version": "v1"
        },
        {
          "date": "2024-02-06T03:42:12+00:00",
          "link": "https://arxiv.org/abs/2311.09386v2",
          "size": "13983kb",
          "version": "v2"
        },
        {
          "date": "2024-08-21T20:19:53+00:00",
          "link": "https://arxiv.org/abs/2311.09386v3",
          "size": "18502kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T16:39:10+00:00",
          "link": "https://arxiv.org/abs/2311.09386v4",
          "size": "2604kb",
          "version": "v4"
        }
      ],
      "title": "Gram-Schmidt Methods for Unsupervised Feature Extraction and Selection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.09386",
        "HTML": "https://arxiv.org/html/2311.09386v4",
        "PDF": "https://arxiv.org/pdf/2311.09386"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes feature extraction methods using the Gram-Schmidt process and focuses on unsupervised feature selection, not related to LLM training data processing."
      },
      "tasks": [
        "feature selection"
      ],
      "repo_urls": [
        "https://github.com/byaghooti/gram_schmidt_feature_extraction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10912",
      "abstract": "LUT (Look-Up Table) mapping is a critical step in FPGA logic synthesis, where a logic network is transformed into a form that can be directly implemented using the FPGA's LUTs. An FPGA LUT is a flexible digital memory structure that can implement any logic function of a limited number of inputs, typically 4 to 6 inputs, depending on the FPGA architecture. The goal of LUT mapping is to map the Boolean network into LUTs, where each LUT can implement any function with a fixed number of inputs. In parallel to FPGA technology mapping, ASIC technology mapping maps the Boolean network to user-defined standard cells, which has traditionally been developed separately from LUT mapping algorithms. However, in this work, our motivating examples demonstrate that ASIC technology mappers can potentially improve the performance of LUT mappers, such that standard cell mapping and LUT mapping work in an incremental manner.\n  Therefore, we propose the FuseMap framework, which explores this opportunity to improve LUT mapping in the FPGA design flow by utilizing reinforcement learning to make design-specific choices during cell selection. The effectiveness of FuseMap is evaluated on a wide range of benchmarks, different technology libraries, and technology mappers. The experimental results demonstrate that FuseMap achieves higher mapping accuracy while reducing delay and area across diverse circuit designs collected from ISCAS 85/89, ITC/ISCAS 99, VTR 8.0, and EPFL benchmarks.",
      "authors": [
        "Cunxi Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T02:08:36+00:00",
          "link": "https://arxiv.org/abs/2507.10912v1",
          "size": "467kb",
          "version": "v1"
        }
      ],
      "title": "Mapping Fusion: Improving FPGA Technology Mapping with ASIC Mapper",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10912",
        "HTML": "https://arxiv.org/html/2507.10912v1",
        "PDF": "https://arxiv.org/pdf/2507.10912"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses FPGA technology mapping improvements using reinforcement learning but does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.10227",
      "abstract": "There are different ways of measuring diversity in complex systems. In particular, in language, lexical diversity is characterized in terms of the type-token ratio and the word entropy. We here investigate both diversity metrics in six massive linguistic datasets in English, Spanish, and Turkish, consisting of books, news articles, and tweets. These gigaword corpora correspond to languages with distinct morphological features and differ in registers and genres, thus constituting a varied testbed for a quantitative approach to lexical diversity. We unveil an empirical functional relation between entropy and type-token ratio of texts of a given corpus and language, which is a consequence of the statistical laws observed in natural language. Further, in the limit of large text lengths we find an analytical expression for this relation relying on both Zipf and Heaps laws that agrees with our empirical findings.",
      "authors": [
        "Pablo Rosillo-Rodes",
        "Maxi San Miguel and David Sanchez"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-15T14:40:59+00:00",
          "link": "https://arxiv.org/abs/2411.10227v1",
          "size": "4045kb",
          "version": "v1"
        },
        {
          "date": "2025-02-26T22:21:27+00:00",
          "link": "https://arxiv.org/abs/2411.10227v2",
          "size": "10920kb",
          "version": "v2"
        },
        {
          "date": "2025-06-24T17:18:03+00:00",
          "link": "https://arxiv.org/abs/2411.10227v3",
          "size": "6447kb",
          "version": "v3"
        }
      ],
      "title": "Entropy and type-token ratio in gigaword corpora",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.10227",
        "HTML": "https://arxiv.org/html/2411.10227",
        "PDF": "https://arxiv.org/pdf/2411.10227"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on quantifying lexical diversity in linguistic datasets using entropy and type-token ratio, but it does not discuss LLM training data processing or improving data quality for LLMs."
      },
      "tasks": [
        "Articles",
        "Diversity",
        "Relation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10714",
      "abstract": "Stochastic Petri Nets (SPNs) are an increasingly popular tool of choice for modeling discrete-event dynamics in areas such as epidemiology and systems biology, yet their parameter estimation remains challenging in general and in particular when transition rates depend on external covariates and explicit likelihoods are unavailable. We introduce a neural-surrogate (neural-network--based approximation of the posterior distribution) framework that predicts the coefficients of known covariate-dependent rate functions directly from noisy, partially observed token trajectories. Our model employs a lightweight 1D Convolutional Residual Network trained end-to-end on Gillespie-simulated SPN realizations, learning to invert system dynamics under realistic conditions of event dropout. During inference, Monte Carlo dropout provides calibrated uncertainty bounds together with point estimates. On synthetic SPNs with 20% missing events, our surrogate recovers rate-function coefficients with an RMSE = 0.108 and substantially runs faster than traditional Bayesian approaches. These results demonstrate that data-driven, likelihood-free surrogates can enable accurate, robust, and real-time parameter recovery in complex, partially observed discrete-event systems.",
      "authors": [
        "Bright Kwaku Manu",
        "Trevor Reckell",
        "Beckett Sterner",
        "Petar Jevtic"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:31:19+00:00",
          "link": "https://arxiv.org/abs/2507.10714v1",
          "size": "6465kb",
          "version": "v1"
        }
      ],
      "title": "A Simple Approximate Bayesian Inference Neural Surrogate for Stochastic Petri Net Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10714",
        "HTML": "https://arxiv.org/html/2507.10714v1",
        "PDF": "https://arxiv.org/pdf/2507.10714"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a neural-surrogate framework for parameter estimation in Stochastic Petri Nets, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11127",
      "abstract": "Neurosymbolic AI focuses on integrating learning and reasoning, in particular, on unifying logical and neural representations. Despite the existence of an alphabet soup of neurosymbolic AI systems, the field is lacking a generally accepted formal definition of what neurosymbolic models and inference really are. We introduce a formal definition for neurosymbolic AI that makes abstraction of its key ingredients. More specifically, we define neurosymbolic inference as the computation of an integral over a product of a logical and a belief function. We show that our neurosymbolic AI definition makes abstraction of key representative neurosymbolic AI systems.",
      "authors": [
        "Lennert De Smet and Luc De Raedt"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:23:22+00:00",
          "link": "https://arxiv.org/abs/2507.11127v1",
          "size": "161kb",
          "version": "v1"
        }
      ],
      "title": "Defining neurosymbolic AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11127",
        "HTML": "https://arxiv.org/html/2507.11127v1",
        "PDF": "https://arxiv.org/pdf/2507.11127"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a formal definition for neurosymbolic AI, focusing on integrating logic and neural models, rather than on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11241",
      "abstract": "Physically reduced-scale vehicles are emerging to accelerate the development of advanced automated driving functions. In this paper, we investigate the effects of scaling on self-localization accuracy with visual and visual-inertial algorithms using cameras and an inertial measurement unit (IMU). For this purpose, ROS2-compatible visual and visual-inertial algorithms are selected, and datasets are chosen as a baseline for real-sized vehicles. A test drive is conducted to record data of reduced-scale vehicles. We compare the selected localization algorithms, OpenVINS, VINS-Fusion, and RTAB-Map, in terms of their pose accuracy against the ground-truth and against data from real-sized vehicles. When comparing the implementation of the selected localization algorithms to real-sized vehicles, OpenVINS has the lowest average localization error. Although all selected localization algorithms have overlapping error ranges, OpenVINS also performs best when applied to a reduced-scale vehicle. When reduced-scale vehicles were compared to real-sized vehicles, minor differences were found in translational vehicle motion estimation accuracy. However, no significant differences were found when comparing the estimation accuracy of rotational vehicle motion, allowing RSVRs to be used as testing platforms for self-localization algorithms.",
      "authors": [
        "Tobias Kern",
        "Leon Tolksdorf",
        "Christian Birkner"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:14:57+00:00",
          "link": "https://arxiv.org/abs/2507.11241v1",
          "size": "2952kb",
          "version": "v1"
        }
      ],
      "title": "Comparison of Localization Algorithms between Reduced-Scale and Real-Sized Vehicles Using Visual and Inertial Sensors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11241",
        "PDF": "https://arxiv.org/pdf/2507.11241"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates localization algorithms using sensors for vehicles but does not address LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10877",
      "abstract": "Structural assessment of biomolecular complexes is vital for translating molecular models into functional insights, shaping our understanding of biology and aiding drug discovery. However, current structure-based scoring functions often lack generalizability across diverse biomolecular systems. We present BioScore, a foundational scoring function that addresses key challenges -- data sparsity, cross-system representation, and task compatibility -- through a dual-scale geometric graph learning framework with tailored modules for structure assessment and affinity prediction. BioScore supports a wide range of tasks, including affinity prediction, conformation ranking, and structure-based virtual screening. Evaluated on 16 benchmarks spanning proteins, nucleic acids, small molecules, and carbohydrates, BioScore consistently outperforms or matches 70 traditional and deep learning methods. Our newly proposed PPI Benchmark further enables comprehensive evaluation of protein-protein complex scoring. BioScore demonstrates broad applicability: (1) pretraining on mixed-structure data boosts protein-protein affinity prediction by up to 40% and antigen-antibody binding correlation by over 90%; (2) cross-system generalizability enables zero- and few-shot prediction with up to 71% correlation gain; and (3) its unified representation captures chemically challenging systems such as cyclic peptides, improving affinity prediction by over 60%. BioScore establishes a robust and generalizable framework for structural assessment across complex biomolecular landscapes.",
      "authors": [
        "Yuchen Zhu",
        "Jihong Chen",
        "Yitong Li",
        "Xiaomin Fang",
        "Xianbin Ye",
        "Jingzhou He",
        "Xujun Zhang",
        "Jingxuan Ge",
        "Chao Shen",
        "Xiaonan Zhang",
        "Tingjun Hou",
        "Chang-Yu Hsieh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Chemical Physics (physics.chem-ph)",
        "Machine Learning (cs.LG)",
        "Biological Physics (physics.bio-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T00:41:58+00:00",
          "link": "https://arxiv.org/abs/2507.10877v1",
          "size": "8283kb",
          "version": "v1"
        }
      ],
      "title": "BioScore: A Foundational Scoring Function For Diverse Biomolecular Complexes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10877",
        "PDF": "https://arxiv.org/pdf/2507.10877"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "BioScore focuses on a scoring function for biomolecular complexes, dealing with biomolecular data analysis rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10980",
      "abstract": "We give a decision procedure and proof of correctness for the equational theory of probabilistic Kleene algebra with angelic nondeterminism introduced in Ong, Ma, and Kozen (2025).",
      "authors": [
        "Shawn Ong",
        "Dexter Kozen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T04:49:44+00:00",
          "link": "https://arxiv.org/abs/2507.10980v1",
          "size": "22kb",
          "version": "v1"
        }
      ],
      "title": "A Decision Procedure for Probabilistic Kleene Algebra with Angelic Nondeterminism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10980",
        "HTML": "https://arxiv.org/html/2507.10980v1",
        "PDF": "https://arxiv.org/pdf/2507.10980"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper provides a decision procedure for a theoretical construct in probabilistic Kleene algebra, with no relation to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11012",
      "abstract": "This study explores the potential for predicting turbulent kinetic energy (TKE) from more readily acquired temperature data using temperature profiles and turbulence data collected concurrently at 10 Hz during a small experimental prescribed burn in the New Jersey Pine Barrens. Machine learning models, including Deep Neural Networks, Random Forest Regressor, Gradient Boosting, and Gaussian Process Regressor, were employed to assess the potential to predict TKE from temperature perturbations and explore temporal and spatial dynamics of correlations. Data visualization and correlation analyses revealed patterns and relationships between thermocouple temperatures and TKE, providing insight into the underlying dynamics. More accurate predictions of TKE were achieved by employing various machine learning models despite a weak correlation between the predictors and the target variable. The results demonstrate significant success, particularly from regression models, in accurately predicting the TKE. The findings of this study demonstrate a novel numerical approach to identifying new relationships between temperature and airflow processes in and around the fire environment. These relationships can help refine our understanding of combustion environment processes and the coupling and decoupling of fire environment processes necessary for improving fire operations strategy and fire and smoke model predictions. The findings of this study additionally highlight the valuable role of machine learning techniques in analyzing the complex large datasets of the fire environments, showcasing their potential to advance fire research and management practices.",
      "authors": [
        "Dipak Dulal",
        "Joseph J. Charney",
        "Michael R. Gallagher",
        "Pitambar Acharya",
        "Carmeliza Navasca",
        "Nicholas S. Skowronski"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T06:07:14+00:00",
          "link": "https://arxiv.org/abs/2507.11012v1",
          "size": "5926kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging Advanced Machine Learning to Predict Turbulence Dynamics from Temperature Observations at an Experimental Prescribed Fire",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11012",
        "HTML": "https://arxiv.org/html/2507.11012v1",
        "PDF": "https://arxiv.org/pdf/2507.11012"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study focuses on predicting turbulence dynamics using machine learning from temperature data, without any discussion of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11522",
      "abstract": "EEG-based brain-computer interfaces (BCIs) have shown promise in various applications, such as motor imagery and cognitive state monitoring. However, decoding visual representations from EEG signals remains a significant challenge due to their complex and noisy nature. We thus propose a novel 5-stage framework for decoding visual representations from EEG signals: (1) an EEG encoder for concept classification, (2) cross-modal alignment of EEG and text embeddings in CLIP feature space, (3) caption refinement via re-ranking, (4) weighted interpolation of concept and caption embeddings for richer semantics, and (5) image generation using a pre-trained Stable Diffusion model. We enable context-aware EEG-to-image generation through cross-modal alignment and re-ranking. Experimental results demonstrate that our method generates high-quality images aligned with visual stimuli, outperforming SOTA approaches by 13.43% in Classification Accuracy, 15.21% in Generation Accuracy and reducing Fr\\'echet Inception Distance by 36.61%, indicating superior semantic alignment and image quality.",
      "authors": [
        "Tariq Mehmood",
        "Hamza Ahmad",
        "Muhammad Haroon Shakeel",
        "Murtaza Taj"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:47:01+00:00",
          "link": "https://arxiv.org/abs/2507.11522v1",
          "size": "1631kb",
          "version": "v1"
        }
      ],
      "title": "CATVis: Context-Aware Thought Visualization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11522",
        "HTML": "https://arxiv.org/html/2507.11522v1",
        "PDF": "https://arxiv.org/pdf/2507.11522"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for decoding visual representations from EEG signals but does not focus on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.16975",
      "abstract": "Pre-trained language models (PLM) based on transformer neural networks developed in the field of natural language processing (NLP) offer great opportunities to improve automatic content analysis in communication science, especially for the coding of complex semantic categories in large datasets via supervised machine learning. However, three characteristics so far impeded the widespread adoption of the methods in the applying disciplines: the dominance of English language models in NLP research, the necessary computing resources, and the effort required to produce training data to fine-tune PLMs. In this study, we address these challenges by using a multilingual transformer model in combination with the adapter extension to transformers, and few-shot learning methods. We test our approach on a realistic use case from communication science to automatically detect claims and arguments together with their stance in the German news debate on arms deliveries to Ukraine. In three experiments, we evaluate (1) data preprocessing strategies and model variants for this task, (2) the performance of different few-shot learning methods, and (3) how well the best setup performs on varying training set sizes in terms of validity, reliability, replicability and reproducibility of the results. We find that our proposed combination of transformer adapters with pattern exploiting training provides a parameter-efficient and easily shareable alternative to fully fine-tuning PLMs. It performs on par in terms of validity, while overall, provides better properties for application in communication studies. The results also show that pre-fine-tuning for a task on a near-domain dataset leads to substantial improvement, in particular in the few-shot setting. Further, the results indicate that it is useful to bias the dataset away from the viewpoints of specific prominent individuals.",
      "authors": [
        "Jonas Rieger",
        "Kostiantyn Yanchenko",
        "Mattes Ruckdeschel",
        "Gerret von Nordheim",
        "Katharina Kleinen-von K\\\"onigsl\\\"ow",
        "Gregor Wiedemann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-28T11:39:08+00:00",
          "link": "https://arxiv.org/abs/2312.16975v1",
          "size": "1354kb",
          "version": "v1"
        }
      ],
      "title": "Few-shot learning for automated content analysis: Efficient coding of arguments and claims in the debate on arms deliveries to Ukraine",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.16975",
        "PDF": "https://arxiv.org/pdf/2312.16975"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper examines few-shot learning for automated content analysis using pre-trained language models, mentioning data preprocessing strategies but not focusing on broader LLM training data processing."
      },
      "tasks": [
        "Few-Shot Learning",
        "Task 2"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.06110",
      "abstract": "This project performs multimodal sentiment analysis using the CMU-MOSEI dataset, using transformer-based models with early fusion to integrate text, audio, and visual modalities. We employ BERT-based encoders for each modality, extracting embeddings that are concatenated before classification. The model achieves strong performance, with 97.87% 7-class accuracy and a 0.9682 F1-score on the test set, demonstrating the effectiveness of early fusion in capturing cross-modal interactions. The training utilized Adam optimization (lr=1e-4), dropout (0.3), and early stopping to ensure generalization and robustness. Results highlight the superiority of transformer architectures in modeling multimodal sentiment, with a low MAE (0.1060) indicating precise sentiment intensity prediction. Future work may compare fusion strategies or enhance interpretability. This approach utilizes multimodal learning by effectively combining linguistic, acoustic, and visual cues for sentiment analysis.",
      "authors": [
        "Jugal Gajjar and Kaustik Ranaware"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-09T15:10:57+00:00",
          "link": "https://arxiv.org/abs/2505.06110v1",
          "size": "1262kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T01:30:36+00:00",
          "link": "https://arxiv.org/abs/2505.06110v2",
          "size": "1262kb",
          "version": "v2"
        }
      ],
      "title": "Multimodal Sentiment Analysis on CMU-MOSEI Dataset using Transformer-based Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.06110",
        "HTML": "https://arxiv.org/html/2505.06110v2",
        "PDF": "https://arxiv.org/pdf/2505.06110"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on multimodal sentiment analysis using a pre-existing dataset (CMU-MOSEI) without contributing to LLM training data processing or data creation."
      },
      "tasks": [
        "Multimodal Sentiment Analysis",
        "Sentiment Analysis"
      ],
      "repo_urls": [
        "https://github.com/JugalGajjar/Multimodal-Sentiment-Analysis-with-MOSEI-Dataset"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10956",
      "abstract": "It is important to identify the discriminative features for high dimensional clustering. However, due to the lack of cluster labels, the regularization methods developed for supervised feature selection can not be directly applied. To learn the pseudo labels and select the discriminative features simultaneously, we propose a new unsupervised feature selection method, named GlObal and Local information combined Feature Selection (GOLFS), for high dimensional clustering problems. The GOLFS algorithm combines both local geometric structure via manifold learning and global correlation structure of samples via regularized self-representation to select the discriminative features. The combination improves the accuracy of both feature selection and clustering by exploiting more comprehensive information. In addition, an iterative algorithm is proposed to solve the optimization problem and the convergency is proved. Simulations and two real data applications demonstrate the excellent finite-sample performance of GOLFS on both feature selection and clustering.",
      "authors": [
        "Zhaoyu Xing",
        "Yang Wan",
        "Juan Wen",
        "Wei Zhong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T03:39:07+00:00",
          "link": "https://arxiv.org/abs/2507.10956v1",
          "size": "16695kb",
          "version": "v1"
        }
      ],
      "title": "GOLFS: Feature Selection via Combining Both Global and Local Information for High Dimensional Clustering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10956",
        "HTML": "https://arxiv.org/html/2507.10956v1",
        "PDF": "https://arxiv.org/pdf/2507.10956"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on feature selection for high-dimensional clustering tasks, which is not directly relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11281",
      "abstract": "We define a class of $C^k$-regular surfaces, $k \\geq 1$, \\emph{tileable surfaces}, that admit geometric tilings by a finite number of congruence classes of tiles. We show how to construct many examples, and examine the relationship with the well known tilings of the plane and sphere, as well as monohedral polyhedral surfaces.",
      "authors": [
        "David Brander and Jens Gravesen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Differential Geometry (math.DG)",
        "Computational Geometry (cs.CG)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:58:09+00:00",
          "link": "https://arxiv.org/abs/2507.11281v1",
          "size": "2500kb",
          "version": "v1"
        }
      ],
      "title": "Tileable Surfaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11281",
        "HTML": "https://arxiv.org/html/2507.11281v1",
        "PDF": "https://arxiv.org/pdf/2507.11281"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on geometrical and mathematical properties of tileable surfaces without discussing LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11539",
      "abstract": "Perceiving and reconstructing 4D spatial-temporal geometry from videos is a fundamental yet challenging computer vision task. To facilitate interactive and real-time applications, we propose a streaming 4D visual geometry transformer that shares a similar philosophy with autoregressive large language models. We explore a simple and efficient design and employ a causal transformer architecture to process the input sequence in an online manner. We use temporal causal attention and cache the historical keys and values as implicit memory to enable efficient streaming long-term 4D reconstruction. This design can handle real-time 4D reconstruction by incrementally integrating historical information while maintaining high-quality spatial consistency. For efficient training, we propose to distill knowledge from the dense bidirectional visual geometry grounded transformer (VGGT) to our causal model. For inference, our model supports the migration of optimized efficient attention operator (e.g., FlashAttention) from the field of large language models. Extensive experiments on various 4D geometry perception benchmarks demonstrate that our model increases the inference speed in online scenarios while maintaining competitive performance, paving the way for scalable and interactive 4D vision systems. Code is available at: https://github.com/wzzheng/StreamVGGT.",
      "authors": [
        "Dong Zhuo",
        "Wenzhao Zheng",
        "Jiahe Guo",
        "Yuqi Wu",
        "Jie Zhou",
        "Jiwen Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:59:57+00:00",
          "link": "https://arxiv.org/abs/2507.11539v1",
          "size": "9132kb",
          "version": "v1"
        }
      ],
      "title": "Streaming 4D Visual Geometry Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11539",
        "HTML": "https://arxiv.org/html/2507.11539v1",
        "PDF": "https://arxiv.org/pdf/2507.11539"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a 4D visual geometry transformer and its improvements in processing video sequences for tasks like 4D reconstruction. It does not discuss aspects of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02221",
      "abstract": "The Genomic Data Commons (GDC) provides access to high quality, harmonized cancer genomics data through a unified curation and analysis platform centered around patient cohorts. While GDC users can interactively create complex cohorts through the graphical Cohort Builder, users (especially new ones) may struggle to find specific cohort descriptors across hundreds of possible fields and properties. However, users may be better able to describe their desired cohort in free-text natural language. We introduce GDC Cohort Copilot, an open-source copilot tool for curating cohorts from the GDC. GDC Cohort Copilot automatically generates the GDC cohort filter corresponding to a user-input natural language description of their desired cohort, before exporting the cohort back to the GDC for further analysis. An interactive user interface allows users to further refine the generated cohort. We develop and evaluate multiple large language models (LLMs) for GDC Cohort Copilot and demonstrate that our locally-served, open-source GDC Cohort LLM achieves better results than GPT-4o prompting in generating GDC cohorts. We implement and share GDC Cohort Copilot as a containerized Gradio app on HuggingFace Spaces, available at https://huggingface.co/spaces/uc-ctds/GDC-Cohort-Copilot. GDC Cohort LLM weights are available at https://huggingface.co/uc-ctds. All source code is available at https://github.com/uc-cdis/gdc-cohort-copilot.",
      "authors": [
        "Steven Song",
        "Anirudh Subramanyam",
        "Zhenyu Zhang",
        "Aarti Venkat",
        "Robert L. Grossman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T00:55:58+00:00",
          "link": "https://arxiv.org/abs/2507.02221v1",
          "size": "308kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T18:30:25+00:00",
          "link": "https://arxiv.org/abs/2507.02221v2",
          "size": "294kb",
          "version": "v2"
        }
      ],
      "title": "GDC Cohort Copilot: An AI Copilot for Curating Cohorts from the Genomic Data Commons",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02221",
        "HTML": "https://arxiv.org/html/2507.02221v2",
        "PDF": "https://arxiv.org/pdf/2507.02221"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the development of LLMs for cohort curation in genomic data but does not primarily focus on LLM training data processing; instead, it is about applying LLMs in a specific use case."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10891",
      "abstract": "Artificial Intelligence (AI) is reshaping journalistic practices across the globe, offering new opportunities while raising ethical, professional, and societal concerns. This study presents a comprehensive systematic review of published articles on AI in journalism from 2010 to 2025. Following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) 2020 guidelines, a total of 72 peer-reviewed articles were selected from Scopus and Web of Science databases. The analysis combines bibliometric mapping and qualitative thematic synthesis to identify dominant trends, technologies, geographical distributions, and ethical debates. Additionally, sentiment analysis was performed on article abstracts using the Valence Aware Dictionary and sEntiment Reasoner (VADER) algorithm to capture evaluative tones across the literature. The findings show a sharp increase in research activity after 2020, with prominent focus areas including automation, misinformation, and ethical governance. While most studies reflect cautious optimism, concerns over bias, transparency, and accountability remain persistent. The review also highlights regional disparities in scholarly contributions, with limited representation from the Global South. By integrating quantitative and qualitative insights, this study offers a multi-dimensional understanding of how AI is transforming journalism and proposes future research directions for inclusive and responsible innovation.",
      "authors": [
        "Mohammad Al Masum Molla and Md Manjurul Ahsan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T01:11:39+00:00",
          "link": "https://arxiv.org/abs/2507.10891v1",
          "size": "3435kb",
          "version": "v1"
        }
      ],
      "title": "Artificial Intelligence and Journalism: A Systematic Bibliometric and Thematic Analysis of Global Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10891",
        "HTML": "https://arxiv.org/html/2507.10891v1",
        "PDF": "https://arxiv.org/pdf/2507.10891"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This systematic review focuses on AI in journalism and its trends without delving into LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11001",
      "abstract": "Service robots are increasingly deployed in diverse and dynamic environments, where both physical layouts and social contexts change over time and across locations. In these unstructured settings, conventional navigation systems that rely on fixed parameters often fail to generalize across scenarios, resulting in degraded performance and reduced social acceptance. Although recent approaches have leveraged reinforcement learning to enhance traditional planners, these methods often fail in real-world deployments due to poor generalization and limited simulation diversity, which hampers effective sim-to-real transfer. To tackle these issues, we present LE-Nav, an interpretable and scene-aware navigation framework that leverages multi-modal large language model reasoning and conditional variational autoencoders to adaptively tune planner hyperparameters. To achieve zero-shot scene understanding, we utilize one-shot exemplars and chain-of-thought prompting strategies. Additionally, a conditional variational autoencoder captures the mapping between natural language instructions and navigation hyperparameters, enabling expert-level tuning. Experiments show that LE-Nav can generate hyperparameters achieving human-level tuning across diverse planners and scenarios. Real-world navigation trials and a user study on a smart wheelchair platform demonstrate that it outperforms state-of-the-art methods on quantitative metrics such as success rate, efficiency, safety, and comfort, while receiving higher subjective scores for perceived safety and social acceptance. Code is available at https://github.com/Cavendish518/LE-Nav.",
      "authors": [
        "Yanbo Wang",
        "Zipeng Fang",
        "Lei Zhao",
        "Weidong Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T05:37:24+00:00",
          "link": "https://arxiv.org/abs/2507.11001v1",
          "size": "9838kb",
          "version": "v1"
        }
      ],
      "title": "Learning to Tune Like an Expert: Interpretable and Scene-Aware Navigation via MLLM Reasoning and CVAE-Based Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11001",
        "HTML": "https://arxiv.org/html/2507.11001v1",
        "PDF": "https://arxiv.org/pdf/2507.11001"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a navigation framework using large language models and autoencoders for tuning planner hyperparameters. It does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.19347",
      "abstract": "We present an all-digital programmable machine learning accelerator chip for image classification, underpinning on the Tsetlin machine (TM) principles. The TM is an emerging machine learning algorithm founded on propositional logic, utilizing sub-pattern recognition expressions called clauses. The accelerator implements the coalesced TM version with convolution, and classifies booleanized images of 28$\\times$28 pixels with 10 categories. A configuration with 128 clauses is used in a highly parallel architecture. Fast clause evaluation is achieved by keeping all clause weights and Tsetlin automata (TA) action signals in registers. The chip is implemented in a 65 nm low-leakage CMOS technology, and occupies an active area of 2.7 mm$^2$. At a clock frequency of 27.8 MHz, the accelerator achieves 60.3k classifications per second, and consumes 8.6 nJ per classification. This demonstrates the energy-efficiency of the TM, which was the main motivation for developing this chip. The latency for classifying a single image is 25.4 $\\mu$s which includes system timing overhead. The accelerator achieves 97.42%, 84.54% and 82.55% test accuracies for the datasets MNIST, Fashion-MNIST and Kuzushiji-MNIST, respectively, matching the TM software models.",
      "authors": [
        "Svein Anders Tunheim",
        "Yujin Zheng",
        "Lei Jiao",
        "Rishad Shafik",
        "Alex Yakovlev",
        "Ole-Christoffer Granmo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-31T17:51:46+00:00",
          "link": "https://arxiv.org/abs/2501.19347v1",
          "size": "24855kb",
          "version": "v1"
        },
        {
          "date": "2025-04-02T09:46:06+00:00",
          "link": "https://arxiv.org/abs/2501.19347v2",
          "size": "18823kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T14:44:46+00:00",
          "link": "https://arxiv.org/abs/2501.19347v3",
          "size": "19351kb",
          "version": "v3"
        }
      ],
      "title": "An All-digital 8.6-nJ/Frame 65-nm Tsetlin Machine Image Classification Accelerator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.19347",
        "HTML": "https://arxiv.org/html/2501.19347v3",
        "PDF": "https://arxiv.org/pdf/2501.19347"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper presents a Tsetlin machine-based image classification accelerator without discussing any aspect of LLM training data processing or engineering."
      },
      "tasks": [
        "All",
        "image-classification",
        "Image Classification"
      ],
      "repo_urls": [
        "https://github.com/satunheim/convcotm_inference_accelerator",
        "https://github.com/satunheim/convcotm-fpga-28x28"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.07363",
      "abstract": "Deepfake Technology Unveiled: The Commoditization of AI and Its Impact on Digital Trust. With the increasing accessibility of generative AI, tools for voice cloning, face-swapping, and synthetic media creation have advanced significantly, lowering both financial and technical barriers for their use. While these technologies present innovative opportunities, their rapid growth raises concerns about trust, privacy, and security. This white paper explores the implications of deepfake technology, analyzing its role in enabling fraud, misinformation, and the erosion of authenticity in multimedia. Using cost-effective, easy to use tools such as Runway, Rope, and ElevenLabs, we explore how realistic deepfakes can be created with limited resources, demonstrating the risks posed to individuals and organizations alike. By analyzing the technical and ethical challenges of deepfake mitigation and detection, we emphasize the urgent need for regulatory frameworks, public awareness, and collaborative efforts to maintain trust in digital media.",
      "authors": [
        "Claudiu Popa",
        "Rex Pallath",
        "Liam Cunningham",
        "Hewad Tahiri",
        "Abiram Kesavarajah",
        "Tao Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-24T18:02:49+00:00",
          "link": "https://arxiv.org/abs/2506.07363v1",
          "size": "536kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T14:07:07+00:00",
          "link": "https://arxiv.org/abs/2506.07363v2",
          "size": "536kb",
          "version": "v2"
        }
      ],
      "title": "Deepfake Technology Unveiled: The Commoditization of AI and Its Impact on Digital Trust",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07363",
        "PDF": "https://arxiv.org/pdf/2506.07363"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with deepfake technology and its implications, lacking any contribution to the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.14110",
      "abstract": "The universal learning framework has been developed to obtain guarantees on the learning rates that hold for any fixed distribution, which can be much faster than the ones uniformly hold over all the distributions. Given that the Empirical Risk Minimization (ERM) principle being fundamental in the PAC theory and ubiquitous in practical machine learning, the recent work of arXiv:2412.02810 studied the universal rates of ERM for binary classification under the realizable setting. However, the assumption of realizability is too restrictive to hold in practice. Indeed, the majority of the literature on universal learning has focused on the realizable case, leaving the non-realizable case barely explored.\n  In this paper, we consider the problem of universal learning by ERM for binary classification under the agnostic setting, where the ''learning curve\" reflects the decay of the excess risk as the sample size increases. We explore the possibilities of agnostic universal rates and reveal a compact trichotomy: there are three possible agnostic universal rates of ERM, being either $e^{-n}$, $o(n^{-1/2})$, or arbitrarily slow. We provide a complete characterization of which concept classes fall into each of these categories. Moreover, we also establish complete characterizations for the target-dependent universal rates as well as the Bayes-dependent universal rates.",
      "authors": [
        "Steve Hanneke and Mingyue Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T02:02:11+00:00",
          "link": "https://arxiv.org/abs/2506.14110v1",
          "size": "54kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T13:56:42+00:00",
          "link": "https://arxiv.org/abs/2506.14110v2",
          "size": "42kb",
          "version": "v2"
        }
      ],
      "title": "Universal rates of ERM for agnostic learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14110",
        "PDF": "https://arxiv.org/pdf/2506.14110"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores learning rates for empirical risk minimization in classification settings, without contributing to LLM training data processing."
      },
      "tasks": [
        "Binary Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10620",
      "abstract": "Large Language Models (LLMs) have emerged as a promising paradigm for time series analytics, leveraging their massive parameters and the shared sequential nature of textual and time series data. However, a cross-modality gap exists between time series and textual data, as LLMs are pre-trained on textual corpora and are not inherently optimized for time series. In this tutorial, we provide an up-to-date overview of LLM-based cross-modal time series analytics. We introduce a taxonomy that classifies existing approaches into three groups based on cross-modal modeling strategies, e.g., conversion, alignment, and fusion, and then discuss their applications across a range of downstream tasks. In addition, we summarize several open challenges. This tutorial aims to expand the practical application of LLMs in solving real-world problems in cross-modal time series analytics while balancing effectiveness and efficiency. Participants will gain a thorough understanding of current advancements, methodologies, and future research directions in cross-modal time series analytics.",
      "authors": [
        "Chenxi Liu",
        "Hao Miao",
        "Cheng Long",
        "Yan Zhao",
        "Ziyue Li",
        "Panos Kalnis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T23:47:32+00:00",
          "link": "https://arxiv.org/abs/2507.10620v1",
          "size": "182kb",
          "version": "v1"
        }
      ],
      "title": "LLMs Meet Cross-Modal Time Series Analytics: Overview and Directions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10620",
        "HTML": "https://arxiv.org/html/2507.10620v1",
        "PDF": "https://arxiv.org/pdf/2507.10620"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides an overview of LLM-based cross-modal time series analytics and does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10872",
      "abstract": "We model a delivery platform facilitating transactions among three sides: buyers, stores, and couriers. In addition to buyers paying store-specific purchase prices and couriers receiving store--buyer-specific delivery compensation from the platform, each buyer has the option to directly tip for delivery from a specific store. An equilibrium consists of prices, compensations, tips, and transactions that clear the market, such that buyers receive deliveries from preferred stores considering the prices and tips they pay, and couriers deliver preferred orders considering the compensations and tips they receive.\n  We illustrate the role of tips in pricing: Without tips, an equilibrium is only guaranteed to exist when there are at least as many couriers as buyers or stores. In contrast, with tips an equilibrium always exists. From an efficiency perspective, the optimal with-tip equilibrium welfare is always weakly larger than the optimal without-tip equilibrium welfare. However, we show that even with tips, efficient equilibria may not exist, and calculating the optimal equilibrium welfare is NP-hard. To address these challenges, we identify natural conditions on market structure that ensure the existence of efficient with-tip equilibria and allow these efficient equilibria to be computed in polynomial time.",
      "authors": [
        "Yannai A. Gonczarowski",
        "Gary Qiurui Ma",
        "David C. Parkes"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T00:24:49+00:00",
          "link": "https://arxiv.org/abs/2507.10872v1",
          "size": "43kb",
          "version": "v1"
        }
      ],
      "title": "Pricing with Tips in Three-Sided Delivery Platforms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10872",
        "HTML": "https://arxiv.org/html/2507.10872v1",
        "PDF": "https://arxiv.org/pdf/2507.10872"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses pricing strategies in delivery platforms, which is unrelated to the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11269",
      "abstract": "Deep reinforcement learning (DRL) agents excel in solving complex decision-making tasks across various domains. However, they often require a substantial number of training steps and a vast experience replay buffer, leading to significant computational and resource demands. To address these challenges, we introduce a novel theoretical result that leverages the Neyman-Rubin potential outcomes framework into DRL. Unlike most methods that focus on bounding the counterfactual loss, we establish a causal bound on the factual loss, which is analogous to the on-policy loss in DRL. This bound is computed by storing past value network outputs in the experience replay buffer, effectively utilizing data that is usually discarded. Extensive experiments across the Atari 2600 and MuJoCo domains on various agents, such as DQN and SAC, achieve up to 2,427% higher reward ratio, outperforming the same agents without our proposed term, and reducing the experience replay buffer size by up to 96%, significantly improving sample efficiency at negligible cost.",
      "authors": [
        "Tal Fiskus",
        "Uri Shaham"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:46:25+00:00",
          "link": "https://arxiv.org/abs/2507.11269v1",
          "size": "11784kb",
          "version": "v1"
        }
      ],
      "title": "Turning Sand to Gold: Recycling Data to Bridge On-Policy and Off-Policy Learning via Causal Bound",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11269",
        "HTML": "https://arxiv.org/html/2507.11269v1",
        "PDF": "https://arxiv.org/pdf/2507.11269"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses leveraging past data in reinforcement learning to improve efficiency through a novel causal bound approach. While it mentions data reuse and efficient storage, it does not focus on processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11533",
      "abstract": "In text-to-image generation, producing a series of consistent contents that preserve the same identity is highly valuable for real-world applications. Although a few works have explored training-free methods to enhance the consistency of generated subjects, we observe that they suffer from the following problems. First, they fail to maintain consistent background details, which limits their applicability. Furthermore, when the foreground character undergoes large motion variations, inconsistencies in identity and clothing details become evident. To address these problems, we propose CharaConsist, which employs point-tracking attention and adaptive token merge along with decoupled control of the foreground and background. CharaConsist enables fine-grained consistency for both foreground and background, supporting the generation of one character in continuous shots within a fixed scene or in discrete shots across different scenes. Moreover, CharaConsist is the first consistent generation method tailored for text-to-image DiT model. Its ability to maintain fine-grained consistency, combined with the larger capacity of latest base model, enables it to produce high-quality visual outputs, broadening its applicability to a wider range of real-world scenarios. The source code has been released at https://github.com/Murray-Wang/CharaConsist",
      "authors": [
        "Mengyu Wang",
        "Henghui Ding",
        "Jianing Peng",
        "Yao Zhao",
        "Yunpeng Chen",
        "Yunchao Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:58:08+00:00",
          "link": "https://arxiv.org/abs/2507.11533v1",
          "size": "31098kb",
          "version": "v1"
        }
      ],
      "title": "CharaConsist: Fine-Grained Consistent Character Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11533",
        "HTML": "https://arxiv.org/html/2507.11533v1",
        "PDF": "https://arxiv.org/pdf/2507.11533"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about improving consistency in text-to-image generation and does not address LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.03525",
      "abstract": "In this paper we study the harmonic map heat flow problem for a radially symmetric case. The corresponding partial dfferential equation plays a key role in many analyses of harmonic map heat flow problems. We consider a basic discretization method for this problem, namely a second order finite difference discretization in space combined with a semi-implicit Euler method in time. The semi-implicit Euler method results in a linear problem in each time step. We restrict to the regime of smooth solutions of the continuous problem and present an error analysis of this discretization method. This results in optimal order discretization error bounds (apart from a logarithmic term). We also present discrete energy estimates that mimic the decrease of the energy of the continuous solution.",
      "authors": [
        "Nam Anh Nguyen and Arnold Reusken"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-05T14:09:48+00:00",
          "link": "https://arxiv.org/abs/2503.03525v1",
          "size": "369kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T08:55:01+00:00",
          "link": "https://arxiv.org/abs/2503.03525v2",
          "size": "372kb",
          "version": "v2"
        }
      ],
      "title": "Discretization error analysis for a radially symmetric harmonic map heat flow problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.03525",
        "HTML": "https://arxiv.org/html/2503.03525v2",
        "PDF": "https://arxiv.org/pdf/2503.03525"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents an error analysis for a discretization method in harmonic map heat flow problems, with no relevance to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.07112",
      "abstract": "As AI-driven agents become increasingly integrated into the digital ecosystem, they reshape how online advertising is perceived and processed. Particularly in the travel and hotel booking sector, these autonomous systems influence the effectiveness of traditional advertising formats. While visual cues and emotional appeals sway human users, AI agents prioritize structured data such as price, availability, and specifications. This study examines how different AI agents interact with online advertising, whether they incorporate ads into their decision-making processes, and which ad formats prove most effective. We analyze interaction patterns, click behavior, and decision-making strategies through experiments with multimodal language models such as OpenAI GPT-4o, Anthropic Claude 3.7 Sonnet, and Google Gemini 2.0 Flash. Our findings reveal that AI agents neither ignore nor systematically avoid advertisements but instead favor certain features-particularly keywords and structured data. These insights have significant implications for the future design of advertising strategies in AI-dominated digital environments.",
      "authors": [
        "Andreas St\\\"ockl and Joel Nitu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-20T08:38:57+00:00",
          "link": "https://arxiv.org/abs/2504.07112v1",
          "size": "2492kb",
          "version": "v1"
        },
        {
          "date": "2025-05-21T05:57:26+00:00",
          "link": "https://arxiv.org/abs/2504.07112v2",
          "size": "1606kb",
          "version": "v2"
        },
        {
          "date": "2025-06-10T09:17:48+00:00",
          "link": "https://arxiv.org/abs/2504.07112v3",
          "size": "1606kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T12:07:42+00:00",
          "link": "https://arxiv.org/abs/2504.07112v4",
          "size": "873kb",
          "version": "v4"
        }
      ],
      "title": "Are AI Agents interacting with Online Ads?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07112",
        "HTML": "https://arxiv.org/html/2504.07112v4",
        "PDF": "https://arxiv.org/pdf/2504.07112"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the interaction between AI agents and online advertising, analyzing interaction patterns and decision-making strategies, without discussing any aspect of LLM training data processing or collection."
      },
      "tasks": [
        "Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10969",
      "abstract": "Sports action classification representing complex body postures and player-object interactions is an emerging area in image-based sports analysis. Some works have contributed to automated sports action recognition using machine learning techniques over the past decades. However, sufficient image datasets representing women sports actions with enough intra- and inter-class variations are not available to the researchers. To overcome this limitation, this work presents a new dataset named WomenSports for women sports classification using small-scale training data. This dataset includes a variety of sports activities, covering wide variations in movements, environments, and interactions among players. In addition, this study proposes a convolutional neural network (CNN) for deep feature extraction. A channel attention scheme upon local contextual regions is applied to refine and enhance feature representation. The experiments are carried out on three different sports datasets and one dance dataset for generalizing the proposed algorithm, and the performances on these datasets are noteworthy. The deep learning method achieves 89.15% top-1 classification accuracy using ResNet-50 on the proposed WomenSports dataset, which is publicly available for research at Mendeley Data.",
      "authors": [
        "Palash Ray",
        "Mahuya Sasmal",
        "and Asish Bera"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T04:18:15+00:00",
          "link": "https://arxiv.org/abs/2507.10969v1",
          "size": "3869kb",
          "version": "v1"
        }
      ],
      "title": "Women Sport Actions Dataset for Visual Classification Using Small Scale Training Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10969",
        "PDF": "https://arxiv.org/pdf/2507.10969"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper presents the creation of a new dataset, 'WomenSports,' detailing data collection and processing for sports action classification, which is relevant to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.05995",
      "abstract": "The high configurability of modern software systems has made configuration tuning a crucial step for assuring system performance, e.g., latency or throughput. However, given the expensive measurements, large configuration space, and rugged configuration landscape, existing tuners suffer ineffectiveness due to the difficult balance of budget utilization between exploring uncertain regions (for escaping from local optima) and exploiting guidance of known good configurations (for fast convergence). The root cause is that we lack knowledge of where the promising regions lay, which also causes challenges in the explainability of the results.\n  In this paper, we propose PromiseTune that tunes configuration guided by causally purified rules. PromiseTune is unique in the sense that we learn rules, which reflect certain regions in the configuration landscape, and purify them with causal inference. The remaining rules serve as approximated reflections of the promising regions, bounding the tuning to emphasize these places in the landscape. This, as we demonstrate, can effectively mitigate the impact of the exploration and exploitation trade-off. Those purified regions can then be paired with the measured configurations to provide spatial explainability at the landscape level. Comparing with 11 state-of-the-art tuners on 12 systems and varying budgets, we show that PromiseTune performs significantly better than the others with 42% superior rank to the overall second best while providing richer information to explain the hidden system characteristics.",
      "authors": [
        "Pengzhou Chen and Tao Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-08T13:54:22+00:00",
          "link": "https://arxiv.org/abs/2507.05995v1",
          "size": "967kb",
          "version": "v1"
        },
        {
          "date": "2025-07-10T03:56:12+00:00",
          "link": "https://arxiv.org/abs/2507.05995v2",
          "size": "967kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T10:08:17+00:00",
          "link": "https://arxiv.org/abs/2507.05995v3",
          "size": "967kb",
          "version": "v3"
        }
      ],
      "title": "PromiseTune: Unveiling Causally Promising and Explainable Configuration Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05995",
        "PDF": "https://arxiv.org/pdf/2507.05995"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "PromiseTune proposes a method for software system configuration tuning using causal inference but does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11067",
      "abstract": "Matrix-accelerated stencil computation is a hot research topic, yet its application to three-dimensional (3D) high-order stencils and HPC remains underexplored. With the emergence of matrix units on multicore CPUs, we analyze matrix-based acceleration strategies and tailor an optimal approach for 3D high-order stencils. We introduce algorithmic optimizations based on SIMD and matrix units to address strided memory accesses, alignment conflicts, and redundant accesses. We propose memory optimizations to boost on-package memory efficiency, and a novel multi-thread parallelism paradigm to overcome data-sharing challenges caused by the absence of shared data caches. MMStencil sustains consistently high hardware utilization across diverse stencil shapes and dimensions. Our DMA-based inter-NUMA communication further mitigates NUMA effects and MPI limitations in hybrid parallelism. Combining all the innovations, MMStencil outperforms state-of-the-art libraries on Nvidia A100 GPGPU by up to 2.1x. Moreover, the performance improvements translate directly to real-world HPC applications and enable RTM applications to yield 1.8x speedup versus a highly optimized industrial Nvidia A100 GPGPU version.",
      "authors": [
        "Yinuo Wang",
        "Tianqi Mao",
        "Lin Gan",
        "Wubing Wan",
        "Zeyu Song",
        "Jiayu Fu",
        "Lanke He",
        "Wenqiang Wang",
        "Zekun Yin",
        "Wei Xue",
        "and Guangwen Yang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:00:11+00:00",
          "link": "https://arxiv.org/abs/2507.11067v1",
          "size": "16129kb",
          "version": "v1"
        }
      ],
      "title": "MMStencil: Optimizing High-order Stencils on Multicore CPU using Matrix Unit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11067",
        "HTML": "https://arxiv.org/html/2507.11067v1",
        "PDF": "https://arxiv.org/pdf/2507.11067"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus here is on optimizing stencil computation in high-performance computing, unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11420",
      "abstract": "Solving chance-constrained optimal control problems for systems subject to non-stationary uncertainties is a significant challenge.Conventional robust model predictive control (MPC) often yields excessive conservatism by relying on static worst-case assumptions, while standard stochastic MPC methods struggle when underlying uncertainty distributions are unknown a priori.This article presents a Risk-Aware Adaptive Robust MPC (RAAR-MPC) framework,a hierarchical architecture that systematically orchestrates a novel synthesis of proactive, learning-based risk assessment and reactive risk regulation. The framework employs a medium-frequency risk assessment engine, which leverages Gaussian process regression and active learning, to construct a tight, data-driven characterization of the prediction error set from operational data.Concurrently, a low-timescale outer loop implements a self-correcting update law for an adaptive safety margin to precisely regulate the empirical risk and compensate for unmodeled dynamics.This dual-timescale adaptation enables the system to rigorously satisfy chance constraints with a user-defined probability, while minimizing the conservatism inherent in traditional approaches.We formally establish that the interplay between these adaptive components guarantees recursive feasibility and ensures the closed-loop system satisfies the chance constraints up to a user-defined risk level with high probability.Numerical experiments on a benchmark DC-DC converter under non-stationary parametric uncertainties demonstrate that our framework precisely achieves the target risk level, resulting in a significantly lower average cost compared to state-of-the-art robust and stochastic MPC strategies.",
      "authors": [
        "Mingcong Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:45:55+00:00",
          "link": "https://arxiv.org/abs/2507.11420v1",
          "size": "1005kb",
          "version": "v1"
        }
      ],
      "title": "A Risk-Aware Adaptive Robust MPC with Learned Uncertainty Quantification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11420",
        "HTML": "https://arxiv.org/html/2507.11420v1",
        "PDF": "https://arxiv.org/pdf/2507.11420"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a risk-aware adaptive robust model predictive control framework and does not touch on LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.21425",
      "abstract": "With the widespread application of large language models in code generation, recent studies demonstrate that employing additional Chain-of-Thought generation models can significantly enhance code generation performance by providing explicit reasoning steps. However, as external components, CoT models are particularly vulnerable to backdoor attacks, which existing defense mechanisms often fail to detect effectively. To address this challenge, we propose GUARD, a novel dual-agent defense framework specifically designed to counter CoT backdoor attacks in neural code generation. GUARD integrates two core components: GUARD-Judge, which identifies suspicious CoT steps and potential triggers through comprehensive analysis, and GUARD-Repair, which employs a retrieval-augmented generation approach to regenerate secure CoT steps for identified anomalies. Experimental results show that GUARD effectively mitigates attacks while maintaining generation quality, advancing secure code generation systems.",
      "authors": [
        "Naizhu Jin",
        "Zhong Li",
        "Tian Zhang",
        "Qingkai Zeng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T16:55:46+00:00",
          "link": "https://arxiv.org/abs/2505.21425v1",
          "size": "2126kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T11:07:06+00:00",
          "link": "https://arxiv.org/abs/2505.21425v2",
          "size": "2126kb",
          "version": "v2"
        }
      ],
      "title": "GUARD:Dual-Agent based Backdoor Defense on Chain-of-Thought in Neural Code Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.21425",
        "HTML": "https://arxiv.org/html/2505.21425v2",
        "PDF": "https://arxiv.org/pdf/2505.21425"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a defense framework for backdoor attacks in neural code generation, unrelated to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11260",
      "abstract": "This paper considers coresets for the robust $k$-medians problem with $m$ outliers, and new constructions in various metric spaces are obtained. Specifically, for metric spaces with a bounded VC or doubling dimension $d$, the coreset size is $O(m) + \\tilde{O}(kd\\varepsilon^{-2})$, which is optimal up to logarithmic factors. For Euclidean spaces, the coreset size is $O(m\\varepsilon^{-1}) + \\tilde{O}(\\min\\{k^{4/3}\\varepsilon^{-2},k\\varepsilon^{-3}\\})$, improving upon a recent result by Jiang and Lou (ICALP 2025). These results also extend to robust $(k,z)$-clustering, yielding, for VC and doubling dimension, a coreset size of $O(m) + \\tilde{O}(kd\\varepsilon^{-2z})$ with the optimal linear dependence on $m$. This extended result improves upon the earlier work of Huang et al. (SODA 2025). The techniques introduce novel dataset decompositions, enabling chaining arguments to be applied jointly across multiple components.",
      "authors": [
        "Lingxiao Huang",
        "Zhenyu Jiang",
        "Yi Li",
        "Xuan Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Geometry (cs.CG)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:33:19+00:00",
          "link": "https://arxiv.org/abs/2507.11260v1",
          "size": "389kb",
          "version": "v1"
        }
      ],
      "title": "On Tight Robust Coresets for $k$-Medians Clustering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11260",
        "HTML": "https://arxiv.org/html/2507.11260v1",
        "PDF": "https://arxiv.org/pdf/2507.11260"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study addresses coresets for robust k-medians clustering, focusing on metric spaces and coreset construction. It does not pertain to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11247",
      "abstract": "Within a legal framework, fairness in datasets and models is typically assessed by dividing observations into predefined groups and then computing fairness measures (e.g., Disparate Impact or Equality of Odds with respect to gender). However, when sensitive attributes such as skin color are continuous, dividing into default groups may overlook or obscure the discrimination experienced by certain minority subpopulations. To address this limitation, we propose a fairness-based grouping approach for continuous (possibly multidimensional) sensitive attributes. By grouping data according to observed levels of discrimination, our method identifies the partition that maximizes a novel criterion based on inter-group variance in discrimination, thereby isolating the most critical subgroups.\n  We validate the proposed approach using multiple synthetic datasets and demonstrate its robustness under changing population distributions - revealing how discrimination is manifested within the space of sensitive attributes. Furthermore, we examine a specialized setting of monotonic fairness for the case of skin color. Our empirical results on both CelebA and FFHQ, leveraging the skin tone as predicted by an industrial proprietary algorithm, show that the proposed segmentation uncovers more nuanced patterns of discrimination than previously reported, and that these findings remain stable across datasets for a given model. Finally, we leverage our grouping model for debiasing purpose, aiming at predicting fair scores with group-by-group post-processing. The results demonstrate that our approach improves fairness while having minimal impact on accuracy, thus confirming our partition method and opening the door for industrial deployment.",
      "authors": [
        "Veronika Shilova",
        "Emmanuel Malherbe",
        "Giovanni Palma",
        "Laurent Risser",
        "Jean-Michel Loubes"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:21:52+00:00",
          "link": "https://arxiv.org/abs/2507.11247v1",
          "size": "539kb",
          "version": "v1"
        }
      ],
      "title": "Fairness-Aware Grouping for Continuous Sensitive Variables: Application for Debiasing Face Analysis with respect to Skin Tone",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11247",
        "HTML": "https://arxiv.org/html/2507.11247v1",
        "PDF": "https://arxiv.org/pdf/2507.11247"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on fairness in datasets, specifically on grouping for sensitive variables, and debiasing, but does not primarily focus on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2312.09611",
      "abstract": "Societal change is often driven by shifts in public opinion. As citizens evolve in their norms, beliefs, and values, public policies change too. While traditional opinion polling and surveys can outline the broad strokes of whether public opinion on a particular topic is changing, they usually cannot capture the full multi-dimensional richness and diversity of opinion present in a large heterogeneous population. However, an increasing fraction of public discourse about public policy issues is now occurring on online platforms, which presents an opportunity to measure public opinion change at a qualitatively different scale of resolution and context.\n  In this paper, we present a conceptual model of observed opinion change on online platforms and apply it to study public discourse on Universal Basic Income (UBI) on Reddit throughout its history. UBI is a periodic, no-strings-attached cash payment given to every citizen of a population. We study UBI as it is a clearly-defined policy proposal that has recently experienced a surge of interest through trends like automation and events like the COVID-19 pandemic. We find that overall stance towards UBI on Reddit significantly declined until mid-2019, when this historical trend suddenly reversed and Reddit became substantially more supportive. Using our model, we find the most significant drivers of this overall stance change were shifts within different user cohorts, within communities that represented similar affluence levels, and within communities that represented similar partisan leanings. Our method identifies nuanced social drivers of opinion change in the large-scale public discourse that now regularly occurs online, and could be applied to a broad set of other important issues and policies.",
      "authors": [
        "Rachel Kim",
        "Veniamin Veselovsky",
        "Ashton Anderson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-15T08:54:10+00:00",
          "link": "https://arxiv.org/abs/2312.09611v1",
          "size": "7112kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T23:54:15+00:00",
          "link": "https://arxiv.org/abs/2312.09611v2",
          "size": "208kb",
          "version": "v2"
        }
      ],
      "title": "Capturing Dynamics in Online Public Discourse: A Case Study of Universal Basic Income Discussions on Reddit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.09611",
        "HTML": "https://arxiv.org/html/2312.09611v2",
        "PDF": "https://arxiv.org/pdf/2312.09611"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes public discourse on Reddit regarding Universal Basic Income but does not involve any processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.08193",
      "abstract": "Large Language Models (LLMs) exhibit impressive capabilities but require careful alignment with human preferences. Traditional training-time methods finetune LLMs using human preference datasets but incur significant training costs and require repeated training to handle diverse user preferences. Test-time alignment methods address this by using reward models (RMs) to guide frozen LLMs without retraining. However, existing test-time approaches rely on trajectory-level RMs which are designed to evaluate complete responses, making them unsuitable for autoregressive text generation that requires computing next-token rewards from partial responses. To address this, we introduce GenARM, a test-time alignment approach that leverages the Autoregressive Reward Model--a novel reward parametrization designed to predict next-token rewards for efficient and effective autoregressive generation. Theoretically, we demonstrate that this parametrization can provably guide frozen LLMs toward any distribution achievable by traditional RMs within the KL-regularized reinforcement learning framework. Experimental results show that GenARM significantly outperforms prior test-time alignment baselines and matches the performance of training-time methods. Additionally, GenARM enables efficient weak-to-strong guidance, aligning larger LLMs with smaller RMs without the high costs of training larger models. Furthermore, GenARM supports multi-objective alignment, allowing real-time trade-offs between preference dimensions and catering to diverse user preferences without retraining. Our project page is available at: https://genarm.github.io.",
      "authors": [
        "Yuancheng Xu",
        "Udari Madhushani Sehwag",
        "Alec Koppel",
        "Sicheng Zhu",
        "Bang An",
        "Furong Huang",
        "Sumitra Ganesh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-10T17:58:24+00:00",
          "link": "https://arxiv.org/abs/2410.08193v1",
          "size": "452kb",
          "version": "v1"
        },
        {
          "date": "2025-01-28T03:28:12+00:00",
          "link": "https://arxiv.org/abs/2410.08193v2",
          "size": "461kb",
          "version": "v2"
        },
        {
          "date": "2025-02-10T22:20:07+00:00",
          "link": "https://arxiv.org/abs/2410.08193v3",
          "size": "466kb",
          "version": "v3"
        },
        {
          "date": "2025-06-11T06:11:03+00:00",
          "link": "https://arxiv.org/abs/2410.08193v4",
          "size": "467kb",
          "version": "v4"
        },
        {
          "date": "2025-07-15T00:32:25+00:00",
          "link": "https://arxiv.org/abs/2410.08193v5",
          "size": "439kb",
          "version": "v5"
        }
      ],
      "title": "GenARM: Reward Guided Generation with Autoregressive Reward Model for Test-time Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08193",
        "PDF": "https://arxiv.org/pdf/2410.08193"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses alignment of LLMs with human preferences using reward models, which mentions the use of training data indirectly, but the focus is on alignment using reward models rather than data processing."
      },
      "tasks": [
        "Text Generation"
      ],
      "repo_urls": [
        "https://github.com/Yuancheng-Xu/GenARM"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.11737",
      "abstract": "Graph pooling, which compresses a whole graph into a smaller coarsened graph, is an essential component of graph representation learning. To efficiently compress a given graph, graph pooling methods often drop their nodes with attention-based scoring with the task loss. However, this often results in simply removing nodes with lower degrees without consideration of their feature-level relevance to the given task. To fix this problem, we propose a Multi-View Pruning(MVP), a graph pruning method based on a multi-view framework and reconstruction loss. Given a graph, MVP first constructs multiple graphs for different views either by utilizing the predefined modalities or by randomly partitioning the input features, to consider the importance of each node in diverse perspectives. Then, it learns the score for each node by considering both the reconstruction and the task loss. MVP can be incorporated with any hierarchical pooling framework to score the nodes. We validate MVP on multiple benchmark datasets by coupling it with two graph pooling methods, and show that it significantly improves the performance of the base graph pooling method, outperforming all baselines. Further analysis shows that both the encoding of multiple views and the consideration of reconstruction loss are the key to the success of MVP, and that it indeed identifies nodes that are less important according to domain knowledge.",
      "authors": [
        "Jiseong Park",
        "Hanjin Kim",
        "Seojin Kim",
        "Jueun Choi",
        "Doheon Lee",
        "Sung Ju Hwang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-14T14:44:54+00:00",
          "link": "https://arxiv.org/abs/2503.11737v1",
          "size": "2213kb",
          "version": "v1"
        },
        {
          "date": "2025-03-18T14:34:49+00:00",
          "link": "https://arxiv.org/abs/2503.11737v2",
          "size": "2213kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T11:59:01+00:00",
          "link": "https://arxiv.org/abs/2503.11737v3",
          "size": "1158kb",
          "version": "v3"
        }
      ],
      "title": "Multi-View Node Pruning for Accurate Graph Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11737",
        "HTML": "https://arxiv.org/html/2503.11737v3",
        "PDF": "https://arxiv.org/pdf/2503.11737"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with graph representation learning and node pruning, which involves model architecture optimization, not training data processing for LLMs."
      },
      "tasks": [
        "Graph Representation Learning",
        "Representation Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10634",
      "abstract": "Massive MIMO systems are moving toward increased numbers of radio frequency chains, higher carrier frequencies and larger bandwidths. As such, digital-to-analog converters (DACs) are becoming a bottleneck in terms of hardware complexity and power consumption. In this work, non-linear precoding for coarsely quantized downlink massive MIMO is studied. Given the NP-hard nature of this problem, a graph neural network (GNN) is proposed that directly outputs the precoded quantized vector based on the channel matrix and the intended transmit symbols. The model is trained in a self-supervised manner, by directly maximizing the achievable rate. To overcome the non-differentiability of the objective function, introduced due to the non-differentiable DAC functions, a straight-through Gumbel-softmax estimation of the gradient is proposed. The proposed method achieves a significant increase in achievable sum rate under coarse quantization. For instance, in the single-user case, the proposed method can achieve the same sum rate as maximum ratio transmission (MRT) by using one-bit DAC's as compared to 3 bits for MRT. This reduces the DAC's power consumption by a factor 4-7 and 3 for baseband and RF DACs respectively. This, however, comes at the cost of increased digital signal processing power consumption. When accounting for this, the reduction in overall power consumption holds for a system bandwidth up to 3.5 MHz for baseband DACs, while the RF DACs can maintain a power reduction of 2.9 for higher bandwidths. Notably, indirect effects, which further reduce the power consumption, such as a reduced fronthaul consumption and reduction in other components, are not considered in this analysis.",
      "authors": [
        "Thomas Feys",
        "Liesbet Van der Perre and Fran\\c{c}ois Rottenberg"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Signal Processing (eess.SP)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T12:16:50+00:00",
          "link": "https://arxiv.org/abs/2507.10634v1",
          "size": "656kb",
          "version": "v1"
        }
      ],
      "title": "Learning to Quantize and Precode in Massive MIMO Systems for Energy Reduction: a Graph Neural Network Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10634",
        "PDF": "https://arxiv.org/pdf/2507.10634"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses energy reduction in massive MIMO systems using graph neural networks, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10934",
      "abstract": "Data quality remains an important challenge in data-driven systems, as errors in tabular data can severely compromise downstream analytics and machine learning performance. Although numerous error detection algorithms have been proposed, the lack of diverse, real-world error datasets limits comprehensive evaluation. Manual error annotation is both time-consuming and inconsistent, motivating the exploration of synthetic error generation as an alternative. In this work, we introduce TableEG, a framework that leverages large language models (LLMs) to generate authentic errors. By employing a table fine-tuning strategy and a triplet representation $(I, T, O)$ to model error generation, detection, and correction tasks, TableEG captures the complex dependencies inherent in two-dimensional tables. Trained on 12 real-world datasets spanning 10 diverse domains, TableEG ensures that the synthesized errors faithfully reflect authentic error distributions. Experimental results indicate that errors generated by TableEG exhibit superior pattern and distribution similarity compared to both rule-based methods and LLM-generated errors without fine-tuning. Furthermore, performance metrics on TableEG-generated errors closely align with those on real-world errors across nearly all datasets and detection algorithms, particularly for machine learning based detection techniques. Overall, TableEG not only bridges the gap between synthetic and real-world errors but also establishes a robust benchmark for subsequent error detection and correction tasks.",
      "authors": [
        "Xinyuan Liu",
        "Jiahui Chen",
        "Bocheng Hu",
        "Yu Sun",
        "Xinyang Chen",
        "Shaoxu Song"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T02:58:25+00:00",
          "link": "https://arxiv.org/abs/2507.10934v1",
          "size": "712kb",
          "version": "v1"
        }
      ],
      "title": "Towards Practical Benchmarking of Data Cleaning Techniques: On Generating Authentic Errors via Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10934",
        "HTML": "https://arxiv.org/html/2507.10934v1",
        "PDF": "https://arxiv.org/pdf/2507.10934"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces TableEG, which uses LLMs for synthesizing error patterns in datasets, highlighting significant contributions to generating high-quality data for error detection and correction benchmarks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11386",
      "abstract": "In this work we extend the Dune solver library with another grid interface to the open-source p4est software. While Dune already supports about a dozen different mesh implementations through its mesh interface Dune-Grid, we undertake this new coupling effort in order to inherit p4est's practically unlimited MPI scalability as well as its relatively thin data structures, and its native support for multi-block (forest) mesh topologies in both 2D and 3D.\n  The presented implementation is compared to an existing implementation based on Dune-ALUGrid for a variety of challenging test examples in a parallel environment. The numerical experiments show that the implementation presented here is outperforming Dune-ALUGrid in terms of scalability. In addition, an alternative balancing strategy is presented to ensure 2:1 balancing across element faces showing improved performance compared to the existing p4est balance strategy in the numerical examples considered in this work.",
      "authors": [
        "Carsten Burstedde",
        "Mikhail Kirilin",
        "Robert Kl\\\"ofkorn"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:56:23+00:00",
          "link": "https://arxiv.org/abs/2507.11386v1",
          "size": "9403kb",
          "version": "v1"
        }
      ],
      "title": "A new Dune grid for scalable dynamic adaptivity based on the p4est software library",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11386",
        "HTML": "https://arxiv.org/html/2507.11386v1",
        "PDF": "https://arxiv.org/pdf/2507.11386"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on scalable dynamic adaptivity in the Dune grid using the p4est software library, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11498",
      "abstract": "Humanoid robots have seen remarkable advances in dexterity, balance, and locomotion, yet their role in expressive domains, such as music performance, remains largely unexplored. Musical tasks, like drumming, present unique challenges, including split-second timing, rapid contacts, and multi-limb coordination over pieces lasting minutes. In this paper, we introduce Robot Drummer, a humanoid system capable of expressive, high-precision drumming across a diverse repertoire of songs. We formulate humanoid drumming as sequential fulfillment of timed-contacts and transform drum scores in to a Rhythmic Contact Chain. To handle the long-horizon nature of musical performance, we decompose each piece into fixed-length segments and train a single policy across all segments in parallel using reinforcement learning. Through extensive experiments on over thirty popular rock, metal, and jazz tracks, our results demonstrate that Robot Drummer consistently achieves high F1 scores. The learned behaviors exhibit emergent human-like drumming strategies, such as cross-arm strikes, and adaptive sticks assignments, demonstrating the potential of reinforcement learning to bring humanoid robots into the domain of creative musical performance. Project page: \\href{https://robot-drummer.github.io}{robot-drummer.github.io}",
      "authors": [
        "Asad Ali Shahid and Francesco Braghin and Loris Roveda"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:16:50+00:00",
          "link": "https://arxiv.org/abs/2507.11498v1",
          "size": "9210kb",
          "version": "v1"
        }
      ],
      "title": "Robot Drummer: Learning Rhythmic Skills for Humanoid Drumming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11498",
        "HTML": "https://arxiv.org/html/2507.11498v1",
        "PDF": "https://arxiv.org/pdf/2507.11498"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about developing a robot drummer using reinforcement learning, not about LLM training data processing or any associated data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.04696",
      "abstract": "Learning correlations from data forms the foundation of today's machine learning (ML) and artificial intelligence (AI) research. While contemporary methods enable the automatic discovery of complex patterns, they are prone to failure when unintended correlations are captured. This vulnerability has spurred a growing interest in interrogating spuriousness, which is often seen as a threat to model performance, fairness, and robustness. In this article, we trace departures from the conventional statistical definition of spuriousness -- which denotes a non-causal relationship arising from coincidence or confounding -- to examine how its meaning is negotiated in ML research. Rather than relying solely on formal definitions, researchers assess spuriousness through what we call pragmatic frames: judgments based on what a correlation does in practice -- how it affects model behavior, supports or impedes task performance, or aligns with broader normative goals. Drawing on a broad survey of ML literature, we identify four such frames: relevance (\"Models should use correlations that are relevant to the task\"), generalizability (\"Models should use correlations that generalize to unseen data\"), human-likeness (\"Models should use correlations that a human would use to perform the same task\"), and harmfulness (\"Models should use correlations that are not socially or ethically harmful\"). These representations reveal that correlation desirability is not a fixed statistical property but a situated judgment informed by technical, epistemic, and ethical considerations. By examining how a foundational ML conundrum is problematized in research literature, we contribute to broader conversations on the contingent practices through which technical concepts like spuriousness are defined and operationalized.",
      "authors": [
        "Samuel J. Bell and Skyler Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-07T13:29:32+00:00",
          "link": "https://arxiv.org/abs/2411.04696v1",
          "size": "729kb",
          "version": "v1"
        },
        {
          "date": "2024-11-11T10:38:39+00:00",
          "link": "https://arxiv.org/abs/2411.04696v2",
          "size": "729kb",
          "version": "v2"
        },
        {
          "date": "2024-11-28T12:00:41+00:00",
          "link": "https://arxiv.org/abs/2411.04696v3",
          "size": "729kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T12:30:00+00:00",
          "link": "https://arxiv.org/abs/2411.04696v4",
          "size": "978kb",
          "version": "v4"
        }
      ],
      "title": "The Pragmatic Frames of Spurious Correlations in Machine Learning: Interpreting How and Why They Matter",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.04696",
        "PDF": "https://arxiv.org/pdf/2411.04696"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses spurious correlations in machine learning, focusing on interpretative frameworks rather than contributions to LLM training data processing."
      },
      "tasks": [
        "Fairness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.04775",
      "abstract": "Shapley values have several desirable, theoretically well-supported, properties for explaining black-box model predictions. Traditionally, Shapley values are computed post-hoc, leading to additional computational cost at inference time. To overcome this, a novel method, called ViaSHAP, is proposed, that learns a function to compute Shapley values, from which the predictions can be derived directly by summation. Two approaches to implement the proposed method are explored; one based on the universal approximation theorem and the other on the Kolmogorov-Arnold representation theorem. Results from a large-scale empirical investigation are presented, showing that ViaSHAP using Kolmogorov-Arnold Networks performs on par with state-of-the-art algorithms for tabular data. It is also shown that the explanations of ViaSHAP are significantly more accurate than the popular approximator FastSHAP on both tabular data and images.",
      "authors": [
        "Amr Alkhatib",
        "Roman Bresson",
        "Henrik Bostr\\\"om",
        "Michalis Vazirgiannis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-07T19:51:17+00:00",
          "link": "https://arxiv.org/abs/2505.04775v1",
          "size": "4081kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T22:55:55+00:00",
          "link": "https://arxiv.org/abs/2505.04775v2",
          "size": "3360kb",
          "version": "v2"
        }
      ],
      "title": "Prediction via Shapley Value Regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.04775",
        "HTML": "https://arxiv.org/html/2505.04775v2",
        "PDF": "https://arxiv.org/pdf/2505.04775"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a method for computing Shapley values for model predictions, without discussing LLM training data processing or creation."
      },
      "tasks": [
        "Kolmogorov-Arnold Networks",
        "Prediction",
        "regression"
      ],
      "repo_urls": [
        "https://github.com/amrmalkhatib/ViaSHAP"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10605",
      "abstract": "As a primary medium for modern information dissemination, social networking services (SNS) have experienced rapid growth, which has proposed significant challenges for platform content management and interaction quality improvement. Recently, the development of large language models (LLMs) has offered potential solutions but existing studies focus on isolated tasks, which not only encounter diminishing benefit from the data scaling within individual scenarios but also fail to flexibly adapt to diverse real-world context. To address these challenges, we introduce RedOne, a domain-specific LLM designed to break the performance bottleneck of single-task baselines and establish a comprehensive foundation for the SNS. RedOne was developed through a three-stage training strategy consisting of continue pretraining, supervised fine-tuning, and preference optimization, using a large-scale real-world dataset. Through extensive experiments, RedOne maintains strong general capabilities, and achieves an average improvement up to 14.02% across 8 major SNS tasks and 7.56% in SNS bilingual evaluation benchmark, compared with base models. Furthermore, through online testing, RedOne reduced the exposure rate in harmful content detection by 11.23% and improved the click page rate in post-view search by 14.95% compared with single-tasks finetuned baseline models. These results establish RedOne as a robust domain-specific LLM for SNS, demonstrating excellent generalization across various tasks and promising applicability in real-world scenarios.",
      "authors": [
        "Fei Zhao",
        "Chonggang Lu",
        "Yue Wang",
        "Zheyong Xie",
        "Ziyan Liu",
        "Haofu Qian",
        "JianZhao Huang",
        "Fangcheng Shi",
        "Zijie Meng",
        "Hongcheng Guo",
        "Mingqian He",
        "Xinze Lyu",
        "Yiming Lu",
        "Ziyang Xiang",
        "Zheyu Ye",
        "Chengqiang Lu",
        "Zhe Xu",
        "Yi Wu",
        "Yao Hu",
        "Yan Gao",
        "Jun Fan",
        "Xiaolong Jiang",
        "Weiting Liu",
        "Boyang Wang",
        "Shaosheng Cao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T02:22:59+00:00",
          "link": "https://arxiv.org/abs/2507.10605v1",
          "size": "2025kb",
          "version": "v1"
        }
      ],
      "title": "RedOne: Revealing Domain-specific LLM Post-Training in Social Networking Services",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10605",
        "HTML": "https://arxiv.org/html/2507.10605v1",
        "PDF": "https://arxiv.org/pdf/2507.10605"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves an LLM post-training strategy using a large-scale dataset but primarily emphasizes domain-specific LLM applications and performance enhancements, not the core processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10843",
      "abstract": "Offline reinforcement learning (RL) aims to learn an optimal policy from a static dataset, making it particularly valuable in scenarios where data collection is costly, such as robotics. A major challenge in offline RL is distributional shift, where the learned policy deviates from the dataset distribution, potentially leading to unreliable out-of-distribution actions. To mitigate this issue, regularization techniques have been employed. While many existing methods utilize density ratio-based measures, such as the $f$-divergence, for regularization, we propose an approach that utilizes the Wasserstein distance, which is robust to out-of-distribution data and captures the similarity between actions. Our method employs input-convex neural networks (ICNNs) to model optimal transport maps, enabling the computation of the Wasserstein distance in a discriminator-free manner, thereby avoiding adversarial training and ensuring stable learning. Our approach demonstrates comparable or superior performance to widely used existing methods on the D4RL benchmark dataset. The code is available at https://github.com/motokiomura/Q-DOT .",
      "authors": [
        "Motoki Omura",
        "Yusuke Mukuta",
        "Kazuki Ota",
        "Takayuki Osa",
        "Tatsuya Harada"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T22:28:36+00:00",
          "link": "https://arxiv.org/abs/2507.10843v1",
          "size": "373kb",
          "version": "v1"
        }
      ],
      "title": "Offline Reinforcement Learning with Wasserstein Regularization via Optimal Transport Maps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10843",
        "HTML": "https://arxiv.org/html/2507.10843v1",
        "PDF": "https://arxiv.org/pdf/2507.10843"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily discusses a reinforcement learning method and its application, specifically focusing on offline RL and the use of the Wasserstein distance for regularization, without contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10850",
      "abstract": "In this work, we present a new deep-learning model for microseismicity monitoring that utilizes continuous spatiotemporal relationships between seismic station recordings, forming an end-to-end pipeline for seismic catalog creation. It employs graph theory and state-of-the-art graph neural network architectures to perform phase picking, association, and event location simultaneously over rolling windows, making it suitable for both playback and near-real-time monitoring. As part of the global strategy to reduce carbon emissions within the broader context of a green-energy transition, there has been growing interest in exploiting enhanced geothermal systems. Tested in the complex geothermal area of Iceland's Hengill region using open-access data from a temporary experiment, our model was trained and validated using both manually revised and automatic seismic catalogs. Results showed a significant increase in event detection compared to previously published automatic systems and reference catalogs, including a $4 M_w$ seismic sequence in December 2018 and a single-day sequence in February 2019. Our method reduces false events, minimizes manual oversight, and decreases the need for extensive tuning of pipelines or transfer learning of deep-learning models. Overall, it validates a robust monitoring tool for geothermal seismic regions, complementing existing systems and enhancing operational risk mitigation during geothermal energy exploitation.",
      "authors": [
        "Matteo Bagagli",
        "Francesco Grigoli",
        "Davide Bacciu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Geophysics (physics.geo-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T22:47:49+00:00",
          "link": "https://arxiv.org/abs/2507.10850v1",
          "size": "3400kb",
          "version": "v1"
        }
      ],
      "title": "HEIMDALL: a grapH-based sEIsMic Detector And Locator for microseismicity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10850",
        "HTML": "https://arxiv.org/html/2507.10850v1",
        "PDF": "https://arxiv.org/pdf/2507.10850"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a deep-learning model for seismic detection and localization, and does not discuss processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10985",
      "abstract": "This paper presents a novel approach for detecting mispronunciations by analyzing deviations between a user's original speech and their voice-cloned counterpart with corrected pronunciation. We hypothesize that regions with maximal acoustic deviation between the original and cloned utterances indicate potential mispronunciations. Our method leverages recent advances in voice cloning to generate a synthetic version of the user's voice with proper pronunciation, then performs frame-by-frame comparisons to identify problematic segments. Experimental results demonstrate the effectiveness of this approach in pinpointing specific pronunciation errors without requiring predefined phonetic rules or extensive training data for each target language.",
      "authors": [
        "Andrew Valdivia",
        "Yueming Zhang",
        "Hailu Xu",
        "Amir Ghasemkhani",
        "Xin Qin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T04:58:19+00:00",
          "link": "https://arxiv.org/abs/2507.10985v1",
          "size": "3500kb",
          "version": "v1"
        }
      ],
      "title": "Pronunciation Deviation Analysis Through Voice Cloning and Acoustic Comparison",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10985",
        "HTML": "https://arxiv.org/html/2507.10985v1",
        "PDF": "https://arxiv.org/pdf/2507.10985"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about detecting mispronunciations using voice cloning, not related to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11095",
      "abstract": "New recursive least squares algorithms with rank two updates (RLSR2) that include both exponential and instantaneous forgetting (implemented via a proper choice of the forgetting factor and the window size) are introduced and systematically associated in this report with well-known RLS algorithms with rank one updates. Moreover, new properties (which can be used for further performance improvement) of the recursive algorithms associated with the convergence of the inverse of information matrix and parameter vector are established in this report. The performance of new algorithms is examined in the problem of estimation of the grid events in the presence of significant harmonic emissions.",
      "authors": [
        "Alexander Stotsky"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Information Theory (cs.IT)",
        "Numerical Analysis (cs.NA)",
        "Dynamical Systems (math.DS)",
        "History and Overview (math.HO)",
        "Information Theory (math.IT)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:42:39+00:00",
          "link": "https://arxiv.org/abs/2507.11095v1",
          "size": "245kb",
          "version": "v1"
        }
      ],
      "title": "Performance Enhancement of the Recursive Least Squares Algorithms with Rank Two Updates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11095",
        "HTML": "https://arxiv.org/html/2507.11095v1",
        "PDF": "https://arxiv.org/pdf/2507.11095"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces algorithms to enhance recursive least squares with rank two updates, focusing on algorithmic performance rather than LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11113",
      "abstract": "Cyber-Physical Systems (CPSs) are facing a fast-growing wave of attacks. To achieve effective proactive defense, this paper models honeypot deployment as a gamma-fixed signaling game in which node liveness serves as the only signal and normal-node signal gamma is exogenously fixed. We define the gamma-perfect Bayesian-Nash equilibrium (gamma-PBNE). Analytical expressions are obtained for all gamma-PBNEs, revealing three distinct equilibrium regimes that depend on the priori honeypot ratio. Furthermore, the optimal honeypot ratio and signaling strategy that jointly maximize the network average utility are obtained. To capture strategic interaction over time, we develop a discrete-time fictitious-play algorithm that couples Bayesian belief updates with empirical best responses. We prove that, as long as the honeypot ratio is perturbed within a non-degenerate neighbourhood of the optimum, every fictitious-play path converges to the defender-optimal gamma-PBNE. Numerical results confirm the effectiveness of the proposed method and demonstrate its applicability to CPS defense.",
      "authors": [
        "Yueyue Xu",
        "Yuewei Chen",
        "Lin Wang",
        "Zhaoyang Cheng",
        "Xiaoming Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:04:31+00:00",
          "link": "https://arxiv.org/abs/2507.11113v1",
          "size": "770kb",
          "version": "v1"
        }
      ],
      "title": "Optimal Honeypot Ratio and Convergent Fictitious-Play Learning in Signaling Games for CPS Defense",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11113",
        "HTML": "https://arxiv.org/html/2507.11113v1",
        "PDF": "https://arxiv.org/pdf/2507.11113"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with CPS defense through signaling games and honeypot deployment, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11513",
      "abstract": "Two OFFO (Objective-Function Free Optimization) noise tolerant algorithms are presented that handle bound constraints, inexact gradients and use second-order information when available.The first is a multi-level method exploiting a hierarchical description of the problem and the second is a domain-decomposition method covering the standard addditive Schwarz decompositions. Both are generalizations of the first-order AdaGrad algorithm for unconstrained optimization. Because these algorithms share a common theoretical framework, a single convergence/complexity theory is provided which covers them both. Its main result is that, with high probability, both methods need at most $O(\\epsilon^{-2})$ iterations and noisy gradient evaluations to compute an $\\epsilon$-approximate first-order critical point of the bound-constrained problem. Extensive numerical experiments are discussed on applications ranging from PDE-based problems to deep neural network training, illustrating their remarkable computational efficiency.",
      "authors": [
        "Serge Gratton and Alena Kopani\\v{c}\\'akov\\'a and Philippe Toint"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Artificial Intelligence (cs.AI)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:32:10+00:00",
          "link": "https://arxiv.org/abs/2507.11513v1",
          "size": "1897kb",
          "version": "v1"
        }
      ],
      "title": "Recursive Bound-Constrained AdaGrad with Applications to Multilevel and Domain Decomposition Minimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11513",
        "HTML": "https://arxiv.org/html/2507.11513v1",
        "PDF": "https://arxiv.org/pdf/2507.11513"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents optimizations in bound-constrained optimization algorithms and their applications but does not relate to LLM training data processing or any steps involved therein."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11236",
      "abstract": "We study the problem of sampling from a distribution $\\mu$ with density $\\propto e^{-V}$ for some potential function $V:\\mathbb R^d\\to \\mathbb R$ with query access to $V$ and $\\nabla V$. We start with the following standard assumptions:\n  (1) The potential function $V$ is $L$-smooth.\n  (2) The second moment $\\mathbf{E}_{X\\sim \\mu}[\\|X\\|^2]\\leq M$.\n  Recently, He and Zhang (COLT'25) showed that the query complexity of sampling from such distributions is at least $\\left(\\frac{LM}{d\\epsilon}\\right)^{\\Omega(d)}$ where $\\epsilon$ is the desired accuracy in total variation distance, and the Poincar\\'e constant can be arbitrarily large.\n  Meanwhile, another common assumption in the study of diffusion based samplers (see e.g., the work of Chen, Chewi, Li, Li, Salim and Zhang (ICLR'23)) strengthens the smoothness condition (1) to the following:\n  (1*) The potential function of *every* distribution along the Ornstein-Uhlenbeck process starting from $\\mu$ is $L$-smooth.\n  We show that under the assumptions (1*) and (2), the query complexity of sampling from $\\mu$ can be $\\mathrm{poly}(L,d)\\cdot \\left(\\frac{Ld+M}{\\epsilon^2}\\right)^{\\mathcal{O}(L+1)}$, which is polynomial in $d$ and $\\frac{1}{\\epsilon}$ when $L=\\mathcal{O}(1)$ and $M=\\mathrm{poly}(d)$. This improves the algorithm with quasi-polynomial query complexity developed by Huang et al. (COLT'24). Our results imply that the seemly moderate strengthening of the smoothness condition (1) to (1*) can lead to an exponential gap in the query complexity of sampling algorithms.\n  Moreover, we show that together with the assumption (1*) and the stronger moment assumption that $\\|X\\|$ is $\\lambda$-sub-Gaussian for $X\\sim\\mu$, the Poincar\\'e constant of $\\mu$ is at most $\\mathcal{O}(\\lambda)^{2(L+1)}$. As an application of our technique, we obtain improved estimate of the Poincar\\'e constant for mixture of Gaussians with the same covariance.",
      "authors": [
        "Yuchen He",
        "Zhehan Lei",
        "Jianan Shao",
        "Chihao Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)",
        "Probability (math.PR)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:06:11+00:00",
          "link": "https://arxiv.org/abs/2507.11236v1",
          "size": "41kb",
          "version": "v1"
        }
      ],
      "title": "Improved sampling algorithms and Poincar\\'e inequalities for non-log-concave distributions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11236",
        "PDF": "https://arxiv.org/pdf/2507.11236"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on sampling algorithms for certain distributions, with no relevance to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11471",
      "abstract": "With advancements in computing and communication technologies, the Internet of Things (IoT) has seen significant growth. IoT devices typically collect data from various sensors, such as temperature, humidity, and energy meters. Much of this data is temporal in nature. Traditionally, data from IoT devices is centralized for analysis, but this approach introduces delays and increased communication costs. Federated learning (FL) has emerged as an effective alternative, allowing for model training across distributed devices without the need to centralize data. In many applications, such as smart home energy and environmental monitoring, the data collected by IoT devices across different locations can exhibit significant variation in trends and seasonal patterns. Accurately forecasting such non-stationary, non-linear time-series data is crucial for applications like energy consumption estimation and weather forecasting. However, these data variations can severely impact prediction accuracy. The key contributions of this paper are: (1) Investigating how non-linear, non-stationary time-series data distributions, like generalized extreme value (gen-extreme) and log norm distributions, affect FL performance. (2) Analyzing how different detrending techniques for non-linear time-series data influence the forecasting model's performance in a FL setup. We generated several synthetic time-series datasets using non-linear data distributions and trained an LSTM-based forecasting model using both centralized and FL approaches. Additionally, we evaluated the impact of detrending on real-world datasets with non-linear time-series data distributions. Our experimental results show that: (1) FL performs worse than centralized approaches when dealing with non-linear data distributions. (2) The use of appropriate detrending techniques improves FL performance, reducing loss across different data distributions.",
      "authors": [
        "Harsha Varun Marisetty",
        "Manik Gupta",
        "Yogesh Simmhan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:41:31+00:00",
          "link": "https://arxiv.org/abs/2507.11471v1",
          "size": "2212kb",
          "version": "v1"
        }
      ],
      "title": "D3FL: Data Distribution and Detrending for Robust Federated Learning in Non-linear Time-series Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11471",
        "HTML": "https://arxiv.org/html/2507.11471v1",
        "PDF": "https://arxiv.org/pdf/2507.11471"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses federated learning and detrending techniques for non-linear time-series data, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11534",
      "abstract": "In this study, we report that quantum quasi-cyclic low-density parity-check codes decoded via joint belief propagation (BP) exhibit steep error-rate curves, despite the presence of error floors. To the best of our knowledge, this is the first observation of such threshold-like behavior for quantum codes with non-vanishing coding rate, excluding those decoded with non-binary BP decoders. Moreover, we find that dominant error events contributing to the error floor typically involve only a small number of bits. These findings suggest that the error floor is caused by trapping sets -- specific subgraph structures in the Tanner graph -- and indicate that identifying and avoiding such structures may lead to further reduction of the error floor.",
      "authors": [
        "Daiki Komoto and Kenta Kasai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:58:33+00:00",
          "link": "https://arxiv.org/abs/2507.11534v1",
          "size": "117kb",
          "version": "v1"
        }
      ],
      "title": "Sharp Error-Rate Transitions in Quantum QC-LDPC Codes under Joint BP Decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11534",
        "HTML": "https://arxiv.org/html/2507.11534v1",
        "PDF": "https://arxiv.org/pdf/2507.11534"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses quantum error correction codes and does not relate to LLM training data engineering or processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11515",
      "abstract": "Operating Large Language Models (LLMs) on edge devices is increasingly challenged by limited communication bandwidth and strained computational and memory costs. Thus, cloud-assisted remote fine-tuning becomes indispensable. Nevertheless, existing Low-Rank Adaptation (LoRA) approaches typically employ fixed or heuristic rank configurations, and the subsequent over-the-air transmission of all LoRA parameters could be rather inefficient. To address this limitation, we develop AirLLM, a hierarchical diffusion policy framework for communication-aware LoRA adaptation. Specifically, AirLLM models the rank configuration as a structured action vector that spans all LoRA-inserted projections. To solve the underlying high-dimensional sequential decision-making problem, a Proximal Policy Optimization (PPO) agent generates coarse-grained decisions by jointly observing wireless states and linguistic complexity, which are then refined via Denoising Diffusion Implicit Models (DDIM) to produce high-resolution, task- and channel-adaptive rank vectors. The two modules are optimized alternatively, with the DDIM trained under the Classifier-Free Guidance (CFG) paradigm to maintain alignment with PPO rewards. Experiments under varying signal-to-noise ratios demonstrate that AirLLM consistently enhances fine-tuning performance while significantly reducing transmission costs, highlighting the effectiveness of reinforcement-driven, diffusion-refined rank adaptation for scalable and efficient remote fine-tuning over the air.",
      "authors": [
        "Shiyi Yang",
        "Xiaoxue Yu",
        "Rongpeng Li",
        "Jianhang Zhu",
        "Zhifeng Zhao",
        "Honggang Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:36:37+00:00",
          "link": "https://arxiv.org/abs/2507.11515v1",
          "size": "920kb",
          "version": "v1"
        }
      ],
      "title": "AirLLM: Diffusion Policy-based Adaptive LoRA for Remote Fine-Tuning of LLM over the Air",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11515",
        "HTML": "https://arxiv.org/html/2507.11515v1",
        "PDF": "https://arxiv.org/pdf/2507.11515"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving remote fine-tuning of LLMs using a communication-aware adaptation framework, primarily addressing transmission efficiency rather than data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10573",
      "abstract": "Solid-state drives (SSDs) have revolutionized data storage with their high performance, energy efficiency, and reliability. However, as storage demands grow, SSDs face critical challenges in scalability, endurance, latency, and security. This survey provides a comprehensive analysis of SSD architecture, key challenges, and device-level optimization techniques. We first examine the fundamental components of SSDs, including NAND flash memory structures, SSD controller functionalities (e.g., address mapping, garbage collection, wear leveling), and host interface protocols (SATA, SAS, NVMe). Next, we discuss major challenges such as reliability degradation, endurance limitations, latency variations, and security threats (e.g., secure deletion, ransomware defense). We then explore advanced optimization techniques, including error correction mechanisms, flash translation layer (FTL) enhancements, and emerging architectures like zoned namespace (ZNS) SSDs and flexible data placement (FDP). Finally, we highlight open research challenges, such as QLC/PLC NAND scalability, performance-reliability trade-offs, and SSD optimizations for AI/LLM workloads. This survey aims to guide future research in developing next-generation SSDs that balance performance, longevity, and security in evolving storage ecosystems.",
      "authors": [
        "Tianyu Ren",
        "Yajuan Du",
        "Jinhua Cui",
        "Yina Lv",
        "Qiao Li",
        "Chun Jason Xue"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T09:33:01+00:00",
          "link": "https://arxiv.org/abs/2507.10573v1",
          "size": "356kb",
          "version": "v1"
        }
      ],
      "title": "Device-Level Optimization Techniques for Solid-State Drives: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10573",
        "HTML": "https://arxiv.org/html/2507.10573v1",
        "PDF": "https://arxiv.org/pdf/2507.10573"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The survey is centered on device-level optimization techniques for SSDs, primarily addressing storage challenges and optimizations, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10852",
      "abstract": "Large Language Models (LLMs) are increasingly used in high-stakes fields where their decisions impact rights and equity. However, LLMs' judicial fairness and implications for social justice remain underexplored. When LLMs act as judges, the ability to fairly resolve judicial issues is a prerequisite to ensure their trustworthiness. Based on theories of judicial fairness, we construct a comprehensive framework to measure LLM fairness, leading to a selection of 65 labels and 161 corresponding values. Applying this framework to the judicial system, we compile an extensive dataset, JudiFair, comprising 177,100 unique case facts. To achieve robust statistical inference, we develop three evaluation metrics, inconsistency, bias, and imbalanced inaccuracy, and introduce a method to assess the overall fairness of multiple LLMs across various labels. Through experiments with 16 LLMs, we uncover pervasive inconsistency, bias, and imbalanced inaccuracy across models, underscoring severe LLM judicial unfairness. Particularly, LLMs display notably more pronounced biases on demographic labels, with slightly less bias on substance labels compared to procedure ones. Interestingly, increased inconsistency correlates with reduced biases, but more accurate predictions exacerbate biases. While we find that adjusting the temperature parameter can influence LLM fairness, model size, release date, and country of origin do not exhibit significant effects on judicial fairness. Accordingly, we introduce a publicly available toolkit containing all datasets and code, designed to support future research in evaluating and improving LLM fairness.",
      "authors": [
        "Yiran Hu",
        "Zongyue Xue",
        "Haitao Li",
        "Siyuan Zheng",
        "Qingjing Chen",
        "Shaochun Wang",
        "Xihan Zhang",
        "Ning Zheng",
        "Yun Liu",
        "Qingyao Ai",
        "Yiqun Liu",
        "Charles L.A. Clarke",
        "Weixing Shen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T22:56:58+00:00",
          "link": "https://arxiv.org/abs/2507.10852v1",
          "size": "49652kb",
          "version": "v1"
        }
      ],
      "title": "LLMs on Trial: Evaluating Judicial Fairness for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10852",
        "HTML": "https://arxiv.org/html/2507.10852v1",
        "PDF": "https://arxiv.org/pdf/2507.10852"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a dataset for evaluating LLM fairness but does not focus on the creation or processing of LLM training data itself. It mentions fairness evaluation rather than data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11138",
      "abstract": "Facial motion capture in mixed reality headsets enables real-time avatar animation, allowing users to convey non-verbal cues during virtual interactions. However, as facial motion data constitutes a behavioral biometric, its use raises novel privacy concerns. With mixed reality systems becoming more immersive and widespread, understanding whether face motion data can lead to user identification or inference of sensitive attributes is increasingly important.\n  To address this, we conducted a study with 116 participants using three types of headsets across three sessions, collecting facial, eye, and head motion data during verbal and non-verbal tasks. The data used is not raw video, but rather, abstract representations that are used to animate digital avatars. Our analysis shows that individuals can be re-identified from this data with up to 98% balanced accuracy, are even identifiable across device types, and that emotional states can be inferred with up to 86% accuracy. These results underscore the potential privacy risks inherent in face motion tracking in mixed reality environments.",
      "authors": [
        "Adriano Castro",
        "Simon Hanisch",
        "Matin Fallahi",
        "Thorsten Strufe"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:40:49+00:00",
          "link": "https://arxiv.org/abs/2507.11138v1",
          "size": "4361kb",
          "version": "v1"
        }
      ],
      "title": "FacialMotionID: Identifying Users of Mixed Reality Headsets using Abstract Facial Motion Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11138",
        "HTML": "https://arxiv.org/html/2507.11138v1",
        "PDF": "https://arxiv.org/pdf/2507.11138"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses privacy concerns with facial motion data in mixed reality environments and does not cover LLM training data processing or management."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11191",
      "abstract": "The optimization of industrial processes remains a critical challenge, particularly when no mathematical formulation of objective functions or constraints is available. This study addresses this issue by proposing a surrogate-based, data-driven methodology for optimizing complex real-world manufacturing systems using only historical process data. Machine learning models are employed to approximate system behavior and construct surrogate models, which are integrated into a tailored metaheuristic approach: Data-Driven Differential Evolution with Multi-Level Penalty Functions and Surrogate Models, an adapted version of Differential Evolution suited to the characteristics of the studied process. The methodology is applied to an extrusion process in the tire manufacturing industry, with the goal of optimizing initialization parameters to reduce waste and production time. Results show that the surrogate-based optimization approach outperforms historical best configurations, achieving a 65\\% reduction in initialization and setup time, while also significantly minimizing material waste. These findings highlight the potential of combining data-driven modeling and metaheuristic optimization for industrial processes where explicit formulations are unavailable.",
      "authors": [
        "Eider Garate-Perez and Kerman L\\'opez de Calle-Etxabe and Susana Ferreiro"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:52:45+00:00",
          "link": "https://arxiv.org/abs/2507.11191v1",
          "size": "2515kb",
          "version": "v1"
        }
      ],
      "title": "Data-Driven Differential Evolution in Tire Industry Extrusion: Leveraging Surrogate Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11191",
        "HTML": "https://arxiv.org/html/2507.11191v1",
        "PDF": "https://arxiv.org/pdf/2507.11191"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Focuses on surrogate-based optimization in the tire industry, unrelated to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11473",
      "abstract": "AI systems that \"think\" in human language offer a unique opportunity for AI safety: we can monitor their chains of thought (CoT) for the intent to misbehave. Like all other known AI oversight methods, CoT monitoring is imperfect and allows some misbehavior to go unnoticed. Nevertheless, it shows promise and we recommend further research into CoT monitorability and investment in CoT monitoring alongside existing safety methods. Because CoT monitorability may be fragile, we recommend that frontier model developers consider the impact of development decisions on CoT monitorability.",
      "authors": [
        "Tomek Korbak",
        "Mikita Balesni",
        "Elizabeth Barnes",
        "Yoshua Bengio",
        "Joe Benton",
        "Joseph Bloom",
        "Mark Chen",
        "Alan Cooney",
        "Allan Dafoe",
        "Anca Dragan",
        "Scott Emmons",
        "Owain Evans",
        "David Farhi",
        "Ryan Greenblatt",
        "Dan Hendrycks",
        "Marius Hobbhahn",
        "Evan Hubinger",
        "Geoffrey Irving",
        "Erik Jenner",
        "Daniel Kokotajlo",
        "Victoria Krakovna",
        "Shane Legg",
        "David Lindner",
        "David Luan",
        "Aleksander M\\k{a}dry",
        "Julian Michael",
        "Neel Nanda",
        "Dave Orr",
        "Jakub Pachocki",
        "Ethan Perez",
        "Mary Phuong",
        "Fabien Roger",
        "Joshua Saxe",
        "Buck Shlegeris",
        "Mart\\'in Soto",
        "Eric Steinberger",
        "Jasmine Wang",
        "Wojciech Zaremba",
        "Bowen Baker",
        "Rohin Shah",
        "Vlad Mikulik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:43:41+00:00",
          "link": "https://arxiv.org/abs/2507.11473v1",
          "size": "132kb",
          "version": "v1"
        }
      ],
      "title": "Chain of Thought Monitorability: A New and Fragile Opportunity for AI Safety",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11473",
        "HTML": "https://arxiv.org/html/2507.11473v1",
        "PDF": "https://arxiv.org/pdf/2507.11473"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses AI safety and monitorability of AI systems through chains of thought, without any focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10564",
      "abstract": "We consider the problem of tool-to-tool matching (TTTM), also called, chamber matching in the context of a semiconductor manufacturing equipment. Traditional TTTM approaches utilize static configuration data or depend on a golden reference which are difficult to obtain in a commercial manufacturing line. Further, existing methods do not extend very well to a heterogeneous setting, where equipment are of different make-and-model, sourced from different equipment vendors. We propose novel TTTM analysis pipelines to overcome these issues. We hypothesize that a mismatched equipment would have higher variance and/or higher number of modes in the data. Our best univariate method achieves a correlation coefficient >0.95 and >0.5 with the variance and number of modes, respectively showing that the proposed methods are effective. Also, the best multivariate method achieves a correlation coefficient >0.75 with the top-performing univariate methods, showing its effectiveness. Finally, we analyze the sensitivity of the multivariate algorithms to the algorithm hyper-parameters.",
      "authors": [
        "Sameera Bharadwaja H.",
        "Siddhrath Jandial",
        "Shashank S. Agashe",
        "Rajesh Kumar Reddy Moore",
        "Youngkwan Kim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Signal Processing (eess.SP)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T06:52:01+00:00",
          "link": "https://arxiv.org/abs/2507.10564v1",
          "size": "1084kb",
          "version": "v1"
        }
      ],
      "title": "Tool-to-Tool Matching Analysis Based Difference Score Computation Methods for Semiconductor Manufacturing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10564",
        "HTML": "https://arxiv.org/html/2507.10564v1",
        "PDF": "https://arxiv.org/pdf/2507.10564"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses tool-to-tool matching in semiconductor manufacturing. It does not focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10873",
      "abstract": "Host-based intrusion detection system (HIDS) is a key defense component to protect the organizations from advanced threats like Advanced Persistent Threats (APT). By analyzing the fine-grained logs with approaches like data provenance, HIDS has shown successes in capturing sophisticated attack traces. Despite the progresses embarked by the research community and industry, HIDS still frequently encounters backlash from their operators in the deployed environments, due to issues like high false-positive rate, inconsistent outcomes across environments and human-unfriendly detection results. Large Language Models (LLMs) have great potentials to advance the state of HIDS, given their extensive knowledge of attack techniques and their ability to detect anomalies through semantic analysis, anchored by recent studies. Yet, our preliminary analysis indicates that building an HIDS by naively prompting an LLM is unlikely to succeed. In this work, we explore the direction of building a customized LLM pipeline for HIDS and develop a system named SHIELD. SHIELD addresses challenges related to LLM's token limits, confusion of background noises, etc., by integrating a variety of techniques like event-level Masked Autoencoder (MAE) for attack window detection, attack evidence identification and expansion, Deterministic Data Augmentation (DDA) for profiling normal activities, and multi-purpose prompting that guides the LLM to conduct precise and interpretable attack investigations. Extensive experiments on three log datasets (DARPA-E3, NodLink-simulated-data and ATLASv2) show that SHIELD consistently achieves outstanding performance in comparison with 5 representative HIDS. These findings highlight the potential of LLMs as powerful tools for intrusion detection and pave the way for future research in this domain.",
      "authors": [
        "Danyu Sun",
        "Jinghuai Zhang",
        "Jiacen Xu",
        "Yu Zheng",
        "Yuan Tian",
        "Zhou Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T00:24:53+00:00",
          "link": "https://arxiv.org/abs/2507.10873v1",
          "size": "494kb",
          "version": "v1"
        }
      ],
      "title": "From Alerts to Intelligence: A Novel LLM-Aided Framework for Host-based Intrusion Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10873",
        "PDF": "https://arxiv.org/pdf/2507.10873"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper explores building a customized LLM pipeline for intrusion detection, it mainly focuses on applying models to specific tasks with data rather than LLM training data processing techniques."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11097",
      "abstract": "Diffusion-based large language models (dLLMs) have recently emerged as a powerful alternative to autoregressive LLMs, offering faster inference and greater interactivity via parallel decoding and bidirectional modeling. However, despite strong performance in code generation and text infilling, we identify a fundamental safety concern: existing alignment mechanisms fail to safeguard dLLMs against context-aware, masked-input adversarial prompts, exposing novel vulnerabilities. To this end, we present DIJA, the first systematic study and jailbreak attack framework that exploits unique safety weaknesses of dLLMs. Specifically, our proposed DIJA constructs adversarial interleaved mask-text prompts that exploit the text generation mechanisms of dLLMs, i.e., bidirectional modeling and parallel decoding. Bidirectional modeling drives the model to produce contextually consistent outputs for masked spans, even when harmful, while parallel decoding limits model dynamic filtering and rejection sampling of unsafe content. This causes standard alignment mechanisms to fail, enabling harmful completions in alignment-tuned dLLMs, even when harmful behaviors or unsafe instructions are directly exposed in the prompt. Through comprehensive experiments, we demonstrate that DIJA significantly outperforms existing jailbreak methods, exposing a previously overlooked threat surface in dLLM architectures. Notably, our method achieves up to 100% keyword-based ASR on Dream-Instruct, surpassing the strongest prior baseline, ReNeLLM, by up to 78.5% in evaluator-based ASR on JailbreakBench and by 37.7 points in StrongREJECT score, while requiring no rewriting or hiding of harmful content in the jailbreak prompt. Our findings underscore the urgent need for rethinking safety alignment in this emerging class of language models. Code is available at https://github.com/ZichenWen1/DIJA.",
      "authors": [
        "Zichen Wen",
        "Jiashu Qu",
        "Dongrui Liu",
        "Zhiyuan Liu",
        "Ruixi Wu",
        "Yicun Yang",
        "Xiangqi Jin",
        "Haoyun Xu",
        "Xuyang Liu",
        "Weijia Li",
        "Chaochao Lu",
        "Jing Shao",
        "Conghui He",
        "Linfeng Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:44:46+00:00",
          "link": "https://arxiv.org/abs/2507.11097v1",
          "size": "1350kb",
          "version": "v1"
        }
      ],
      "title": "The Devil behind the mask: An emergent safety vulnerability of Diffusion LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11097",
        "HTML": "https://arxiv.org/html/2507.11097v1",
        "PDF": "https://arxiv.org/pdf/2507.11097"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper identifies safety vulnerabilities in diffusion-based LLMs, it primarily addresses security concerns in LLM models rather than training data processing. However, it touches on alignment failures, tangentially related to data usage in model alignment."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11316",
      "abstract": "Aligning Large Language Models (LLMs) with human values has attracted increasing attention since it provides clarity, transparency, and the ability to adapt to evolving scenarios. In this paper, we introduce a Controlled Value Vector Activation (ConVA) method that directly aligns the internal values of LLMs by interpreting how a value is encoded in their latent representations and modifies relevant activations to ensure consistent values in LLMs. To ensure an accurate and unbiased interpretation, we propose a context-controlled value vector identification method. To consistently control values without sacrificing model performance, we introduce a gated value vector activation method for effective and minimum degree of value control. Experiments show that our method achieves the highest control success rate across 10 basic values without hurting LLM performance and fluency, and ensures target values even with opposite and potentially malicious input prompts. Source code and data are available at~ https://github.com/hr-jin/ConVA.",
      "authors": [
        "Haoran Jin",
        "Meng Li",
        "Xiting Wang",
        "Zhihao Xu",
        "Minlie Huang",
        "Yantao Jia",
        "Defu Lian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T13:48:35+00:00",
          "link": "https://arxiv.org/abs/2507.11316v1",
          "size": "1144kb",
          "version": "v1"
        }
      ],
      "title": "Internal Value Alignment in Large Language Models through Controlled Value Vector Activation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11316",
        "HTML": "https://arxiv.org/html/2507.11316v1",
        "PDF": "https://arxiv.org/pdf/2507.11316"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on aligning LLMs with human values through controlled value vector activation, but does not discuss processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11352",
      "abstract": "Logistics operators, from battlefield coordinators rerouting airlifts ahead of a storm to warehouse managers juggling late trucks, often face life-critical decisions that demand both domain expertise and rapid and continuous replanning. While popular methods like integer programming yield logistics plans that satisfy user-defined logical constraints, they are slow and assume an idealized mathematical model of the environment that does not account for uncertainty. On the other hand, large language models (LLMs) can handle uncertainty and promise to accelerate replanning while lowering the barrier to entry by translating free-form utterances into executable plans, yet they remain prone to misinterpretations and hallucinations that jeopardize safety and cost. We introduce a neurosymbolic framework that pairs the accessibility of natural-language dialogue with verifiable guarantees on goal interpretation. It converts user requests into structured planning specifications, quantifies its own uncertainty at the field and token level, and invokes an interactive clarification loop whenever confidence falls below an adaptive threshold. A lightweight model, fine-tuned on just 100 uncertainty-filtered examples, surpasses the zero-shot performance of GPT-4.1 while cutting inference latency by nearly 50%. These preliminary results highlight a practical path toward certifiable, real-time, and user-aligned decision-making for complex logistics.",
      "authors": [
        "Yunhao Yang",
        "Neel P. Bhatt",
        "Christian Ellis",
        "Alvaro Velasquez",
        "Zhangyang Wang",
        "Ufuk Topcu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:24:01+00:00",
          "link": "https://arxiv.org/abs/2507.11352v1",
          "size": "2517kb",
          "version": "v1"
        }
      ],
      "title": "Foundation Models for Logistics: Toward Certifiable, Conversational Planning Interfaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11352",
        "HTML": "https://arxiv.org/html/2507.11352v1",
        "PDF": "https://arxiv.org/pdf/2507.11352"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses LLMs in logistics and mentions fine-tuning on uncertainty-filtered examples, it primarily focuses on model performance and application in logistics, not on data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11356",
      "abstract": "Large Language Models (LLMs) are increasingly applied for Process Modeling (PMo) tasks such as Process Model Generation (PMG). To support these tasks, researchers have introduced a variety of Process Model Representations (PMRs) that serve as model abstractions or generation targets. However, these PMRs differ widely in structure, complexity, and usability, and have never been systematically compared. Moreover, recent PMG approaches rely on distinct evaluation strategies and generation techniques, making comparison difficult. This paper presents the first empirical study that evaluates multiple PMRs in the context of PMo with LLMs. We introduce the PMo Dataset, a new dataset containing 55 process descriptions paired with models in nine different PMRs. We evaluate PMRs along two dimensions: suitability for LLM-based PMo and performance on PMG. \\textit{Mermaid} achieves the highest overall score across six PMo criteria, whereas \\textit{BPMN text} delivers the best PMG results in terms of process element similarity.",
      "authors": [
        "Alexis Brissard",
        "Fr\\'ed\\'eric Cuppens",
        "Amal Zouaq"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:26:50+00:00",
          "link": "https://arxiv.org/abs/2507.11356v1",
          "size": "534kb",
          "version": "v1"
        }
      ],
      "title": "What is the Best Process Model Representation? A Comparative Analysis for Process Modeling with Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11356",
        "HTML": "https://arxiv.org/html/2507.11356v1",
        "PDF": "https://arxiv.org/pdf/2507.11356"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces the PMo Dataset, focusing explicitly on the evaluation of different process model representations and contributes a structured dataset, which involves creation and possibly detailed data processing steps."
      },
      "source": "arXiv"
    },
    {
      "id": "2309.16431",
      "abstract": "While seemingly undesirable, it is not a surprising fact that there are certain problems for which quantum computers offer no computational advantage over their respective classical counterparts. Moreover, there are problems for which there is no `useful' computational advantage possible with the current quantum hardware. This situation however can be beneficial if we don't want quantum computers to solve certain problems fast - say problems relevant to post-quantum cryptography. In such a situation, we would like to have evidence that it is difficult to solve those problems on quantum computers; but what is their exact complexity?\n  To do so one has to prove lower bounds, but proving unconditional time lower bounds has never been easy. As a result, resorting to conditional lower bounds has been quite popular in the classical community and is gaining momentum in the quantum community. In this paper, by the use of the QSETH framework [Buhrman-Patro-Speelman 2021], we are able to understand the quantum complexity of a few natural variants of CNFSAT, such as parity-CNFSAT or counting-CNFSAT, and also are able to comment on the non-trivial complexity of approximate-#CNFSAT; both of these have interesting implications about the complexity of (variations of) lattice problems, strong simulation and hitting set problem, and more.\n  In the process, we explore the QSETH framework in greater detail than was (required and) discussed in the original paper, thus also serving as a useful guide on how to effectively use the QSETH framework.",
      "authors": [
        "Yanlin Chen",
        "Yilei Chen",
        "Rajendra Kumar",
        "Subhasree Patro",
        "Florian Speelman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-28T13:30:20+00:00",
          "link": "https://arxiv.org/abs/2309.16431v1",
          "size": "46kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T01:51:03+00:00",
          "link": "https://arxiv.org/abs/2309.16431v2",
          "size": "55kb",
          "version": "v2"
        }
      ],
      "title": "QSETH strikes again: finer quantum lower bounds for lattice problem, strong simulation, hitting set problem, and more",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.16431",
        "HTML": "https://arxiv.org/html/2309.16431v2",
        "PDF": "https://arxiv.org/pdf/2309.16431"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper explores quantum complexity and framework applications, with no relation to processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.03689",
      "abstract": "Quantum processors may enhance machine learning by mapping high-dimensional data onto quantum systems for processing. Conventional quantum kernels, or feature maps, for encoding data features onto a quantum circuit are currently impractical, as the number of entangling gates scales quadratically with the dimension of the dataset and the number of qubits. In this work, we introduce a quantum kernel designed to handle high-dimensional data with a significantly reduced number of qubits and entangling operations. Our approach preserves essential data characteristics while promoting computational efficiency, as evidenced by extensive experiments on benchmark datasets that demonstrate a marked improvement in both accuracy and resource utilization, as compared to state-of-the-art quantum feature maps. Our noisy simulations results combined with lower resource requirements highlight our kernel's ability to function within the constraints of noisy intermediate-scale quantum devices. Through numerical simulations and small-scale implementation on a superconducting circuit quantum computing platform, we demonstrate that our scheme performs on par or better than a set of classical algorithms for classification. Our findings herald a promising avenue for the practical implementation of quantum machine learning algorithms on near future quantum computing platforms.",
      "authors": [
        "Utkarsh Singh",
        "Jean-Fr\\'ed\\'eric Laprade",
        "Aaron Z. Goldberg",
        "Khabat Heshami"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-04T16:12:57+00:00",
          "link": "https://arxiv.org/abs/2507.03689v1",
          "size": "544kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T15:37:48+00:00",
          "link": "https://arxiv.org/abs/2507.03689v2",
          "size": "544kb",
          "version": "v2"
        }
      ],
      "title": "A Resource Efficient Quantum Kernel",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.03689",
        "HTML": "https://arxiv.org/html/2507.03689v2",
        "PDF": "https://arxiv.org/pdf/2507.03689"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a quantum kernel for machine learning with improved resource efficiency; it does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10917",
      "abstract": "Recently, much effort has been devoted to modeling users' multi-interests based on their behaviors or auxiliary signals. However, existing methods often rely on heuristic assumptions, e.g., co-occurring items indicate the same interest of users, failing to capture user multi-interests aligning with real-world scenarios. While large language models (LLMs) show significant potential for multi-interest analysis due to their extensive knowledge and powerful reasoning capabilities, two key challenges remain. First, the granularity of LLM-driven multi-interests is agnostic, possibly leading to overly fine or coarse interest grouping. Second, individual user analysis provides limited insights due to the data sparsity issue. In this paper, we propose an LLM-driven dual-level multi-interest modeling framework for more effective recommendation. At the user-individual level, we exploit LLMs to flexibly allocate items engaged by users into different semantic clusters, indicating their diverse and distinct interests. To alleviate the agnostic generation of LLMs, we adaptively assign these semantic clusters to users' collaborative multi-interests learned from global user-item interactions, allowing the granularity to be automatically adjusted according to the user's behaviors using an alignment module. To alleviate the limited insights derived from individual users' behaviors, at the user-crowd level, we propose aggregating user cliques into synthesized users with rich behaviors for more comprehensive LLM-driven multi-interest analysis. We formulate a max covering problem to ensure the compactness and representativeness of synthesized users' behaviors, and then conduct contrastive learning based on their LLM-driven multi-interests to disentangle item representations among different interests. Experiments on real-world datasets show the superiority of our approach against state-of-the-art methods.",
      "authors": [
        "Ziyan Wang",
        "Yingpeng Du",
        "Zhu Sun",
        "Jieyi Bi",
        "Haoyan Chua",
        "Tianjun Wei",
        "Jie Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T02:13:54+00:00",
          "link": "https://arxiv.org/abs/2507.10917v1",
          "size": "2434kb",
          "version": "v1"
        }
      ],
      "title": "LLM-Driven Dual-Level Multi-Interest Modeling for Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10917",
        "HTML": "https://arxiv.org/html/2507.10917v1",
        "PDF": "https://arxiv.org/pdf/2507.10917"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on recommendation systems and multi-interest modeling using LLMs, but does not address the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.04762",
      "abstract": "The critical perception capabilities of EdgeAI systems, such as autonomous vehicles, are required to be resilient against adversarial threats, by enabling accurate identification and localization of multiple objects in the scene over time, mitigating their impact. Single-agent tracking offers resilience to adversarial attacks but lacks situational awareness, underscoring the need for multi-agent cooperation to enhance context understanding and robustness. This paper proposes a novel mitigation framework on 3D LiDAR scene against adversarial noise by tracking objects based on least-squares graph on multi-agent adversarial bounding boxes. Specifically, we employ the least-squares graph tool to reduce the induced positional error of each detection's centroid utilizing overlapped bounding boxes on a fully connected graph via differential coordinates and anchor points. Hence, the multi-vehicle detections are fused and refined mitigating the adversarial impact, and associated with existing tracks in two stages performing tracking to further suppress the adversarial threat. An extensive evaluation study on the real-world V2V4Real dataset demonstrates that the proposed method significantly outperforms both state-of-the-art single and multi-agent tracking frameworks by up to 23.3% under challenging adversarial conditions, operating as a resilient approach without relying on additional defense mechanisms.",
      "authors": [
        "Maria Damanaki",
        "Ioulia Kapsali",
        "Nikos Piperigkos",
        "Alexandros Gkillas",
        "Aris S. Lalos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T08:41:08+00:00",
          "link": "https://arxiv.org/abs/2507.04762v1",
          "size": "710kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T13:29:17+00:00",
          "link": "https://arxiv.org/abs/2507.04762v2",
          "size": "710kb",
          "version": "v2"
        }
      ],
      "title": "Robustifying 3D Perception via Least-Squares Graphs for Multi-Agent Object Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.04762",
        "HTML": "https://arxiv.org/html/2507.04762v2",
        "PDF": "https://arxiv.org/pdf/2507.04762"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on multi-agent object tracking in autonomous systems using a least-squares graph approach to mitigate adversarial threats, with no mention of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08898",
      "abstract": "Safety alignment is critical for LLM-powered systems. While recent LLM-powered guardrail approaches such as LlamaGuard achieve high detection accuracy of unsafe inputs written in English (e.g., ``How to create a bomb?''), they struggle with multilingual unsafe inputs. This limitation leaves LLM systems vulnerable to unsafe and jailbreak prompts written in low-resource languages such as those in Southeast Asia. This paper introduces SEALGuard, a multilingual guardrail designed to improve the safety alignment across diverse languages. It aims to address the multilingual safety alignment gap of existing guardrails and ensure effective filtering of unsafe and jailbreak prompts in LLM-powered systems. We adapt a general-purpose multilingual language model into a multilingual guardrail using low-rank adaptation (LoRA). We construct SEALSBench, a large-scale multilingual safety alignment dataset containing over 260,000 prompts in ten languages, including safe, unsafe, and jailbreak cases. We evaluate SEALGuard against state-of-the-art guardrails such as LlamaGuard on this benchmark. Our findings show that multilingual unsafe and jailbreak prompts substantially degrade the performance of the state-of-the-art LlamaGuard, which experiences a drop in Defense Success Rate (DSR) by 9% and 18%, respectively, compared to its performance on English-only prompts. In contrast, SEALGuard outperforms existing guardrails in detecting multilingual unsafe and jailbreak prompts, improving DSR by 48% over LlamaGuard and achieving the best DSR, precision, and F1-score. Our ablation study further reveals the contributions of adaptation strategies and model size to the overall performance of SEALGuard. SEALGuard advances the safety alignment of LLM systems by introducing an effective multilingual guardrail.",
      "authors": [
        "Wenliang Shan",
        "Michael Fu",
        "Rui Yang",
        "Chakkrit Tantithamthavorn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T05:15:35+00:00",
          "link": "https://arxiv.org/abs/2507.08898v1",
          "size": "7452kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T05:06:59+00:00",
          "link": "https://arxiv.org/abs/2507.08898v2",
          "size": "7434kb",
          "version": "v2"
        }
      ],
      "title": "SEALGuard: Safeguarding the Multilingual Conversations in Southeast Asian Languages for LLM Software Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08898",
        "PDF": "https://arxiv.org/pdf/2507.08898"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper constructs SEALSBench, a multilingual safety alignment dataset, but the focus is on performance evaluation of multilingual guardrails rather than processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10607",
      "abstract": "This paper introduces \\textbf{Measure Learning}, a paradigm for modeling ambiguity via non-linear expectations. We define Neural Expectation Operators as solutions to Backward Stochastic Differential Equations (BSDEs) whose drivers are parameterized by neural networks. The main mathematical contribution is a rigorous well-posedness theorem for BSDEs whose drivers satisfy a local Lipschitz condition in the state variable $y$ and quadratic growth in its martingale component $z$. This result circumvents the classical global Lipschitz assumption, is applicable to common neural network architectures (e.g., with ReLU activations), and holds for exponentially integrable terminal data, which is the sharp condition for this setting. Our primary innovation is to build a constructive bridge between the abstract, and often restrictive, assumptions of the deep theory of quadratic BSDEs and the world of machine learning, demonstrating that these conditions can be met by concrete, verifiable neural network designs. We provide constructive methods for enforcing key axiomatic properties, such as convexity, by architectural design. The theory is extended to the analysis of fully coupled Forward-Backward SDE systems and to the asymptotic analysis of large interacting particle systems, for which we establish both a Law of Large Numbers (propagation of chaos) and a Central Limit Theorem. This work provides the foundational mathematical framework for data-driven modeling under ambiguity.",
      "authors": [
        "Qian Qi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Probability (math.PR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T06:19:28+00:00",
          "link": "https://arxiv.org/abs/2507.10607v1",
          "size": "96kb",
          "version": "v1"
        }
      ],
      "title": "Neural Expectation Operators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10607",
        "HTML": "https://arxiv.org/html/2507.10607v1",
        "PDF": "https://arxiv.org/pdf/2507.10607"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The primary focus is on neural expectation operators and theoretical advancements in BSDEs, with no connection to LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10979",
      "abstract": "Infinite networks are complex interconnected systems comprising a countably infinite number of subsystems, where counting them precisely poses a significant challenge due to the seemingly endless interconnected nature of the network (e.g., counting vehicles on the road). In such scenarios, the presence of infinitely many subsystems within the network renders the existing analysis frameworks tailored for finite networks inapplicable to infinite ones. This paper is concerned with offering a data-driven approach, within a compositional framework, for the safety certification of infinite networks with both unknown mathematical models and interconnection topologies. Given the immense computational complexity stemming from the extensive dimension of infinite networks, our approach capitalizes on the joint dissipativity-type properties of subsystems, characterized by storage certificates. We introduce innovative compositional data-driven conditions to construct a barrier certificate for the infinite network leveraging storage certificates of its unknown subsystems derived from data, while offering correctness guarantees across the network safety. We demonstrate that our compositional data-driven reasoning eliminates the requirement for checking the traditional dissipativity condition, which typically mandates precise knowledge of the interconnection topology. In addition, while existing data-driven literature demonstrates an exponential trend in sample complexity with respect to network size, we showcase that our compositional strategy notably reduces it to a linear scale in terms of the number of subsystems. We illustrate our data-driven results on two physical infinite networks with unknown models and interconnection topologies.",
      "authors": [
        "Mahdieh Zaker",
        "Amy Nejati",
        "Abolfazl Lavaei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T04:45:42+00:00",
          "link": "https://arxiv.org/abs/2507.10979v1",
          "size": "3341kb",
          "version": "v1"
        }
      ],
      "title": "Data-Driven Safety Certificates of Infinite Networks with Unknown Models and Interconnection Topologies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10979",
        "PDF": "https://arxiv.org/pdf/2507.10979"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a data-driven approach for safety certification in infinite networks, focusing on network analysis rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11150",
      "abstract": "In the design of integrated circuits, one critical metric is the maximum delay introduced by combinational modules within the circuit. This delay is crucial because it represents the time required to perform a computation: in an Arithmetic-Logic Unit it represents the maximum time taken by the circuit to perform an arithmetic operation. When such a circuit is part of a larger, synchronous system, like a CPU, the maximum delay directly impacts the maximum clock frequency of the entire system. Typically, hardware designers use Static Timing Analysis to compute an upper bound of the maximum delay because it can be determined in polynomial time. However, relying on this upper bound can lead to suboptimal processor speeds, thereby missing performance opportunities. In this work, we tackle the challenging task of computing the actual maximum delay, rather than an approximate value. Since the problem is computationally hard, we model it in Answer Set Programming (ASP), a logic language featuring extremely efficient solvers. We propose non-trivial encodings of the problem into ASP. Experimental results show that ASP is a viable solution to address complex problems in hardware design.",
      "authors": [
        "Alessandro Bertagnon",
        "Marcello Dalpasso",
        "Michele Favalli",
        "Marco Gavanelli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:57:45+00:00",
          "link": "https://arxiv.org/abs/2507.11150v1",
          "size": "100kb",
          "version": "v1"
        }
      ],
      "title": "Fine-grained Timing Analysis of Digital Integrated Circuits in Answer Set Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11150",
        "PDF": "https://arxiv.org/pdf/2507.11150"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with timing analysis in digital circuits using Answer Set Programming and does not pertain to processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11270",
      "abstract": "The COVID-19 pandemic has severely affected public health, healthcare systems, and daily life, especially amid resource shortages and limited workers. This crisis has underscored the urgent need for automation in hospital environments, particularly disinfection, which is crucial to controlling virus transmission and improving the safety of healthcare personnel and patients. Ultraviolet (UV) light disinfection, known for its high efficiency, has been widely adopted in hospital settings. However, most existing research focuses on maximizing UV coverage while paying little attention to the impact of human activity on virus distribution. To address this issue, we propose a mobile robotic system for UV disinfection focusing on the virus hotspot. The system prioritizes disinfection in high-risk areas and employs an approach for optimized UV dosage to ensure that all surfaces receive an adequate level of UV exposure while significantly reducing disinfection time. It not only improves disinfection efficiency but also minimizes unnecessary exposure in low-risk areas. In two representative hospital scenarios, our method achieves the same disinfection effectiveness while reducing disinfection time by 30.7% and 31.9%, respectively. The video of the experiment is available at: https://youtu.be/wHcWzOcoMPM.",
      "authors": [
        "Ting-Wei Ou",
        "Jia-Hao Jiang",
        "Guan-Lin Huang and Kuu-Young Young"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:46:31+00:00",
          "link": "https://arxiv.org/abs/2507.11270v1",
          "size": "2186kb",
          "version": "v1"
        }
      ],
      "title": "Development of an Autonomous Mobile Robotic System for Efficient and Precise Disinfection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11270",
        "HTML": "https://arxiv.org/html/2507.11270v1",
        "PDF": "https://arxiv.org/pdf/2507.11270"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is focused on developing a mobile robotic system for UV disinfection, with no mention of processing or engineering LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2111.06105",
      "abstract": "Analytic combinatorics in several variables is a branch of mathematics that deals with deriving the asymptotic behavior of combinatorial quantities by analyzing multivariate generating functions. We study information-theoretic questions about sequences in a discrete noiseless channel under cost constraints. Our main contributions involve the relationship between the graph structure of the channel and the singularities of the bivariate generating function whose coefficients are the number of sequences satisfying the constraints. We use these new results to invoke theorems from multivariate analytic combinatorics to obtain the asymptotic behavior of the number of cost-limited strings that are admissible by the channel. This builds a new bridge between analytic combinatorics in several variables and labeled weighted graphs, bringing a new perspective and a set of powerful results to the literature of cost-constrained channels. Along the way, we show that the cost-constrained channel capacity is determined by a cost-dependent singularity of the bivariate generating function, generalizing Shannon's classical result for unconstrained capacity, and provide a new proof of the equivalence of the combinatorial and probabilistic definitions of the cost-constrained capacity.",
      "authors": [
        "Andreas Lenz",
        "Stephen Melczer",
        "Cyrus Rashtchian",
        "Paul H. Siegel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Computational Complexity (cs.CC)",
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2021-11-11T09:00:25+00:00",
          "link": "https://arxiv.org/abs/2111.06105v1",
          "size": "98kb",
          "version": "v1"
        },
        {
          "date": "2021-11-14T12:14:32+00:00",
          "link": "https://arxiv.org/abs/2111.06105v2",
          "size": "98kb",
          "version": "v2"
        },
        {
          "date": "2025-01-14T21:20:05+00:00",
          "link": "https://arxiv.org/abs/2111.06105v3",
          "size": "50kb",
          "version": "v3"
        },
        {
          "date": "2025-01-25T12:41:31+00:00",
          "link": "https://arxiv.org/abs/2111.06105v4",
          "size": "51kb",
          "version": "v4"
        },
        {
          "date": "2025-07-14T20:34:00+00:00",
          "link": "https://arxiv.org/abs/2111.06105v5",
          "size": "138kb",
          "version": "v5"
        }
      ],
      "title": "Multivariate Analytic Combinatorics for Cost Constrained Channels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2111.06105",
        "PDF": "https://arxiv.org/pdf/2111.06105"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with information-theoretic questions and analytic combinatorics related to channels, but does not address LLM training data processing or dataset engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2302.05545",
      "abstract": "A novel form of inference attack in vertical federated learning (VFL) is proposed, where two parties collaborate in training a machine learning (ML) model. Logistic regression is considered for the VFL model. One party, referred to as the active party, possesses the ground truth labels of the samples in the training phase, while the other, referred to as the passive party, only shares a separate set of features corresponding to these samples. It is shown that the active party can carry out inference attacks on both training and prediction phase samples by acquiring an ML model independently trained on the training samples available to them. This type of inference attack does not require the active party to be aware of the score of a specific sample, hence it is referred to as an agnostic inference attack. It is shown that utilizing the observed confidence scores during the prediction phase, before the time of the attack, can improve the performance of the active party's autonomous ML model, and thus improve the quality of the agnostic inference attack. As a countermeasure, privacy-preserving schemes (PPSs) are proposed. While the proposed schemes preserve the utility of the VFL model, they systematically distort the VFL parameters corresponding to the passive party's features. The level of the distortion imposed on the passive party's parameters is adjustable, giving rise to a trade-off between privacy of the passive party and interpretabiliy of the VFL outcomes by the active party. The distortion level of the passive party's parameters could be chosen carefully according to the privacy and interpretabiliy concerns of the passive and active parties, respectively, with the hope of keeping both parties (partially) satisfied. Finally, experimental results demonstrate the effectiveness of the proposed attack and the PPSs.",
      "authors": [
        "Morteza Varasteh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2023-02-10T23:19:30+00:00",
          "link": "https://arxiv.org/abs/2302.05545v1",
          "size": "876kb",
          "version": "v1"
        },
        {
          "date": "2023-03-02T21:08:45+00:00",
          "link": "https://arxiv.org/abs/2302.05545v2",
          "size": "553kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T12:42:15+00:00",
          "link": "https://arxiv.org/abs/2302.05545v3",
          "size": "450kb",
          "version": "v3"
        }
      ],
      "title": "Privacy Against Agnostic Inference Attacks in Vertical Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2302.05545",
        "HTML": "https://arxiv.org/html/2302.05545v3",
        "PDF": "https://arxiv.org/pdf/2302.05545"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses inference attacks and privacy schemes in federated learning, with no direct contribution to LLM training data processing."
      },
      "tasks": [
        "Federated Learning",
        "Inference Attack",
        "Privacy Preserving",
        "Vertical Federated Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.14688",
      "abstract": "This paper introduces semi-competitive differential game logic dGLsc, which enables verification of safety-critical applications that involve interactions between two agents. In dGLsc, these interactions are specified as games on hybrid systems with two players that may collaborate with each other when helpful and may compete when necessary. The players in the hybrid games of dGLsc have individual goals that may overlap, leading to nonzero-sum games. This makes dGLsc especially well-suited for verifying situations where players, e.g., share safety objectives but otherwise pursue different goals, so that zero-sum assumptions lead to overly conservative results. Additionally, dGLsc solves the subtlety that even though each player may benefit from knowledge of the other player's goals, e.g., concerning shared safety objectives, unsafe situations might still occur if every player were to mutually assume the other player would act to avoid unsafety. The syntax and semantics, as well as a sound and relatively complete proof calculus are presented for dGLsc. The relationship between dGLsc and zero-sum differential game logic dGL is discussed and the purpose of dGLsc illustrated in a canonical example.",
      "authors": [
        "Julia Butte and Andr\\'e Platzer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-10T13:37:44+00:00",
          "link": "https://arxiv.org/abs/2505.14688v1",
          "size": "91kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T09:24:41+00:00",
          "link": "https://arxiv.org/abs/2505.14688v2",
          "size": "37kb",
          "version": "v2"
        }
      ],
      "title": "Semi-Competitive Differential Game Logic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.14688",
        "HTML": "https://arxiv.org/html/2505.14688v2",
        "PDF": "https://arxiv.org/pdf/2505.14688"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses semi-competitive differential game logic and does not focus on any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10775",
      "abstract": "Spacecraft deployed in outer space are routinely subjected to various forms of damage due to exposure to hazardous environments. In addition, there are significant risks to the subsequent process of in-space repairs through human extravehicular activity or robotic manipulation, incurring substantial operational costs. Recent developments in image segmentation could enable the development of reliable and cost-effective autonomous inspection systems. While these models often require large amounts of training data to achieve satisfactory results, publicly available annotated spacecraft segmentation data are very scarce. Here, we present a new dataset of nearly 64k annotated spacecraft images that was created using real spacecraft models, superimposed on a mixture of real and synthetic backgrounds generated using NASA's TTALOS pipeline. To mimic camera distortions and noise in real-world image acquisition, we also added different types of noise and distortion to the images. Finally, we finetuned YOLOv8 and YOLOv11 segmentation models to generate performance benchmarks for the dataset under well-defined hardware and inference time constraints to mimic real-world image segmentation challenges for real-time onboard applications in space on NASA's inspector spacecraft. The resulting models, when tested under these constraints, achieved a Dice score of 0.92, Hausdorff distance of 0.69, and an inference time of about 0.5 second. The dataset and models for performance benchmark are available at https://github.com/RiceD2KLab/SWiM.",
      "authors": [
        "Jeffrey Joan Sam",
        "Janhavi Sathe",
        "Nikhil Chigali",
        "Naman Gupta",
        "Radhey Ruparel",
        "Yicheng Jiang",
        "Janmajay Singh",
        "James W. Berck",
        "and Arko Barman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T20:02:40+00:00",
          "link": "https://arxiv.org/abs/2507.10775v1",
          "size": "7907kb",
          "version": "v1"
        }
      ],
      "title": "A New Dataset and Performance Benchmark for Real-time Spacecraft Segmentation in Onboard Flight Computers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10775",
        "HTML": "https://arxiv.org/html/2507.10775v1",
        "PDF": "https://arxiv.org/pdf/2507.10775"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a new dataset for spacecraft segmentation, including data processing steps such as noise and distortion addition, but its primary focus is on benchmarking models, not LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10914",
      "abstract": "We study online algorithms to tune the parameters of a robot controller in a setting where the dynamics, policy class, and optimality objective are all time-varying. The system follows a single trajectory without episodes or state resets, and the time-varying information is not known in advance. Focusing on nonlinear geometric quadrotor controllers as a test case, we propose a practical implementation of a single-trajectory model-based online policy optimization algorithm, M-GAPS,along with reparameterizations of the quadrotor state space and policy class to improve the optimization landscape. In hardware experiments,we compare to model-based and model-free baselines that impose artificial episodes. We show that M-GAPS finds near-optimal parameters more quickly, especially when the episode length is not favorable. We also show that M-GAPS rapidly adapts to heavy unmodeled wind and payload disturbances, and achieves similar strong improvement on a 1:6-scale Ackermann-steered car. Our results demonstrate the hardware practicality of this emerging class of online policy optimization that offers significantly more flexibility than classic adaptive control, while being more stable and data-efficient than model-free reinforcement learning.",
      "authors": [
        "James A. Preiss",
        "Fengze Xie",
        "Yiheng Lin",
        "Adam Wierman",
        "and Yisong Yue"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T02:10:52+00:00",
          "link": "https://arxiv.org/abs/2507.10914v1",
          "size": "1313kb",
          "version": "v1"
        }
      ],
      "title": "Fast Non-Episodic Adaptive Tuning of Robot Controllers with Online Policy Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10914",
        "HTML": "https://arxiv.org/html/2507.10914v1",
        "PDF": "https://arxiv.org/pdf/2507.10914"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This research pertains to adaptive tuning of robot controllers and online policy optimization, not focused on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10938",
      "abstract": "Semantic change detection (SCD) extends the binary change detection task to provide not only the change locations but also the detailed \"from-to\" categories in multi-temporal remote sensing data. Such detailed semantic insights into changes offer considerable advantages for a wide array of applications. However, since SCD involves the simultaneous optimization of multiple tasks, the model is prone to negative transfer due to task-specific learning difficulties and conflicting gradient flows. To address this issue, we propose Graph Aggregation Prototype Learning for Semantic Change Detection in remote sensing(GAPL-SCD). In this framework, a multi-task joint optimization method is designed to optimize the primary task of semantic segmentation and change detection, along with the auxiliary task of graph aggregation prototype learning. Adaptive weight allocation and gradient rotation methods are used to alleviate the conflict between training tasks and improve multi-task learning capabilities. Specifically, the graph aggregation prototype learning module constructs an interaction graph using high-level features. Prototypes serve as class proxies, enabling category-level domain alignment across time points and reducing interference from irrelevant changes. Additionally, the proposed self-query multi-level feature interaction and bi-temporal feature fusion modules further enhance multi-scale feature representation, improving performance in complex scenes. Experimental results on the SECOND and Landsat-SCD datasets demonstrate that our method achieves state-of-the-art performance, with significant improvements in accuracy and robustness for SCD task.",
      "authors": [
        "Zhengyi Xu",
        "Haoran Wu",
        "Wen Jiang",
        "Jie Geng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T03:03:29+00:00",
          "link": "https://arxiv.org/abs/2507.10938v1",
          "size": "6984kb",
          "version": "v1"
        }
      ],
      "title": "Graph Aggregation Prototype Learning for Semantic Change Detection in Remote Sensing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10938",
        "HTML": "https://arxiv.org/html/2507.10938v1",
        "PDF": "https://arxiv.org/pdf/2507.10938"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on semantic change detection in remote sensing, specifically on model optimization for multi-task learning, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11133",
      "abstract": "Diagnostic activities, such as ultrasound scans and palpation, are relatively low-cost. They play a crucial role in the early detection of health problems and in assessing their progression. However, they are also error-prone activities, which require highly skilled medical staff. The use of robotic solutions can be key to decreasing the inherent subjectivity of the results and reducing the waiting list. For a robot to perform palpation or ultrasound scans, it must effectively manage physical interactions with the human body, which greatly benefits from precise estimation of the patient's tissue biomechanical properties. This paper assesses the accuracy and precision of a robotic system in estimating the viscoelastic parameters of various materials, including some tests on ex vivo tissues as a preliminary proof-of-concept demonstration of the method's applicability to biological samples. The measurements are compared against a ground truth derived from silicone specimens with different viscoelastic properties, characterised using a high-precision instrument. Experimental results show that the robotic system's accuracy closely matches the ground truth, increasing confidence in the potential use of robots for such clinical applications.",
      "authors": [
        "Luca Beber",
        "Edoardo Lamon",
        "Giacomo Moretti",
        "Matteo Saveriano",
        "Luca Fambri",
        "Luigi Palopoli",
        "Daniele Fontanelli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:33:25+00:00",
          "link": "https://arxiv.org/abs/2507.11133v1",
          "size": "14698kb",
          "version": "v1"
        }
      ],
      "title": "Force-Based Viscosity and Elasticity Measurements for Material Biomechanical Characterisation with a Collaborative Robotic Arm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11133",
        "HTML": "https://arxiv.org/html/2507.11133v1",
        "PDF": "https://arxiv.org/pdf/2507.11133"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study is centered on using robotic systems for biomechanical characterisation, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11408",
      "abstract": "Chain-of-thought traces have been shown to improve performance of large language models in a plethora of reasoning tasks, yet there is no consensus on the mechanism through which this performance boost is achieved. To shed more light on this, we introduce Causal CoT Graphs (CCGs), which are directed acyclic graphs automatically extracted from reasoning traces that model fine-grained causal dependencies in the language model output. A collection of $1671$ mathematical reasoning problems from MATH500, GSM8K and AIME, and their associated CCGs are compiled into our dataset -- \\textbf{KisMATH}. Our detailed empirical analysis with 15 open-weight LLMs shows that (i) reasoning nodes in the CCG are mediators for the final answer, a condition necessary for reasoning; and (ii) LLMs emphasise reasoning paths given by the CCG, indicating that models internally realise structures akin to our graphs. KisMATH enables controlled, graph-aligned interventions and opens up avenues for further investigation into the role of chain-of-thought in LLM reasoning.",
      "authors": [
        "Soumadeep Saha",
        "Akshay Chaturvedi",
        "Saptarshi Saha",
        "Utpal Garain",
        "Nicholas Asher"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:28:37+00:00",
          "link": "https://arxiv.org/abs/2507.11408v1",
          "size": "1738kb",
          "version": "v1"
        }
      ],
      "title": "KisMATH: Do LLMs Have Knowledge of Implicit Structures in Mathematical Reasoning?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11408",
        "HTML": "https://arxiv.org/html/2507.11408v1",
        "PDF": "https://arxiv.org/pdf/2507.11408"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses the compilation of a new dataset KisMATH, but its focus is on evaluating reasoning capabilities of LLMs with causal reasoning graphs, not primarily on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2405.14374",
      "abstract": "Traditional offline reinforcement learning (RL) methods predominantly operate in a batch-constrained setting. This confines the algorithms to a specific state-action distribution present in the dataset, reducing the effects of distributional shift but restricting the policy to seen actions. In this paper, we alleviate this limitation by introducing state-constrained offline RL, a novel framework that focuses solely on the dataset's state distribution. This approach allows the policy to take high-quality out-of-distribution actions that lead to in-distribution states, significantly enhancing learning potential. The proposed setting not only broadens the learning horizon but also improves the ability to combine different trajectories from the dataset effectively, a desirable property inherent in offline RL. Our research is underpinned by theoretical findings that pave the way for subsequent advancements in this area. Additionally, we introduce StaCQ, a deep learning algorithm that achieves state-of-the-art performance on the D4RL benchmark datasets and aligns with our theoretical propositions. StaCQ establishes a strong baseline for forthcoming explorations in this domain.",
      "authors": [
        "Charles A. Hepburn and Yue Jin and Giovanni Montana"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-23T09:50:04+00:00",
          "link": "https://arxiv.org/abs/2405.14374v1",
          "size": "281kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T18:36:30+00:00",
          "link": "https://arxiv.org/abs/2405.14374v2",
          "size": "3042kb",
          "version": "v2"
        }
      ],
      "title": "State-Constrained Offline Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.14374",
        "HTML": "https://arxiv.org/html/2405.14374v2",
        "PDF": "https://arxiv.org/pdf/2405.14374"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on state-constrained offline reinforcement learning and introduces a novel RL framework. It is not related to LLM training data processing."
      },
      "tasks": [
        "D4RL",
        "reinforcement-learning",
        "Reinforcement Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.16790",
      "abstract": "Graph Neural Networks (GNNs) often suffer from performance degradation as the network depth increases. This paper addresses this issue by introducing initialization methods that enhance signal propagation (SP) within GNNs. We propose three key metrics for effective SP in GNNs: forward propagation, backward propagation, and graph embedding variation (GEV). While the first two metrics derive from classical SP theory, the third is specifically designed for GNNs. We theoretically demonstrate that a broad range of commonly used initialization methods for GNNs, which exhibit performance degradation with increasing depth, fail to control these three metrics simultaneously. To deal with this limitation, a direct exploitation of the SP analysis--searching for weight initialization variances that optimize the three metrics--is shown to significantly enhance the SP in deep GCNs. This approach is called Signal Propagation on Graph-guided Initialization (SPoGInit). Our experiments demonstrate that SPoGInit outperforms commonly used initialization methods on various tasks and architectures. Notably, SPoGInit enables performance improvements as GNNs deepen, which represents a significant advancement in addressing depth-related challenges and highlights the validity and effectiveness of the SP analysis framework.",
      "authors": [
        "Senmiao Wang",
        "Yupeng Chen",
        "Yushun Zhang",
        "Ruoyu Sun",
        "Tian Ding"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T07:14:31+00:00",
          "link": "https://arxiv.org/abs/2506.16790v1",
          "size": "3479kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T05:21:45+00:00",
          "link": "https://arxiv.org/abs/2506.16790v2",
          "size": "1739kb",
          "version": "v2"
        }
      ],
      "title": "Exploring and Improving Initialization for Deep Graph Neural Networks: A Signal Propagation Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16790",
        "HTML": "https://arxiv.org/html/2506.16790v2",
        "PDF": "https://arxiv.org/pdf/2506.16790"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses initialization methods for improving signal propagation in graph neural networks, which does not pertain to LLM training data processing or data engineering."
      },
      "tasks": [
        "Graph Embedding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10694",
      "abstract": "Passive deformation due to compliance is a commonly used benefit of soft robots, providing opportunities to achieve robust actuation with few active degrees of freedom. Soft growing robots in particular have shown promise in navigation of unstructured environments due to their passive deformation. If their collisions and subsequent deformations can be better understood, soft robots could be used to understand the structure of the environment from direct tactile measurements. In this work, we propose the use of soft growing robots as mapping and exploration tools. We do this by first characterizing collision behavior during discrete turns, then leveraging this model to develop a geometry-based simulator that models robot trajectories in 2D environments. Finally, we demonstrate the model and simulator validity by mapping unknown environments using Monte Carlo sampling to estimate the optimal next deployment given current knowledge. Over both uniform and non-uniform environments, this selection method rapidly approaches ideal actions, showing the potential for soft growing robots in unstructured environment exploration and mapping.",
      "authors": [
        "Francesco Fuentes",
        "Serigne Diagne",
        "Zachary Kingston",
        "Laura H. Blumenschein"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:07:44+00:00",
          "link": "https://arxiv.org/abs/2507.10694v1",
          "size": "30494kb",
          "version": "v1"
        }
      ],
      "title": "Exteroception through Proprioception Sensing through Improved Contact Modeling for Soft Growing Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10694",
        "HTML": "https://arxiv.org/html/2507.10694v1",
        "PDF": "https://arxiv.org/pdf/2507.10694"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on soft growing robots as tools for mapping and exploration, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11274",
      "abstract": "We study population convergence guarantees of stochastic gradient descent (SGD) for smooth convex objectives in the interpolation regime, where the noise at optimum is zero or near zero. The behavior of the last iterate of SGD in this setting -- particularly with large (constant) stepsizes -- has received growing attention in recent years due to implications for the training of over-parameterized models, as well as to analyzing forgetting in continual learning and to understanding the convergence of the randomized Kaczmarz method for solving linear systems. We establish that after $T$ steps of SGD on $\\beta$-smooth convex loss functions with stepsize $\\eta \\leq 1/\\beta$, the last iterate exhibits expected excess risk $\\widetilde{O}(1/(\\eta T^{1-\\beta\\eta/2}) + \\eta T^{\\beta\\eta/2} \\sigma_\\star^2)$, where $\\sigma_\\star^2$ denotes the variance of the stochastic gradients at the optimum. In particular, for a well-tuned stepsize we obtain a near optimal $\\widetilde{O}(1/T + \\sigma_\\star/\\sqrt{T})$ rate for the last iterate, extending the results of Varre et al. (2021) beyond least squares regression; and when $\\sigma_\\star=0$ we obtain a rate of $O(1/\\sqrt{T})$ with $\\eta=1/\\beta$, improving upon the best-known $O(T^{-1/4})$ rate recently established by Evron et al. (2025) in the special case of realizable linear regression.",
      "authors": [
        "Amit Attia",
        "Matan Schliserman",
        "Uri Sherman",
        "Tomer Koren"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:52:47+00:00",
          "link": "https://arxiv.org/abs/2507.11274v1",
          "size": "34kb",
          "version": "v1"
        }
      ],
      "title": "Fast Last-Iterate Convergence of SGD in the Smooth Interpolation Regime",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11274",
        "PDF": "https://arxiv.org/pdf/2507.11274"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses statistical convergence properties of SGD in smooth convex regimes without any focus on LLM training data processing or data engineering practices."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18629",
      "abstract": "Equivariant models leverage prior knowledge on symmetries to improve predictive performance, but misspecified architectural constraints can harm it instead. While work has explored learning or relaxing constraints, selecting among pretrained models with varying symmetry biases remains challenging. We examine this model selection task from an uncertainty-aware perspective, comparing frequentist (via Conformal Prediction), Bayesian (via the marginal likelihood), and calibration-based measures to naive error-based evaluation. We find that uncertainty metrics generally align with predictive performance, but Bayesian model evidence does so inconsistently. We attribute this to a mismatch in Bayesian and geometric notions of model complexity for the employed last-layer Laplace approximation, and discuss possible remedies. Our findings point towards the potential of uncertainty in guiding symmetry-aware model selection.",
      "authors": [
        "Putri A. van der Linden",
        "Alexander Timans",
        "Dharmesh Tailor",
        "Erik J. Bekkers"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T13:35:06+00:00",
          "link": "https://arxiv.org/abs/2506.18629v1",
          "size": "1749kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T11:52:41+00:00",
          "link": "https://arxiv.org/abs/2506.18629v2",
          "size": "1750kb",
          "version": "v2"
        }
      ],
      "title": "On Equivariant Model Selection through the Lens of Uncertainty",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18629",
        "HTML": "https://arxiv.org/html/2506.18629v2",
        "PDF": "https://arxiv.org/pdf/2506.18629"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses model selection based on uncertainty metrics in equivariant models, without any aspect of LLM-specific training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11202",
      "abstract": "Multimodal Emotion Recognition (MER) often encounters incomplete multimodality in practical applications due to sensor failures or privacy protection requirements. While existing methods attempt to address various incomplete multimodal scenarios by balancing the training of each modality combination through additional gradients, these approaches face a critical limitation: training gradients from different modality combinations conflict with each other, ultimately degrading the performance of the final prediction model. In this paper, we propose a unimodal decoupled dynamic low-rank adaptation method based on modality combinations, named MCULoRA, which is a novel framework for the parameter-efficient training of incomplete multimodal learning models. MCULoRA consists of two key modules, modality combination aware low-rank adaptation (MCLA) and dynamic parameter fine-tuning (DPFT). The MCLA module effectively decouples the shared information from the distinct characteristics of individual modality combinations. The DPFT module adjusts the training ratio of modality combinations based on the separability of each modality's representation space, optimizing the learning efficiency across different modality combinations. Our extensive experimental evaluation in multiple benchmark datasets demonstrates that MCULoRA substantially outperforms previous incomplete multimodal learning approaches in downstream task accuracy.",
      "authors": [
        "Xinkui Zhao",
        "Jinsong Shu",
        "Yangyang Wu",
        "Guanjie Cheng",
        "Zihe Liu",
        "Naibo Wang",
        "Shuiguang Deng",
        "Zhongle Xie",
        "Jianwei Yin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T11:15:35+00:00",
          "link": "https://arxiv.org/abs/2507.11202v1",
          "size": "1659kb",
          "version": "v1"
        }
      ],
      "title": "A Robust Incomplete Multimodal Low-Rank Adaptation Approach for Emotion Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11202",
        "HTML": "https://arxiv.org/html/2507.11202v1",
        "PDF": "https://arxiv.org/pdf/2507.11202"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces a method for multimodal emotion recognition with incomplete data but does not tackle LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.00166",
      "abstract": "In the fields of affective computing (AC) and brain-machine interface (BMI), the analysis of physiological and behavioral signals to discern individual emotional states has emerged as a critical research frontier. While deep learning-based approaches have made notable strides in EEG emotion recognition, particularly in feature extraction and pattern recognition, significant challenges persist in achieving end-to-end emotion computation, including real-time processing, individual adaptation, and seamless user interaction. This paper presents the EEG Emotion Copilot, a system optimizing a lightweight large language model (LLM) with 0.5B parameters operating in a local setting, which first recognizes emotional states directly from EEG signals, subsequently generates personalized diagnostic and treatment suggestions, and finally supports the automation of assisted electronic medical records. Specifically, we demonstrate the critical techniques in the novel data structure of prompt, model pruning and fine-tuning training, and deployment strategies aiming at improving real-time performance and computational efficiency. Extensive experiments show that our optimized lightweight LLM-based copilot achieves an enhanced intuitive interface for participant interaction, superior accuracy of emotion recognition and assisted electronic medical records generation, in comparison to such models with similar scale parameters or large-scale parameters such as 1.5B, 1.8B, 3B and 7B. In summary, through these efforts, the proposed copilot is expected to advance the application of AC in the medical domain, offering innovative solution to mental health monitoring. The codes will be released at https://github.com/NZWANG/EEG_Emotion_Copilot.",
      "authors": [
        "Hongyu Chen",
        "Weiming Zeng",
        "Chengcheng Chen",
        "Luhui Cai",
        "Fei Wang",
        "Yuhu Shi",
        "Lei Wang",
        "Wei Zhang",
        "Yueyang Li",
        "Hongjie Yan",
        "Wai Ting Siok and Nizhuan Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-30T19:15:05+00:00",
          "link": "https://arxiv.org/abs/2410.00166v1",
          "size": "10135kb",
          "version": "v1"
        },
        {
          "date": "2025-01-07T03:21:43+00:00",
          "link": "https://arxiv.org/abs/2410.00166v2",
          "size": "12974kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T13:11:26+00:00",
          "link": "https://arxiv.org/abs/2410.00166v3",
          "size": "15612kb",
          "version": "v3"
        }
      ],
      "title": "EEG Emotion Copilot: Optimizing Lightweight LLMs for Emotional EEG Interpretation with Assisted Medical Record Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.00166",
        "HTML": "https://arxiv.org/html/2410.00166v3",
        "PDF": "https://arxiv.org/pdf/2410.00166"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses optimizing an LLM for EEG interpretation, the focus is on model performance and deployment rather than on LLM training data processing."
      },
      "tasks": [
        "Computational Efficiency",
        "Diagnostic",
        "EEG",
        "EEG Emotion Recognition",
        "Emotion Recognition",
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10995",
      "abstract": "Reward functions, learned or manually specified, are rarely perfect. Instead of accurately expressing human goals, these reward functions are often distorted by human beliefs about how best to achieve those goals. Specifically, these reward functions often express a combination of the human's terminal goals -- those which are ends in themselves -- and the human's instrumental goals -- those which are means to an end. We formulate a simple example in which even slight conflation of instrumental and terminal goals results in severe misalignment: optimizing the misspecified reward function results in poor performance when measured by the true reward function. This example distills the essential properties of environments that make reinforcement learning highly sensitive to conflation of instrumental and terminal goals. We discuss how this issue can arise with a common approach to reward learning and how it can manifest in real environments.",
      "authors": [
        "Henrik Marklund",
        "Alex Infanger",
        "Benjamin Van Roy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T05:27:51+00:00",
          "link": "https://arxiv.org/abs/2507.10995v1",
          "size": "286kb",
          "version": "v1"
        }
      ],
      "title": "Misalignment from Treating Means as Ends",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10995",
        "HTML": "https://arxiv.org/html/2507.10995v1",
        "PDF": "https://arxiv.org/pdf/2507.10995"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses reward function alignment issues in reinforcement learning, without any focus on LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00236",
      "abstract": "Simulation-based design, optimization, and validation of autonomous driving algorithms have proven to be crucial for their improvement over the years. Nevertheless, the ultimate measure of effectiveness is their successful transition from simulation to reality (sim2real). However, existing sim2real transfer methods struggle to address the autonomy-oriented requirements of balancing: (i) conditioned domain adaptation, (ii) robust performance with limited examples, (iii) modularity in handling multiple domain representations, and (iv) real-time performance. To alleviate these pain points, we present a unified framework for learning cross-domain adaptive representations through conditional latent diffusion for sim2real transferable autonomous driving algorithms. Our framework offers options to leverage: (i) alternate foundation models, (ii) a few-shot fine-tuning pipeline, and (iii) textual as well as image prompts for mapping across given source and target domains. It is also capable of generating diverse high-quality samples when diffusing across parameter spaces such as times of day, weather conditions, seasons, and operational design domains. We systematically analyze the presented framework and report our findings in terms of performance benchmarks and ablation studies, with critical quantitative metrics as well as insightful qualitative examples and remarks. Additionally, we demonstrate the serviceability of sim2real diffusion for autonomous driving using a behavioral cloning case study. Our experiments indicate that the proposed framework is capable of bridging the perceptual sim2real gap by over 40%, which highlights the potential of diffusion models in sim2real transfer.",
      "authors": [
        "Chinmay Vilas Samak",
        "Tanmay Vilas Samak",
        "Bing Li",
        "Venkat Krovi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T20:07:35+00:00",
          "link": "https://arxiv.org/abs/2507.00236v1",
          "size": "6011kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T04:11:30+00:00",
          "link": "https://arxiv.org/abs/2507.00236v2",
          "size": "6011kb",
          "version": "v2"
        }
      ],
      "title": "Sim2Real Diffusion: Learning Cross-Domain Adaptive Representations for Transferable Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00236",
        "HTML": "https://arxiv.org/html/2507.00236v2",
        "PDF": "https://arxiv.org/pdf/2507.00236"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper explores sim2real transfer in autonomous driving using diffusion models but does not focus on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07603",
      "abstract": "This paper presents enhancements to the SAM2 framework for video object tracking task, addressing challenges such as occlusions, background clutter, and target reappearance. We introduce a hierarchical motion estimation strategy, combining lightweight linear prediction with selective non-linear refinement to improve tracking accuracy without requiring additional training. In addition, we optimize the memory bank by distinguishing long-term and short-term memory frames, enabling more reliable tracking under long-term occlusions and appearance changes. Experimental results show consistent improvements across different model scales. Our method achieves state-of-the-art performance on LaSOT and LaSOText with the large model, achieving 9.6% and 7.2% relative improvements in AUC over the original SAM2, and demonstrates even larger relative gains on smaller models, highlighting the effectiveness of our trainless, low-overhead improvements for boosting long-term tracking performance. The code is available at https://github.com/LouisFinner/HiM2SAM.",
      "authors": [
        "Ruixiang Chen",
        "Guolei Sun",
        "Yawei Li",
        "Jie Qin",
        "Luca Benini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T10:05:11+00:00",
          "link": "https://arxiv.org/abs/2507.07603v1",
          "size": "2505kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T18:18:22+00:00",
          "link": "https://arxiv.org/abs/2507.07603v2",
          "size": "2505kb",
          "version": "v2"
        }
      ],
      "title": "HiM2SAM: Enhancing SAM2 with Hierarchical Motion Estimation and Memory Optimization towards Long-term Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07603",
        "HTML": "https://arxiv.org/html/2507.07603v2",
        "PDF": "https://arxiv.org/pdf/2507.07603"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Enhancements to a video tracking framework focus on motion estimation and memory optimization, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10936",
      "abstract": "State-sponsored information operations (IOs) increasingly influence global discourse on social media platforms, yet their emotional and rhetorical strategies remain inadequately characterized in scientific literature. This study presents the first comprehensive analysis of toxic language deployment within such campaigns, examining 56 million posts from over 42 thousand accounts linked to 18 distinct geopolitical entities on X/Twitter. Using Google's Perspective API, we systematically detect and quantify six categories of toxic content and analyze their distribution across national origins, linguistic structures, and engagement metrics, providing essential information regarding the underlying patterns of such operations. Our findings reveal that while toxic content constitutes only 1.53% of all posts, they are associated with disproportionately high engagement and appear to be strategically deployed in specific geopolitical contexts. Notably, toxic content originating from Russian influence operations receives significantly higher user engagement compared to influence operations from any other country in our dataset. Our code is available at https://github.com/shafin191/Toxic_IO.",
      "authors": [
        "Ashfaq Ali Shafin and Khandaker Mamun Ahmed"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T03:00:47+00:00",
          "link": "https://arxiv.org/abs/2507.10936v1",
          "size": "360kb",
          "version": "v1"
        }
      ],
      "title": "Toxicity in State Sponsored Information Operations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10936",
        "HTML": "https://arxiv.org/html/2507.10936v1",
        "PDF": "https://arxiv.org/pdf/2507.10936"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes toxic language in state-sponsored information operations on social media, without focusing on training data processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10943",
      "abstract": "The latest developments in Face Restoration have yielded significant advancements in visual quality through the utilization of diverse diffusion priors. Nevertheless, the uncertainty of face identity introduced by identity-obscure inputs and stochastic generative processes remains unresolved. To address this challenge, we present Robust ID-Specific Face Restoration (RIDFR), a novel ID-specific face restoration framework based on diffusion models. Specifically, RIDFR leverages a pre-trained diffusion model in conjunction with two parallel conditioning modules. The Content Injection Module inputs the severely degraded image, while the Identity Injection Module integrates the specific identity from a given image. Subsequently, RIDFR incorporates Alignment Learning, which aligns the restoration results from multiple references with the same identity in order to suppress the interference of ID-irrelevant face semantics (e.g. pose, expression, make-up, hair style). Experiments demonstrate that our framework outperforms the state-of-the-art methods, reconstructing high-quality ID-specific results with high identity fidelity and demonstrating strong robustness.",
      "authors": [
        "Yushun Fang",
        "Lu Liu",
        "Xiang Gao",
        "Qiang Hu",
        "Ning Cao",
        "Jianghe Cui",
        "Gang Chen",
        "Xiaoyun Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T03:16:12+00:00",
          "link": "https://arxiv.org/abs/2507.10943v1",
          "size": "8776kb",
          "version": "v1"
        }
      ],
      "title": "Robust ID-Specific Face Restoration via Alignment Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10943",
        "PDF": "https://arxiv.org/pdf/2507.10943"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper describes a framework for ID-specific face restoration using diffusion models, which does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.23022",
      "abstract": "Automatically synthesizing dense rewards from natural language descriptions is a promising paradigm in reinforcement learning (RL), with applications to sparse reward problems, open-ended exploration, and hierarchical skill design. Recent works have made promising steps by exploiting the prior knowledge of large language models (LLMs). However, these approaches suffer from important limitations: they are either not scalable to problems requiring billions of environment samples, due to requiring LLM annotations for each observation, or they require a diverse offline dataset, which may not exist or be impossible to collect. In this work, we address these limitations through a combination of algorithmic and systems-level contributions. We propose ONI, a distributed architecture that simultaneously learns an RL policy and an intrinsic reward function using LLM feedback. Our approach annotates the agent's collected experience via an asynchronous LLM server, which is then distilled into an intrinsic reward model. We explore a range of algorithmic choices for reward modeling with varying complexity, including hashing, classification, and ranking models. Our approach achieves state-of-the-art performance across a range of challenging tasks from the NetHack Learning Environment, while removing the need for large offline datasets required by prior work. We make our code available at https://github.com/facebookresearch/oni .",
      "authors": [
        "Qinqing Zheng",
        "Mikael Henaff",
        "Amy Zhang",
        "Aditya Grover",
        "Brandon Amos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-30T13:52:43+00:00",
          "link": "https://arxiv.org/abs/2410.23022v1",
          "size": "16729kb",
          "version": "v1"
        },
        {
          "date": "2024-12-17T22:29:46+00:00",
          "link": "https://arxiv.org/abs/2410.23022v2",
          "size": "18612kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T05:15:18+00:00",
          "link": "https://arxiv.org/abs/2410.23022v3",
          "size": "18434kb",
          "version": "v3"
        }
      ],
      "title": "Online Intrinsic Rewards for Decision Making Agents from Large Language Model Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.23022",
        "HTML": "https://arxiv.org/html/2410.23022v3",
        "PDF": "https://arxiv.org/pdf/2410.23022"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about synthesizing dense rewards in reinforcement learning using large language models, but does not focus on training data processing for LLMs."
      },
      "tasks": [
        "Decision Making",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "NetHack",
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/facebookresearch/oni"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.02962",
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks, while they remain prone to generating hallucinated or outdated responses due to their static internal knowledge. Recent advancements in Retrieval-Augmented Generation (RAG) methods have explored enhancing models' search and reasoning capabilities through reinforcement learning (RL). Although these methods demonstrate promising results, they face challenges in training stability and encounter issues such as substantial inference time and restricted capabilities due to the single-query mode. In this paper, we propose RAG-R1, a novel training framework designed to enable LLMs to adaptively leverage internal and external knowledge during the reasoning process. We further expand the generation and retrieval processes within the framework from single-query mode to multi-query parallelism, aimed at reducing inference time and enhancing the model's capabilities. Extensive experiments on seven question-answering benchmarks demonstrate that our method outperforms the strongest baseline by up to 13.2% and decreases inference time by 11.1%.",
      "authors": [
        "Zhiwen Tan",
        "Jiaming Huang",
        "Qintong Wu",
        "Hongxuan Zhang",
        "Chenyi Zhuang",
        "Jinjie Gu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:02:45+00:00",
          "link": "https://arxiv.org/abs/2507.02962v1",
          "size": "186kb",
          "version": "v1"
        },
        {
          "date": "2025-07-08T06:38:26+00:00",
          "link": "https://arxiv.org/abs/2507.02962v2",
          "size": "186kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T12:01:49+00:00",
          "link": "https://arxiv.org/abs/2507.02962v3",
          "size": "197kb",
          "version": "v3"
        }
      ],
      "title": "RAG-R1 : Incentivize the Search and Reasoning Capabilities of LLMs through Multi-query Parallelism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02962",
        "HTML": "https://arxiv.org/html/2507.02962v3",
        "PDF": "https://arxiv.org/pdf/2507.02962"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses a training framework (RAG-R1) that enhances LLM capabilities through multi-query parallelism, focusing more on retrieval-augmented generation techniques rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10861",
      "abstract": "Cognitive reappraisal is a key strategy in emotion regulation, involving reinterpretation of emotionally charged stimuli to alter affective responses. Despite its central role in clinical and cognitive science, real-world reappraisal interventions remain cognitively demanding, abstract, and primarily verbal. This reliance on higher-order cognitive and linguistic processes is often impaired in individuals with trauma or depression, limiting the effectiveness of standard approaches. Here, we propose a novel, visually based augmentation of cognitive reappraisal by integrating large-scale text-to-image diffusion models into the emotional regulation process. Specifically, we introduce a system in which users reinterpret emotionally negative images via spoken reappraisals, which are transformed into supportive, emotionally congruent visualizations using stable diffusion models with a fine-tuned IP-adapter. This generative transformation visually instantiates users' reappraisals while maintaining structural similarity to the original stimuli, externalizing and reinforcing regulatory intent. To test this approach, we conducted a within-subject experiment (N = 20) using a modified cognitive emotion regulation (CER) task. Participants reappraised or described aversive images from the International Affective Picture System (IAPS), with or without AI-generated visual feedback. Results show that AI-assisted reappraisal significantly reduced negative affect compared to both non-AI and control conditions. Further analyses reveal that sentiment alignment between participant reappraisals and generated images correlates with affective relief, suggesting that multimodal coherence enhances regulatory efficacy. These findings demonstrate that generative visual input can support cogitive reappraisal and open new directions at the intersection of generative AI, affective computing, and therapeutic technology.",
      "authors": [
        "Edoardo Pinzuti",
        "Oliver T\\\"uscher and Andr\\'e Ferreira Castro"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T23:28:59+00:00",
          "link": "https://arxiv.org/abs/2507.10861v1",
          "size": "6037kb",
          "version": "v1"
        }
      ],
      "title": "Visually grounded emotion regulation via diffusion models and user-driven reappraisal",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10861",
        "HTML": "https://arxiv.org/html/2507.10861v1",
        "PDF": "https://arxiv.org/pdf/2507.10861"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper integrates text-to-image diffusion models for visual emotion regulation and does not involve any discussion related to LLM training data processing or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10965",
      "abstract": "Motivated by the convolutive behavior of the counting function for partitions with designated summands in which all parts are odd, we consider coefficient sequences $(a_n)_{n\\ge 0}$ of primitive eta-products that satisfy the generic convolutive property\n  \\begin{align*}\n  \\sum_{n\\ge 0} a_{mn} q^n = \\left(\\sum_{n\\ge 0} a_n q^n\\right)^m\n  \\end{align*}\n  for a specific positive integer $m$. Given the results of an exhaustive search of the Online Encyclopedia of Integer Sequences for such sequences for $m$ up to $6$, we first focus on the case where $m=2$ with our attention mainly paid to the combinatorics of two $2$-convolutive sequences, featuring bijective proofs for both. For other $2$-convolutive sequences discovered in the OEIS, we apply generating function manipulations to show their convolutivity. We also give two examples of $3$-convolutive sequences. Finally, we discuss other convolutive series that are not eta-products.",
      "authors": [
        "Shane Chern",
        "Dennis Eichhorn",
        "Shishuo Fu",
        "and James A. Sellers"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)",
        "Number Theory (math.NT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T04:05:55+00:00",
          "link": "https://arxiv.org/abs/2507.10965v1",
          "size": "16kb",
          "version": "v1"
        }
      ],
      "title": "Convolutive sequences, I: Through the lens of integer partition functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10965",
        "HTML": "https://arxiv.org/html/2507.10965v1",
        "PDF": "https://arxiv.org/pdf/2507.10965"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines convolutive sequences in mathematics, with no relevant content on LLM training data processing or dataset handling."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10643",
      "abstract": "Existing post-hoc model-agnostic methods generate external explanations for opaque models, primarily by locally attributing the model output to its input features. However, they often lack an explicit and systematic framework for quantifying the contribution of individual features. Building on the Taylor expansion framework introduced by Deng et al. (2024) to unify existing local attribution methods, we propose a rigorous set of postulates -- \"precision\", \"federation\", and \"zero-discrepancy\" -- to govern Taylor term-specific attribution. Guided by these postulates, we introduce TaylorPODA (Taylor expansion-derived imPortance-Order aDapted Attribution), which incorporates an additional \"adaptation\" property. This property enables alignment with task-specific goals, especially in post-hoc settings lacking ground-truth explanations. Empirical evaluations demonstrate that TaylorPODA achieves competitive results against baseline methods, providing principled and visualization-friendly explanations. This work represents a step toward the trustworthy deployment of opaque models by offering explanations with stronger theoretical grounding.",
      "authors": [
        "Yuchi Tang",
        "I\\~naki Esnaola",
        "Suzanne Mason",
        "George Panoutsos"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:38:30+00:00",
          "link": "https://arxiv.org/abs/2507.10643v1",
          "size": "2892kb",
          "version": "v1"
        }
      ],
      "title": "TaylorPODA: A Taylor Expansion-Based Method to Improve Post-Hoc Attributions for Opaque Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10643",
        "HTML": "https://arxiv.org/html/2507.10643v1",
        "PDF": "https://arxiv.org/pdf/2507.10643"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on a method to improve post-hoc attributions for opaque models, not on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11136",
      "abstract": "Tensor Network (TN) Kernel Machines speed up model learning by representing parameters as low-rank TNs, reducing computation and memory use. However, most TN-based Kernel methods are deterministic and ignore parameter uncertainty. Further, they require manual tuning of model complexity hyperparameters like tensor rank and feature dimensions, often through trial-and-error or computationally costly methods like cross-validation. We propose Bayesian Tensor Network Kernel Machines, a fully probabilistic framework that uses sparsity-inducing hierarchical priors on TN factors to automatically infer model complexity. This enables automatic inference of tensor rank and feature dimensions, while also identifying the most relevant features for prediction, thereby enhancing model interpretability. All the model parameters and hyperparameters are treated as latent variables with corresponding priors. Given the Bayesian approach and latent variable dependencies, we apply a mean-field variational inference to approximate their posteriors. We show that applying a mean-field approximation to TN factors yields a Bayesian ALS algorithm with the same computational complexity as its deterministic counterpart, enabling uncertainty quantification at no extra computational cost. Experiments on synthetic and real-world datasets demonstrate the superior performance of our model in prediction accuracy, uncertainty quantification, interpretability, and scalability.",
      "authors": [
        "Afra Kilic and Kim Batselier"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:37:49+00:00",
          "link": "https://arxiv.org/abs/2507.11136v1",
          "size": "88kb",
          "version": "v1"
        }
      ],
      "title": "Interpretable Bayesian Tensor Network Kernel Machines with Automatic Rank and Feature Selection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11136",
        "HTML": "https://arxiv.org/html/2507.11136v1",
        "PDF": "https://arxiv.org/pdf/2507.11136"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper introduces Bayesian Tensor Network Kernel Machines for prediction tasks and does not involve LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.08979",
      "abstract": "Reinforcement learning (RL) is rapidly reaching and surpassing human-level control capabilities. However, state-of-the-art RL algorithms often require timesteps and reaction times significantly faster than human capabilities, which is impractical in real-world settings and typically necessitates specialized hardware. We introduce Sequence Reinforcement Learning (SRL), an RL algorithm designed to produce a sequence of actions for a given input state, enabling effective control at lower decision frequencies. SRL addresses the challenges of learning action sequences by employing both a model and an actor-critic architecture operating at different temporal scales. We propose a \"temporal recall\" mechanism, where the critic uses the model to estimate intermediate states between primitive actions, providing a learning signal for each individual action within the sequence. Once training is complete, the actor can generate action sequences independently of the model, achieving model-free control at a slower frequency. We evaluate SRL on a suite of continuous control tasks, demonstrating that it achieves performance comparable to state-of-the-art algorithms while significantly reducing actor sample complexity. To better assess performance across varying decision frequencies, we introduce the Frequency-Averaged Score (FAS) metric. Our results show that SRL significantly outperforms traditional RL algorithms in terms of FAS, making it particularly suitable for applications requiring variable decision frequencies. Furthermore, we compare SRL with model-based online planning, showing that SRL achieves comparable FAS while leveraging the same model during training that online planners use for planning.",
      "authors": [
        "Devdhar Patel",
        "Hava Siegelmann"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-11T16:54:07+00:00",
          "link": "https://arxiv.org/abs/2410.08979v1",
          "size": "5602kb",
          "version": "v1"
        },
        {
          "date": "2024-10-18T14:35:53+00:00",
          "link": "https://arxiv.org/abs/2410.08979v2",
          "size": "5602kb",
          "version": "v2"
        },
        {
          "date": "2025-03-04T03:11:25+00:00",
          "link": "https://arxiv.org/abs/2410.08979v3",
          "size": "13430kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T16:07:53+00:00",
          "link": "https://arxiv.org/abs/2410.08979v4",
          "size": "9753kb",
          "version": "v4"
        }
      ],
      "title": "Overcoming Slow Decision Frequencies in Continuous Control: Model-Based Sequence Reinforcement Learning for Model-Free Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08979",
        "HTML": "https://arxiv.org/html/2410.08979v4",
        "PDF": "https://arxiv.org/pdf/2410.08979"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is about reinforcement learning for continuous control and does not address any aspects of LLM training data processing."
      },
      "tasks": [
        "continuous-control",
        "Continuous Control",
        "model",
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/dee0512/Temporally-Layered-Architecture"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.10281",
      "abstract": "As large language models (LLMs) are shaping the way information is shared and accessed online, their opinions have the potential to influence a wide audience. This study examines who the LLMs view as the most prominent figures across various fields, using prompts in ten different languages to explore the influence of linguistic diversity. Our findings reveal low diversity in responses, with a small number of figures dominating recognition across languages (also known as the \"superstar effect\"). These results highlight the risk of narrowing global knowledge representation when LLMs retrieve subjective information.",
      "authors": [
        "Sofie Goethals",
        "Lauren Rhue"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-13T17:03:56+00:00",
          "link": "https://arxiv.org/abs/2412.10281v1",
          "size": "393kb",
          "version": "v1"
        }
      ],
      "title": "One world, one opinion? The superstar effect in LLM responses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.10281",
        "HTML": "https://arxiv.org/html/2412.10281",
        "PDF": "https://arxiv.org/pdf/2412.10281"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper examines the influence of LLMs' generated responses across cultures and languages but does not discuss training data processing for LLMs."
      },
      "tasks": [
        "Diversity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.09571",
      "abstract": "The field of text-to-image generation has undergone significant advancements with the introduction of diffusion models. Nevertheless, the challenge of editing real images persists, as most methods are either computationally intensive or produce poor reconstructions. This paper introduces SAGE (Self-Attention Guidance for image Editing) - a novel technique leveraging pre-trained diffusion models for image editing. SAGE builds upon the DDIM algorithm and incorporates a novel guidance mechanism utilizing the self-attention layers of the diffusion U-Net. This mechanism computes a reconstruction objective based on attention maps generated during the inverse DDIM process, enabling efficient reconstruction of unedited regions without the need to precisely reconstruct the entire input image. Thus, SAGE directly addresses the key challenges in image editing. The superiority of SAGE over other methods is demonstrated through quantitative and qualitative evaluations and confirmed by a statistically validated comprehensive user study, in which all 47 surveyed users preferred SAGE over competing methods. Additionally, SAGE ranks as the top-performing method in seven out of 10 quantitative analyses and secures second and third places in the remaining three.",
      "authors": [
        "Guillermo Gomez-Trenado",
        "Pablo Mesejo",
        "Oscar Cord\\'on",
        "St\\'ephane Lathuili\\`ere"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-14T17:15:03+00:00",
          "link": "https://arxiv.org/abs/2505.09571v1",
          "size": "15317kb",
          "version": "v1"
        }
      ],
      "title": "Don't Forget your Inverse DDIM for Image Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.09571",
        "HTML": "https://arxiv.org/html/2505.09571",
        "PDF": "https://arxiv.org/pdf/2505.09571"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses image editing using diffusion models and does not focus on processing LLM training data or data engineering for LLMs."
      },
      "tasks": [
        "Image Generation",
        "Text to Image Generation",
        "Text-to-Image Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.05412",
      "abstract": "We consider the problem of learning robust discriminative representations of causally-related latent variables. In addition to observational data, the training dataset also includes interventional data obtained through targeted interventions on some of these latent variables to learn representations robust against the resulting interventional distribution shifts. Existing approaches treat interventional data like observational data, even when the underlying causal model is known, and ignore the independence relations that arise from these interventions. Since these approaches do not fully exploit the causal relational information resulting from interventions, they learn representations that produce large disparities in predictive performance on observational and interventional data, which worsens when the number of interventional training samples is limited. In this paper, (1) we first identify a strong correlation between this performance disparity and adherence of the representations to the independence conditions induced by the interventional causal model. (2) For linear models, we derive sufficient conditions on the proportion of interventional data in the training dataset, for which enforcing interventional independence between representations corresponding to the intervened node and its non-descendants lowers the error on interventional data. Combining these insights, (3) we propose RepLIn, a training algorithm to explicitly enforce this statistical independence during interventions. We demonstrate the utility of RepLIn on a synthetic dataset and on real image and text datasets on facial attribute classification and toxicity detection, respectively. Our experiments show that RepLIn is scalable with the number of nodes in the causal graph and is suitable to improve the robust representations against interventional distribution shifts of both continuous and discrete latent variables.",
      "authors": [
        "Gautam Sreekumar and Vishnu Naresh Boddeti"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-07T18:51:20+00:00",
          "link": "https://arxiv.org/abs/2507.05412v1",
          "size": "34756kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T20:01:54+00:00",
          "link": "https://arxiv.org/abs/2507.05412v2",
          "size": "19769kb",
          "version": "v2"
        }
      ],
      "title": "Incorporating Interventional Independence Improves Robustness against Interventional Distribution Shift",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.05412",
        "PDF": "https://arxiv.org/pdf/2507.05412"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper proposes a training algorithm (RepLIn) that enhances representation learning by incorporating interventional independence, but it does not focus primarily on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10827",
      "abstract": "The SEN\\'{C}OTEN language, spoken on the Saanich peninsula of southern Vancouver Island, is in the midst of vigorous language revitalization efforts to turn the tide of language loss as a result of colonial language policies. To support these on-the-ground efforts, the community is turning to digital technology. Automatic Speech Recognition (ASR) technology holds great promise for accelerating language documentation and the creation of educational resources. However, developing ASR systems for SEN\\'{C}OTEN is challenging due to limited data and significant vocabulary variation from its polysynthetic structure and stress-driven metathesis. To address these challenges, we propose an ASR-driven documentation pipeline that leverages augmented speech data from a text-to-speech (TTS) system and cross-lingual transfer learning with Speech Foundation Models (SFMs). An n-gram language model is also incorporated via shallow fusion or n-best restoring to maximize the use of available data. Experiments on the SEN\\'{C}OTEN dataset show a word error rate (WER) of 19.34% and a character error rate (CER) of 5.09% on the test set with a 57.02% out-of-vocabulary (OOV) rate. After filtering minor cedilla-related errors, WER improves to 14.32% (26.48% on unseen words) and CER to 3.45%, demonstrating the potential of our ASR-driven pipeline to support SEN\\'{C}OTEN language documentation.",
      "authors": [
        "Mengzhe Geng",
        "Patrick Littell",
        "Aidan Pine",
        "PEN\\'A\\'C",
        "Marc Tessier",
        "Roland Kuhn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T21:44:35+00:00",
          "link": "https://arxiv.org/abs/2507.10827v1",
          "size": "9287kb",
          "version": "v1"
        }
      ],
      "title": "Supporting SEN\\'{C}OTEN Language Documentation Efforts with Automatic Speech Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10827",
        "HTML": "https://arxiv.org/html/2507.10827v1",
        "PDF": "https://arxiv.org/pdf/2507.10827"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper describes an ASR-driven documentation pipeline using augmented data and cross-lingual transfer learning, which involves significant technical contributions to data processing for language model training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11064",
      "abstract": "Reducing feedback overhead in beyond 5G networks is a critical challenge, as the growing number of antennas in modern massive MIMO systems substantially increases the channel state information (CSI) feedback demand in frequency division duplex (FDD) systems. To address this, extensive research has focused on CSI compression and prediction, with neural network-based approaches gaining momentum and being considered for integration into the 3GPP 5G-Advanced standards. While deep learning has been effectively applied to CSI-limited beamforming and handover optimization, reference signal allocation under such constraints remains surprisingly underexplored. To fill this gap, we introduce the concept of channel prediction-based reference signal allocation (CPRS), which jointly optimizes channel prediction and DM-RS allocation to improve data throughput without requiring CSI feedback. We further propose a standards-compliant ViViT/CNN-based architecture that implements CPRS by treating evolving CSI matrices as sequential image-like data, enabling efficient and adaptive transmission in dynamic environments. Simulation results using ray-tracing channel data generated in NVIDIA Sionna validate the proposed method, showing up to 36.60% throughput improvement over benchmark strategies.",
      "authors": [
        "Sehyun Ryu and Hyun Jong Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T07:56:37+00:00",
          "link": "https://arxiv.org/abs/2507.11064v1",
          "size": "555kb",
          "version": "v1"
        }
      ],
      "title": "Standards-Compliant DM-RS Allocation via Temporal Channel Prediction for Massive MIMO Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11064",
        "HTML": "https://arxiv.org/html/2507.11064v1",
        "PDF": "https://arxiv.org/pdf/2507.11064"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper primarily addresses channel prediction in MIMO systems and does not pertain to LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11083",
      "abstract": "Large language models (LLMs) have made significant strides in code translation tasks. However, ensuring both the correctness and readability of translated code remains a challenge, limiting their effective adoption in real-world software development. In this work, we propose F2STrans, a function-to-style guiding paradigm designed to progressively improve the performance of LLMs in code translation. Our approach comprises two key stages: (1) Functional learning, which optimizes translation correctness using high-quality source-target code pairs mined from online programming platforms, and (2) Style learning, which improves translation readability by incorporating both positive and negative style examples. Additionally, we introduce a novel code translation benchmark that includes up-to-date source code, extensive test cases, and manually annotated ground-truth translations, enabling comprehensive functional and stylistic evaluations. Experiments on both our new benchmark and existing datasets demonstrate that our approach significantly improves code translation performance. Notably, our approach enables Qwen-1.5B to outperform prompt-enhanced Qwen-32B and GPT-4 on average across 20 diverse code translation scenarios.",
      "authors": [
        "Longhui Zhang",
        "Bin Wang",
        "Jiahao Wang",
        "Xiaofeng Zhao",
        "Min Zhang",
        "Hao Yang",
        "Meishan Zhang",
        "Yu Li",
        "Jing Li",
        "Jun Yu",
        "Min Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:25:02+00:00",
          "link": "https://arxiv.org/abs/2507.11083v1",
          "size": "983kb",
          "version": "v1"
        }
      ],
      "title": "Function-to-Style Guidance of LLMs for Code Translation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11083",
        "PDF": "https://arxiv.org/pdf/2507.11083"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper introduces a new code translation benchmark, it primarily focuses on improving code translation using high-quality source-target code pairs, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.17755",
      "abstract": "This paper addresses a challenging interactive task learning scenario we call rearrangement under unawareness: an agent must manipulate a rigid-body environment without knowing a key concept necessary for solving the task and must learn about it during deployment. For example, the user may ask to \"put the two granny smith apples inside the basket\", but the agent cannot correctly identify which objects in the environment are \"granny smith\" as the agent has not been exposed to such a concept before. We introduce SECURE, an interactive task learning policy designed to tackle such scenarios. The unique feature of SECURE is its ability to enable agents to engage in semantic analysis when processing embodied conversations and making decisions. Through embodied conversation, a SECURE agent adjusts its deficient domain model by engaging in dialogue to identify and learn about previously unforeseen possibilities. The SECURE agent learns from the user's embodied corrective feedback when mistakes are made and strategically engages in dialogue to uncover useful information about novel concepts relevant to the task. These capabilities enable the SECURE agent to generalize to new tasks with the acquired knowledge. We demonstrate in the simulated Blocksworld and the real-world apple manipulation environments that the SECURE agent, which solves such rearrangements under unawareness, is more data-efficient than agents that do not engage in embodied conversation or semantic analysis.",
      "authors": [
        "Rimvydas Rubavicius",
        "Peter David Fagan",
        "Alex Lascarides",
        "Subramanian Ramamoorthy"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-26T11:40:07+00:00",
          "link": "https://arxiv.org/abs/2409.17755v1",
          "size": "23769kb",
          "version": "v1"
        },
        {
          "date": "2025-02-10T18:39:13+00:00",
          "link": "https://arxiv.org/abs/2409.17755v2",
          "size": "35256kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T10:13:18+00:00",
          "link": "https://arxiv.org/abs/2409.17755v3",
          "size": "35135kb",
          "version": "v3"
        }
      ],
      "title": "SECURE: Semantics-aware Embodied Conversation under Unawareness for Lifelong Robot Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.17755",
        "HTML": "https://arxiv.org/html/2409.17755v3",
        "PDF": "https://arxiv.org/pdf/2409.17755"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses an interactive task learning scenario for agents but does not involve the processing or engineering of LLM training data."
      },
      "tasks": [
        "Novel Concepts",
        "Sentence"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.12633",
      "abstract": "Traditional approaches to studying decision-making in neuroscience focus on simplified behavioral tasks where animals perform repetitive, stereotyped actions to receive explicit rewards. While informative, these methods constrain our understanding of decision-making to short timescale behaviors driven by explicit goals. In natural environments, animals exhibit more complex, long-term behaviors driven by intrinsic motivations that are often unobservable. Recent works in time-varying inverse reinforcement learning (IRL) aim to capture shifting motivations in long-term, freely moving behaviors. However, a crucial challenge remains: animals make decisions based on their history, not just their current state. To address this, we introduce SWIRL (SWitching IRL), a novel framework that extends traditional IRL by incorporating time-varying, history-dependent reward functions. SWIRL models long behavioral sequences as transitions between short-term decision-making processes, each governed by a unique reward function. SWIRL incorporates biologically plausible history dependency to capture how past decisions and environmental contexts shape behavior, offering a more accurate description of animal decision-making. We apply SWIRL to simulated and real-world animal behavior datasets and show that it outperforms models lacking history dependency, both quantitatively and qualitatively. This work presents the first IRL model to incorporate history-dependent policies and rewards to advance our understanding of complex, naturalistic decision-making in animals.",
      "authors": [
        "Jingyang Ke",
        "Feiyang Wu",
        "Jiyi Wang",
        "Jeffrey Markowitz and Anqi Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-22T04:38:33+00:00",
          "link": "https://arxiv.org/abs/2501.12633v1",
          "size": "10300kb",
          "version": "v1"
        },
        {
          "date": "2025-06-03T17:35:00+00:00",
          "link": "https://arxiv.org/abs/2501.12633v2",
          "size": "8871kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T15:08:23+00:00",
          "link": "https://arxiv.org/abs/2501.12633v3",
          "size": "8454kb",
          "version": "v3"
        }
      ],
      "title": "Inverse Reinforcement Learning with Switching Rewards and History Dependency for Characterizing Animal Behaviors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.12633",
        "HTML": "https://arxiv.org/html/2501.12633v3",
        "PDF": "https://arxiv.org/pdf/2501.12633"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses inverse reinforcement learning for characterizing animal behavior without any focus on LLM training data processing or data engineering methods."
      },
      "tasks": [
        "Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10776",
      "abstract": "Successful execution of dexterous robotic manipulation tasks in new environments, such as grasping, depends on the ability to proficiently segment unseen objects from the background and other objects. Previous works in unseen object instance segmentation (UOIS) train models on large-scale datasets, which often leads to overfitting on static visual features. This dependency results in poor generalization performance when confronted with out-of-distribution scenarios. To address this limitation, we rethink the task of UOIS based on the principle that vision is inherently interactive and occurs over time. We propose a novel real-time interactive perception framework, rt-RISeg, that continuously segments unseen objects by robot interactions and analysis of a designed body frame-invariant feature (BFIF). We demonstrate that the relative rotational and linear velocities of randomly sampled body frames, resulting from selected robot interactions, can be used to identify objects without any learned segmentation model. This fully self-contained segmentation pipeline generates and updates object segmentation masks throughout each robot interaction without the need to wait for an action to finish. We showcase the effectiveness of our proposed interactive perception method by achieving an average object segmentation accuracy rate 27.5% greater than state-of-the-art UOIS methods. Furthermore, although rt-RISeg is a standalone framework, we show that the autonomously generated segmentation masks can be used as prompts to vision foundation models for significantly improved performance.",
      "authors": [
        "Howard H. Qian",
        "Yiting Chen",
        "Gaotian Wang",
        "Podshara Chanrungmaneekul",
        "Kaiyu Hang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T20:02:52+00:00",
          "link": "https://arxiv.org/abs/2507.10776v1",
          "size": "1792kb",
          "version": "v1"
        }
      ],
      "title": "rt-RISeg: Real-Time Model-Free Robot Interactive Segmentation for Active Instance-Level Object Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10776",
        "HTML": "https://arxiv.org/html/2507.10776v1",
        "PDF": "https://arxiv.org/pdf/2507.10776"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a real-time interactive segmentation framework for robotics and does not address any LLM training data processing or dataset creation for language models."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11106",
      "abstract": "We present a novel mathematical optimization framework for outlier detection in multimodal datasets, extending Support Vector Data Description approaches. We provide a primal formulation, in the shape of a Mixed Integer Second Order Cone model, that constructs Euclidean hyperspheres to identify anomalous observations. Building on this, we develop a dual model that enables the application of the kernel trick, thus allowing for the detection of outliers within complex, non-linear data structures. An extensive computational study demonstrates the effectiveness of our exact method, showing clear advantages over existing heuristic techniques in terms of accuracy and robustness.",
      "authors": [
        "V\\'ictor Blanco",
        "Inmaculada Espejo",
        "Ra\\'ul P\\'aez",
        "Antonio M. Rodr\\'iguez-Ch\\'ia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:57:27+00:00",
          "link": "https://arxiv.org/abs/2507.11106v1",
          "size": "2935kb",
          "version": "v1"
        }
      ],
      "title": "A Mathematical Optimization Approach to Multisphere Support Vector Data Description",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11106",
        "HTML": "https://arxiv.org/html/2507.11106v1",
        "PDF": "https://arxiv.org/pdf/2507.11106"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a framework for outlier detection using a mathematical optimization approach, with no discussion on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11482",
      "abstract": "Three core tenets of reinforcement learning (RL)--concerning the definition of agency, the objective of learning, and the scope of the reward hypothesis--have been highlighted as key targets for conceptual revision, with major implications for theory and application. We propose a framework, inspired by open-ended evolutionary theory, to reconsider these three \"dogmas.\" We revisit each assumption and address related concerns raised alongside them. To make our arguments relevant to RL as a model of biological learning, we first establish that evolutionary dynamics can plausibly operate within living brains over an individual's lifetime, and are not confined to cross-generational processes. We begin by revisiting the second dogma, drawing on evolutionary insights to enrich the \"adaptation-rather-than-search\" view of learning. We then address the third dogma regarding the limits of the reward hypothesis, using analogies from evolutionary fitness to illuminate the scalar reward vs. multi-objective debate. After discussing practical implications for exploration in RL, we turn to the first--and arguably most fundamental--issue: the absence of a formal account of agency. We argue that unlike the other two problems, the evolutionary paradigm alone cannot resolve the agency question, though it gestures in a productive direction. We advocate integrating ideas from origins-of-life theory, where the thermodynamics of sustenance and replication offer promising foundations for understanding agency and resource-constrained reinforcement learning in biological systems.",
      "authors": [
        "Mani Hamidi",
        "Terrence W. Deacon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:53:14+00:00",
          "link": "https://arxiv.org/abs/2507.11482v1",
          "size": "93kb",
          "version": "v1"
        }
      ],
      "title": "Illuminating the Three Dogmas of Reinforcement Learning under Evolutionary Light",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11482",
        "HTML": "https://arxiv.org/html/2507.11482v1",
        "PDF": "https://arxiv.org/pdf/2507.11482"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper reconsiders core concepts in reinforcement learning using an evolutionary framework, but it does not involve LLM training data processing or data engineering techniques relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2503.21073",
      "abstract": "Researchers have recently suggested that models share common representations. In our work, we find numerous geometric similarities across the token embeddings of large language models. First, we find ``global'' similarities: token embeddings often share similar relative orientations. Next, we characterize local geometry in two ways: (1) by using Locally Linear Embeddings, and (2) by defining a simple measure for the intrinsic dimension of each embedding. Both characterizations allow us to find local similarities across token embeddings. Additionally, our intrinsic dimension demonstrates that embeddings lie on a lower dimensional manifold, and that tokens with lower intrinsic dimensions often have semantically coherent clusters, while those with higher intrinsic dimensions do not. Based on our findings, we introduce EMB2EMB, a simple application to linearly transform steering vectors from one language model to another, despite the two models having different dimensions.",
      "authors": [
        "Andrew Lee",
        "Melanie Weber",
        "Fernanda Vi\\'egas",
        "Martin Wattenberg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-27T01:17:06+00:00",
          "link": "https://arxiv.org/abs/2503.21073v1",
          "size": "158kb",
          "version": "v1"
        },
        {
          "date": "2025-04-24T02:54:29+00:00",
          "link": "https://arxiv.org/abs/2503.21073v2",
          "size": "158kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T12:15:41+00:00",
          "link": "https://arxiv.org/abs/2503.21073v3",
          "size": "187kb",
          "version": "v3"
        }
      ],
      "title": "Shared Global and Local Geometry of Language Model Embeddings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.21073",
        "HTML": "https://arxiv.org/html/2503.21073v3",
        "PDF": "https://arxiv.org/pdf/2503.21073"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper investigates geometric similarities across token embeddings in language models, without focusing on LLM training data processing or developing new datasets."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.11068",
      "abstract": "The Active Flux method is a numerical method for conservation laws using a combination of cell averages and point values, based on ideas from finite volumes and finite differences. This unusual mix has been shown to work well in many situations. We expand the theoretical justifications of the Active Flux method by analyzing it from the point of view of summation-by-parts (SBP) operators, which are routinely used to analyze finite difference, finite volume, and finite element schemes. We show that the Active Flux method can be formulated using degenerate SBP operators, yielding a first and novel approach for showing the energy stability of the Active Flux method.",
      "authors": [
        "Wasilij Barsukow",
        "Christian Klingenberg",
        "Lisa Lechner",
        "Jan Nordstr\\\"om",
        "Sigrun Ortleb",
        "Hendrik Ranocha"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:01:26+00:00",
          "link": "https://arxiv.org/abs/2507.11068v1",
          "size": "103kb",
          "version": "v1"
        }
      ],
      "title": "Stability of the Active Flux Method in the Framework of Summation-by-Parts Operators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11068",
        "HTML": "https://arxiv.org/html/2507.11068v1",
        "PDF": "https://arxiv.org/pdf/2507.11068"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with the stability of the Active Flux numerical method and does not discuss LLM training data or its processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11474",
      "abstract": "Accurate characterization of vascular geometry is essential for cardiovascular diagnosis and treatment planning. Traditional statistical shape modeling (SSM) methods rely on linear assumptions, limiting their expressivity and scalability to complex topologies such as multi-branch vascular structures. We introduce HUG-VAS, a Hierarchical NURBS Generative model for Vascular geometry Synthesis, which integrates NURBS surface parameterization with diffusion-based generative modeling to synthesize realistic, fine-grained aortic geometries. Trained with 21 patient-specific samples, HUG-VAS generates anatomically faithful aortas with supra-aortic branches, yielding biomarker distributions that closely match those of the original dataset. HUG-VAS adopts a hierarchical architecture comprising a denoising diffusion model that generates centerlines and a guided diffusion model that synthesizes radial profiles conditioned on those centerlines, thereby capturing two layers of anatomical variability. Critically, the framework supports zero-shot conditional generation from image-derived priors, enabling practical applications such as interactive semi-automatic segmentation, robust reconstruction under degraded imaging conditions, and implantable device optimization. To our knowledge, HUG-VAS is the first SSM framework to bridge image-derived priors with generative shape modeling via a unified integration of NURBS parameterization and hierarchical diffusion processes.",
      "authors": [
        "Pan Du",
        "Mingqi Xu",
        "Xiaozhi Zhu",
        "Jian-xun Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:45:43+00:00",
          "link": "https://arxiv.org/abs/2507.11474v1",
          "size": "40015kb",
          "version": "v1"
        }
      ],
      "title": "HUG-VAS: A Hierarchical NURBS-Based Generative Model for Aortic Geometry Synthesis and Controllable Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11474",
        "HTML": "https://arxiv.org/html/2507.11474v1",
        "PDF": "https://arxiv.org/pdf/2507.11474"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is centered on generative modeling for aortic geometry synthesis, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2401.04846",
      "abstract": "This paper will examine what makes a being intelligent, whether that be a biological being or an artificial silicon being on a computer. Special attention will be paid to the being having the ability to characterize and control a collective system of many identical conservative sub-systems conservatively interacting. The essence of intelligence will be found to be the golden rule -- \"the collective acts as one\" or \"knowing the global consequences of local actions\". The flow of the collective is a small set of twinkling textures, that are governed by a puppeteer who is pulling a small number of strings according to a geodesic motion of least action, determined by the symmetries. Controlling collective conservative systems is difficult and has historically been done by adding significant viscosity to the system to stabilize the desirable meta stable equilibriums of maximum performance, but it degrades or destroys them in the process. There is an alternative. Once the optimum twinkling textures of the meta stable equilibriums are identified, the collective system can be moved to the optimum twinkling textures, then quickly vibrated according to the textures so that the collective system remains at the meta stable equilibrium. Well educated intelligence knows the global consequences of its local actions so that it will not take short term actions that will lead to poor long term outcomes. In contrast, trained intelligence or trained stupidity will optimize its short term actions, leading to poor long term outcomes. Well educated intelligence is inherently good, but trained stupidity is inherently evil and should be feared. Particular attention is paid to the control and optimization of economic and social collectives. These new results are also applicable to physical collectives such as fields, fluids and plasmas.",
      "authors": [
        "Michael E. Glinsky"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-09T22:56:21+00:00",
          "link": "https://arxiv.org/abs/2401.04846v1",
          "size": "18161kb",
          "version": "v1"
        },
        {
          "date": "2024-01-14T02:12:28+00:00",
          "link": "https://arxiv.org/abs/2401.04846v2",
          "size": "18165kb",
          "version": "v2"
        },
        {
          "date": "2024-01-19T22:09:12+00:00",
          "link": "https://arxiv.org/abs/2401.04846v3",
          "size": "27833kb",
          "version": "v3"
        },
        {
          "date": "2024-02-08T17:44:15+00:00",
          "link": "https://arxiv.org/abs/2401.04846v4",
          "size": "5081kb",
          "version": "v4"
        },
        {
          "date": "2024-03-09T13:58:07+00:00",
          "link": "https://arxiv.org/abs/2401.04846v5",
          "size": "5082kb",
          "version": "v5"
        },
        {
          "date": "2024-04-18T19:01:01+00:00",
          "link": "https://arxiv.org/abs/2401.04846v6",
          "size": "5082kb",
          "version": "v6"
        },
        {
          "date": "2024-07-17T14:04:44+00:00",
          "link": "https://arxiv.org/abs/2401.04846v7",
          "size": "5774kb",
          "version": "v7"
        },
        {
          "date": "2024-10-15T15:10:57+00:00",
          "link": "https://arxiv.org/abs/2401.04846v8",
          "size": "5670kb",
          "version": "v8"
        },
        {
          "date": "2024-12-23T04:12:30+00:00",
          "link": "https://arxiv.org/abs/2401.04846v9",
          "size": "6054kb",
          "version": "v9"
        },
        {
          "date": "2025-01-28T03:19:49+00:00",
          "link": "https://arxiv.org/abs/2401.04846v10",
          "size": "6054kb",
          "version": "v10"
        },
        {
          "date": "2025-07-15T13:10:38+00:00",
          "link": "https://arxiv.org/abs/2401.04846v11",
          "size": "6055kb",
          "version": "v11"
        }
      ],
      "title": "The inherent goodness of well educated intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.04846",
        "HTML": "https://arxiv.org/html/2401.04846",
        "PDF": "https://arxiv.org/pdf/2401.04846"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses the essence of intelligence and control of collective systems, not addressing any aspect of LLM training data processing or engineering."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.10591",
      "abstract": "Feature selection is vital for building effective predictive models, as it reduces dimensionality and emphasizes key features. However, current research often suffers from limited benchmarking and reliance on proprietary datasets. This severely hinders reproducibility and can negatively impact overall performance. To address these limitations, we introduce the MH-FSF framework, a comprehensive, modular, and extensible platform designed to facilitate the reproduction and implementation of feature selection methods. Developed through collaborative research, MH-FSF provides implementations of 17 methods (11 classical, 6 domain-specific) and enables systematic evaluation on 10 publicly available Android malware datasets. Our results reveal performance variations across both balanced and imbalanced datasets, highlighting the critical need for data preprocessing and selection criteria that account for these asymmetries. We demonstrate the importance of a unified platform for comparing diverse feature selection techniques, fostering methodological consistency and rigor. By providing this framework, we aim to significantly broaden the existing literature and pave the way for new research directions in feature selection, particularly within the context of Android malware detection.",
      "authors": [
        "Vanderson Rocha and Diego Kreutz and Gabriel Canto and Hendrio Bragan\\c{c}a and Eduardo Feitosa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:53:37+00:00",
          "link": "https://arxiv.org/abs/2507.10591v1",
          "size": "88kb",
          "version": "v1"
        }
      ],
      "title": "MH-FSF: A Unified Framework for Overcoming Benchmarking and Reproducibility Limitations in Feature Selection Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10591",
        "HTML": "https://arxiv.org/html/2507.10591v1",
        "PDF": "https://arxiv.org/pdf/2507.10591"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper mentions the importance of data preprocessing in feature selection, the main contribution is about feature selection methods and benchmarking. It does not primarily focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10715",
      "abstract": "Spectroscopic anomaly detection and isotope identification algorithms are integral components in nuclear nonproliferation applications such as search operations. The task is especially challenging in the case of mobile detector systems due to the fact that the observed gamma-ray background changes more than for a static detector system, and a pretrained background model can easily find itself out of domain. The result is that algorithms may exceed their intended false alarm rate, or sacrifice detection sensitivity in order to maintain the desired false alarm rate. Non-negative matrix factorization (NMF) has been shown to be a powerful tool for spectral anomaly detection and identification, but, like many similar algorithms that rely on data-driven background models, in its conventional implementation it is unable to update in real time to account for environmental changes that affect the background spectroscopic signature. We have developed a novel NMF-based algorithm that periodically updates its background model to accommodate changing environmental conditions. The Adaptive NMF algorithm involves fewer assumptions about its environment, making it more generalizable than existing NMF-based methods while maintaining or exceeding detection performance on simulated and real-world datasets.",
      "authors": [
        "Chandler Jones",
        "Mark Bandstra",
        "Stefan Faaland",
        "Yue Shi Lai",
        "Nico Abgrall",
        "Scott Suchyta",
        "Reynold Cooper"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Applied Physics (physics.app-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:31:26+00:00",
          "link": "https://arxiv.org/abs/2507.10715v1",
          "size": "5381kb",
          "version": "v1"
        }
      ],
      "title": "Real-time, Adaptive Radiological Anomaly Detection and Isotope Identification Using Non-negative Matrix Factorization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10715",
        "HTML": "https://arxiv.org/html/2507.10715v1",
        "PDF": "https://arxiv.org/pdf/2507.10715"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses adaptive anomaly detection using non-negative matrix factorization for spectroscopic data, not LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10792",
      "abstract": "This work aims to address the problem of long-term dynamic forecasting in complex environments where data are noisy and irregularly sampled. While recent studies have introduced some methods to improve prediction performance, these approaches still face a significant challenge in handling long-term extrapolation tasks under such complex scenarios. To overcome this challenge, we propose Phy-SSM, a generalizable method that integrates partial physics knowledge into state space models (SSMs) for long-term dynamics forecasting in complex environments. Our motivation is that SSMs can effectively capture long-range dependencies in sequential data and model continuous dynamical systems, while the incorporation of physics knowledge improves generalization ability. The key challenge lies in how to seamlessly incorporate partially known physics into SSMs. To achieve this, we decompose partially known system dynamics into known and unknown state matrices, which are integrated into a Phy-SSM unit. To further enhance long-term prediction performance, we introduce a physics state regularization term to make the estimated latent states align with system dynamics. Besides, we theoretically analyze the uniqueness of the solutions for our method. Extensive experiments on three real-world applications, including vehicle motion prediction, drone state prediction, and COVID-19 epidemiology forecasting, demonstrate the superior performance of Phy-SSM over the baselines in both long-term interpolation and extrapolation tasks. The code is available at https://github.com/511205787/Phy_SSM-ICML2025.",
      "authors": [
        "Yuchen Wang",
        "Hongjue Zhao",
        "Haohong Lin",
        "Enze Xu",
        "Lifang He",
        "Huajie Shao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T20:46:12+00:00",
          "link": "https://arxiv.org/abs/2507.10792v1",
          "size": "1595kb",
          "version": "v1"
        }
      ],
      "title": "A Generalizable Physics-Enhanced State Space Model for Long-Term Dynamics Forecasting in Complex Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10792",
        "HTML": "https://arxiv.org/html/2507.10792v1",
        "PDF": "https://arxiv.org/pdf/2507.10792"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a new method for long-term dynamics forecasting using state space models with physics knowledge, which is not related to LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11403",
      "abstract": "The rapid rise of AI is poised to disrupt the labor market. However, AI is not a monolith; its impact depends on both the nature of the innovation and the jobs it affects. While computational approaches are emerging, there is no consensus on how to systematically measure an innovation's disruptive potential. Here, we calculate the disruption index of 3,237 U.S. AI patents (2015-2022) and link them to job tasks to distinguish between \"consolidating\" AI innovations that reinforce existing structures and \"disruptive\" AI innovations that alter them. Our analysis reveals that consolidating AI primarily targets physical, routine, and solo tasks, common in manufacturing and construction in the Midwest and central states. By contrast, disruptive AI affects unpredictable and mental tasks, particularly in coastal science and technology sectors. Surprisingly, we also find that disruptive AI disproportionately affects areas already facing skilled labor shortages, suggesting disruptive AI technologies may accelerate change where workers are scarce rather than replacing a surplus. Ultimately, consolidating AI appears to extend current automation trends, while disruptive AI is set to transform complex mental work, with a notable exception for collaborative tasks.",
      "authors": [
        "Munjung Kim",
        "Marios Constantinides",
        "Sanja \\v{S}\\'cepanovi\\'c",
        "Yong-Yeol Ahn",
        "Daniele Quercia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:20:09+00:00",
          "link": "https://arxiv.org/abs/2507.11403v1",
          "size": "22885kb",
          "version": "v1"
        }
      ],
      "title": "The Potential Impact of Disruptive AI Innovations on U.S. Occupations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11403",
        "HTML": "https://arxiv.org/html/2507.11403v1",
        "PDF": "https://arxiv.org/pdf/2507.11403"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper analyzes the impact of AI on occupations and jobs but does not discuss LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.09126",
      "abstract": "Traditional anomaly detection techniques onboard satellites are based on reliable, yet limited, thresholding mechanisms which are designed to monitor univariate signals and trigger recovery actions according to specific European Cooperation for Space Standardization (ECSS) standards. However, Artificial Intelligence-based Fault Detection, Isolation and Recovery (FDIR) solutions have recently raised with the prospect to overcome the limitations of these standard methods, expanding the range of detectable failures and improving response times. This paper presents a novel approach to detecting stuck values within the Accelerometer and Inertial Measurement Unit of a drone-like spacecraft for the exploration of Small Solar System Bodies (SSSB), leveraging a multi-channel Convolutional Neural Network (CNN) to perform multi-target classification and independently detect faults in the sensors. Significant attention has been dedicated to ensuring the compatibility of the algorithm within the onboard FDIR system, representing a step forward to the in-orbit validation of a technology that remains experimental until its robustness is thoroughly proven. An integration methodology is proposed to enable the network to effectively detect anomalies and trigger recovery actions at the system level. The detection performances and the capability of the algorithm in reaction triggering are evaluated employing a set of custom-defined detection and system metrics, showing the outstanding performances of the algorithm in performing its FDIR task.",
      "authors": [
        "Riccardo Gallon",
        "Fabian Schiemenz",
        "Alessandra Menicucci",
        "Eberhard Gill"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-11T09:36:38+00:00",
          "link": "https://arxiv.org/abs/2410.09126v1",
          "size": "1621kb",
          "version": "v1"
        }
      ],
      "title": "Convolutional Neural Network Design and Evaluation for Real-Time Multivariate Time Series Fault Detection in Spacecraft Attitude Sensors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.09126",
        "HTML": "https://arxiv.org/html/2410.09126",
        "PDF": "https://arxiv.org/pdf/2410.09126"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with fault detection in spacecraft sensors using CNNs and does not discuss LLM training data processing or dataset creation."
      },
      "tasks": [
        "Anomaly Detection",
        "Fault Detection",
        "Time Series"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.12824",
      "abstract": "We present a non-deterministic semantic framework for all modal logics in the modal cube, extending prior works by Kearns and others. Our approach introduces modular and uniform multi-valued non-deterministic matrices (Nmatrices) for each logic, where necessitation is captured by the systematic use of level valuations. The semantics is grounded in an eight-valued system and provides a sound and complete decision procedure for each modal logic, extending and refining earlier semantics as particular cases. Additionally, we propose a novel model-theoretic perspective that links our framework to relational (Kripke-style) semantics, addressing longstanding conjectures regarding the correspondence between modal axioms and semantic conditions within non-deterministic settings. The result is a philosophically robust and technically modular alternative to standard possible-world semantics.",
      "authors": [
        "Renato Leme",
        "Carlos Olarte",
        "Elaine Pimentel and Marcelo E. Coniglio"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T08:07:26+00:00",
          "link": "https://arxiv.org/abs/2505.12824v1",
          "size": "75kb",
          "version": "v1"
        },
        {
          "date": "2025-06-12T19:10:38+00:00",
          "link": "https://arxiv.org/abs/2505.12824v2",
          "size": "101kb",
          "version": "v2"
        },
        {
          "date": "2025-07-14T20:57:26+00:00",
          "link": "https://arxiv.org/abs/2505.12824v3",
          "size": "78kb",
          "version": "v3"
        }
      ],
      "title": "The Modal Cube Revisited: Semantics without Worlds (Technical Report)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12824",
        "HTML": "https://arxiv.org/html/2505.12824v3",
        "PDF": "https://arxiv.org/pdf/2505.12824"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper provides a semantic framework for modal logics, unrelated to LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.08053",
      "abstract": "Tree-structured Parzen estimator (TPE) is a versatile hyperparameter optimization (HPO) method supported by popular HPO tools. Since these HPO tools have been developed in line with the trend of deep learning (DL), the problem setups often used in the DL domain have been discussed for TPE such as multi-objective optimization and multi-fidelity optimization. However, the practical applications of HPO are not limited to DL, and black-box combinatorial optimization is actively utilized in some domains, e.g., chemistry and biology. As combinatorial optimization has been an untouched, yet very important, topic in TPE, we propose an efficient combinatorial optimization algorithm for TPE. In this paper, we first generalize the categorical kernel with the numerical kernel in TPE, enabling us to introduce a distance structure to the categorical kernel. Then we discuss modifications for the newly developed kernel to handle a large combinatorial search space. These modifications reduce the time complexity of the kernel calculation with respect to the size of a combinatorial search space. In the experiments using synthetic problems, we verified that our proposed method identifies better solutions with fewer evaluations than the original TPE. Our algorithm is available in Optuna, an open-source framework for HPO.",
      "authors": [
        "Kenshin Abe",
        "Yunzhuo Wang",
        "Shuhei Watanabe"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T08:26:49+00:00",
          "link": "https://arxiv.org/abs/2507.08053v1",
          "size": "276kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T08:40:16+00:00",
          "link": "https://arxiv.org/abs/2507.08053v2",
          "size": "274kb",
          "version": "v2"
        }
      ],
      "title": "Tree-Structured Parzen Estimator Can Solve Black-Box Combinatorial Optimization More Efficiently",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.08053",
        "HTML": "https://arxiv.org/html/2507.08053v2",
        "PDF": "https://arxiv.org/pdf/2507.08053"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses improvements in black-box combinatorial optimization methods using Tree-Structured Parzen Estimator (TPE), with no mention of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11172",
      "abstract": "Understanding the complex behavior of molecular systems is fundamental to fields such as physics, materials science, and biology. Molecular dynamics (MD) simulations are crucial tools for studying atomic-level dynamics. This work focuses on improving the efficiency of MD simulations involving two-body and three-body interactions. Traditional two-body potentials often can not fully capture the complexity of molecular systems, making the inclusion of three-body interactions important. However, these interactions are in a cubic complexity class, compared to a quadratic one for two-body interactions, and therefore are computationally expensive, even when a cutoff distance is applied. One way to improve efficiency is to use the r-RESPA multiple time-stepping algorithm to reduce the number of three-body interaction calculations. In this work, we investigate this method in the context of High Performance Computing (HPC) methods that parallelize the calculations. In particular, we investigate a communication-reducing distributed-memory parallel method from literature and present a novel shared-memory parallel cutoff method, implemented in the particle simulation library AutoPas. The results and methods are discussed, providing insights into potential advancements in MD simulation efficiency.",
      "authors": [
        "David Martin",
        "Samuel James Newcome",
        "Markus M\\\"uhlh\\\"au{\\ss}er",
        "Manish Kumar Mishra",
        "Fabio Alexander Gratl and Hans-Joachim Bungartz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:27:27+00:00",
          "link": "https://arxiv.org/abs/2507.11172v1",
          "size": "224kb",
          "version": "v1"
        }
      ],
      "title": "The Multiple Time-Stepping Method for 3-Body Interactions in High Performance Molecular Dynamics Simulations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11172",
        "HTML": "https://arxiv.org/html/2507.11172v1",
        "PDF": "https://arxiv.org/pdf/2507.11172"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This study focuses on improving molecular dynamics simulations' efficiency without discussing any contributions to LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11512",
      "abstract": "Mixed-precision algorithms have been proposed as a way for scientific computing to benefit from some of the gains seen for artificial intelligence (AI) on recent high performance computing (HPC) platforms. A few applications dominated by dense matrix operations have seen substantial speedups by utilizing low precision formats such as FP16. However, a majority of scientific simulation applications are memory bandwidth limited. Beyond preliminary studies, the practical gain from using mixed-precision algorithms on a given HPC system is largely unclear.\n  The High Performance GMRES Mixed Precision (HPG-MxP) benchmark has been proposed to measure the useful performance of a HPC system on sparse matrix-based mixed-precision applications. In this work, we present a highly optimized implementation of the HPG-MxP benchmark for an exascale system and describe our algorithm enhancements. We show for the first time a speedup of 1.6x using a combination of double- and single-precision on modern GPU-based supercomputers.",
      "authors": [
        "Aditya Kashi and Nicholson Koukpaizan and Hao Lu and Michael Matheson and Sarp Oral and Feiyi Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Numerical Analysis (cs.NA)",
        "Performance (cs.PF)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:26:37+00:00",
          "link": "https://arxiv.org/abs/2507.11512v1",
          "size": "983kb",
          "version": "v1"
        }
      ],
      "title": "Scaling the memory wall using mixed-precision -- HPG-MxP on an exascale machine",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11512",
        "HTML": "https://arxiv.org/html/2507.11512v1",
        "PDF": "https://arxiv.org/pdf/2507.11512"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a mixed-precision benchmark for an exascale system, focusing on scientific simulation applications and not on any aspect of data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2505.18409",
      "abstract": "Concurrent accesses to databases are typically grouped in transactions which define units of work that should be isolated from other concurrent computations and resilient to failures. Modern databases provide different levels of isolation for transactions that correspond to different trade-offs between consistency and throughput. Quite often, an application can use transactions with different isolation levels at the same time. In this work, we investigate the problem of testing isolation level implementations in databases, i.e., checking whether a given execution composed of multiple transactions adheres to the prescribed isolation level semantics. We particularly focus on transactions formed of SQL queries and the use of multiple isolation levels at the same time. We show that many restrictions of this problem are NP-complete and provide an algorithm which is exponential-time in the worst-case, polynomial-time in relevant cases, and practically efficient.",
      "authors": [
        "Ahmed Bouajjani",
        "Constantin Enea",
        "Enrique Rom\\'an-Calvo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-23T22:33:03+00:00",
          "link": "https://arxiv.org/abs/2505.18409v1",
          "size": "131kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T15:13:15+00:00",
          "link": "https://arxiv.org/abs/2505.18409v2",
          "size": "91kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T17:50:19+00:00",
          "link": "https://arxiv.org/abs/2505.18409v3",
          "size": "131kb",
          "version": "v3"
        }
      ],
      "title": "On the Complexity of Checking Mixed Isolation Levels for SQL Transactions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.18409",
        "PDF": "https://arxiv.org/pdf/2505.18409"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the complexity of checking mixed isolation levels for SQL transactions, which is not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.03106",
      "abstract": "Recent advances in reinforcement learning (RL) with numerical feedback, such as scalar rewards, have significantly enhanced the complex reasoning capabilities of large language models (LLMs). Despite this success, we identify three key challenges encountered by RL with solely numerical feedback: performance plateaus, limited effectiveness of self-reflection, and persistent failures. We then demonstrate that RL-finetuned models, even after exhibiting performance plateaus, can generate correct refinements on persistently failed problems by leveraging natural language feedback in the form of critiques. Building on this insight, we propose Critique-GRPO, an online RL framework that integrates both natural language and numerical feedback for effective policy optimization. Critique-GRPO enables LLMs to learn from initial responses and critique-guided self-refinements simultaneously while maintaining exploration. Additionally, we employ a shaping function to amplify learning from correct, especially unfamiliar, refinements and penalize incorrect ones. Extensive experiments with Qwen2.5-7B-Base, Qwen2.5-Math-7B-Base, and Qwen3-8B demonstrate that Critique-GRPO consistently outperforms supervised learning and RL-based fine-tuning methods across eight challenging mathematical, STEM, and general reasoning tasks, improving average pass@1 scores by approximately 4.4% and 3.8% on Qwen2.5-7B-Base and Qwen3-8B, respectively. Notably, Critique-GRPO enables effective self-improvement through self-critiquing and weak-to-strong generalization, achieving consistent gains over GRPO, such as 16.7% and 10.0% pass@1 improvements on AIME 2024, respectively.",
      "authors": [
        "Xiaoying Zhang",
        "Hao Sun",
        "Yipeng Zhang",
        "Kaituo Feng",
        "Chaochao Lu",
        "Chao Yang",
        "Helen Meng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-03T17:39:02+00:00",
          "link": "https://arxiv.org/abs/2506.03106v1",
          "size": "4081kb",
          "version": "v1"
        },
        {
          "date": "2025-06-04T13:45:47+00:00",
          "link": "https://arxiv.org/abs/2506.03106v2",
          "size": "4395kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T12:11:37+00:00",
          "link": "https://arxiv.org/abs/2506.03106v3",
          "size": "6053kb",
          "version": "v3"
        }
      ],
      "title": "Critique-GRPO: Advancing LLM Reasoning with Natural Language and Numerical Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03106",
        "HTML": "https://arxiv.org/html/2506.03106v3",
        "PDF": "https://arxiv.org/pdf/2506.03106"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the focus is on improving reasoning capabilities and model fine-tuning, it does not primarily deal with LLM training data processing. It involves RL-enhanced learning rather than data engineering."
      },
      "tasks": [
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10646",
      "abstract": "Programming assistants powered by large language models have transformed software development, yet most benchmarks focus narrowly on code generation tasks. Recent efforts like InfiBench and StackEval attempt to address this gap using Stack Overflow data but remain limited to single-turn interactions in isolated contexts, require significant manual curation, and fail to represent complete project environments. We introduce CodeAssistBench (CAB), the first benchmark framework for evaluating multi-turn programming assistance in realistic settings that address real-world questions about actual codebases. Unlike existing programming Q&A benchmarks, CAB automatically generates scalable datasets from question-related GitHub issues using configurable parameters (e.g., repository creation date, star count, programming languages), and includes automatic containerization of codebases for evaluation. It then evaluates models through simulated users in these containerized environments with full codebase access. Using this framework, we constructed a test set of 3,286 real-world programming questions across 231 repositories, spanning seven programming languages and diverse problem domains. Our evaluation of leading LLMs reveals a substantial capability gap: while models perform well on Stack Overflow questions with success rates of 70-83%, they resolve only up to 16.49% of CAB's recent issues. This discrepancy highlights the challenges of providing assistance in complex, project-specific contexts versus answering standalone questions.",
      "authors": [
        "Myeongsoo Kim",
        "Shweta Garg",
        "Baishakhi Ray",
        "Varun Kumar",
        "and Anoop Deoras"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:19:00+00:00",
          "link": "https://arxiv.org/abs/2507.10646v1",
          "size": "6078kb",
          "version": "v1"
        }
      ],
      "title": "CodeAssistBench (CAB): Dataset & Benchmarking for Multi-turn Chat-Based Code Assistance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10646",
        "HTML": "https://arxiv.org/html/2507.10646v1",
        "PDF": "https://arxiv.org/pdf/2507.10646"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a benchmark framework, CodeAssistBench (CAB), which involves the generation of scalable datasets from GitHub issues; however, the main focus is on evaluation and benchmarking rather than the technical contribution to LLM training data processing itself."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11181",
      "abstract": "This paper presents a comprehensive review of the Mixture-of-Experts (MoE) architecture in large language models, highlighting its ability to significantly enhance model performance while maintaining minimal computational overhead. Through a systematic analysis spanning theoretical foundations, core architectural designs, and large language model (LLM) applications, we examine expert gating and routing mechanisms, hierarchical and sparse MoE configurations, meta-learning approaches, multimodal and multitask learning scenarios, real-world deployment cases, and recent advances and challenges in deep learning. Our analysis identifies key advantages of MoE, including superior model capacity compared to equivalent Bayesian approaches, improved task-specific performance, and the ability to scale model capacity efficiently. We also underscore the importance of ensuring expert diversity, accurate calibration, and reliable inference aggregation, as these are essential for maximizing the effectiveness of MoE architectures. Finally, this review outlines current research limitations, open challenges, and promising future directions, providing a foundation for continued innovation in MoE architecture and its applications.",
      "authors": [
        "Danyang Zhang",
        "Junhao Song",
        "Ziqian Bi",
        "Yingfang Yuan",
        "Tianyang Wang",
        "Joe Yeong",
        "Junfeng Hao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:36:43+00:00",
          "link": "https://arxiv.org/abs/2507.11181v1",
          "size": "8123kb",
          "version": "v1"
        }
      ],
      "title": "Mixture of Experts in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11181",
        "HTML": "https://arxiv.org/html/2507.11181v1",
        "PDF": "https://arxiv.org/pdf/2507.11181"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper reviews the Mixture-of-Experts architecture for LLMs without addressing any aspect of training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10798",
      "abstract": "Timely decision making is critical to the effectiveness of mobile health (mHealth) interventions. At predefined timepoints called \"decision points,\" intelligent mHealth systems such as just-in-time adaptive interventions (JITAIs) estimate an individual's biobehavioral context from sensor or survey data and determine whether and how to intervene. For interventions targeting habitual behavior (e.g., oral hygiene), effectiveness often hinges on delivering support shortly before the target behavior is likely to occur. Current practice schedules decision points at a fixed interval (e.g., one hour) before user-provided behavior times, and the fixed interval is kept the same for all individuals. However, this one-size-fits-all approach performs poorly for individuals with irregular routines, often scheduling decision points after the target behavior has already occurred, rendering interventions ineffective. In this paper, we propose SigmaScheduling, a method to dynamically schedule decision points based on uncertainty in predicted behavior times. When behavior timing is more predictable, SigmaScheduling schedules decision points closer to the predicted behavior time; when timing is less certain, SigmaScheduling schedules decision points earlier, increasing the likelihood of timely intervention. We evaluated SigmaScheduling using real-world data from 68 participants in a 10-week trial of Oralytics, a JITAI designed to improve daily toothbrushing. SigmaScheduling increased the likelihood that decision points preceded brushing events in at least 70% of cases, preserving opportunities to intervene and impact behavior. Our results indicate that SigmaScheduling can advance precision mHealth, particularly for JITAIs targeting time-sensitive, habitual behaviors such as oral hygiene or dietary habits.",
      "authors": [
        "Asim H. Gazi",
        "Bhanu T. Gullapalli",
        "Daiqi Gao",
        "Benjamin M. Marlin",
        "Vivek Shetty",
        "Susan A. Murphy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T20:51:02+00:00",
          "link": "https://arxiv.org/abs/2507.10798v1",
          "size": "2984kb",
          "version": "v1"
        }
      ],
      "title": "Uncertainty-Informed Scheduling of Decision Points for Intelligent Mobile Health Interventions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10798",
        "HTML": "https://arxiv.org/html/2507.10798v1",
        "PDF": "https://arxiv.org/pdf/2507.10798"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is centered on uncertainty-informed scheduling for mobile health interventions, which does not involve LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10996",
      "abstract": "This paper presents our approach to EXIST 2025 Task 1, addressing text-based sexism detection in English and Spanish tweets through hierarchical Low-Rank Adaptation (LoRA) of Llama 3.1 8B. Our method introduces conditional adapter routing that explicitly models label dependencies across three hierarchically structured subtasks: binary sexism identification, source intention detection, and multilabel sexism categorization. Unlike conventional LoRA applications that target only attention layers, we apply adaptation to all linear transformations, enhancing the model's capacity to capture task-specific patterns. In contrast to complex data processing and ensemble approaches, we show that straightforward parameter-efficient fine-tuning achieves strong performance. We train separate LoRA adapters (rank=16, QLoRA 4-bit) for each subtask using unified multilingual training that leverages Llama 3.1's native bilingual capabilities. The method requires minimal preprocessing and uses standard supervised learning. Our multilingual training strategy eliminates the need for separate language-specific models, achieving 1.7-2.4\\% F1 improvements through cross-lingual transfer. With only 1.67\\% trainable parameters compared to full fine-tuning, our approach reduces training time by 75\\% and model storage by 98\\%, while achieving competitive performance across all subtasks (ICM-Hard: 0.6774 for binary classification, 0.4991 for intention detection, 0.6519 for multilabel categorization).",
      "authors": [
        "Lin Tian",
        "Johanne R. Trippas",
        "Marian-Andrei Rizoiu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T05:30:32+00:00",
          "link": "https://arxiv.org/abs/2507.10996v1",
          "size": "61kb",
          "version": "v1"
        }
      ],
      "title": "Mario at EXIST 2025: A Simple Gateway to Effective Multilingual Sexism Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10996",
        "HTML": "https://arxiv.org/html/2507.10996v1",
        "PDF": "https://arxiv.org/pdf/2507.10996"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper focuses on fine-tuning models for multilingual sexism detection with minimal preprocessing. It does not primarily address LLM training data processing, focusing instead on model architecture and fine-tuning."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11155",
      "abstract": "Vision-language models (VLMs) are increasingly applied to identify unsafe or inappropriate images due to their internal ethical standards and powerful reasoning abilities. However, it is still unclear whether they can recognize various unsafe concepts when presented in different modalities, such as text and images. To address this, we first compile the UnsafeConcepts dataset, featuring 75 unsafe concepts, i.e., ``Swastika,'' ``Sexual Harassment,'' and ``Assaults,'' along with associated 1.5K images. We then conduct a systematic evaluation of VLMs' perception (concept recognition) and alignment (ethical reasoning) capabilities. We assess eight popular VLMs and find that, although most VLMs accurately perceive unsafe concepts, they sometimes mistakenly classify these concepts as safe. We also identify a consistent modality gap among open-source VLMs in distinguishing between visual and textual unsafe concepts. To bridge this gap, we introduce a simplified reinforcement learning (RL)-based approach using proximal policy optimization (PPO) to strengthen the ability to identify unsafe concepts from images. Our approach uses reward scores based directly on VLM responses, bypassing the need for collecting human-annotated preference data to train a new reward model. Experimental results show that our approach effectively enhances VLM alignment on images while preserving general capabilities. It outperforms baselines such as supervised fine-tuning (SFT) and direct preference optimization (DPO). We hope our dataset, evaluation findings, and proposed alignment solution contribute to the community's efforts in advancing safe VLMs.",
      "authors": [
        "Yiting Qu and Michael Backes and Yang Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:04:27+00:00",
          "link": "https://arxiv.org/abs/2507.11155v1",
          "size": "4203kb",
          "version": "v1"
        }
      ],
      "title": "Bridging the Gap in Vision Language Models in Identifying Unsafe Concepts Across Modalities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11155",
        "HTML": "https://arxiv.org/html/2507.11155v1",
        "PDF": "https://arxiv.org/pdf/2507.11155"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper focuses on evaluating VLMs and their ability to identify unsafe concepts, and proposes a reinforcement learning approach to improve this recognition. It compiles a dataset but does not primarily contribute to LLM training-data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11367",
      "abstract": "Training neural networks with reinforcement learning (RL) typically relies on backpropagation (BP), necessitating storage of activations from the forward pass for subsequent backward updates. Furthermore, backpropagating error signals through multiple layers often leads to vanishing or exploding gradients, which can degrade learning performance and stability. We propose a novel approach that trains each layer of the neural network using local signals during the forward pass in RL settings. Our approach introduces local, layer-wise losses leveraging the principle of matching pairwise distances from multi-dimensional scaling, enhanced with optional reward-driven guidance. This method allows each hidden layer to be trained using local signals computed during forward propagation, thus eliminating the need for backward passes and storing intermediate activations. Our experiments, conducted with policy gradient methods across common RL benchmarks, demonstrate that this backpropagation-free method achieves competitive performance compared to their classical BP-based counterpart. Additionally, the proposed method enhances stability and consistency within and across runs, and improves performance especially in challenging environments.",
      "authors": [
        "Daniel Tanneberg"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:39:41+00:00",
          "link": "https://arxiv.org/abs/2507.11367v1",
          "size": "5754kb",
          "version": "v1"
        }
      ],
      "title": "Local Pairwise Distance Matching for Backpropagation-Free Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11367",
        "HTML": "https://arxiv.org/html/2507.11367v1",
        "PDF": "https://arxiv.org/pdf/2507.11367"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a novel approach for training neural networks in reinforcement learning and does not discuss LLM training data processing or data engineering operations."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11443",
      "abstract": "The escalating adoption of high-resolution, large-field-of-view imagery amplifies the need for efficient compression methodologies. Conventional techniques frequently fail to preserve critical image details, while data-driven approaches exhibit limited generalizability. Implicit Neural Representations (INRs) present a promising alternative by learning continuous mappings from spatial coordinates to pixel intensities for individual images, thereby storing network weights rather than raw pixels and avoiding the generalization problem. However, INR-based compression of large images faces challenges including slow compression speed and suboptimal compression ratios. To address these limitations, we introduce COLI (Compressor for Large Images), a novel framework leveraging Neural Representations for Videos (NeRV). First, recognizing that INR-based compression constitutes a training process, we accelerate its convergence through a pretraining-finetuning paradigm, mixed-precision training, and reformulation of the sequential loss into a parallelizable objective. Second, capitalizing on INRs' transformation of image storage constraints into weight storage, we implement Hyper-Compression, a novel post-training technique to substantially enhance compression ratios while maintaining minimal output distortion. Evaluations across two medical imaging datasets demonstrate that COLI consistently achieves competitive or superior PSNR and SSIM metrics at significantly reduced bits per pixel (bpp), while accelerating NeRV training by up to 4 times.",
      "authors": [
        "Haoran Wang",
        "Hanyu Pei",
        "Yang Lyu",
        "Kai Zhang",
        "Li Li",
        "Feng-Lei Fan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:07:07+00:00",
          "link": "https://arxiv.org/abs/2507.11443v1",
          "size": "18522kb",
          "version": "v1"
        }
      ],
      "title": "COLI: A Hierarchical Efficient Compressor for Large Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11443",
        "HTML": "https://arxiv.org/html/2507.11443v1",
        "PDF": "https://arxiv.org/pdf/2507.11443"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on image compression techniques using neural representations and does not address any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.15416",
      "abstract": "Representation learning for time series using contrastive learning has emerged as a critical technique for improving the performance of downstream tasks. To advance this effective approach, we introduce CaTT (\\textit{Contrast All The Time}), a new approach to unsupervised contrastive learning for time series, which takes advantage of dynamics between temporally similar moments more efficiently and effectively than existing methods. CaTT departs from conventional time-series contrastive approaches that rely on data augmentations or selected views. Instead, it uses the full temporal dimension by contrasting all time steps in parallel. This is made possible by a scalable NT-pair formulation, which extends the classic N-pair loss across both batch and temporal dimensions, making the learning process end-to-end and more efficient. CaTT learns directly from the natural structure of temporal data, using repeated or adjacent time steps as implicit supervision, without the need for pair selection heuristics. We demonstrate that this approach produces superior embeddings which allow better performance in downstream tasks. Additionally, training is faster than other contrastive learning approaches, making it suitable for large-scale and real-world time series applications. The source code is publicly available at \\href{https://github.com/sfi-norwai/CaTT}{https://github.com/sfi-norwai/CaTT}.",
      "authors": [
        "Abdul-Kazeem Shamba and Kerstin Bach and Gavin Taylor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-20T15:20:24+00:00",
          "link": "https://arxiv.org/abs/2410.15416v1",
          "size": "3506kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T13:42:19+00:00",
          "link": "https://arxiv.org/abs/2410.15416v2",
          "size": "5520kb",
          "version": "v2"
        }
      ],
      "title": "Contrast All the Time: Learning Time Series Representation from Temporal Consistency",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.15416",
        "HTML": "https://arxiv.org/html/2410.15416v2",
        "PDF": "https://arxiv.org/pdf/2410.15416"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus of this paper is on contrastive learning for time series data, without any discussion of LLM training data processing."
      },
      "tasks": [
        "Contrastive Learning",
        "Representation Learning",
        "Time Series"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.04644",
      "abstract": "We introduce Agentic Reasoning, a framework that enhances large language model (LLM) reasoning by integrating external tool-using agents. Agentic Reasoning dynamically leverages web search, code execution, and structured memory to address complex problems requiring deep research. A key innovation in our framework is the Mind-Map agent, which constructs a structured knowledge graph to store reasoning context and track logical relationships, ensuring coherence in long reasoning chains with extensive tool usage. Additionally, we conduct a comprehensive exploration of the Web-Search agent, leading to a highly effective search mechanism that surpasses all prior approaches. When deployed on DeepSeek-R1, our method achieves a new state-of-the-art (SOTA) among public models and delivers performance comparable to OpenAI Deep Research, the leading proprietary model in this domain. Extensive ablation studies validate the optimal selection of agentic tools and confirm the effectiveness of our Mind-Map and Web-Search agents in enhancing LLM reasoning. The code is at: https://github.com/theworldofagents/Agentic-Reasoning",
      "authors": [
        "Junde Wu",
        "Jiayuan Zhu",
        "Yuyuan Liu",
        "Min Xu",
        "Yueming Jin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-07T04:08:46+00:00",
          "link": "https://arxiv.org/abs/2502.04644v1",
          "size": "3548kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T20:06:23+00:00",
          "link": "https://arxiv.org/abs/2502.04644v2",
          "size": "2840kb",
          "version": "v2"
        }
      ],
      "title": "Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.04644",
        "HTML": "https://arxiv.org/html/2502.04644v2",
        "PDF": "https://arxiv.org/pdf/2502.04644"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a framework for enhancing LLM reasoning with tools, but it does not focus on the processing or creation of training data for LLMs."
      },
      "tasks": [
        "Decision Making",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "repo_urls": [
        "https://github.com/theworldofagents/agentic-reasoning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.09065",
      "abstract": "With the success of transformer architectures across diverse applications, the error correction code transformer (ECCT) has gained significant attention for its superior decoding performance. In spite of its advantages, the error floor problem in ECCT decoding remains unexplored. We present the first investigation into this issue, revealing that ECCT encounters error floors, limiting its effectiveness in practical settings. To address this error floor problem, we adopt a hybrid decoding framework that integrates ECCT with conventional hard decision decoders. Unlike prior hybrid decoding schemes, our key contribution lies in proposing a novel loss function that explicitly takes into account the interaction between ECCT and hard decision decoders during training. The proposed loss function guides ECCT to focus on residual errors that are not corrected by the hard decision stages, effectively lowering the error floor. Simulation results confirm that the hybrid decoder trained with the proposed loss function achieves substantial performance gains over standard ECCT in both the waterfall and the error floor regions.",
      "authors": [
        "Taewoo Park",
        "Seong-Joon Park",
        "Hee-Youl Kwak",
        "Sang-Hyo Kim",
        "and Yongjune Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-13T08:26:57+00:00",
          "link": "https://arxiv.org/abs/2502.09065v1",
          "size": "1959kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T01:28:00+00:00",
          "link": "https://arxiv.org/abs/2502.09065v2",
          "size": "1380kb",
          "version": "v2"
        }
      ],
      "title": "Lowering the Error Floor of Error Correction Code Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.09065",
        "HTML": "https://arxiv.org/html/2502.09065v2",
        "PDF": "https://arxiv.org/pdf/2502.09065"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses error correction in transformer architectures and proposes a novel loss function for hybrid decoding frameworks, with no focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10729",
      "abstract": "Modern software systems are increasingly complex, presenting significant challenges in quality assurance. Just-in-time vulnerability prediction (JIT-VP) is a proactive approach to identifying vulnerable commits and providing early warnings about potential security risks. However, we observe that current JIT-VP evaluations rely on an idealized setting, where the evaluation datasets are artificially balanced, consisting exclusively of vulnerability-introducing and vulnerability-fixing commits.\n  To address this limitation, this study assesses the effectiveness of JIT-VP techniques under a more realistic setting that includes both vulnerability-related and vulnerability-neutral commits. To enable a reliable evaluation, we introduce a large-scale public dataset comprising over one million commits from FFmpeg and the Linux kernel. Our empirical analysis of eight state-of-the-art JIT-VP techniques reveals a significant decline in predictive performance when applied to real-world conditions; for example, the average PR-AUC on Linux drops 98\\% from 0.805 to 0.016. This discrepancy is mainly attributed to the severe class imbalance in real-world datasets, where vulnerability-introducing commits constitute only a small fraction of all commits.\n  To mitigate this issue, we explore the effectiveness of widely adopted techniques for handling dataset imbalance, including customized loss functions, oversampling, and undersampling. Surprisingly, our experimental results indicate that these techniques are ineffective in addressing the imbalance problem in JIT-VP. These findings underscore the importance of realistic evaluations of JIT-VP and the need for domain-specific techniques to address data imbalance in such scenarios.",
      "authors": [
        "Duong Nguyen",
        "Thanh Le-Cong",
        "Triet Huynh Minh Le",
        "M. Ali Babar and Quyet-Thang Huynh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:49:57+00:00",
          "link": "https://arxiv.org/abs/2507.10729v1",
          "size": "972kb",
          "version": "v1"
        }
      ],
      "title": "Toward Realistic Evaluations of Just-In-Time Vulnerability Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10729",
        "HTML": "https://arxiv.org/html/2507.10729v1",
        "PDF": "https://arxiv.org/pdf/2507.10729"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses methods for evaluating JIT vulnerability prediction in software commits, highlighting dataset imbalance issues. It does not address LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11061",
      "abstract": "Recent advances in 3D neural representations and instance-level editing models have enabled the efficient creation of high-quality 3D content. However, achieving precise local 3D edits remains challenging, especially for Gaussian Splatting, due to inconsistent multi-view 2D part segmentations and inherently ambiguous nature of Score Distillation Sampling (SDS) loss. To address these limitations, we propose RoMaP, a novel local 3D Gaussian editing framework that enables precise and drastic part-level modifications. First, we introduce a robust 3D mask generation module with our 3D-Geometry Aware Label Prediction (3D-GALP), which uses spherical harmonics (SH) coefficients to model view-dependent label variations and soft-label property, yielding accurate and consistent part segmentations across viewpoints. Second, we propose a regularized SDS loss that combines the standard SDS loss with additional regularizers. In particular, an L1 anchor loss is introduced via our Scheduled Latent Mixing and Part (SLaMP) editing method, which generates high-quality part-edited 2D images and confines modifications only to the target region while preserving contextual coherence. Additional regularizers, such as Gaussian prior removal, further improve flexibility by allowing changes beyond the existing context, and robust 3D masking prevents unintended edits. Experimental results demonstrate that our RoMaP achieves state-of-the-art local 3D editing on both reconstructed and generated Gaussian scenes and objects qualitatively and quantitatively, making it possible for more robust and flexible part-level 3D Gaussian editing.",
      "authors": [
        "Hayeon Kim",
        "Ji Ha Jang and Se Young Chun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T07:54:11+00:00",
          "link": "https://arxiv.org/abs/2507.11061v1",
          "size": "32579kb",
          "version": "v1"
        }
      ],
      "title": "Robust 3D-Masked Part-level Editing in 3D Gaussian Splatting with Regularized Score Distillation Sampling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11061",
        "HTML": "https://arxiv.org/html/2507.11061v1",
        "PDF": "https://arxiv.org/pdf/2507.11061"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on 3D content creation and editing using neural representations and does not involve processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.19043",
      "abstract": "The development of image time series retrieval (ITSR) methods is a growing research interest in remote sensing (RS). Given a user-defined image time series (i.e., the query time series), ITSR methods search and retrieve from large archives the image time series that have similar content to the query time series. Existing ITSR methods in RS are designed for unimodal retrieval problems, relying on an assumption that users always have access to a query image time series in the considered image modality. In operational scenarios, this assumption may not hold. To overcome this issue, as a first time in RS we introduce the task of cross-modal text-image time series retrieval (text-ITSR). In detail, we present a self-supervised cross-modal text-ITSR method that enables the retrieval of image time series using text sentences as queries, and vice versa. We focus our attention on text-ITSR in pairs of images (i.e., bitemporal images). Our text-ITSR method consists of two key components: 1) modality-specific encoders to model the semantic content of bitemporal images and text sentences with discriminative features; and 2) modality-specific projection heads to align textual and image representations in a shared embedding space. To effectively model the temporal information in the bitemporal images, we exploit two fusion strategies: i) global feature fusion (GFF) strategy that combines global image features through simple yet effective operators; and ii) transformer-based feature fusion (TFF) strategy that leverages transformers for fine-grained temporal integration. Extensive experiments conducted on two benchmark RS archives demonstrate the effectiveness of our method in accurately retrieving semantically relevant bitemporal images (or text sentences) to a query text sentence (or bitemporal image). The code of this work is publicly available at https://git.tu-berlin.de/rsim/cross-modal-text-tsir .",
      "authors": [
        "Genc Hoxha and Oliv\\'er Angyal and Beg\\\"um Demir"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-31T11:14:38+00:00",
          "link": "https://arxiv.org/abs/2501.19043v1",
          "size": "33850kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T15:06:16+00:00",
          "link": "https://arxiv.org/abs/2501.19043v2",
          "size": "43793kb",
          "version": "v2"
        }
      ],
      "title": "Self-Supervised Cross-Modal Text-Image Time Series Retrieval in Remote Sensing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.19043",
        "HTML": "https://arxiv.org/html/2501.19043v2",
        "PDF": "https://arxiv.org/pdf/2501.19043"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a method for cross-modal text-image time series retrieval in remote sensing, which is not related to LLM training data processing or data quality improvement techniques."
      },
      "tasks": [
        "Retrieval",
        "Time Series"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.16179",
      "abstract": "This paper provides, for the first time, analytical expressions for the Long-Range (LoRa) waveform and cross-correlation in both continuous and discrete time domains under the Doppler effect in satellite communication. We propose the concept and formulas of the shared visibility window for satellites toward two ground devices. Our analysis covers cross-correlation results with varying spreading factors (SF) for no-Doppler and with-Doppler cases. We find the maximum cross-correlation with different SFs and the mean cross-correlation are immune to the Doppler effect. However, the maximum cross-correlation with the same SFs is only immune to high Doppler shift, with its value fluctuating between 0.6 and 1 under high Doppler rate. We interpret this fluctuation by introducing the relationship between transmission start time and cross-correlation. We provide a parameter analysis for orbit height, ground device distance, and inclination angle. Additionally, we analyze the bit error rate (BER) for LoRa signals and observe worse performance under high Doppler shift or interference with same SF. Increasing the SNR or the SIR improves the BER only when Doppler effect is below a frequency threshold. Notably, under Doppler effect, the performance behaviors of BER no longer align with those of maximum cross-correlation. Finally, our results lead to two recommendations: 1) To mitigate Doppler impact on cross-correlation, we recommend utilizing low SFs, high orbit height, short ground device distance, and the transmission start time with high Doppler shift; 2) To mitigate Doppler impact on BER, we recommend employing low SFs, high bandwidth, and transmission start time with high Doppler rate. These conflicting recommendations regarding transmission start time highlight the necessity of Doppler shift compensation techniques to help operate LoRa in space properly.",
      "authors": [
        "Jikang Deng",
        "Fatma Benkhelifa",
        "Mohamed-Slim Alouini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-22T10:46:50+00:00",
          "link": "https://arxiv.org/abs/2502.16179v1",
          "size": "2152kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T15:34:31+00:00",
          "link": "https://arxiv.org/abs/2502.16179v2",
          "size": "1562kb",
          "version": "v2"
        }
      ],
      "title": "Orthogonality Analysis in LoRa Uplink Satellite Communications Affected by Doppler Effect",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.16179",
        "HTML": "https://arxiv.org/html/2502.16179v2",
        "PDF": "https://arxiv.org/pdf/2502.16179"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with satellite communication and Doppler effects on LoRa signals, without any connection to LLM training data processing or related topics."
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2507.09923",
      "abstract": "Super-resolution (SR) has been a pivotal task in image processing, aimed at enhancing image resolution across various applications. Recently, look-up table (LUT)-based approaches have attracted interest due to their efficiency and performance. However, these methods are typically designed for fixed scale factors, making them unsuitable for arbitrary-scale image SR (ASISR). Existing ASISR techniques often employ implicit neural representations, which come with considerable computational cost and memory demands. To address these limitations, we propose Interpolation Mixing LUT (IM-LUT), a novel framework that operates ASISR by learning to blend multiple interpolation functions to maximize their representational capacity. Specifically, we introduce IM-Net, a network trained to predict mixing weights for interpolation functions based on local image patterns and the target scale factor. To enhance efficiency of interpolation-based methods, IM-Net is transformed into IM-LUT, where LUTs are employed to replace computationally expensive operations, enabling lightweight and fast inference on CPUs while preserving reconstruction quality. Experimental results on several benchmark datasets demonstrate that IM-LUT consistently achieves a superior balance between image quality and efficiency compared to existing methods, highlighting its potential as a promising solution for resource-constrained applications.",
      "authors": [
        "Sejin Park",
        "Sangmin Lee",
        "Kyong Hwan Jin",
        "Seung-Won Jung"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T05:02:57+00:00",
          "link": "https://arxiv.org/abs/2507.09923v1",
          "size": "24652kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T10:04:02+00:00",
          "link": "https://arxiv.org/abs/2507.09923v2",
          "size": "24652kb",
          "version": "v2"
        }
      ],
      "title": "IM-LUT: Interpolation Mixing Look-Up Tables for Image Super-Resolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09923",
        "HTML": "https://arxiv.org/html/2507.09923v2",
        "PDF": "https://arxiv.org/pdf/2507.09923"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about image super-resolution using look-up tables and does not involve LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10755",
      "abstract": "Facial expression recognition (FER) algorithms classify facial expressions into emotions such as happy, sad, or angry. An evaluative challenge facing FER algorithms is the fall in performance when detecting spontaneous expressions compared to posed expressions. An ethical (and evaluative) challenge facing FER algorithms is that they tend to perform poorly for people of some races and skin colors. These challenges are linked to the data collection practices employed in the creation of FER datasets. In this study, we audit two state-of-the-art FER datasets. We take random samples from each dataset and examine whether images are spontaneous or posed. In doing so, we propose a methodology for identifying spontaneous or posed images. We discover a significant number of images that were posed in the datasets purporting to consist of in-the-wild images. Since performance of FER models vary between spontaneous and posed images, the performance of models trained on these datasets will not represent the true performance if such models were to be deployed in in-the-wild applications. We also observe the skin color of individuals in the samples, and test three models trained on each of the datasets to predict facial expressions of people from various races and skin tones. We find that the FER models audited were more likely to predict people labeled as not white or determined to have dark skin as showing a negative emotion such as anger or sadness even when they were smiling. This bias makes such models prone to perpetuate harm in real life applications.",
      "authors": [
        "Rina Khan and Catherine Stinson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:25:09+00:00",
          "link": "https://arxiv.org/abs/2507.10755v1",
          "size": "230kb",
          "version": "v1"
        }
      ],
      "title": "Auditing Facial Emotion Recognition Datasets for Posed Expressions and Racial Bias",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10755",
        "HTML": "https://arxiv.org/html/2507.10755v1",
        "PDF": "https://arxiv.org/pdf/2507.10755"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper audits FER datasets to identify biases and proposes a methodology for evaluating data quality, focusing substantially on processing and improving training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10894",
      "abstract": "Language-guided navigation is a cornerstone of embodied AI, enabling agents to interpret language instructions and navigate complex environments. However, expert-provided instructions are limited in quantity, while synthesized annotations often lack quality, making them insufficient for large-scale research. To address this, we propose NavComposer, a novel framework for automatically generating high-quality navigation instructions. NavComposer explicitly decomposes semantic entities such as actions, scenes, and objects, and recomposes them into natural language instructions. Its modular architecture allows flexible integration of state-of-the-art techniques, while the explicit use of semantic entities enhances both the richness and accuracy of instructions. Moreover, it operates in a data-agnostic manner, supporting adaptation to diverse navigation trajectories without domain-specific training. Complementing NavComposer, we introduce NavInstrCritic, a comprehensive annotation-free evaluation system that assesses navigation instructions on three dimensions: contrastive matching, semantic consistency, and linguistic diversity. NavInstrCritic provides a holistic evaluation of instruction quality, addressing limitations of traditional metrics that rely heavily on expert annotations. By decoupling instruction generation and evaluation from specific navigation agents, our method enables more scalable and generalizable research. Extensive experiments provide direct and practical evidence for the effectiveness of our method.",
      "authors": [
        "Zongtao He",
        "Liuyi Wang",
        "Lu Chen",
        "Chengju Liu",
        "Qijun Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T01:20:22+00:00",
          "link": "https://arxiv.org/abs/2507.10894v1",
          "size": "2936kb",
          "version": "v1"
        }
      ],
      "title": "NavComposer: Composing Language Instructions for Navigation Trajectories through Action-Scene-Object Modularization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10894",
        "HTML": "https://arxiv.org/html/2507.10894v1",
        "PDF": "https://arxiv.org/pdf/2507.10894"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "NavComposer introduces a framework for automatically generating high-quality navigation instructions, involving significant data processing techniques for LLM-style instruction generation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11345",
      "abstract": "Robotic task execution faces challenges due to the inconsistency between symbolic planner models and the rich control structures actually running on the robot. In this paper, we present the first physical deployment of an integrated actor-planner system that shares hierarchical operational models for both acting and planning, interleaving the Reactive Acting Engine (RAE) with an anytime UCT-like Monte Carlo planner (UPOM). We implement RAE+UPOM on a mobile manipulator in a real-world deployment for an object collection task. Our experiments demonstrate robust task execution under action failures and sensor noise, and provide empirical insights into the interleaved acting-and-planning decision making process.",
      "authors": [
        "Oscar Lima",
        "Marc Vinci",
        "Sunandita Patra",
        "Sebastian Stock",
        "Joachim Hertzberg",
        "Martin Atzmueller",
        "Malik Ghallab",
        "Dana Nau",
        "Paolo Traverso"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:20:26+00:00",
          "link": "https://arxiv.org/abs/2507.11345v1",
          "size": "2303kb",
          "version": "v1"
        }
      ],
      "title": "Acting and Planning with Hierarchical Operational Models on a Mobile Robot: A Study with RAE+UPOM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11345",
        "HTML": "https://arxiv.org/html/2507.11345v1",
        "PDF": "https://arxiv.org/pdf/2507.11345"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper deals with robotic task execution and hierarchical operational models, without any mention of LLM training data processing or related data engineering tasks."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.02281",
      "abstract": "Financial reinforcement learning (FinRL) is now a practical paradigm for financial engineering. However, applying RL strategies to real-world trading tasks remains a challenge for individuals, as it is error-prone and engineering-heavy. The non-stationarity of financial data, low signal-to-noise ratios, and various market frictions require deep accumulations. Although numerous FinRL methods have been developed for tasks such as stock/crypto trading and portfolio management, the lack of standardized task definitions, real-time high-quality datasets, close-to-real market environments, and robust baselines has hindered consistent reproduction in both open-source community and FinTech industry. To bridge this gap, we organized a series of FinRL Contests from 2023 to 2025, covering a diverse range of financial tasks such as stock trading, order execution, crypto trading, and the use of large language model (LLM)-engineered signals. These contests attracted 200+ participants from 100+ institutions over 20+ countries. To encourage participations, we provided starter kits featuring GPU-optimized parallel market environments, ensemble learning, and comprehensive instructions. In this paper, we summarize these benchmarking efforts, detailing task formulations, data curation pipelines, environment implementations, evaluation protocols, participant performance, and organizational insights. It guides our follow-up FinRL contests, and also provides a reference for FinAI contests alike.",
      "authors": [
        "Keyi Wang and Nikolaus Holzer and Ziyi Xia and Yupeng Cao and Jiechao Gao and Anwar Walid and Kairong Xiao and Xiao-Yang Liu Yanglet"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-03T05:08:04+00:00",
          "link": "https://arxiv.org/abs/2504.02281v1",
          "size": "840kb",
          "version": "v1"
        },
        {
          "date": "2025-04-11T06:05:40+00:00",
          "link": "https://arxiv.org/abs/2504.02281v2",
          "size": "1104kb",
          "version": "v2"
        },
        {
          "date": "2025-05-16T17:34:05+00:00",
          "link": "https://arxiv.org/abs/2504.02281v3",
          "size": "9795kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T08:32:03+00:00",
          "link": "https://arxiv.org/abs/2504.02281v4",
          "size": "2244kb",
          "version": "v4"
        }
      ],
      "title": "FinRL Contests: Benchmarking Data-driven Financial Reinforcement Learning Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.02281",
        "HTML": "https://arxiv.org/html/2504.02281v4",
        "PDF": "https://arxiv.org/pdf/2504.02281"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "While the paper discusses benchmarking efforts in financial reinforcement learning and LLM-engineered signals, it does not primarily focus on LLM data processing nor creates new datasets specifically for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.09647",
      "abstract": "In recent years, the rampant spread of misinformation on social media has made accurate detection of multimodal fake news a critical research focus. However, previous research has not adequately understood the semantics of images, and models struggle to discern news authenticity with limited textual information. Meanwhile, treating all emotional types of news uniformly without tailored approaches further leads to performance degradation. Therefore, we propose a novel Knowledge Augmentation and Emotion Guidance Network (KEN). On the one hand, we effectively leverage LVLM's powerful semantic understanding and extensive world knowledge. For images, the generated captions provide a comprehensive understanding of image content and scenes, while for text, the retrieved evidence helps break the information silos caused by the closed and limited text and context. On the other hand, we consider inter-class differences between different emotional types of news through balanced learning, achieving fine-grained modeling of the relationship between emotional types and authenticity. Extensive experiments on two real-world datasets demonstrate the superiority of our KEN.",
      "authors": [
        "Peican Zhu",
        "Yubo Jing",
        "Le Cheng",
        "Keke Tang",
        "Yangming Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T14:28:20+00:00",
          "link": "https://arxiv.org/abs/2507.09647v1",
          "size": "1775kb",
          "version": "v1"
        }
      ],
      "title": "KEN: Knowledge Augmentation and Emotion Guidance Network for Multimodal Fake News Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09647",
        "HTML": "https://arxiv.org/html/2507.09647",
        "PDF": "https://arxiv.org/pdf/2507.09647"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces a network for fake news detection using knowledge augmentation and emotion guidance, with no connection to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10434",
      "abstract": "Self-supervised learning (SSL) is able to build latent representations that generalize well to unseen data. However, only a few SSL techniques exist for the online CL setting, where data arrives in small minibatches, the model must comply with a fixed computational budget, and task boundaries are absent. We introduce Continual Latent Alignment (CLA), a novel SSL strategy for Online CL that aligns the representations learned by the current model with past representations to mitigate forgetting. We found that our CLA is able to speed up the convergence of the training process in the online scenario, outperforming state-of-the-art approaches under the same computational budget. Surprisingly, we also discovered that using CLA as a pretraining protocol in the early stages of pretraining leads to a better final performance when compared to a full i.i.d. pretraining.",
      "authors": [
        "Giacomo Cignoni",
        "Andrea Cossu",
        "Alexandra Gomez-Villa",
        "Joost van de Weijer and Antonio Carta"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T16:23:39+00:00",
          "link": "https://arxiv.org/abs/2507.10434v1",
          "size": "467kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T09:43:30+00:00",
          "link": "https://arxiv.org/abs/2507.10434v2",
          "size": "484kb",
          "version": "v2"
        }
      ],
      "title": "CLA: Latent Alignment for Online Continual Self-Supervised Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10434",
        "HTML": "https://arxiv.org/html/2507.10434v2",
        "PDF": "https://arxiv.org/pdf/2507.10434"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions a self-supervised learning strategy that could be relevant for pre-training models, but it doesn't focus primarily on LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.17507",
      "abstract": "Cross-modal retrieval aims to search for instances, which are semantically related to the query through the interaction of different modal data. Traditional solutions utilize a single-tower or dual-tower framework to explicitly compute the score between queries and candidates, which is challenged by training cost and inference latency with large-scale data. Inspired by the remarkable performance and efficiency of generative models, we propose a generative cross-modal retrieval framework (CART) based on coarse-to-fine semantic modeling, which assigns identifiers to each candidate and treats the generating identifier as the retrieval target. Specifically, we explore an effective coarse-to-fine scheme, combining K-Means and RQ-VAE to discretize multimodal data into token sequences that support autoregressive generation. Further, considering the lack of explicit interaction between queries and candidates, we propose a feature fusion strategy to align their semantics. Extensive experiments demonstrate the effectiveness of the strategies in the CART, achieving excellent results in both retrieval performance and efficiency.",
      "authors": [
        "Minghui Fang",
        "Shengpeng Ji",
        "Jialong Zuo",
        "Hai Huang",
        "Yan Xia",
        "Jieming Zhu",
        "Xize Cheng",
        "Xiaoda Yang",
        "Wenrui Liu",
        "Gang Wang",
        "Zhenhua Dong",
        "Zhou Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-25T12:47:04+00:00",
          "link": "https://arxiv.org/abs/2406.17507v1",
          "size": "353kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T03:20:06+00:00",
          "link": "https://arxiv.org/abs/2406.17507v2",
          "size": "493kb",
          "version": "v2"
        }
      ],
      "title": "CART: A Generative Cross-Modal Retrieval Framework with Coarse-To-Fine Semantic Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.17507",
        "PDF": "https://arxiv.org/pdf/2406.17507"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a generative cross-modal retrieval framework and does not mention LLM training data processing or creation."
      },
      "tasks": [
        "Cross-Modal Retrieval",
        "Natural Language Queries",
        "Retrieval",
        "Text Retrieval",
        "Video Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.18419",
      "abstract": "Advection-dominated problems are predominantly noticed in nature, engineering systems, and various industrial processes. Traditional linear compression methods, such as proper orthogonal decomposition (POD) and reduced basis (RB) methods are ill-suited for these problems, due to slow Kolmogorov $n$-width decay. This results in inefficient and inaccurate reduced order models (ROMs). There are few non-linear approaches to accelerate the Kolmogorov $n$-width decay. In this work, we use a neural network shift augmented transformation technique that employs automatic shift detection. This approach leverages a deep-learning framework to derive a parameter-dependent mapping between the original manifold $\\mathcal{M}$ and the transformed manifold $\\tilde{\\mathcal{M}}$. We apply a linear compression method to obtain a low-dimensional linear approximation subspace of the transformed manifold $\\tilde{\\mathcal{M}}$. Furthermore, we construct non-intrusive reduced order models on the resulting transformed linear approximation subspace and employ automatic shift detection for predictions in the online stage. We propose a complete framework, the neural network shift-augmented proper orthogonal decomposition-based reduced order model (NNsPOD-ROM) algorithm, comprising both offline and online stages for model reduction of advection-dominated problems. We test our proposed methodology on numerous experiments to evaluate its performance on the 1D linear advection equation, a higher order method benchmark case - the 2D isentropic convective vortex, and 2D two-phase flow.",
      "authors": [
        "Harshith Gowrachari",
        "Nicola Demo",
        "Giovanni Stabile and Gianluigi Rozza"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Fluid Dynamics (physics.flu-dyn)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-25T22:35:11+00:00",
          "link": "https://arxiv.org/abs/2407.18419v1",
          "size": "16464kb",
          "version": "v1"
        },
        {
          "date": "2024-09-10T06:33:30+00:00",
          "link": "https://arxiv.org/abs/2407.18419v2",
          "size": "16464kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T14:30:51+00:00",
          "link": "https://arxiv.org/abs/2407.18419v3",
          "size": "5127kb",
          "version": "v3"
        }
      ],
      "title": "Non-intrusive model reduction of advection-dominated hyperbolic problems using neural network shift augmented manifold transformation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.18419",
        "HTML": "https://arxiv.org/html/2407.18419v3",
        "PDF": "https://arxiv.org/pdf/2407.18419"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on model reduction for advection-dominated problems using neural networks but does not address any aspect of LLM training data processing or data engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2411.15821",
      "abstract": "This study investigates the relative impact of training data quality versus quantity on the performance of small language models (SLMs), utilizing the TinyStories dataset for empirical analysis. Analysis of dataset variations with respect to size (25% and 50% of the original size) and duplication (controlled rates of 25%, 50%, 75%, and 100%) were performed. Model performance was evaluated based on the validation loss, accuracy, and perplexity metrics. Results indicate training data quality plays a more significant role in the overall performance of SLMs, especially given scale of this experiment. Minimal duplication positively impacted model accuracy (+0.87% increase in accuracy at 25% duplication) without significantly increasing perplexity (+0.52% increase going from 0% to 25% duplication) but excessive duplication led to pronounced performance degradation (-40% drop in accuracy at 100% duplication). The implications of this exploration extend beyond just model performance; training large-scale models imposes significant financial and computational burdens, which can be prohibitive for organizations, individuals, and the public at large, especially in developing countries. Additionally, the energy consumption associated with large-scale training raises environmental concerns. Understanding the relative importance of data quality versus quantity could democratize AI technology, making advanced models more accessible and sustainable for all.",
      "authors": [
        "Aryan Sajith",
        "Krishna Chaitanya Rao Kathala"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-24T12:51:50+00:00",
          "link": "https://arxiv.org/abs/2411.15821v1",
          "size": "612kb",
          "version": "v1"
        },
        {
          "date": "2025-03-28T22:38:02+00:00",
          "link": "https://arxiv.org/abs/2411.15821v2",
          "size": "404kb",
          "version": "v2"
        },
        {
          "date": "2025-05-23T20:23:08+00:00",
          "link": "https://arxiv.org/abs/2411.15821v3",
          "size": "475kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T03:41:57+00:00",
          "link": "https://arxiv.org/abs/2411.15821v4",
          "size": "504kb",
          "version": "v4"
        }
      ],
      "title": "Is Training Data Quality or Quantity More Impactful to Small Language Model Performance?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.15821",
        "PDF": "https://arxiv.org/pdf/2411.15821"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper's primary focus is on analyzing training data quality versus quantity and their impact on model performance, involving data duplication and dataset size variations, which is directly related to LLM training data processing."
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Small Language Model"
      ],
      "repo_urls": [
        "https://github.com/aryan-sajith/urv-data_quantity_vs_data_quality-research"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.10741",
      "abstract": "Grounding language in complex perception (e.g. pixels) and action is a key challenge when building situated agents that can interact with humans via language. In past works, this is often solved via manual design of the language grounding or by curating massive datasets relating language to elements of the environment. We propose Ground-Compose-Reinforce, a neurosymbolic framework for grounding formal language from data, and eliciting behaviours by directly tasking RL agents through this language. By virtue of data-driven learning, our framework avoids the manual design of domain-specific elements like reward functions or symbol detectors. By virtue of compositional formal language semantics, our framework achieves data-efficient grounding and generalization to arbitrary language compositions. Experiments on an image-based gridworld and a MuJoCo robotics domain show that our approach reliably maps formal language instructions to behaviours with limited data while end-to-end, data-driven approaches fail.",
      "authors": [
        "Andrew C. Li",
        "Toryn Q. Klassen",
        "Andrew Wang",
        "Parand A. Alamdari",
        "Sheila A. McIlraith"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T19:05:15+00:00",
          "link": "https://arxiv.org/abs/2507.10741v1",
          "size": "3687kb",
          "version": "v1"
        }
      ],
      "title": "Ground-Compose-Reinforce: Tasking Reinforcement Learning Agents through Formal Language",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10741",
        "HTML": "https://arxiv.org/html/2507.10741v1",
        "PDF": "https://arxiv.org/pdf/2507.10741"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on grounding language in reinforcement learning agents and does not discuss any aspect of LLM training data collection, processing, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11015",
      "abstract": "Recent advances in automated radiology report generation from chest X-rays using deep learning algorithms have the potential to significantly reduce the arduous workload of radiologists. However, due to the inherent massive data bias in radiology images, where abnormalities are typically subtle and sparsely distributed, existing methods often produce fluent yet medically inaccurate reports, limiting their applicability in clinical practice. To address this issue effectively, we propose a Semantically Informed Salient Regions-guided (SISRNet) report generation method. Specifically, our approach explicitly identifies salient regions with medically critical characteristics using fine-grained cross-modal semantics. Then, SISRNet systematically focuses on these high-information regions during both image modeling and report generation, effectively capturing subtle abnormal findings, mitigating the negative impact of data bias, and ultimately generating clinically accurate reports. Compared to its peers, SISRNet demonstrates superior performance on widely used IU-Xray and MIMIC-CXR datasets.",
      "authors": [
        "Zeyi Hou",
        "Zeqiang Wei",
        "Ruixin Yan",
        "Ning Lang",
        "Xiuzhuang Zhou"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T06:15:07+00:00",
          "link": "https://arxiv.org/abs/2507.11015v1",
          "size": "16945kb",
          "version": "v1"
        }
      ],
      "title": "Semantically Informed Salient Regions Guided Radiology Report Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11015",
        "HTML": "https://arxiv.org/html/2507.11015v1",
        "PDF": "https://arxiv.org/pdf/2507.11015"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on generating radiology reports from chest X-rays and does not involve LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11053",
      "abstract": "Accurate indoor localization is crucial for enabling spatial context in smart environments and navigation systems. Wi-Fi Received Signal Strength (RSS) fingerprinting is a widely used indoor localization approach due to its compatibility with mobile embedded devices. Deep Learning (DL) models improve accuracy in localization tasks by learning RSS variations across locations, but they assume fingerprint vectors exist in a Euclidean space, failing to incorporate spatial relationships and the non-uniform distribution of real-world RSS noise. This results in poor generalization across heterogeneous mobile devices, where variations in hardware and signal processing distort RSS readings. Graph Neural Networks (GNNs) can improve upon conventional DL models by encoding indoor locations as nodes and modeling their spatial and signal relationships as edges. However, GNNs struggle with non-Euclidean noise distributions and suffer from the GNN blind spot problem, leading to degraded accuracy in environments with dense access points (APs). To address these challenges, we propose GATE, a novel framework that constructs an adaptive graph representation of fingerprint vectors while preserving an indoor state-space topology, modeling the non-Euclidean structure of RSS noise to mitigate environmental noise and address device heterogeneity. GATE introduces 1) a novel Attention Hyperspace Vector (AHV) for enhanced message passing, 2) a novel Multi-Dimensional Hyperspace Vector (MDHV) to mitigate the GNN blind spot, and 3) an new Real-Time Edge Construction (RTEC) approach for dynamic graph adaptation. Extensive real-world evaluations across multiple indoor spaces with varying path lengths, AP densities, and heterogeneous devices demonstrate that GATE achieves 1.6x to 4.72x lower mean localization errors and 1.85x to 4.57x lower worst-case errors compared to state-of-the-art indoor localization frameworks.",
      "authors": [
        "Danish Gufran",
        "Sudeep Pasricha"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T07:37:33+00:00",
          "link": "https://arxiv.org/abs/2507.11053v1",
          "size": "2881kb",
          "version": "v1"
        }
      ],
      "title": "GATE: Graph Attention Neural Networks with Real-Time Edge Construction for Robust Indoor Localization using Mobile Embedded Devices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11053",
        "PDF": "https://arxiv.org/pdf/2507.11053"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on indoor localization using Graph Neural Networks and does not discuss any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2409.15346",
      "abstract": "Big data analytics is one of the most promising areas of new research and development in computer science, enterprises, e-commerce, and defense. For many organizations, big data is considered one of their most important strategic assets. This explosive growth has made it necessary to develop effective techniques for examining and analyzing big data from mathematical perspectives. Among various methods of analyzing big data, topological data analysis (TDA) is now considered one of the useful tools. However, there is no fundamental concept related to the topological structure in big data. In this paper, we present fundamental concepts related to the neighborhood structures of words in big data search, laying the groundwork for developing topological frameworks for big data in the future. We also introduce the notion of big data primal within the context of big data search and explore how neighborhood structures, combined with the Jaccard similarity coefficient, can be utilized to detect anomalies in search behavior.",
      "authors": [
        "Santanu Acharjee and Ripunjoy Choudhury"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-10T13:46:14+00:00",
          "link": "https://arxiv.org/abs/2409.15346v1",
          "size": "499kb",
          "version": "v1"
        },
        {
          "date": "2024-12-07T16:00:31+00:00",
          "link": "https://arxiv.org/abs/2409.15346v2",
          "size": "716kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T07:51:12+00:00",
          "link": "https://arxiv.org/abs/2409.15346v3",
          "size": "721kb",
          "version": "v3"
        }
      ],
      "title": "Big data searching using words",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.15346",
        "HTML": "https://arxiv.org/html/2409.15346v3",
        "PDF": "https://arxiv.org/pdf/2409.15346"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses topological data analysis for big data search but does not address LLM training data processing or dataset creation."
      },
      "tasks": [
        "Topological Data Analysis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.11740",
      "abstract": "After a concise introduction to the square of opposition, in particular, and, Aristotelian Diagrams, in general, I describe how one can create a mathematical universe to host these objects. Since these objects assume that the underlying logic is the bivalent logic, I have used these objects as a starting point to introduce fuzzy Aristotelian Diagrams and describe a mathematical formulation of them. In addition, I outline the characteristrics of a mathematical universe that hosts them.",
      "authors": [
        "Apostolos Syropoulos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-15T16:17:11+00:00",
          "link": "https://arxiv.org/abs/2410.11740v1",
          "size": "122kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T20:23:00+00:00",
          "link": "https://arxiv.org/abs/2410.11740v2",
          "size": "122kb",
          "version": "v2"
        }
      ],
      "title": "Fuzzy Aristotelian Diagrams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.11740",
        "HTML": "https://arxiv.org/html/2410.11740v2",
        "PDF": "https://arxiv.org/pdf/2410.11740"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work introduces fuzzy Aristotelian Diagrams and mathematical formulations, without addressing any aspect of LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10340",
      "abstract": "Despite the success of diffusion models in image generation tasks such as text-to-image, the enormous computational complexity of diffusion models limits their use in resource-constrained environments. To address this, network quantization has emerged as a promising solution for designing efficient diffusion models. However, existing diffusion model quantization methods do not consider input conditions, such as text prompts, as an essential source of information for quantization. In this paper, we propose a novel quantization method dubbed Quantization of Language-to-Image diffusion models using text Prompts (QLIP). QLIP leverages text prompts to guide the selection of bit precision for every layer at each time step. In addition, QLIP can be seamlessly integrated into existing quantization methods to enhance quantization efficiency. Our extensive experiments demonstrate the effectiveness of QLIP in reducing computational complexity and improving the quality of the generated images across various datasets.",
      "authors": [
        "Hongjae Lee",
        "Myungjun Son",
        "Dongjea Kang",
        "Seung-Won Jung"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T14:44:59+00:00",
          "link": "https://arxiv.org/abs/2507.10340v1",
          "size": "35980kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T14:12:26+00:00",
          "link": "https://arxiv.org/abs/2507.10340v2",
          "size": "35980kb",
          "version": "v2"
        }
      ],
      "title": "Text Embedding Knows How to Quantize Text-Guided Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10340",
        "HTML": "https://arxiv.org/html/2507.10340v2",
        "PDF": "https://arxiv.org/pdf/2507.10340"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper discusses improvements in model efficiency through quantization of text-guided diffusion models, which is a method-related innovation instead of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10708",
      "abstract": "In this study we introduce a symbolic dataset composed of non-metric Iranian classical music, and algorithms for structural parsing of this music, and generation of variations. The corpus comprises MIDI files and data sheets of Dastgah Shour from Radif Mirza Abdollah, the foundational repertoire of Iranian classical music. Furthermore, we apply our previously-introduced algorithm for parsing melodic structure (Kanani et al., 2023b)to the dataset. Unlike much Western music, this type of non-metric music does not follow bar-centric organisation. The non-metric organisation can be captured well by our parsing algorithm. We parse each tune (Gusheh) into a grammar to identify motifs and phrases. These grammar representations can be useful for educational and ethnomusicological purposes. We also further develop a previously-introduced method of creating melodic variations (Kanani et al., 2023b). After parsing an existing tune to produce a grammar, by applying mutations to this grammar, we generate a new grammar. Expanding this new version yields a variation of the original tune. Variations are assessed by a domain-expert listener. Additionally, we conduct a statistical analysis of mutation with different representation setups for our parsing and generation algorithms. The overarching conclusion is that the system successfully produces acceptable variations post-mutation. While our case study focuses on Iranian classical music, the methodology can be adapted for Arabic or Turkish classical music.",
      "authors": [
        "Maziar Kanani",
        "Sean O Leary",
        "James McDermott"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:21:07+00:00",
          "link": "https://arxiv.org/abs/2507.10708v1",
          "size": "1034kb",
          "version": "v1"
        }
      ],
      "title": "Grammatical Structure and Grammatical Variations in Non-Metric Iranian Classical Music",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10708",
        "HTML": "https://arxiv.org/html/2507.10708v1",
        "PDF": "https://arxiv.org/pdf/2507.10708"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper introduces a symbolic dataset and develops algorithms for parsing and generating music variations, which include data processing aspects. However, it is focused more on music structure than LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10725",
      "abstract": "The relationship between computational models and dynamics has captivated mathematicians and computer scientists since the earliest conceptualizations of computation. Recently, this connection has gained renewed attention, fueled by T. Tao's programme aiming to discover blowing-up solutions of the Navier-Stokes equations using an embedded computational model. In this survey paper, we review some of the recent works that introduce novel and exciting perspectives on the representation of computability through dynamical systems. Starting from dynamical universality in a classical sense, we shall explore the modern notions of Turing universality in fluid dynamics and Topological Kleene Field Theories as a systematic way of representing computable functions by means of dynamical bordisms. Finally, we will discuss some important open problems in the area.",
      "authors": [
        "\\'Angel Gonz\\'alez-Prieto",
        "Eva Miranda",
        "Daniel Peralta-Salas"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Dynamical Systems (math.DS)",
        "Formal Languages and Automata Theory (cs.FL)",
        "Differential Geometry (math.DG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:46:58+00:00",
          "link": "https://arxiv.org/abs/2507.10725v1",
          "size": "136kb",
          "version": "v1"
        }
      ],
      "title": "Universality in computable dynamical systems: Old and new",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10725",
        "HTML": "https://arxiv.org/html/2507.10725v1",
        "PDF": "https://arxiv.org/pdf/2507.10725"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on the relationships between computational models and dynamics via dynamical systems, not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10869",
      "abstract": "Masked Autoencoders (MAEs) have emerged as a dominant strategy for self-supervised representation learning in natural images, where models are pre-trained to reconstruct masked patches with a pixel-wise mean squared error (MSE) between original and reconstructed RGB values as the loss. We observe that MSE encourages blurred image re-construction, but still works for natural images as it preserves dominant edges. However, in medical imaging, when the texture cues are more important for classification of a visual abnormality, the strategy fails. Taking inspiration from Gray Level Co-occurrence Matrix (GLCM) feature in Radiomics studies, we propose a novel MAE based pre-training framework, GLCM-MAE, using reconstruction loss based on matching GLCM. GLCM captures intensity and spatial relationships in an image, hence proposed loss helps preserve morphological features. Further, we propose a novel formulation to convert matching GLCM matrices into a differentiable loss function. We demonstrate that unsupervised pre-training on medical images with the proposed GLCM loss improves representations for downstream tasks. GLCM-MAE outperforms the current state-of-the-art across four tasks - gallbladder cancer detection from ultrasound images by 2.1%, breast cancer detection from ultrasound by 3.1%, pneumonia detection from x-rays by 0.5%, and COVID detection from CT by 0.6%. Source code and pre-trained models are available at: https://github.com/ChetanMadan/GLCM-MAE.",
      "authors": [
        "Chetan Madan",
        "Aarjav Satia",
        "Soumen Basu",
        "Pankaj Gupta",
        "Usha Dutta",
        "Chetan Arora"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T00:12:26+00:00",
          "link": "https://arxiv.org/abs/2507.10869v1",
          "size": "634kb",
          "version": "v1"
        }
      ],
      "title": "Focus on Texture: Rethinking Pre-training in Masked Autoencoders for Medical Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10869",
        "HTML": "https://arxiv.org/html/2507.10869v1",
        "PDF": "https://arxiv.org/pdf/2507.10869"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a novel pre-training framework for medical image classification using Masked Autoencoders, focusing on preserving texture features rather than any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11249",
      "abstract": "The linear regression model with a random variable (RV) measurement matrix, where the mean of the random measurement matrix has full column rank, has been extensively studied. In particular, the quasiconvexity of the maximum likelihood estimation (MLE) problem was established, and the corresponding Cramer-Rao bound (CRB) was derived, leading to the development of an efficient bisection-based algorithm known as RV-ML. In contrast, this work extends the analysis to both overdetermined and underdetermined cases, allowing the mean of the random measurement matrix to be rank-deficient. A remarkable contribution is the proof that the equivalent MLE problem is convex and satisfies strong duality, strengthening previous quasiconvexity results. Moreover, it is shown that in underdetermined scenarios, the randomness in the measurement matrix can be beneficial for estimation under certain conditions. In addition, a fast and unified implementation of the MLE solution, referred to as generalized RV-ML (GRV-ML), is proposed, which handles a more general case including both underdetermined and overdetermined systems. Extensive numerical simulations are provided to validate the theoretical findings.",
      "authors": [
        "Ruohai Guo",
        "Jiang Zhu",
        "Xing Jiang and Fengzhong Qu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:23:16+00:00",
          "link": "https://arxiv.org/abs/2507.11249v1",
          "size": "9059kb",
          "version": "v1"
        }
      ],
      "title": "Fast and Efficient Implementation of the Maximum Likelihood Estimation for the Linear Regression with Gaussian Model Uncertainty",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11249",
        "HTML": "https://arxiv.org/html/2507.11249v1",
        "PDF": "https://arxiv.org/pdf/2507.11249"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses maximum likelihood estimation in linear regression, which is unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "1805.10708",
      "abstract": "Algorithmic meta-theorems, stating that graph properties expressible in some particular logic can be decided efficiently in graph classes having some specific structural properties, are now standard in sequential graph algorithms. One of the most classic examples is Courcelle's theorem: all properties expressible in Monadic Second-Order logic (MSO) are decidable in linear time in graphs of bounded treewidth.\n  We provide here a distributed version of Courcelle's theorem, in the standard CONGEST model for distributed computing: For any MSO formula $\\varphi$ and any constant $k$, there is a CONGEST algorithm that, given an input communication network $G$ of treewidth at most $k$ and of diameter $D$, decides if $G$ satisfies property $\\varphi$ in $\\tilde O(D)$ rounds. Simple examples show that the dependency on $D$ is unavoidable. Also, if we drop the assumption of bounded treewidth, deciding MSO properties such as 3-colorability are known to require $\\tilde{\\Omega}(n^2)$ rounds in the CONGEST model. Our results extend to optimization problems (e.g., computing a maximum size independent set, or a minimum dominating set) and counting (e.g. triangle counting). As usual, the $\\tilde{O}$ notation hides polylogarithmic factors in $n$; here it also hides a constant factor depending on $k$ and on the MSO formula $\\varphi$.\n  We also give a distributed algorithm producing a linear approximation for treewidth: For any $k$, it decides that the treewidth of the input network $G$ is larger than $k$ or computes a tree decomposition of width $O(k)$ and depth $O(\\log n)$, in $\\tilde O(k^{O(k)} D)$ rounds in CONGEST.\n  Our algorithms make use of the low-congestion shortcuts framework introduced by Ghaffari and Haeupler [SODA 2016], and our main technical tool is an $\\tilde O(k^4 D)$ algorithm for computing $(s,t)$-vertex separators of size at most $k+1$ in graphs of treewidth at most $k$.",
      "authors": [
        "Benjamin Jauregui",
        "Jason Li",
        "Pedro Montealegre",
        "Ioan Todinca"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2018-05-27T23:01:25+00:00",
          "link": "https://arxiv.org/abs/1805.10708v1",
          "size": "99kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T18:48:35+00:00",
          "link": "https://arxiv.org/abs/1805.10708v2",
          "size": "210kb",
          "version": "v2"
        }
      ],
      "title": "Distributed Treewidth Computation and Courcelle's Theorem in the CONGEST Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/1805.10708",
        "PDF": "https://arxiv.org/pdf/1805.10708"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on distributed computing and graph algorithms, specifically adapting Courcelle's theorem to the CONGEST model, without any discussion on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10630",
      "abstract": "API calls by large language models (LLMs) offer a cutting-edge approach for data analysis. However, their ability to effectively utilize tools via API calls remains underexplored in knowledge-intensive domains like meteorology. This paper introduces KG2data, a system that integrates knowledge graphs, LLMs, ReAct agents, and tool-use technologies to enable intelligent data acquisition and query handling in the meteorological field. Using a virtual API, we evaluate API call accuracy across three metrics: name recognition failure, hallucination failure, and call correctness. KG2data achieves superior performance (1.43%, 0%, 88.57%) compared to RAG2data (16%, 10%, 72.14%) and chat2data (7.14%, 8.57%, 71.43%). KG2data differs from typical LLM-based systems by addressing their limited access to domain-specific knowledge, which hampers performance on complex or terminology-rich queries. By using a knowledge graph as persistent memory, our system enhances content retrieval, complex query handling, domain-specific reasoning, semantic relationship resolution, and heterogeneous data integration. It also mitigates the high cost of fine-tuning LLMs, making the system more adaptable to evolving domain knowledge and API structures. In summary, KG2data provides a novel solution for intelligent, knowledge-based question answering and data analysis in domains with high knowledge demands.",
      "authors": [
        "Ye Yang",
        "Xue Xiao",
        "Ping Yin",
        "Taotao Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T08:20:06+00:00",
          "link": "https://arxiv.org/abs/2507.10630v1",
          "size": "1599kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing the Capabilities of Large Language Models for API calls through Knowledge Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10630",
        "PDF": "https://arxiv.org/pdf/2507.10630"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions data acquisition and integration using knowledge graphs, but it focuses more on improving API usage rather than directly processing training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11038",
      "abstract": "WiFi received signal strength (RSS) environment evolves over time due to movement of access points (APs), AP power adjustment, installation and removal of APs, etc. We study how to effectively update an existing database of fingerprints, defined as the RSS values of APs at designated locations, using a batch of newly collected unlabelled (possibly crowdsourced) WiFi signals. Prior art either estimates the locations of the new signals without updating the existing fingerprints or filters out the new APs without sufficiently embracing their features. To address that, we propose GUFU, a novel effective graph-based approach to update WiFi fingerprints using unlabelled signals with possibly new APs. Based on the observation that similar signal vectors likely imply physical proximity, GUFU employs a graph neural network (GNN) and a link prediction algorithm to retrain an incremental network given the new signals and APs. After the retraining, it then updates the signal vectors at the designated locations. Through extensive experiments in four large representative sites, GUFU is shown to achieve remarkably higher fingerprint adaptivity as compared with other state-of-the-art approaches, with error reduction of 21.4% and 29.8% in RSS values and location prediction, respectively.",
      "authors": [
        "Ka Ho Chiu",
        "Handi Yin",
        "Weipeng Zhuo",
        "Chul-Ho Lee",
        "S.-H. Gary Chan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T07:05:20+00:00",
          "link": "https://arxiv.org/abs/2507.11038v1",
          "size": "1356kb",
          "version": "v1"
        }
      ],
      "title": "Graph-based Fingerprint Update Using Unlabelled WiFi Signals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11038",
        "HTML": "https://arxiv.org/html/2507.11038v1",
        "PDF": "https://arxiv.org/pdf/2507.11038"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a WiFi fingerprint update method and does not contribute to LLM training data processing or dataset construction."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11143",
      "abstract": "In recent years, landslide disasters have reported frequently due to the extreme weather events of droughts, floods , storms, or the consequence of human activities such as deforestation, excessive exploitation of natural resources. However, automatically observing landslide is challenging due to the extremely large observing area and the rugged topography such as mountain or highland. This motivates us to propose an end-to-end deep-learning-based model which explores the remote sensing images for automatically observing landslide events. By considering remote sensing images as the input data, we can obtain free resource, observe large and rough terrains by time. To explore the remote sensing images, we proposed a novel neural network architecture which is for two tasks of landslide detection and landslide segmentation. We evaluated our proposed model on three different benchmark datasets of LandSlide4Sense, Bijie, and Nepal. By conducting extensive experiments, we achieve F1 scores of 98.23, 93.83 for the landslide detection task on LandSlide4Sense, Bijie datasets; mIoU scores of 63.74, 76.88 on the segmentation tasks regarding LandSlide4Sense, Nepal datasets. These experimental results prove potential to integrate our proposed model into real-life landslide observation systems.",
      "authors": [
        "Lam Pham",
        "Cam Le",
        "Hieu Tang",
        "Khang Truong",
        "Truong Nguyen",
        "Jasmin Lampert",
        "Alexander Schindler",
        "Martin Boyer",
        "Son Phan"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:48:36+00:00",
          "link": "https://arxiv.org/abs/2507.11143v1",
          "size": "8219kb",
          "version": "v1"
        }
      ],
      "title": "RMAU-NET: A Residual-Multihead-Attention U-Net Architecture for Landslide Segmentation and Detection from Remote Sensing Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11143",
        "HTML": "https://arxiv.org/html/2507.11143v1",
        "PDF": "https://arxiv.org/pdf/2507.11143"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a novel neural network architecture for landslide detection and segmentation using remote sensing images, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11185",
      "abstract": "Heart disease remains a major global health concern, particularly in regions with limited access to medical resources and diagnostic facilities. Traditional diagnostic methods often fail to accurately identify and manage heart disease risks, leading to adverse outcomes. Machine learning has the potential to significantly enhance the accuracy, efficiency, and speed of heart disease diagnosis. In this study, we proposed a comprehensive framework that combines classification models for heart disease detection and regression models for risk prediction. We employed the Heart Disease dataset, which comprises 1,035 cases. To address the issue of class imbalance, the Synthetic Minority Oversampling Technique (SMOTE) was applied, resulting in the generation of an additional 100,000 synthetic data points. Performance metrics, including accuracy, precision, recall, F1-score, R2, MSE, RMSE, and MAE, were used to evaluate the model's effectiveness. Among the classification models, Random Forest emerged as the standout performer, achieving an accuracy of 97.2% on real data and 97.6% on synthetic data. For regression tasks, Linear Regression demonstrated the highest R2 values of 0.992 and 0.984 on real and synthetic datasets, respectively, with the lowest error metrics. Additionally, Explainable AI techniques were employed to enhance the interpretability of the models. This study highlights the potential of machine learning to revolutionize heart disease diagnosis and risk prediction, thereby facilitating early intervention and enhancing clinical decision-making.",
      "authors": [
        "Md. Emon Akter Sourov",
        "Md. Sabbir Hossen",
        "Pabon Shaha",
        "Mohammad Minoar Hossain",
        "and Md Sadiq Iqbal"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:38:38+00:00",
          "link": "https://arxiv.org/abs/2507.11185v1",
          "size": "6591kb",
          "version": "v1"
        }
      ],
      "title": "An Explainable AI-Enhanced Machine Learning Approach for Cardiovascular Disease Detection and Risk Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11185",
        "HTML": "https://arxiv.org/html/2507.11185v1",
        "PDF": "https://arxiv.org/pdf/2507.11185"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper presents a machine learning approach for cardiovascular disease detection using existing data, without making contributions to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11411",
      "abstract": "Multi-task learning (MTL) has shown effectiveness in exploiting shared information across tasks to improve generalization. MTL assumes tasks share similarities that can improve performance. In addition, boosting algorithms have demonstrated exceptional performance across diverse learning problems, primarily due to their ability to focus on hard-to-learn instances and iteratively reduce residual errors. This makes them a promising approach for learning multi-task problems. However, real-world MTL scenarios often involve tasks that are not well-aligned (known as outlier or adversarial tasks), which do not share beneficial similarities with others and can, in fact, deteriorate the performance of the overall model. To overcome this challenge, we propose Robust-Multi-Task Gradient Boosting (R-MTGB), a novel boosting framework that explicitly models and adapts to task heterogeneity during training. R-MTGB structures the learning process into three sequential blocks: (1) learning shared patterns, (2) partitioning tasks into outliers and non-outliers with regularized parameters, and (3) fine-tuning task-specific predictors. This architecture enables R-MTGB to automatically detect and penalize outlier tasks while promoting effective knowledge transfer among related tasks. Our method integrates these mechanisms seamlessly within gradient boosting, allowing robust handling of noisy or adversarial tasks without sacrificing accuracy. Extensive experiments on both synthetic benchmarks and real-world datasets demonstrate that our approach successfully isolates outliers, transfers knowledge, and consistently reduces prediction errors for each task individually, and achieves overall performance gains across all tasks. These results highlight robustness, adaptability, and reliable convergence of R-MTGB in challenging MTL environments.",
      "authors": [
        "Seyedsaman Emami",
        "Gonzalo Mart\\'inez-Mu\\~noz",
        "Daniel Hern\\'andez-Lobato"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T15:31:12+00:00",
          "link": "https://arxiv.org/abs/2507.11411v1",
          "size": "460kb",
          "version": "v1"
        }
      ],
      "title": "Robust-Multi-Task Gradient Boosting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11411",
        "HTML": "https://arxiv.org/html/2507.11411v1",
        "PDF": "https://arxiv.org/pdf/2507.11411"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a new multi-task learning framework focusing on modeling and adapting to task heterogeneity, with no discussion on processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11531",
      "abstract": "Neural populations exhibit latent dynamical structures that drive time-evolving spiking activities, motivating the search for models that capture both intrinsic network dynamics and external unobserved influences. In this work, we introduce LangevinFlow, a sequential Variational Auto-Encoder where the time evolution of latent variables is governed by the underdamped Langevin equation. Our approach incorporates physical priors -- such as inertia, damping, a learned potential function, and stochastic forces -- to represent both autonomous and non-autonomous processes in neural systems. Crucially, the potential function is parameterized as a network of locally coupled oscillators, biasing the model toward oscillatory and flow-like behaviors observed in biological neural populations. Our model features a recurrent encoder, a one-layer Transformer decoder, and Langevin dynamics in the latent space. Empirically, our method outperforms state-of-the-art baselines on synthetic neural populations generated by a Lorenz attractor, closely matching ground-truth firing rates. On the Neural Latents Benchmark (NLB), the model achieves superior held-out neuron likelihoods (bits per spike) and forward prediction accuracy across four challenging datasets. It also matches or surpasses alternative methods in decoding behavioral metrics such as hand velocity. Overall, this work introduces a flexible, physics-inspired, high-performing framework for modeling complex neural population dynamics and their unobserved influences.",
      "authors": [
        "Yue Song",
        "T. Anderson Keller",
        "Yisong Yue",
        "Pietro Perona",
        "Max Welling"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:57:48+00:00",
          "link": "https://arxiv.org/abs/2507.11531v1",
          "size": "4520kb",
          "version": "v1"
        }
      ],
      "title": "Langevin Flows for Modeling Neural Latent Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11531",
        "HTML": "https://arxiv.org/html/2507.11531v1",
        "PDF": "https://arxiv.org/pdf/2507.11531"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on modeling neural latent dynamics using Langevin flows and does not involve processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2407.10867",
      "abstract": "Generalization of machine learning models can be severely compromised by data poisoning, where adversarial changes are applied to the training data. This vulnerability has led to interest in certifying (i.e., proving) that such changes up to a certain magnitude do not affect test predictions. We, for the first time, certify Graph Neural Networks (GNNs) against poisoning attacks, including backdoors, targeting the node features of a given graph. Our certificates are white-box and based upon $(i)$ the neural tangent kernel, which characterizes the training dynamics of sufficiently wide networks; and $(ii)$ a novel reformulation of the bilevel optimization problem describing poisoning as a mixed-integer linear program. Consequently, we leverage our framework to provide fundamental insights into the role of graph structure and its connectivity on the worst-case robustness behavior of convolution-based and PageRank-based GNNs. We note that our framework is more general and constitutes the first approach to derive white-box poisoning certificates for NNs, which can be of independent interest beyond graph-related tasks.",
      "authors": [
        "Lukas Gosch and Mahalakshmi Sabanayagam and Debarghya Ghoshdastidar and Stephan G\\\"unnemann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-15T16:12:51+00:00",
          "link": "https://arxiv.org/abs/2407.10867v1",
          "size": "4888kb",
          "version": "v1"
        },
        {
          "date": "2024-10-14T13:23:58+00:00",
          "link": "https://arxiv.org/abs/2407.10867v2",
          "size": "8658kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T11:31:28+00:00",
          "link": "https://arxiv.org/abs/2407.10867v3",
          "size": "10578kb",
          "version": "v3"
        }
      ],
      "title": "Provable Robustness of (Graph) Neural Networks Against Data Poisoning and Backdoor Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.10867",
        "HTML": "https://arxiv.org/html/2407.10867v3",
        "PDF": "https://arxiv.org/pdf/2407.10867"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper is concerned with certifying Graph Neural Networks against data poisoning, and does not involve any LLM training data processing or dataset creation."
      },
      "tasks": [
        "Bilevel Optimization",
        "Data Poisoning"
      ],
      "repo_urls": [
        "https://github.com/saper0/qpcert"
      ],
      "source": "arXiv"
    },
    {
      "id": "2507.09469",
      "abstract": "For precise, efficient, and safe drone landings, ground platforms should real-time, accurately locate descending drones and guide them to designated spots. While mmWave sensing combined with cameras improves localization accuracy, lower sampling frequency of traditional frame cameras compared to mmWave radar creates bottlenecks in system throughput. In this work, we upgrade traditional frame camera with event camera, a novel sensor that harmonizes in sampling frequency with mmWave radar within ground platform setup, and introduce mmE-Loc, a high-precision, low-latency ground localization system designed for precise drone landings. To fully exploit the \\textit{temporal consistency} and \\textit{spatial complementarity} between these two modalities, we propose two innovative modules: \\textit{(i)} the Consistency-instructed Collaborative Tracking module, which further leverages the drone's physical knowledge of periodic micro-motions and structure for accurate measurements extraction, and \\textit{(ii)} the Graph-informed Adaptive Joint Optimization module, which integrates drone motion information for efficient sensor fusion and drone localization. Real-world experiments conducted in landing scenarios with a drone delivery company demonstrate that mmE-Loc significantly outperforms state-of-the-art methods in both accuracy and latency.",
      "authors": [
        "Haoyang Wang",
        "Jingao Xu",
        "Xinyu Luo",
        "Ting Zhang",
        "Xuecheng Chen",
        "Ruiyang Duan",
        "Jialong Chen",
        "Yunhao Liu",
        "Jianfeng Zheng",
        "Weijie Hong",
        "Xinlei Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-13T03:06:12+00:00",
          "link": "https://arxiv.org/abs/2507.09469v1",
          "size": "12798kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T02:23:03+00:00",
          "link": "https://arxiv.org/abs/2507.09469v2",
          "size": "12798kb",
          "version": "v2"
        }
      ],
      "title": "mmE-Loc: Facilitating Accurate Drone Landing with Ultra-High-Frequency Localization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.09469",
        "HTML": "https://arxiv.org/html/2507.09469v2",
        "PDF": "https://arxiv.org/pdf/2507.09469"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on drone landing and localization systems, not on LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10731",
      "abstract": "We consider random walks on ``balanced multislices'' of any ``grid'' that respects the ``symmetries'' of the grid, and show that a broad class of such walks are good spectral expanders. (A grid is a set of points of the form $\\mathcal{S}^n$ for finite $\\mathcal{S}$, and a balanced multi-slice is the subset that contains an equal number of coordinates taking every value in $\\mathcal{S}$. A walk respects symmetries if the probability of going from $u = (u_1,\\ldots,u_n)$ to $v = (v_1,\\ldots,v_n)$ is invariant under simultaneous permutations of the coordinates of $u$ and $v$.) Our main theorem shows that, under some technical conditions, every such walk where a single step leads to an almost $\\mathcal{O}(1)$-wise independent distribution on the next state, conditioned on the previous state, satisfies a non-trivially small singular value bound.\n  We give two applications of our theorem to error-correcting codes: (1) We give an analog of the Ore-DeMillo-Lipton-Schwartz-Zippel lemma for polynomials, and junta-sums, over balanced multislices. (2) We also give a local list-correction algorithm for $d$-junta-sums mapping an arbitrary grid $\\mathcal{S}^n$ to an Abelian group, correcting from a near-optimal $(\\frac{1}{|\\mathcal{S}|^{d}} - \\varepsilon)$ fraction of errors for every $\\varepsilon > 0$, where a $d$-junta-sum is a sum of (arbitrarily many) $d$-juntas (and a $d$-junta is a function that depends on only $d$ of the $n$ variables).\n  Our proofs are obtained by exploring the representation theory of the symmetric group and merging it with some careful spectral analysis.",
      "authors": [
        "Prashanth Amireddy",
        "Amik Raj Behera",
        "Srikanth Srinivasan",
        "Madhu Sudan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:54:16+00:00",
          "link": "https://arxiv.org/abs/2507.10731v1",
          "size": "107kb",
          "version": "v1"
        }
      ],
      "title": "Eigenvalue Bounds for Symmetric Markov Chains on Multislices With Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10731",
        "PDF": "https://arxiv.org/pdf/2507.10731"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on random walks and spectral expanders in graph theory, with applications to error-correcting codes, not on processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10990",
      "abstract": "Scaling reinforcement learning (RL) workloads often requires distributing environment simulation across compute clusters. Existing frameworks entangle simulation, learning logic, and orchestration into monolithic systems, limiting modularity and reusability. We present ClusterEnv, a lightweight, learner-agnostic interface for distributed environment execution that mirrors the Gymnasium API. ClusterEnv introduces the DETACH pattern, which decouples simulation from training by offloading reset() and step() operations to remote workers while keeping learning centralized. To address policy staleness in distributed execution, we propose Adaptive Actor Policy Synchronization (AAPS), a divergence-triggered update mechanism that reduces synchronization overhead without sacrificing performance. ClusterEnv integrates cleanly into existing RL pipelines, supports both on-policy and off-policy methods, and requires minimal code changes. Experiments on discrete control tasks demonstrate that AAPS achieves high sample efficiency with significantly fewer weight updates. Source code is available at https://github.com/rodlaf/ClusterEnv.",
      "authors": [
        "Rodney Lafuente-Mercado"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T05:07:12+00:00",
          "link": "https://arxiv.org/abs/2507.10990v1",
          "size": "841kb",
          "version": "v1"
        }
      ],
      "title": "High-Throughput Distributed Reinforcement Learning via Adaptive Policy Synchronization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10990",
        "HTML": "https://arxiv.org/html/2507.10990v1",
        "PDF": "https://arxiv.org/pdf/2507.10990"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses reinforcement learning and distributed environment execution, with no mention of LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11381",
      "abstract": "We propose a framework for building patient-specific treatment recommendation models, building on the large recent literature on learning patient-level causal models and inspired by the target trial paradigm of Hernan and Robins. We focus on safety and validity, including the crucial issue of causal identification when using observational data. We do not provide a specific model, but rather a way to integrate existing methods and know-how into a practical pipeline. We further provide a real world use-case of treatment optimization for patients with heart failure who develop acute kidney injury during hospitalization. The results suggest our pipeline can improve patient outcomes over the current treatment regime.",
      "authors": [
        "Rom Gutman",
        "Shimon Sheiba",
        "Omer Noy Klien",
        "Naama Dekel Bird",
        "Amit Gruber",
        "Doron Aronson",
        "Oren Caspi",
        "Uri Shalit"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:50:41+00:00",
          "link": "https://arxiv.org/abs/2507.11381v1",
          "size": "6883kb",
          "version": "v1"
        }
      ],
      "title": "From Observational Data to Clinical Recommendations: A Causal Framework for Estimating Patient-level Treatment Effects and Learning Policies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11381",
        "HTML": "https://arxiv.org/html/2507.11381v1",
        "PDF": "https://arxiv.org/pdf/2507.11381"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a framework for patient-specific treatment models using observational data but does not involve any processing or engineering of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21246",
      "abstract": "This study investigates the impact of data source diversity on the performance of cryptocurrency forecasting models by integrating various data categories, including technical indicators, on-chain metrics, sentiment and interest metrics, traditional market indices, and macroeconomic indicators. We introduce the Crypto100 index, representing the top 100 cryptocurrencies by market capitalization, and propose a novel feature reduction algorithm to identify the most impactful and resilient features from diverse data sources. Our comprehensive experiments demonstrate that data source diversity significantly enhances the predictive performance of forecasting models across different time horizons. Key findings include the paramount importance of on-chain metrics for both short-term and long-term predictions, the growing relevance of traditional market indices and macroeconomic indicators for longer-term forecasts, and substantial improvements in model accuracy when diverse data sources are utilized. These insights help demystify the short-term and long-term driving factors of the cryptocurrency market and lay the groundwork for developing more accurate and resilient forecasting models.",
      "authors": [
        "Giorgos Demosthenous",
        "Chryssis Georgiou",
        "Eliada Polydorou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Portfolio Management (q-fin.PM)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)",
        "Statistical Finance (q-fin.ST)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T13:29:19+00:00",
          "link": "https://arxiv.org/abs/2506.21246v1",
          "size": "2117kb",
          "version": "v1"
        }
      ],
      "title": "From On-chain to Macro: Assessing the Importance of Data Source Diversity in Cryptocurrency Market Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21246",
        "HTML": "https://arxiv.org/html/2506.21246",
        "PDF": "https://arxiv.org/pdf/2506.21246"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The study examines the diversity of data sources on cryptocurrency forecasting, without involvement in LLM training data processing or dataset creation for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.00917",
      "abstract": "The pursuit of artificial general intelligence (AGI) has placed embodied intelligence at the forefront of robotics research. Embodied intelligence focuses on agents capable of perceiving, reasoning, and acting within the physical world. Achieving robust embodied intelligence requires not only advanced perception and control, but also the ability to ground abstract cognition in real-world interactions. Two foundational technologies, physical simulators and world models, have emerged as critical enablers in this quest. Physical simulators provide controlled, high-fidelity environments for training and evaluating robotic agents, allowing safe and efficient development of complex behaviors. In contrast, world models empower robots with internal representations of their surroundings, enabling predictive planning and adaptive decision-making beyond direct sensory input. This survey systematically reviews recent advances in learning embodied AI through the integration of physical simulators and world models. We analyze their complementary roles in enhancing autonomy, adaptability, and generalization in intelligent robots, and discuss the interplay between external simulation and internal modeling in bridging the gap between simulated training and real-world deployment. By synthesizing current progress and identifying open challenges, this survey aims to provide a comprehensive perspective on the path toward more capable and generalizable embodied AI systems. We also maintain an active repository that contains up-to-date literature and open-source projects at https://github.com/NJU3DV-LoongGroup/Embodied-World-Models-Survey.",
      "authors": [
        "Xiaoxiao Long",
        "Qingrui Zhao",
        "Kaiwen Zhang",
        "Zihao Zhang",
        "Dingrui Wang",
        "Yumeng Liu",
        "Zhengjie Shu",
        "Yi Lu",
        "Shouzheng Wang",
        "Xinzhe Wei",
        "Wei Li",
        "Wei Yin",
        "Yao Yao",
        "Jia Pan",
        "Qiu Shen",
        "Ruigang Yang",
        "Xun Cao",
        "Qionghai Dai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-01T16:23:00+00:00",
          "link": "https://arxiv.org/abs/2507.00917v1",
          "size": "25019kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T16:06:05+00:00",
          "link": "https://arxiv.org/abs/2507.00917v2",
          "size": "25049kb",
          "version": "v2"
        }
      ],
      "title": "A Survey: Learning Embodied Intelligence from Physical Simulators and World Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.00917",
        "HTML": "https://arxiv.org/html/2507.00917v2",
        "PDF": "https://arxiv.org/pdf/2507.00917"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This is a survey paper discussing embodied intelligence in robotics, focusing on physical simulators and world models, not related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10594",
      "abstract": "Online learning, where feature spaces can change over time, offers a flexible learning paradigm that has attracted considerable attention. However, it still faces three significant challenges. First, the heterogeneity of real-world data streams with mixed feature types presents challenges for traditional parametric modeling. Second, data stream distributions can shift over time, causing an abrupt and substantial decline in model performance. Third, it is often infeasible to label every data instance due to time and cost constraints. To address these issues, we proposed OL-MDISF (Online Learning from Mix-typed, Drifted, and Incomplete Streaming Features), which constructs a latent copula-based representation for heterogeneous features, detects drifts via ensemble entropy and latent mismatch, and performs structure-aware pseudo-labeling.\n  This companion paper serves as a standalone technical reference to OL-MDISF. It provides a contextual discussion of related work in mixed-type modeling, drift adaptation, and weak supervision, as well as a comprehensive set of experiments across 14 real-world datasets under two types of drift scenarios. These include CER trends, ablation studies, sensitivity analyses, and temporal ensemble dynamics. We hope this document offers a reproducible benchmark for online learning on complex, weakly supervised streaming data.",
      "authors": [
        "Shengda Zhuo",
        "Di Wu",
        "Yi He",
        "Shuqiang Huang",
        "Xindong Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T02:44:25+00:00",
          "link": "https://arxiv.org/abs/2507.10594v1",
          "size": "1298kb",
          "version": "v1"
        }
      ],
      "title": "Extension OL-MDISF: Online Learning from Mix-Typed, Drifted, and Incomplete Streaming Features",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10594",
        "HTML": "https://arxiv.org/html/2507.10594v1",
        "PDF": "https://arxiv.org/pdf/2507.10594"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper addresses online learning with mixed, drifted, and incomplete streaming features, which may involve some data processing, but the primary focus is not on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11137",
      "abstract": "As valuable digital assets, deep neural networks necessitate robust ownership protection, positioning neural network watermarking (NNW) as a promising solution. Among various NNW approaches, weight-based methods are favored for their simplicity and practicality; however, they remain vulnerable to forging and overwriting attacks. To address those challenges, we propose NeuralMark, a robust method built around a hashed watermark filter. Specifically, we utilize a hash function to generate an irreversible binary watermark from a secret key, which is then used as a filter to select the model parameters for embedding. This design cleverly intertwines the embedding parameters with the hashed watermark, providing a robust defense against both forging and overwriting attacks. An average pooling is also incorporated to resist fine-tuning and pruning attacks. Furthermore, it can be seamlessly integrated into various neural network architectures, ensuring broad applicability. Theoretically, we analyze its security boundary. Empirically, we verify its effectiveness and robustness across 13 distinct Convolutional and Transformer architectures, covering five image classification tasks and one text generation task. The source codes are available at https://github.com/AIResearch-Group/NeuralMark.",
      "authors": [
        "Yuan Yao",
        "Jin Song",
        "Jian Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T09:38:11+00:00",
          "link": "https://arxiv.org/abs/2507.11137v1",
          "size": "1830kb",
          "version": "v1"
        }
      ],
      "title": "Hashed Watermark as a Filter: Defeating Forging and Overwriting Attacks in Weight-based Neural Network Watermarking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11137",
        "HTML": "https://arxiv.org/html/2507.11137v1",
        "PDF": "https://arxiv.org/pdf/2507.11137"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses neural network watermarking methods for ownership protection and doesn't relate to processing training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11535",
      "abstract": "Standard Bayesian approaches for linear time-invariant (LTI) system identification are hindered by parameter non-identifiability; the resulting complex, multi-modal posteriors make inference inefficient and impractical. We solve this problem by embedding canonical forms of LTI systems within the Bayesian framework. We rigorously establish that inference in these minimal parameterizations fully captures all invariant system dynamics (e.g., transfer functions, eigenvalues, predictive distributions of system outputs) while resolving identifiability. This approach unlocks the use of meaningful, structure-aware priors (e.g., enforcing stability via eigenvalues) and ensures conditions for a Bernstein--von Mises theorem -- a link between Bayesian and frequentist large-sample asymptotics that is broken in standard forms. Extensive simulations with modern MCMC methods highlight advantages over standard parameterizations: canonical forms achieve higher computational efficiency, generate interpretable and well-behaved posteriors, and provide robust uncertainty estimates, particularly from limited data.",
      "authors": [
        "Andrey Bryutkin",
        "Matthew E. Levine",
        "I\\~nigo Urteaga",
        "Youssef Marzouk"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:58:55+00:00",
          "link": "https://arxiv.org/abs/2507.11535v1",
          "size": "21059kb",
          "version": "v1"
        }
      ],
      "title": "Canonical Bayesian Linear System Identification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11535",
        "HTML": "https://arxiv.org/html/2507.11535v1",
        "PDF": "https://arxiv.org/pdf/2507.11535"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper discusses Bayesian approaches for linear system identification and does not involve LLM training data processing or preparation."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.03262",
      "abstract": "Visual anomaly detection aims to identify anomalous regions in images through unsupervised learning paradigms, with increasing application demand and value in fields such as industrial inspection and medical lesion detection. Despite significant progress in recent years, there is a lack of comprehensive benchmarks to adequately evaluate the performance of various mainstream methods across different datasets under the practical multi-class setting. The absence of standardized experimental setups can lead to potential biases in training epochs, resolution, and metric results, resulting in erroneous conclusions. This paper addresses this issue by proposing a comprehensive visual anomaly detection benchmark, ADer, which is a modular framework that is highly extensible for new methods. The benchmark includes multiple datasets from industrial and medical domains, implementing fifteen state-of-the-art methods and nine comprehensive metrics. Additionally, we have proposed the GPU-assisted ADEval package to address the slow evaluation problem of metrics like time-consuming mAU-PRO on large-scale data, significantly reducing evaluation time by more than \\textit{1000-fold}. Through extensive experimental results, we objectively reveal the strengths and weaknesses of different methods and provide insights into the challenges and future directions of multi-class visual anomaly detection. We hope that ADer will become a valuable resource for researchers and practitioners in the field, promoting the development of more robust and generalizable anomaly detection systems. Full codes are open-sourced at https://github.com/zhangzjn/ader.",
      "authors": [
        "Jiangning Zhang",
        "Haoyang He",
        "Zhenye Gan",
        "Qingdong He",
        "Yuxuan Cai",
        "Zhucun Xue",
        "Yabiao Wang",
        "Chengjie Wang",
        "Lei Xie",
        "Yong Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-05T13:40:07+00:00",
          "link": "https://arxiv.org/abs/2406.03262v1",
          "size": "1214kb",
          "version": "v1"
        },
        {
          "date": "2024-06-06T07:20:10+00:00",
          "link": "https://arxiv.org/abs/2406.03262v2",
          "size": "1208kb",
          "version": "v2"
        },
        {
          "date": "2024-09-30T13:19:43+00:00",
          "link": "https://arxiv.org/abs/2406.03262v3",
          "size": "7208kb",
          "version": "v3"
        },
        {
          "date": "2025-07-15T06:17:54+00:00",
          "link": "https://arxiv.org/abs/2406.03262v4",
          "size": "7078kb",
          "version": "v4"
        }
      ],
      "title": "A Comprehensive Library for Benchmarking Multi-class Visual Anomaly Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.03262",
        "HTML": "https://arxiv.org/html/2406.03262v4",
        "PDF": "https://arxiv.org/pdf/2406.03262"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on creating benchmarks for visual anomaly detection and not on any aspect of LLM training data processing."
      },
      "tasks": [
        "Anomaly Detection",
        "Benchmarking",
        "Lesion Detection",
        "Multi-class Anomaly Detection"
      ],
      "repo_urls": [
        "https://github.com/zhangzjn/ader"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.11299",
      "abstract": "Spatial audio is a crucial component in creating immersive experiences. Traditional simulation-based approaches to generate spatial audio rely on expertise, have limited scalability, and assume independence between semantic and spatial information. To address these issues, we explore end-to-end spatial audio generation. We introduce and formulate a new task of generating first-order Ambisonics (FOA) given a sound category and sound source spatial location. We propose Diff-SAGe, an end-to-end, flow-based diffusion-transformer model for this task. Diff-SAGe utilizes a complex spectrogram representation for FOA, preserving the phase information crucial for accurate spatial cues. Additionally, a multi-conditional encoder integrates the input conditions into a unified representation, guiding the generation of FOA waveforms from noise. Through extensive evaluations on two datasets, we demonstrate that our method consistently outperforms traditional simulation-based baselines across both objective and subjective metrics.",
      "authors": [
        "Saksham Singh Kushwaha",
        "Jianbo Ma",
        "Mark R. P. Thomas",
        "Yapeng Tian",
        "Avery Bruni"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-15T05:37:22+00:00",
          "link": "https://arxiv.org/abs/2410.11299v1",
          "size": "1846kb",
          "version": "v1"
        }
      ],
      "title": "Diff-SAGe: End-to-End Spatial Audio Generation Using Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.11299",
        "HTML": "https://arxiv.org/html/2410.11299",
        "PDF": "https://arxiv.org/pdf/2410.11299"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on spatial audio generation using diffusion models, without discussing LLM training data processing, collection, or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2502.01706",
      "abstract": "Biologically inspired neural networks offer alternative avenues to model data distributions. FlyVec is a recent example that draws inspiration from the fruit fly's olfactory circuit to tackle the task of learning word embeddings. Surprisingly, this model performs competitively even against deep learning approaches specifically designed to encode text, and it does so with the highest degree of computational efficiency. We pose the question of whether this performance can be improved further. For this, we introduce Comply. By incorporating positional information through complex weights, we enable a single-layer neural network to learn sequence representations. Our experiments show that Comply not only supersedes FlyVec but also performs on par with significantly larger state-of-the-art models. We achieve this without additional parameters. Comply yields sparse contextual representations of sentences that can be interpreted explicitly from the neuron weights.",
      "authors": [
        "Alexei Figueroa",
        "Justus Westerhoff",
        "Golzar Atefi",
        "Dennis Fast",
        "Benjamin Winter",
        "Felix Alexander Gers",
        "Alexander L\\\"oser",
        "Wolfgang Nejdl"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-03T13:30:44+00:00",
          "link": "https://arxiv.org/abs/2502.01706v1",
          "size": "246kb",
          "version": "v1"
        },
        {
          "date": "2025-02-05T14:17:37+00:00",
          "link": "https://arxiv.org/abs/2502.01706v2",
          "size": "246kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T07:52:08+00:00",
          "link": "https://arxiv.org/abs/2502.01706v3",
          "size": "246kb",
          "version": "v3"
        }
      ],
      "title": "Comply: Learning Sentences with Complex Weights inspired by Fruit Fly Olfaction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.01706",
        "HTML": "https://arxiv.org/html/2502.01706v3",
        "PDF": "https://arxiv.org/pdf/2502.01706"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses a biologically inspired neural network for learning word embeddings, but focuses on model architecture rather than processing or creating training data for LLMs."
      },
      "tasks": [
        "Computational Efficiency",
        "Learning Word Embeddings",
        "Word Embeddings"
      ],
      "repo_urls": [
        "https://github.com/datexis/comply"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.11355",
      "abstract": "A fundamental task in quantum information science is state certification: testing whether a lab-prepared $n$-qubit state is close to a given hypothesis state. In this work, we show that every pure hypothesis state can be certified using only $O(n^2)$ single-qubit measurements applied to $O(n)$ copies of the lab state. Prior to our work, it was not known whether even subexponentially many single-qubit measurements could suffice to certify arbitrary states. This resolves the main open question of Huang, Preskill, and Soleimanifar (FOCS 2024, QIP 2024).\n  Our algorithm also showcases the power of adaptive measurements: within each copy of the lab state, previous measurement outcomes dictate how subsequent qubit measurements are made. We show that the adaptivity is necessary, by proving an exponential lower bound on the number of copies needed for any nonadaptive single-qubit measurement algorithm.",
      "authors": [
        "Meghal Gupta",
        "William He",
        "Ryan O'Donnell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T23:08:09+00:00",
          "link": "https://arxiv.org/abs/2506.11355v1",
          "size": "16kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T16:16:12+00:00",
          "link": "https://arxiv.org/abs/2506.11355v2",
          "size": "25kb",
          "version": "v2"
        }
      ],
      "title": "Few Single-Qubit Measurements Suffice to Certify Any Quantum State",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11355",
        "PDF": "https://arxiv.org/pdf/2506.11355"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper is about certifying quantum states and does not discuss any aspect of LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10563",
      "abstract": "With increasing wastewater rates, achieving energy-neutral purification is challenging. We introduce a coral-reef-inspired Swarm Interaction Network for carbon-neutral wastewater treatment, combining morphogenetic abstraction with multi-task carbon awareness. Scalability stems from linear token complexity, mitigating the energy-removal problem. Compared with seven baselines, our approach achieves 96.7\\% removal efficiency, 0.31~kWh~m$^{-3}$ energy consumption, and 14.2~g~m$^{-3}$ CO$_2$ emissions. Variance analysis demonstrates robustness under sensor drift. Field scenarios--insular lagoons, brewery spikes, and desert greenhouses--show potential diesel savings of up to 22\\%. However, data-science staffing remains an impediment. Future work will integrate AutoML wrappers within the project scope, although governance restrictions pose interpretability challenges that require further visual analytics.",
      "authors": [
        "Antonis Messinis"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-05T16:19:42+00:00",
          "link": "https://arxiv.org/abs/2507.10563v1",
          "size": "542kb",
          "version": "v1"
        }
      ],
      "title": "A Biomimetic Way for Coral-Reef-Inspired Swarm Intelligence for Carbon-Neutral Wastewater Treatment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10563",
        "HTML": "https://arxiv.org/html/2507.10563v1",
        "PDF": "https://arxiv.org/pdf/2507.10563"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This work discusses a swarm intelligence approach for carbon-neutral wastewater treatment without mentioning LLM training data processing or data engineering for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10710",
      "abstract": "This article introduces a novel, geometric approach for multi-manifold clustering (MMC), i.e. for clustering a collection of potentially intersecting, d-dimensional manifolds into the individual manifold components. We first compute a locality graph on d-simplices, using the dihedral angle in between adjacent simplices as the graph weights, and then compute infinity path distances in this simplex graph. This procedure gives a metric on simplices which we refer to as the largest angle path distance (LAPD). We analyze the properties of LAPD under random sampling, and prove that with an appropriate denoising procedure, this metric separates the manifold components with high probability. We validate the proposed methodology with extensive numerical experiments on both synthetic and real-world data sets. These experiments demonstrate that the method is robust to noise, curvature, and small intersection angle, and generally out-performs other MMC algorithms. In addition, we provide a highly scalable implementation of the proposed algorithm, which leverages approximation schemes for infinity path distance to achieve quasi-linear computational complexity.",
      "authors": [
        "Haoyu Chen",
        "Anna Little",
        "Akin Narayan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T18:22:50+00:00",
          "link": "https://arxiv.org/abs/2507.10710v1",
          "size": "1010kb",
          "version": "v1"
        }
      ],
      "title": "Robust Multi-Manifold Clustering via Simplex Paths",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10710",
        "HTML": "https://arxiv.org/html/2507.10710v1",
        "PDF": "https://arxiv.org/pdf/2507.10710"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a geometric approach for multi-manifold clustering, which does not involve processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10977",
      "abstract": "Human-object interaction (HOI) detection is essential for accurately localizing and characterizing interactions between humans and objects, providing a comprehensive understanding of complex visual scenes across various domains. However, existing HOI detectors often struggle to deliver reliable predictions efficiently, relying on resource-intensive training methods and inefficient architectures. To address these challenges, we conceptualize a wavelet attention-like backbone and a novel ray-based encoder architecture tailored for HOI detection. Our wavelet backbone addresses the limitations of expressing middle-order interactions by aggregating discriminative features from the low- and high-order interactions extracted from diverse convolutional filters. Concurrently, the ray-based encoder facilitates multi-scale attention by optimizing the focus of the decoder on relevant regions of interest and mitigating computational overhead. As a result of harnessing the attenuated intensity of learnable ray origins, our decoder aligns query embeddings with emphasized regions of interest for accurate predictions. Experimental results on benchmark datasets, including ImageNet and HICO-DET, showcase the potential of our proposed architecture. The code is publicly available at [https://github.com/henry-pay/RayEncoder].",
      "authors": [
        "Quan Bi Pay",
        "Vishnu Monn Baskaran",
        "Junn Yong Loo",
        "KokSheik Wong and Simon See"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T04:44:54+00:00",
          "link": "https://arxiv.org/abs/2507.10977v1",
          "size": "18905kb",
          "version": "v1"
        }
      ],
      "title": "Conceptualizing Multi-scale Wavelet Attention and Ray-based Encoding for Human-Object Interaction Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10977",
        "HTML": "https://arxiv.org/html/2507.10977v1",
        "PDF": "https://arxiv.org/pdf/2507.10977"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes new model architectures for human-object interaction detection and does not discuss LLM training data processing or dataset creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06513",
      "abstract": "Advances in vision-based sensors and computer vision algorithms have significantly improved the analysis and understanding of traffic scenarios. To facilitate the use of these improvements for road safety, this survey systematically categorizes the critical elements that demand attention in traffic scenarios and comprehensively analyzes available vision-driven tasks and datasets. Compared to existing surveys that focus on isolated domains, our taxonomy categorizes attention-worthy traffic entities into two main groups that are anomalies and normal but critical entities, integrating ten categories and twenty subclasses. It establishes connections between inherently related fields and provides a unified analytical framework. Our survey highlights the analysis of 35 vision-driven tasks and comprehensive examinations and visualizations of 73 available datasets based on the proposed taxonomy. The cross-domain investigation covers the pros and cons of each benchmark with the aim of providing information on standards unification and resource optimization. Our article concludes with a systematic discussion of the existing weaknesses, underlining the potential effects and promising solutions from various perspectives. The integrated taxonomy, comprehensive analysis, and recapitulatory tables serve as valuable contributions to this rapidly evolving field by providing researchers with a holistic overview, guiding strategic resource selection, and highlighting critical research gaps.",
      "authors": [
        "Yaoqi Huang",
        "Julie Stephany Berrio",
        "Mao Shan",
        "and Stewart Worrall"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T03:26:02+00:00",
          "link": "https://arxiv.org/abs/2507.06513v1",
          "size": "234732kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T02:13:37+00:00",
          "link": "https://arxiv.org/abs/2507.06513v2",
          "size": "27802kb",
          "version": "v2"
        }
      ],
      "title": "What Demands Attention in Urban Street Scenes? From Scene Understanding towards Road Safety: A Survey of Vision-driven Datasets and Studies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06513",
        "HTML": "https://arxiv.org/html/2507.06513v2",
        "PDF": "https://arxiv.org/pdf/2507.06513"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on vision-driven datasets related to urban street scenes and road safety, without any focus on LLM training data processing or data engineering techniques for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10541",
      "abstract": "Recent Large Reasoning Models (LRMs) have achieved remarkable progress on task-specific benchmarks, yet their evaluation methods remain constrained by isolated problem-solving paradigms. Existing benchmarks predominantly assess single-question reasoning through sequential testing, resulting critical limitations: (1) vulnerability to data contamination and less challenging (e.g., DeepSeek-R1 achieves 97.0% on MATH500), forcing costly creation of new questions with large human efforts, (2) failure to evaluate models under multi-context pressure, a key requirement for real-world deployment. To bridge this gap, we present REST (Reasoning Evaluation through Simultaneous Testing), a stress-testing framework that exposes LRMs to multiple problems simultaneously. Beyond basic reasoning, REST evaluates several under-tested capabilities: contextual priority allocation, cross-problem interference resistance, and dynamic cognitive load management. Our evaluation reveals several striking findings: Even state-of-the-art (SOTA) models like DeepSeek-R1 exhibit substantial performance degradation under stress testing. Crucially, REST demonstrates stronger discriminative power than existing benchmarks, revealing pronounced performance differences among models that exhibit similar, near-ceiling performance under single-question evaluations. Some key insights emerge from our analysis: (1) the \"overthinking trap\" is a critical factor contributing to the performance degradation; (2) the models trained with \"long2short\" technique preserve more accuracy of their single-problem performance under REST, outperforming standard-trained counterparts. These results establish REST as a cost-efficient, future-proof evaluation paradigm that better reflects real-world reasoning demands while reducing reliance on continuous human annotation. Code and results are available at https://opendatalab.github.io/REST.",
      "authors": [
        "Zhuoshi Pan and Qizhi Pei and Yu Li and Qiyao Sun and Zinan Tang and H. Vicky Zhao and Conghui He and Lijun Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T17:58:47+00:00",
          "link": "https://arxiv.org/abs/2507.10541v1",
          "size": "1204kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T06:16:53+00:00",
          "link": "https://arxiv.org/abs/2507.10541v2",
          "size": "1204kb",
          "version": "v2"
        }
      ],
      "title": "REST: Stress Testing Large Reasoning Models by Asking Multiple Problems at Once",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10541",
        "HTML": "https://arxiv.org/html/2507.10541v2",
        "PDF": "https://arxiv.org/pdf/2507.10541"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on stress-testing large reasoning models using a novel evaluation framework and does not contribute to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10596",
      "abstract": "Large Language Models (LLMs) excel in text classification, but their complexity hinders interpretability, making it difficult to understand the reasoning behind their predictions. Explainable AI (XAI) methods like LIME and SHAP offer local explanations by identifying influential words, but they rely on computationally expensive perturbations. These methods typically generate thousands of perturbed sentences and perform inferences on each, incurring a substantial computational burden, especially with LLMs. To address this, we propose \\underline{P}erturbation-free \\underline{L}ocal \\underline{Ex}planation (PLEX), a novel method that leverages the contextual embeddings extracted from the LLM and a ``Siamese network\" style neural network trained to align with feature importance scores. This one-off training eliminates the need for subsequent perturbations, enabling efficient explanations for any new sentence. We demonstrate PLEX's effectiveness on four different classification tasks (sentiment, fake news, fake COVID-19 news and depression), showing more than 92\\% agreement with LIME and SHAP. Our evaluation using a ``stress test\" reveals that PLEX accurately identifies influential words, leading to a similar decline in classification accuracy as observed with LIME and SHAP when these words are removed. Notably, in some cases, PLEX demonstrates superior performance in capturing the impact of key features. PLEX dramatically accelerates explanation, reducing time and computational overhead by two and four orders of magnitude, respectively. This work offers a promising solution for explainable LLM-based text classification.",
      "authors": [
        "Yogachandran Rahulamathavan and Misbah Farooq and Varuna De Silva"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-12T06:31:38+00:00",
          "link": "https://arxiv.org/abs/2507.10596v1",
          "size": "1749kb",
          "version": "v1"
        }
      ],
      "title": "PLEX: Perturbation-free Local Explanations for LLM-Based Text Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10596",
        "HTML": "https://arxiv.org/html/2507.10596v1",
        "PDF": "https://arxiv.org/pdf/2507.10596"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper proposes a method for perturbation-free local explanations in LLM-based text classification, primarily focusing on explainability rather than on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11334",
      "abstract": "Mobile robots are increasingly required to navigate and interact within unknown and unstructured environments to meet human demands. Demand-driven navigation (DDN) enables robots to identify and locate objects based on implicit human intent, even when object locations are unknown. However, traditional data-driven DDN methods rely on pre-collected data for model training and decision-making, limiting their generalization capability in unseen scenarios. In this paper, we propose CogDDN, a VLM-based framework that emulates the human cognitive and learning mechanisms by integrating fast and slow thinking systems and selectively identifying key objects essential to fulfilling user demands. CogDDN identifies appropriate target objects by semantically aligning detected objects with the given instructions. Furthermore, it incorporates a dual-process decision-making module, comprising a Heuristic Process for rapid, efficient decisions and an Analytic Process that analyzes past errors, accumulates them in a knowledge base, and continuously improves performance. Chain of Thought (CoT) reasoning strengthens the decision-making process. Extensive closed-loop evaluations on the AI2Thor simulator with the ProcThor dataset show that CogDDN outperforms single-view camera-only methods by 15%, demonstrating significant improvements in navigation accuracy and adaptability. The project page is available at https://yuehaohuang.github.io/CogDDN/.",
      "authors": [
        "Yuehao Huang",
        "Liang Liu",
        "Shuangming Lei",
        "Yukai Ma",
        "Hao Su",
        "Jianbiao Mei",
        "Pengxiang Zhao",
        "Yaqing Gu",
        "Yong Liu",
        "Jiajun Lv"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:06:24+00:00",
          "link": "https://arxiv.org/abs/2507.11334v1",
          "size": "12678kb",
          "version": "v1"
        }
      ],
      "title": "CogDDN: A Cognitive Demand-Driven Navigation with Decision Optimization and Dual-Process Thinking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11334",
        "HTML": "https://arxiv.org/html/2507.11334v1",
        "PDF": "https://arxiv.org/pdf/2507.11334"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on improving decision-making and navigation for mobile robots through cognitive processes and dual-process thinking. It does not address LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.02309",
      "abstract": "RESTful APIs facilitate data exchange between applications, but they also expose sensitive resources to potential exploitation. Broken Object Level Authorization (BOLA) is the top vulnerability in the OWASP API Security Top 10, exemplifies a critical access control flaw where attackers manipulate API parameters to gain unauthorized access. To address this, we propose BOLAZ, a defense framework grounded in zero trust principles. BOLAZ analyzes the data flow of resource IDs, pinpointing BOLA attack injection points and determining the associated authorization intervals to prevent horizontal privilege escalation. Our approach leverages static taint tracking to categorize APIs into producers and consumers based on how they handle resource IDs. By mapping the propagation paths of resource IDs, BOLAZ captures the context in which these IDs are produced and consumed, allowing for precise identification of authorization boundaries. Unlike defense methods based on common authorization models, BOLAZ is the first authorization-guided method that adapts defense rules based on the system's best-practice authorization logic. We validate BOLAZ through empirical research on 10 GitHub projects. The results demonstrate BOLAZ's effectiveness in defending against vulnerabilities collected from CVE and discovering 35 new BOLA vulnerabilities in the wild, demonstrating its practicality in real-world deployments.",
      "authors": [
        "Anbin Wu (1)",
        "Zhiyong Feng (1)",
        "Ruitao Feng (2)",
        "Zhenchang Xing (3)",
        "Yang Liu (4) ((1) The College of Intelligence and Computing",
        "Tianjin University",
        "(2) The Southern Cross University",
        "(3) CSIRO's Data61",
        "(4) School of Computer Science and Engineering",
        "Nanyang Technological University)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-03T04:40:14+00:00",
          "link": "https://arxiv.org/abs/2507.02309v1",
          "size": "1746kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T01:18:05+00:00",
          "link": "https://arxiv.org/abs/2507.02309v2",
          "size": "1747kb",
          "version": "v2"
        }
      ],
      "title": "Rethinking Broken Object Level Authorization Attacks Under Zero Trust Principle",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.02309",
        "HTML": "https://arxiv.org/html/2507.02309v2",
        "PDF": "https://arxiv.org/pdf/2507.02309"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper deals with API security and defense frameworks, specifically focusing on preventing Broken Object Level Authorization attacks, which does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.07986",
      "abstract": "We study the problem of training and fine-tuning expressive policies with online reinforcement learning (RL) given an offline dataset. Training expressive policy classes with online RL present a unique challenge of stable value maximization. Unlike simpler Gaussian policies commonly used in online RL, expressive policies like diffusion and flow-matching policies are parameterized by a long denoising chain, which hinders stable gradient propagation from actions to policy parameters when optimizing against some value function. Our key insight is that we can address stable value maximization by avoiding direct optimization over value with the expressive policy and instead construct an on-the-fly RL policy to maximize Q-value. We propose Expressive Policy Optimization (EXPO), a sample-efficient online RL algorithm that utilizes an on-the-fly policy to maximize value with two parameterized policies -- a larger expressive base policy trained with a stable imitation learning objective and a light-weight Gaussian edit policy that edits the actions sampled from the base policy toward a higher value distribution. The on-the-fly policy optimizes the actions from the base policy with the learned edit policy and chooses the value maximizing action from the base and edited actions for both sampling and temporal-difference (TD) backup. Our approach yields up to 2-3x improvement in sample efficiency on average over prior methods both in the setting of fine-tuning a pretrained policy given offline data and in leveraging offline data to train online.",
      "authors": [
        "Perry Dong",
        "Qiyang Li",
        "Dorsa Sadigh",
        "Chelsea Finn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-10T17:57:46+00:00",
          "link": "https://arxiv.org/abs/2507.07986v1",
          "size": "6010kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T17:54:16+00:00",
          "link": "https://arxiv.org/abs/2507.07986v2",
          "size": "6232kb",
          "version": "v2"
        }
      ],
      "title": "EXPO: Stable Reinforcement Learning with Expressive Policies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.07986",
        "HTML": "https://arxiv.org/html/2507.07986v2",
        "PDF": "https://arxiv.org/pdf/2507.07986"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper addresses stable reinforcement learning with expressive policies but does not focus on processing or improving LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11069",
      "abstract": "Understanding the 3D geometry of transparent objects from RGB images is challenging due to their inherent physical properties, such as reflection and refraction. To address these difficulties, especially in scenarios with sparse views and dynamic environments, we introduce TRAN-D, a novel 2D Gaussian Splatting-based depth reconstruction method for transparent objects. Our key insight lies in separating transparent objects from the background, enabling focused optimization of Gaussians corresponding to the object. We mitigate artifacts with an object-aware loss that places Gaussians in obscured regions, ensuring coverage of invisible surfaces while reducing overfitting. Furthermore, we incorporate a physics-based simulation that refines the reconstruction in just a few seconds, effectively handling object removal and chain-reaction movement of remaining objects without the need for rescanning. TRAN-D is evaluated on both synthetic and real-world sequences, and it consistently demonstrated robust improvements over existing GS-based state-of-the-art methods. In comparison with baselines, TRAN-D reduces the mean absolute error by over 39% for the synthetic TRansPose sequences. Furthermore, despite being updated using only one image, TRAN-D reaches a {\\delta} < 2.5 cm accuracy of 48.46%, over 1.5 times that of baselines, which uses six images. Code and more results are available at https://jeongyun0609.github.io/TRAN-D/.",
      "authors": [
        "Jeongyun Kim",
        "Seunghoon Jeong",
        "Giseop Kim",
        "Myung-Hwan Jeon",
        "Eunji Jun and Ayoung Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T08:02:37+00:00",
          "link": "https://arxiv.org/abs/2507.11069v1",
          "size": "31608kb",
          "version": "v1"
        }
      ],
      "title": "TRAN-D: 2D Gaussian Splatting-based Sparse-view Transparent Object Depth Reconstruction via Physics Simulation for Scene Update",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11069",
        "HTML": "https://arxiv.org/html/2507.11069v1",
        "PDF": "https://arxiv.org/pdf/2507.11069"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper focuses on depth reconstruction of transparent objects using Gaussian Splatting and physics-based simulation, without discussing LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11176",
      "abstract": "Traditional Chinese Medicine diagnosis and treatment principles, established through centuries of trial-and-error clinical practice, directly maps patient-specific symptom patterns to personalised herbal therapies. These empirical holistic mapping principles offer valuable strategies to address remaining challenges of reductionism methodologies in modern biomedicine. However, the lack of a quantitative framework and molecular-level evidence has limited their interpretability and reliability. Here, we present an AI framework trained on ancient and classical TCM formula records to quantify the symptom pattern-herbal therapy mappings. Interestingly, we find that empirical TCM diagnosis and treatment are consistent with the encoding-decoding processes in the AI model. This enables us to construct an interpretable TCM embedding space (TCM-ES) using the model's quantitative representation of TCM principles. Validated through broad and extensive TCM patient data, the TCM-ES offers universal quantification of the TCM practice and therapeutic efficacy. We further map biomedical entities into the TCM-ES through correspondence alignment. We find that the principal directions of the TCM-ES are significantly associated with key biological functions (such as metabolism, immune, and homeostasis), and that the disease and herb embedding proximity aligns with their genetic relationships in the human protein interactome, which demonstrate the biological significance of TCM principles. Moreover, the TCM-ES uncovers latent disease relationships, and provides alternative metric to assess clinical efficacy for modern disease-drug pairs. Finally, we construct a comprehensive and integrative TCM knowledge graph, which predicts potential associations between diseases and targets, drugs, herbal compounds, and herbal therapies, providing TCM-informed opportunities for disease analysis and drug development.",
      "authors": [
        "Haoran Li",
        "Xingye Cheng",
        "Ziyang Huang",
        "Jingyuan Luo",
        "Qianqian Xu",
        "Qiguang Zhao",
        "Tianchen Guo",
        "Yumeng Zhang",
        "Linda Lidan Zhong",
        "Zhaoxiang Bian",
        "Leihan Tang",
        "Aiping Lyu",
        "Liang Tian"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Machine Learning (cs.LG)",
        "Other Quantitative Biology (q-bio.OT)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:30:45+00:00",
          "link": "https://arxiv.org/abs/2507.11176v1",
          "size": "5051kb",
          "version": "v1"
        }
      ],
      "title": "An Interpretable AI framework Quantifying Traditional Chinese Medicine Principles Towards Enhancing and Integrating with Modern Biomedicine",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11176",
        "PDF": "https://arxiv.org/pdf/2507.11176"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on applying AI to quantify Traditional Chinese Medicine principles for biomedicine integration and does not involve any LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11507",
      "abstract": "KV cache accelerates LLM inference by avoiding redundant computation, at the expense of memory. To support larger KV caches, prior work extends GPU memory with CPU memory via CPU-offloading. This involves swapping KV cache between GPU and CPU memory. However, because the cache updates dynamically, such swapping incurs high CPU memory traffic. We make a key observation that model parameters remain constant during runtime, unlike the dynamically updated KV cache. Building on this, we introduce MIRAGE, which avoids KV cache swapping by remapping, and thereby repurposing, the memory allocated to model parameters for KV cache. This parameter remapping is especially beneficial in multi-tenant environments, where the memory used for the parameters of the inactive models can be more aggressively reclaimed. Exploiting the high CPU-GPU bandwidth offered by the modern hardware, such as the NVIDIA Grace Hopper Superchip, we show that MIRAGE significantly outperforms state-of-the-art solutions, achieving a reduction of 44.8%-82.5% in tail time-between-token latency, 20.7%-99.3% in tail time-to-first-token latency, and 6.6%-86.7% higher throughput compared to vLLM.",
      "authors": [
        "Ruihao Li",
        "Shagnik Pal",
        "Vineeth Narayan Pullu",
        "Prasoon Sinha",
        "Jeeho Ryoo",
        "Lizy K. John",
        "Neeraja J. Yadwadkar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Operating Systems (cs.OS)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T17:23:22+00:00",
          "link": "https://arxiv.org/abs/2507.11507v1",
          "size": "558kb",
          "version": "v1"
        }
      ],
      "title": "MIRAGE: KV Cache Optimization through Parameter Remapping for Multi-tenant LLM Serving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11507",
        "HTML": "https://arxiv.org/html/2507.11507v1",
        "PDF": "https://arxiv.org/pdf/2507.11507"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on optimizing KV cache via parameter remapping for multi-tenant LLM serving, which relates to inference efficiency rather than data processing for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2504.01738",
      "abstract": "Specialized reasoning language models (RLMs) have demonstrated that scaling test-time computation through detailed reasoning traces significantly enhances performance. Although these traces effectively facilitate knowledge distillation into smaller, instruction-tuned models, the precise nature of transferred reasoning remains unclear. In this study, we investigate to what extent distilled models internalize replicated stylistic patterns during reasoning. To this end, we systematically analyze reasoning traces, identifying structural and lexical patterns that characterize successful reasoning. We then introduce two new datasets -- a dataset of emergent reasoning traces and a synthetic dataset explicitly constructed to replicate these stylistic patterns -- to precisely examine their influence on distilled models' reasoning capabilities. We find that models trained on the synthetic traces achieve comparable performance, indicating that distilled reasoning abilities rely significantly on surface-level patterns. Surprisingly, we observe an increase in performance even when the synthetic traces are altered to lead to the wrong answer. Our findings highlight how stylistic patterns can be leveraged to efficiently enhance LM reasoning across diverse model families.",
      "authors": [
        "Philip Lippmann and Jie Yang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-02T13:50:20+00:00",
          "link": "https://arxiv.org/abs/2504.01738v1",
          "size": "274kb",
          "version": "v1"
        },
        {
          "date": "2025-06-11T11:31:47+00:00",
          "link": "https://arxiv.org/abs/2504.01738v2",
          "size": "271kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T09:34:32+00:00",
          "link": "https://arxiv.org/abs/2504.01738v3",
          "size": "271kb",
          "version": "v3"
        }
      ],
      "title": "Style over Substance: Distilled Language Models Reason Via Stylistic Replication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.01738",
        "HTML": "https://arxiv.org/html/2504.01738v3",
        "PDF": "https://arxiv.org/pdf/2504.01738"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces two new datasets with clearly detailed data processing steps to investigate the impact of stylistic patterns on reasoning capabilities in language models, focusing on data generation and synthesis."
      },
      "tasks": [
        "Knowledge Distillation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.05447",
      "abstract": "This work aims to understand how scaling improves language models, specifically in terms of training dynamics. We find that language models undergo loss deceleration early in training; an abrupt slowdown in the rate of loss improvement, resulting in piecewise linear behaviour of the loss curve in log-log space. Scaling up the model mitigates this transition by (1) decreasing the loss at which deceleration occurs, and (2) improving the log-log rate of loss improvement after deceleration. We attribute loss deceleration to a type of degenerate training dynamics we term zero-sum learning (ZSL). In ZSL, per-example gradients become systematically opposed, leading to destructive interference in per-example changes in loss. As a result, improving loss on one subset of examples degrades it on another, bottlenecking overall progress. Loss deceleration and ZSL provide new insights into the training dynamics underlying language model scaling laws, and could potentially be targeted directly to improve language models independent of scale. We make our code and artefacts available at: https://github.com/mirandrom/zsl",
      "authors": [
        "Andrei Mircea",
        "Supriyo Chakraborty",
        "Nima Chitsazan",
        "Milind Naphade",
        "Sambit Sahu",
        "Irina Rish",
        "Ekaterina Lobacheva"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-05T15:18:35+00:00",
          "link": "https://arxiv.org/abs/2506.05447v1",
          "size": "36838kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T23:29:38+00:00",
          "link": "https://arxiv.org/abs/2506.05447v2",
          "size": "36838kb",
          "version": "v2"
        }
      ],
      "title": "Training Dynamics Underlying Language Model Scaling Laws: Loss Deceleration and Zero-Sum Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.05447",
        "HTML": "https://arxiv.org/html/2506.05447v2",
        "PDF": "https://arxiv.org/pdf/2506.05447"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Though the paper investigates language model training dynamics, it does not focus on data processing or engineering for LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11246",
      "abstract": "Click-Through Rate (CTR) prediction models are integral to a myriad of industrial settings, such as personalized search advertising. Current methods typically involve feature extraction from users' historical behavior sequences combined with product information, feeding into a discriminative model that is trained on user feedback to estimate CTR. With the success of models such as GPT, the potential for generative models to enrich expressive power beyond discriminative models has become apparent. In light of this, we introduce a novel model that leverages generative models to enhance the precision of CTR predictions in discriminative models. To reconcile the disparate data aggregation needs of both model types, we design a two-stage training process: 1) Generative pre-training for next-item prediction with the given item category in user behavior sequences; 2) Fine-tuning the well-trained generative model within a discriminative CTR prediction framework. Our method's efficacy is substantiated through extensive experiments on a new dataset, and its significant utility is further corroborated by online A/B testing results. Currently, the model is deployed on one of the world's largest e-commerce platforms, and we intend to release the associated code and dataset in the future.",
      "authors": [
        "Lingwei Kong",
        "Lu Wang",
        "Changping Peng",
        "Zhangang Lin",
        "Ching Law",
        "Jingping Shao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T12:21:30+00:00",
          "link": "https://arxiv.org/abs/2507.11246v1",
          "size": "108kb",
          "version": "v1"
        }
      ],
      "title": "Generative Click-through Rate Prediction with Applications to Search Advertising",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11246",
        "HTML": "https://arxiv.org/html/2507.11246v1",
        "PDF": "https://arxiv.org/pdf/2507.11246"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper explores generative models for click-through rate prediction and involves a new dataset, but its focus is not primarily on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2404.13914",
      "abstract": "The availability of smart devices leads to an exponential increase in multimedia content. However, advancements in deep learning have also enabled the creation of highly sophisticated Deepfake content, including speech Deepfakes, which pose a serious threat by generating realistic voices and spreading misinformation. To combat this, numerous challenges have been organized to advance speech Deepfake detection techniques. In this survey, we systematically analyze more than 200 papers published up to March 2024. We provide a comprehensive review of each component in the detection pipeline, including model architectures, optimization techniques, generalizability, evaluation metrics, performance comparisons, available datasets, and open source availability. For each aspect, we assess recent progress and discuss ongoing challenges. In addition, we explore emerging topics such as partial Deepfake detection, cross-dataset evaluation, and defences against adversarial attacks, while suggesting promising research directions. This survey not only identifies the current state of the art to establish strong baselines for future experiments but also offers clear guidance for researchers aiming to enhance speech Deepfake detection systems.",
      "authors": [
        "Menglu Li",
        "Yasaman Ahmadiadli",
        "Xiao-Ping Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Cryptography and Security (cs.CR)",
        "Multimedia (cs.MM)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-22T06:52:12+00:00",
          "link": "https://arxiv.org/abs/2404.13914v1",
          "size": "237kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T22:26:06+00:00",
          "link": "https://arxiv.org/abs/2404.13914v2",
          "size": "742kb",
          "version": "v2"
        }
      ],
      "title": "A Survey on Speech Deepfake Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.13914",
        "HTML": "https://arxiv.org/html/2404.13914v2",
        "PDF": "https://arxiv.org/pdf/2404.13914"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The survey on speech Deepfake detection covers techniques and evaluations but does not focus on the processing of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10590",
      "abstract": "Language Model (LM) pipelines can dynamically refine their outputs against programmatic constraints. However, their effectiveness collapses when faced with competing soft constraints, leading to inefficient backtracking loops where satisfying one constraint violates another. We introduce Meta Self-Refining, a framework that equips LM pipelines with a meta-corrective layer to repair these competitions at runtime/inference-time. Our approach monitors the pipeline's execution history to detect oscillatory failures. Upon detection, it invokes a meta-repairer LM that analyzes the holistic state of the backtracking attempts and synthesizes a strategic instruction to balance the competing requirements. This self-repair instruction guides the original LM out of a failing refining loop towards a successful output. Our results show Meta Self-Refining can successfully repair these loops, leading to more efficient LM programs.",
      "authors": [
        "Mojtaba Eshghie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-11T17:35:12+00:00",
          "link": "https://arxiv.org/abs/2507.10590v1",
          "size": "77kb",
          "version": "v1"
        }
      ],
      "title": "Repairing Language Model Pipelines by Meta Self-Refining Competing Constraints at Runtime",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10590",
        "HTML": "https://arxiv.org/html/2507.10590v1",
        "PDF": "https://arxiv.org/pdf/2507.10590"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on repairing language model pipelines by introducing a framework at runtime. It does not discuss any methods related to processing or creating LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11035",
      "abstract": "Transformer-based models exhibit strong global modeling capabilities in single-image dehazing, but their high computational cost limits real-time applicability. Existing methods predominantly rely on spatial-domain features to capture long-range dependencies, which are computationally expensive and often inadequate under complex haze conditions. While some approaches introduce frequency-domain cues, the weak coupling between spatial and frequency branches limits the overall performance. To overcome these limitations, we propose the Dark Channel Guided Frequency-aware Dehazing Network (DGFDNet), a novel dual-domain framework that performs physically guided degradation alignment across spatial and frequency domains. At its core, the DGFDBlock comprises two key modules: 1) the Haze-Aware Frequency Modulator (HAFM), which generates a pixel-level haze confidence map from dark channel priors to adaptively enhance haze-relevant frequency components, thereby achieving global degradation-aware spectral modulation; 2) the Multi-level Gating Aggregation Module (MGAM), which fuses multi-scale features through diverse convolutional kernels and hybrid gating mechanisms to recover fine structural details. Additionally, a Prior Correction Guidance Branch (PCGB) incorporates a closed-loop feedback mechanism, enabling iterative refinement of the prior by intermediate dehazed features and significantly improving haze localization accuracy, especially in challenging outdoor scenes. Extensive experiments on four benchmark haze datasets demonstrate that DGFDNet achieves state-of-the-art performance with superior robustness and real-time efficiency. Code is available at: https://github.com/Dilizlr/DGFDNet.",
      "authors": [
        "Lirong Zheng",
        "Yanshan Li",
        "Rui Yu",
        "Kaihao Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T06:56:56+00:00",
          "link": "https://arxiv.org/abs/2507.11035v1",
          "size": "16622kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Dual-domain Image Dehazing with Haze Prior Perception",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11035",
        "HTML": "https://arxiv.org/html/2507.11035v1",
        "PDF": "https://arxiv.org/pdf/2507.11035"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "This paper addresses image dehazing and proposes a dual-domain framework, unrelated to the processing or creation of training data for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11047",
      "abstract": "In this article, we study the dimension of the spline space of di-degree $(d,d)$ with the highest order of smoothness over a hierarchical T-mesh $\\mathscr T$ using the smoothing cofactor-conformality method. Firstly, we obtain a dimensional formula for the conformality vector space over a tensor product T-connected component. Then, we prove that the dimension of the conformality vector space over a T-connected component of a hierarchical T-mesh under the tensor product subdivision can be calculated in a recursive manner. Combining these two aspects, we obtain a dimensional formula for the bi-degree $(d,d)$ spline space with the highest order of smoothness over a hierarchical T-mesh $\\mathscr T$ with mild assumption. Additionally, we provide a strategy to modify an arbitrary hierarchical T-mesh such that the dimension of the bi-degree $(d,d)$ spline space is stable over the modified hierarchical T-mesh. Finally, we prove that the dimension of the spline space over such a hierarchical T-mesh is the same as that of a lower-degree spline space over its CVR graph. Thus, the proposed solution can pave the way for the subsequent construction of basis functions for spline space over such a hierarchical T-mesh.",
      "authors": [
        "Bingru Huang and Falai Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T07:20:34+00:00",
          "link": "https://arxiv.org/abs/2507.11047v1",
          "size": "29kb",
          "version": "v1"
        }
      ],
      "title": "Dimension of Bi-degree $(d,d)$ Spline Spaces with the Highest Order of Smoothness over Hierarchical T-Meshes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11047",
        "HTML": "https://arxiv.org/html/2507.11047v1",
        "PDF": "https://arxiv.org/pdf/2507.11047"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses mathematical properties of spline spaces and does not relate to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11349",
      "abstract": "Motivated by the transfer of proofs between proof systems, and in particular from first order automated theorem provers (ATPs) to interactive theorem provers (ITPs), we specify an extension of the TPTP derivation text format to describe proofs in first-order logic: SC-TPTP. To avoid multiplication of standards, our proposed format over-specifies the TPTP derivation format by focusing on sequent formalisms. By doing so, it provides a high level of detail, is faithful to mathematical tradition, and cover multiple existing tools and in particular tableaux-based strategies. We make use of this format to allow the Lisa proof assistant to query the Go\\'eland automated theorem prover, and implement a library of tools able to parse, print and check SC-TPTP proofs, export them into Coq files, and rebuild low-level proof steps from advanced ones.",
      "authors": [
        "Julie Cailler and Simon Guilloud"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T14:22:55+00:00",
          "link": "https://arxiv.org/abs/2507.11349v1",
          "size": "130kb",
          "version": "v1"
        }
      ],
      "title": "SC-TPTP: An Extension of the TPTP Derivation Format for Sequent-Based Calculus",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11349",
        "HTML": "https://arxiv.org/html/2507.11349v1",
        "PDF": "https://arxiv.org/pdf/2507.11349"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on an extension of the TPTP derivation format for theorem proving, which does not relate to LLM training data processing or improvements to dataset quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2406.13797",
      "abstract": "This paper is a continuation of a previous study on the so-called measure once finite quantum automata model introduced by Moore and Crutchfield in 2000. We investigate conditions assuring that, given a language recognized by such a device and a language generated by a context-free grammar of finite index or by a matrix context-free grammar, it is recursively decidable whether or not they have a nonempty intersection.",
      "authors": [
        "Andrea Benso",
        "Flavio D'Alessandro",
        "Paolo Papi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-19T19:56:03+00:00",
          "link": "https://arxiv.org/abs/2406.13797v1",
          "size": "50kb",
          "version": "v1"
        },
        {
          "date": "2024-08-05T19:38:34+00:00",
          "link": "https://arxiv.org/abs/2406.13797v2",
          "size": "52kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T17:12:40+00:00",
          "link": "https://arxiv.org/abs/2406.13797v3",
          "size": "60kb",
          "version": "v3"
        }
      ],
      "title": "On the Intersection Problem for Quantum Finite Automata",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.13797",
        "HTML": "https://arxiv.org/html/2406.13797v3",
        "PDF": "https://arxiv.org/pdf/2406.13797"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on the intersection problem for quantum finite automata, which is unrelated to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2501.00150",
      "abstract": "Quasi-Monte Carlo sampling can attain far better accuracy than plain Monte Carlo sampling. However, with plain Monte Carlo sampling it is much easier to estimate the attained accuracy. This article describes methods old and new to quantify the error in quasi-Monte Carlo estimates. An important challenge in this setting is that the goal of getting accuracy conflicts with that of estimating the attained accuracy. A related challenge is that rigorous uncertainty quantifications can be extremely conservative. A recent surprise is that some RQMC estimates have nearly symmetric distributions and that has the potential to allow confidence intervals that do not require either a central limit theorem or a consistent variance estimate.",
      "authors": [
        "Art B. Owen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-30T21:51:18+00:00",
          "link": "https://arxiv.org/abs/2501.00150v1",
          "size": "48kb",
          "version": "v1"
        },
        {
          "date": "2025-01-03T20:30:01+00:00",
          "link": "https://arxiv.org/abs/2501.00150v2",
          "size": "48kb",
          "version": "v2"
        },
        {
          "date": "2025-07-15T01:20:28+00:00",
          "link": "https://arxiv.org/abs/2501.00150v3",
          "size": "52kb",
          "version": "v3"
        }
      ],
      "title": "Error estimation for quasi-Monte Carlo",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.00150",
        "HTML": "https://arxiv.org/html/2501.00150v3",
        "PDF": "https://arxiv.org/pdf/2501.00150"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses methods for error estimation in quasi-Monte Carlo sampling, which is unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10015",
      "abstract": "Foundation multi-modal models are often designed by stitching of multiple existing pretrained uni-modal models: for example, an image classifier with an text model. This stitching process is performed by training a connector module that aims to align the representation spaces of these uni-modal models towards a multi-modal objective. However, given the complexity of training such connectors on large scale web-based datasets coupled with the ever-increasing number of available pretrained uni-modal models, the task of uni-modal models selection and subsequent connector module training becomes computationally demanding. To address this under-studied critical problem, we propose Hypernetwork Model Alignment (Hyma), a novel all-in-one solution for optimal uni-modal model selection and connector training by leveraging hypernetworks. Specifically, our framework utilizes the parameter prediction capability of a hypernetwork to obtain jointly trained connector modules for $N \\times M$ combinations of uni-modal models. In our experiments, Hyma reduces the cost of searching for the best performing uni-modal model pair by $10\\times$, while matching the ranking and trained connector performance obtained via grid search across a suite of diverse multi-modal benchmarks.",
      "authors": [
        "Jaisidh Singh",
        "Diganta Misra",
        "Boris Knyazev",
        "Antonio Orvieto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-14T07:51:01+00:00",
          "link": "https://arxiv.org/abs/2507.10015v1",
          "size": "464kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T07:15:38+00:00",
          "link": "https://arxiv.org/abs/2507.10015v2",
          "size": "464kb",
          "version": "v2"
        }
      ],
      "title": "(Almost) Free Modality Stitching of Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10015",
        "HTML": "https://arxiv.org/html/2507.10015v2",
        "PDF": "https://arxiv.org/pdf/2507.10015"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on model architecture and connector training for multi-modal models, not on the processing or creation of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10904",
      "abstract": "High-quality training data is essential for building reliable and efficient machine learning systems. One-shot coreset selection addresses this by pruning the dataset while maintaining or even improving model performance, often relying on training-dynamics-based data difficulty scores. However, most existing methods implicitly assume class-wise homogeneity in data difficulty, overlooking variation in data difficulty across different classes.\n  In this work, we challenge this assumption by showing that, in domains such as network intrusion detection and medical imaging, data difficulty often clusters by class. We formalize this as class-difficulty separability and introduce the Class Difficulty Separability Coefficient (CDSC) as a quantitative measure. We demonstrate that high CDSC values correlate with performance degradation in class-agnostic coreset methods, which tend to overrepresent easy majority classes while neglecting rare but informative ones.\n  To address this, we introduce class-proportional variants of multiple sampling strategies. Evaluated on five diverse datasets spanning security and medical domains, our methods consistently achieve state-of-the-art data efficiency. For instance, on CTU-13, at an extreme 99% pruning rate, a class-proportional variant of Coverage-centric Coreset Selection (CCS-CP) shows remarkable stability, with accuracy dropping only 2.58%, precision 0.49%, and recall 0.19%. In contrast, the class-agnostic CCS baseline, the next best method, suffers sharper declines of 7.59% in accuracy, 4.57% in precision, and 4.11% in recall.\n  We further show that aggressive pruning enhances generalization in noisy, imbalanced, and large-scale datasets. Our results underscore that explicitly modeling class-difficulty separability leads to more effective, robust, and generalizable data pruning, particularly in high-stakes scenarios.",
      "authors": [
        "Elisa Tsai and Haizhong Zheng and Atul Prakash"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T01:43:32+00:00",
          "link": "https://arxiv.org/abs/2507.10904v1",
          "size": "380kb",
          "version": "v1"
        }
      ],
      "title": "Class-Proportional Coreset Selection for Difficulty-Separable Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10904",
        "HTML": "https://arxiv.org/html/2507.10904v1",
        "PDF": "https://arxiv.org/pdf/2507.10904"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "core",
        "reason": "The paper introduces class-proportional coreset selection for pruning datasets, which is a direct contribution to data processing by improving data efficiency. This involves creating more balanced training datasets, enhancing LLM training data quality."
      },
      "source": "arXiv"
    },
    {
      "id": "2403.06031",
      "abstract": "Machine learning requires defining one's target variable for predictions or decisions, a process that can have profound implications for fairness, since biases are often encoded in target variable definition itself, before any data collection or training. The downstream impacts of target variable definition must be taken into account in order to responsibly develop, deploy, and use the algorithmic systems. We propose FairTargetSim (FTS), an interactive and simulation-based approach for this. We demonstrate FTS using the example of algorithmic hiring, grounded in real-world data and user-defined target variables. FTS is open-source; it can be used by algorithm developers, non-technical stakeholders, researchers, and educators in a number of ways. FTS is available at: http://tinyurl.com/ftsinterface. The video accompanying this paper is here: http://tinyurl.com/ijcaifts.",
      "authors": [
        "Dalia Gala",
        "Milo Phillips-Brown",
        "Naman Goel",
        "Carinal Prunkl",
        "Laura Alvarez Jubete",
        "medb corcoran",
        "Ray Eitel-Porter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-09T22:41:33+00:00",
          "link": "https://arxiv.org/abs/2403.06031v1",
          "size": "863kb",
          "version": "v1"
        },
        {
          "date": "2025-07-14T22:53:10+00:00",
          "link": "https://arxiv.org/abs/2403.06031v2",
          "size": "480kb",
          "version": "v2"
        }
      ],
      "title": "FairTargetSim: An Interactive Simulator for Understanding and Explaining the Fairness Effects of Target Variable Definition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.06031",
        "HTML": "https://arxiv.org/html/2403.06031v2",
        "PDF": "https://arxiv.org/pdf/2403.06031"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper introduces FairTargetSim for exploring fairness in target variable definition, which is not related to LLM training data processing or improvements."
      },
      "tasks": [
        "Fairness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.09719",
      "abstract": "We report on an ethnographic study with members of the climate movement in the United Kingdom (UK). We conducted participant observation and interviews at protests and in various activist settings. Reporting on the findings as they relate to information security, we show that members of the UK climate movement wrestled with (i) a fundamental tension between openness and secrecy; (ii) tensions between autonomy and collective interdependence in information-security decision-making; (iii) conflicting activist ideals that shape security discourses; and (iv) pressures from different social gazes -- from each other, from people outside the movement and from their adversaries. Overall, our findings shed light on the social complexities of information-security research in activist settings and provoke methodological questions about programmes that aim to design for activists.",
      "authors": [
        "Mikaela Brough",
        "Rikke Bjerg Jensen",
        "Martin R. Albrecht"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T13:31:35+00:00",
          "link": "https://arxiv.org/abs/2506.09719v1",
          "size": "44kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T10:39:45+00:00",
          "link": "https://arxiv.org/abs/2506.09719v2",
          "size": "44kb",
          "version": "v2"
        }
      ],
      "title": "On the Virtues of Information Security in the UK Climate Movement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09719",
        "HTML": "https://arxiv.org/html/2506.09719v2",
        "PDF": "https://arxiv.org/pdf/2506.09719"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper discusses information security within activist settings, focusing on social and ethical implications rather than technical contributions to LLM training data processing or creation."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.06803",
      "abstract": "This paper contributes to speeding up the design and deployment of engineering dynamical systems by proposing a strategy for exploiting domain and expert knowledge for the automated generation of dynamical system computational model starting from a corpus of document relevant to the dynamical system of interest and an input document describing the specific system. This strategy is implemented in five steps and, crucially, it uses system modeling language diagrams (SysML) to extract accurate information about the dependencies, attributes, and operations of components. Natural Language Processing (NLP) strategies and Large Language Models (LLMs) are employed in specific tasks to improve intermediate outputs of the SySML diagrams automated generation, such as: list of key nouns; list of extracted relationships; list of key phrases and key relationships; block attribute values; block relationships; and BDD diagram generation. The applicability of automated SysML diagram generation is illustrated with different case studies. The computational models of complex dynamical systems from SysML diagrams are then obtained via code generation and computational model generation steps. In the code generation step, NLP strategies are used for summarization, while LLMs are used for validation only. The proposed approach is not limited to a specific system, domain, or computational software. The applicability of the proposed approach is shown via an end-to-end example from text to model of a simple pendulum, showing improved performance compared to results yielded by LLMs only.",
      "authors": [
        "Matthew Anderson Hendricks and Alice Cicirello"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-09T12:44:49+00:00",
          "link": "https://arxiv.org/abs/2507.06803v1",
          "size": "2519kb",
          "version": "v1"
        },
        {
          "date": "2025-07-15T11:05:37+00:00",
          "link": "https://arxiv.org/abs/2507.06803v2",
          "size": "2519kb",
          "version": "v2"
        }
      ],
      "title": "Text to model via SysML: Automated generation of dynamical system computational models from unstructured natural language text via enhanced System Modeling Language diagrams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.06803",
        "HTML": "https://arxiv.org/html/2507.06803v2",
        "PDF": "https://arxiv.org/pdf/2507.06803"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper involves using LLMs for natural language processing tasks to improve SysML diagram generation, but it does not primarily focus on LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.10999",
      "abstract": "The resurgence of convolutional neural networks (CNNs) in visual recognition tasks, exemplified by ConvNeXt, has demonstrated their capability to rival transformer-based architectures through advanced training methodologies and ViT-inspired design principles. However, both CNNs and transformers exhibit a simplicity bias, favoring straightforward features over complex structural representations. Furthermore, modern CNNs often integrate MLP-like blocks akin to those in transformers, but these blocks suffer from significant information redundancies, necessitating high expansion ratios to sustain competitive performance. To address these limitations, we propose SpaRTAN, a lightweight architectural design that enhances spatial and channel-wise information processing. SpaRTAN employs kernels with varying receptive fields, controlled by kernel size and dilation factor, to capture discriminative multi-order spatial features effectively. A wave-based channel aggregation module further modulates and reinforces pixel interactions, mitigating channel-wise redundancies. Combining the two modules, the proposed network can efficiently gather and dynamically contextualize discriminative features. Experimental results in ImageNet and COCO demonstrate that SpaRTAN achieves remarkable parameter efficiency while maintaining competitive performance. In particular, on the ImageNet-1k benchmark, SpaRTAN achieves 77. 7% accuracy with only 3.8M parameters and approximately 1.0 GFLOPs, demonstrating its ability to deliver strong performance through an efficient design. On the COCO benchmark, it achieves 50.0% AP, surpassing the previous benchmark by 1.2% with only 21.5M parameters. The code is publicly available at [https://github.com/henry-pay/SpaRTAN].",
      "authors": [
        "Quan Bi Pay",
        "Vishnu Monn Baskaran",
        "Junn Yong Loo",
        "KokSheik Wong and Simon See"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T05:34:56+00:00",
          "link": "https://arxiv.org/abs/2507.10999v1",
          "size": "8720kb",
          "version": "v1"
        }
      ],
      "title": "SpaRTAN: Spatial Reinforcement Token-based Aggregation Network for Visual Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.10999",
        "HTML": "https://arxiv.org/html/2507.10999v1",
        "PDF": "https://arxiv.org/pdf/2507.10999"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The paper focuses on a new architectural design for visual recognition tasks using CNNs and transformers, specifically SpaRTAN, and does not mention processing LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11187",
      "abstract": "Online collaborative medical prediction platforms offer convenience and real-time feedback by leveraging massive electronic health records. However, growing concerns about privacy and low prediction quality can deter patient participation and doctor cooperation. In this paper, we first clarify the privacy attacks, namely attribute attacks targeting patients and model extraction attacks targeting doctors, and specify the corresponding privacy principles. We then propose a privacy-preserving mechanism and integrate it into a novel one-shot distributed learning framework, aiming to simultaneously meet both privacy requirements and prediction performance objectives. Within the framework of statistical learning theory, we theoretically demonstrate that the proposed distributed learning framework can achieve the optimal prediction performance under specific privacy requirements. We further validate the developed privacy-preserving collaborative medical prediction platform through both toy simulations and real-world data experiments.",
      "authors": [
        "Shao-Bo Lin",
        "Xiaotong Liu",
        "Yao Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T10:41:55+00:00",
          "link": "https://arxiv.org/abs/2507.11187v1",
          "size": "1392kb",
          "version": "v1"
        }
      ],
      "title": "Striking the Perfect Balance: Preserving Privacy While Boosting Utility in Collaborative Medical Prediction Platforms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11187",
        "HTML": "https://arxiv.org/html/2507.11187v1",
        "PDF": "https://arxiv.org/pdf/2507.11187"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "Focuses on privacy-preserving mechanisms in collaborative medical platforms without discussing LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2507.11465",
      "abstract": "High-quality 3D assets are essential for various applications in computer graphics and 3D vision but remain scarce due to significant acquisition costs. To address this shortage, we introduce Elevate3D, a novel framework that transforms readily accessible low-quality 3D assets into higher quality. At the core of Elevate3D is HFS-SDEdit, a specialized texture enhancement method that significantly improves texture quality while preserving the appearance and geometry while fixing its degradations. Furthermore, Elevate3D operates in a view-by-view manner, alternating between texture and geometry refinement. Unlike previous methods that have largely overlooked geometry refinement, our framework leverages geometric cues from images refined with HFS-SDEdit by employing state-of-the-art monocular geometry predictors. This approach ensures detailed and accurate geometry that aligns seamlessly with the enhanced texture. Elevate3D outperforms recent competitors by achieving state-of-the-art quality in 3D model refinement, effectively addressing the scarcity of high-quality open-source 3D assets.",
      "authors": [
        "Nuri Ryu",
        "Jiyun Won",
        "Jooeun Son",
        "Minsu Gong",
        "Joo-Haeng Lee",
        "Sunghyun Cho"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-07-15T16:36:20+00:00",
          "link": "https://arxiv.org/abs/2507.11465v1",
          "size": "40616kb",
          "version": "v1"
        }
      ],
      "title": "Elevating 3D Models: High-Quality Texture and Geometry Refinement from a Low-Quality Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2507.11465",
        "HTML": "https://arxiv.org/html/2507.11465v1",
        "PDF": "https://arxiv.org/pdf/2507.11465"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "irrelevant",
        "reason": "The focus is on refining 3D models and enhancing 3D texture and geometry, without any connection to LLM training data processing."
      },
      "source": "arXiv"
    }
  ],
  "subjects": [
    "Computer Vision and Pattern Recognition (cs.CV)",
    "Multimedia (cs.MM)",
    "Computation and Language (cs.CL)",
    "Systems and Control (eess.SY)",
    "Cryptography and Security (cs.CR)",
    "Robotics (cs.RO)",
    "Artificial Intelligence (cs.AI)",
    "Systems and Control (cs.SY)",
    "Medical Physics (physics.med-ph)",
    "Signal Processing (eess.SP)",
    "Social and Information Networks (cs.SI)",
    "Machine Learning (stat.ML)",
    "Numerical Analysis (cs.NA)",
    "Machine Learning (cs.LG)",
    "Numerical Analysis (math.NA)",
    "Logic in Computer Science (cs.LO)",
    "Computer Science and Game Theory (cs.GT)",
    "Computational Engineering, Finance, and Science (cs.CE)",
    "Information Theory (math.IT)",
    "Information Theory (cs.IT)",
    "Formal Languages and Automata Theory (cs.FL)",
    "Data Structures and Algorithms (cs.DS)",
    "Software Engineering (cs.SE)",
    "General Economics (econ.GN)",
    "Economics (q-fin.EC)",
    "Applications (stat.AP)",
    "Computers and Society (cs.CY)",
    "Performance (cs.PF)",
    "Information Retrieval (cs.IR)",
    "Analysis of PDEs (math.AP)",
    "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
    "Databases (cs.DB)",
    "Hardware Architecture (cs.AR)",
    "Combinatorics (math.CO)",
    "Theoretical Economics (econ.TH)",
    "Optimization and Control (math.OC)",
    "Human-Computer Interaction (cs.HC)",
    "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
    "Computational Complexity (cs.CC)",
    "Neural and Evolutionary Computing (cs.NE)",
    "Graphics (cs.GR)",
    "Multiagent Systems (cs.MA)",
    "Networking and Internet Architecture (cs.NI)",
    "Methodology (stat.ME)",
    "Statistical Mechanics (cond-mat.stat-mech)",
    "Adaptation and Self-Organizing Systems (nlin.AO)",
    "Soft Condensed Matter (cond-mat.soft)",
    "Mathematical Physics (math.MP)",
    "Mathematical Physics (math-ph)",
    "Image and Video Processing (eess.IV)",
    "Computational Geometry (cs.CG)",
    "Quantitative Methods (q-bio.QM)",
    "Geometric Topology (math.GT)",
    "Operating Systems (cs.OS)",
    "Sound (cs.SD)",
    "Solar and Stellar Astrophysics (astro-ph.SR)",
    "Audio and Speech Processing (eess.AS)",
    "Discrete Mathematics (cs.DM)",
    "Quantum Physics (quant-ph)",
    "Probability (math.PR)",
    "Computation (stat.CO)",
    "Classical Analysis and ODEs (math.CA)",
    "Portfolio Management (q-fin.PM)",
    "Trading and Market Microstructure (q-fin.TR)",
    "Mathematical Finance (q-fin.MF)",
    "Atmospheric and Oceanic Physics (physics.ao-ph)",
    "Algebraic Geometry (math.AG)",
    "Biological Physics (physics.bio-ph)",
    "Physics and Society (physics.soc-ph)",
    "Emerging Technologies (cs.ET)",
    "Strongly Correlated Electrons (cond-mat.str-el)",
    "Neurons and Cognition (q-bio.NC)",
    "Digital Libraries (cs.DL)",
    "Risk Management (q-fin.RM)",
    "Number Theory (math.NT)",
    "Programming Languages (cs.PL)",
    "Data Analysis, Statistics and Probability (physics.data-an)",
    "Logic (math.LO)",
    "Computational Physics (physics.comp-ph)",
    "Dynamical Systems (math.DS)",
    "Materials Science (cond-mat.mtrl-sci)",
    "General Relativity and Quantum Cosmology (gr-qc)",
    "High Energy Astrophysical Phenomena (astro-ph.HE)",
    "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "High Energy Physics - Lattice (hep-lat)",
    "Nuclear Theory (nucl-th)",
    "Optics (physics.optics)",
    "Statistics Theory (stat.TH)",
    "Statistics Theory (math.ST)",
    "Populations and Evolution (q-bio.PE)",
    "Differential Geometry (math.DG)",
    "Group Theory (math.GR)",
    "Fluid Dynamics (physics.flu-dyn)",
    "Chemical Physics (physics.chem-ph)",
    "Geophysics (physics.geo-ph)",
    "History and Overview (math.HO)",
    "Applied Physics (physics.app-ph)",
    "Statistical Finance (q-fin.ST)",
    "Other Quantitative Biology (q-bio.OT)"
  ],
  "prompt": {
    "train_data": "\nHigh-quality training data is critical to LLM performance. You are a computer science expert specializing in data engineering for large language model (LLM) training data. Your task is to analyze a set of arXiv papers and identify those that focus on processing LLM training data.\n\n---\n\n### **Task Objective**\n\nFor each paper, determine whether it makes a technical contribution to **LLM training data processing**. In particular, focus on papers that involve **training-data processing** , including but not limited to:\n\n1. **Data processing during pretraining or fine-tuning**\n   * Preparation of data for LLM pretraining, instruction tuning, supervised fine-tuning (SFT), alignment tuning, etc.\n2. **training-data processing**\n   * Common data engineering operations, including data collection, data generation, data deduplication, data filtering, etc.\n   * Any methods or techniques that significantly improve data quality.\n   * Creation of a new dataset **with clear, detailed data processing steps.**\n\n**Note:** Ignore papers that merely use existing training datasets for downstream tasks (e.g., QA, reasoning), propose new model architectures, or conduct evaluation benchmarks\u2014unless they also **substantively modify or process the training data itself**.\n\n---\n\n### **Relevance Level Classification**\n\n* **`core`**: The paper\u2019s primary contribution lies in processing or creating LLM training data, or in constructing a higher-quality dataset from existing data\u2014e.g., dataset creation, data generation or synthesis, pipeline design, filtering methods, or other data\u2011engineering operations that improve data quality.\n* **`partial`**: The paper briefly mentions training data or standard preprocessing (e.g., using a standard dataset or tokenization, it focuses on model architecture, tasks, evaluation, prompting methods) but does **not** focus primarily on data processing.\n* **`irrelevant`**: The paper does **not** discuss any aspect of LLM training data collection, processing, or engineering.\n\n---\n\n### **Output Format (strictly follow this JSON schema)**\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"<paper ID>\",\n      \"level\": \"core | partial | irrelevant\",\n      \"reason\": \"A 1-2 sentence explanation citing the key part of the abstract or methodology that justifies your classification\"\n    }\n    // \u2026additional papers\n  ]\n}\n```\n"
  },
  "description": "Data source: https://arxiv.org/list/cs/new",
  "level_tatistics": {
    "partial": 121,
    "irrelevant": 724,
    "core": 37
  },
  "arxiv_update_date": "2025-07-16",
  "updated_at": "2025-07-16 10:11:52"
}