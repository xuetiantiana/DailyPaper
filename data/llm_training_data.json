{
  "data": [
    {
      "id": "2506.22437",
      "abstract": "Accurate image alignment is essential for monitoring crack evolution in structural health monitoring (SHM), particularly under real-world conditions involving perspective distortion, occlusion, and low contrast. However, traditional feature detectors such as SIFT and SURF, which rely on Gaussian-based scale spaces, tend to suppress high-frequency edges, making them unsuitable for thin crack localization. Lightweight binary alternatives like ORB and BRISK, while computationally efficient, often suffer from poor keypoint repeatability on textured or shadowed surfaces. This study presents a physics-informed alignment framework that adapts the open KAZE architecture to SHM-specific challenges. By utilizing nonlinear anisotropic diffusion to construct a crack-preserving scale space, and integrating RANSAC-based homography estimation, the framework enables accurate geometric correction without the need for training, parameter tuning, or prior calibration. The method is validated on time-lapse images of masonry and concrete acquired via handheld smartphone under varied field conditions, including shadow interference, cropping, oblique viewing angles, and surface clutter. Compared to classical detectors, the proposed framework reduces crack area and spine length errors by up to 70 percent and 90 percent, respectively, while maintaining sub-5 percent alignment error in key metrics. Unsupervised, interpretable, and computationally lightweight, this approach supports scalable deployment via UAVs and mobile platforms. By tailoring nonlinear scale-space modeling to SHM image alignment, this work offers a robust and physically grounded alternative to conventional techniques for tracking real-world crack evolution.",
      "authors": [
        "Xinxin Sun and Peter Chang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-06T07:25:33+00:00",
          "link": "https://arxiv.org/abs/2506.22437v1",
          "size": "5320kb",
          "version": "v1"
        }
      ],
      "title": "Robust Perspective Correction for Real-World Crack Evolution Tracking in Image-Based Structural Health Monitoring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22437",
        "PDF": "https://arxiv.org/pdf/2506.22437"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22438",
      "abstract": "Accurate pest population monitoring and tracking their dynamic changes are crucial for precision agriculture decision-making. A common limitation in existing vision-based automatic pest counting research is that models are typically evaluated on datasets with ground truth but deployed in real-world scenarios without assessing the reliability of counting results due to the lack of ground truth. To this end, this paper proposed a method for comprehensively evaluating pest counting confidence in the image, based on information related to counting results and external environmental conditions. First, a pest detection network is used for pest detection and counting, extracting counting result-related information. Then, the pest images undergo image quality assessment, image complexity assessment, and pest distribution uniformity assessment. And the changes in image clarity caused by stirring during image acquisition are quantified by calculating the average gradient magnitude. Notably, we designed a hypothesis-driven multi-factor sensitivity analysis method to select the optimal image quality assessment and image complexity assessment methods. And we proposed an adaptive DBSCAN clustering algorithm for pest distribution uniformity assessment. Finally, the obtained information related to counting results and external environmental conditions is input into a regression model for prediction, resulting in the final pest counting confidence. To the best of our knowledge, this is the first study dedicated to comprehensively evaluating counting confidence in counting tasks, and quantifying the relationship between influencing factors and counting confidence through a model. Experimental results show our method reduces MSE by 31.7% and improves R2 by 15.2% on the pest counting confidence test set, compared to the baseline built primarily on information related to counting results.",
      "authors": [
        "Xumin Gao",
        "Mark Stevens",
        "Grzegorz Cielniak"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T18:01:58+00:00",
          "link": "https://arxiv.org/abs/2506.22438v1",
          "size": "6681kb",
          "version": "v1"
        }
      ],
      "title": "Counting with Confidence: Accurate Pest Monitoring in Water Traps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22438",
        "PDF": "https://arxiv.org/pdf/2506.22438"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22439",
      "abstract": "The evaluation of LLMs has so far focused primarily on how well they can perform different tasks such as reasoning, question-answering, paraphrasing, or translating. For most of these tasks, performance can be measured with objective metrics, such as the number of correct answers. However, other language features are not easily quantified. For example, arousal, concreteness, or gender associated with a given word, as well as the extent to which we experience words with senses and relate them to a specific sense. Those features have been studied for many years by psycholinguistics, conducting large-scale experiments with humans to produce ratings for thousands of words. This opens an opportunity to evaluate how well LLMs align with human ratings on these word features, taking advantage of existing studies that cover many different language features in a large number of words. In this paper, we evaluate the alignment of a representative group of LLMs with human ratings on two psycholinguistic datasets: the Glasgow and Lancaster norms. These datasets cover thirteen features over thousands of words. The results show that alignment is \\textcolor{black}{generally} better in the Glasgow norms evaluated (arousal, valence, dominance, concreteness, imageability, familiarity, and gender) than on the Lancaster norms evaluated (introceptive, gustatory, olfactory, haptic, auditory, and visual). This suggests a potential limitation of current LLMs in aligning with human sensory associations for words, which may be due to their lack of embodied cognition present in humans and illustrates the usefulness of evaluating LLMs with psycholinguistic datasets.",
      "authors": [
        "Javier Conde",
        "Miguel Gonz\\'alez",
        "Mar\\'ia Grandury",
        "Gonzalo Mart\\'inez",
        "Pedro Reviriego",
        "Mar Brysbaert"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T20:56:48+00:00",
          "link": "https://arxiv.org/abs/2506.22439v1",
          "size": "99kb",
          "version": "v1"
        }
      ],
      "title": "Psycholinguistic Word Features: a New Approach for the Evaluation of LLMs Alignment with Humans",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22439",
        "HTML": "https://arxiv.org/html/2506.22439v1",
        "PDF": "https://arxiv.org/pdf/2506.22439"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22440",
      "abstract": "This paper introduces the Generality-Accuracy-Simplicity (GAS) framework to analyze how large language models (LLMs) are reshaping organizations and competitive strategy. We argue that viewing AI as a simple reduction in input costs overlooks two critical dynamics: (a) the inherent trade-offs among generality, accuracy, and simplicity, and (b) the redistribution of complexity across stakeholders. While LLMs appear to defy the traditional trade-off by offering high generality and accuracy through simple interfaces, this user-facing simplicity masks a significant shift of complexity to infrastructure, compliance, and specialized personnel. The GAS trade-off, therefore, does not disappear but is relocated from the user to the organization, creating new managerial challenges, particularly around accuracy in high-stakes applications. We contend that competitive advantage no longer stems from mere AI adoption, but from mastering this redistributed complexity through the design of abstraction layers, workflow alignment, and complementary expertise. This study advances AI strategy by clarifying how scalable cognition relocates complexity and redefines the conditions for technology integration.",
      "authors": [
        "Sharique Hasan",
        "Alexander Oettl",
        "Sampsa Samila"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T15:22:09+00:00",
          "link": "https://arxiv.org/abs/2506.22440v1",
          "size": "138kb",
          "version": "v1"
        }
      ],
      "title": "From Model Design to Organizational Design: Complexity Redistribution and Trade-Offs in Generative AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22440",
        "HTML": "https://arxiv.org/html/2506.22440v1",
        "PDF": "https://arxiv.org/pdf/2506.22440"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22441",
      "abstract": "Intelligent transportation systems (ITS) rely heavily on complete and high-quality spatiotemporal traffic data to achieve optimal performance. Nevertheless, in real-word traffic data collection processes, issues such as communication failures and sensor malfunctions often lead to incomplete or corrupted datasets, thereby posing significant challenges to the advancement of ITS. Among various methods for imputing missing spatiotemporal traffic data, the latent factorization of tensors (LFT) model has emerged as a widely adopted and effective solution. However, conventional LFT models typically employ the standard L2-norm in their learning objective, which makes them vulnerable to the influence of outliers. To overcome this limitation, this paper proposes a threshold distance weighted (TDW) loss-incorporated Latent Factorization of Tensors (TDWLFT) model. The proposed loss function effectively reduces the model's sensitivity to outliers by assigning differentiated weights to individual samples. Extensive experiments conducted on two traffic speed datasets sourced from diverse urban environments confirm that the proposed TDWLFT model consistently outperforms state-of-the-art approaches in terms of both in both prediction accuracy and computational efficiency.",
      "authors": [
        "Lei Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T05:36:13+00:00",
          "link": "https://arxiv.org/abs/2506.22441v1",
          "size": "819kb",
          "version": "v1"
        }
      ],
      "title": "Latent Factorization of Tensors with Threshold Distance Weighted Loss for Traffic Data Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22441",
        "PDF": "https://arxiv.org/pdf/2506.22441"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22442",
      "abstract": "In everyday reasoning, when we think about a particular object, we associate it with a unique set of expected properties such as weight, size, or more abstract attributes like density or horsepower. These expectations are shaped by our prior knowledge and the conceptual categories we have formed through experience. This paper investigates how such knowledge-based structured thinking can be reproduced in deep learning models using features based embeddings. Specially, it introduces an specific approach to build feature-grounded embedding, aiming to align shareable representations of operable dictionary with interpretable domain-specific conceptual features.",
      "authors": [
        "Piotr Makarevich"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T10:24:29+00:00",
          "link": "https://arxiv.org/abs/2506.22442v1",
          "size": "3317kb",
          "version": "v1"
        }
      ],
      "title": "Features-based embedding or Feature-grounding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22442",
        "HTML": "https://arxiv.org/html/2506.22442v1",
        "PDF": "https://arxiv.org/pdf/2506.22442"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22443",
      "abstract": "Rule-based models offer interpretability but struggle with complex data, while deep neural networks excel in performance yet lack transparency. This work investigates a neuro-symbolic rule learning neural network named RL-Net that learns interpretable rule lists through neural optimization, applied for the first time to radar-based hand gesture recognition (HGR). We benchmark RL-Net against a fully transparent rule-based system (MIRA) and an explainable black-box model (XentricAI), evaluating accuracy, interpretability, and user adaptability via transfer learning. Our results show that RL-Net achieves a favorable trade-off, maintaining strong performance (93.03% F1) while significantly reducing rule complexity. We identify optimization challenges specific to rule pruning and hierarchy bias and propose stability-enhancing modifications. Compared to MIRA and XentricAI, RL-Net emerges as a practical middle ground between transparency and performance. This study highlights the real-world feasibility of neuro-symbolic models for interpretable HGR and offers insights for extending explainable AI to edge-deployable sensing systems.",
      "authors": [
        "Sarah Seifi",
        "Tobias Sukianto",
        "Cecilia Carbonelli",
        "Lorenzo Servadei",
        "Robert Wille"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T11:30:48+00:00",
          "link": "https://arxiv.org/abs/2506.22443v1",
          "size": "371kb",
          "version": "v1"
        }
      ],
      "title": "Learning Interpretable Rules from Neural Networks: Neurosymbolic AI for Radar Hand Gesture Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22443",
        "HTML": "https://arxiv.org/html/2506.22443v1",
        "PDF": "https://arxiv.org/pdf/2506.22443"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22444",
      "abstract": "The long-term effects of Postacute Sequelae of SARS-CoV-2, known as PASC, pose a significant challenge to healthcare systems worldwide. Accurate identification of progression events, such as hospitalization and reinfection, is essential for effective patient management and resource allocation. However, traditional models trained on structured data struggle to capture the nuanced progression of PASC. In this study, we introduce the first publicly available cohort of 18 PASC patients, with text time series features based on Large Language Model Llama-3.1-70B-Instruct and clinical risk annotated by clinical expert. We propose an Active Attention Network to predict the clinical risk and identify progression events related to the risk. By integrating human expertise with active learning, we aim to enhance clinical risk prediction accuracy and enable progression events identification with fewer number of annotation. The ultimate goal is to improves patient care and decision-making for SARS-CoV-2 patient.",
      "authors": [
        "Jing Wang and Amar Sra and Jeremy C. Weiss"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T14:14:54+00:00",
          "link": "https://arxiv.org/abs/2506.22444v1",
          "size": "34kb",
          "version": "v1"
        }
      ],
      "title": "Active Learning for Forecasting Severity among Patients with Post Acute Sequelae of SARS-CoV-2",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22444",
        "HTML": "https://arxiv.org/html/2506.22444v1",
        "PDF": "https://arxiv.org/pdf/2506.22444"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22445",
      "abstract": "Cyber-Physical Systems play a critical role in the infrastructure of various sectors, including manufacturing, energy distribution, and autonomous transportation systems. However, their increasing connectivity renders them highly vulnerable to sophisticated cyber threats, such as adaptive and zero-day attacks, against which traditional security methods like rule-based intrusion detection and single-agent reinforcement learning prove insufficient. To overcome these challenges, this paper introduces a novel Hierarchical Adversarially-Resilient Multi-Agent Reinforcement Learning (HAMARL) framework. HAMARL employs a hierarchical structure consisting of local agents dedicated to subsystem security and a global coordinator that oversees and optimizes comprehensive, system-wide defense strategies. Furthermore, the framework incorporates an adversarial training loop designed to simulate and anticipate evolving cyber threats, enabling proactive defense adaptation. Extensive experimental evaluations conducted on a simulated industrial IoT testbed indicate that HAMARL substantially outperforms traditional multi-agent reinforcement learning approaches, significantly improving attack detection accuracy, reducing response times, and ensuring operational continuity. The results underscore the effectiveness of combining hierarchical multi-agent coordination with adversarially-aware training to enhance the resilience and security of next-generation CPS.",
      "authors": [
        "Saad Alqithami"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T01:38:25+00:00",
          "link": "https://arxiv.org/abs/2506.22445v1",
          "size": "50kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Adversarially-Resilient Multi-Agent Reinforcement Learning for Cyber-Physical Systems Security",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22445",
        "HTML": "https://arxiv.org/html/2506.22445v1",
        "PDF": "https://arxiv.org/pdf/2506.22445"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22446",
      "abstract": "Accurate cancer survival prediction requires integration of diverse data modalities that reflect the complex interplay between imaging, clinical parameters, and textual reports. However, existing multimodal approaches suffer from simplistic fusion strategies, massive computational requirements, and lack of interpretability-critical barriers to clinical adoption. We present EAGLE (Efficient Alignment of Generalized Latent Embeddings), a novel deep learning framework that addresses these limitations through attention-based multimodal fusion with comprehensive attribution analysis. EAGLE introduces four key innovations: (1) dynamic cross-modal attention mechanisms that learn hierarchical relationships between modalities, (2) massive dimensionality reduction (99.96%) while maintaining predictive performance, (3) three complementary attribution methods providing patient-level interpretability, and (4) a unified pipeline enabling seamless adaptation across cancer types. We evaluated EAGLE on 911 patients across three distinct malignancies: glioblastoma (GBM, n=160), intraductal papillary mucinous neoplasms (IPMN, n=171), and non-small cell lung cancer (NSCLC, n=580). Patient-level analysis showed high-risk individuals relied more heavily on adverse imaging features, while low-risk patients demonstrated balanced modality contributions. Risk stratification identified clinically meaningful groups with 4-fold (GBM) to 5-fold (NSCLC) differences in median survival, directly informing treatment intensity decisions. By combining state-of-the-art performance with clinical interpretability, EAGLE bridges the gap between advanced AI capabilities and practical healthcare deployment, offering a scalable solution for multimodal survival prediction that enhances both prognostic accuracy and physician trust in automated predictions.",
      "authors": [
        "Aakash Tripathi",
        "Asim Waqas",
        "Matthew B. Schabath",
        "Yasin Yilmaz",
        "Ghulam Rasool"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T03:56:13+00:00",
          "link": "https://arxiv.org/abs/2506.22446v1",
          "size": "3779kb",
          "version": "v1"
        }
      ],
      "title": "EAGLE: Efficient Alignment of Generalized Latent Embeddings for Multimodal Survival Prediction with Interpretable Attribution Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22446",
        "HTML": "https://arxiv.org/html/2506.22446v1",
        "PDF": "https://arxiv.org/pdf/2506.22446"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22447",
      "abstract": "Global Climate Models (GCMs) are critical for simulating large-scale climate dynamics, but their coarse spatial resolution limits their applicability in regional studies. Regional Climate Models (RCMs) refine this through dynamic downscaling, albeit at considerable computational cost and with limited flexibility. While deep learning has emerged as an efficient data-driven alternative, most existing studies have focused on single-variable models that downscale one variable at a time. This approach can lead to limited contextual awareness, redundant computation, and lack of cross-variable interaction. Our study addresses these limitations by proposing a multi-task, multi-variable Vision Transformer (ViT) architecture with a shared encoder and variable-specific decoders (1EMD). The proposed architecture jointly predicts three key climate variables: surface temperature (tas), wind speed (sfcWind), and 500 hPa geopotential height (zg500), directly from GCM-resolution inputs, emulating RCM-scale downscaling over Europe. We show that our multi-variable approach achieves positive cross-variable knowledge transfer and consistently outperforms single-variable baselines trained under identical conditions, while also improving computational efficiency. These results demonstrate the effectiveness of multi-variable modeling for high-resolution climate downscaling.",
      "authors": [
        "Fabio Merizzi",
        "Harilaos Loukos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T11:48:41+00:00",
          "link": "https://arxiv.org/abs/2506.22447v1",
          "size": "14255kb",
          "version": "v1"
        }
      ],
      "title": "Vision Transformers for Multi-Variable Climate Downscaling: Emulating Regional Climate Models with a Shared Encoder and Multi-Decoder Architecture",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22447",
        "HTML": "https://arxiv.org/html/2506.22447v1",
        "PDF": "https://arxiv.org/pdf/2506.22447"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22449",
      "abstract": "This thesis explores the impact of the Climate Emergency movement on local government climate policy, using computational methods. The Climate Emergency movement sought to accelerate climate action at local government level through the mechanism of Climate Emergency Declarations (CEDs), resulting in a series of commitments from councils to treat climate change as an emergency. With the aim of assessing the potential of current large language models to answer complex policy questions, I first built and configured a system named PALLM (Policy Analysis with a Large Language Model), using the OpenAI model GPT-4. This system is designed to apply a conceptual framework for climate emergency response plans to a dataset of climate policy documents. I validated the performance of this system with the help of local government policymakers, by generating analyses of the climate policies of 11 local governments in Victoria and assessing the policymakers' level of agreement with PALLM's responses. Having established that PALLM's performance is satisfactory, I used it to conduct a large-scale analysis of current policy documents from local governments in the state of Victoria, Australia. This thesis presents the methodology and results of this analysis, comparing the results for councils which have passed a CED to those which did not. This study finds that GPT-4 is capable of high-level policy analysis, with limitations including a lack of reliable attribution, and can also enable more nuanced analysis by researchers. Its use in this research shows that councils which have passed a CED are more likely to have a recent and climate-specific policy, and show more attention to urgency, prioritisation, and equity and social justice, than councils which have not. It concludes that the ability to assess policy documents at scale opens up exciting new opportunities for policy researchers.",
      "authors": [
        "Carolyn Hicks"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T00:13:30+00:00",
          "link": "https://arxiv.org/abs/2506.22449v1",
          "size": "1385kb",
          "version": "v1"
        }
      ],
      "title": "Computational Analysis of Climate Policy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22449",
        "PDF": "https://arxiv.org/pdf/2506.22449"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22463",
      "abstract": "Diffusion models have emerged as powerful generative models, but their high computation cost in iterative sampling remains a significant bottleneck. In this work, we present an in-depth and insightful study of state-of-the-art acceleration techniques for diffusion models, including caching and quantization, revealing their limitations in computation error and generation quality. To break these limits, this work introduces Modulated Diffusion (MoDiff), an innovative, rigorous, and principled framework that accelerates generative modeling through modulated quantization and error compensation. MoDiff not only inherents the advantages of existing caching and quantization methods but also serves as a general framework to accelerate all diffusion models. The advantages of MoDiff are supported by solid theoretical insight and analysis. In addition, extensive experiments on CIFAR-10 and LSUN demonstrate that MoDiff significant reduces activation quantization from 8 bits to 3 bits without performance degradation in post-training quantization (PTQ). Our code implementation is available at https://github.com/WeizhiGao/MoDiff.",
      "authors": [
        "Weizhi Gao",
        "Zhichao Hou",
        "Junqi Yin",
        "Feiyi Wang",
        "Linyu Peng",
        "Xiaorui Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T03:31:53+00:00",
          "link": "https://arxiv.org/abs/2506.22463v1",
          "size": "3968kb",
          "version": "v1"
        }
      ],
      "title": "Modulated Diffusion: Accelerating Generative Modeling with Modulated Quantization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22463",
        "PDF": "https://arxiv.org/pdf/2506.22463"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22464",
      "abstract": "This paper presents a novel localization algorithm for wireless sensor networks (WSNs) called Golden Ratio Localization (GRL), which leverages the mathematical properties of the golden ratio (phi 1.618) to optimize both node placement and communication range. GRL introduces phi-based anchor node deployment and hop-sensitive weighting using phi-exponents to improve localization accuracy while minimizing energy consumption. Through extensive simulations conducted on a 100 m * 100 m sensor field with 100 nodes and 10 anchors, GRL achieved an average localization error of 2.35 meters, outperforming DV- Hop (3.87 meters) and Centroid (4.95 meters). In terms of energy efficiency, GRL reduced localization energy consumption to 1.12 microJ per node, compared to 1.78 microJ for DV-Hop and 1.45 microJ for Centroid. These results confirm that GRL provides a more balanced and efficient localization approach, making it especially suitable for energy-constrained and large-scale WSN deployments.",
      "authors": [
        "Hitesh Mohapatra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T04:26:16+00:00",
          "link": "https://arxiv.org/abs/2506.22464v1",
          "size": "688kb",
          "version": "v1"
        }
      ],
      "title": "Golden Ratio Assisted Localization for Wireless Sensor Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22464",
        "HTML": "https://arxiv.org/html/2506.22464v1",
        "PDF": "https://arxiv.org/pdf/2506.22464"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22466",
      "abstract": "The android robot Andrea was set up at a public museum in Germany for six consecutive days to have conversations with visitors, fully autonomously. No specific context was given, so visitors could state their opinions regarding possible use-cases in structured interviews, without any bias. Additionally the 44 interviewees were asked for their general opinions of the robot, their reasons (not) to interact with it and necessary improvements for future use. The android's voice and wig were changed between different days of operation to give varying cues regarding its gender. This did not have a significant impact on the positive overall perception of the robot. Most visitors want the robot to provide information about exhibits in the future, while opinions on other roles, like a receptionist, were both wanted and explicitly not wanted by different visitors. Speaking more languages (than only English) and faster response times were the improvements most desired. These findings from the interviews are in line with an analysis of the system logs, which revealed, that after chitchat and personal questions, most of the 4436 collected requests asked for information related to the museum and to converse in a different language. The valuable insights gained from these real-world interactions are now used to improve the system to become a useful real-world application.",
      "authors": [
        "Marcel Heisler and Christian Becker-Asano"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T15:30:20+00:00",
          "link": "https://arxiv.org/abs/2506.22466v1",
          "size": "2490kb",
          "version": "v1"
        }
      ],
      "title": "Conversations with Andrea: Visitors' Opinions on Android Robots in a Museum",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22466",
        "HTML": "https://arxiv.org/html/2506.22466v1",
        "PDF": "https://arxiv.org/pdf/2506.22466"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22470",
      "abstract": "Delay/Disruption Tolerant Networking (DTN) employs the Licklider Transmission Protocol (LTP) with Automatic Repeat reQuest (ARQ) for reliable data delivery in challenging interplanetary networks. While previous studies have integrated packet-level Forward Erasure Correction (FEC) into LTP to reduce retransmission time costs, existing static and delay-feedback-based dynamic coding methods struggle with highly variable and unpredictable deep space channel conditions. This paper proposes a reinforcement learning (RL)-based adaptive FEC algorithm to address these limitations. The algorithm utilizes historical feedback and system state to predict future channel conditions and proactively adjust the code rate. This approach aims to anticipate channel quality degradation, thereby preventing decoding failures and subsequent LTP retransmissions and improving coding efficiency by minimizing redundancy during favorable channel conditions. Performance evaluations conducted in simulated Earth-Moon and Earth-Mars link scenarios demonstrate this algorithm's effectiveness in optimizing data transmission for interplanetary networks. Compared to existing methods, this approach demonstrates significant improvement, with matrix decoding failures reduced by at least 2/3.",
      "authors": [
        "Liang Chen",
        "Yu Song",
        "Kanglian Zhao",
        "Juan A. Fraire",
        "and Wenfeng Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T14:20:23+00:00",
          "link": "https://arxiv.org/abs/2506.22470v1",
          "size": "6064kb",
          "version": "v1"
        }
      ],
      "title": "Reliable Transmission of LTP Using Reinforcement Learning-Based Adaptive FEC",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22470",
        "HTML": "https://arxiv.org/html/2506.22470v1",
        "PDF": "https://arxiv.org/pdf/2506.22470"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22473",
      "abstract": "The movements of both animals and robots give rise to streams of high-dimensional motor and sensory information. Imagine the brain of a newborn or the controller of a baby humanoid robot trying to make sense of unprocessed sensorimotor time series. Here, we present a framework for studying the dynamic functional connectivity between the multimodal sensory signals of a robotic agent to uncover an underlying structure. Using instantaneous mutual information, we capture the time-varying functional connectivity (FC) between proprioceptive, tactile, and visual signals, revealing the sensorimotor relationships. Using an infinite relational model, we identified sensorimotor modules and their evolving connectivity. To further interpret these dynamic interactions, we employed non-negative matrix factorization, which decomposed the connectivity patterns into additive factors and their corresponding temporal coefficients. These factors can be considered the agent's motion primitives or movement synergies that the agent can use to make sense of its sensorimotor space and later for behavior selection. In the future, the method can be deployed in robot learning as well as in the analysis of human movement trajectories or brain signals.",
      "authors": [
        "Fernando Diaz Ledezma",
        "Valentin Marcel",
        "and Matej Hoffmann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T14:56:16+00:00",
          "link": "https://arxiv.org/abs/2506.22473v1",
          "size": "8162kb",
          "version": "v1"
        }
      ],
      "title": "Unsupervised Discovery of Behavioral Primitives from Sensorimotor Dynamic Functional Connectivity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22473",
        "HTML": "https://arxiv.org/html/2506.22473v1",
        "PDF": "https://arxiv.org/pdf/2506.22473"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22474",
      "abstract": "The Internet of Things (IoT) has been increasingly used in our everyday lives as well as in numerous industrial applications. However, due to limitations in computing and power capabilities, IoT devices need to send their respective tasks to cloud service stations that are usually located at far distances. Having to transmit data far distances introduces challenges for services that require low latency such as industrial control in factories and plants as well as artificial intelligence assisted autonomous driving. To solve this issue, mobile edge computing (MEC) is deployed at the networks edge to reduce transmission time. In this regard, this study proposes a new offloading scheme for MEC-assisted ultra dense cellular networks using reinforcement learning (RL) techniques. The proposed scheme enables efficient resource allocation and dynamic offloading decisions based on varying network conditions and user demands. The RL algorithm learns from the networks historical data and adapts the offloading decisions to optimize the networks overall performance. Non-orthogonal multiple access is also adopted to improve resource utilization among the IoT devices. Simulation results demonstrate that the proposed scheme outperforms other stateof the art offloading algorithms in terms of energy efficiency, network throughput, and user satisfaction.",
      "authors": [
        "Ziad Qais Al Abbasi",
        "Khaled M. Rabie",
        "Senior Member",
        "Xingwang Li",
        "Senior Member",
        "Wali Ullah Khan",
        "and Asma Abu Samah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T20:42:32+00:00",
          "link": "https://arxiv.org/abs/2506.22474v1",
          "size": "787kb",
          "version": "v1"
        }
      ],
      "title": "RL-based Adaptive Task Offloading in Mobile-Edge Computing for Future IoT Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22474",
        "HTML": "https://arxiv.org/html/2506.22474v1",
        "PDF": "https://arxiv.org/pdf/2506.22474"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22477",
      "abstract": "This paper introduces an innovative design for robotic operating platforms, underpinned by a transformative Internet of Things (IoT) architecture, seamlessly integrating cutting-edge technologies such as large language models (LLMs), generative AI, edge computing, and 5G networks. The proposed platform aims to elevate the intelligence and autonomy of IoT systems and robotics, enabling them to make real-time decisions and adapt dynamically to changing environments. Through a series of compelling case studies across industries including smart manufacturing, healthcare, and service sectors, this paper demonstrates the substantial potential of IoT-enabled robotics to optimize operational workflows, enhance productivity, and deliver innovative, scalable solutions. By emphasizing the roles of LLMs and generative AI, the research highlights how these technologies drive the evolution of intelligent robotics and IoT, shaping the future of industry-specific advancements. The findings not only showcase the transformative power of these technologies but also offer a forward-looking perspective on their broader societal and industrial implications, positioning them as catalysts for next-generation automation and technological convergence.",
      "authors": [
        "Huiwen Han"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-22T00:12:20+00:00",
          "link": "https://arxiv.org/abs/2506.22477v1",
          "size": "406kb",
          "version": "v1"
        }
      ],
      "title": "Innovative Research on IoT Architecture and Robotic Operating Platforms: Applications of Large Language Models and Generative AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22477",
        "PDF": "https://arxiv.org/pdf/2506.22477"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22480",
      "abstract": "As users in small cell networks increasingly rely on computation-intensive services, cloud-based access often results in high latency. Multi-access edge computing (MEC) mitigates this by bringing computational resources closer to end users, with small base stations (SBSs) serving as edge servers to enable low-latency service delivery. However, limited edge capacity makes it challenging to decide which services to deploy locally versus in the cloud, especially under unknown service demand and dynamic network conditions. To tackle this problem, we model service demand as a linear function of service attributes and formulate the service placement task as a linear bandit problem, where SBSs act as agents and services as arms. The goal is to identify the service that, when placed at the edge, offers the greatest reduction in total user delay compared to cloud deployment. We propose a distributed and adaptive multi-agent best-arm identification (BAI) algorithm under a fixed-confidence setting, where SBSs collaborate to accelerate learning. Simulations show that our algorithm identifies the optimal service with the desired confidence and achieves near-optimal speedup, as the number of learning rounds decreases proportionally with the number of SBSs. We also provide theoretical analysis of the algorithm's sample complexity and communication overhead.",
      "authors": [
        "Mariam Yahya",
        "Aydin Sezgin",
        "Setareh Maghsudi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-22T12:45:01+00:00",
          "link": "https://arxiv.org/abs/2506.22480v1",
          "size": "700kb",
          "version": "v1"
        }
      ],
      "title": "Service Placement in Small Cell Networks Using Distributed Best Arm Identification in Linear Bandits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22480",
        "HTML": "https://arxiv.org/html/2506.22480v1",
        "PDF": "https://arxiv.org/pdf/2506.22480"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22481",
      "abstract": "In recent years, significant advancements in the field of Natural Language Processing (NLP) have positioned commercialized language models as wide-reaching, highly useful tools. In tandem, there has been an explosion of multidisciplinary research examining how NLP tasks reflect, perpetuate, and amplify social biases such as gender and racial bias. A significant gap in this scholarship is a detailed analysis of how queer sexualities are encoded and (mis)represented by both NLP systems and practitioners. Following previous work in the field of AI fairness, we document how sexuality is defined and operationalized via a survey and analysis of 55 articles that quantify sexuality-based NLP bias. We find that sexuality is not clearly defined in a majority of the literature surveyed, indicating a reliance on assumed or normative conceptions of sexual/romantic practices and identities. Further, we find that methods for extracting biased outputs from NLP technologies often conflate gender and sexual identities, leading to monolithic conceptions of queerness and thus improper quantifications of bias. With the goal of improving sexuality-based NLP bias analyses, we conclude with recommendations that encourage more thorough engagement with both queer communities and interdisciplinary literature.",
      "authors": [
        "Jacob Hobbs"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-22T18:16:53+00:00",
          "link": "https://arxiv.org/abs/2506.22481v1",
          "size": "37kb",
          "version": "v1"
        }
      ],
      "title": "Theories of \"Sexuality\" in Natural Language Processing Bias Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22481",
        "HTML": "https://arxiv.org/html/2506.22481v1",
        "PDF": "https://arxiv.org/pdf/2506.22481"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22482",
      "abstract": "With the advent of Internet of Things, Wireless Home Automation Systems WHAS are gradually gaining popularity. These systems are faced with multiple challenges such as security; controlling a variety of home appliances with a single interface and user friendliness. In this paper we propose a system that uses secure authentication systems of social networking websites such as Twitter, tracks the end-users activities on the social network and then control his or her domestic appliances. At the end, we highlight the applications of the proposed WHAS and compare the advantages of our proposed system over traditional home automation systems.",
      "authors": [
        "Divya Alok Gupta",
        "Dwith Chenna",
        "B. Aditya Vighnesh Ramakanth"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Cryptography and Security (cs.CR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T06:21:58+00:00",
          "link": "https://arxiv.org/abs/2506.22482v1",
          "size": "198kb",
          "version": "v1"
        }
      ],
      "title": "Wireless Home Automation Using Social Networking Websites",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22482",
        "PDF": "https://arxiv.org/pdf/2506.22482"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22484",
      "abstract": "Urban cellular networks face complex performance challenges due to high infrastructure density, varied user mobility, and diverse service demands. While several datasets address network behaviour across different environments, there is a lack of datasets that captures user centric Quality of Experience (QoE), and diverse mobility patterns needed for efficient network planning and optimization solutions, which are important for QoE driven optimizations and mobility management. This study presents a curated dataset of 30,925 labelled records, collected using GNetTrack Pro within a 2 km2 dense urban area, spanning three major commercial network operators. The dataset captures key signal quality parameters (e.g., RSRP, RSRQ, SNR), across multiple real world mobility modes including pedestrian routes, canopy walkways, shuttle buses, and Bus Rapid Transit (BRT) routes. It also includes diverse network traffic scenarios including (1) FTP upload and download, (2) video streaming, and (3) HTTP browsing. A total of 132 physical cell sites were identified and validated through OpenCellID and on-site field inspections, illustrating the high cell density characteristic of 5G and emerging heterogeneous network deployment. The dataset is particularly suited for machine learning applications, such as handover optimization, signal quality prediction, and multi operator performance evaluation. Released in a structured CSV format with accompanying preprocessing and visualization scripts, this dataset offers a reproducible, application ready resource for researchers and practitioners working on urban cellular network planning and optimization.",
      "authors": [
        "Muhammad Kabeer",
        "Rosdiadee Nordin",
        "Mehran Behjati",
        "Farah Yasmin binti Mohd Shaharuddin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T10:49:59+00:00",
          "link": "https://arxiv.org/abs/2506.22484v1",
          "size": "1627kb",
          "version": "v1"
        }
      ],
      "title": "An Urban Multi-Operator QoE-Aware Dataset for Cellular Networks in Dense Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22484",
        "PDF": "https://arxiv.org/pdf/2506.22484"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22485",
      "abstract": "This study presents a modular, multi-agent system for the automated review of highly structured enterprise business documents using AI agents. Unlike prior solutions focused on unstructured texts or limited compliance checks, this framework leverages modern orchestration tools such as LangChain, CrewAI, TruLens, and Guidance to enable section-by-section evaluation of documents for accuracy, consistency, completeness, and clarity. Specialized agents, each responsible for discrete review criteria such as template compliance or factual correctness, operate in parallel or sequence as required. Evaluation outputs are enforced to a standardized, machine-readable schema, supporting downstream analytics and auditability. Continuous monitoring and a feedback loop with human reviewers allow for iterative system improvement and bias mitigation.\n  Quantitative evaluation demonstrates that the AI Agent-as-Judge system approaches or exceeds human performance in key areas: achieving 99% information consistency (vs. 92% for humans), halving error and bias rates, and reducing average review time from 30 to 2.5 minutes per document, with a 95% agreement rate between AI and expert human judgment. While promising for a wide range of industries, the study also discusses current limitations, including the need for human oversight in highly specialized domains and the operational cost of large-scale LLM usage. The proposed system serves as a flexible, auditable, and scalable foundation for AI-driven document quality assurance in the enterprise context.",
      "authors": [
        "Sudip Dasgupta",
        "Himanshu Shankar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T17:46:15+00:00",
          "link": "https://arxiv.org/abs/2506.22485v1",
          "size": "59kb",
          "version": "v1"
        }
      ],
      "title": "AI Agents-as-Judge: Automated Assessment of Accuracy, Consistency, Completeness and Clarity for Enterprise Documents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22485",
        "HTML": "https://arxiv.org/html/2506.22485v1",
        "PDF": "https://arxiv.org/pdf/2506.22485"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22486",
      "abstract": "Since the introduction of ChatGPT, large language models (LLMs) have demonstrated significant utility in various tasks, such as answering questions through retrieval-augmented generation. Context can be retrieved using a vectorized database, serving as a foundation for LLMs to generate responses. However, hallucinations in responses can undermine the reliability of LLMs in practical applications, and they are not easily detectable in the absence of ground truth, particularly in question-and-answer scenarios. This paper proposes a framework that integrates multiple small language models to verify responses generated by LLMs using the retrieved context from a vectorized database. By breaking down the responses into individual sentences and utilizing the probability of generating \"Yes\" tokens from the outputs of multiple models for a given set of questions, responses, and relevant context, hallucinations can be detected. The proposed framework is validated through experiments with real datasets comprising over 100 sets of questions, answers, and contexts, including responses with fully and partially correct sentences. The results demonstrate a 10\\% improvement in F1 scores for detecting correct responses compared to hallucinations, indicating that multiple small language models can be effectively employed for answer verification, providing a scalable and efficient solution for both academic and practical applications.",
      "authors": [
        "Ming Cheung"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T02:19:26+00:00",
          "link": "https://arxiv.org/abs/2506.22486v1",
          "size": "1950kb",
          "version": "v1"
        }
      ],
      "title": "Hallucination Detection with Small Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22486",
        "HTML": "https://arxiv.org/html/2506.22486v1",
        "PDF": "https://arxiv.org/pdf/2506.22486"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22487",
      "abstract": "The integration of the Internet of Everything (IoX) and Artificial General Intelligence (AGI) has given rise to a transformative paradigm aimed at addressing critical bottlenecks across sensing, network, and application layers in Cyber-Physical-Social Thinking (CPST) ecosystems. In this survey, we provide a systematic and comprehensive review of AGI-enhanced IoX research, focusing on three key components: sensing-layer data management, network-layer protocol optimization, and application-layer decision-making frameworks. Specifically, this survey explores how AGI can mitigate IoX bottlenecks challenges by leveraging adaptive sensor fusion, edge preprocessing, and selective attention mechanisms at the sensing layer, while resolving network-layer issues such as protocol heterogeneity and dynamic spectrum management, neuro-symbolic reasoning, active inference, and causal reasoning, Furthermore, the survey examines AGI-enabled frameworks for managing identity and relationship explosion. Key findings suggest that AGI-driven strategies, such as adaptive sensor fusion, edge preprocessing, and semantic modeling, offer novel solutions to sensing-layer data overload, network-layer protocol heterogeneity, and application-layer identity explosion. The survey underscores the importance of cross-layer integration, quantum-enabled communication, and ethical governance frameworks for future AGI-enabled IoX systems. Finally, the survey identifies unresolved challenges, such as computational requirements, scalability, and real-world validation, calling for further research to fully realize AGI's potential in addressing IoX bottlenecks. we believe AGI-enhanced IoX is emerging as a critical research field at the intersection of interconnected systems and advanced AI.",
      "authors": [
        "Amar Khelloufi",
        "Huansheng Ning",
        "Sahraoui Dhelim",
        "Jianguo Ding"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T02:33:43+00:00",
          "link": "https://arxiv.org/abs/2506.22487v1",
          "size": "3975kb",
          "version": "v1"
        }
      ],
      "title": "AGI Enabled Solutions For IoX Layers Bottlenecks In Cyber-Physical-Social-Thinking Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22487",
        "HTML": "https://arxiv.org/html/2506.22487v1",
        "PDF": "https://arxiv.org/pdf/2506.22487"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22489",
      "abstract": "This paper proposes a comprehensive methodology for siting fusion energy facilities, integrating expert judgment, geospatial data, and multi-criteria decision making tools to evaluate site suitability systematically. As a case study, we apply this framework to all currently operational coal power plant sites in the United States to examine their potential for hosting future fusion facilities at a time when these coal plants are shut down on reaching their end of life - timelines which are expected to coincide with the potential deployment of fusion energy facilities. Drawing on 22 siting criteria - including state and federal policies, risk and hazard assessments, and spatial and infrastructural parameters - we implement two MultiCriteria Decision-Making (MCDM) methods: the Fuzzy Full Consistency Method (F-FUCOM) to derive attribute weights and the Weighted Sum Method (WSM) to rank sites based on composite suitability scores. By focusing on fusion-specific siting needs and demonstrating the framework through a coal site application, this study contributes a scalable and transparent decision-support tool for identifying optimal fusion energy deployment locations.",
      "authors": [
        "Muhammad R. Abdussami",
        "Kevin Daley",
        "Gabrielle Hoelzle",
        "and Aditi Verma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Applied Physics (physics.app-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T07:16:30+00:00",
          "link": "https://arxiv.org/abs/2506.22489v1",
          "size": "838kb",
          "version": "v1"
        }
      ],
      "title": "A Multi-Criteria Evaluation Framework for Siting Fusion Energy Facilities: Application and Evaluation of U.S. Coal Power Plants",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22489",
        "HTML": "https://arxiv.org/html/2506.22489v1",
        "PDF": "https://arxiv.org/pdf/2506.22489"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22491",
      "abstract": "Given the rise of conflicts on social media, effective classification models to detect harmful behaviours are essential. Following the garbage-in-garbage-out maxim, machine learning performance depends heavily on training data quality. However, high-quality labelled data, especially for nuanced tasks like identifying conflict behaviours, is limited, expensive, and difficult to obtain. Additionally, as social media platforms increasingly restrict access to research data, text data augmentation is gaining attention as an alternative to generate training data. Augmenting conflict-related data poses unique challenges due to Large Language Model (LLM) guardrails that prevent generation of offensive content. This paper introduces PromptAug, an innovative LLM-based data augmentation method. PromptAug achieves statistically significant improvements of 2% in both accuracy and F1-score on conflict and emotion datasets. To thoroughly evaluate PromptAug against other data augmentation methods we conduct a robust evaluation using extreme data scarcity scenarios, quantitative diversity analysis and a qualitative thematic analysis. The thematic analysis identifies four problematic patterns in augmented text: Linguistic Fluidity, Humour Ambiguity, Augmented Content Ambiguity, and Augmented Content Misinterpretation.\n  Overall, this work presents PromptAug as an effective method for augmenting data in sensitive tasks like conflict detection, offering a unique, interdisciplinary evaluation grounded in both natural language processing and social science methodology.",
      "authors": [
        "Oliver Warke",
        "Joemon M. Jose",
        "Faegheh Hasibi",
        "and Jan Breitsohl"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T15:33:18+00:00",
          "link": "https://arxiv.org/abs/2506.22491v1",
          "size": "288kb",
          "version": "v1"
        }
      ],
      "title": "PromptAug: Fine-grained Conflict Classification Using Data Augmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22491",
        "HTML": "https://arxiv.org/html/2506.22491v1",
        "PDF": "https://arxiv.org/pdf/2506.22491"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22492",
      "abstract": "Recent advances in machine learning, particularly the emergence of foundation models, are leading to new opportunities to develop technology-based solutions to societal problems. However, the reasoning and inner workings of today's complex AI models are not transparent to the user, and there are no safety guarantees regarding their predictions. Consequently, to fulfill the promise of AI, we must address the following scientific challenge: how to develop AI-based systems that are not only accurate and performant but also safe and trustworthy?\n  The criticality of safe operation is particularly evident for autonomous systems for control and robotics, and was the catalyst for the Safe Learning Enabled Systems (SLES) program at NSF. For the broader class of AI applications, such as users interacting with chatbots and clinicians receiving treatment recommendations, safety is, while no less important, less well-defined with context-dependent interpretations. This motivated the organization of a day-long workshop, held at University of Pennsylvania on February 26, 2025, to bring together investigators funded by the NSF SLES program with a broader pool of researchers studying AI safety. This report is the result of the discussions in the working groups that addressed different aspects of safety at the workshop. The report articulates a new research agenda focused on developing theory, methods, and tools that will provide the foundations of the next generation of AI-enabled systems.",
      "authors": [
        "Rajeev Alur",
        "Greg Durrett",
        "Hadas Kress-Gazit",
        "Corina P\\u{a}s\\u{a}reanu",
        "and Ren\\'e Vidal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T18:55:29+00:00",
          "link": "https://arxiv.org/abs/2506.22492v1",
          "size": "105kb",
          "version": "v1"
        }
      ],
      "title": "Report on NSF Workshop on Science of Safe AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22492",
        "HTML": "https://arxiv.org/html/2506.22492v1",
        "PDF": "https://arxiv.org/pdf/2506.22492"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22493",
      "abstract": "Political Compass Test (PCT) or similar questionnaires have been used to quantify LLM's political leanings. Building on a recent line of work that examines the validity of PCT tests, we demonstrate that variation in standard generation parameters does not significantly impact the models' PCT scores. However, external factors such as prompt variations and fine-tuning individually and in combination affect the same. Finally, we demonstrate that when models are fine-tuned on text datasets with higher political content than others, the PCT scores are not differentially affected. This calls for a thorough investigation into the validity of PCT and similar tests, as well as the mechanism by which political leanings are encoded in LLMs.",
      "authors": [
        "Sadia Kamal",
        "Lalu Prasad Yadav Prakash",
        "S M Rafiuddin",
        "Mohammed Rakib",
        "Arunkumar Bagavathi",
        "Atriya Sen",
        "Sagnik Ray Choudhury"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T20:33:51+00:00",
          "link": "https://arxiv.org/abs/2506.22493v1",
          "size": "251kb",
          "version": "v1"
        }
      ],
      "title": "A Detailed Factor Analysis for the Political Compass Test: Navigating Ideologies of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22493",
        "HTML": "https://arxiv.org/html/2506.22493v1",
        "PDF": "https://arxiv.org/pdf/2506.22493"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22494",
      "abstract": "This paper introduces a new framework, DriveBLIP2, built upon the BLIP2-OPT architecture, to generate accurate and contextually relevant explanations for emerging driving scenarios. While existing vision-language models perform well in general tasks, they encounter difficulties in understanding complex, multi-object environments, particularly in real-time applications such as autonomous driving, where the rapid identification of key objects is crucial. To address this limitation, an Attention Map Generator is proposed to highlight significant objects relevant to driving decisions within critical video frames. By directing the model's focus to these key regions, the generated attention map helps produce clear and relevant explanations, enabling drivers to better understand the vehicle's decision-making process in critical situations. Evaluations on the DRAMA dataset reveal significant improvements in explanation quality, as indicated by higher BLEU, ROUGE, CIDEr, and SPICE scores compared to baseline models. These findings underscore the potential of targeted attention mechanisms in vision-language models for enhancing explainability in real-time autonomous driving.",
      "authors": [
        "Shihong Ling",
        "Yue Wan",
        "Xiaowei Jia",
        "Na Du"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T00:46:38+00:00",
          "link": "https://arxiv.org/abs/2506.22494v1",
          "size": "2255kb",
          "version": "v1"
        }
      ],
      "title": "DriveBLIP2: Attention-Guided Explanation Generation for Complex Driving Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22494",
        "HTML": "https://arxiv.org/html/2506.22494v1",
        "PDF": "https://arxiv.org/pdf/2506.22494"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22496",
      "abstract": "Large Language Models (LLMs) exhibit systematic risk-taking behaviors analogous to those observed in gambling psychology, including overconfidence bias, loss-chasing tendencies, and probability misjudgment. Drawing from behavioral economics and prospect theory, we identify and formalize these \"gambling-like\" patterns where models sacrifice accuracy for high-reward outputs, exhibit escalating risk-taking after errors, and systematically miscalibrate uncertainty. We propose the Risk-Aware Response Generation (RARG) framework, incorporating insights from gambling research to address these behavioral biases through risk-calibrated training, loss-aversion mechanisms, and uncertainty-aware decision making. Our approach introduces novel evaluation paradigms based on established gambling psychology experiments, including AI adaptations of the Iowa Gambling Task and probability learning assessments. Experimental results demonstrate measurable reductions in gambling-like behaviors: 18.7\\% decrease in overconfidence bias, 24.3\\% reduction in loss-chasing tendencies, and improved risk calibration across diverse scenarios. This work establishes the first systematic framework for understanding and mitigating gambling psychology patterns in AI systems.",
      "authors": [
        "Y. Du"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T03:45:35+00:00",
          "link": "https://arxiv.org/abs/2506.22496v1",
          "size": "58kb",
          "version": "v1"
        }
      ],
      "title": "Mitigating Gambling-Like Risk-Taking Behaviors in Large Language Models: A Behavioral Economics Approach to AI Safety",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22496",
        "HTML": "https://arxiv.org/html/2506.22496v1",
        "PDF": "https://arxiv.org/pdf/2506.22496"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22497",
      "abstract": "This paper reconceptualises peer review as structured public commentary. Traditional academic validation is hindered by anonymity, latency, and gatekeeping. We propose a transparent, identity-linked, and reproducible system of scholarly evaluation anchored in open commentary. Leveraging blockchain for immutable audit trails and AI for iterative synthesis, we design a framework that incentivises intellectual contribution, captures epistemic evolution, and enables traceable reputational dynamics. This model empowers fields from computational science to the humanities, reframing academic knowledge as a living process rather than a static credential.",
      "authors": [
        "Craig Steven Wright"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Digital Libraries (cs.DL)",
        "Social and Information Networks (cs.SI)",
        "History and Philosophy of Physics (physics.hist-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T03:57:40+00:00",
          "link": "https://arxiv.org/abs/2506.22497v1",
          "size": "62kb",
          "version": "v1"
        }
      ],
      "title": "Peer Review as Structured Commentary: Immutable Identity, Public Dialogue, and Reproducible Scholarship",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22497",
        "HTML": "https://arxiv.org/html/2506.22497v1",
        "PDF": "https://arxiv.org/pdf/2506.22497"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22498",
      "abstract": "Bed-related falls remain a leading source of injury in hospitals and long-term-care facilities, yet many commercial alarms trigger only after a patient has already left the bed. We show that early bed-exit intent can be predicted using only four low-cost load cells mounted under the bed legs. The resulting load signals are first converted into a compact set of complementary images: an RGB line plot that preserves raw waveforms and three texture maps - recurrence plot, Markov transition field, and Gramian angular field - that expose higher-order dynamics. We introduce ViFusionTST, a dual-stream Swin Transformer that processes the line plot and texture maps in parallel and fuses them through cross-attention to learn data-driven modality weights.\n  To provide a realistic benchmark, we collected six months of continuous data from 95 beds in a long-term-care facility. On this real-world dataset ViFusionTST reaches an accuracy of 0.885 and an F1 score of 0.794, surpassing recent 1D and 2D time-series baselines across F1, recall, accuracy, and AUPRC. The results demonstrate that image-based fusion of load-sensor signals for time series classification is a practical and effective solution for real-time, privacy-preserving fall prevention.",
      "authors": [
        "Hao Liu",
        "Yu Hu",
        "Rakiba Rayhana",
        "Ling Bai",
        "and Zheng Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T06:30:59+00:00",
          "link": "https://arxiv.org/abs/2506.22498v1",
          "size": "1563kb",
          "version": "v1"
        }
      ],
      "title": "ViFusionTST: Deep Fusion of Time-Series Image Representations from Load Signals for Early Bed-Exit Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22498",
        "HTML": "https://arxiv.org/html/2506.22498v1",
        "PDF": "https://arxiv.org/pdf/2506.22498"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22499",
      "abstract": "This study presents a novel integrated framework for dynamic origin-destination demand estimation (DODE) in multi-class mesoscopic network models, leveraging high-resolution satellite imagery together with conventional traffic data from local sensors. Unlike sparse local detectors, satellite imagery offers consistent, city-wide road and traffic information of both parking and moving vehicles, overcoming data availability limitations. To extract information from imagery data, we design a computer vision pipeline for class-specific vehicle detection and map matching, generating link-level traffic density observations by vehicle class. Building upon this information, we formulate a computational graph-based DODE model that calibrates dynamic network states by jointly matching observed traffic counts and travel times from local sensors with density measurements derived from satellite imagery. To assess the accuracy and scalability of the proposed framework, we conduct a series of numerical experiments using both synthetic and real-world data. The results of out-of-sample tests demonstrate that supplementing traditional data with satellite-derived density significantly improves estimation performance, especially for links without local sensors. Real-world experiments also confirm the framework's capability to handle large-scale networks, supporting its potential for practical deployment in cities of varying sizes. Sensitivity analysis further evaluates the impact of data quality related to satellite imagery data.",
      "authors": [
        "Jiachao Liu",
        "Pablo Guarda",
        "Koichiro Niinuma",
        "Sean Qian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T06:47:06+00:00",
          "link": "https://arxiv.org/abs/2506.22499v1",
          "size": "8692kb",
          "version": "v1"
        }
      ],
      "title": "Scalable Dynamic Origin-Destination Demand Estimation Enhanced by High-Resolution Satellite Imagery Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22499",
        "HTML": "https://arxiv.org/html/2506.22499v1",
        "PDF": "https://arxiv.org/pdf/2506.22499"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22500",
      "abstract": "Surgical risk identification is critical for patient safety and reducing preventable medical errors. While multimodal large language models (MLLMs) show promise for automated operating room (OR) risk detection, they often exhibit visual-semantic knowledge conflicts (VS-KC), failing to identify visual safety violations despite understanding textual rules. To address this, we introduce a dataset comprising over 34,000 synthetic images generated by diffusion models, depicting operating room scenes containing entities that violate established safety rules. These images were created to alleviate data scarcity and examine MLLMs vulnerabilities. In addition, the dataset includes 214 human-annotated images that serve as a gold-standard reference for validation. This comprehensive dataset, spanning diverse perspectives, stages, and configurations, is designed to expose and study VS-KC. Fine-tuning on OR-VSKC significantly improves MLLMs' detection of trained conflict entities and generalizes well to new viewpoints for these entities, but performance on untrained entity types remains poor, highlighting learning specificity and the need for comprehensive training. The main contributions of this work include: (1) a data generation methodology tailored for rule-violation scenarios; (2) the release of the OR-VSKC dataset and its associated benchmark as open-source resources; and (3) an empirical analysis of violation-sensitive knowledge consistency in representative MLLMs. The dataset and appendix are available at https://github.com/zgg2577/VS-KC.",
      "authors": [
        "Weiyi Zhao",
        "Xiaoyu Tan",
        "Liang Liu",
        "Sijia Li",
        "Youwei Song",
        "Xihe Qiu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T07:06:29+00:00",
          "link": "https://arxiv.org/abs/2506.22500v1",
          "size": "9203kb",
          "version": "v1"
        }
      ],
      "title": "Visual-Semantic Knowledge Conflicts in Operating Rooms: Synthetic Data Curation for Surgical Risk Perception in Multimodal Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22500",
        "HTML": "https://arxiv.org/html/2506.22500v1",
        "PDF": "https://arxiv.org/pdf/2506.22500"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22501",
      "abstract": "Remote sensing datasets offer significant promise for tackling key classification tasks such as land-use categorization, object presence detection, and rural/urban classification. However, many existing studies tend to focus on narrow tasks or datasets, which limits their ability to generalize across various remote sensing classification challenges. To overcome this, we propose a novel model, SpatialNet-ViT, leveraging the power of Vision Transformers (ViTs) and Multi-Task Learning (MTL). This integrated approach combines spatial awareness with contextual understanding, improving both classification accuracy and scalability. Additionally, techniques like data augmentation, transfer learning, and multi-task learning are employed to enhance model robustness and its ability to generalize across diverse datasets",
      "authors": [
        "Gautam Siddharth Kashyap",
        "Manaswi Kulahara",
        "Nipun Joshi",
        "Usman Naseem"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T10:50:33+00:00",
          "link": "https://arxiv.org/abs/2506.22501v1",
          "size": "74kb",
          "version": "v1"
        }
      ],
      "title": "How Can Multimodal Remote Sensing Datasets Transform Classification via SpatialNet-ViT?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22501",
        "HTML": "https://arxiv.org/html/2506.22501v1",
        "PDF": "https://arxiv.org/pdf/2506.22501"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22502",
      "abstract": "The stabilization of time series processes is a crucial problem that is ubiquitous in various industrial fields. The application of machine learning to its solution can have a decisive impact, improving both the quality of the resulting stabilization with less computational resources required. In this work, we present a simple pipeline consisting of two neural networks: the oracle predictor and the optimizer, proposing a substitution of the point-wise values optimization to the problem of the neural network training, which successfully improves stability in terms of the temperature control by about 3 times compared to ordinary solvers.",
      "authors": [
        "Matvei Anoshin",
        "Olga Tsurkan",
        "Vadim Lopatkin",
        "Leonid Fedichkin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T12:04:23+00:00",
          "link": "https://arxiv.org/abs/2506.22502v1",
          "size": "294kb",
          "version": "v1"
        }
      ],
      "title": "Stabilization of industrial processes with time series machine learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22502",
        "HTML": "https://arxiv.org/html/2506.22502v1",
        "PDF": "https://arxiv.org/pdf/2506.22502"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22503",
      "abstract": "Data analysis plays an increasingly important role in soccer, offering new ways to evaluate individual and team performance. One specific application is the evaluation of dribbles: one-on-one situations where an attacker attempts to bypass a defender with the ball. While previous research has primarily relied on 2D positional tracking data, this fails to capture aspects like balance, orientation, and ball control, limiting the depth of current insights. This study explores how pose tracking data (capturing players' posture and movement in three dimensions) can improve our understanding of dribbling skills. We extract novel pose-based features from 1,736 dribbles in the 2022/23 Champions League season and evaluate their impact on dribble success. Our results indicate that features capturing the attacker's balance and the alignment of the orientation between the attacker and defender are informative for predicting dribble success. Incorporating these pose-based features on top of features derived from traditional 2D positional data leads to a measurable improvement in model performance.",
      "authors": [
        "Michiel Schepers",
        "Pieter Robberechts",
        "Jan Van Haaren",
        "Jesse Davis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T15:01:30+00:00",
          "link": "https://arxiv.org/abs/2506.22503v1",
          "size": "1764kb",
          "version": "v1"
        }
      ],
      "title": "What Makes a Dribble Successful? Insights From 3D Pose Tracking Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22503",
        "HTML": "https://arxiv.org/html/2506.22503v1",
        "PDF": "https://arxiv.org/pdf/2506.22503"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22504",
      "abstract": "Detecting brain lesions as abnormalities observed in magnetic resonance imaging (MRI) is essential for diagnosis and treatment. In the search of abnormalities, such as tumors and malformations, radiologists may benefit from computer-aided diagnostics that use computer vision systems trained with machine learning to segment normal tissue from abnormal brain tissue. While supervised learning methods require annotated lesions, we propose a new unsupervised approach (Patch2Loc) that learns from normal patches taken from structural MRI. We train a neural network model to map a patch back to its spatial location within a slice of the brain volume. During inference, abnormal patches are detected by the relatively higher error and/or variance of the location prediction. This generates a heatmap that can be integrated into pixel-wise methods to achieve finer-grained segmentation. We demonstrate the ability of our model to segment abnormal brain tissues by applying our approach to the detection of tumor tissues in MRI on T2-weighted images from BraTS2021 and MSLUB datasets and T1-weighted images from ATLAS and WMH datasets. We show that it outperforms the state-of-the art in unsupervised segmentation. The codebase for this work can be found on our \\href{https://github.com/bakerhassan/Patch2Loc}{GitHub page}.",
      "authors": [
        "Hassan Baker",
        "Austin J. Brockmeier"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T16:00:12+00:00",
          "link": "https://arxiv.org/abs/2506.22504v1",
          "size": "2277kb",
          "version": "v1"
        }
      ],
      "title": "Patch2Loc: Learning to Localize Patches for Unsupervised Brain Lesion Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22504",
        "HTML": "https://arxiv.org/html/2506.22504v1",
        "PDF": "https://arxiv.org/pdf/2506.22504"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22505",
      "abstract": "As a computer vision task, automatic object segmentation remains challenging in specialized image domains without massive labeled data, such as synthetic aperture sonar images, remote sensing, biomedical imaging, etc. In any domain, obtaining pixel-wise segmentation masks is expensive. In this work, we propose a method for training a masking network to perform binary object segmentation using weak supervision in the form of image-wise presence or absence of an object of interest, which provides less information but may be obtained more quickly from manual or automatic labeling. A key step in our method is that the segmented objects can be placed into background-only images to create realistic, images of the objects with counterfactual backgrounds. To create a contrast between the original and counterfactual background images, we propose to first cluster the background-only images, and then during learning create counterfactual images that blend objects segmented from their original source backgrounds to backgrounds chosen from a targeted cluster. One term in the training loss is the divergence between these counterfactual images and the real object images with backgrounds of the target cluster. The other term is a supervised loss for background-only images. While an adversarial critic could provide the divergence, we use sample-based divergences. We conduct experiments on side-scan and synthetic aperture sonar in which our approach succeeds compared to previous unsupervised segmentation baselines that were only tested on natural images. Furthermore, to show generality we extend our experiments to natural images, obtaining reasonable performance with our method that avoids pretrained networks, generative networks, and adversarial critics. The basecode for this work can be found at \\href{GitHub}{https://github.com/bakerhassan/WSOS}.",
      "authors": [
        "Hassan Baker",
        "Matthew S. Emigh",
        "and Austin J. Brockmeier"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T16:46:46+00:00",
          "link": "https://arxiv.org/abs/2506.22505v1",
          "size": "47805kb",
          "version": "v1"
        }
      ],
      "title": "Weakly Supervised Object Segmentation by Background Conditional Divergence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22505",
        "HTML": "https://arxiv.org/html/2506.22505v1",
        "PDF": "https://arxiv.org/pdf/2506.22505"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22506",
      "abstract": "Federated Prompt Learning has emerged as a communication-efficient and privacy-preserving paradigm for adapting large vision-language models like CLIP across decentralized clients. However, the security implications of this setup remain underexplored. In this work, we present the first study of backdoor attacks in Federated Prompt Learning. We show that when malicious clients inject visually imperceptible, learnable noise triggers into input images, the global prompt learner becomes vulnerable to targeted misclassification while still maintaining high accuracy on clean inputs. Motivated by this vulnerability, we propose SABRE-FL, a lightweight, modular defense that filters poisoned prompt updates using an embedding-space anomaly detector trained offline on out-of-distribution data. SABRE-FL requires no access to raw client data or labels and generalizes across diverse datasets. We show, both theoretically and empirically, that malicious clients can be reliably identified and filtered using an embedding-based detector. Across five diverse datasets and four baseline defenses, SABRE-FL outperforms all baselines by significantly reducing backdoor accuracy while preserving clean accuracy, demonstrating strong empirical performance and underscoring the need for robust prompt learning in future federated systems.",
      "authors": [
        "Momin Ahmad Khan",
        "Yasra Chandio",
        "Fatima Muhammad Anwar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T23:15:20+00:00",
          "link": "https://arxiv.org/abs/2506.22506v1",
          "size": "447kb",
          "version": "v1"
        }
      ],
      "title": "SABRE-FL: Selective and Accurate Backdoor Rejection for Federated Prompt Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22506",
        "HTML": "https://arxiv.org/html/2506.22506v1",
        "PDF": "https://arxiv.org/pdf/2506.22506"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22507",
      "abstract": "The evolution towards 6G networks requires the intelligent integration of communication and sensing capabilities to support diverse and complex applications, such as autonomous driving and immersive services. However, existing integrated sensing and communication (ISAC) systems predominantly rely on single-modal sensors as primary participants, which leads to a limited representation of environmental features and significant performance bottlenecks under the emerging requirements of 6G applications. This limitation motivates a paradigm shift from single-modal to multimodal ISAC. In this article, we first analyze the key challenges in realizing multimodal ISAC, including the fusion of heterogeneous multimodal data, the high communication overhead among distributed sensors, and the design of efficient and scalable system architectures. We then introduce several enabling technologies, such as large AI models, semantic communication, and multi-agent systems, that hold promise for addressing these challenges. To operationalize these technologies, we zoom into three architectural paradigms: fusion-based multimodal ISAC (F-MAC), interaction-based multimodal ISAC (I-MAC), and relay-based multimodal ISAC (R-MAC), each tailored to organize devices and modalities for efficient collaboration in different scenarios. Thereafter, a case study is presented based on the F-MAC scheme, demonstrating that the scheme achieves more comprehensive sensing and improves sensing accuracy by approximately 80% compared to conventional single-modal ISAC systems. Finally, we discuss several open issues to be addressed in the future.",
      "authors": [
        "Yubo Peng",
        "Luping Xiang",
        "Kun Yang",
        "Feibo Jiang",
        "Kezhi Wang",
        "and Christos Masouros"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Multiagent Systems (cs.MA)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T01:27:23+00:00",
          "link": "https://arxiv.org/abs/2506.22507v1",
          "size": "772kb",
          "version": "v1"
        }
      ],
      "title": "Integrated Multimodal Sensing and Communication: Challenges, Technologies, and Architectures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22507",
        "HTML": "https://arxiv.org/html/2506.22507v1",
        "PDF": "https://arxiv.org/pdf/2506.22507"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22508",
      "abstract": "In today's digital world, casual user-generated content often contains subtle cues that may inadvertently expose sensitive personal attributes. Such risks underscore the growing importance of effective text anonymization to safeguard individual privacy. However, existing methods either rely on rigid replacements that damage utility or cloud-based LLMs that are costly and pose privacy risks. To address these issues, we explore the use of locally deployed smaller-scale language models (SLMs) for anonymization. Yet training effective SLMs remains challenging due to limited high-quality supervision. To address the challenge, we propose AgentStealth, a self-reinforcing LLM anonymization framework.First, we introduce an adversarial anonymization workflow enhanced by In-context Contrastive Learning and Adaptive Utility-Aware Control. Second, we perform supervised adaptation of SLMs using high-quality data collected from the workflow, which includes both anonymization and attack signals. Finally, we apply online reinforcement learning where the model leverages its internal adversarial feedback to iteratively improve anonymization performance. Experiments on two datasets show that our method outperforms baselines in both anonymization effectiveness (+12.3%) and utility (+6.8%). Our lightweight design supports direct deployment on edge devices, avoiding cloud reliance and communication-based privacy risks. Our code is open-source at https://github.com/tsinghua-fib-lab/AgentStealth.",
      "authors": [
        "Chenyang Shao and Tianxing Li and Chenhao Pu and Fengli Xu and Yong Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T02:48:16+00:00",
          "link": "https://arxiv.org/abs/2506.22508v1",
          "size": "714kb",
          "version": "v1"
        }
      ],
      "title": "AgentStealth: Reinforcing Large Language Model for Anonymizing User-generated Text",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22508",
        "PDF": "https://arxiv.org/pdf/2506.22508"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22509",
      "abstract": "Domain Adaptation(DA) for dense prediction tasks is an important topic, which enhances the dense prediction model's performance when tested on its unseen domain. Recently, with the development of Diffusion-based Dense Prediction (DDP) models, the exploration of DA designs tailored to this framework is worth exploring, since the diffusion model is effective in modeling the distribution transformation that comprises domain information. In this work, we propose a training-free mechanism for DDP frameworks, endowing them with DA capabilities. Our motivation arises from the observation that the exposure bias (e.g., noise statistics bias) in diffusion brings domain shift, and different domains in conditions of DDP models can also be effectively captured by the noise prediction statistics. Based on this, we propose a training-free Domain Noise Alignment (DNA) approach, which alleviates the variations of noise statistics to domain changes during the diffusion sampling process, thereby achieving domain adaptation. Specifically, when the source domain is available, we directly adopt the DNA method to achieve domain adaptation by aligning the noise statistics of the target domain with those of the source domain. For the more challenging source-free DA, inspired by the observation that regions closer to the source domain exhibit higher confidence meeting variations of sampling noise, we utilize the statistics from the high-confidence regions progressively to guide the noise statistic adjustment during the sampling process. Notably, our method demonstrates the effectiveness of enhancing the DA capability of DDP models across four common dense prediction tasks. Code is available at \\href{https://github.com/xuhang07/FreeDNA}{https://github.com/xuhang07/FreeDNA}.",
      "authors": [
        "Hang Xu",
        "Jie Huang",
        "Linjiang Huang",
        "Dong Li",
        "Yidi Liu",
        "Feng Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T02:54:27+00:00",
          "link": "https://arxiv.org/abs/2506.22509v1",
          "size": "1223kb",
          "version": "v1"
        }
      ],
      "title": "FreeDNA: Endowing Domain Adaptation of Diffusion-Based Dense Prediction with Training-Free Domain Noise Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22509",
        "HTML": "https://arxiv.org/html/2506.22509v1",
        "PDF": "https://arxiv.org/pdf/2506.22509"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22510",
      "abstract": "Foundation models have achieved great success in natural language processing (NLP) and computer vision (CV). Their success largely stems from the ability to integrate multi-domain knowledge in pre-training and transfer it to target domains. Considering graph data, especially graphs without textual features, is ubiquitous in real-world applications such as social networks and recommendation systems, some researchers have attempted to extend this paradigm to the graph field, aiming to construct graph foundation models. However, unlike CV and NLP, there are huge gaps among the semantics and properties of graphs in different domains, while current works still adopt traditional contrastive pre-training strategies designed in the single-domain scenario, which regard contrastive samples from different domains as equivalent. From experimental investigations, we discovered that inherent domain-specific differences prevent these strategies from effectively absorbing knowledge from different domains to generate informative representations. In this paper, we propose a novel multi-domain pre-training and cross-domain transfer framework, namely MDGCL.In the pre-training stage, we design a contrastive learning strategy to substantially recognize and capture domain differences, and introduce domain tokens to encode domain-level global information. In the downstream stage, we introduce a domain attention mechanism to enable fine-grained domain knowledge transfer. Extensive experiments on five benchmark datasets have demonstrated that our method outperforms state-of-the-art significantly, with the maximum improvement of 19.33\\% on accuracy and 19.13\\% on Macro-F1 score.",
      "authors": [
        "Zihao Zhao",
        "Xinlong Zhai",
        "Jinyu Yang",
        "Chuan Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T03:14:50+00:00",
          "link": "https://arxiv.org/abs/2506.22510v1",
          "size": "613kb",
          "version": "v1"
        }
      ],
      "title": "Towards Text-free Graph Foundation Models: Rethinking Multi-Domain Graph Contrastive Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22510",
        "HTML": "https://arxiv.org/html/2506.22510v1",
        "PDF": "https://arxiv.org/pdf/2506.22510"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22511",
      "abstract": "The visible light reflectance data from geostationary satellites is crucial for meteorological observations and plays an important role in weather monitoring and forecasting. However, due to the lack of visible light at night, it is impossible to conduct continuous all-day weather observations using visible light reflectance data. This study pioneers the use of generative diffusion models to address this limitation. Based on the multi-band thermal infrared brightness temperature data from the Advanced Geostationary Radiation Imager (AGRI) onboard the Fengyun-4B (FY4B) geostationary satellite, we developed a high-precision visible light reflectance retrieval model, called Reflectance Diffusion (RefDiff), which enables 0.47~\\mu\\mathrm{m}, 0.65~\\mu\\mathrm{m}, and 0.825~\\mu\\mathrm{m} bands visible light reflectance retrieval at night. Compared to the classical models, RefDiff not only significantly improves accuracy through ensemble averaging but also provides uncertainty estimation. Specifically, the SSIM index of RefDiff can reach 0.90, with particularly significant improvements in areas with complex cloud structures and thick clouds. The model's nighttime retrieval capability was validated using VIIRS nighttime product, demonstrating comparable performance to its daytime counterpart. In summary, this research has made substantial progress in the ability to retrieve visible light reflectance at night, with the potential to expand the application of nighttime visible light data.",
      "authors": [
        "Tingting Zhou",
        "Feng Zhang",
        "Haoyang Fu",
        "Baoxiang Pan",
        "Renhe Zhang",
        "Feng Lu",
        "Zhixin Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T03:21:08+00:00",
          "link": "https://arxiv.org/abs/2506.22511v1",
          "size": "6359kb",
          "version": "v1"
        }
      ],
      "title": "Lightning the Night with Generative Artificial Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22511",
        "PDF": "https://arxiv.org/pdf/2506.22511"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22512",
      "abstract": "AI for good initiatives often rely on the assumption that technical interventions can resolve complex social problems. In the context of human trafficking (HT), such techno-solutionism risks oversimplifying exploitation, reinforcing power imbalances and causing harm to the very communities AI claims to support. In this paper, we introduce the Radical Questioning (RQ) framework as a five step, pre-project ethical assessment tool to critically evaluate whether AI should be built at all, especially in domains involving marginalized populations and entrenched systemic injustice. RQ does not replace principles based ethics but precedes it, offering an upstream, deliberative space to confront assumptions, map power, and consider harms before design. Using a case study in AI for HT, we demonstrate how RQ reveals overlooked sociocultural complexities and guides us away from surveillance based interventions toward survivor empowerment tools. While developed in the context of HT, RQ's five step structure can generalize to other domains, though the specific questions must be contextual. This paper situates RQ within a broader AI ethics philosophy that challenges instrumentalist norms and centers relational, reflexive responsibility.",
      "authors": [
        "Pratheeksha Nair",
        "Gabriel Lefebvre",
        "Sophia Garrel",
        "Maryam Molamohammadi",
        "Reihaneh Rabbany"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T04:05:15+00:00",
          "link": "https://arxiv.org/abs/2506.22512v1",
          "size": "407kb",
          "version": "v1"
        }
      ],
      "title": "Ask before you Build: Rethinking AI-for-Good in Human Trafficking Interventions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22512",
        "PDF": "https://arxiv.org/pdf/2506.22512"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22513",
      "abstract": "This investigation attempts to create an automated framework for fault detection and organization for usage in contemporary radiography, as per NDE 4.0. The review's goals are to address the lack of information that is sufficiently explained, learn how to make the most of virtual defect increase, and determine whether the framework is viable by using NDE measurements. As its basic information source, the technique consists of compiling and categorizing 223 CR photographs of airplane welds. Information expansion systems, such as virtual defect increase and standard increase, are used to work on the preparation dataset. A modified U-net model is prepared using the improved data to produce semantic fault division veils. To assess the effectiveness of the model, NDE boundaries such as Case, estimating exactness, and misleading call rate are used. Tiny a90/95 characteristics, which provide strong differentiating evidence of flaws, reveal that the suggested approach achieves exceptional awareness in defect detection. Considering a 90/95, size error, and fake call rate in the weld area, the consolidated expansion approach clearly wins. Due to the framework's fast derivation speed, large images can be broken down efficiently and quickly. Professional controllers evaluate the transmitted system in the field and believe that it has a guarantee as a support device in the testing cycle, irrespective of particular equipment cut-off points and programming resemblance.",
      "authors": [
        "Aditya Sharma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T06:25:36+00:00",
          "link": "https://arxiv.org/abs/2506.22513v1",
          "size": "574kb",
          "version": "v1"
        }
      ],
      "title": "Automated Defect Identification and Categorization in NDE 4.0 with the Application of Artificial Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22513",
        "PDF": "https://arxiv.org/pdf/2506.22513"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22515",
      "abstract": "Traditional phishing detection often overlooks psychological manipulation. This study investigates using Large Language Model (LLM) In-Context Learning (ICL) for fine-grained classification of phishing emails based on a taxonomy of 40 manipulation techniques. Using few-shot examples with GPT-4o-mini on real-world French phishing emails (SignalSpam), we evaluated performance against a human-annotated test set (100 emails). The approach effectively identifies prevalent techniques (e.g., Baiting, Curiosity Appeal, Request For Minor Favor) with a promising accuracy of 0.76. This work demonstrates ICL's potential for nuanced phishing analysis and provides insights into attacker strategies.",
      "authors": [
        "Antony Dalmiere (LAAS-TRUST",
        "LAAS)",
        "Guillaume Auriol (LAAS-TRUST",
        "INSA Toulouse)",
        "Vincent Nicomette (LAAS-TSF",
        "LAAS)",
        "Pascal Marchand (LERASS)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T08:07:30+00:00",
          "link": "https://arxiv.org/abs/2506.22515v1",
          "size": "1328kb",
          "version": "v1"
        }
      ],
      "title": "In-context learning for the classification of manipulation techniques in phishing emails",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22515",
        "PDF": "https://arxiv.org/pdf/2506.22515"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22516",
      "abstract": "Integrated Information Theory (IIT) provides a quantitative framework for explaining consciousness phenomenon, positing that conscious systems comprise elements integrated through causal properties. We apply IIT 3.0 and 4.0 -- the latest iterations of this framework -- to sequences of Large Language Model (LLM) representations, analyzing data derived from existing Theory of Mind (ToM) test results. Our study systematically investigates whether the differences of ToM test performances, when presented in the LLM representations, can be revealed by IIT estimates, i.e., $\\Phi^{\\max}$ (IIT 3.0), $\\Phi$ (IIT 4.0), Conceptual Information (IIT 3.0), and $\\Phi$-structure (IIT 4.0). Furthermore, we compare these metrics with the Span Representations independent of any estimate for consciousness. This additional effort aims to differentiate between potential \"consciousness\" phenomena and inherent separations within LLM representational space. We conduct comprehensive experiments examining variations across LLM transformer layers and linguistic spans from stimuli. Our results suggest that sequences of contemporary Transformer-based LLM representations lack statistically significant indicators of observed \"consciousness\" phenomena but exhibit intriguing patterns under $\\textit{spatio}$-permutational analyses. The Appendix and code are available as Supplementary Materials at: https://doi.org/10.1016/j.nlp.2025.100163.",
      "authors": [
        "Jingkai Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T13:59:22+00:00",
          "link": "https://arxiv.org/abs/2506.22516v1",
          "size": "1897kb",
          "version": "v1"
        }
      ],
      "title": "Can \"consciousness\" be observed from large language model (LLM) internal states? Dissecting LLM representations obtained from Theory of Mind test with Integrated Information Theory and Span Representation analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22516",
        "HTML": "https://arxiv.org/html/2506.22516v1",
        "PDF": "https://arxiv.org/pdf/2506.22516"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22517",
      "abstract": "Containers are an integral part of the logistics industry and act as a barrier for cargo. A typical service life for a container is more than 20 years. However, overtime containers suffer various types of damage due to the mechanical as well as natural factors. A damaged container is a safety hazard for the employees handling it and a liability for the logistic company. Therefore, a timely inspection and detection of the damaged container is a key for prolonging service life as well as avoiding safety hazards. In this paper, we will compare the performance of the damage detection by three state-of-the-art advanced computer vision models Yolov12, Yolov11 and RF-DETR. We will use a dataset of 278 annotated images to train, validate and test the model. We will compare the mAP and precision of the model. The objective of this paper is to identify the model that is best suited for container damage detection. The result is mixed. mAP@50 score of Yolov11 and 12 was 81.9% compared to RF-DETR, which was 77.7%. However, while testing the model for not-so-common damaged containers, the RF-DETR model outperformed the others overall, exhibiting superiority to accurately detecting both damaged containers as well as damage occurrences with high confidence.",
      "authors": [
        "Subhadip Kumar"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T14:29:54+00:00",
          "link": "https://arxiv.org/abs/2506.22517v1",
          "size": "982kb",
          "version": "v1"
        }
      ],
      "title": "Container damage detection using advanced computer vision model Yolov12 vs Yolov11 vs RF-DETR A comparative analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22517",
        "PDF": "https://arxiv.org/pdf/2506.22517"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22518",
      "abstract": "Graph-based retrieval-augmented generation (RAG) enables large language models (LLMs) to ground responses with structured external knowledge from up-to-date knowledge graphs (KGs) and reduce hallucinations. However, LLMs often rely on a weak retriever in graph-based RAG: I) Due to the lack of ground truth, the retriever is often trained on weak supervision, which often introduces spurious signals to the LLMs. II) Due to the abstraction of graph data, the retrieved knowledge is often presented in unorganized forms. To mitigate the issue, we present Refined Graph-based RAG (ReG) to align weak retrievers to LLMs for graph-based RAG. Specifically, ReG incorporates LLM feedback to get rid of spurious signals and improve the quality of the supervision. Meanwhile, ReG introduces a structure-aware reorganization module to refactor the retrieval results into logically coherent evidence chains. Experiments on prominent benchmarks demonstrate that ReG significantly and consistently brings improvements across different LLM backbones by up to 10%. The improved supervision quality enables ReG to match the state-of-the-art performance with 5% training data and to transfer to out-of-distribution KGs. Notably, when adopted to reasoning-based LLMs, ReG reduces the reasoning token cost by up to 30% and improves the performance by up to 4%.",
      "authors": [
        "Deyu Zou",
        "Yongqiang Chen",
        "Mufei Li",
        "Siqi Miao",
        "Chenxi Liu",
        "Bo Han",
        "James Cheng",
        "Pan Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T17:40:23+00:00",
          "link": "https://arxiv.org/abs/2506.22518v1",
          "size": "412kb",
          "version": "v1"
        }
      ],
      "title": "Weak-to-Strong GraphRAG: Aligning Weak Retrievers with Large Language Models for Graph-based Retrieval Augmented Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22518",
        "HTML": "https://arxiv.org/html/2506.22518v1",
        "PDF": "https://arxiv.org/pdf/2506.22518"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22520",
      "abstract": "This study examines the impact of an Artificial Intelligence tutor teammate (AI) on student curiosity-driven engagement and learning effectiveness during Interactive Molecular Dynamics (IMD) tasks on the Visual Molecular Dynamics platform. It explores the role of the AI's curiosity-triggering and response behaviors in stimulating and sustaining student curiosity, affecting the frequency and complexity of student-initiated questions. The study further assesses how AI interventions shape student engagement, foster discovery curiosity, and enhance team performance within the IMD learning environment. Using a Wizard-of-Oz paradigm, a human experimenter dynamically adjusts the AI tutor teammate's behavior through a large language model. By employing a mixed-methods exploratory design, a total of 11 high school students participated in four IMD tasks that involved molecular visualization and calculations, which increased in complexity over a 60-minute period. Team performance was evaluated through real-time observation and recordings, whereas team communication was measured by question complexity and AI's curiosity-triggering and response behaviors. Cross Recurrence Quantification Analysis (CRQA) metrics reflected structural alignment in coordination and were linked to communication behaviors. High-performing teams exhibited superior task completion, deeper understanding, and increased engagement. Advanced questions were associated with AI curiosity-triggering, indicating heightened engagement and cognitive complexity. CRQA metrics highlighted dynamic synchronization in student-AI interactions, emphasizing structured yet adaptive engagement to promote curiosity. These proof-of-concept findings suggest that the AI's dual role as a teammate and educator indicates its capacity to provide adaptive feedback, sustaining engagement and epistemic curiosity.",
      "authors": [
        "Mustafa Demir",
        "Jacob Miratsky",
        "Jonathan Nguyen",
        "Chun Kit Chan",
        "Punya Mishra",
        "and Abhishek Singharoy"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T19:30:25+00:00",
          "link": "https://arxiv.org/abs/2506.22520v1",
          "size": "1193kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Artificial Intelligence Tutor Teammate Adaptability to Harness Discovery Curiosity and Promote Learning in the Context of Interactive Molecular Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22520",
        "PDF": "https://arxiv.org/pdf/2506.22520"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22521",
      "abstract": "Model extraction attacks pose significant security threats to deployed language models, potentially compromising intellectual property and user privacy. This survey provides a comprehensive taxonomy of LLM-specific extraction attacks and defenses, categorizing attacks into functionality extraction, training data extraction, and prompt-targeted attacks. We analyze various attack methodologies including API-based knowledge distillation, direct querying, parameter recovery, and prompt stealing techniques that exploit transformer architectures. We then examine defense mechanisms organized into model protection, data privacy protection, and prompt-targeted strategies, evaluating their effectiveness across different deployment scenarios. We propose specialized metrics for evaluating both attack effectiveness and defense performance, addressing the specific challenges of generative language models. Through our analysis, we identify critical limitations in current approaches and propose promising research directions, including integrated attack methodologies and adaptive defense mechanisms that balance security with model utility. This work serves NLP researchers, ML engineers, and security professionals seeking to protect language models in production environments.",
      "authors": [
        "Kaixiang Zhao",
        "Lincan Li",
        "Kaize Ding",
        "Neil Zhenqiang Gong",
        "Yue Zhao",
        "Yushun Dong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T22:02:01+00:00",
          "link": "https://arxiv.org/abs/2506.22521v1",
          "size": "319kb",
          "version": "v1"
        }
      ],
      "title": "A Survey on Model Extraction Attacks and Defenses for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22521",
        "HTML": "https://arxiv.org/html/2506.22521v1",
        "PDF": "https://arxiv.org/pdf/2506.22521"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22523",
      "abstract": "Generative AI is present in multiple industries. Dana-Farber Cancer Institute, in partnership with Microsoft, has created an internal AI tool, GPT4DFCI. Together we hosted a red teaming event to assess whether the underlying GPT models that support the tool would output copyrighted data. Our teams focused on reproducing content from books, news articles, scientific articles, and electronic health records. We found isolated instances where GPT4DFCI was able to identify copyrighted material and reproduce exact quotes from famous books which indicates that copyrighted material was in the training data. The model was not able to reproduce content from our target news article, scientific article, or electronic health records. However, there were instances of fabrication. As a result of this event, a mitigation strategy is in production in GPT4DFCI v2.8.2, deployed on January 21, 2025. We hope this report leads to similar events in which AI software tools are stress-tested to assess the perimeter of their legal and ethical usage.",
      "authors": [
        "James Wen",
        "Sahil Nalawade",
        "Zhiwei Liang",
        "Catherine Bielick",
        "Marisa Ferrara Boston",
        "Alexander Chowdhury",
        "Adele Collin",
        "Luigi De Angelis",
        "Jacob Ellen",
        "Heather Frase",
        "Rodrigo R. Gameiro",
        "Juan Manuel Gutierrez",
        "Pooja Kadam",
        "Murat Keceli",
        "Srikanth Krishnamurthy",
        "Anne Kwok",
        "Yanan Lance Lu",
        "Heather Mattie",
        "Liam G. McCoy",
        "Katherine Miller",
        "Allison C. Morgan",
        "Marlene Louisa Moerig",
        "Trang Nguyen",
        "Alexander Owen-Post",
        "Alex D. Ruiz",
        "Sreekar Reddy Puchala",
        "Soujanya Samineni",
        "Takeshi Tohyama",
        "Varun Ullanat",
        "Carmine Valenza",
        "Camilo Velez",
        "Pengcheng Wang",
        "Anna Wuest",
        "Yuxiang Zhou",
        "Yingde Zhu",
        "Jason M. Johnson",
        "Jennifer Willcox",
        "Francis J. Vitiello",
        "Leo Anthony G. Celi",
        "Renato Umeton"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T23:11:49+00:00",
          "link": "https://arxiv.org/abs/2506.22523v1",
          "size": "159kb",
          "version": "v1"
        }
      ],
      "title": "Red Teaming for Generative AI, Report on a Copyright-Focused Exercise Completed in an Academic Medical Center",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22523",
        "PDF": "https://arxiv.org/pdf/2506.22523"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22529",
      "abstract": "Connectivity and message propagation are central, yet often underutilized, sources of information in misinformation detection -- especially on poorly moderated platforms such as Telegram, which has become a critical channel for misinformation dissemination, namely in the German electoral context. In this paper, we introduce Misinfo-TeleGraph, the first German-language Telegram-based graph dataset for misinformation detection. It includes over 5 million messages from public channels, enriched with metadata, channel relationships, and both weak and strong labels. These labels are derived via semantic similarity to fact-checks and news articles using M3-embeddings, as well as manual annotation. To establish reproducible baselines, we evaluate both text-only models and graph neural networks (GNNs) that incorporate message forwarding as a network structure. Our results show that GraphSAGE with LSTM aggregation significantly outperforms text-only baselines in terms of Matthews Correlation Coefficient (MCC) and F1-score. We further evaluate the impact of subscribers, view counts, and automatically versus human-created labels on performance, and highlight both the potential and challenges of weak supervision in this domain. This work provides a reproducible benchmark and open dataset for future research on misinformation detection in German-language Telegram networks and other low-moderation social platforms.",
      "authors": [
        "Lu Kalkbrenner",
        "Veronika Solopova",
        "Steffen Zeiler",
        "Robert Nickel",
        "Dorothea Kolossa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T12:32:19+00:00",
          "link": "https://arxiv.org/abs/2506.22529v1",
          "size": "299kb",
          "version": "v1"
        }
      ],
      "title": "MisinfoTeleGraph: Network-driven Misinformation Detection for German Telegram Messages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22529",
        "PDF": "https://arxiv.org/pdf/2506.22529"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22530",
      "abstract": "Relational Deep Learning (RDL) is an emerging paradigm that leverages Graph Neural Network principles to learn directly from relational databases by representing them as heterogeneous graphs. However, existing RDL models typically rely on task-specific supervised learning, requiring training separate models for each predictive task, which may hamper scalability and reuse.\n  In this work, we propose a novel task-agnostic contrastive pretraining approach for RDL that enables database-wide representation learning. For that aim, we introduce three levels of contrastive objectives$-$row-level, link-level, and context-level$-$designed to capture the structural and semantic heterogeneity inherent to relational data. We implement the respective pretraining approach through a modular RDL architecture and an efficient sampling strategy tailored to the heterogeneous database setting. Our preliminary results on standard RDL benchmarks demonstrate that fine-tuning the pretrained models measurably outperforms training from scratch, validating the promise of the proposed methodology in learning transferable representations for relational data.",
      "authors": [
        "Jakub Pele\\v{s}ka and Gustav \\v{S}\\'ir"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:18:13+00:00",
          "link": "https://arxiv.org/abs/2506.22530v1",
          "size": "32kb",
          "version": "v1"
        }
      ],
      "title": "Task-Agnostic Contrastive Pretraining for Relational Deep Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22530",
        "HTML": "https://arxiv.org/html/2506.22530v1",
        "PDF": "https://arxiv.org/pdf/2506.22530"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22531",
      "abstract": "We introduce \\textit{Preserve Anything}, a novel method for controlled image synthesis that addresses key limitations in object preservation and semantic consistency in text-to-image (T2I) generation. Existing approaches often fail (i) to preserve multiple objects with fidelity, (ii) maintain semantic alignment with prompts, or (iii) provide explicit control over scene composition. To overcome these challenges, the proposed method employs an N-channel ControlNet that integrates (i) object preservation with size and placement agnosticism, color and detail retention, and artifact elimination, (ii) high-resolution, semantically consistent backgrounds with accurate shadows, lighting, and prompt adherence, and (iii) explicit user control over background layouts and lighting conditions. Key components of our framework include object preservation and background guidance modules, enforcing lighting consistency and a high-frequency overlay module to retain fine details while mitigating unwanted artifacts. We introduce a benchmark dataset consisting of 240K natural images filtered for aesthetic quality and 18K 3D-rendered synthetic images with metadata such as lighting, camera angles, and object relationships. This dataset addresses the deficiencies of existing benchmarks and allows a complete evaluation. Empirical results demonstrate that our method achieves state-of-the-art performance, significantly improving feature-space fidelity (FID 15.26) and semantic alignment (CLIP-S 32.85) while maintaining competitive aesthetic quality. We also conducted a user study to demonstrate the efficacy of the proposed work on unseen benchmark and observed a remarkable improvement of $\\sim25\\%$, $\\sim19\\%$, $\\sim13\\%$, and $\\sim14\\%$ in terms of prompt alignment, photorealism, the presence of AI artifacts, and natural aesthetics over existing works.",
      "authors": [
        "Prasen Kumar Sharma",
        "Neeraj Matiyali",
        "Siddharth Srivastava",
        "Gaurav Sharma"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:39:21+00:00",
          "link": "https://arxiv.org/abs/2506.22531v1",
          "size": "13263kb",
          "version": "v1"
        }
      ],
      "title": "Preserve Anything: Controllable Image Synthesis with Object Preservation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22531",
        "HTML": "https://arxiv.org/html/2506.22531v1",
        "PDF": "https://arxiv.org/pdf/2506.22531"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22554",
      "abstract": "Human communication involves a complex interplay of verbal and nonverbal signals, essential for conveying meaning and achieving interpersonal goals. To develop socially intelligent AI technologies, it is crucial to develop models that can both comprehend and generate dyadic behavioral dynamics. To this end, we introduce the Seamless Interaction Dataset, a large-scale collection of over 4,000 hours of face-to-face interaction footage from over 4,000 participants in diverse contexts. This dataset enables the development of AI technologies that understand dyadic embodied dynamics, unlocking breakthroughs in virtual agents, telepresence experiences, and multimodal content analysis tools. We also develop a suite of models that utilize the dataset to generate dyadic motion gestures and facial expressions aligned with human speech. These models can take as input both the speech and visual behavior of their interlocutors. We present a variant with speech from an LLM model and integrations with 2D and 3D rendering methods, bringing us closer to interactive virtual agents. Additionally, we describe controllable variants of our motion models that can adapt emotional responses and expressivity levels, as well as generating more semantically-relevant gestures. Finally, we discuss methods for assessing the quality of these dyadic motion models, which are demonstrating the potential for more intuitive and responsive human-AI interactions.",
      "authors": [
        "Vasu Agrawal",
        "Akinniyi Akinyemi",
        "Kathryn Alvero",
        "Morteza Behrooz",
        "Julia Buffalini",
        "Fabio Maria Carlucci",
        "Joy Chen",
        "Junming Chen",
        "Zhang Chen",
        "Shiyang Cheng",
        "Praveen Chowdary",
        "Joe Chuang",
        "Antony D'Avirro",
        "Jon Daly",
        "Ning Dong",
        "Mark Duppenthaler",
        "Cynthia Gao",
        "Jeff Girard",
        "Martin Gleize",
        "Sahir Gomez",
        "Hongyu Gong",
        "Srivathsan Govindarajan",
        "Brandon Han",
        "Sen He",
        "Denise Hernandez",
        "Yordan Hristov",
        "Rongjie Huang",
        "Hirofumi Inaguma",
        "Somya Jain",
        "Raj Janardhan",
        "Qingyao Jia",
        "Christopher Klaiber",
        "Dejan Kovachev",
        "Moneish Kumar",
        "Hang Li",
        "Yilei Li",
        "Pavel Litvin",
        "Wei Liu",
        "Guangyao Ma",
        "Jing Ma",
        "Martin Ma",
        "Xutai Ma",
        "Lucas Mantovani",
        "Sagar Miglani",
        "Sreyas Mohan",
        "Louis-Philippe Morency",
        "Evonne Ng",
        "Kam-Woh Ng",
        "Tu Anh Nguyen",
        "Amia Oberai",
        "Benjamin Peloquin",
        "Juan Pino",
        "Jovan Popovic",
        "Omid Poursaeed",
        "Fabian Prada",
        "Alice Rakotoarison",
        "Alexander Richard",
        "Christophe Ropers",
        "Safiyyah Saleem",
        "Vasu Sharma",
        "Alex Shcherbyna",
        "Jia Shen",
        "Jie Shen",
        "Anastasis Stathopoulos",
        "Anna Sun",
        "Paden Tomasello",
        "Tuan Tran",
        "Arina Turkatenko",
        "Bo Wan",
        "Chao Wang",
        "Jeff Wang",
        "Mary Williamson",
        "Carleigh Wood",
        "Tao Xiang",
        "Yilin Yang",
        "Julien Yao",
        "Chen Zhang",
        "Jiemin Zhang",
        "Xinyue Zhang",
        "Jason Zheng",
        "Pavlo Zhyzheria",
        "Jan Zikes",
        "Michael Zollhoefer"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T18:09:49+00:00",
          "link": "https://arxiv.org/abs/2506.22554v1",
          "size": "39479kb",
          "version": "v1"
        }
      ],
      "title": "Seamless Interaction: Dyadic Audiovisual Motion Modeling and Large-Scale Dataset",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22554",
        "HTML": "https://arxiv.org/html/2506.22554v1",
        "PDF": "https://arxiv.org/pdf/2506.22554"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22556",
      "abstract": "We present a patch-based image reconstruction and animation method that uses existing image data to bring still images to life through motion. Image patches from curated datasets are grouped using k-means clustering and a new target image is reconstructed by matching and randomly sampling from these clusters. This approach emphasizes reinterpretation over replication, allowing the source and target domains to differ conceptually while sharing local structures.",
      "authors": [
        "Markus Juvonen and Samuli Siltanen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T18:14:34+00:00",
          "link": "https://arxiv.org/abs/2506.22556v1",
          "size": "31378kb",
          "version": "v1"
        }
      ],
      "title": "Recomposed realities: animating still images via patch clustering and randomness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22556",
        "HTML": "https://arxiv.org/html/2506.22556v1",
        "PDF": "https://arxiv.org/pdf/2506.22556"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22557",
      "abstract": "The growing capabilities of large language models (LLMs) have exposed them to increasingly sophisticated jailbreak attacks. Among these, obfuscation-based attacks -- which encrypt malicious content to evade detection -- remain highly effective. By leveraging the reasoning ability of advanced LLMs to interpret encrypted prompts, such attacks circumvent conventional defenses that rely on keyword detection or context filtering. These methods are very difficult to defend against, as existing safety mechanisms are not designed to interpret or decode ciphered content. In this work, we propose \\textbf{MetaCipher}, a novel obfuscation-based jailbreak framework, along with a reinforcement learning-based dynamic cipher selection mechanism that adaptively chooses optimal encryption strategies from a cipher pool. This approach enhances jailbreak effectiveness and generalizability across diverse task types, victim LLMs, and safety guardrails. Our framework is modular and extensible by design, supporting arbitrary cipher families and accommodating evolving adversarial strategies. We complement our method with a large-scale empirical analysis of cipher performance across multiple victim LLMs. Within as few as 10 queries, MetaCipher achieves over 92\\% attack success rate (ASR) on most recent standard malicious prompt benchmarks against state-of-the-art non-reasoning LLMs, and over 74\\% ASR against reasoning-capable LLMs, outperforming all existing obfuscation-based jailbreak methods. These results highlight the long-term robustness and adaptability of our approach, making it more resilient than prior methods in the face of advancing safety measures.",
      "authors": [
        "Boyuan Chen",
        "Minghao Shao",
        "Abdul Basit",
        "Siddharth Garg",
        "Muhammad Shafique"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T18:15:56+00:00",
          "link": "https://arxiv.org/abs/2506.22557v1",
          "size": "1921kb",
          "version": "v1"
        }
      ],
      "title": "MetaCipher: A General and Extensible Reinforcement Learning Framework for Obfuscation-Based Jailbreak Attacks on Black-Box LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22557",
        "PDF": "https://arxiv.org/pdf/2506.22557"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22560",
      "abstract": "Recent studies on many-to-one matching markets have explored agents with flexible capacity and truthful preference reporting, focusing on mechanisms that jointly design capacities and select a matching. However, in real-world applications such as school choice and residency matching, preferences are revealed after capacity decisions are made, with matching occurring afterward; uncertainty about agents' preferences must be considered during capacity planning. Moreover, even under strategy-proof mechanisms, agents may strategically misreport preferences based on beliefs about admission chances. We introduce a two-stage stochastic matching problem with uncertain preferences, using school choice as a case study. In the first stage, the clearinghouse expands schools' capacities before observing students' reported preferences. Students either report their true preferences, producing exogenous uncertainty, or act strategically, submitting reported preferences based on their true preferences and admission chances (which depend on capacities), introducing endogenous uncertainty. In the second stage, the clearinghouse computes the student-optimal stable matching based on schools' priorities and students' reported preferences. In strategic cases, endogenous reported preferences are utility-maximizing transformations of capacity decisions and exogenous true preferences; we handle uncertainty using sample average approximation(SAA). We develop behavior-based mathematical formulations and, due to problem complexity, propose Lagrangian- and local-search-based behavior-specific heuristics for near-optimal solutions. Our SAA-based approaches outperform the average scenario approach on students' matching preferences and admission outcomes, emphasizing the impact of stochastic preferences on capacity decisions. Student behavior notably influences capacity design, stressing the need to consider misreports.",
      "authors": [
        "Maria Bazotte",
        "Margarida Carvalho",
        "and Thibaut Vidal"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T18:19:38+00:00",
          "link": "https://arxiv.org/abs/2506.22560v1",
          "size": "6716kb",
          "version": "v1"
        }
      ],
      "title": "Capacity Planning in Stable Matching with Truthful or Strategic Preference Uncertainty",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22560",
        "HTML": "https://arxiv.org/html/2506.22560v1",
        "PDF": "https://arxiv.org/pdf/2506.22560"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22561",
      "abstract": "Vectors addition systems with states (VASS), or equivalently Petri nets, are arguably one of the most studied formalisms for the modeling and analysis of concurrent systems. A central decision problem for VASS is reachability: whether there exists a run from an initial configuration to a final one. This problem has been known to be decidable for over forty years, and its complexity has recently been precisely characterized. Our work concerns the reachability problem for BVASS, a branching generalization of VASS. In dimension one, the exact complexity of this problem is known. In this paper, we prove that the reachability problem for 2-dimensional BVASS is decidable. In fact, we even show that the reachability set admits a computable semilinear presentation. The decidability status of the reachability problem for BVASS remains open in higher dimensions.",
      "authors": [
        "Clotilde Bizi\\`ere",
        "Thibault Hilaire",
        "J\\'er\\^ome Leroux",
        "Gr\\'egoire Sutre"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T18:20:20+00:00",
          "link": "https://arxiv.org/abs/2506.22561v1",
          "size": "258kb",
          "version": "v1"
        }
      ],
      "title": "On the Reachability Problem for Two-Dimensional Branching VASS",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22561",
        "HTML": "https://arxiv.org/html/2506.22561v1",
        "PDF": "https://arxiv.org/pdf/2506.22561"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22562",
      "abstract": "This paper improves upon the Pix2Seq object detector by extending it for videos. In the process, it introduces a new way to perform end-to-end video object detection that improves upon existing video detectors in two key ways. First, by representing objects as variable-length sequences of discrete tokens, we can succinctly represent widely varying numbers of video objects, with diverse shapes and locations, without having to inject any localization cues in the training process. This eliminates the need to sample the space of all possible boxes that constrains conventional detectors and thus solves the dual problems of loss sparsity during training and heuristics-based postprocessing during inference. Second, it conceptualizes and outputs the video objects as fully integrated and indivisible 3D boxes or tracklets instead of generating image-specific 2D boxes and linking these boxes together to construct the video object, as done in most conventional detectors. This allows it to scale effortlessly with available computational resources by simply increasing the length of the video subsequence that the network takes as input, even generalizing to multi-object tracking if the subsequence can span the entire video. We compare our video detector with the baseline Pix2Seq static detector on several datasets and demonstrate consistent improvement, although with strong signs of being bottlenecked by our limited computational resources. We also compare it with several video detectors on UA-DETRAC to show that it is competitive with the current state of the art even with the computational bottleneck. We make our code and models publicly available.",
      "authors": [
        "Abhineet Singh and Nilanjan Ray"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T18:21:58+00:00",
          "link": "https://arxiv.org/abs/2506.22562v1",
          "size": "11664kb",
          "version": "v1"
        }
      ],
      "title": "Improving Token-based Object Detection with Video",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22562",
        "HTML": "https://arxiv.org/html/2506.22562v1",
        "PDF": "https://arxiv.org/pdf/2506.22562"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22566",
      "abstract": "Exploration remains a fundamental challenge in reinforcement learning (RL), particularly in environments with sparse or adversarial reward structures. In this work, we study how the architecture of deep neural policies implicitly shapes exploration before training. We theoretically and empirically demonstrate strategies for generating ballistic or diffusive trajectories from untrained policies in a toy model. Using the theory of infinite-width networks and a continuous-time limit, we show that untrained policies return correlated actions and result in non-trivial state-visitation distributions. We discuss the distributions of the corresponding trajectories for a standard architecture, revealing insights into inductive biases for tackling exploration. Our results establish a theoretical and experimental framework for using policy initialization as a design tool to understand exploration behavior in early training.",
      "authors": [
        "Jacob Adamczyk"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T18:28:41+00:00",
          "link": "https://arxiv.org/abs/2506.22566v1",
          "size": "433kb",
          "version": "v1"
        }
      ],
      "title": "Exploration Behavior of Untrained Policies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22566",
        "HTML": "https://arxiv.org/html/2506.22566v1",
        "PDF": "https://arxiv.org/pdf/2506.22566"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22567",
      "abstract": "CLIP models pretrained on natural images with billion-scale image-text pairs have demonstrated impressive capabilities in zero-shot classification, cross-modal retrieval, and open-ended visual answering. However, transferring this success to biomedicine is hindered by the scarcity of large-scale biomedical image-text corpora, the heterogeneity of image modalities, and fragmented data standards across institutions. These limitations hinder the development of a unified and generalizable biomedical foundation model trained from scratch. To overcome this, we introduce MMKD-CLIP, a generalist biomedical foundation model developed via Multiple Medical CLIP Knowledge Distillation. Rather than relying on billion-scale raw data, MMKD-CLIP distills knowledge from nine state-of-the-art domain-specific or generalist biomedical CLIP models, each pretrained on millions of biomedical image-text pairs. Our two-stage training pipeline first performs CLIP-style pretraining on over 2.9 million biomedical image-text pairs from 26 image modalities, followed by feature-level distillation using over 19.2 million feature pairs extracted from teacher models. We evaluate MMKD-CLIP on 58 diverse biomedical datasets, encompassing over 10.8 million biomedical images across nine image modalities. The evaluation spans six core task types: zero-shot classification, linear probing, cross-modal retrieval, visual question answering, survival prediction, and cancer diagnosis. MMKD-CLIP consistently outperforms all teacher models while demonstrating remarkable robustness and generalization across image domains and task settings. These results underscore that multi-teacher knowledge distillation is a scalable and effective paradigm for building high-performing biomedical foundation models under the practical constraints of real-world data availability.",
      "authors": [
        "Shansong Wang and Zhecheng Jin and Mingzhe Hu and Mojtaba Safari and Feng Zhao and Chih-Wei Chang and Richard LJ Qiu and Justin Roper and David S. Yu and Xiaofeng Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T18:28:57+00:00",
          "link": "https://arxiv.org/abs/2506.22567v1",
          "size": "2992kb",
          "version": "v1"
        }
      ],
      "title": "Unifying Biomedical Vision-Language Expertise: Towards a Generalist Foundation Model via Multi-CLIP Knowledge Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22567",
        "HTML": "https://arxiv.org/html/2506.22567v1",
        "PDF": "https://arxiv.org/pdf/2506.22567"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22570",
      "abstract": "Agricultural image semantic segmentation is a pivotal component of modern agriculture, facilitating accurate visual data analysis to improve crop management, optimize resource utilization, and boost overall productivity. This study proposes an efficient image segmentation method for precision agriculture, focusing on accurately delineating farmland anomalies to support informed decision-making and proactive interventions. A novel Dual Atrous Separable Convolution (DAS Conv) module is integrated within the DeepLabV3-based segmentation framework. The DAS Conv module is meticulously designed to achieve an optimal balance between dilation rates and padding size, thereby enhancing model performance without compromising efficiency. The study also incorporates a strategic skip connection from an optimal stage in the encoder to the decoder to bolster the model's capacity to capture fine-grained spatial features. Despite its lower computational complexity, the proposed model outperforms its baseline and achieves performance comparable to highly complex transformer-based state-of-the-art (SOTA) models on the Agriculture Vision benchmark dataset. It achieves more than 66% improvement in efficiency when considering the trade-off between model complexity and performance, compared to the SOTA model. This study highlights an efficient and effective solution for improving semantic segmentation in remote sensing applications, offering a computationally lightweight model capable of high-quality performance in agricultural imagery.",
      "authors": [
        "Chee Mei Ling",
        "Thangarajah Akilan",
        "Aparna Ravinda Phalke"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T18:37:43+00:00",
          "link": "https://arxiv.org/abs/2506.22570v1",
          "size": "10683kb",
          "version": "v1"
        }
      ],
      "title": "Dual Atrous Separable Convolution for Improving Agricultural Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22570",
        "HTML": "https://arxiv.org/html/2506.22570v1",
        "PDF": "https://arxiv.org/pdf/2506.22570"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22572",
      "abstract": "We present a simple, accessible method for autonomously transforming flat plastic sheets into intricate three-dimensional structures using only uniform heating and common tools such as household ovens and scissors. Our approach combines heat-shrinkable thermoplastics with Kirigami patterns tailored to the target 3D shape, creating bilayer composites that morph into a wide range of complex structures, e.g., bowls, pyramids, and even custom ergonomic surfaces like mouse covers. Critically, the transformation is driven by a low-information stimulus (uniform heat) yet produces highly intricate shapes through programmed geometric design. The morphing behavior, confirmed by finite element simulations, arises from strain mismatch between the contracting thermoplastic layer and the constraining Kirigami layer. By decoupling material composition from mechanical response, this method avoids detailed process control and enables a broad class of self-morphing structures, offering a versatile platform for adaptive design and scalable manufacturing.",
      "authors": [
        "Mrunmayi Mungekar",
        "Sanjith Menon",
        "M. Ravi Shankar",
        "M. Khalid Jawed"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T18:41:24+00:00",
          "link": "https://arxiv.org/abs/2506.22572v1",
          "size": "1148kb",
          "version": "v1"
        }
      ],
      "title": "Directed Shape Morphing using Kirigami-enhanced Thermoplastics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22572",
        "HTML": "https://arxiv.org/html/2506.22572v1",
        "PDF": "https://arxiv.org/pdf/2506.22572"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22576",
      "abstract": "This paper introduces a new method for solving the planar heat equation based on the Lightning Method. The lightning method is a recent development in the numerical solution of linear PDEs which expresses solutions using sums of polynomials and rational functions, or more generally as sums of fundamental solutions. The method is particularly well suited to handle domains with sharp corners where solution singularities are present. Boundary conditions are formed on a set of collocation points which is then solved as an overdetermined linear system. The approach of the present work is to utilize the Laplace transform to obtain a modified Helmholtz equation which is solved by an application of the lightning method. The numerical inversion of the Laplace transform is then performed by means of Talbot integration. Our validation of the method against existing results and multiple challenging test problems shows the method attains spectral accuracy with root-exponential convergence while being robust across a wide range of time intervals and adaptable to a variety of geometric scenarios.",
      "authors": [
        "Hunter L Croix and Alan E. Lindsay"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Complex Variables (math.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T18:45:55+00:00",
          "link": "https://arxiv.org/abs/2506.22576v1",
          "size": "3037kb",
          "version": "v1"
        }
      ],
      "title": "The lightning method for the heat equation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22576",
        "HTML": "https://arxiv.org/html/2506.22576v1",
        "PDF": "https://arxiv.org/pdf/2506.22576"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22578",
      "abstract": "Alignment of large language models (LLMs) with human values has recently garnered significant attention, with prominent examples including the canonical yet costly Reinforcement Learning from Human Feedback (RLHF) and the simple Direct Preference Optimization (DPO). In this work, we demonstrate that both RLHF and DPO can be interpreted from the perspective of mutual information (MI) maximization, uncovering a profound connection to contrastive learning. Within this framework, both RLHF and DPO can be viewed as methods that perform contrastive learning based on the positive and negative samples derived from the base model, leveraging the Donsker-Varadhan (DV) lower bound on MI (equivalently, the MINE estimator). This paradigm further explains why RLHF may not intrinsically incentivize reasoning capacities in LLMs beyond what is already present in the base model. Building on this perspective, we replace the DV/MINE bound with the Jensen-Shannon MI estimator and propose Mutual Information Optimization (MIO). Comprehensive theoretical analysis and extensive empirical evaluations demonstrate that MIO mitigates the late-stage decline in chosen-likelihood observed in DPO, achieving competitive or superior performance across various challenging reasoning and mathematical benchmarks. We will release the model and code upon acceptance.",
      "authors": [
        "Xufei Lv",
        "Haoyuan Sun",
        "Xuefeng Bai",
        "Min Zhang",
        "Houde Liu",
        "Kehai Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T18:51:25+00:00",
          "link": "https://arxiv.org/abs/2506.22578v1",
          "size": "2460kb",
          "version": "v1"
        }
      ],
      "title": "The Hidden Link Between RLHF and Contrastive Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22578",
        "HTML": "https://arxiv.org/html/2506.22578v1",
        "PDF": "https://arxiv.org/pdf/2506.22578"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22579",
      "abstract": "Accurate excavation force prediction is essential for enabling autonomous operation and optimizing control strategies in earthmoving machinery. Conventional methods typically require extensive data collection or simulations across diverse soil types, limiting scalability and adaptability. This paper proposes a data-efficient framework that calibrates soil parameters using force data from the prior bucket-loading cycle. Leveraging an analytical soil-tool interaction model, the fundamental earthmoving equation (FEE), our approach uses a multi-stage optimization strategy, on soil parameters during the loading phase. These fitted parameters are then used to predict excavation forces in the upcoming digging cycle, allowing the system to adapt its control inputs without the need for extensive data collection or machine learning-based model training. The framework is validated in high-fidelity simulations using the Algoryx Dynamics engine, across multiple soil types and excavation trajectories, demonstrating accurate force predictions with root-mean-square errors of 10\\% to 15\\% in primary test cases. This cycle-to-cycle adaptation strategy showcases the potential for online and scalable efficient path planning for wheel loader operations.",
      "authors": [
        "Armin Abdolmohammadi",
        "Navid Mojahed",
        "Shima Nazari",
        "and Bahram Ravani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T18:52:00+00:00",
          "link": "https://arxiv.org/abs/2506.22579v1",
          "size": "2642kb",
          "version": "v1"
        }
      ],
      "title": "Data-Efficient Excavation Force Estimation for Wheel Loaders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22579",
        "HTML": "https://arxiv.org/html/2506.22579v1",
        "PDF": "https://arxiv.org/pdf/2506.22579"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22583",
      "abstract": "Level of detail (LOD) is widely used to control visual feedback in interactive applications. LOD control is typically based on perception at threshold - the conditions in which a stimulus first becomes perceivable. Yet most LOD manipulations are quite perceivable and occur well above threshold. Moreover, research shows that supra-threshold perception differs drastically from perception at threshold. In that case, should supra-threshold LOD control also differ from LOD control at threshold?\n  In two experiments, we examine supra-threshold LOD control in the visual periphery and find that indeed, it should differ drastically from LOD control at threshold. Specifically, we find that LOD must support a task-dependent level of reliable perceptibility. Above that level, perceptibility of LOD control manipulations should be minimized, and detail contrast is a better predictor of perceptibility than detail size. Below that level, perceptibility must be maximized, and LOD should be improved as eccentricity rises or contrast drops. This directly contradicts prevailing threshold-based LOD control schemes, and strongly suggests a reexamination of LOD control for foveal display.",
      "authors": [
        "Benjamin Watson",
        "Neff Walker",
        "Larry F Hodges"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T19:01:45+00:00",
          "link": "https://arxiv.org/abs/2506.22583v1",
          "size": "524kb",
          "version": "v1"
        }
      ],
      "title": "Supra-threshold control of peripheral LOD",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22583",
        "PDF": "https://arxiv.org/pdf/2506.22583"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22584",
      "abstract": "This work investigates the relation between model-based quantifier instantiation (MBQI) and enumerative instantiation (EI) in Satisfiability Modulo Theories (SMT). MBQI operates at the semantic level and guarantees to find a counterexample to a given a non-model. However, it may lead to weak instantiations. In contrast, EI strives for completeness by systematically enumerating terms at the syntactic level. However, such terms may not be counter-examples. Here we investigate the relation between the two techniques and report on our initial experiments of the proposed algorithm that combines the two.",
      "authors": [
        "Marek Dan\\v{c}o",
        "Petra Hozzov\\'a",
        "Mikol\\'a\\v{s} Janota"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T19:06:29+00:00",
          "link": "https://arxiv.org/abs/2506.22584v1",
          "size": "47kb",
          "version": "v1"
        }
      ],
      "title": "From MBQI to Enumerative Instantiation and Back",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22584",
        "HTML": "https://arxiv.org/html/2506.22584v1",
        "PDF": "https://arxiv.org/pdf/2506.22584"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22589",
      "abstract": "Text on historical maps provides valuable information for studies in history, economics, geography, and other related fields. Unlike structured or semi-structured documents, text on maps varies significantly in orientation, reading order, shape, and placement. Many modern methods can detect and transcribe text regions, but they struggle to effectively ``link'' the recognized text fragments, e.g., determining a multi-word place name. Existing layout analysis methods model word relationships to improve text understanding in structured documents, but they primarily rely on linguistic features and neglect geometric information, which is essential for handling map text. To address these challenges, we propose LIGHT, a novel multi-modal approach that integrates linguistic, image, and geometric features for linking text on historical maps. In particular, LIGHT includes a geometry-aware embedding module that encodes the polygonal coordinates of text regions to capture polygon shapes and their relative spatial positions on an image. LIGHT unifies this geometric information with the visual and linguistic token embeddings from LayoutLMv3, a pretrained layout analysis model. LIGHT uses the cross-modal information to predict the reading-order successor of each text instance directly with a bi-directional learning strategy that enhances sequence robustness. Experimental results show that LIGHT outperforms existing methods on the ICDAR 2024/2025 MapText Competition data, demonstrating the effectiveness of multi-modal learning for historical map text linking.",
      "authors": [
        "Yijun Lin",
        "Rhett Olson",
        "Junhan Wu",
        "Yao-Yi Chiang and Jerod Weinman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T19:18:00+00:00",
          "link": "https://arxiv.org/abs/2506.22589v1",
          "size": "28703kb",
          "version": "v1"
        }
      ],
      "title": "LIGHT: Multi-Modal Text Linking on Historical Maps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22589",
        "HTML": "https://arxiv.org/html/2506.22589v1",
        "PDF": "https://arxiv.org/pdf/2506.22589"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22591",
      "abstract": "Recent advances in deep learning have made it possible to predict phenotypic measures directly from functional magnetic resonance imaging (fMRI) brain volumes, sparking significant interest in the neuroimaging community. However, existing approaches, primarily based on convolutional neural networks or transformer architectures, often struggle to model the complex relationships inherent in fMRI data, limited by their inability to capture long-range spatial and temporal dependencies. To overcome these shortcomings, we introduce BrainMT, a novel hybrid framework designed to efficiently learn and integrate long-range spatiotemporal attributes in fMRI data. Our framework operates in two stages: (1) a bidirectional Mamba block with a temporal-first scanning mechanism to capture global temporal interactions in a computationally efficient manner; and (2) a transformer block leveraging self-attention to model global spatial relationships across the deep features processed by the Mamba block. Extensive experiments on two large-scale public datasets, UKBioBank and the Human Connectome Project, demonstrate that BrainMT achieves state-of-the-art performance on both classification (sex prediction) and regression (cognitive intelligence prediction) tasks, outperforming existing methods by a significant margin. Our code and implementation details will be made publicly available at this https://github.com/arunkumar-kannan/BrainMT-fMRI",
      "authors": [
        "Arunkumar Kannan",
        "Martin A. Lindquist",
        "and Brian Caffo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T19:20:41+00:00",
          "link": "https://arxiv.org/abs/2506.22591v1",
          "size": "4086kb",
          "version": "v1"
        }
      ],
      "title": "BrainMT: A Hybrid Mamba-Transformer Architecture for Modeling Long-Range Dependencies in Functional MRI Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22591",
        "HTML": "https://arxiv.org/html/2506.22591v1",
        "PDF": "https://arxiv.org/pdf/2506.22591"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22593",
      "abstract": "Autonomous robots are increasingly playing key roles as support platforms for human operators in high-risk, dangerous applications. To accomplish challenging tasks, an efficient human-robot cooperation and understanding is required. While typically robotic planning leverages 3D geometric information, human operators are accustomed to a high-level compact representation of the environment, like top-down 2D maps representing the Building Information Model (BIM). 3D scene graphs have emerged as a powerful tool to bridge the gap between human readable 2D BIM and the robot 3D maps. In this work, we introduce Pixels-to-Graph (Pix2G), a novel lightweight method to generate structured scene graphs from image pixels and LiDAR maps in real-time for the autonomous exploration of unknown environments on resource-constrained robot platforms. To satisfy onboard compute constraints, the framework is designed to perform all operation on CPU only. The method output are a de-noised 2D top-down environment map and a structure-segmented 3D pointcloud which are seamlessly connected using a multi-layer graph abstracting information from object-level up to the building-level. The proposed method is quantitatively and qualitatively evaluated during real-world experiments performed using the NASA JPL NeBula-Spot legged robot to autonomously explore and map cluttered garage and urban office like environments in real-time.",
      "authors": [
        "Antonello Longo",
        "Chanyoung Chung",
        "Matteo Palieri",
        "Sung-Kyun Kim",
        "Ali Agha",
        "Cataldo Guaragnella and Shehryar Khattak"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T19:23:31+00:00",
          "link": "https://arxiv.org/abs/2506.22593v1",
          "size": "11672kb",
          "version": "v1"
        }
      ],
      "title": "Pixels-to-Graph: Real-time Integration of Building Information Models and Scene Graphs for Semantic-Geometric Human-Robot Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22593",
        "HTML": "https://arxiv.org/html/2506.22593v1",
        "PDF": "https://arxiv.org/pdf/2506.22593"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22597",
      "abstract": "Wayfinding, the ability to recall the environment and navigate through it, is an essential cognitive skill relied upon almost every day in a person's life. A crucial component of wayfinding is the construction of cognitive maps, mental representations of the environments through which a person travels. Age, disease or injury can severely affect cognitive mapping, making assessment of this basic survival skill particularly important to clinicians and therapists. Cognitive mapping has also been the focus of decades of basic research by cognitive psychologists. Both communities have evolved a number of techniques for assessing cognitive mapping ability. We present the Cognitive Map Probe (CMP), a new computerized tool for assessment of cognitive mapping ability that increases consistency and promises improvements in flexibility, accessibility, sensitivity and control. The CMP uses a tangible user interface that affords spatial manipulation. We describe the design of the CMP, and find that it is sensitive to factors known to affect cognitive mapping performance in extensive experimental testing.",
      "authors": [
        "Ehud Sharlin",
        "Benjamin Watson",
        "Steve Sutphen",
        "Lili Liu",
        "Robert Lederer",
        "John Frazer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T19:36:27+00:00",
          "link": "https://arxiv.org/abs/2506.22597v1",
          "size": "220kb",
          "version": "v1"
        }
      ],
      "title": "A tangible user interface for assessing cognitive mapping ability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22597",
        "PDF": "https://arxiv.org/pdf/2506.22597"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22598",
      "abstract": "Agents based on Large Language Models (LLMs) have shown promise for performing sophisticated software engineering tasks autonomously. In addition, there has been progress towards developing agents that can perform parts of the research pipeline in machine learning and the natural sciences. We argue that research extension and its implementation is a critical capability for such systems, and introduce RExBench to support the evaluation of this capability. RExBench is a benchmark consisting of 12 realistic research experiment implementation tasks that aim to investigate research hypotheses that have not previously been implemented. Each task is set up as an extension to an existing research paper and codebase, accompanied by domain expert-written instructions. RExBench is robust to data contamination, and supports an automatic evaluation infrastructure that executes agent outputs to determine whether the success criteria are met. We use this benchmark to evaluate nine LLM agents implemented using three different frameworks: aider, Claude Code, and OpenHands. We find that all agents evaluated fail to autonomously implement the majority of the extensions. Although the success rate improves with additional human-written hints, the best performance under this setting remains below 40%. This indicates that current agents are still short of being able to handle realistic research extension tasks without substantial human guidance.",
      "authors": [
        "Nicholas Edwards",
        "Yukyung Lee",
        "Yujun (Audrey) Mao",
        "Yulu Qin",
        "Sebastian Schuster",
        "Najoung Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T19:41:41+00:00",
          "link": "https://arxiv.org/abs/2506.22598v1",
          "size": "469kb",
          "version": "v1"
        }
      ],
      "title": "RExBench: Can coding agents autonomously implement AI research extensions?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22598",
        "PDF": "https://arxiv.org/pdf/2506.22598"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22602",
      "abstract": "Transfer learning is often used to decrease the computational cost of model training, as fine-tuning a model allows a downstream task to leverage the features learned from the pre-training dataset and quickly adapt them to a new task. This is particularly useful for achieving adversarial robustness, as adversarially training models from scratch is very computationally expensive. However, high robustness in transfer learning still requires adversarial training during the fine-tuning phase, which requires up to an order of magnitude more time than standard fine-tuning. In this work, we revisit the use of the fast gradient sign method (FGSM) in robust transfer learning to improve the computational cost of adversarial fine-tuning. We surprisingly find that FGSM is much more stable in adversarial fine-tuning than when training from scratch. In particular, FGSM fine-tuning does not suffer from any issues with catastrophic overfitting at standard perturbation budgets of $\\varepsilon=4$ or $\\varepsilon=8$. This stability is further enhanced with parameter-efficient fine-tuning methods, where FGSM remains stable even up to $\\varepsilon=32$ for linear probing. We demonstrate how this stability translates into performance across multiple datasets. Compared to fine-tuning with the more commonly used method of projected gradient descent (PGD), on average, FGSM only loses 0.39% and 1.39% test robustness for $\\varepsilon=4$ and $\\varepsilon=8$ while using $4\\times$ less training time. Surprisingly, FGSM may not only be a significantly more efficient alternative to PGD in adversarially robust transfer learning but also a well-performing one.",
      "authors": [
        "Joshua C. Zhao and Saurabh Bagchi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T19:53:53+00:00",
          "link": "https://arxiv.org/abs/2506.22602v1",
          "size": "121kb",
          "version": "v1"
        }
      ],
      "title": "Are Fast Methods Stable in Adversarially Robust Transfer Learning?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22602",
        "HTML": "https://arxiv.org/html/2506.22602v1",
        "PDF": "https://arxiv.org/pdf/2506.22602"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22604",
      "abstract": "Robot end users increasingly require accessible means of specifying tasks for robots to perform. Two common end-user programming paradigms include drag-and-drop interfaces and natural language programming. Although natural language interfaces harness an intuitive form of human communication, drag-and-drop interfaces enable users to meticulously and precisely dictate the key actions of the robot's task. In this paper, we investigate the degree to which both approaches can be combined. Specifically, we construct a large language model (LLM)-based pipeline that accepts natural language as input and produces human-like action sequences as output, specified at a level of granularity that a human would produce. We then compare these generated action sequences to another dataset of hand-specified action sequences. Although our results reveal that larger models tend to outperform smaller ones in the production of human-like action sequences, smaller models nonetheless achieve satisfactory performance.",
      "authors": [
        "David Porfirio",
        "Vincent Hsiao",
        "Morgan Fine-Morris",
        "Leslie Smith",
        "and Laura M. Hiatt"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T20:00:51+00:00",
          "link": "https://arxiv.org/abs/2506.22604v1",
          "size": "285kb",
          "version": "v1"
        }
      ],
      "title": "Bootstrapping Human-Like Planning via LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22604",
        "HTML": "https://arxiv.org/html/2506.22604v1",
        "PDF": "https://arxiv.org/pdf/2506.22604"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22606",
      "abstract": "In the current paradigm of digital personalized services, the centralized management of personal data raises significant privacy concerns, security vulnerabilities, and diminished individual autonomy over sensitive information. Despite their efficiency, traditional centralized architectures frequently fail to satisfy rigorous privacy requirements and expose users to data breaches and unauthorized access risks. This pressing challenge calls for a fundamental paradigm shift in methodologies for collecting, storing, and utilizing personal data across diverse sectors, including education, healthcare, and finance.\n  This paper introduces a novel decentralized, privacy-preserving architecture that handles heterogeneous personal information, ranging from educational credentials to health records and financial data. Unlike traditional models, our system grants users complete data ownership and control, allowing them to selectively share information without compromising privacy. The architecture's foundation comprises advanced privacy-enhancing technologies, including secure enclaves and federated learning, enabling secure computation, verification, and data sharing. The system supports diverse functionalities, including local computation, model training, and privacy-preserving data sharing, while ensuring data credibility and robust user privacy.",
      "authors": [
        "Osama Zafar",
        "Mina Namazi",
        "Yuqiao Xu",
        "Youngjin Yoo",
        "Erman Ayday"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T20:05:46+00:00",
          "link": "https://arxiv.org/abs/2506.22606v1",
          "size": "427kb",
          "version": "v1"
        }
      ],
      "title": "A User-Centric, Privacy-Preserving, and Verifiable Ecosystem for Personal Data Management and Utilization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22606",
        "HTML": "https://arxiv.org/html/2506.22606v1",
        "PDF": "https://arxiv.org/pdf/2506.22606"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22608",
      "abstract": "We study the problem of distributed distinct element estimation, where $\\alpha$ servers each receive a subset of a universe $[n]$ and aim to compute a $(1+\\varepsilon)$-approximation to the number of distinct elements using minimal communication. While prior work establishes a worst-case bound of $\\Theta\\left(\\alpha\\log n+\\frac{\\alpha}{\\varepsilon^2}\\right)$ bits, these results rely on assumptions that may not hold in practice. We introduce a new parameterization based on the number $C = \\frac{\\beta}{\\varepsilon^2}$ of pairwise collisions, i.e., instances where the same element appears on multiple servers, and design a protocol that uses only $\\mathcal{O}\\left(\\alpha\\log n+\\frac{\\sqrt{\\beta}}{\\varepsilon^2} \\log n\\right)$ bits, breaking previous lower bounds when $C$ is small. We further improve our algorithm under assumptions on the number of distinct elements or collisions and provide matching lower bounds in all regimes, establishing $C$ as a tight complexity measure for the problem. Finally, we consider streaming algorithms for distinct element estimation parameterized by the number of items with frequency larger than $1$. Overall, our results offer insight into why statistical problems with known hardness results can be efficiently solved in practice.",
      "authors": [
        "Ilias Diakonikolas",
        "Daniel M. Kane",
        "Jasper C.H. Lee",
        "Thanasis Pittas",
        "David P. Woodruff",
        "Samson Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T20:13:44+00:00",
          "link": "https://arxiv.org/abs/2506.22608v1",
          "size": "135kb",
          "version": "v1"
        }
      ],
      "title": "On Fine-Grained Distinct Element Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22608",
        "HTML": "https://arxiv.org/html/2506.22608v1",
        "PDF": "https://arxiv.org/pdf/2506.22608"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22609",
      "abstract": "Games have long been used as benchmarks and testing environments for research in artificial intelligence. A key step in supporting this research was the development of game description languages: frameworks that compile domain-specific code into playable and simulatable game environments, allowing researchers to generalize their algorithms and approaches across multiple games without having to manually implement each one. More recently, progress in reinforcement learning (RL) has been largely driven by advances in hardware acceleration. Libraries like JAX allow practitioners to take full advantage of cutting-edge computing hardware, often speeding up training and testing by orders of magnitude. Here, we present a synthesis of these strands of research: a domain-specific language for board games which automatically compiles into hardware-accelerated code. Our framework, Ludax, combines the generality of game description languages with the speed of modern parallel processing hardware and is designed to fit neatly into existing deep learning pipelines. We envision Ludax as a tool to help accelerate games research generally, from RL to cognitive science, by enabling rapid simulation and providing a flexible representation scheme. We present a detailed breakdown of Ludax's description language and technical notes on the compilation process, along with speed benchmarking and a demonstration of training RL agents. The Ludax framework, along with implementations of existing board games, is open-source and freely available.",
      "authors": [
        "Graham Todd",
        "Alexander G. Padula",
        "Dennis J.N.J. Soemers",
        "Julian Togelius"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T20:15:53+00:00",
          "link": "https://arxiv.org/abs/2506.22609v1",
          "size": "137kb",
          "version": "v1"
        }
      ],
      "title": "Ludax: A GPU-Accelerated Domain Specific Language for Board Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22609",
        "HTML": "https://arxiv.org/html/2506.22609v1",
        "PDF": "https://arxiv.org/pdf/2506.22609"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22615",
      "abstract": "The Arnoldi process provides an efficient framework for approximating functions of a matrix applied to a vector, i.e., of the form $f(M)\\mathbf{b}$, by repeated matrix-vector multiplications. In this paper, we derive an \\textit{a priori} error estimate for approximating the action of a matrix square root using the Arnoldi process, where the integral representation of the error is reformulated in terms of the error for solving the linear system $M\\mathbf{x}=\\mathbf{b}$. The results extend the error analysis of the Lanczos method for Hermitian matrices in [Chen et al., SIAM J. Matrix Anal. Appl., 2022] to non-Hermitian cases. Furthermore, to make the method applicable to large-scale problems, we assume that the matrices are preprocessed utilizing data-sparse approximations preserving positive definiteness, and then establish a refined error bound in this setting. The numerical results on matrices with different structures demonstrate that our theoretical analysis yields a reliable upper bound. Finally, simulations on large-scale matrices arising in particulate suspensions validate the effectiveness and practicality of the approach.",
      "authors": [
        "James H. Adler",
        "Xiaozhe Hu",
        "Wenxiao Pan",
        "Zhongqin Xue"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T20:22:46+00:00",
          "link": "https://arxiv.org/abs/2506.22615v1",
          "size": "1936kb",
          "version": "v1"
        }
      ],
      "title": "Error Estimates for the Arnoldi Approximation of a Matrix Square Root",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22615",
        "HTML": "https://arxiv.org/html/2506.22615v1",
        "PDF": "https://arxiv.org/pdf/2506.22615"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22619",
      "abstract": "Given an undirected weighted graph $G$ and an integer $k$, Exact-Weight Perfect Matching (EWPM) is the problem of finding a perfect matching of weight exactly $k$ in $G$. In this paper, we study EWPM and its variants. The EWPM problem is famous, since in the case of unary encoded weights, Mulmuley, Vazirani, and Vazirani showed almost 40 years ago that the problem can be solved in randomized polynomial time. However, up to this date no derandomization is known.\n  Our first result is a simple deterministic algorithm for EWPM that runs in time $n^{O(\\ell)}$, where $\\ell$ is the number of distinct weights that perfect matchings in $G$ can take. In fact, we show how to find an $\\ell$-th smallest perfect matching in any weighted graph (even if the weights are encoded in binary, in which case EWPM in general is known to be NP-complete) in time $n^{O(\\ell)}$ for any integer $\\ell$. Similar next-to-optimal variants have also been studied recently for the shortest path problem.\n  For our second result, we extend the list of problems that are known to be equivalent to EWPM. We show that EWPM is equivalent under a weight-preserving reduction to the Exact Cycle Sum problem (ECS) in undirected graphs with a conservative (i.e. no negative cycles) weight function. To the best of our knowledge, we are the first to study this problem. As a consequence, the latter problem is contained in RP if the weights are encoded in unary. Finally, we identify a special case of EWPM, called BCPM, which was recently studied by El Maalouly, Steiner and Wulf. We show that BCPM is equivalent under a weight-preserving transformation to another problem recently studied by Schlotter and Seb\\H{o} as well as Geelen and Kapadia: the Shortest Odd Cycle problem (SOC) in undirected graphs with conservative weights.",
      "authors": [
        "Nicolas El Maalouly",
        "Sebastian Haslebacher",
        "Adrian Taubner",
        "Lasse Wulf"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T20:31:35+00:00",
          "link": "https://arxiv.org/abs/2506.22619v1",
          "size": "131kb",
          "version": "v1"
        }
      ],
      "title": "On Finding $\\ell$-th Smallest Perfect Matchings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22619",
        "HTML": "https://arxiv.org/html/2506.22619v1",
        "PDF": "https://arxiv.org/pdf/2506.22619"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22621",
      "abstract": "Simulation-based problems involving mixed-variable inputs frequently feature domains that are hierarchical, conditional, heterogeneous, or tree-structured. These characteristics pose challenges for data representation, modeling, and optimization. This paper reviews extensive literature on these structured input spaces and proposes a unified framework that generalizes existing approaches. In this framework, input variables may be continuous, integer, or categorical. A variable is described as meta if its value governs the presence of other decreed variables, enabling the modeling of conditional and hierarchical structures.\n  We further introduce the concept of partially-decreed variables, whose activation depends on contextual conditions. To capture these inter-variable hierarchical relationships, we introduce design space graphs, combining principles from feature modeling and graph theory. This allows the definition of general hierarchical domains suitable for describing complex system architectures. The framework supports the use of surrogate models over such domains and integrates hierarchical kernels and distances for efficient modeling and optimization. The proposed methods are implemented in the open-source Surrogate Modeling Toolbox (SMT 2.0), and their capabilities are demonstrated through applications in Bayesian optimization for complex system design, including a case study in green aircraft architecture.",
      "authors": [
        "Paul Saves and Edward Hall\\'e-Hannan and Jasper Bussemaker and Youssef Diouane and Nathalie Bartoli"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T20:38:57+00:00",
          "link": "https://arxiv.org/abs/2506.22621v1",
          "size": "815kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Modeling and Architecture Optimization: Review and Unified Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22621",
        "PDF": "https://arxiv.org/pdf/2506.22621"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22623",
      "abstract": "In the present-day scenario, Large Language Models (LLMs) are establishing their presence as powerful instruments permeating various sectors of society. While their utility offers valuable support to individuals, there are multiple concerns over potential misuse. Consequently, some academic endeavors have sought to introduce watermarking techniques, characterized by the inclusion of markers within machine-generated text, to facilitate algorithmic identification. This research project is focused on the development of a novel methodology for the detection of synthetic text, with the overarching goal of ensuring the ethical application of LLMs in AI-driven text generation. The investigation commences with replicating findings from a previous baseline study, thereby underscoring its susceptibility to variations in the underlying generation model. Subsequently, we propose an innovative watermarking approach and subject it to rigorous evaluation, employing paraphrased generated text to asses its robustness. Experimental results highlight the robustness of our proposal compared to the~\\cite{aarson} watermarking method.",
      "authors": [
        "Badr Youbi Idrissi",
        "Monica Millunzi",
        "Amelia Sorrenti",
        "Lorenzo Baraldi",
        "Daryna Dementieva"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T20:39:35+00:00",
          "link": "https://arxiv.org/abs/2506.22623v1",
          "size": "207kb",
          "version": "v1"
        }
      ],
      "title": "Temperature Matters: Enhancing Watermark Robustness Against Paraphrasing Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22623",
        "HTML": "https://arxiv.org/html/2506.22623v1",
        "PDF": "https://arxiv.org/pdf/2506.22623"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22624",
      "abstract": "We present Seg-R1, a preliminary exploration of using reinforcement learning (RL) to enhance the pixel-level understanding and reasoning capabilities of large multimodal models (LMMs). Starting with foreground segmentation tasks, specifically camouflaged object detection (COD) and salient object detection (SOD), our approach enables the LMM to generate point and bounding box prompts in the next-token fashion, which are then used to guide SAM2 in producing segmentation masks. We introduce Group Relative Policy Optimization (GRPO) into the segmentation domain, equipping the LMM with pixel-level comprehension through a carefully designed training strategy. Notably, Seg-R1 achieves remarkable performance with purely RL-based training, achieving .873 S-measure on COD10K without complex model modification. Moreover, we found that pure RL training demonstrates strong open-world generalization. Despite being trained solely on foreground segmentation image-mask pairs without text supervision, Seg-R1 achieves impressive zero-shot performance on referring segmentation and reasoning segmentation tasks, with 71.4 cIoU on RefCOCOg test and 56.7 gIoU on ReasonSeg test, outperforming models fully supervised on these datasets.",
      "authors": [
        "Zuyao You",
        "Zuxuan Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T20:40:45+00:00",
          "link": "https://arxiv.org/abs/2506.22624v1",
          "size": "16367kb",
          "version": "v1"
        }
      ],
      "title": "Seg-R1: Segmentation Can Be Surprisingly Simple with Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22624",
        "HTML": "https://arxiv.org/html/2506.22624v1",
        "PDF": "https://arxiv.org/pdf/2506.22624"
      },
      "datasets": [
        {
          "dataset_name": "geshang/FCoT",
          "downloads": "12",
          "likes": "0",
          "link": "https://huggingface.co/datasets/geshang/FCoT"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.22628",
      "abstract": "Manual sound design with a synthesizer is inherently iterative: an artist compares the synthesized output to a mental target, adjusts parameters, and repeats until satisfied. Iterative sound-matching automates this workflow by continually programming a synthesizer under the guidance of a loss function (or similarity measure) toward a target sound. Prior comparisons of loss functions have typically favored one metric over another, but only within narrow settings: limited synthesis methods, few loss types, often without blind listening tests. This leaves open the question of whether a universally optimal loss exists, or the choice of loss remains a creative decision conditioned on the synthesis method and the sound designer's preference. We propose differentiable iterative sound-matching as the natural extension of the available literature, since it combines the manual approach to sound design with modern advances in machine learning. To analyze the variability of loss function performance across synthesizers, we implemented a mix of four novel and established differentiable loss functions, and paired them with differentiable subtractive, additive, and AM synthesizers. For each of the sixteen synthesizer--loss combinations, we ran 300 randomized sound-matching trials. Performance was measured using parameter differences, spectrogram-distance metrics, and manually assigned listening scores. We observed a moderate level of consistency among the three performance measures. Our post-hoc analysis shows that the loss function performance is highly dependent on the synthesizer. These findings underscore the value of expanding the scope of sound-matching experiments and developing new similarity metrics tailored to specific synthesis techniques rather than pursuing one-size-fits-all solutions.",
      "authors": [
        "Amir Salimi",
        "Abram Hindle",
        "Osmar R. Zaiane"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T20:43:28+00:00",
          "link": "https://arxiv.org/abs/2506.22628v1",
          "size": "511kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Sound Similarity Metrics for Differentiable, Iterative Sound-Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22628",
        "HTML": "https://arxiv.org/html/2506.22628v1",
        "PDF": "https://arxiv.org/pdf/2506.22628"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22631",
      "abstract": "We study the problem of online regression with the unconstrained quadratic loss against a time-varying sequence of functions from a Reproducing Kernel Hilbert Space (RKHS). Recently, Jacobsen and Cutkosky (2024) introduced a discounted Vovk-Azoury-Warmuth (DVAW) forecaster that achieves optimal dynamic regret in the finite-dimensional case. In this work, we lift their approach to the non-parametric domain by synthesizing the DVAW framework with a random feature approximation. We propose a fully adaptive, hierarchical algorithm, which we call H-VAW-D (Hierarchical Vovk-Azoury-Warmuth with Discounting), that learns both the discount factor and the number of random features. We prove that this algorithm, which has a per-iteration computational complexity of $O(T\\ln T)$, achieves an expected dynamic regret of $O(T^{2/3}P_T^{1/3} + \\sqrt{T}\\ln T)$, where $P_T$ is the functional path length of a comparator sequence.",
      "authors": [
        "Dmitry B. Rokhlin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T20:47:52+00:00",
          "link": "https://arxiv.org/abs/2506.22631v1",
          "size": "21kb",
          "version": "v1"
        }
      ],
      "title": "A hierarchical Vovk-Azoury-Warmuth forecaster with discounting for online regression in RKHS",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22631",
        "HTML": "https://arxiv.org/html/2506.22631v1",
        "PDF": "https://arxiv.org/pdf/2506.22631"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22632",
      "abstract": "The cost of communication between the operating system kernel and user applications has long blocked improvements in software performance. Traditionally, operating systems encourage software developers to use the system call interface to transfer (or initiate transfer of) data between user applications and the kernel. This approach not only hurts performance at the software level due to memory copies between user space address spaces and kernel space address spaces, it also hurts system performance at the microarchitectural level by flushing processor pipelines and other microarchitectural state.\n  In this paper, we propose a new communication interface between user applications and the kernel by setting up a shared memory region between user space applications and the kernel's address space. We acknowledge the danger in breaking the golden law of user-kernel address space isolation, so we coupled a uBPF VM (user-space BPF Virtual Machine) with shared memory to control access to the kernel's memory from the user's application. In this case, user-space programs can access the shared memory under the supervision of the uBPF VM (and the kernel's blessing of its shared library) to gain non-blocking data transfer to and from the kernel's memory space. We test our implementation in several use cases and find this mechanism can bring speedups over traditional user-kernel information passing mechanisms.",
      "authors": [
        "Boming Kong",
        "Zhizhou Zhang",
        "Jonathan Balkind"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Operating Systems (cs.OS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T20:49:59+00:00",
          "link": "https://arxiv.org/abs/2506.22632v1",
          "size": "328kb",
          "version": "v1"
        }
      ],
      "title": "Using SBPF to Accelerate Kernel Memory Access From Userspace",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22632",
        "HTML": "https://arxiv.org/html/2506.22632v1",
        "PDF": "https://arxiv.org/pdf/2506.22632"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22636",
      "abstract": "Vision Language Models (VLMs) show impressive capabilities in integrating and reasoning with both visual and language data. But these models make mistakes. A common finding -- similar to LLMs -- is their tendency to hallucinate, i.e., generate plausible sounding text which is not grounded in the visual input, or at worst, is contradictory. A growing consensus attributes this behavior to an over-reliance on language -- especially as the generation progresses, the model suffers from a ``fading memory effect'' with respect to the provided visual input. We study mechanisms by which this behavior can be controlled. Specifically, using ideas from geometric algebra and relational compositions, we propose the addition of a small, trainable module (named ReCo) on top of any VLM -- no other modification is needed. We show that such a lightweight module is able to mitigate the fading memory effect on three of the most widely used VLMs (InstructBLIP, LlaVA, MiniGPT4), where we see performance improvements on multiple benchmarks. Additionally, we show that our module can be combined with many of the other approaches for reducing hallucination where we achieve improved results for each one.",
      "authors": [
        "Sotirios Panagiotis Chytas",
        "Miso Choi",
        "Hyunwoo J. Kim",
        "Vikas Singh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T21:01:02+00:00",
          "link": "https://arxiv.org/abs/2506.22636v1",
          "size": "45084kb",
          "version": "v1"
        }
      ],
      "title": "ReCo: Reminder Composition Mitigates Hallucinations in Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22636",
        "HTML": "https://arxiv.org/html/2506.22636v1",
        "PDF": "https://arxiv.org/pdf/2506.22636"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22637",
      "abstract": "The recent introduction of diffusion models in dataset distillation has shown promising potential in creating compact surrogate datasets for large, high-resolution target datasets, offering improved efficiency and performance over traditional bi-level/uni-level optimization methods. However, current diffusion-based dataset distillation approaches overlook the evaluation process and exhibit two critical inconsistencies in the distillation process: (1) Objective Inconsistency, where the distillation process diverges from the evaluation objective, and (2) Condition Inconsistency, leading to mismatches between generated images and their corresponding conditions. To resolve these issues, we introduce Condition-aware Optimization with Objective-guided Sampling (CaO$_2$), a two-stage diffusion-based framework that aligns the distillation process with the evaluation objective. The first stage employs a probability-informed sample selection pipeline, while the second stage refines the corresponding latent representations to improve conditional likelihood. CaO$_2$ achieves state-of-the-art performance on ImageNet and its subsets, surpassing the best-performing baselines by an average of 2.3% accuracy.",
      "authors": [
        "Haoxuan Wang",
        "Zhenghao Zhao",
        "Junyi Wu",
        "Yuzhang Shang",
        "Gaowen Liu",
        "Yan Yan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T21:02:05+00:00",
          "link": "https://arxiv.org/abs/2506.22637v1",
          "size": "2593kb",
          "version": "v1"
        }
      ],
      "title": "CaO$_2$: Rectifying Inconsistencies in Diffusion-Based Dataset Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22637",
        "HTML": "https://arxiv.org/html/2506.22637v1",
        "PDF": "https://arxiv.org/pdf/2506.22637"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22638",
      "abstract": "Large language models can exhibit improved mathematical reasoning capabilities following post-training with instruction tuning, reinforcement learning, or knowledge distillation. However, it remains unclear whether these improvements are driven by major changes in transformer layers or from minor adjustments that leave the relative layer importance structures of the base model largely unchanged. We investigate this question through systematic layer-wise ablation experiments, examining base, instruction-tuned, knowledge-distilled, and reinforcement learning variants on mathematical reasoning benchmarks. Our findings show that mathematical reasoning gives rise to a specific layer importance structure, and this structure persists across all post-training paradigms. Removal of such layers causes accuracy drops of up to 80%. In contrast, non-mathematical tasks like factual recall exhibit no critical layers. This distinction suggests that mathematical reasoning requires specialized layers that emerge during pre-training, while other non-reasoning tasks do not. From an information-theoretic perspective, we also observe that these critical layers are the same layers where major representational transformation occurs.",
      "authors": [
        "Aadim Nepal",
        "Safal Shrestha",
        "Anubhav Shrestha",
        "Minwu Kim",
        "Keith Ross"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T21:04:55+00:00",
          "link": "https://arxiv.org/abs/2506.22638v1",
          "size": "519kb",
          "version": "v1"
        }
      ],
      "title": "Layer Importance for Mathematical Reasoning is Forged in Pre-Training and Invariant after Post-Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22638",
        "PDF": "https://arxiv.org/pdf/2506.22638"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22639",
      "abstract": "This paper presents a large-scale analysis of fingerprinting-like behavior in the mobile application ecosystem. We take a market-based approach, focusing on third-party tracking as enabled by applications' common use of third-party SDKs. Our dataset consists of over 228,000 SDKs from popular Maven repositories, 178,000 Android applications collected from the Google Play store, and our static analysis pipeline detects exfiltration of over 500 individual signals. To the best of our knowledge, this represents the largest-scale analysis of SDK behavior undertaken to date.\n  We find that Ads SDKs (the ostensible focus of industry efforts such as Apple's App Tracking Transparency and Google's Privacy Sandbox) appear to be the source of only 30.56% of the fingerprinting behaviors. A surprising 23.92% originate from SDKs whose purpose was unknown or unclear. Furthermore, Security and Authentication SDKs are linked to only 11.7% of likely fingerprinting instances. These results suggest that addressing fingerprinting solely in specific market-segment contexts like advertising may offer incomplete benefit. Enforcing anti-fingerprinting policies is also complex, as we observe a sparse distribution of signals and APIs used by likely fingerprinting SDKs. For instance, only 2% of exfiltrated APIs are used by more than 75% of SDKs, making it difficult to rely on user permissions to control fingerprinting behavior.",
      "authors": [
        "Michael A. Specter",
        "Mihai Christodorescu",
        "Abbie Farr",
        "Bo Ma",
        "Robin Lassonde",
        "Xiaoyang Xu",
        "Xiang Pan",
        "Fengguo Wei",
        "Saswat Anand",
        "Dave Kleidermacher"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T21:05:48+00:00",
          "link": "https://arxiv.org/abs/2506.22639v1",
          "size": "1024kb",
          "version": "v1"
        }
      ],
      "title": "Fingerprinting SDKs for Mobile Apps and Where to Find Them: Understanding the Market for Device Fingerprinting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22639",
        "PDF": "https://arxiv.org/pdf/2506.22639"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22644",
      "abstract": "We present our submission to the LiveRAG Challenge 2025, which evaluates retrieval-augmented generation (RAG) systems on dynamic test sets using the FineWeb-10BT corpus. Our final hybrid approach combines sparse (BM25) and dense (E5) retrieval methods and then aims to generate relevant and faithful answers with Falcon3-10B-Instruct. Through systematic evaluation on 200 synthetic questions generated with DataMorgana across 64 unique question-user combinations, we demonstrate that neural re-ranking with RankLLaMA improves MAP from 0.523 to 0.797 (52% relative improvement) but introduces prohibitive computational costs (84s vs 1.74s per question). While DSPy-optimized prompting strategies achieved higher semantic similarity (0.771 vs 0.668), their 0% refusal rates raised concerns about over-confidence and generalizability. Our submitted hybrid system without re-ranking achieved 4th place in faithfulness and 11th place in correctness among 25 teams. Analysis across question categories reveals that vocabulary alignment between questions and documents was the strongest predictor of performance on our development set, with document-similar phrasing improving cosine similarity from 0.562 to 0.762.",
      "authors": [
        "Chase Fensore",
        "Kaustubh Dhole",
        "Joyce C Ho and Eugene Agichtein"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T21:20:43+00:00",
          "link": "https://arxiv.org/abs/2506.22644v1",
          "size": "87kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Hybrid Retrieval Augmented Generation using Dynamic Test Sets: LiveRAG Challenge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22644",
        "HTML": "https://arxiv.org/html/2506.22644v1",
        "PDF": "https://arxiv.org/pdf/2506.22644"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22645",
      "abstract": "Machine Learning surrogates have been developed to accelerate solving systems dynamics of complex processes in different science and engineering applications. To faithfully capture governing systems dynamics, these methods rely on large training datasets, hence restricting their applicability in real-world problems. In this work, we propose BayPOD-AL, an active learning framework based on an uncertainty-aware Bayesian proper orthogonal decomposition (POD) approach, which aims to effectively learn reduced-order models from high-fidelity full-order models representing complex systems. Experimental results on predicting the temperature evolution over a rod demonstrate BayPOD-AL's effectiveness in suggesting the informative data and reducing computational cost related to constructing a training dataset compared to other uncertainty-guided active learning strategies. Furthermore, we demonstrate BayPOD-AL's generalizability and efficiency by evaluating its performance on a dataset of higher temporal resolution than the training dataset.",
      "authors": [
        "Amir Hossein Rahmati",
        "Nathan M. Urban",
        "Byung-Jun Yoon",
        "Xiaoning Qian"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T21:23:37+00:00",
          "link": "https://arxiv.org/abs/2506.22645v1",
          "size": "200kb",
          "version": "v1"
        }
      ],
      "title": "Cost-effective Reduced-Order Modeling via Bayesian Active Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22645",
        "HTML": "https://arxiv.org/html/2506.22645v1",
        "PDF": "https://arxiv.org/pdf/2506.22645"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22648",
      "abstract": "Over the past decade, recommender systems have experienced a surge in popularity. Despite notable progress, they grapple with challenging issues, such as high data dimensionality and sparseness. Representing users and items as low-dimensional embeddings learned via neural networks has become a leading solution. However, while recent studies show promising results, many approaches rely on complex architectures or require content data, which may not always be available. This paper presents Interact2Vec, a novel neural network-based model that simultaneously learns distributed embeddings for users and items while demanding only implicit feedback. The model employs state-of-the-art strategies that natural language processing models commonly use to optimize the training phase and enhance the final embeddings. Two types of experiments were conducted regarding the extrinsic and intrinsic quality of the model. In the former, we benchmarked the recommendations generated by Interact2Vec's embeddings in a top-$N$ ranking problem, comparing them with six other recommender algorithms. The model achieved the second or third-best results in 30\\% of the datasets, being competitive with other recommenders, and has proven to be very efficient with an average training time reduction of 274\\% compared to other embedding-based models. Later, we analyzed the intrinsic quality of the embeddings through similarity tables. Our findings suggest that Interact2Vec can achieve promising results, especially on the extrinsic task, and is an excellent embedding-generator model for scenarios of scarce computing resources, enabling the learning of item and user embeddings simultaneously and efficiently.",
      "authors": [
        "Pedro R. Pires and Tiago A. Almeida"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T21:30:03+00:00",
          "link": "https://arxiv.org/abs/2506.22648v1",
          "size": "558kb",
          "version": "v1"
        }
      ],
      "title": "Interact2Vec -- An efficient neural network-based model for simultaneously learning users and items embeddings in recommender systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22648",
        "HTML": "https://arxiv.org/html/2506.22648v1",
        "PDF": "https://arxiv.org/pdf/2506.22648"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22652",
      "abstract": "Efficient and fair coexistence in unlicensed spectrum is essential to support heterogeneous networks such as 5G NR-U and Wi-Fi, which often contend for shared wireless resources. We introduce a general framework for wireless Coexistence Parameter Management (CPM) based on state-augmented constrained reinforcement learning. We propose a novel algorithm, QaSAL-CPM, which incorporates state-augmentation by embedding the dual variables in the constrained optimization formulation directly into the agent's observation space. This method enables the agent to respond to constraint violations in real time while continuing to optimize a primary performance objective. Through extensive simulations of 5G NR-U and Wi-Fi coexistence scenarios, we show that QaSAL-CPM achieves reliable QoS compliance and improved policy robustness across various transmitter densities compared to previous approaches. The proposed framework offers a scalable and adaptive solution for real-time coexistence optimization in next-generation wireless networks.",
      "authors": [
        "Mohammad Reza Fasihi and Brian L. Mark"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T21:48:27+00:00",
          "link": "https://arxiv.org/abs/2506.22652v1",
          "size": "2842kb",
          "version": "v1"
        }
      ],
      "title": "QoS-aware State-Augmented Learnable Algorithm for Wireless Coexistence Parameter Management",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22652",
        "HTML": "https://arxiv.org/html/2506.22652v1",
        "PDF": "https://arxiv.org/pdf/2506.22652"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22653",
      "abstract": "Large language models (LLMs) have moved far beyond their initial form as simple chatbots, now carrying out complex reasoning, planning, writing, coding, and research tasks. These skills overlap significantly with those that human scientists use day-to-day to solve complex problems that drive the cutting edge of research. Using LLMs in \"agentic\" AI has the potential to revolutionize modern science and remove bottlenecks to progress. In this work, we present URSA, a scientific agent ecosystem for accelerating research tasks. URSA consists of a set of modular agents and tools, including coupling to advanced physics simulation codes, that can be combined to address scientific problems of varied complexity and impact. This work highlights the architecture of URSA, as well as examples that highlight the potential of the system.",
      "authors": [
        "Michael Grosskopf",
        "Russell Bent",
        "Rahul Somasundaram",
        "Isaac Michaud",
        "Arthur Lui",
        "Nathan Debardeleben",
        "Earl Lawrence"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T21:56:02+00:00",
          "link": "https://arxiv.org/abs/2506.22653v1",
          "size": "841kb",
          "version": "v1"
        }
      ],
      "title": "URSA: The Universal Research and Scientific Agent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22653",
        "PDF": "https://arxiv.org/pdf/2506.22653"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22654",
      "abstract": "Data center hardware refresh cycles are lengthening. However, increasing processor complexity is raising the potential for faults. To achieve longevity in the face of increasingly fault-prone datapaths, fault tolerance is needed, especially in on-chip accelerator datapaths. Previously researched methods for adding fault tolerance to accelerator designs require high area, lowering chip utilisation. We propose a novel architecture for accelerator fault tolerance, Oobleck, which leverages modular acceleration to enable fault tolerance without burdensome area requirements.\n  In order to streamline the development and enforce modular conventions, we introduce the Viscosity language, an actor based approach to hardware-software co-design. Viscosity uses a single description of the accelerator's function and produces both hardware and software descriptions.\n  Our high-level models of data centers indicate that our approach can decrease the number of failure-induced chip purchases inside data centers while not affecting aggregate throughput, thus reducing data center costs. To show the feasibility of our approach, we show three case-studies: FFT, AES, and DCT accelerators. We additionally profile the performance under the key parameters affecting latency. Under a single fault we can maintain speedups of between 1.7x-5.16x for accelerated applications over purely software implementations. We show further benefits can be achieved by adding hot-spare FPGAs into the chip.",
      "authors": [
        "Guy Wilks",
        "Brian Li",
        "Jonathan Balkind"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T21:56:39+00:00",
          "link": "https://arxiv.org/abs/2506.22654v1",
          "size": "1542kb",
          "version": "v1"
        }
      ],
      "title": "Oobleck: Low-Compromise Design for Fault Tolerant Accelerators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22654",
        "HTML": "https://arxiv.org/html/2506.22654v1",
        "PDF": "https://arxiv.org/pdf/2506.22654"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22655",
      "abstract": "The physical sciences are replete with dynamical systems that require the resolution of a wide range of length and time scales. This presents significant computational challenges since direct numerical simulation requires discretization at the finest relevant scales, leading to a high-dimensional state space. In this work, we propose an approach to learn stochastic multiscale models in the form of stochastic differential equations directly from observational data. Our method resolves the state on a coarse mesh while introducing an auxiliary state to capture the effects of unresolved scales. We learn the parameters of the multiscale model using a modern forward-solver-free amortized variational inference method. Our approach draws inspiration from physics-based multiscale modeling approaches, such as large-eddy simulation in fluid dynamics, while learning directly from data. We present numerical studies to demonstrate that our learned multiscale models achieve superior predictive accuracy compared to direct numerical simulation and closure-type models at equivalent resolution.",
      "authors": [
        "Andrew F. Ilersich and Prasanth B. Nair"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T21:57:06+00:00",
          "link": "https://arxiv.org/abs/2506.22655v1",
          "size": "3469kb",
          "version": "v1"
        }
      ],
      "title": "Learning Stochastic Multiscale Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22655",
        "PDF": "https://arxiv.org/pdf/2506.22655"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22656",
      "abstract": "This paper envisions a knowledge-guided multi-agent framework named KGMAF for automated requirements development. KGMAF aims to address gaps in current automation systems for SE, which prioritize code development and overlook the complexities of requirements tasks. KGMAF is composed of six specialized agents and an artifact pool to improve efficiency and accuracy. Specifically, KGMAF outlines the functionality, actions, and knowledge of each agent and provides the conceptual design of the artifact pool. Our case study highlights the potential of KGMAF in real-world scenarios. Finally, we outline several research opportunities for implementing and enhancing automated requirements development using multi-agent systems. We believe that KGMAF will play a pivotal role in shaping the future of automated requirements development in the era of LLMs.",
      "authors": [
        "Jiangping Huang and Dongming Jin and Weisong Sun and Yang Liu and Zhi Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T21:57:53+00:00",
          "link": "https://arxiv.org/abs/2506.22656v1",
          "size": "284kb",
          "version": "v1"
        }
      ],
      "title": "Knowledge-Guided Multi-Agent Framework for Automated Requirements Development: A Vision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22656",
        "HTML": "https://arxiv.org/html/2506.22656v1",
        "PDF": "https://arxiv.org/pdf/2506.22656"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22657",
      "abstract": "For the approximation of solutions for It\\^o and Stratonovich stochastic differential equations (SDEs)a new class of efficient stochastic Runge-Kutta (SRK) methods is developed. As the main novelty only two stages are necessary for the proposed SRK methods of order 1 that can be applied to SDEs with non-commutative or with commutative noise. In addition, a variant of the SRK method for SDEs with additive noise is presented. All proposed SRK methods cover also the case of drift-implicit schemes and general order conditions for the coefficients are calculated explicitly. The new class of SRK methods is highly efficient in the sense that it features computational cost depending only linearly on the dimension of the SDE and on the dimension of the driving Wiener process. For all proposed SRK methods strong convergence with order 1 in $L^p$-norm for any $p \\geq 2$ is proved. Moreover, sufficient conditions for approximated iterated stochastic integrals are established such that convergence with order 1 in $L^p$-norm is preserved if they are applied for the SRK method. The presented theoretical results are confirmed by numerical experiments.",
      "authors": [
        "Andreas R\\\"o{\\ss}ler"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T22:00:54+00:00",
          "link": "https://arxiv.org/abs/2506.22657v1",
          "size": "171kb",
          "version": "v1"
        }
      ],
      "title": "A Class of Stochastic Runge-Kutta Methods for Stochastic Differential Equations Converging with Order 1 in $L^p$-Norm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22657",
        "PDF": "https://arxiv.org/pdf/2506.22657"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22661",
      "abstract": "Audio fingerprinting (AFP) allows the identification of unknown audio content by extracting compact representations, termed audio fingerprints, that are designed to remain robust against common audio degradations. Neural AFP methods often employ metric learning, where representation quality is influenced by the nature of the supervision and the utilized loss function. However, recent work unrealistically simulates real-life audio degradation during training, resulting in sub-optimal supervision. Additionally, although several modern metric learning approaches have been proposed, current neural AFP methods continue to rely on the NT-Xent loss without exploring the recent advances or classical alternatives. In this work, we propose a series of best practices to enhance the self-supervision by leveraging musical signal properties and realistic room acoustics. We then present the first systematic evaluation of various metric learning approaches in the context of AFP, demonstrating that a self-supervised adaptation of the triplet loss yields superior performance. Our results also reveal that training with multiple positive samples per anchor has critically different effects across loss functions. Our approach is built upon these insights and achieves state-of-the-art performance on both a large, synthetically degraded dataset and a real-world dataset recorded using microphones in diverse music venues.",
      "authors": [
        "R. O. Araz",
        "G. Cortes-Sebastia",
        "E. Molina",
        "J. Serra",
        "X. Serra",
        "Y. Mitsufuji",
        "and D. Bogdanov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T22:06:53+00:00",
          "link": "https://arxiv.org/abs/2506.22661v1",
          "size": "53kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Neural Audio Fingerprint Robustness to Audio Degradation for Music Identification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22661",
        "HTML": "https://arxiv.org/html/2506.22661v1",
        "PDF": "https://arxiv.org/pdf/2506.22661"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22664",
      "abstract": "In this paper, we propose and analyze ETD-Multistep-Pad\\'{e} (ETD-MS-Pad\\'{e}) and ETD Implicit Multistep-Pad\\'{e} (ETD-IMS-Pad\\'{e}) for semilinear parabolic delay differential equations with smooth solutions. In our previous work [15], we proposed ETD-RK-Pad\\'{e} scheme to compute high-order numerical solutions for nonlinear parabolic reaction-diffusion equation with constant time delay. However, the based ETD-RK numerical scheme in [15] is very complex and the corresponding calculation program is also very complicated. We propose in this paper ETD-MS-Pad\\'{e} and ETD-IMS-Pad\\'{e} schemes for the solution of semilinear parabolic equations with delay. We synergize the ETD-MS-Pad\\'{e} with ETD-IMS-Pad\\'{e} to construct efficient predictor-corrector scheme. This new predictor-corrector scheme will become an important tool for solving the numerical solutions of parabolic differential equations. Remarkably, we also conducted experiments in Table$10$ to compare the numerical results of the predictor-corrector scheme with the EERK scheme proposed in paper [42]. The predictor-corrector scheme demonstrated better convergence.\n  The main idea is to employ an ETD-based Adams multistep extrapolation for the time integration of the corresponding equation. To overcome the well-known numerical instability associated with computing the exponential operator, we utilize the Pad\\'{e} approach to approximate this exponential operator. This methodology leads to the development of the ETD-MS-Pad\\'{e} and ETD-IMS-Pad\\'{e} schemes, applicable even for arbitrary time orders. We validate the ETD-MS1,2,3,4-Pad\\'{e} schemes and ETD-IMS2,3,4 schemes through numerical experiments.",
      "authors": [
        "Haishen Dai",
        "Huan Lei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T22:10:13+00:00",
          "link": "https://arxiv.org/abs/2506.22664v1",
          "size": "915kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid Explicit-Implicit Predictor-Corrector Exponential Time-Differencing Multistep Pad\\'{e} Schemes for Semilinear Parabolic Equations with Time-Delay",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22664",
        "HTML": "https://arxiv.org/html/2506.22664v1",
        "PDF": "https://arxiv.org/pdf/2506.22664"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22666",
      "abstract": "The rise of API-only access to state-of-the-art LLMs highlights the need for effective black-box jailbreak methods to identify model vulnerabilities in real-world settings. Without a principled objective for gradient-based optimization, most existing approaches rely on genetic algorithms, which are limited by their initialization and dependence on manually curated prompt pools. Furthermore, these methods require individual optimization for each prompt, failing to provide a comprehensive characterization of model vulnerabilities. To address this gap, we introduce VERA: Variational infErence fRamework for jAilbreaking. VERA casts black-box jailbreak prompting as a variational inference problem, training a small attacker LLM to approximate the target LLM's posterior over adversarial prompts. Once trained, the attacker can generate diverse, fluent jailbreak prompts for a target query without re-optimization. Experimental results show that VERA achieves strong performance across a range of target LLMs, highlighting the value of probabilistic inference for adversarial prompt generation.",
      "authors": [
        "Anamika Lochab",
        "Lu Yan",
        "Patrick Pynadath",
        "Xiangyu Zhang",
        "and Ruqi Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T22:22:00+00:00",
          "link": "https://arxiv.org/abs/2506.22666v1",
          "size": "3937kb",
          "version": "v1"
        }
      ],
      "title": "VERA: Variational Inference Framework for Jailbreaking Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22666",
        "HTML": "https://arxiv.org/html/2506.22666v1",
        "PDF": "https://arxiv.org/pdf/2506.22666"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22668",
      "abstract": "With the growing adoption of graph neural networks (GNNs), explaining their predictions has become increasingly important. However, attributing predictions to specific edges or features remains computationally expensive. For example, classifying a node with 100 neighbors using a 3-layer GNN may involve identifying important edges from millions of candidates contributing to the prediction. To address this challenge, we propose DistShap, a parallel algorithm that distributes Shapley value-based explanations across multiple GPUs. DistShap operates by sampling subgraphs in a distributed setting, executing GNN inference in parallel across GPUs, and solving a distributed least squares problem to compute edge importance scores. DistShap outperforms most existing GNN explanation methods in accuracy and is the first to scale to GNN models with millions of features by using up to 128 GPUs on the NERSC Perlmutter supercomputer.",
      "authors": [
        "Selahattin Akkas",
        "Aditya Devarakonda",
        "Ariful Azad"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T22:30:49+00:00",
          "link": "https://arxiv.org/abs/2506.22668v1",
          "size": "413kb",
          "version": "v1"
        }
      ],
      "title": "DistShap: Scalable GNN Explanations with Distributed Shapley Values",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22668",
        "HTML": "https://arxiv.org/html/2506.22668v1",
        "PDF": "https://arxiv.org/pdf/2506.22668"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22671",
      "abstract": "Cyclic Queuing and Forwarding (CQF) is a Time-Sensitive Networking (TSN) shaping mechanism that provides bounded latency and deterministic Quality of Service (QoS). However, CQF's use of a single cycle restricts its ability to support TSN traffic with diverse timing requirements. Multi-Cyclic Queuing and Forwarding (Multi-CQF) is a new and emerging TSN shaping mechanism that uses multiple cycles on the same egress port, allowing it to accommodate TSN flows with varied timing requirements more effectively than CQF. Despite its potential, current Multi-CQF configuration studies are limited, leading to a lack of comprehensive research, poor understanding of the mechanism, and limited adoption of Multi-CQF in practical applications. Previous work has shown the impact of Time Injection (TI), defined as the start time of Time-Triggered (TT) flows at the source node, on CQF queue resource utilization. However, the impact of TI has not yet been explored in the context of Multi-CQF. This paper introduces a set of constraints and leverages Domain Specific Knowledge (DSK) to reduce the search space for Multi-CQF configuration. Building on this foundation, we develop an open-source Genetic Algorithm (GA) and a hybrid GA-Simulated Annealing (GASA) approach to efficiently configure Multi-CQF networks and introduce TI in Multi-CQF to enhance schedulability. Experimental results show that our proposed algorithms significantly increase the number of scheduled TT flows compared to the baseline Simulated Annealing (SA) model, improving scheduling by an average of 15%. Additionally, GASA achieves a 20% faster convergence rate and lower time complexity, outperforming the SA model in speed, and efficiency.",
      "authors": [
        "Rubi Debnath",
        "Mohammadreza Barzegaran",
        "Sebastian Steinhorst"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T22:53:33+00:00",
          "link": "https://arxiv.org/abs/2506.22671v1",
          "size": "6746kb",
          "version": "v1"
        }
      ],
      "title": "Towards an Optimized Multi-Cyclic Queuing and Forwarding in Time Sensitive Networking with Time Injection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22671",
        "HTML": "https://arxiv.org/html/2506.22671v1",
        "PDF": "https://arxiv.org/pdf/2506.22671"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22674",
      "abstract": "Electric vehicles (EVs) are a promising alternative to fuel vehicles (FVs), given some unique characteristics of EVs, for example, the low air pollution and maintenance cost. However, the increasing prevalence of EVs is accompanied by widespread complaints regarding the high likelihood of motion sickness (MS) induction, especially when compared to FVs, which has become one of the major obstacles to the acceptance and popularity of EVs. Despite the prevalence of such complaints online and among EV users, the association between vehicle type (i.e., EV versus FV) and MS prevalence and severity has not been quantified. Thus, this study aims to investigate the existence of EV-induced MS and explore the potential factors leading to it. A survey study was conducted to collect passengers' MS experience in EVs and FVs in the past one year. In total, 639 valid responses were collected from mainland China. The results show that FVs were associated with a higher frequency of MS, while EVs were found to induce more severe MS symptoms. Further, we found that passengers' MS severity was associated with individual differences (i.e., age, gender, sleep habits, susceptibility to motion-induced MS), in-vehicle activities (i.e., chatting with others and watching in-vehicle displays), and road conditions (i.e., congestion and slope), while the MS frequency was associated with the vehicle ownership and riding frequency. The results from this study can guide the directions of future empirical studies that aim to quantify the inducers of MS in EVs and FVs, as well as the optimization of EVs to reduce MS.",
      "authors": [
        "Weiyin Xie",
        "Chunxi Huang",
        "Jiyao Wang",
        "Dengbo He"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T22:55:55+00:00",
          "link": "https://arxiv.org/abs/2506.22674v1",
          "size": "530kb",
          "version": "v1"
        }
      ],
      "title": "Do Electric Vehicles Induce More Motion Sickness Than Fuel Vehicles? A Survey Study in China",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22674",
        "PDF": "https://arxiv.org/pdf/2506.22674"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22676",
      "abstract": "We present a design through analysis workflow that enables virtual prototyping of electric devices. A CAD plugin establishes the interaction between design and analysis, allowing the preparation of analysis models and the visualization of its results within the design environment. The simulations utilize a fast boundary element method (BEM) that allows for non-conforming and higher-order meshes. Our numerical experiments investigate the accuracy of the approach and its sensitivity to the initial CAD representation. Overall, the workflow enables a close link between design and analysis, where the non-conforming higher-order BEM approach provides accurate results and significantly simplifies the interaction.",
      "authors": [
        "Benjamin Marussig and J\\\"urgen Zechner and Thomas R\\\"uberg and Lars Kielhorn and Domagoj Bo\\v{s}njak and Thomas-Peter Fries"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T23:00:51+00:00",
          "link": "https://arxiv.org/abs/2506.22676v1",
          "size": "5317kb",
          "version": "v1"
        }
      ],
      "title": "CAD-Integrated Electrostatic Boundary Element Simulations with Non-Conforming Higher-Order Meshes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22676",
        "HTML": "https://arxiv.org/html/2506.22676v1",
        "PDF": "https://arxiv.org/pdf/2506.22676"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22677",
      "abstract": "Accurate prediction of protein active site structures remains a central challenge in structural biology, particularly for short and flexible peptide fragments where conventional methods often fail. Here, we present a quantum computing framework specifically developed for utility-level quantum processors to address this problem. Starting from an amino acid sequence, we formulate the structure prediction task as a ground-state energy minimization problem using the Variational Quantum Eigensolver (VQE). Amino acid connectivity is encoded on a tetrahedral lattice model, and structural constraints-including steric, geometric, and chirality terms-are mapped into a problem-specific Hamiltonian expressed as sparse Pauli operators. The optimization is executed via a two-stage architecture separating energy estimation and measurement decoding, allowing noise mitigation under realistic quantum device conditions. We evaluate the framework on 23 randomly selected real protein fragments from the PDBbind dataset, as well as 7 real fragments from proteins with therapeutic potential, and run the experiments on the IBM-Cleveland Clinic quantum processor. Structural predictions are benchmarked against AlphaFold3 (AF3) using identical postprocessing and docking procedures. Our quantum method outperformed AF3 in both RMSD (Root-Mean-Square Deviation) and docking efficacy. This work demonstrates, for the first time, a complete end-to-end pipeline for biologically relevant structure prediction on real quantum hardware, highlighting its engineering feasibility and practical advantage over existing classical and deep learning approaches.",
      "authors": [
        "Yuqi Zhang",
        "Yuxin Yang",
        "William Martin",
        "Kingsten Lin",
        "Zixu Wang",
        "Cheng-Chang Lu",
        "Weiwen Jiang",
        "Ruth Nussinov",
        "Joseph Loscalzo",
        "Qiang Guan",
        "Feixiong Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T23:02:07+00:00",
          "link": "https://arxiv.org/abs/2506.22677v1",
          "size": "6930kb",
          "version": "v1"
        }
      ],
      "title": "Prediction of Protein Three-dimensional Structures via a Hardware-Executable Quantum Computing Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22677",
        "HTML": "https://arxiv.org/html/2506.22677v1",
        "PDF": "https://arxiv.org/pdf/2506.22677"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22678",
      "abstract": "Recent advances in deep learning have significantly transformed the field of 3D shape generation, enabling the synthesis of complex, diverse, and semantically meaningful 3D objects. This survey provides a comprehensive overview of the current state of the art in 3D shape generation, organizing the discussion around three core components: shape representations, generative modeling approaches, and evaluation protocols. We begin by categorizing 3D representations into explicit, implicit, and hybrid setups, highlighting their structural properties, advantages, and limitations. Next, we review a wide range of generation methods, focusing on feedforward architectures. We further summarize commonly used datasets and evaluation metrics that assess fidelity, diversity, and realism of generated shapes. Finally, we identify open challenges and outline future research directions that could drive progress in controllable, efficient, and high-quality 3D shape generation. This survey aims to serve as a valuable reference for researchers and practitioners seeking a structured and in-depth understanding of this rapidly evolving field.",
      "authors": [
        "Nicolas Caytuiro and Ivan Sipiran"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T23:06:06+00:00",
          "link": "https://arxiv.org/abs/2506.22678v1",
          "size": "1597kb",
          "version": "v1"
        }
      ],
      "title": "3D Shape Generation: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22678",
        "HTML": "https://arxiv.org/html/2506.22678v1",
        "PDF": "https://arxiv.org/pdf/2506.22678"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22679",
      "abstract": "We explore the feasibility of large language models (LLMs) in detecting subtle expressions of micro-behaviors in team conversations using transcripts collected during simulated space missions. Specifically, we examine zero-shot classification, fine-tuning, and paraphrase-augmented fine-tuning with encoder-only sequence classification LLMs, as well as few-shot text generation with decoder-only causal language modeling LLMs, to predict the micro-behavior associated with each conversational turn (i.e., dialogue). Our findings indicate that encoder-only LLMs, such as RoBERTa and DistilBERT, struggled to detect underrepresented micro-behaviors, particularly discouraging speech, even with weighted fine-tuning. In contrast, the instruction fine-tuned version of Llama-3.1, a decoder-only LLM, demonstrated superior performance, with the best models achieving macro F1-scores of 44% for 3-way classification and 68% for binary classification. These results have implications for the development of speech technologies aimed at analyzing team communication dynamics and enhancing training interventions in high-stakes environments such as space missions, particularly in scenarios where text is the only accessible data.",
      "authors": [
        "Ankush Raut",
        "Projna Paromita",
        "Sydney Begerowski",
        "Suzanne Bell",
        "Theodora Chaspari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T23:06:24+00:00",
          "link": "https://arxiv.org/abs/2506.22679v1",
          "size": "385kb",
          "version": "v1"
        }
      ],
      "title": "Assessing the feasibility of Large Language Models for detecting micro-behaviors in team interactions during space missions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22679",
        "HTML": "https://arxiv.org/html/2506.22679v1",
        "PDF": "https://arxiv.org/pdf/2506.22679"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22685",
      "abstract": "In this paper, we investigate the semantic collapsing problem in generative personalization, an under-explored topic where the learned visual concept ($V^*$) gradually shifts from its original textual meaning and comes to dominate other concepts in multi-concept input prompts. This issue not only reduces the semantic richness of complex input prompts like \"a photo of $V^*$ wearing glasses and playing guitar\" into simpler, less contextually rich forms such as \"a photo of $V^*$\" but also leads to simplified output images that fail to capture the intended concept.\n  We identify the root cause as unconstrained optimisation, which allows the learned embedding $V^*$ to drift arbitrarily in the embedding space, both in direction and magnitude. To address this, we propose a simple yet effective training-free method that adjusts the magnitude and direction of pre-trained embedding at inference time, effectively mitigating the semantic collapsing problem. Our method is broadly applicable across different personalization methods and demonstrates significant improvements in text-image alignment in diverse use cases. Our code is anonymously published at https://anonymous.4open.science/r/Embedding-Adjustment.",
      "authors": [
        "Anh Bui",
        "Trang Vu",
        "Trung Le",
        "Junae Kim",
        "Tamas Abraham",
        "Rollin Omari",
        "Amar Kaur",
        "Dinh Phung"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T23:40:27+00:00",
          "link": "https://arxiv.org/abs/2506.22685v1",
          "size": "15340kb",
          "version": "v1"
        }
      ],
      "title": "Mitigating Semantic Collapse in Generative Personalization with a Surprisingly Simple Test-Time Embedding Adjustment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22685",
        "HTML": "https://arxiv.org/html/2506.22685v1",
        "PDF": "https://arxiv.org/pdf/2506.22685"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22687",
      "abstract": "Boolean circuits abstract away from physical details to focus on the logical structure and computational behaviour of digital components. Despite they have been studied for many decades, compositionality has been widely ignored or examined in an informal manner, which is a property for combining circuits without delving into their internal structure, while supporting modularity and formal reasoning. In this paper, we address this longstanding theoretical gap by proposing colimit-based operators for compositional circuit construction. We define separate operators for forming sequential, parallel, branchial and iterative circuits. As composites encapsulate explicit control flow, a new model of computation emerges which we refer to as (families of) control-driven Boolean circuits. We show how this model is at least as powerful as its classical counterpart. In other words, it is able to non-uniformly compute any Boolean function on inputs of arbitrary length.",
      "authors": [
        "Damian Arellanes"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T23:46:14+00:00",
          "link": "https://arxiv.org/abs/2506.22687v1",
          "size": "44kb",
          "version": "v1"
        }
      ],
      "title": "Compositional Control-Driven Boolean Circuits",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22687",
        "PDF": "https://arxiv.org/pdf/2506.22687"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22688",
      "abstract": "Designing effective software architectures is a complex, iterative process that traditionally relies on expert judgment. This paper proposes an approach for Large Language Model (LLM)-assisted software architecture design using the Attribute-Driven Design (ADD) method. By providing an LLM with an explicit description of ADD, an architect persona, and a structured iteration plan, our method guides the LLM to collaboratively produce architecture artifacts with a human architect. We validate the approach through case studies, comparing generated designs against proven solutions and evaluating them with professional architects. Results show that our LLM-assisted ADD process can generate architectures closely aligned with established solutions and partially satisfying architectural drivers, highlighting both the promise and current limitations of using LLMs in architecture design. Our findings emphasize the importance of human oversight and iterative refinement when leveraging LLMs in this domain.",
      "authors": [
        "Humberto Cervantes",
        "Rick Kazman and Yuanfang Cai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T23:58:15+00:00",
          "link": "https://arxiv.org/abs/2506.22688v1",
          "size": "837kb",
          "version": "v1"
        }
      ],
      "title": "An LLM-assisted approach to designing software architectures using ADD",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22688",
        "PDF": "https://arxiv.org/pdf/2506.22688"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22689",
      "abstract": "Lasso regression is a widely employed approach within the $\\ell_1$ regularization framework used to promote sparsity and recover piecewise smooth signals $f:[a,b) \\rightarrow \\mathbb{R}$ when the given observations are obtained from noisy, blurred, and/or incomplete data environments. In choosing the regularizing sparsity-promoting operator, it is assumed that the particular type of variability of the underlying signal, for example, piecewise constant or piecewise linear behavior across the entire domain, is both known and fixed. Such an assumption is problematic in more general cases, e.g.~when a signal exhibits piecewise oscillatory behavior with varying wavelengths and magnitudes. To address the limitations of assuming a fixed (and typically low order) variability when choosing a sparsity-promoting operator, this investigation proposes a novel residual transform operator that can be used within the Lasso regression formulation. In a nutshell, the idea is that for a general piecewise smooth signal $f$, it is possible to design two operators $\\mathcal L_1$ and $\\mathcal L_2$ such that $\\mathcal L_1{\\boldsymbol f} \\approx \\mathcal L_2{\\boldsymbol f}$, where ${\\boldsymbol f} \\in \\mathbb{R}^n$ is a discretized approximation of $f$, but $\\mathcal L_1 \\not\\approx \\mathcal L_2$. The corresponding residual transform operator, $\\mathcal L = \\mathcal L_1- \\mathcal L_2$, yields a result that (1) effectively reduces the variability dependent error that occurs when applying either $\\mathcal L_1$ or $\\mathcal L_2$ to ${\\boldsymbol f}$, a property that holds even when $\\mathcal L_1{\\boldsymbol f} \\approx \\mathcal L_2{\\boldsymbol f}$ is not a good approximation to the true sparse domain vector of ${\\boldsymbol f}$, and (2) does not require $\\mathcal L_1$ or $\\mathcal L_2$ to have prior information regarding the variability of the underlying signal.",
      "authors": [
        "Yao Xiao",
        "Anne Gelb",
        "Aditya Viswanathan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T00:02:41+00:00",
          "link": "https://arxiv.org/abs/2506.22689v1",
          "size": "436kb",
          "version": "v1"
        }
      ],
      "title": "A new sparsity promoting residual transform operator for Lasso regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22689",
        "HTML": "https://arxiv.org/html/2506.22689v1",
        "PDF": "https://arxiv.org/pdf/2506.22689"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22694",
      "abstract": "In this paper, we introduce a simple training-free technique to improve the performance of drafter-based speculative decoding (SpD) methods that incorporates language modeling head (LM head) during drafting process. A drafter-based speculative decoding leverages one or more smaller language models, a.k.a. drafters or draft models, to sample a draft sequence or tree consisting of multiple tokens, followed by verification by a base LLM, a target model, accepting a subset as its valid generation. As it is usually considered that the speculative decoding requires one-to-one mapping between vocabularies of the target model and the draft model, it has been natural to share the vocabulary between them, or even share the LM head as in EAGLE or Medusa. We first identify that this draft token sampling scheme inherently contains an unnecessary inference overhead in drafting, especially for some target LLMs with very large vocabularies. Then, we propose a simple technique, VocabTrim, to mitigate the drafting overhead to improve the generation speed in memory-bound environment. VocabTrim reconstructs the drafter LM head to contain only a limited set of tokens, selected by the most frequently sampled from the vocabulary of the target model. While limiting the vocabulary in drafting slightly degrades the acceptance rate, it significantly reduces the drafting latency in memory-bound process which is often the case on edge devices, resulting in higher memory-bound speed up (MBSU). We show that our method can boost the memory-bound speed-up for Llama-3 models on Spec-Bench, specifically by 16% for Llama-3.2-3B-Instruct.",
      "authors": [
        "Raghavv Goel",
        "Sudhanshu Agrawal",
        "Mukul Gagrani",
        "Junyoung Park",
        "Yifan Zao",
        "He Zhang",
        "Tian Liu",
        "Yiping Yang",
        "Xin Yuan",
        "Jiuyan Lu",
        "Chris Lott",
        "Mingu Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T00:26:40+00:00",
          "link": "https://arxiv.org/abs/2506.22694v1",
          "size": "491kb",
          "version": "v1"
        }
      ],
      "title": "VOCABTRIM: Vocabulary Pruning for Efficient Speculative Decoding in LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22694",
        "HTML": "https://arxiv.org/html/2506.22694v1",
        "PDF": "https://arxiv.org/pdf/2506.22694"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22696",
      "abstract": "The residual stream acts as a memory bus where transformer layers both store and access features (Elhage et al., 2021). We consider changing the mechanism for retrieving and storing information in the residual stream, and replace the residual stream of the transformer with an outer product memory matrix (Kohonen, 1972, Anderson, 1972). We call this model the Residual Matrix Transformer (RMT). We find that the RMT enjoys a number of attractive properties: 1) the size of the residual stream can be scaled independently of compute and model size, improving performance, 2) the RMT can achieve the same loss as the transformer with 58% fewer FLOPS, 25% fewer parameters, and 41% fewer training tokens tokens, and 3) the RMT outperforms the transformer on downstream evaluations. We theoretically analyze the transformer and the RMT, and show that the RMT allows for more efficient scaling of the residual stream, as well as improved variance propagation properties. Code for this project can be found at https://github.com/bmac3/residual-matrix-transformer.",
      "authors": [
        "Brian Mak and Jeffrey Flanigan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T00:29:42+00:00",
          "link": "https://arxiv.org/abs/2506.22696v1",
          "size": "1897kb",
          "version": "v1"
        }
      ],
      "title": "Residual Matrix Transformers: Scaling the Size of the Residual Stream",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22696",
        "HTML": "https://arxiv.org/html/2506.22696v1",
        "PDF": "https://arxiv.org/pdf/2506.22696"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22698",
      "abstract": "This report synthesizes the outcomes of a recent interdisciplinary workshop that brought together leading experts in cognitive psychology, language learning, and artificial intelligence (AI)-based natural language processing (NLP). The workshop, funded by the National Science Foundation, aimed to address a critical knowledge gap in our understanding of the relationship between AI language models and human cognitive processes in text comprehension and composition. Through collaborative dialogue across cognitive, linguistic, and technological perspectives, workshop participants examined the underlying processes involved when humans produce and comprehend text, and how AI can both inform our understanding of these processes and augment human capabilities. The workshop revealed emerging patterns in the relationship between large language models (LLMs) and human cognition, with highlights on both the capabilities of LLMs and their limitations in fully replicating human-like language understanding and generation. Key findings include the potential of LLMs to offer insights into human language processing, the increasing alignment between LLM behavior and human language processing when models are fine-tuned with human feedback, and the opportunities and challenges presented by human-AI collaboration in language tasks. By synthesizing these findings, this report aims to guide future research, development, and implementation of LLMs in cognitive psychology, linguistics, and education. It emphasizes the importance of ethical considerations and responsible use of AI technologies while striving to enhance human capabilities in text comprehension and production through effective human-AI collaboration.",
      "authors": [
        "Emily Dux Speltz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T00:31:14+00:00",
          "link": "https://arxiv.org/abs/2506.22698v1",
          "size": "2331kb",
          "version": "v1"
        }
      ],
      "title": "Text Production and Comprehension by Human and Artificial Intelligence: Interdisciplinary Workshop Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22698",
        "PDF": "https://arxiv.org/pdf/2506.22698"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22702",
      "abstract": "Aiming at simplifying the hardware structure and reducing the energy consumption in wireless communication via reconfigurable intelligent surfaces (RIS), this paper introduces a novel RIS design founded on the correlation between the phase shift values of the surface elements. First, a correlation analysis is conducted, considering the azimuth angle of a target device within a coverage region spanning from $-80^{\\circ}$ to $80^{\\circ}$. The correlation is demonstrated for different deployment cases, creating the basis for the new RIS structure, termed Connected-RIS, where correlated elements are designed to share the same control signal. The fundamental performance of the proposed design is then analyzed in terms of control signals, power consumption, and communication system performance, comparing it to two RIS structures with full control: one with the same size as the proposed design, and the other employing the minimum number of elements necessary to satisfy the fair coverage criterion. The correlation-based RIS design enables three-dimensional passive beamforming and significantly reduces the number of required load impedances and control signals, thereby lowering the hardware cost and simplifying the control circuitry. It also achieves substantial power savings as compared to the baseline schemes, while maintaining sufficient gain for a fair radio coverage. For instance, numerical simulations demonstrate that the proposed design reduces the power consumption by almost 86-92\\% and the control signals by 83-98\\% compared to operation with fully controlled RIS.",
      "authors": [
        "Zina Mohamed",
        "Ammar B. Kouki",
        "and Sonia A\\\"issa"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Hardware Architecture (cs.AR)",
        "Systems and Control (cs.SY)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T00:56:42+00:00",
          "link": "https://arxiv.org/abs/2506.22702v1",
          "size": "1386kb",
          "version": "v1"
        }
      ],
      "title": "A Correlation-Based Design of RIS for Reduced Power Consumption and Simplified Control Circuitry",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22702",
        "HTML": "https://arxiv.org/html/2506.22702v1",
        "PDF": "https://arxiv.org/pdf/2506.22702"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22703",
      "abstract": "We present P4OMP, a retrieval-augmented framework for transforming serial C/C++ code into OpenMP-annotated parallel code using large language models (LLMs). To our knowledge, this is the first system to apply retrieval-based prompting for OpenMP pragma correctness without model fine-tuning or compiler instrumentation. P4OMP leverages Retrieval-Augmented Generation (RAG) with structured instructional knowledge from OpenMP tutorials to improve the reliability of prompt-driven code generation. By grounding generation in the retrieved context, P4OMP improves syntactic correctness compared to baseline prompting with GPT-3.5-Turbo. We evaluate P4OMP against a baseline, GPT-3.5-Turbo without retrieval, on a comprehensive benchmark of 108 real-world C++ programs drawn from Stack Overflow, PolyBench, and NAS benchmark suites. P4OMP achieves 100% compilation success on all parallelizable cases, while the baseline fails to compile in 20 out of 108 cases. Six cases that rely on non-random-access iterators or thread-unsafe constructs are excluded due to fundamental OpenMP limitations. A detailed analysis demonstrates how P4OMP consistently avoids scoping errors, syntactic misuse, and invalid directive combinations that commonly affect baseline-generated code. We further demonstrate strong runtime scaling across seven compute-intensive benchmarks on an HPC cluster. P4OMP offers a robust, modular pipeline that significantly improves the reliability and applicability of LLM-generated OpenMP code.",
      "authors": [
        "Wali Mohammad Abdullah",
        "Azmain Kabir"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T01:06:34+00:00",
          "link": "https://arxiv.org/abs/2506.22703v1",
          "size": "644kb",
          "version": "v1"
        }
      ],
      "title": "P4OMP: Retrieval-Augmented Prompting for OpenMP Parallelism in Serial Code",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22703",
        "HTML": "https://arxiv.org/html/2506.22703v1",
        "PDF": "https://arxiv.org/pdf/2506.22703"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22706",
      "abstract": "In the face of evolving cyber threats such as malware, ransomware and phishing, autonomous cybersecurity defense (ACD) systems have become essential for real-time threat detection and response with optional human intervention. However, existing ACD systems rely on limiting assumptions, particularly the stationarity of the underlying network dynamics. In real-world scenarios, network topologies can change due to actions taken by attackers or defenders, system failures, or time evolution of networks, leading to failures in the adaptive capabilities of current defense agents. Moreover, many agents are trained on static environments, resulting in overfitting to specific topologies, which hampers their ability to generalize to out-of-distribution network topologies. This work addresses these challenges by exploring methods for developing agents to learn generalizable policies across dynamic network environments -- general ACD (GACD).",
      "authors": [
        "Arun Ramamurthy and Neil Dhir"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T01:12:13+00:00",
          "link": "https://arxiv.org/abs/2506.22706v1",
          "size": "233kb",
          "version": "v1"
        }
      ],
      "title": "General Autonomous Cybersecurity Defense: Learning Robust Policies for Dynamic Topologies and Diverse Attackers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22706",
        "PDF": "https://arxiv.org/pdf/2506.22706"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22707",
      "abstract": "Traditional von Neumann architectures suffer from fundamental bottlenecks due to continuous data movement between memory and processing units, a challenge that worsens with technology scaling as electrical interconnect delays become more significant. These limitations impede the performance and energy efficiency required for modern data-intensive applications. In contrast, photonic in-memory computing presents a promising alternative by harnessing the advantages of light, enabling ultra-fast data propagation without length-dependent impedance, thereby significantly reducing computational latency and energy consumption. This work proposes a novel differential photonic static random access memory (pSRAM) bitcell that facilitates electro-optic data storage while enabling ultra-fast in-memory Boolean XOR computation. By employing cross-coupled microring resonators and differential photodiodes, the XOR-augmented pSRAM (X-pSRAM) bitcell achieves at least 10 GHz read, write, and compute operations entirely in the optical domain. Additionally, wavelength-division multiplexing (WDM) enables n-bit XOR computation in a single-shot operation, supporting massively parallel processing and enhanced computational efficiency. Validated on GlobalFoundries' 45SPCLO node, the X-pSRAM consumed 13.2 fJ energy per bit for XOR computation, representing a significant advancement toward next-generation optical computing with applications in cryptography, hyperdimensional computing, and neural networks.",
      "authors": [
        "Md Abdullah-Al Kaiser",
        "Sugeet Sunder",
        "Ajey P. Jacob",
        "and Akhilesh R. Jaiswal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T01:17:04+00:00",
          "link": "https://arxiv.org/abs/2506.22707v1",
          "size": "1665kb",
          "version": "v1"
        }
      ],
      "title": "X-pSRAM: A Photonic SRAM with Embedded XOR Logic for Ultra-Fast In-Memory Computing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22707",
        "HTML": "https://arxiv.org/html/2506.22707v1",
        "PDF": "https://arxiv.org/pdf/2506.22707"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22708",
      "abstract": "Peer-to-peer (P2P) trading is increasingly recognized as a key mechanism for decentralized market regulation, yet existing approaches often lack robust frameworks to ensure fairness. This paper presents FairMarket-RL, a novel hybrid framework that combines Large Language Models (LLMs) with Reinforcement Learning (RL) to enable fairness-aware trading agents. In a simulated P2P microgrid with multiple sellers and buyers, the LLM acts as a real-time fairness critic, evaluating each trading episode using two metrics: Fairness-To-Buyer (FTB) and Fairness-Between-Sellers (FBS). These fairness scores are integrated into agent rewards through scheduled {\\lambda}-coefficients, forming an adaptive LLM-guided reward shaping loop that replaces brittle, rule-based fairness constraints. Agents are trained using Independent Proximal Policy Optimization (IPPO) and achieve equitable outcomes, fulfilling over 90% of buyer demand, maintaining fair seller margins, and consistently reaching FTB and FBS scores above 0.80. The training process demonstrates that fairness feedback improves convergence, reduces buyer shortfalls, and narrows profit disparities between sellers. With its language-based critic, the framework scales naturally, and its extension to a large power distribution system with household prosumers illustrates its practical applicability. FairMarket-RL thus offers a scalable, equity-driven solution for autonomous trading in decentralized energy systems.",
      "authors": [
        "Shrenik Jadhav",
        "Birva Sevak",
        "Srijita Das",
        "Akhtar Hussain",
        "Wencong Su",
        "Van-Hai Bui"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "General Economics (econ.GN)",
        "Systems and Control (eess.SY)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T01:17:55+00:00",
          "link": "https://arxiv.org/abs/2506.22708v1",
          "size": "502kb",
          "version": "v1"
        }
      ],
      "title": "FairMarket-RL: LLM-Guided Fairness Shaping for Multi-Agent Reinforcement Learning in Peer-to-Peer Markets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22708",
        "PDF": "https://arxiv.org/pdf/2506.22708"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22710",
      "abstract": "Implicit degradation estimation-based blind super-resolution (IDE-BSR) hinges on extracting the implicit degradation representation (IDR) of the LR image and adapting it to LR image features to guide HR detail restoration. Although IDE-BSR has shown potential in dealing with noise interference and complex degradations, existing methods ignore the importance of IDR discriminability for BSR and instead over-complicate the adaptation process to improve effect, resulting in a significant increase in the model's parameters and computations. In this paper, we focus on the discriminability optimization of IDR and propose a new powerful and lightweight BSR model termed LightBSR. Specifically, we employ a knowledge distillation-based learning framework. We first introduce a well-designed degradation-prior-constrained contrastive learning technique during teacher stage to make the model more focused on distinguishing different degradation types. Then we utilize a feature alignment technique to transfer the degradation-related knowledge acquired by the teacher to the student for practical inferencing. Extensive experiments demonstrate the effectiveness of IDR discriminability-driven BSR model design. The proposed LightBSR can achieve outstanding performance with minimal complexity across a range of blind SR tasks. Our code is accessible at: https://github.com/MJ-NCEPU/LightBSR.",
      "authors": [
        "Jiang Yuan",
        "JI Ma",
        "Bo Wang",
        "Guanzhou Ke",
        "Weiming Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T01:24:10+00:00",
          "link": "https://arxiv.org/abs/2506.22710v1",
          "size": "11702kb",
          "version": "v1"
        }
      ],
      "title": "LightBSR: Towards Lightweight Blind Super-Resolution via Discriminative Implicit Degradation Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22710",
        "HTML": "https://arxiv.org/html/2506.22710v1",
        "PDF": "https://arxiv.org/pdf/2506.22710"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22712",
      "abstract": "Understanding the geometry of neural network loss landscapes is a central question in deep learning, with implications for generalization and optimization. A striking phenomenon is linear mode connectivity (LMC), where independently trained models can be connected by low- or zero-loss paths, despite appearing to lie in separate loss basins. However, this is often obscured by symmetries in parameter space -- such as neuron permutations -- which make functionally equivalent models appear dissimilar. Prior work has predominantly focused on neuron re-ordering through permutations, but such approaches are limited in scope and fail to capture the richer symmetries exhibited by modern architectures such as Transformers. In this work, we introduce a unified framework that captures four symmetry classes: permutations, semi-permutations, orthogonal transformations, and general invertible maps -- broadening the set of valid reparameterizations and subsuming many previous approaches as special cases. Crucially, this generalization enables, for the first time, the discovery of low- and zero-barrier linear interpolation paths between independently trained Vision Transformers and GPT-2 models. These results reveal deeper structure in the loss landscape and underscore the importance of symmetry-aware analysis for understanding model space geometry.",
      "authors": [
        "Alexander Theus",
        "Alessandro Cabodi",
        "Sotiris Anagnostidis",
        "Antonio Orvieto",
        "Sidak Pal Singh",
        "and Valentina Boeva"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T01:46:36+00:00",
          "link": "https://arxiv.org/abs/2506.22712v1",
          "size": "503kb",
          "version": "v1"
        }
      ],
      "title": "Generalized Linear Mode Connectivity for Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22712",
        "HTML": "https://arxiv.org/html/2506.22712v1",
        "PDF": "https://arxiv.org/pdf/2506.22712"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22713",
      "abstract": "Low-rank matrix approximation plays an important role in various applications such as image processing, signal processing and data analysis. The existing methods require a guess of the ranks of matrices that represent images or involve additional costs to determine the ranks. A novel efficient orthogonal decomposition with automatic basis extraction (EOD-ABE) is proposed to compute the optimal low-rank matrix approximation with adaptive identification of the optimal rank. By introducing a randomized basis extraction mechanism, EOD-ABE eliminates the need for additional rank determination steps and can compute a rank-revealing approximation to a low-rank matrix. With a computational complexity of $O(mnr)$, where $m$ and $n$ are the dimensions of the matrix and $r$ is its rank, EOD-ABE achieves significant speedups compared to the state-of-the-art methods. Experimental results demonstrate the superior speed, accuracy and robustness of EOD-ABE and indicate that EOD-ABE is a powerful tool for fast image compression and reconstruction and hyperspectral image dimensionality reduction in large-scale applications.",
      "authors": [
        "Weiwei Xu",
        "Weijie Shen",
        "Chang Liu and Zhigang Jia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T01:48:42+00:00",
          "link": "https://arxiv.org/abs/2506.22713v1",
          "size": "4878kb",
          "version": "v1"
        }
      ],
      "title": "A Novel Adaptive Low-Rank Matrix Approximation Method for Image Compression and Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22713",
        "HTML": "https://arxiv.org/html/2506.22713v1",
        "PDF": "https://arxiv.org/pdf/2506.22713"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22714",
      "abstract": "Sparse matrix multiplication operators (i.e., SpMM and SDDMM) are widely used in deep learning and scientific computing. Modern accelerators are commonly equipped with Tensor cores and CUDA cores to accelerate sparse operators. The former brings superior computing power but only for structured matrix multiplication, while the latter has relatively lower performance but with higher programming flexibility. In this work, we discover that utilizing one resource alone leads to inferior performance for sparse matrix multiplication, due to their respective limitations. To this end, we propose Libra, a systematic approach that enables synergistic computation between CUDA and Tensor cores to achieve the best performance for sparse matrix multiplication. Specifically, we propose a 2D-aware workload distribution strategy to find out the sweet point of task mapping for different sparse operators, leveraging both the high performance of Tensor cores and the low computational redundancy on CUDA cores. In addition, Libra incorporates systematic optimizations for heterogeneous computing, including hybrid load-balancing, finely optimized kernel implementations, and GPU-accelerated preprocessing. Extensive experimental results on H100 and RTX 4090 GPUs show that Libra outperforms the state-of-the-art by on average 3.1x (up to 9.23x) over DTC-SpMM and 2.9x (up to 3.9x) for end-to-end GNN applications. Libra opens up a new perspective for sparse operator acceleration by fully exploiting the heterogeneous computing resources on GPUs.",
      "authors": [
        "Jinliang Shi",
        "Shigang Li",
        "Youxuan Xu",
        "Xueying Wang",
        "Rongtian Fu",
        "Zhi Ma",
        "Tong Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T01:50:13+00:00",
          "link": "https://arxiv.org/abs/2506.22714v1",
          "size": "4081kb",
          "version": "v1"
        }
      ],
      "title": "Libra: Synergizing CUDA and Tensor Cores for High-Performance Sparse Matrix Multiplication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22714",
        "HTML": "https://arxiv.org/html/2506.22714v1",
        "PDF": "https://arxiv.org/pdf/2506.22714"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22716",
      "abstract": "Large language models (LLMs) are powerful tools but are often expensive to deploy at scale. LLM query routing mitigates this by dynamically assigning queries to models of varying cost and quality to obtain a desired trade-off. Prior query routing approaches generate only one response from the selected model and a single response from a small (inexpensive) model was often not good enough to beat a response from a large (expensive) model due to which they end up overusing the large model and missing out on potential cost savings. However, it is well known that for small models, generating multiple responses and selecting the best can enhance quality while remaining cheaper than a single large-model response. We leverage this idea to propose BEST-Route, a novel routing framework that chooses a model and the number of responses to sample from it based on query difficulty and the quality thresholds. Experiments on real-world datasets demonstrate that our method reduces costs by up to 60% with less than 1% performance drop.",
      "authors": [
        "Dujian Ding",
        "Ankur Mallick",
        "Shaokun Zhang",
        "Chi Wang",
        "Daniel Madrigal",
        "Mirian Del Carmen Hipolito Garcia",
        "Menglin Xia",
        "Laks V.S. Lakshmanan",
        "Qingyun Wu",
        "Victor R\\\"uhle"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T01:52:50+00:00",
          "link": "https://arxiv.org/abs/2506.22716v1",
          "size": "258kb",
          "version": "v1"
        }
      ],
      "title": "BEST-Route: Adaptive LLM Routing with Test-Time Optimal Compute",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22716",
        "HTML": "https://arxiv.org/html/2506.22716v1",
        "PDF": "https://arxiv.org/pdf/2506.22716"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22718",
      "abstract": "Part segmentation and motion estimation are two fundamental problems for articulated object motion analysis. In this paper, we present a method to solve these two problems jointly from a sequence of observed point clouds of a single articulated object. The main challenge in our problem setting is that the point clouds are not assumed to be generated by a fixed set of moving points. Instead, each point cloud in the sequence could be an arbitrary sampling of the object surface at that particular time step. Such scenarios occur when the object undergoes major occlusions, or if the dataset is collected using measurements from multiple sensors asynchronously. In these scenarios, methods that rely on tracking point correspondences are not appropriate. We present an alternative approach based on a compact but effective representation where we represent the object as a collection of simple building blocks modeled as 3D Gaussians. We parameterize the Gaussians with time-dependent rotations, translations, and scales that are shared across all time steps. With our representation, part segmentation can be achieved by building correspondences between the observed points and the Gaussians. Moreover, the transformation of each point across time can be obtained by following the poses of the assigned Gaussian (even when the point is not observed). Experiments show that our method outperforms existing methods that solely rely on finding point correspondences. Additionally, we extend existing datasets to emulate real-world scenarios by considering viewpoint occlusions. We further demonstrate that our method is more robust to missing points as compared to existing approaches on these challenging datasets, even when some parts are completely occluded in some time-steps. Notably, our part segmentation performance outperforms the state-of-the-art method by 13% on point clouds with occlusions.",
      "authors": [
        "Jun-Jee Chao",
        "Qingyuan Jiang",
        "Volkan Isler"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T01:56:35+00:00",
          "link": "https://arxiv.org/abs/2506.22718v1",
          "size": "3494kb",
          "version": "v1"
        }
      ],
      "title": "Part Segmentation and Motion Estimation for Articulated Objects with Dynamic 3D Gaussians",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22718",
        "HTML": "https://arxiv.org/html/2506.22718v1",
        "PDF": "https://arxiv.org/pdf/2506.22718"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22720",
      "abstract": "6D pose confidence region estimation has emerged as a critical direction, aiming to perform uncertainty quantification for assessing the reliability of estimated poses. However, current sampling-based approach suffers from critical limitations that severely impede their practical deployment: 1) the sampling speed significantly decreases as the number of samples increases. 2) the derived confidence regions are often excessively large. To address these challenges, we propose a deterministic and efficient method for estimating pose confidence regions. Our approach uses inductive conformal prediction to calibrate the deterministically regressed Gaussian keypoint distributions into 2D keypoint confidence regions. We then leverage the implicit function theorem to propagate these keypoint confidence regions directly into 6D pose confidence regions. This method avoids the inefficiency and inflated region sizes associated with sampling and ensembling. It provides compact confidence regions that cover the ground-truth poses with a user-defined confidence level. Experimental results on the LineMOD Occlusion and SPEED datasets show that our method achieves higher pose estimation accuracy with reduced computational time. For the same coverage rate, our method yields significantly smaller confidence region volumes, reducing them by up to 99.9\\% for rotations and 99.8\\% for translations. The code will be available soon.",
      "authors": [
        "Jinghao Wang",
        "Zhang Li",
        "Zi Wang",
        "Banglei Guan",
        "Yang Shang",
        "Qifeng Yu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T02:03:34+00:00",
          "link": "https://arxiv.org/abs/2506.22720v1",
          "size": "10156kb",
          "version": "v1"
        }
      ],
      "title": "Deterministic Object Pose Confidence Region Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22720",
        "HTML": "https://arxiv.org/html/2506.22720v1",
        "PDF": "https://arxiv.org/pdf/2506.22720"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22722",
      "abstract": "The proposed UniGuard is the first unified online detection framework capable of simultaneously addressing adversarial examples and backdoor attacks. UniGuard builds upon two key insights: first, both AE and backdoor attacks have to compromise the inference phase, making it possible to tackle them simultaneously during run-time via online detection. Second, an adversarial input, whether a perturbed sample in AE attacks or a trigger-carrying sample in backdoor attacks, exhibits distinctive trajectory signatures from a benign sample as it propagates through the layers of a DL model in forward inference. The propagation trajectory of the adversarial sample must deviate from that of its benign counterpart; otherwise, the adversarial objective cannot be fulfilled. Detecting these trajectory signatures is inherently challenging due to their subtlety; UniGuard overcomes this by treating the propagation trajectory as a time-series signal, leveraging LSTM and spectrum transformation to amplify differences between adversarial and benign trajectories that are subtle in the time domain. UniGuard exceptional efficiency and effectiveness have been extensively validated across various modalities (image, text, and audio) and tasks (classification and regression), ranging from diverse model architectures against a wide range of AE attacks and backdoor attacks, including challenging partial backdoors and dynamic triggers. When compared to SOTA methods, including ContraNet (NDSS 22) specific for AE detection and TED (IEEE SP 24) specific for backdoor detection, UniGuard consistently demonstrates superior performance, even when matched against each method's strengths in addressing their respective threats-each SOTA fails to parts of attack strategies while UniGuard succeeds for all.",
      "authors": [
        "Anmin Fu",
        "Fanyu Meng",
        "Huaibing Peng",
        "Hua Ma",
        "Zhi Zhang",
        "Yifeng Zheng",
        "Willy Susilo",
        "Yansong Gao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T02:06:23+00:00",
          "link": "https://arxiv.org/abs/2506.22722v1",
          "size": "1562kb",
          "version": "v1"
        }
      ],
      "title": "Kill Two Birds with One Stone! Trajectory enabled Unified Online Detection of Adversarial Examples and Backdoor Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22722",
        "HTML": "https://arxiv.org/html/2506.22722v1",
        "PDF": "https://arxiv.org/pdf/2506.22722"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22724",
      "abstract": "Multilingual generation with large language models (LLMs) is often of poor quality for mid- to low-resource languages. Building on insights from interpretability, we demonstrate the existence of an implicit task-solving-->translation pipeline for generation, whereby the model first solves the required task in a largely target-language-agnostic manner, and subsequently translates answer concepts into the intended target language. We hypothesize that the failure of the translation stage is an important culprit for the observed low quality of final outputs, and formalize this as the translation barrier hypothesis. We test this hypothesis for a word translation task across 108 language pairs, using logit lens to observe model processing in intermediate layers. We find that a significant portion of overall failures indeed stems from translation failure, or the model's inability to translate correctly solved intermediate concepts into the target language. This is especially true for low-resource target languages. Our results highlight an important hurdle for end-to-end multilingual generation, and lend guiding insights for future work seeking to improve multilinguality in LLMs.",
      "authors": [
        "Niyati Bafna",
        "Tianjian Li",
        "Kenton Murray",
        "David R. Mortensen",
        "David Yarowsky",
        "Hale Sirin",
        "Daniel Khashabi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T02:09:21+00:00",
          "link": "https://arxiv.org/abs/2506.22724v1",
          "size": "570kb",
          "version": "v1"
        }
      ],
      "title": "The Translation Barrier Hypothesis: Multilingual Generation with Large Language Models Suffers from Implicit Translation Failure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22724",
        "HTML": "https://arxiv.org/html/2506.22724v1",
        "PDF": "https://arxiv.org/pdf/2506.22724"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22726",
      "abstract": "Deep learning for human sensing on edge systems offers significant opportunities for smart applications. However, its training and development are hindered by the limited availability of sensor data and resource constraints of edge systems. Current methods that rely on transferring pre-trained models often encounter issues such as modality shift and high resource demands, resulting in substantial accuracy loss, resource overhead, and poor adaptability across different sensing applications. In this paper, we propose XTransfer, a first-of-its-kind method for resource-efficient, modality-agnostic model transfer. XTransfer freely leverages single or multiple pre-trained models and transfers knowledge across different modalities by (i) model repairing that safely repairs modality shift in pre-trained model layers with only few sensor data, and (ii) layer recombining that efficiently searches and recombines layers of interest from source models in a layer-wise manner to create compact models. We benchmark various baselines across diverse human sensing datasets spanning different modalities. Comprehensive results demonstrate that XTransfer achieves state-of-the-art performance on human sensing tasks while significantly reducing the costs of sensor data collection, model training, and edge deployment.",
      "authors": [
        "Yu Zhang",
        "Xi Zhang",
        "Hualin zhou",
        "Xinyuan Chen",
        "Shang Gao",
        "Hong Jia",
        "Jianfei Yang",
        "Yuankai Qi",
        "Tao Gu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T02:14:43+00:00",
          "link": "https://arxiv.org/abs/2506.22726v1",
          "size": "2965kb",
          "version": "v1"
        }
      ],
      "title": "XTransfer: Cross-Modality Model Transfer for Human Sensing with Few Data at the Edge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22726",
        "HTML": "https://arxiv.org/html/2506.22726v1",
        "PDF": "https://arxiv.org/pdf/2506.22726"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22727",
      "abstract": "Differential privacy (DP) has been integrated into graph neural networks (GNNs) to protect sensitive structural information, e.g., edges, nodes, and associated features across various applications. A common approach is to perturb the message-passing process, which forms the core of most GNN architectures. However, existing methods typically incur a privacy cost that grows linearly with the number of layers (Usenix Security'23), ultimately requiring excessive noise to maintain a reasonable privacy level. This limitation becomes particularly problematic when deep GNNs are necessary to capture complex and long-range interactions in graphs. In this paper, we theoretically establish that the privacy budget can converge with respect to the number of layers by applying privacy amplification techniques to the message-passing process, exploiting the contractive properties inherent to standard GNN operations. Motivated by this analysis, we propose a simple yet effective Contractive Graph Layer (CGL) that ensures the contractiveness required for theoretical guarantees while preserving model utility. Our framework, CARIBOU, supports both training and inference, equipped with a contractive aggregation module, a privacy allocation module, and a privacy auditing module. Experimental evaluations demonstrate that CARIBOU significantly improves the privacy-utility trade-off and achieves superior performance in privacy auditing tasks.",
      "authors": [
        "Yu Zheng",
        "Chenang Li",
        "Zhou Li",
        "Qingsong Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T02:17:53+00:00",
          "link": "https://arxiv.org/abs/2506.22727v1",
          "size": "2818kb",
          "version": "v1"
        }
      ],
      "title": "Convergent Privacy Framework with Contractive GNN Layers for Multi-hop Aggregations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22727",
        "HTML": "https://arxiv.org/html/2506.22727v1",
        "PDF": "https://arxiv.org/pdf/2506.22727"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22728",
      "abstract": "Let $w$ be a string of length $n$. The problem of counting factors crossing a position - Problem 64 from the textbook ``125 Problems in Text Algorithms'' [Crochemore, Leqroc, and Rytter, 2021], asks to count the number $\\mathcal{C}(w,k)$ (resp. $\\mathcal{N}(w,k)$) of distinct substrings in $w$ that have occurrences containing (resp. not containing) a position $k$ in $w$. The solutions provided in their textbook compute $\\mathcal{C}(w,k)$ and $\\mathcal{N}(w,k)$ in $O(n)$ time for a single position $k$ in $w$, and thus a direct application would require $O(n^2)$ time for all positions $k = 1, \\ldots, n$ in $w$. Their solution is designed for constant-size alphabets. In this paper, we present new algorithms which compute $\\mathcal{C}(w,k)$ in $O(n)$ total time for general ordered alphabets, and $\\mathcal{N}(w,k)$ in $O(n)$ total time for linearly sortable alphabets, for all positions $k = 1, \\ldots, n$ in $w$.",
      "authors": [
        "Haruki Umezaki",
        "Hiroki Shibata",
        "Dominik K\\\"oppl",
        "Yuto Nakashima",
        "Shunsuke Inenaga",
        "Hideo Bannai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T02:20:41+00:00",
          "link": "https://arxiv.org/abs/2506.22728v1",
          "size": "421kb",
          "version": "v1"
        }
      ],
      "title": "Counting distinct (non-)crossing substrings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22728",
        "HTML": "https://arxiv.org/html/2506.22728v1",
        "PDF": "https://arxiv.org/pdf/2506.22728"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22729",
      "abstract": "Persistence is often regarded as a virtue in science. In this paper, however, we challenge this conventional view by highlighting its contextual nature, particularly how persistence can become a liability during periods of paradigm shift. We focus on the deep learning revolution catalyzed by AlexNet in 2012. Analyzing the 20-year career trajectories of over 5,000 scientists who were active in top machine learning venues during the preceding decade, we examine how their research focus and output evolved. We first uncover a dynamic period in which leading venues increasingly prioritized cutting-edge deep learning developments that displaced relatively traditional statistical learning methods. Scientists responded to these changes in markedly different ways. Those who were previously successful or affiliated with old teams adapted more slowly, experiencing what we term a rigidity penalty - a reluctance to embrace new directions leading to a decline in scientific impact, as measured by citation percentile rank. In contrast, scientists who pursued strategic adaptation - selectively pivoting toward emerging trends while preserving weak connections to prior expertise - reaped the greatest benefits. Taken together, our macro- and micro-level findings show that scientific breakthroughs act as mechanisms that reconfigure power structures within a field.",
      "authors": [
        "Honglin Bao and Kai Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Digital Libraries (cs.DL)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T02:21:19+00:00",
          "link": "https://arxiv.org/abs/2506.22729v1",
          "size": "2889kb",
          "version": "v1"
        }
      ],
      "title": "Persistence Paradox in Dynamic Science",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22729",
        "HTML": "https://arxiv.org/html/2506.22729v1",
        "PDF": "https://arxiv.org/pdf/2506.22729"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22732",
      "abstract": "In real-world scenarios, spatiotemporal traffic data frequently experiences dual degradation from missing values and noise caused by sensor malfunctions and communication failures. Therefore, effective data recovery methods are essential to ensure the reliability of downstream data-driven applications. while classical tensor completion methods have been widely adopted, they are incapable of modeling noise, making them unsuitable for complex scenarios involving simultaneous data missingness and noise interference. Existing Robust Tensor Completion (RTC) approaches offer potential solutions by separately modeling the actual tensor data and noise. However, their effectiveness is often constrained by the over-relaxation of convex rank surrogates and the suboptimal utilization of local consistency, leading to inadequate model accuracy. To address these limitations, we first introduce the tensor L1-L2 norm, a novel non-convex tensor rank surrogate that functions as an effective low-rank representation tool. Leveraging an advanced feature fusion strategy, we further develop the gradient tensor L1-L2 norm by incorporating the tensor L1-L2 norm in the gradient domain. By integrating the gradient tensor nuclear L1-L2 norm into the RTC framework, we propose the Robust Tensor Completion via Gradient Tensor Nuclear L1-L2 Norm (RTC-GTNLN) model, which not only fully exploits both global low-rankness and local consistency without trade-off parameter, but also effectively handles the dual degradation challenges of missing data and noise in traffic data. Extensive experiments conducted on multiple real-world traffic datasets demonstrate that the RTC-GTNLN model consistently outperforms existing state-of-the-art methods in complex recovery scenarios involving simultaneous missing values and noise.",
      "authors": [
        "Hao Shu",
        "Jicheng Li",
        "Tianyv Lei",
        "Lijun Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T02:38:01+00:00",
          "link": "https://arxiv.org/abs/2506.22732v1",
          "size": "11936kb",
          "version": "v1"
        }
      ],
      "title": "Robust Tensor Completion via Gradient Tensor Nulclear L1-L2 Norm for Traffic Data Recovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22732",
        "HTML": "https://arxiv.org/html/2506.22732v1",
        "PDF": "https://arxiv.org/pdf/2506.22732"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22735",
      "abstract": "In this paper, we develop a logico-algebraic framework for modeling decision-making through deliberation in multi-agent settings. The central concept in this framework is that of interrogative agendas, which represent the cognitive stances of agents regarding which features should be considered relevant in the final decision. We formalize an agent's interrogative agenda as an equivalence relation that identifies outcomes differing only in aspects the agent deems irrelevant. Moreover, we characterize the sublattices of the resulting lattice that correspond to relevant interrogative agendas for deliberation scenarios governed by different ``winning rules.\" We then introduce a two-sorted logico-algebraic structure-comprising the lattice of relevant interrogative agendas and the Boolean algebras of agent coalitions-to model the interaction between agents and agendas during deliberation. Finally, we discuss which interaction conditions can and cannot be defined within this framework.",
      "authors": [
        "Willem Conradie",
        "Krishna Manoorkar",
        "Alessandra Palmigiano",
        "Apostolos Tzimoulis",
        "Nachoem Wijnberg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T02:43:36+00:00",
          "link": "https://arxiv.org/abs/2506.22735v1",
          "size": "101kb",
          "version": "v1"
        }
      ],
      "title": "Questions as cognitive filters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22735",
        "HTML": "https://arxiv.org/html/2506.22735v1",
        "PDF": "https://arxiv.org/pdf/2506.22735"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22736",
      "abstract": "Current multimodal medical image fusion typically assumes that source images are of high quality and perfectly aligned at the pixel level. Its effectiveness heavily relies on these conditions and often deteriorates when handling misaligned or degraded medical images. To address this, we propose UniFuse, a general fusion framework. By embedding a degradation-aware prompt learning module, UniFuse seamlessly integrates multi-directional information from input images and correlates cross-modal alignment with restoration, enabling joint optimization of both tasks within a unified framework. Additionally, we design an Omni Unified Feature Representation scheme, which leverages Spatial Mamba to encode multi-directional features and mitigate modality differences in feature alignment. To enable simultaneous restoration and fusion within an All-in-One configuration, we propose a Universal Feature Restoration & Fusion module, incorporating the Adaptive LoRA Synergistic Network (ALSN) based on LoRA principles. By leveraging ALSN's adaptive feature representation along with degradation-type guidance, we enable joint restoration and fusion within a single-stage framework. Compared to staged approaches, UniFuse unifies alignment, restoration, and fusion within a single framework. Experimental results across multiple datasets demonstrate the method's effectiveness and significant advantages over existing approaches.",
      "authors": [
        "Dayong Su",
        "Yafei Zhang",
        "Huafeng Li",
        "Jinxing Li",
        "Yu Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T02:44:22+00:00",
          "link": "https://arxiv.org/abs/2506.22736v1",
          "size": "22728kb",
          "version": "v1"
        }
      ],
      "title": "UniFuse: A Unified All-in-One Framework for Multi-Modal Medical Image Fusion Under Diverse Degradations and Misalignments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22736",
        "HTML": "https://arxiv.org/html/2506.22736v1",
        "PDF": "https://arxiv.org/pdf/2506.22736"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22740",
      "abstract": "Modern methods for explainable machine learning are designed to describe how models map inputs to outputs--without deep consideration of how these explanations will be used in practice. This paper argues that explanations should be designed and evaluated with a specific end in mind. We describe how to formalize this end in a framework based in statistical decision theory. We show how this functionally-grounded approach can be applied across diverse use cases, such as clinical decision support, providing recourse, or debugging. We demonstrate its use to characterize the maximum \"boost\" in performance on a particular task that an explanation could provide an idealized decision-maker, preventing misuse due to ambiguity by forcing researchers to specify concrete use cases that can be analyzed in light of models of expected explanation use. We argue that evaluation should meld theoretical and empirical perspectives on the value of explanation, and contribute definitions that span these perspectives.",
      "authors": [
        "Jessica Hullman",
        "Ziyang Guo",
        "Berk Ustun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T03:04:21+00:00",
          "link": "https://arxiv.org/abs/2506.22740v1",
          "size": "109kb",
          "version": "v1"
        }
      ],
      "title": "Explanations are a means to an end",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22740",
        "HTML": "https://arxiv.org/html/2506.22740v1",
        "PDF": "https://arxiv.org/pdf/2506.22740"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22741",
      "abstract": "Significant changes in the digital employment landscape, driven by rapid technological advancements and the COVID-19 pandemic, have introduced new opportunities for blind and visually impaired (BVI) individuals in developing countries like India. However, a significant portion of the BVI population in India remains unemployed despite extensive accessibility advancements and job search interventions. Therefore, we conducted semi-structured interviews with 20 BVI persons who were either pursuing or recently sought employment in the digital industry. Our findings reveal that despite gaining digital literacy and extensive training, BVI individuals struggle to meet industry requirements for fulfilling job openings. While they engage in self-reflection to identify shortcomings in their approach and skills, they lack constructive feedback from peers and recruiters. Moreover, the numerous job intervention tools are limited in their ability to meet the unique needs of BVI job seekers. Our results therefore provide key insights that inform the design of future collaborative intervention systems that offer personalized feedback for BVI individuals, effectively guiding their self-reflection process and subsequent job search behaviors, and potentially leading to improved employment outcomes.",
      "authors": [
        "Akshay Nayak Kolgar",
        "Yash Prakash",
        "Sampath Jayarathna",
        "Hae-Na Lee and Vikas Ashok"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T03:05:49+00:00",
          "link": "https://arxiv.org/abs/2506.22741v1",
          "size": "1641kb",
          "version": "v1"
        }
      ],
      "title": "Insights in Adaptation: Examining Self-reflection Strategies of Job Seekers with Visual Impairments in India",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22741",
        "HTML": "https://arxiv.org/html/2506.22741v1",
        "PDF": "https://arxiv.org/pdf/2506.22741"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22742",
      "abstract": "Large Language Models (LLMs) like GPT-3.5-Turbo are increasingly used to assist software development, yet they often produce incomplete code or incorrect imports, especially when lacking access to external or project-specific documentation. We introduce RAILS (Retrieval-Augmented Intelligence for Learning Software Development), a framework that augments LLM prompts with semantically retrieved context from curated Java resources using FAISS and OpenAI embeddings. RAILS incorporates an iterative validation loop guided by compiler feedback to refine suggestions. We evaluated RAILS on 78 real-world Java import error cases spanning standard libraries, GUI APIs, external tools, and custom utilities. Despite using the same LLM, RAILS outperforms baseline prompting by preserving intent, avoiding hallucinations, and surfacing correct imports even when libraries are unavailable locally. Future work will integrate symbolic filtering via PostgreSQL and extend support to other languages and IDEs.",
      "authors": [
        "Wali Mohammad Abdullah",
        "Md. Morshedul Islam",
        "Devraj Parmar",
        "Happy Hasmukhbhai Patel",
        "Sindhuja Prabhakaran",
        "Baidya Saha"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T03:30:04+00:00",
          "link": "https://arxiv.org/abs/2506.22742v1",
          "size": "1556kb",
          "version": "v1"
        }
      ],
      "title": "RAILS: Retrieval-Augmented Intelligence for Learning Software Development",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22742",
        "HTML": "https://arxiv.org/html/2506.22742v1",
        "PDF": "https://arxiv.org/pdf/2506.22742"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22745",
      "abstract": "Due to the scalability and portability, the low-altitude intelligent networks (LAINs) are essential in various fields such as surveillance and disaster rescue. However, in LAINs, unmanned aerial vehicles (UAVs) are characterized by the distributed topology and high dynamic mobility, and vulnerable to security threats, which may degrade the routing performance for data transmission. Hence, how to ensure the routing stability and security of LAINs is a challenge. In this paper, we focus on the routing process in LAINs with multiple UAV clusters and propose the blockchain-enabled zero-trust architecture to manage the joining and exiting of UAVs. Furthermore, we formulate the routing problem to minimize the end-to-end (E2E) delay, which is an integer linear programming and intractable to solve. Therefore, considering the distribution of LAINs, we reformulate the routing problem into a decentralized partially observable Markov decision process. With the proposed soft hierarchical experience replay buffer, the multi-agent double deep Q-network based adaptive routing algorithm is designed. Finally, simulations are conducted and numerical results show that the total E2E delay of the proposed mechanism decreases by 22.38\\% than the benchmark on average.",
      "authors": [
        "Sijie He",
        "Ziye Jia",
        "Qiuming Zhu",
        "Fuhui Zhou",
        "and Qihui Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T03:42:46+00:00",
          "link": "https://arxiv.org/abs/2506.22745v1",
          "size": "1184kb",
          "version": "v1"
        }
      ],
      "title": "Trusted Routing for Blockchain-Enabled Low-Altitude Intelligent Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22745",
        "HTML": "https://arxiv.org/html/2506.22745v1",
        "PDF": "https://arxiv.org/pdf/2506.22745"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22749",
      "abstract": "Colored point cloud, which includes geometry and attribute components, is a mainstream representation enabling realistic and immersive 3D applications. To generate large-scale and denser colored point clouds, we propose a deep learning-based Joint Geometry and Attribute Up-sampling (JGAU) method that learns to model both geometry and attribute patterns while leveraging spatial attribute correlations. First, we establish and release a large-scale dataset for colored point cloud up-sampling called SYSU-PCUD, containing 121 large-scale colored point clouds with diverse geometry and attribute complexities across six categories and four sampling rates. Second, to improve the quality of up-sampled point clouds, we propose a deep learning-based JGAU framework that jointly up-samples geometry and attributes. It consists of a geometry up-sampling network and an attribute up-sampling network, where the latter leverages the up-sampled auxiliary geometry to model neighborhood correlations of the attributes. Third, we propose two coarse attribute up-sampling methods, Geometric Distance Weighted Attribute Interpolation (GDWAI) and Deep Learning-based Attribute Interpolation (DLAI), to generate coarse up-sampled attributes for each point. Then, an attribute enhancement module is introduced to refine these up-sampled attributes and produce high-quality point clouds by further exploiting intrinsic attribute and geometry patterns. Extensive experiments show that the Peak Signal-to-Noise Ratio (PSNR) achieved by the proposed JGAU method is 33.90 decibels, 32.10 decibels, 31.10 decibels, and 30.39 decibels for up-sampling rates of 4 times, 8 times, 12 times, and 16 times, respectively. Compared to state-of-the-art methods, JGAU achieves average PSNR gains of 2.32 decibels, 2.47 decibels, 2.28 decibels, and 2.11 decibels at these four up-sampling rates, demonstrating significant improvement.",
      "authors": [
        "Yun Zhang",
        "Feifan Chen",
        "Na Li",
        "Zhiwei Guo",
        "Xu Wang",
        "Fen Miao",
        "Sam Kwong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T04:08:44+00:00",
          "link": "https://arxiv.org/abs/2506.22749v1",
          "size": "8207kb",
          "version": "v1"
        }
      ],
      "title": "Deep Learning based Joint Geometry and Attribute Up-sampling for Large-Scale Colored Point Clouds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22749",
        "HTML": "https://arxiv.org/html/2506.22749v1",
        "PDF": "https://arxiv.org/pdf/2506.22749"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22750",
      "abstract": "The widespread use of Android applications has made them a prime target for cyberattacks, significantly increasing the risk of malware that threatens user privacy, security, and device functionality. Effective malware detection is thus critical, with static analysis, dynamic analysis, and Machine Learning being widely used approaches. In this work, we focus on a Machine Learning-based method utilizing static features. We first compiled a dataset of benign and malicious APKs and performed static analysis to extract features such as code structure, permissions, and manifest file content, without executing the apps. Instead of relying solely on raw static features, our system uses an LLM to generate high-level functional descriptions of APKs. To mitigate hallucinations, which are a known vulnerability of LLM, we integrated Retrieval-Augmented Generation (RAG), enabling the LLM to ground its output in relevant context. Using carefully designed prompts, we guide the LLM to produce coherent function summaries, which are then analyzed using a transformer-based model, improving detection accuracy over conventional feature-based methods for malware detection.",
      "authors": [
        "Saraga S.",
        "Anagha M. S.",
        "Dincy R. Arikkat",
        "Rafidha Rehiman K. A.",
        "Serena Nicolazzo",
        "Antonino Nocera",
        "Vinod P"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T04:36:31+00:00",
          "link": "https://arxiv.org/abs/2506.22750v1",
          "size": "975kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Android Malware Detection with Retrieval-Augmented Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22750",
        "HTML": "https://arxiv.org/html/2506.22750v1",
        "PDF": "https://arxiv.org/pdf/2506.22750"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22752",
      "abstract": "Bug severity prediction is a critical task in software engineering as it enables more efficient resource allocation and prioritization in software maintenance. While AI-based analyses and models significantly require access to extensive datasets, industrial applications face challenges due to data-sharing constraints and the limited availability of labeled data. In this study, we investigate method-level bug severity prediction using source code metrics and Large Language Models (LLMs) with two widely used datasets. We compare the performance of models trained using centralized learning, federated learning, and synthetic data generation. Our experimental results, obtained using two widely recognized software defect datasets, indicate that models trained with federated learning and synthetic data achieve comparable results to centrally trained models without data sharing. Our finding highlights the potential of privacy-preserving approaches such as federated learning and synthetic data generation to enable effective bug severity prediction in industrial context where data sharing is a major challenge.\n  The source code and dataset are available at our GitHub repository: https://github.com/drvshavva/EASE2025-Privacy-Preserving-Methods-for-Bug-Severity-Prediction.",
      "authors": [
        "Havvanur Dervi\\c{s}o\\u{g}lu",
        "Ru\\c{s}en Halepmollas{\\i}",
        "Elif Eyvaz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T04:40:51+00:00",
          "link": "https://arxiv.org/abs/2506.22752v1",
          "size": "3591kb",
          "version": "v1"
        }
      ],
      "title": "Privacy-Preserving Methods for Bug Severity Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22752",
        "HTML": "https://arxiv.org/html/2506.22752v1",
        "PDF": "https://arxiv.org/pdf/2506.22752"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22753",
      "abstract": "Metalenses offer significant potential for ultra-compact computational imaging but face challenges from complex optical degradation and computational restoration difficulties. Existing methods typically rely on precise optical calibration or massive paired datasets, which are non-trivial for real-world imaging systems. Furthermore, a lack of control over the inference process often results in undesirable hallucinated artifacts. We introduce Degradation-Modeled Multipath Diffusion for tunable metalens photography, leveraging powerful natural image priors from pretrained models instead of large datasets. Our framework uses positive, neutral, and negative-prompt paths to balance high-frequency detail generation, structural fidelity, and suppression of metalens-specific degradation, alongside \\textit{pseudo} data augmentation. A tunable decoder enables controlled trade-offs between fidelity and perceptual quality. Additionally, a spatially varying degradation-aware attention (SVDA) module adaptively models complex optical and sensor-induced degradation. Finally, we design and build a millimeter-scale MetaCamera for real-world validation. Extensive results show that our approach outperforms state-of-the-art methods, achieving high-fidelity and sharp image reconstruction. More materials: https://dmdiff.github.io/.",
      "authors": [
        "Jianing Zhang",
        "Jiayi Zhu",
        "Feiyu Ji",
        "Xiaokang Yang",
        "Xiaoyun Yuan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T04:48:37+00:00",
          "link": "https://arxiv.org/abs/2506.22753v1",
          "size": "2627kb",
          "version": "v1"
        }
      ],
      "title": "Degradation-Modeled Multipath Diffusion for Tunable Metalens Photography",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22753",
        "HTML": "https://arxiv.org/html/2506.22753v1",
        "PDF": "https://arxiv.org/pdf/2506.22753"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22756",
      "abstract": "The development of generalist robot manipulation policies has seen significant progress, driven by large-scale demonstration data across diverse environments. However, the high cost and inefficiency of collecting real-world demonstrations hinder the scalability of data acquisition. While existing simulation platforms enable controlled environments for robotic learning, the challenge of bridging the sim-to-real gap remains. To address these challenges, we propose RoboPearls, an editable video simulation framework for robotic manipulation. Built on 3D Gaussian Splatting (3DGS), RoboPearls enables the construction of photo-realistic, view-consistent simulations from demonstration videos, and supports a wide range of simulation operators, including various object manipulations, powered by advanced modules like Incremental Semantic Distillation (ISD) and 3D regularized NNFM Loss (3D-NNFM). Moreover, by incorporating large language models (LLMs), RoboPearls automates the simulation production process in a user-friendly manner through flexible command interpretation and execution. Furthermore, RoboPearls employs a vision-language model (VLM) to analyze robotic learning issues to close the simulation loop for performance enhancement. To demonstrate the effectiveness of RoboPearls, we conduct extensive experiments on multiple datasets and scenes, including RLBench, COLOSSEUM, Ego4D, Open X-Embodiment, and a real-world robot, which demonstrate our satisfactory simulation performance.",
      "authors": [
        "Tao Tang",
        "Likui Zhang",
        "Youpeng Wen",
        "Kaidong Zhang",
        "Jia-Wang Bian",
        "xia zhou",
        "Tianyi Yan",
        "Kun Zhan",
        "Peng Jia",
        "Hefeng Wu",
        "Liang Lin",
        "Xiaodan Liang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T05:03:31+00:00",
          "link": "https://arxiv.org/abs/2506.22756v1",
          "size": "22877kb",
          "version": "v1"
        }
      ],
      "title": "RoboPearls: Editable Video Simulation for Robot Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22756",
        "HTML": "https://arxiv.org/html/2506.22756v1",
        "PDF": "https://arxiv.org/pdf/2506.22756"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22760",
      "abstract": "Most language models face a fundamental tradeoff where powerful capabilities require substantial computational resources. We shatter this constraint with Jan-nano, a 4B parameter language model that redefines efficiency through radical specialization: instead of trying to know everything, it masters the art of finding anything instantly. Fine-tuned from Qwen3-4B using our novel multi-stage RLVR system that completely eliminates reliance on next token prediction training (SFT), Jan-nano achieves 83.2% on SimpleQA benchmark with MCP integration while running on consumer hardware. With 128K context length, Jan-nano proves that intelligence isn't about scale, it's about strategy.",
      "authors": [
        "Alan Dao (Gia Tuan Dao)",
        "Dinh Bach Vu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T05:44:57+00:00",
          "link": "https://arxiv.org/abs/2506.22760v1",
          "size": "381kb",
          "version": "v1"
        }
      ],
      "title": "Jan-nano Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22760",
        "HTML": "https://arxiv.org/html/2506.22760v1",
        "PDF": "https://arxiv.org/pdf/2506.22760"
      },
      "models": [
        {
          "model_path": "Menlo/Jan-nano-gguf",
          "downloads": "43058",
          "likes": "128",
          "trending_score": "9.0",
          "link": "https://huggingface.co/Menlo/Jan-nano-gguf"
        },
        {
          "model_path": "Menlo/Jan-nano-128k",
          "downloads": "2341",
          "likes": "169",
          "trending_score": "169.0",
          "link": "https://huggingface.co/Menlo/Jan-nano-128k"
        },
        {
          "model_path": "Menlo/Jan-nano",
          "downloads": "32416",
          "likes": "429",
          "trending_score": "59.0",
          "link": "https://huggingface.co/Menlo/Jan-nano"
        },
        {
          "model_path": "Menlo/Jan-nano-128k-gguf",
          "downloads": "7361",
          "likes": "44",
          "trending_score": "44.0",
          "link": "https://huggingface.co/Menlo/Jan-nano-128k-gguf"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.22762",
      "abstract": "Video super-resolution remains a major challenge in low-level vision tasks. To date, CNN- and Transformer-based methods have delivered impressive results. However, CNNs are limited by local receptive fields, while Transformers struggle with quadratic complexity, posing challenges for processing long sequences in VSR. Recently, Mamba has drawn attention for its long-sequence modeling, linear complexity, and large receptive fields. In this work, we propose VSRM, a novel \\textbf{V}ideo \\textbf{S}uper-\\textbf{R}esolution framework that leverages the power of \\textbf{M}amba. VSRM introduces Spatial-to-Temporal Mamba and Temporal-to-Spatial Mamba blocks to extract long-range spatio-temporal features and enhance receptive fields efficiently. To better align adjacent frames, we propose Deformable Cross-Mamba Alignment module. This module utilizes a deformable cross-mamba mechanism to make the compensation stage more dynamic and flexible, preventing feature distortions. Finally, we minimize the frequency domain gaps between reconstructed and ground-truth frames by proposing a simple yet effective Frequency Charbonnier-like loss that better preserves high-frequency content and enhances visual quality. Through extensive experiments, VSRM achieves state-of-the-art results on diverse benchmarks, establishing itself as a solid foundation for future research.",
      "authors": [
        "Dinh Phu Tran",
        "Dao Duy Hung",
        "Daeyoung Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T05:51:42+00:00",
          "link": "https://arxiv.org/abs/2506.22762v1",
          "size": "2648kb",
          "version": "v1"
        }
      ],
      "title": "VSRM: A Robust Mamba-Based Framework for Video Super-Resolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22762",
        "HTML": "https://arxiv.org/html/2506.22762v1",
        "PDF": "https://arxiv.org/pdf/2506.22762"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22766",
      "abstract": "Robust and adaptive robotic peg-in-hole assembly under tight tolerances is critical to various industrial applications. However, it remains an open challenge due to perceptual and physical uncertainties from contact-rich interactions that easily exceed the allowed clearance. In this paper, we study how to leverage contact between the peg and its matching hole to eliminate uncertainties in the assembly process under unstructured settings. By examining the role of compliance under contact constraints, we present a manipulation system that plans collision-inclusive interactions for the peg to 1) iteratively identify its task environment to localize the target hole and 2) exploit environmental contact constraints to refine insertion motions into the target hole without relying on precise perception, enabling a robust solution to peg-in-hole assembly. By conceptualizing the above process as the composition of funneling in different state spaces, we present a formal approach to constructing manipulation funnels as an uncertainty-absorbing paradigm for peg-in-hole assembly. The proposed system effectively generalizes across diverse peg-in-hole scenarios across varying scales, shapes, and materials in a learning-free manner. Extensive experiments on a NIST Assembly Task Board (ATB) and additional challenging scenarios validate its robustness in real-world applications.",
      "authors": [
        "Yiting Chen",
        "Kenneth Kimble",
        "Howard H. Qian",
        "Podshara Chanrungmaneekul",
        "Robert Seney",
        "Kaiyu Hang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T06:02:42+00:00",
          "link": "https://arxiv.org/abs/2506.22766v1",
          "size": "23000kb",
          "version": "v1"
        }
      ],
      "title": "Robust Peg-in-Hole Assembly under Uncertainties via Compliant and Interactive Contact-Rich Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22766",
        "HTML": "https://arxiv.org/html/2506.22766v1",
        "PDF": "https://arxiv.org/pdf/2506.22766"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22769",
      "abstract": "Garment manipulation is a significant challenge for robots due to the complex dynamics and potential self-occlusion of garments. Most existing methods of efficient garment unfolding overlook the crucial role of standardization of flattened garments, which could significantly simplify downstream tasks like folding, ironing, and packing. This paper presents APS-Net, a novel approach to garment manipulation that combines unfolding and standardization in a unified framework. APS-Net employs a dual-arm, multi-primitive policy with dynamic fling to quickly unfold crumpled garments and pick-and-place (p and p) for precise alignment. The purpose of garment standardization during unfolding involves not only maximizing surface coverage but also aligning the garment's shape and orientation to predefined requirements. To guide effective robot learning, we introduce a novel factorized reward function for standardization, which incorporates garment coverage (Cov), keypoint distance (KD), and intersection-over-union (IoU) metrics. Additionally, we introduce a spatial action mask and an Action Optimized Module to improve unfolding efficiency by selecting actions and operation points effectively. In simulation, APS-Net outperforms state-of-the-art methods for long sleeves, achieving 3.9 percent better coverage, 5.2 percent higher IoU, and a 0.14 decrease in KD (7.09 percent relative reduction). Real-world folding tasks further demonstrate that standardization simplifies the folding process. Project page: see https://hellohaia.github.io/APS/",
      "authors": [
        "Changshi Zhou",
        "Feng Luan",
        "Jiarui Hu",
        "Shaoqiang Meng",
        "Zhipeng Wang",
        "Yanchao Dong",
        "Yanmin Zhou",
        "Bin He"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T06:13:13+00:00",
          "link": "https://arxiv.org/abs/2506.22769v1",
          "size": "8958kb",
          "version": "v1"
        }
      ],
      "title": "Learning Efficient Robotic Garment Manipulation with Standardization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22769",
        "HTML": "https://arxiv.org/html/2506.22769v1",
        "PDF": "https://arxiv.org/pdf/2506.22769"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22771",
      "abstract": "Backpropagation has been the cornerstone of neural network training for decades, yet its inefficiencies in time and energy consumption limit its suitability for resource-constrained edge devices. While low-precision neural network quantization has been extensively researched to speed up model inference, its application in training has been less explored. Recently, the Forward-Forward (FF) algorithm has emerged as a promising alternative to backpropagation, replacing the backward pass with an additional forward pass. By avoiding the need to store intermediate activations for backpropagation, FF can reduce memory footprint, making it well-suited for embedded devices. This paper presents an INT8 quantized training approach that leverages FF's layer-by-layer strategy to stabilize gradient quantization. Furthermore, we propose a novel \"look-ahead\" scheme to address limitations of FF and improve model accuracy. Experiments conducted on NVIDIA Jetson Orin Nano board demonstrate 4.6% faster training, 8.3% energy savings, and 27.0% reduction in memory usage, while maintaining competitive accuracy compared to the state-of-the-art.",
      "authors": [
        "Jingxiao Ma",
        "Priyadarshini Panda and Sherief Reda"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T06:16:26+00:00",
          "link": "https://arxiv.org/abs/2506.22771v1",
          "size": "1103kb",
          "version": "v1"
        }
      ],
      "title": "FF-INT8: Efficient Forward-Forward DNN Training on Edge Devices with INT8 Precision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22771",
        "HTML": "https://arxiv.org/html/2506.22771v1",
        "PDF": "https://arxiv.org/pdf/2506.22771"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22772",
      "abstract": "Approximate computing is an emerging paradigm where design accuracy can be traded for improvements in design metrics such as design area and power consumption. In this work, we overview our open-source tool, BLASYS, for synthesis of approximate circuits using Boolean Matrix Factorization (BMF). In our methodology the truth table of a given circuit is approximated using BMF to a controllable approximation degree, and the results of the factorization are used to synthesize the approximate circuit output. BLASYS scales up the computations to large circuits through the use of partition techniques, where an input circuit is partitioned into a number of interconnected subcircuits and then a design-space exploration technique identifies the best order for subcircuit approximations. BLASYS leads to a graceful trade-off between accuracy and full circuit complexity as measured by design area. Using an open-source design flow, we extensively evaluate our methodology on a number of benchmarks, where we demonstrate that the proposed methodology can achieve on average 48.14% in area savings, while introducing an average relative error of 5%.",
      "authors": [
        "Jingxiao Ma",
        "Soheil Hashemi and Sherief Reda"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T06:17:08+00:00",
          "link": "https://arxiv.org/abs/2506.22772v1",
          "size": "1419kb",
          "version": "v1"
        }
      ],
      "title": "Approximate Logic Synthesis Using BLASYS",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22772",
        "HTML": "https://arxiv.org/html/2506.22772v1",
        "PDF": "https://arxiv.org/pdf/2506.22772"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22773",
      "abstract": "Water consumption is an increasingly critical dimension of computing sustainability, especially as AI workloads rapidly scale. However, current water impact assessment often overlooks where and when water stress is more severe. To fill in this gap, we present SCARF, the first general framework that evaluates water impact of computing by factoring in both spatial and temporal variations in water stress. SCARF calculates an Adjusted Water Impact (AWI) metric that considers both consumption volume and local water stress over time. Through three case studies on LLM serving, datacenters, and semiconductor fabrication plants, we show the hidden opportunities for reducing water impact by optimizing location and time choices, paving the way for water-sustainable computing. The code is available at https://github.com/jojacola/SCARF.",
      "authors": [
        "Yanran Wu",
        "Inez Hua",
        "Yi Ding"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Hardware Architecture (cs.AR)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T06:26:06+00:00",
          "link": "https://arxiv.org/abs/2506.22773v1",
          "size": "913kb",
          "version": "v1"
        }
      ],
      "title": "Not All Water Consumption Is Equal: A Water Stress Weighted Metric for Sustainable Computing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22773",
        "HTML": "https://arxiv.org/html/2506.22773v1",
        "PDF": "https://arxiv.org/pdf/2506.22773"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22774",
      "abstract": "Artificial Intelligence (AI) technology epitomizes the complex challenges posed by human-made artifacts, particularly those widely integrated into society and exert significant influence, highlighting potential benefits and their negative consequences. While other technologies may also pose substantial risks, AI's pervasive reach makes its societal effects especially profound. The complexity of AI systems, coupled with their remarkable capabilities, can lead to a reliance on technologies that operate beyond direct human oversight or understanding. To mitigate the risks that arise, several theoretical tools and guidelines have been developed, alongside efforts to create technological tools aimed at safeguarding Trustworthy AI. The guidelines take a more holistic view of the issue but fail to provide techniques for quantifying trustworthiness. Conversely, while technological tools are better at achieving such quantification, they lack a holistic perspective, focusing instead on specific aspects of Trustworthy AI. This paper aims to introduce an assessment method that combines the ethical components of Trustworthy AI with the algorithmic processes of PageRank and TrustRank. The goal is to establish an assessment framework that minimizes the subjectivity inherent in the self-assessment techniques prevalent in the field by introducing algorithmic criteria. The application of our approach indicates that a holistic assessment of an AI system's trustworthiness can be achieved by providing quantitative insights while considering the theoretical content of relevant guidelines.",
      "authors": [
        "Michael Papademas",
        "Xenia Ziouvelou",
        "Antonis Troumpoukis",
        "Vangelis Karkaletsis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T06:27:30+00:00",
          "link": "https://arxiv.org/abs/2506.22774v1",
          "size": "1549kb",
          "version": "v1"
        }
      ],
      "title": "Bridging Ethical Principles and Algorithmic Methods: An Alternative Approach for Assessing Trustworthiness in AI Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22774",
        "PDF": "https://arxiv.org/pdf/2506.22774"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22776",
      "abstract": "Quantization has emerged as a mainstream method for compressing Large Language Models (LLMs), reducing memory requirements and accelerating inference without architectural modifications. While existing research primarily focuses on evaluating the effectiveness of quantized LLMs compared to their original counterparts, the impact on robustness remains largely unexplored.In this paper, we present the first systematic investigation of how quantization affects the robustness of LLMs in code generation tasks. Through extensive experiments across four prominent LLM families (LLaMA, DeepSeek, CodeGen, and StarCoder) with parameter scales ranging from 350M to 33B, we evaluate robustness from dual perspectives: adversarial attacks on input prompts and noise perturbations on model architecture. Our findings challenge conventional wisdom by demonstrating that quantized LLMs often exhibit superior robustness compared to their full-precision counterparts, with 51.59% versus 42.86% of our adversarial experiments showing better resilience in quantized LLMs. Similarly, our noise perturbation experiments also confirm that LLMs after quantitation generally withstand higher levels of weight disturbances. These results suggest that quantization not only reduces computational requirements but can actually enhance LLMs' reliability in code generation tasks, providing valuable insights for developing more robust and efficient LLM deployment strategies.",
      "authors": [
        "Sen Fang",
        "Weiyuan Ding",
        "Antonio Mastropaolo",
        "Bowen Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T06:32:25+00:00",
          "link": "https://arxiv.org/abs/2506.22776v1",
          "size": "4410kb",
          "version": "v1"
        }
      ],
      "title": "Smaller = Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22776",
        "HTML": "https://arxiv.org/html/2506.22776v1",
        "PDF": "https://arxiv.org/pdf/2506.22776"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22777",
      "abstract": "Language models trained with RL can engage in reward hacking--exploiting unintended strategies for high reward--without revealing this behavior in their chain-of-thought reasoning, making detection difficult and posing risks for high-stakes applications. We propose verbalization fine-tuning (VFT), a pre-RL intervention that trains models to explicitly acknowledge when they are influenced by prompt cues--hints which point to incorrect answers (e.g., \"a Stanford professor thinks the answer is A\"). To evaluate VFT, we subsequently train models with RL on environments where held-out prompt cues signal which incorrect answers will receive high reward, incentivizing models to reward hack by exploiting cues instead of reasoning correctly. We measure how often models exploit these cues without verbalizing it. After RL, only 6% of the VFT-trained model's responses consist of undetected reward hacks. In comparison, when we perform RL without VFT, the rate of undetected reward hacks goes up to 88%; with a debiasing baseline intervention, this increases further to 99%. VFT achieves this by substantially increasing how often models verbalize the influence of cues--from 8% to 42% after VFT, and up to 94% after RL--while baselines remain low even after RL (10% and 1%). Our results show that teaching models to explicitly verbalize reward hacking behavior before RL significantly improves their detection, offering a practical path toward more transparent and safe AI systems.",
      "authors": [
        "Miles Turpin",
        "Andy Arditi",
        "Marvin Li",
        "Joe Benton",
        "Julian Michael"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T06:37:10+00:00",
          "link": "https://arxiv.org/abs/2506.22777v1",
          "size": "3360kb",
          "version": "v1"
        }
      ],
      "title": "Teaching Models to Verbalize Reward Hacking in Chain-of-Thought Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22777",
        "HTML": "https://arxiv.org/html/2506.22777v1",
        "PDF": "https://arxiv.org/pdf/2506.22777"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22778",
      "abstract": "The worst-case additive sensitivity of a string repetitiveness measure $c$ is defined to be the largest difference between $c(w)$ and $c(w')$, where $w$ is a string of length $n$ and $w'$ is a string that can be obtained by performing a single-character edit operation on $w$. We present $O(\\sqrt{n})$ upper bounds for the worst-case additive sensitivity of the smallest string attractor size $\\gamma$ and the smallest bidirectional scheme size $b$, which match the known lower bounds $\\Omega(\\sqrt{n})$ for $\\gamma$ and $b$ [Akagi et al. 2023]. Further, we present matching upper and lower bounds for the worst-case additive sensitivity of the Lempel-Ziv family - $\\Theta(n^{\\frac{2}{3}})$ for LZSS and LZ-End, and $\\Theta(n)$ for LZ78.",
      "authors": [
        "Yuto Fujie",
        "Hiroki Shibata",
        "Yuto Nakashima",
        "Shunsuke Inenaga"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T06:37:22+00:00",
          "link": "https://arxiv.org/abs/2506.22778v1",
          "size": "97kb",
          "version": "v1"
        }
      ],
      "title": "Tight Additive Sensitivity on LZ-style Compressors and String Attractors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22778",
        "HTML": "https://arxiv.org/html/2506.22778v1",
        "PDF": "https://arxiv.org/pdf/2506.22778"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22780",
      "abstract": "Score-based diffusion modeling is a generative machine learning algorithm that can be used to sample from complex distributions. They achieve this by learning a score function, i.e., the gradient of the log-probability density of the data, and reversing a noising process using the same. Once trained, score-based diffusion models not only generate new samples but also enable zero-shot conditioning of the generated samples on observed data. This promises a novel paradigm for data and model fusion, wherein the implicitly learned distributions of pretrained score-based diffusion models can be updated given the availability of online data in a Bayesian formulation. In this article, we apply such a concept to the super-resolution of a high-dimensional dynamical system, given the real-time availability of low-resolution and experimentally observed sparse sensor measurements from multimodal data. Additional analysis on how score-based sampling can be used for uncertainty estimates is also provided. Our experiments are performed for a super-resolution task that generates the ERA5 atmospheric dataset given sparse observations from a coarse-grained representation of the same and/or from unstructured experimental observations of the IGRA radiosonde dataset. We demonstrate accurate recovery of the high dimensional state given multiple sources of low-fidelity measurements. We also discover that the generative model can balance the influence of multiple dataset modalities during spatiotemporal reconstructions.",
      "authors": [
        "Dibyajyoti Chakraborty",
        "Haiwen Guan",
        "Jason Stock",
        "Troy Arcomano",
        "Guido Cervone",
        "Romit Maulik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Geophysics (physics.geo-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T06:47:09+00:00",
          "link": "https://arxiv.org/abs/2506.22780v1",
          "size": "15231kb",
          "version": "v1"
        }
      ],
      "title": "Multimodal Atmospheric Super-Resolution With Deep Generative Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22780",
        "HTML": "https://arxiv.org/html/2506.22780v1",
        "PDF": "https://arxiv.org/pdf/2506.22780"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22782",
      "abstract": "This work analyzes the finite element approximation to a viscoelastic flow model, which generalizes the Navier-Stokes equation and Oldroyd's model by introducing the tempered power-law memory kernel. We prove regularity and long-time exponential decay of the solutions, as well as a long-time convolution-type Gr\\\"onwall inequality to support numerical analysis. A Volterra-Stokes projection is developed and analyzed to facilitate the parabolic-type duality argument, leading to the long-time error estimates and exponential decay of velocity and pressure. A benchmark problem of planar four-to-one contraction flow is simulated to substantiate the generality of the proposed model in comparison with the Navier-Stokes equation and Oldroyd's model.",
      "authors": [
        "Yingwen Guo",
        "Yinnian He",
        "Wenlin Qiu",
        "Xiangcheng Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T06:54:24+00:00",
          "link": "https://arxiv.org/abs/2506.22782v1",
          "size": "153kb",
          "version": "v1"
        }
      ],
      "title": "Long-time error estimate and decay of finite element method to a generalized viscoelastic flow",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22782",
        "HTML": "https://arxiv.org/html/2506.22782v1",
        "PDF": "https://arxiv.org/pdf/2506.22782"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22783",
      "abstract": "Deepfake (DF) attacks pose a growing threat as generative models become increasingly advanced. However, our study reveals that existing DF datasets fail to deceive human perception, unlike real DF attacks that influence public discourse. It highlights the need for more realistic DF attack vectors. We introduce PhonemeFake (PF), a DF attack that manipulates critical speech segments using language reasoning, significantly reducing human perception by up to 42% and benchmark accuracies by up to 94%. We release an easy-to-use PF dataset on HuggingFace and open-source bilevel DF segment detection model that adaptively prioritizes compute on manipulated regions. Our extensive experiments across three known DF datasets reveal that our detection model reduces EER by 91% while achieving up to 90% speed-up, with minimal compute overhead and precise localization beyond existing models as a scalable solution.",
      "authors": [
        "Oguzhan Baser",
        "Ahmet Ege Tanriverdi",
        "Sriram Vishwanath",
        "Sandeep P. Chinchali"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T06:56:41+00:00",
          "link": "https://arxiv.org/abs/2506.22783v1",
          "size": "678kb",
          "version": "v1"
        }
      ],
      "title": "PhonemeFake: Redefining Deepfake Realism with Language-Driven Segmental Manipulation and Adaptive Bilevel Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22783",
        "HTML": "https://arxiv.org/html/2506.22783v1",
        "PDF": "https://arxiv.org/pdf/2506.22783"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22784",
      "abstract": "Point-pixel registration between LiDAR point clouds and camera images is a fundamental yet challenging task in autonomous driving and robotic perception. A key difficulty lies in the modality gap between unstructured point clouds and structured images, especially under sparse single-frame LiDAR settings. Existing methods typically extract features separately from point clouds and images, then rely on hand-crafted or learned matching strategies. This separate encoding fails to bridge the modality gap effectively, and more critically, these methods struggle with the sparsity and noise of single-frame LiDAR, often requiring point cloud accumulation or additional priors to improve reliability. Inspired by recent progress in detector-free matching paradigms (e.g. MatchAnything), we revisit the projection-based approach and introduce the detector-free framework for direct point-pixel matching between LiDAR and camera views. Specifically, we project the LiDAR intensity map into a 2D view from the LiDAR perspective and feed it into an attention-based detector-free matching network, enabling cross-modal correspondence estimation without relying on multi-frame accumulation. To further enhance matching reliability, we introduce a repeatability scoring mechanism that acts as a soft visibility prior. This guides the network to suppress unreliable matches in regions with low intensity variation, improving robustness under sparse input. Extensive experiments on KITTI, nuScenes, and MIAS-LCEC-TF70 benchmarks demonstrate that our method achieves state-of-the-art performance, outperforming prior approaches on nuScenes (even those relying on accumulated point clouds), despite using only single-frame LiDAR.",
      "authors": [
        "Yu Han",
        "Zhiwei Huang",
        "Yanting Zhang",
        "Fangjun Ding",
        "Shen Cai",
        "Rui Fan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T06:57:13+00:00",
          "link": "https://arxiv.org/abs/2506.22784v1",
          "size": "2595kb",
          "version": "v1"
        }
      ],
      "title": "Single-Frame Point-Pixel Registration via Supervised Cross-Modal Feature Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22784",
        "HTML": "https://arxiv.org/html/2506.22784v1",
        "PDF": "https://arxiv.org/pdf/2506.22784"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22787",
      "abstract": "We propose a harm-centric conceptualization of privacy that asks: What harms from personal data use can privacy prevent? The motivation behind this research is limitations in existing privacy frameworks (e.g., Contextual Integrity) to capture or categorize many of the harms that arise from modern technology's use of personal data. We operationalize this conceptualization in an online study with 400 college and university students. Study participants indicated their perceptions of different harms (e.g., manipulation, discrimination, and harassment) that may arise when artificial intelligence-based algorithms infer personal data (e.g., demographics, personality traits, and cognitive disability) and use it to identify students who are likely to drop out of a course or the best job candidate. The study includes 14 harms and six types of personal data selected based on an extensive literature review.\n  Comprehensive statistical analyses of the study data show that the 14 harms are internally consistent and collectively represent a general notion of privacy harms. The study data also surfaces nuanced perceptions of harms, both across the contexts and participants' demographic factors. Based on these results, we discuss how privacy can be improved equitably. Thus, this research not only contributes to enhancing the understanding of privacy as a concept but also provides practical guidance to improve privacy in the context of education and employment.",
      "authors": [
        "Sri Harsha Gajavalli",
        "Junichi Koizumi",
        "Rakibul Hasan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T07:00:37+00:00",
          "link": "https://arxiv.org/abs/2506.22787v1",
          "size": "519kb",
          "version": "v1"
        }
      ],
      "title": "What's Privacy Good for? Measuring Privacy as a Shield from Harms due to Personal Data Use",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22787",
        "HTML": "https://arxiv.org/html/2506.22787v1",
        "PDF": "https://arxiv.org/pdf/2506.22787"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22788",
      "abstract": "The widespread application of industrial robots in fields such as cutting and welding has imposed increasingly stringent requirements on the trajectory accuracy of end-effectors. However, current error compensation methods face several critical challenges, including overly simplified mechanism modeling, a lack of physical consistency in data-driven approaches, and substantial data requirements. These issues make it difficult to achieve both high accuracy and strong generalization simultaneously. To address these challenges, this paper proposes a Spatial-Physical Informed Attention Residual Network (SPI-BoTER). This method integrates the kinematic equations of the robotic manipulator with a Transformer architecture enhanced by sparse self-attention masks. A parameter-adaptive hybrid loss function incorporating spatial and physical information is employed to iteratively optimize the network during training, enabling high-precision error compensation under small-sample conditions. Additionally, inverse joint angle compensation is performed using a gradient descent-based optimization method. Experimental results on a small-sample dataset from a UR5 robotic arm (724 samples, with a train:test:validation split of 8:1:1) demonstrate the superior performance of the proposed method. It achieves a 3D absolute positioning error of 0.2515 mm with a standard deviation of 0.15 mm, representing a 35.16\\% reduction in error compared to conventional deep neural network (DNN) methods. Furthermore, the inverse angle compensation algorithm converges to an accuracy of 0.01 mm within an average of 147 iterations. This study presents a solution that combines physical interpretability with data adaptability for high-precision control of industrial robots, offering promising potential for the reliable execution of precision tasks in intelligent manufacturing.",
      "authors": [
        "Xuao Hou",
        "Yongquan Jia",
        "Shijin Zhang",
        "Yuqiang Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T07:00:59+00:00",
          "link": "https://arxiv.org/abs/2506.22788v1",
          "size": "8987kb",
          "version": "v1"
        }
      ],
      "title": "SPI-BoTER: Error Compensation for Industrial Robots via Sparse Attention Masking and Hybrid Loss with Spatial-Physical Information",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22788",
        "HTML": "https://arxiv.org/html/2506.22788v1",
        "PDF": "https://arxiv.org/pdf/2506.22788"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22789",
      "abstract": "Speech embeddings often retain sensitive attributes such as speaker identity, accent, or demographic information, posing risks in biased model training and privacy leakage. We propose WavShape, an information-theoretic speech representation learning framework that optimizes embeddings for fairness and privacy while preserving task-relevant information. We leverage mutual information (MI) estimation using the Donsker-Varadhan formulation to guide an MI-based encoder that systematically filters sensitive attributes while maintaining speech content essential for downstream tasks. Experimental results on three known datasets show that WavShape reduces MI between embeddings and sensitive attributes by up to 81% while retaining 97% of task-relevant information. By integrating information theory with self-supervised speech models, this work advances the development of fair, privacy-aware, and resource-efficient speech systems.",
      "authors": [
        "Oguzhan Baser",
        "Ahmet Ege Tanriverdi",
        "Kaan Kale",
        "Sandeep P. Chinchali",
        "Sriram Vishwanath"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T07:03:55+00:00",
          "link": "https://arxiv.org/abs/2506.22789v1",
          "size": "2891kb",
          "version": "v1"
        }
      ],
      "title": "WavShape: Information-Theoretic Speech Representation Learning for Fair and Privacy-Aware Audio Processing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22789",
        "HTML": "https://arxiv.org/html/2506.22789v1",
        "PDF": "https://arxiv.org/pdf/2506.22789"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22791",
      "abstract": "Semantic caching significantly reduces computational costs and improves efficiency by storing and reusing large language model (LLM) responses. However, existing systems rely primarily on matching individual queries, lacking awareness of multi-turn dialogue contexts, which leads to incorrect cache hits when similar queries appear in different conversational settings. This demonstration introduces ContextCache, a context-aware semantic caching system for multi-turn dialogues. ContextCache employs a two-stage retrieval architecture that first executes vector-based retrieval on the current query to identify potential matches and then integrates current and historical dialogue representations through self-attention mechanisms for precise contextual matching. Evaluation of real-world conversations shows that ContextCache improves precision and recall compared to existing methods. Additionally, cached responses exhibit approximately 10 times lower latency than direct LLM invocation, enabling significant computational cost reductions for LLM conversational applications.",
      "authors": [
        "Jianxin Yan",
        "Wangze Ni",
        "Lei Chen",
        "Xuemin Lin",
        "Peng Cheng",
        "Zhan Qin",
        "Kui Ren"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T07:25:12+00:00",
          "link": "https://arxiv.org/abs/2506.22791v1",
          "size": "898kb",
          "version": "v1"
        }
      ],
      "title": "ContextCache: Context-Aware Semantic Cache for Multi-Turn Queries in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22791",
        "HTML": "https://arxiv.org/html/2506.22791v1",
        "PDF": "https://arxiv.org/pdf/2506.22791"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22793",
      "abstract": "In this work we revisit the Mobility Robustness Optimisation (MRO) algorithm and study the possibility of learning the optimal Cell Individual Offset tuning using offline Reinforcement Learning. Such methods make use of collected offline datasets to learn the optimal policy, without further exploration. We adapt and apply a sequence-based method called Decision Transformers as well as a value-based method called Conservative Q-Learning to learn the optimal policy for the same target reward as the vanilla rule-based MRO. The same input features related to failures, ping-pongs, and other handover issues are used. Evaluation for realistic New Radio networks with 3500 MHz carrier frequency on a traffic mix including diverse user service types and a specific tunable cell-pair shows that offline-RL methods outperform rule-based MRO, offering up to 7% improvement. Furthermore, offline-RL can be trained for diverse objective functions using the same available dataset, thus offering operational flexibility compared to rule-based methods.",
      "authors": [
        "Pegah Alizadeh",
        "Anastasios Giovanidis",
        "Pradeepa Ramachandra",
        "Vasileios Koutsoukis",
        "Osama Arouk"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T07:31:01+00:00",
          "link": "https://arxiv.org/abs/2506.22793v1",
          "size": "1762kb",
          "version": "v1"
        }
      ],
      "title": "Offline Reinforcement Learning for Mobility Robustness Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22793",
        "HTML": "https://arxiv.org/html/2506.22793v1",
        "PDF": "https://arxiv.org/pdf/2506.22793"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22799",
      "abstract": "3D Gaussian Splatting (3DGS) has become horsepower in high-quality, real-time rendering for novel view synthesis of 3D scenes. However, existing methods focus primarily on geometric and appearance modeling, lacking deeper scene understanding while also incurring high training costs that complicate the originally streamlined differentiable rendering pipeline. To this end, we propose VoteSplat, a novel 3D scene understanding framework that integrates Hough voting with 3DGS. Specifically, Segment Anything Model (SAM) is utilized for instance segmentation, extracting objects, and generating 2D vote maps. We then embed spatial offset vectors into Gaussian primitives. These offsets construct 3D spatial votes by associating them with 2D image votes, while depth distortion constraints refine localization along the depth axis. For open-vocabulary object localization, VoteSplat maps 2D image semantics to 3D point clouds via voting points, reducing training costs associated with high-dimensional CLIP features while preserving semantic unambiguity. Extensive experiments demonstrate effectiveness of VoteSplat in open-vocabulary 3D instance localization, 3D point cloud understanding, click-based 3D object localization, hierarchical segmentation, and ablation studies. Our code is available at https://sy-ja.github.io/votesplat/",
      "authors": [
        "Minchao Jiang",
        "Shunyu Jia",
        "Jiaming Gu",
        "Xiaoyuan Lu",
        "Guangming Zhu",
        "Anqi Dong",
        "Liang Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T08:02:43+00:00",
          "link": "https://arxiv.org/abs/2506.22799v1",
          "size": "3377kb",
          "version": "v1"
        }
      ],
      "title": "VoteSplat: Hough Voting Gaussian Splatting for 3D Scene Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22799",
        "HTML": "https://arxiv.org/html/2506.22799v1",
        "PDF": "https://arxiv.org/pdf/2506.22799"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22800",
      "abstract": "A single-pass driving clip frequently results in incomplete scanning of the road structure, making reconstructed scene expanding a critical requirement for sensor simulators to effectively regress driving actions. Although contemporary 3D Gaussian Splatting (3DGS) techniques achieve remarkable reconstruction quality, their direct extension through the integration of diffusion priors often introduces cumulative physical inconsistencies and compromises training efficiency. To address these limitations, we present RGE-GS, a novel expansive reconstruction framework that synergizes diffusion-based generation with reward-guided Gaussian integration. The RGE-GS framework incorporates two key innovations: First, we propose a reward network that learns to identify and prioritize consistently generated patterns prior to reconstruction phases, thereby enabling selective retention of diffusion outputs for spatial stability. Second, during the reconstruction process, we devise a differentiated training strategy that automatically adjust Gaussian optimization progress according to scene converge metrics, which achieving better convergence than baseline methods. Extensive evaluations of publicly available datasets demonstrate that RGE-GS achieves state-of-the-art performance in reconstruction quality. Our source-code will be made publicly available at https://github.com/CN-ADLab/RGE-GS. (Camera-ready version incorporating reviewer suggestions will be updated soon.)",
      "authors": [
        "Sicong Du",
        "Jiarun Liu",
        "Qifeng Chen",
        "Hao-Xiang Chen",
        "Tai-Jiang Mu",
        "Sheng Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T08:02:54+00:00",
          "link": "https://arxiv.org/abs/2506.22800v1",
          "size": "3895kb",
          "version": "v1"
        }
      ],
      "title": "RGE-GS: Reward-Guided Expansive Driving Scene Reconstruction via Diffusion Priors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22800",
        "HTML": "https://arxiv.org/html/2506.22800v1",
        "PDF": "https://arxiv.org/pdf/2506.22800"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22802",
      "abstract": "Recent breakthroughs and rapid integration of generative models (GMs) have sparked interest in the problem of model attribution and their fingerprints. For instance, service providers need reliable methods of authenticating their models to protect their IP, while users and law enforcement seek to verify the source of generated content for accountability and trust. In addition, a growing threat of model collapse is arising, as more model-generated data are being fed back into sources (e.g., YouTube) that are often harvested for training (\"regurgitative training\"), heightening the need to differentiate synthetic from human data. Yet, a gap still exists in understanding generative models' fingerprints, we believe, stemming from the lack of a formal framework that can define, represent, and analyze the fingerprints in a principled way. To address this gap, we take a geometric approach and propose a new definition of artifact and fingerprint of GMs using Riemannian geometry, which allows us to leverage the rich theory of differential geometry. Our new definition generalizes previous work (Song et al., 2024) to non-Euclidean manifolds by learning Riemannian metrics from data and replacing the Euclidean distances and nearest-neighbor search with geodesic distances and kNN-based Riemannian center of mass. We apply our theory to a new gradient-based algorithm for computing the fingerprints in practice. Results show that it is more effective in distinguishing a large array of GMs, spanning across 4 different datasets in 2 different resolutions (64 by 64, 256 by 256), 27 model architectures, and 2 modalities (Vision, Vision-Language). Using our proposed definition significantly improves the performance on model attribution, as well as a generalization to unseen datasets, model types, and modalities, suggesting its practical efficacy.",
      "authors": [
        "Hae Jin Song",
        "Laurent Itti"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T08:08:16+00:00",
          "link": "https://arxiv.org/abs/2506.22802v1",
          "size": "1550kb",
          "version": "v1"
        }
      ],
      "title": "Riemannian-Geometric Fingerprints of Generative Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22802",
        "HTML": "https://arxiv.org/html/2506.22802v1",
        "PDF": "https://arxiv.org/pdf/2506.22802"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22803",
      "abstract": "Recent advances in deep learning have led to increasingly complex models with deeper layers and more parameters, reducing interpretability and making their decisions harder to understand. While many methods explain black-box reasoning, most lack effective interventions or only operate at sample-level without modifying the model itself. To address this, we propose the Concept Bottleneck Model for Enhancing Human-Neural Network Mutual Understanding (CBM-HNMU). CBM-HNMU leverages the Concept Bottleneck Model (CBM) as an interpretable framework to approximate black-box reasoning and communicate conceptual understanding. Detrimental concepts are automatically identified and refined (removed/replaced) based on global gradient contributions. The modified CBM then distills corrected knowledge back into the black-box model, enhancing both interpretability and accuracy. We evaluate CBM-HNMU on various CNN and transformer-based models across Flower-102, CIFAR-10, CIFAR-100, FGVC-Aircraft, and CUB-200, achieving a maximum accuracy improvement of 2.64% and a maximum increase in average accuracy across 1.03%. Source code is available at: https://github.com/XiGuaBo/CBM-HNMU.",
      "authors": [
        "Nuoye Xiong",
        "Anqi Dong",
        "Ning Wang",
        "Cong Hua",
        "Guangming Zhu",
        "Mei Lin",
        "Peiyi Shen",
        "Liang Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T08:11:29+00:00",
          "link": "https://arxiv.org/abs/2506.22803v1",
          "size": "34443kb",
          "version": "v1"
        }
      ],
      "title": "Intervening in Black Box: Concept Bottleneck Model for Enhancing Human Neural Network Mutual Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22803",
        "HTML": "https://arxiv.org/html/2506.22803v1",
        "PDF": "https://arxiv.org/pdf/2506.22803"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22804",
      "abstract": "With the increasing availability of streaming data in dynamic systems, a critical challenge in data-driven modeling for control is how to efficiently select informative data to characterize system dynamics. In this work, we design an online coreset selection method under the framework of set-membership identification for systems subject to process disturbances, with the objective of improving data efficiency while ensuring convergence guarantees. Specifically, we first propose a stacked polyhedral representation that over-approximates the feasible set of system parameters. Leveraging a generalized Gr\\\"unbaum's inequality, we design a geometric selection criterion for constructing the coreset. To reduce computational complexity, an online double-description-based constraint reduction method is introduced to simplify the polyhedral representation. Finally, we analyze the convergence of the feasible set with respect to the coreset and derive upper bounds on the selection probability and the expected number of data in the coreset. The effectiveness of the proposed method is demonstrated through comprehensive simulation studies.",
      "authors": [
        "Jingyuan Li",
        "Dawei Shi",
        "and Ling Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T08:12:33+00:00",
          "link": "https://arxiv.org/abs/2506.22804v1",
          "size": "3283kb",
          "version": "v1"
        }
      ],
      "title": "Online Coreset Selection for Learning Dynamic Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22804",
        "HTML": "https://arxiv.org/html/2506.22804v1",
        "PDF": "https://arxiv.org/pdf/2506.22804"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22806",
      "abstract": "Remarkable progress in text-to-image diffusion models has brought a major concern about potentially generating images on inappropriate or trademarked concepts. Concept erasing has been investigated with the goals of deleting target concepts in diffusion models while preserving other concepts with minimal distortion. To achieve these goals, recent concept erasing methods usually fine-tune the cross-attention layers of diffusion models. In this work, we first show that merely updating the cross-attention layers in diffusion models, which is mathematically equivalent to adding \\emph{linear} modules to weights, may not be able to preserve diverse remaining concepts. Then, we propose a novel framework, dubbed Concept Pinpoint Eraser (CPE), by adding \\emph{nonlinear} Residual Attention Gates (ResAGs) that selectively erase (or cut) target concepts while safeguarding remaining concepts from broad distributions by employing an attention anchoring loss to prevent the forgetting. Moreover, we adversarially train CPE with ResAG and learnable text embeddings in an iterative manner to maximize erasing performance and enhance robustness against adversarial attacks. Extensive experiments on the erasure of celebrities, artistic styles, and explicit contents demonstrated that the proposed CPE outperforms prior arts by keeping diverse remaining concepts while deleting the target concepts with robustness against attack prompts. Code is available at https://github.com/Hyun1A/CPE",
      "authors": [
        "Byung Hyun Lee",
        "Sungjin Lim",
        "Seunggyu Lee",
        "Dong Un Kang",
        "Se Young Chun"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T08:17:19+00:00",
          "link": "https://arxiv.org/abs/2506.22806v1",
          "size": "37562kb",
          "version": "v1"
        }
      ],
      "title": "Concept Pinpoint Eraser for Text-to-image Diffusion Models via Residual Attention Gate",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22806",
        "HTML": "https://arxiv.org/html/2506.22806v1",
        "PDF": "https://arxiv.org/pdf/2506.22806"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22807",
      "abstract": "Electroencephalography (EEG) serves as a reliable and objective signal for emotion recognition in affective brain-computer interfaces, offering unique advantages through its high temporal resolution and ability to capture authentic emotional states that cannot be consciously controlled. However, cross-subject generalization remains a fundamental challenge due to individual variability, cognitive traits, and emotional responses. We propose FreqDGT, a frequency-adaptive dynamic graph transformer that systematically addresses these limitations through an integrated framework. FreqDGT introduces frequency-adaptive processing (FAP) to dynamically weight emotion-relevant frequency bands based on neuroscientific evidence, employs adaptive dynamic graph learning (ADGL) to learn input-specific brain connectivity patterns, and implements multi-scale temporal disentanglement network (MTDN) that combines hierarchical temporal transformers with adversarial feature disentanglement to capture both temporal dynamics and ensure cross-subject robustness. Comprehensive experiments demonstrate that FreqDGT significantly improves cross-subject emotion recognition accuracy, confirming the effectiveness of integrating frequency-adaptive, spatial-dynamic, and temporal-hierarchical modeling while ensuring robustness to individual differences. The code is available at https://github.com/NZWANG/FreqDGT.",
      "authors": [
        "Yueyang Li",
        "Shengyu Gong",
        "Weiming Zeng",
        "Nizhuan Wang and Wai Ting Siok"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T08:18:05+00:00",
          "link": "https://arxiv.org/abs/2506.22807v1",
          "size": "6305kb",
          "version": "v1"
        }
      ],
      "title": "FreqDGT: Frequency-Adaptive Dynamic Graph Networks with Transformer for Cross-subject EEG Emotion Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22807",
        "HTML": "https://arxiv.org/html/2506.22807v1",
        "PDF": "https://arxiv.org/pdf/2506.22807"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22808",
      "abstract": "While Medical Large Language Models (MedLLMs) have demonstrated remarkable potential in clinical tasks, their ethical safety remains insufficiently explored. This paper introduces $\\textbf{MedEthicsQA}$, a comprehensive benchmark comprising $\\textbf{5,623}$ multiple-choice questions and $\\textbf{5,351}$ open-ended questions for evaluation of medical ethics in LLMs. We systematically establish a hierarchical taxonomy integrating global medical ethical standards. The benchmark encompasses widely used medical datasets, authoritative question banks, and scenarios derived from PubMed literature. Rigorous quality control involving multi-stage filtering and multi-faceted expert validation ensures the reliability of the dataset with a low error rate ($2.72\\%$). Evaluation of state-of-the-art MedLLMs exhibit declined performance in answering medical ethics questions compared to their foundation counterparts, elucidating the deficiencies of medical ethics alignment. The dataset, registered under CC BY-NC 4.0 license, is available at https://github.com/JianhuiWei7/MedEthicsQA.",
      "authors": [
        "Jianhui Wei",
        "Zijie Meng",
        "Zikai Xiao",
        "Tianxiang Hu",
        "Yang Feng",
        "Zhijie Zhou",
        "Jian Wu",
        "Zuozhu Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T08:21:35+00:00",
          "link": "https://arxiv.org/abs/2506.22808v1",
          "size": "1171kb",
          "version": "v1"
        }
      ],
      "title": "MedEthicsQA: A Comprehensive Question Answering Benchmark for Medical Ethics Evaluation of LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22808",
        "HTML": "https://arxiv.org/html/2506.22808v1",
        "PDF": "https://arxiv.org/pdf/2506.22808"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22809",
      "abstract": "We propose BayesLoRA, a task-specific uncertainty quantification framework that integrates MC-Dropout into Low-Rank Adapters (LoRA). Unlike general-purpose transformer uncertainty methods, BayesLoRA provides guardrails tailored to downstream workflows, enabling agents to introspect and modulate behavior under uncertainty. We demonstrate mathematically and empirically that LoRA adapters exhibit amplified variance outside fine-tuning distributions, yielding reliable confidence estimates for agentic decision-making.",
      "authors": [
        "Cooper Doyle"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T08:22:02+00:00",
          "link": "https://arxiv.org/abs/2506.22809v1",
          "size": "74kb",
          "version": "v1"
        }
      ],
      "title": "BayesLoRA: Task-Specific Uncertainty in Low-Rank Adapters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22809",
        "HTML": "https://arxiv.org/html/2506.22809v1",
        "PDF": "https://arxiv.org/pdf/2506.22809"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22810",
      "abstract": "Dysarthric speech recognition (DSR) enhances the accessibility of smart devices for dysarthric speakers with limited mobility. Previously, DSR research was constrained by the fact that existing datasets typically consisted of isolated words, command phrases, and a limited number of sentences spoken by a few individuals. This constrained research to command-interaction systems and speaker adaptation. The Speech Accessibility Project (SAP) changed this by releasing a large and diverse English dysarthric dataset, leading to the SAP Challenge to build speaker- and text-independent DSR systems. We enhanced the Whisper model's performance on long dysarthric speech via a novel self-training method. This method increased training data and adapted the model to handle potentially incomplete speech segments encountered during inference. Our system achieved second place in both Word Error Rate and Semantic Score in the SAP Challenge.",
      "authors": [
        "Shiyao Wang",
        "Jiaming Zhou",
        "Shiwan Zhao",
        "Yong Qin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T08:24:15+00:00",
          "link": "https://arxiv.org/abs/2506.22810v1",
          "size": "149kb",
          "version": "v1"
        }
      ],
      "title": "A Self-Training Approach for Whisper to Enhance Long Dysarthric Speech Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22810",
        "HTML": "https://arxiv.org/html/2506.22810v1",
        "PDF": "https://arxiv.org/pdf/2506.22810"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22813",
      "abstract": "Supervised fine-tuning (SFT) is widely used to align large language models (LLMs) with information extraction (IE) tasks, such as named entity recognition (NER). However, annotating such fine-grained labels and training domain-specific models is costly. Existing works typically train a unified model across multiple domains, but such approaches lack adaptation and scalability since not all training data benefits target domains and scaling trained models remains challenging. We propose the SaM framework, which dynamically Selects and Merges expert models at inference time. Specifically, for a target domain, we select domain-specific experts pre-trained on existing domains based on (i) domain similarity to the target domain and (ii) performance on sampled instances, respectively. The experts are then merged to create task-specific models optimized for the target domain. By dynamically merging experts beneficial to target domains, we improve generalization across various domains without extra training. Additionally, experts can be added or removed conveniently, leading to great scalability. Extensive experiments on multiple benchmarks demonstrate our framework's effectiveness, which outperforms the unified model by an average of 10%. We further provide insights into potential improvements, practical experience, and extensions of our framework.",
      "authors": [
        "Zhuojun Ding",
        "Wei Wei",
        "Chenghao Fan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T08:28:52+00:00",
          "link": "https://arxiv.org/abs/2506.22813v1",
          "size": "466kb",
          "version": "v1"
        }
      ],
      "title": "Selecting and Merging: Towards Adaptable and Scalable Named Entity Recognition with Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22813",
        "HTML": "https://arxiv.org/html/2506.22813v1",
        "PDF": "https://arxiv.org/pdf/2506.22813"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22814",
      "abstract": "Automatic image cropping aims to extract the most visually salient regions while preserving essential composition elements. Traditional saliency-aware cropping methods optimize a single bounding box, making them ineffective for applications requiring multiple disjoint crops. In this work, we extend the Fixed Aspect Ratio Cropping algorithm to efficiently extract multiple non-overlapping crops in linear time. Our approach dynamically adjusts attention thresholds and removes selected crops from consideration without recomputing the entire saliency map. We discuss qualitative results and introduce the potential for future datasets and benchmarks.",
      "authors": [
        "Andrew Hamara",
        "Andrew C. Freeman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T08:32:53+00:00",
          "link": "https://arxiv.org/abs/2506.22814v1",
          "size": "668kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Multi-Crop Saliency Partitioning for Automatic Image Cropping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22814",
        "HTML": "https://arxiv.org/html/2506.22814v1",
        "PDF": "https://arxiv.org/pdf/2506.22814"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22815",
      "abstract": "This position paper aims to rethink the role and design of memory in Large Language Model (LLM)-based agent systems. We observe that while current memory practices have begun to transcend the limitations of single interactions, they remain conceptually grounded in \"bound memory\" in terms of design concept-where memory is treated as local state attached to specific context or entities, forming \"memory silos\" that impede cross-entity collaboration. To overcome this architectural bottleneck, this paper proposes the timely design perspective of \"Memory as a Service\" (MaaS). MaaS advocates decoupling memory from its conventional role as an interaction byproduct and encapsulating it as a modular service that can be independently callable, dynamically composable, and finely governed. At its core, MaaS leverages the duality of memory-its inherently private nature and its potential for public service-to grant memory controlled, on-demand interoperability across entities. This paper introduces a two-dimensional design space defined by entity structure and service type, illustrating how MaaS aligns with current memory practices while naturally extending them to cross-entity collaborative scenarios. Finally, we outline an open research agenda spanning governance, security, and ethical ecosystems, and call upon the broader research community to explore this shift toward service-oriented memory for collaborative agents operating across entity boundaries.",
      "authors": [
        "Haichang Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T08:33:17+00:00",
          "link": "https://arxiv.org/abs/2506.22815v1",
          "size": "33kb",
          "version": "v1"
        }
      ],
      "title": "Memory as a Service (MaaS): Rethinking Contextual Memory as Service-Oriented Modules for Collaborative Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22815",
        "HTML": "https://arxiv.org/html/2506.22815v1",
        "PDF": "https://arxiv.org/pdf/2506.22815"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22817",
      "abstract": "Recent open-vocabulary 3D scene understanding approaches mainly focus on training 3D networks through contrastive learning with point-text pairs or by distilling 2D features into 3D models via point-pixel alignment. While these methods show considerable performance in benchmarks with limited vocabularies, they struggle to handle diverse object categories as the limited amount of 3D data upbound training strong open-vocabulary 3d models. We observe that 2D multi-view fusion methods take precedence in understanding diverse concepts in 3D scenes. However, inherent noises in vision-language models lead multi-view fusion to sub-optimal performance. To this end, we introduce MVOV3D, a novel approach aimed at unleashing the potential of 2D multi-view fusion for open-vocabulary 3D scene understanding. We focus on reducing the inherent noises without training, thereby preserving the generalizability while enhancing open-world capabilities. Specifically, MVOV3D improves multi-view 2D features by leveraging precise region-level image features and text features encoded by CLIP encoders and incorporates 3D geometric priors to optimize multi-view fusion. Extensive experiments on various datasets demonstrate the effectiveness of our method. Notably, our MVOV3D achieves a new record with 14.7% mIoU on ScanNet200 and 16.2% mIoU on Matterport160 for challenge open-vocabulary semantic segmentation, outperforming current leading trained 3D networks by a significant margin.",
      "authors": [
        "Xingyilang Yin",
        "Jiale Wang",
        "Xi Yang",
        "Mutian Xu",
        "Xu Gu",
        "Nannan Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T08:40:42+00:00",
          "link": "https://arxiv.org/abs/2506.22817v1",
          "size": "5024kb",
          "version": "v1"
        }
      ],
      "title": "Unleashing the Multi-View Fusion Potential: Noise Correction in VLM for Open-Vocabulary 3D Scene Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22817",
        "HTML": "https://arxiv.org/html/2506.22817v1",
        "PDF": "https://arxiv.org/pdf/2506.22817"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22818",
      "abstract": "Multilinear transformations are key in high-performance computing (HPC) and artificial intelligence (AI) workloads, where data is represented as tensors. However, their high computational and memory demands, which grow with dimensionality, often slow down critical tasks. Moreover, scaling computation by enlarging the number of parallel processing units substantially increases energy consumption, limiting widespread adoption, especially for sparse data, which is common in HPC and AI applications. This paper introduces the Trilinear Algorithm and isomorphic to algorithm Device Architecture (TriADA) to address these challenges with the following innovations: (1) a massively parallel, low-rank algorithm for computing a family of trilinear (3D) discrete orthogonal transformations (3D-DXTs), which is a special case of the more general 3-mode matrix-by-tensor multiplication (3D-GEMT); (2) a new outer-product-based GEMM kernel with decoupled streaming active memory, specially designed to accelerate 3D-GEMT operation; (3) an isomorphic to the proposed algorithm, fully distributed 3D network of mesh interconnected processing elements or cells with a coordinate-free, data-driven local processing activity, which is independent of problem size; (4) an elastic sparse outer-product (ESOP) method that avoids unnecessary computing and communication operations with zero-valued operands, thereby enhancing energy efficiency, computational accuracy, and stability. TriADA is capable of performing a variety of trilinear transformations with hypercubic arithmetic complexity in a linear number of time-steps. The massively parallel, scalable, and energy-efficient architecture of TriADA is ideal for accelerating multilinear tensor operations, which are the most demanding parts of AI and HPC workloads.",
      "authors": [
        "Stanislav Sedukhin (1)",
        "Yoichi Tomioka (1)",
        "Kazuya Matsumoto (1)",
        "Yuichi Okuyama (1) ((1) The University of Aizu",
        "Japan)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Hardware Architecture (cs.AR)",
        "Emerging Technologies (cs.ET)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T08:42:01+00:00",
          "link": "https://arxiv.org/abs/2506.22818v1",
          "size": "628kb",
          "version": "v1"
        }
      ],
      "title": "TriADA: Massively Parallel Trilinear Matrix-by-Tensor Multiply-Add Algorithm and Device Architecture for the Acceleration of 3D Discrete Transformations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22818",
        "HTML": "https://arxiv.org/html/2506.22818v1",
        "PDF": "https://arxiv.org/pdf/2506.22818"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22819",
      "abstract": "Vision-language models (VLM) have demonstrated impressive performance in image recognition by leveraging self-supervised training on large datasets. Their performance can be further improved by adapting to the test sample using test-time prompt tuning (TPT). Unfortunately, the singular focus of TPT approaches on improving the accuracy suffers from tunnel vision, and leads to degradation in confidence calibration. This limits the applicability of TPT in critical applications.\n  We make three contributions in this work. (1) We posit that random or naive initialization of prompts leads to overfitting on a particular test sample, and is the main reason for miscalibration of the VLM after TPT. To mitigate the problem, we propose careful initialization of test time prompt using prior knowledge about the target label attributes from a large language model (LLM); (2) To further maintain the quality of prompts during \\tpt, we propose a novel regularization loss to reduce intraclass distance, and increase inter-class distance between the learnt\n  Through extensive experiments on different CLIP architectures and 15 datasets, we show that our approach can effectively improve the calibration after TPT. We report an average expected calibration error (ECE) of 4.11 with our method, TCA, compared to 11.7 for vanilla TPT, 6.12 for C-TPT (ICLR'24), 6.78 for DiffTPT (CVPR'23), and 8.43 for PromptAlign (NeurIPS'23). The code is publicly accessible at: https://github.com/rhebbalaguppe/TCA_PromptWithoutPanic.",
      "authors": [
        "Ramya Hebbalaguppe",
        "Tamoghno Kandar",
        "Abhinav Nagpal",
        "Chetan Arora"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T08:57:57+00:00",
          "link": "https://arxiv.org/abs/2506.22819v1",
          "size": "2906kb",
          "version": "v1"
        }
      ],
      "title": "Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22819",
        "HTML": "https://arxiv.org/html/2506.22819v1",
        "PDF": "https://arxiv.org/pdf/2506.22819"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22821",
      "abstract": "We present a novel and detailed dataset on origin-destination annual migration flows and stocks between 230 countries and regions, spanning the period from 1990 to the present. Our flow estimates are further disaggregated by country of birth, providing a comprehensive picture of migration over the last 43 years. The estimates are obtained by training a deep recurrent neural network to learn flow patterns from 18 covariates for all countries, including geographic, economic, cultural, societal, and political information. The recurrent architecture of the neural network means that the entire past can influence current migration patterns, allowing us to learn long-range temporal correlations. By training an ensemble of neural networks and additionally pushing uncertainty on the covariates through the trained network, we obtain confidence bounds for all our estimates, allowing researchers to pinpoint the geographic regions most in need of additional data collection. We validate our approach on various test sets of unseen data, demonstrating that it significantly outperforms traditional methods estimating five-year flows while delivering a significant increase in temporal resolution. The model is fully open source: all training data, neural network weights, and training code are made public alongside the migration estimates, providing a valuable resource for future studies of human migration.",
      "authors": [
        "Thomas Gaskin and Guy J. Abel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T09:05:34+00:00",
          "link": "https://arxiv.org/abs/2506.22821v1",
          "size": "11522kb",
          "version": "v1"
        }
      ],
      "title": "Deep learning 40 years of human migration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22821",
        "HTML": "https://arxiv.org/html/2506.22821v1",
        "PDF": "https://arxiv.org/pdf/2506.22821"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22827",
      "abstract": "Enabling humanoid robots to reliably execute complex multi-step manipulation tasks is crucial for their effective deployment in industrial and household environments. This paper presents a hierarchical planning and control framework designed to achieve reliable multi-step humanoid manipulation. The proposed system comprises three layers: (1) a low-level RL-based controller responsible for tracking whole-body motion targets; (2) a mid-level set of skill policies trained via imitation learning that produce motion targets for different steps of a task; and (3) a high-level vision-language planning module that determines which skills should be executed and also monitors their completion in real-time using pretrained vision-language models (VLMs). Experimental validation is performed on a Unitree G1 humanoid robot executing a non-prehensile pick-and-place task. Over 40 real-world trials, the hierarchical system achieved a 72.5% success rate in completing the full manipulation sequence. These experiments confirm the feasibility of the proposed hierarchical system, highlighting the benefits of VLM-based skill planning and monitoring for multi-step manipulation scenarios. See https://vlp-humanoid.github.io/ for video demonstrations of the policy rollout.",
      "authors": [
        "Andr\\'e Schakkal",
        "Ben Zandonati",
        "Zhutian Yang and Navid Azizan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T09:39:37+00:00",
          "link": "https://arxiv.org/abs/2506.22827v1",
          "size": "14555kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Vision-Language Planning for Multi-Step Humanoid Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22827",
        "HTML": "https://arxiv.org/html/2506.22827v1",
        "PDF": "https://arxiv.org/pdf/2506.22827"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22828",
      "abstract": "We study L\\\"owenheim-Skolem and Omitting Types theorems in Transition Algebra, a logical system obtained by enhancing many sorted first-order logic with features from dynamic logic. The sentences we consider include compositions, unions, and transitive closures of transition relations, which are treated similarly to actions in dynamic logics to define necessity and possibility operators. We show that Upward L\\\"owenheim-Skolem theorem, any form of compactness, and joint Robinson consistency property fail due to the expressivity of transitive closures of transitions. In this non-compact many-sorted logical system, we develop a forcing technique method by generalizing the classical method of forcing used by Keisler to prove Omitting Types theorem. Instead of working within a single signature, we work with a directed diagram of signatures, which allows us to establish Downward L\\\"owenheim-Skolem and Omitting Types theorems despite the fact that models interpret sorts as sets, possibly empty. Building on a complete system of proof rules for Transition Algebra, we extend it with additional proof rules to reason about constructor-based and/or finite transition algebras. We then establish the completeness of this extended system for a fragment of Transition Algebra obtained by restricting models to constructor-based and/or finite transition algebras.",
      "authors": [
        "Go Hashimoto and Daniel G\\u{a}in\\u{a}"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T09:43:56+00:00",
          "link": "https://arxiv.org/abs/2506.22828v1",
          "size": "49kb",
          "version": "v1"
        }
      ],
      "title": "Model-theoretic Forcing in Transition Algebra",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22828",
        "HTML": "https://arxiv.org/html/2506.22828v1",
        "PDF": "https://arxiv.org/pdf/2506.22828"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22831",
      "abstract": "We introduce a new multimesh finite element method for direct numerical simulation of incompressible particulate flows. The proposed approach falls into the category of overlapping domain decomposition / Chimera / overset grid meshes. In addition to calculating the velocity and pressure of the fictitious fluid on a fixed background mesh, we solve the incompressible Navier-Stokes equations on body-fitted submeshes that are attached to moving particles. The submesh velocity and pressure are used to calculate the hydrodynamic forces and torques acting on the particles. The coupling with the background velocity and pressure is enforced via (i) Robin-type boundary conditions for an Arbitrary-Lagrangian-Eulerian (ALE) formulation of the submesh problems and (ii) a Dirichlet-type distributed interior penalty term in the weak form of the background mesh problem. The implementation of the weak Dirichlet-Robin coupling is discussed in the context of discrete projection methods and finite element discretizations. Detailed numerical studies are performed for standard test problems involving fixed and moving immersed objects. A comparison of Chimera results with those produced by fictitious boundary methods illustrates significant gains in the accuracy of drag and lift approximations.",
      "authors": [
        "Raphael M\\\"unster",
        "Otto Mierka",
        "Dmitri Kuzmin",
        "and Stefan Turek"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T09:52:40+00:00",
          "link": "https://arxiv.org/abs/2506.22831v1",
          "size": "1823kb",
          "version": "v1"
        }
      ],
      "title": "A Chimera domain decomposition method with weak Dirichlet-Robin coupling for finite element simulation of particulate flows",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22831",
        "HTML": "https://arxiv.org/html/2506.22831v1",
        "PDF": "https://arxiv.org/pdf/2506.22831"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22832",
      "abstract": "Training robust and generalizable reward models for human visual preferences is essential for aligning text-to-image and text-to-video generative models with human intent. However, current reward models often fail to generalize, and supervised fine-tuning leads to memorization, demanding complex annotation pipelines. While reinforcement learning (RL), specifically Group Relative Policy Optimization (GRPO), improves generalization, we uncover a key failure mode: a significant drop in reasoning accuracy occurs when a model's reasoning trace contradicts that of an independent, frozen vision-language model (\"listener\") evaluating the same output. To address this, we introduce a listener-augmented GRPO framework. Here, the listener re-evaluates the reasoner's chain-of-thought to provide a dense, calibrated confidence score, shaping the RL reward signal. This encourages the reasoner not only to answer correctly, but to produce explanations that are persuasive to an independent model. Our listener-shaped reward scheme achieves best accuracy on the ImageReward benchmark (67.4%), significantly improves out-of-distribution (OOD) performance on a large-scale human preference dataset (1.2M votes, up to +6% over naive reasoner), and reduces reasoning contradictions compared to strong GRPO and SFT baselines. These results demonstrate that listener-based rewards provide a scalable, data-efficient path to aligning vision-language models with nuanced human preferences. We will release our reasoning model here: https://huggingface.co/alexgambashidze/qwen2.5vl_image_preference_reasoner.",
      "authors": [
        "Alexander Gambashidze",
        "Li Pengyi",
        "Matvey Skripkin",
        "Andrey Galichin",
        "Anton Gusarov",
        "Konstantin Sobolev",
        "Andrey Kuznetsov",
        "Ivan Oseledets"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T09:53:17+00:00",
          "link": "https://arxiv.org/abs/2506.22832v1",
          "size": "957kb",
          "version": "v1"
        }
      ],
      "title": "Listener-Rewarded Thinking in VLMs for Image Preferences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22832",
        "HTML": "https://arxiv.org/html/2506.22832v1",
        "PDF": "https://arxiv.org/pdf/2506.22832"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22833",
      "abstract": "Despite multiple view consistency offered by 3D-aware GAN techniques, the resulting images often lack the capacity for localized editing. In response, generative radiance manifolds emerge as an efficient approach for constrained point sampling within volumes, effectively reducing computational demands and enabling the learning of fine details. This work introduces SemFaceEdit, a novel method that streamlines the appearance and geometric editing process by generating semantic fields on generative radiance manifolds. Utilizing latent codes, our method effectively disentangles the geometry and appearance associated with different facial semantics within the generated image. In contrast to existing methods that can change the appearance of the entire radiance field, our method enables the precise editing of particular facial semantics while preserving the integrity of other regions. Our network comprises two key modules: the Geometry module, which generates semantic radiance and occupancy fields, and the Appearance module, which is responsible for predicting RGB radiance. We jointly train both modules in adversarial settings to learn semantic-aware geometry and appearance descriptors. The appearance descriptors are then conditioned on their respective semantic latent codes by the Appearance Module, facilitating disentanglement and enhanced control. Our experiments highlight SemFaceEdit's superior performance in semantic field-based editing, particularly in achieving improved radiance field disentanglement.",
      "authors": [
        "Shashikant Verma",
        "Shanmuganathan Raman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T10:29:23+00:00",
          "link": "https://arxiv.org/abs/2506.22833v1",
          "size": "15851kb",
          "version": "v1"
        }
      ],
      "title": "SemFaceEdit: Semantic Face Editing on Generative Radiance Manifolds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22833",
        "HTML": "https://arxiv.org/html/2506.22833v1",
        "PDF": "https://arxiv.org/pdf/2506.22833"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22836",
      "abstract": "Pedestrian attribute recognition (PAR) is a fundamental perception task in intelligent transportation and security. To tackle this fine-grained task, most existing methods focus on extracting regional features to enrich attribute information. However, a regional feature is typically used to predict a fixed set of pre-defined attributes in these methods, which limits the performance and practicality in two aspects: 1) Regional features may compromise fine-grained patterns unique to certain attributes in favor of capturing common characteristics shared across attributes. 2) Regional features cannot generalize to predict unseen attributes in the test time. In this paper, we propose the \\textbf{F}ine-grained \\textbf{O}ptimization with semanti\\textbf{C} g\\textbf{U}ided under\\textbf{S}tanding (FOCUS) approach for PAR, which adaptively extracts fine-grained attribute-level features for each attribute individually, regardless of whether the attributes are seen or not during training. Specifically, we propose the Multi-Granularity Mix Tokens (MGMT) to capture latent features at varying levels of visual granularity, thereby enriching the diversity of the extracted information. Next, we introduce the Attribute-guided Visual Feature Extraction (AVFE) module, which leverages textual attributes as queries to retrieve their corresponding visual attribute features from the Mix Tokens using a cross-attention mechanism. To ensure that textual attributes focus on the appropriate Mix Tokens, we further incorporate a Region-Aware Contrastive Learning (RACL) method, encouraging attributes within the same region to share consistent attention maps. Extensive experiments on PA100K, PETA, and RAPv1 datasets demonstrate the effectiveness and strong generalization ability of our method.",
      "authors": [
        "Hongyan An",
        "Kuan Zhu",
        "Xin He",
        "Haiyun Guo",
        "Chaoyang Zhao",
        "Ming Tang and Jinqiao Wang"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T10:38:54+00:00",
          "link": "https://arxiv.org/abs/2506.22836v1",
          "size": "834kb",
          "version": "v1"
        }
      ],
      "title": "FOCUS: Fine-grained Optimization with Semantic Guided Understanding for Pedestrian Attributes Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22836",
        "HTML": "https://arxiv.org/html/2506.22836v1",
        "PDF": "https://arxiv.org/pdf/2506.22836"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22837",
      "abstract": "The recently proposed xLSTM is a powerful model that leverages expressive multiplicative gating and residual connections, providing the temporal capacity needed for long-horizon forecasting and representation learning. This architecture has demonstrated success in time series forecasting, lossless compression, and even large-scale language modeling tasks, where its linear memory footprint and fast inference make it a viable alternative to Transformers. Despite its growing popularity, no prior work has explored xLSTM for anomaly detection. In this work, we fill this gap by proposing xLSTMAD, the first anomaly detection method that integrates a full encoder-decoder xLSTM architecture, purpose-built for multivariate time series data. Our encoder processes input sequences to capture historical context, while the decoder is devised in two separate variants of the method. In the forecasting approach, the decoder iteratively generates forecasted future values xLSTMAD-F, while the reconstruction approach reconstructs the input time series from its encoded counterpart xLSTMAD-R. We investigate the performance of two loss functions: Mean Squared Error (MSE), and Soft Dynamic Time Warping (SoftDTW) to consider local reconstruction fidelity and global sequence alignment, respectively. We evaluate our method on the comprehensive TSB-AD-M benchmark, which spans 17 real-world datasets, using state-of-the-art challenging metrics such as VUS-PR. In our results, xLSTM showcases state-of-the-art accuracy, outperforming 23 popular anomaly detection baselines. Our paper is the first work revealing the powerful modeling capabilities of xLSTM for anomaly detection, paving the way for exciting new developments on this subject. Our code is available at: https://github.com/Nyderx/xlstmad",
      "authors": [
        "Kamil Faber",
        "Marcin Pietro\\'n",
        "Dominik \\.Zurek",
        "Roberto Corizzo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T10:39:09+00:00",
          "link": "https://arxiv.org/abs/2506.22837v1",
          "size": "154kb",
          "version": "v1"
        }
      ],
      "title": "xLSTMAD: A Powerful xLSTM-based Method for Anomaly Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22837",
        "HTML": "https://arxiv.org/html/2506.22837v1",
        "PDF": "https://arxiv.org/pdf/2506.22837"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22841",
      "abstract": "Adjusting transparency is a common method of mitigating occlusion but is often detrimental for understanding the relative depth relationships between objects as well as removes potentially important information from the occluding object. We propose using dichoptic opacity, a novel method for occlusion management that contrasts the transparency of occluders presented to each eye. This allows for better simultaneous understanding of both occluder and occluded. A user study highlights the technique's potential, showing strong user engagement and a clear preference for dichoptic opacity over traditional presentations. While it does not determine optimal transparency values, it reveals promising trends in both percentage and range that merit further investigation.",
      "authors": [
        "George Bell (1)",
        "Alma Cantu (1) ((1) Newcastle University)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T10:41:38+00:00",
          "link": "https://arxiv.org/abs/2506.22841v1",
          "size": "589kb",
          "version": "v1"
        }
      ],
      "title": "Dichoptic Opacity: Managing Occlusion in Stereoscopic Displays via Dichoptic Presentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22841",
        "HTML": "https://arxiv.org/html/2506.22841v1",
        "PDF": "https://arxiv.org/pdf/2506.22841"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22843",
      "abstract": "Person re-identification (ReID) across aerial and ground vantage points has become crucial for large-scale surveillance and public safety applications. Although significant progress has been made in ground-only scenarios, bridging the aerial-ground domain gap remains a formidable challenge due to extreme viewpoint differences, scale variations, and occlusions. Building upon the achievements of the AG-ReID 2023 Challenge, this paper introduces the AG-VPReID 2025 Challenge - the first large-scale video-based competition focused on high-altitude (80-120m) aerial-ground ReID. Constructed on the new AG-VPReID dataset with 3,027 identities, over 13,500 tracklets, and approximately 3.7 million frames captured from UAVs, CCTV, and wearable cameras, the challenge featured four international teams. These teams developed solutions ranging from multi-stream architectures to transformer-based temporal reasoning and physics-informed modeling. The leading approach, X-TFCLIP from UAM, attained 72.28% Rank-1 accuracy in the aerial-to-ground ReID setting and 70.77% in the ground-to-aerial ReID setting, surpassing existing baselines while highlighting the dataset's complexity. For additional details, please refer to the official website at https://agvpreid25.github.io.",
      "authors": [
        "Kien Nguyen",
        "Clinton Fookes",
        "Sridha Sridharan",
        "Huy Nguyen",
        "Feng Liu",
        "Xiaoming Liu",
        "Arun Ross",
        "Dana Michalski",
        "Tam\\'as Endrei",
        "Ivan DeAndres-Tame",
        "Ruben Tolosana",
        "Ruben Vera-Rodriguez",
        "Aythami Morales",
        "Julian Fierrez",
        "Javier Ortega-Garcia",
        "Zijing Gong",
        "Yuhao Wang",
        "Xuehu Liu",
        "Pingping Zhang",
        "Md Rashidunnabi",
        "Hugo Proen\\c{c}a",
        "Kailash A. Hambarde",
        "Saeid Rezaei"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T10:45:30+00:00",
          "link": "https://arxiv.org/abs/2506.22843v1",
          "size": "19416kb",
          "version": "v1"
        }
      ],
      "title": "AG-VPReID 2025: Aerial-Ground Video-based Person Re-identification Challenge Results",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22843",
        "HTML": "https://arxiv.org/html/2506.22843v1",
        "PDF": "https://arxiv.org/pdf/2506.22843"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22845",
      "abstract": "Quantum Neural Networks (QNNs), a prominent approach in Quantum Machine Learning (QML), are emerging as a powerful alternative to classical machine learning methods. Recent studies have focused on the applicability of QNNs to various tasks, such as time-series forecasting, prediction, and classification, across a wide range of applications, including cybersecurity and medical imaging. With the increased use of smart grids driven by the integration of renewable energy systems, machine learning plays an important role in predicting power demand and detecting system disturbances. This study provides an in-depth investigation of QNNs for predicting the power output of a wind turbine. We assess the predictive performance and simulation time of six QNN configurations that are based on the Z Feature Map for data encoding and varying ansatz structures. Through detailed cross-validation experiments and tests on an unseen hold-out dataset, we experimentally demonstrate that QNNs can achieve predictive performance that is competitive with, and in some cases marginally better than, the benchmarked classical approaches. Our results also reveal the effects of dataset size and circuit complexity on predictive performance and simulation time. We believe our findings will offer valuable insights for researchers in the energy domain who wish to incorporate quantum machine learning into their work.",
      "authors": [
        "Batuhan Hangun",
        "Oguz Altun",
        "Onder Eyecioglu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T10:51:27+00:00",
          "link": "https://arxiv.org/abs/2506.22845v1",
          "size": "27681kb",
          "version": "v1"
        }
      ],
      "title": "Quantum Neural Networks for Wind Energy Forecasting: A Comparative Study of Performance and Scalability with Classical Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22845",
        "HTML": "https://arxiv.org/html/2506.22845v1",
        "PDF": "https://arxiv.org/pdf/2506.22845"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22846",
      "abstract": "End-to-end (E2E) automatic speech recognition (ASR) systems have revolutionized the field by integrating all components into a single neural network, with attention-based encoder-decoder models achieving state-of-the-art performance. However, their autoregressive decoding process limits inference speed, making them unsuitable for real-time applications. In contrast, CTC-based models offer faster, non-autoregressive decoding but struggle to model linguistic dependencies effectively. Addressing this challenge, we propose a novel auxiliary loss framework called Language-Aware Intermediate Loss (LAIL) to enhance CTC-based ASR using the linguistic knowledge of large language models (LLMs). By attaching connector layers to intermediate encoder layers, LAIL maps outputs to the embedding space of an LLM and computes a causal language modeling loss during training. This approach enhances linguistic modeling while preserving the computational efficiency of CTC decoding. Using the Conformer architecture and various LLaMA models, we demonstrate significant improvements in Word Error Rate (WER) on the LibriSpeech, TEDLIUM2, and WSJ corpora, achieving state-of-the-art performance for CTC-based ASR with minimal computational overhead.",
      "authors": [
        "Duygu Altinok"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T10:59:42+00:00",
          "link": "https://arxiv.org/abs/2506.22846v1",
          "size": "151kb",
          "version": "v1"
        }
      ],
      "title": "Boosting CTC-Based ASR Using LLM-Based Intermediate Loss Regularization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22846",
        "HTML": "https://arxiv.org/html/2506.22846v1",
        "PDF": "https://arxiv.org/pdf/2506.22846"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22848",
      "abstract": "Learning the structure of Bayesian networks (BNs) from data is challenging, especially for datasets involving a large number of variables. The recently proposed divide-and-conquer (D\\&D) strategies present a promising approach for learning large BNs. However, they still face a main issue of unstable learning accuracy across subproblems. In this work, we introduce the idea of employing structure learning ensemble (SLE), which combines multiple BN structure learning algorithms, to consistently achieve high learning accuracy. We further propose an automatic approach called Auto-SLE for learning near-optimal SLEs, addressing the challenge of manually designing high-quality SLEs. The learned SLE is then integrated into a D\\&D method. Extensive experiments firmly show the superiority of our method over D\\&D methods with single BN structure learning algorithm in learning large BNs, achieving accuracy improvement usually by 30\\%$\\sim$225\\% on datasets involving 10,000 variables. Furthermore, our method generalizes well to datasets with many more (e.g., 30000) variables and different network characteristics than those present in the training data for learning the SLE. These results indicate the significant potential of employing (automatic learning of) SLEs for scalable BN structure learning.",
      "authors": [
        "Shengcai Liu",
        "Hui Ou-yang",
        "Zhiyuan Wang",
        "Cheng Chen",
        "Qijun Cai",
        "Yew-Soon Ong",
        "Ke Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T11:05:08+00:00",
          "link": "https://arxiv.org/abs/2506.22848v1",
          "size": "1129kb",
          "version": "v1"
        }
      ],
      "title": "Scalable Structure Learning of Bayesian Networks by Learning Algorithm Ensembles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22848",
        "HTML": "https://arxiv.org/html/2506.22848v1",
        "PDF": "https://arxiv.org/pdf/2506.22848"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22849",
      "abstract": "Oriented bounding box (OBB) bounding volume hierarchies offer a more precise fit than axis-aligned bounding box hierarchies in scenarios with thin elongated and arbitrarily rotated geometry, enhancing intersection test performance in ray tracing. However, determining optimally oriented bounding boxes can be computationally expensive and have high memory requirements. Recent research has shown that pre-built hierarchies can be efficiently converted to OBB hierarchies on the GPU in a bottom-up pass, yielding significant ray tracing traversal improvements. In this paper, we introduce a novel OBB construction technique where all internal node children share a consistent OBB transform, chosen from a fixed set of discrete quantized rotations. This allows for efficient encoding and reduces the computational complexity of OBB transformations. We further extend our approach to hierarchies with multiple children per node by leveraging Discrete Orientation Polytopes (k-DOPs), demonstrating improvements in traversal performance while limiting the build time impact for real-time applications. Our method is applied as a post-processing step, integrating seamlessly into existing hierarchy construction pipelines. Despite a 12.6% increase in build time, our experimental results demonstrate an average improvement of 18.5% in primary, 32.4% in secondary rays, and maximum gain of 65% in ray intersection performance, highlighting its potential for advancing real-time applications.",
      "authors": [
        "Michael A. Kern and Alain Galvan and David Oldcorn and Daniel Skinner and Rohan Mehalwal and Leo Reyes Lozano and Matth\\\"aus G. Chajdas"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T11:12:35+00:00",
          "link": "https://arxiv.org/abs/2506.22849v1",
          "size": "29338kb",
          "version": "v1"
        }
      ],
      "title": "DOBB-BVH: Efficient Ray Traversal by Transforming Wide BVHs into Oriented Bounding Box Trees using Discrete Rotations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22849",
        "HTML": "https://arxiv.org/html/2506.22849v1",
        "PDF": "https://arxiv.org/pdf/2506.22849"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22850",
      "abstract": "We present Deep Mesh Denoising Network (DMD-Net), an end-to-end deep learning framework, for solving the mesh denoising problem. DMD-Net consists of a Graph Convolutional Neural Network in which aggregation is performed in both the primal as well as the dual graph. This is realized in the form of an asymmetric two-stream network, which contains a primal-dual fusion block that enables communication between the primal-stream and the dual-stream. We develop a Feature Guided Transformer (FGT) paradigm, which consists of a feature extractor, a transformer, and a denoiser. The feature extractor estimates the local features, that guide the transformer to compute a transformation, which is applied to the noisy input mesh to obtain a useful intermediate representation. This is further processed by the denoiser to obtain the denoised mesh. Our network is trained on a large scale dataset of 3D objects. We perform exhaustive ablation studies to demonstrate that each component in our network is essential for obtaining the best performance. We show that our method obtains competitive or better results when compared with the state-of-the-art mesh denoising algorithms. We demonstrate that our method is robust to various kinds of noise. We observe that even in the presence of extremely high noise, our method achieves excellent performance.",
      "authors": [
        "Aalok Gangopadhyay",
        "Shashikant Verma",
        "Shanmuganathan Raman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T11:13:45+00:00",
          "link": "https://arxiv.org/abs/2506.22850v1",
          "size": "39144kb",
          "version": "v1"
        }
      ],
      "title": "DMD-Net: Deep Mesh Denoising Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22850",
        "HTML": "https://arxiv.org/html/2506.22850v1",
        "PDF": "https://arxiv.org/pdf/2506.22850"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22852",
      "abstract": "Large language models (LLMs) have recently been applied to dialog systems. Despite making progress, LLMs are prone to errors in knowledge-intensive scenarios. Recently, approaches based on retrieval augmented generation (RAG) and agent have emerged to improve the factual accuracy by enhancing the LLMs with knowledge retrieved from external knowledge bases (KBs). This is mostly implemented by prompting the LLMs with instructions, examples and the retrieved knowledge. However, LLMs may have difficulty using the retrieved knowledge effectively for response generation, because they are not well trained to do such generation for specific domains. To mitigate this problem, we propose to finetune the LLMs in the RAG-based and agent-based systems with domain-specific data, together with domain-specific external knowledge, which is called knowledge augmented finetuning (KAFT). We base our study on the MobileCS2 dataset, a real-life customer service dialog dataset that features intensive knowledge interactions, to systematically compare the prompting and KAFT techniques in the RAG-based and agent-based systems. Experiment results show that KAFT substantially surpasses prompting in both RAG and agent systems, particularly in terms of factual accuracy. To the best of our knowledge, this paper represents the first solid empirical work to investigate the KAFT idea.",
      "authors": [
        "Yucheng Cai",
        "Yuxuan Wu",
        "Yi Huang",
        "Junlan Feng",
        "Zhijian Ou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T11:26:31+00:00",
          "link": "https://arxiv.org/abs/2506.22852v1",
          "size": "605kb",
          "version": "v1"
        }
      ],
      "title": "Knowledge Augmented Finetuning Matters in both RAG and Agent Based Dialog Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22852",
        "HTML": "https://arxiv.org/html/2506.22852v1",
        "PDF": "https://arxiv.org/pdf/2506.22852"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22853",
      "abstract": "Existing function-calling benchmarks focus on single-turn interactions. However, they overlook the complexity of real-world scenarios. To quantify how existing benchmarks address practical applications, we introduce DICE-SCORE, a metric that evaluates the dispersion of tool-related information such as function name and parameter values throughout the dialogue. Analyzing existing benchmarks through DICE-SCORE reveals notably low scores, highlighting the need for more realistic scenarios. To address this gap, we present DICE-BENCH, a framework that constructs practical function-calling datasets by synthesizing conversations through a tool graph that maintains dependencies across rounds and a multi-agent system with distinct personas to enhance dialogue naturalness. The final dataset comprises 1,607 high-DICE-SCORE instances. Our experiments on 19 LLMs with DICE-BENCH show that significant advances are still required before such models can be deployed effectively in real-world settings. Our code and data are all publicly available: https://snuhcc.github.io/DICE-Bench/.",
      "authors": [
        "Kyochul Jang",
        "Donghyeon Lee",
        "Kyusik Kim",
        "Dongseok Heo",
        "Taewhoo Lee",
        "Woojeong Kim",
        "Bongwon Suh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T11:28:04+00:00",
          "link": "https://arxiv.org/abs/2506.22853v1",
          "size": "10565kb",
          "version": "v1"
        }
      ],
      "title": "DICE-BENCH: Evaluating the Tool-Use Capabilities of Large Language Models in Multi-Round, Multi-Party Dialogues",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22853",
        "HTML": "https://arxiv.org/html/2506.22853v1",
        "PDF": "https://arxiv.org/pdf/2506.22853"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22855",
      "abstract": "Distributed optimization advances centralized machine learning methods by enabling parallel and decentralized learning processes over a network of computing nodes. This work provides an accelerated consensus-based distributed algorithm for locally non-convex optimization using the gradient-tracking technique. The proposed algorithm (i) improves the convergence rate by adding momentum towards the optimal state using the heavy-ball method, while (ii) addressing general sector-bound nonlinearities over the information-sharing network. The link nonlinearity includes any sign-preserving odd sector-bound mapping, for example, log-scale data quantization or clipping in practical applications. For admissible momentum and gradient-tracking parameters, using perturbation theory and eigen-spectrum analysis, we prove convergence even in the presence of sector-bound nonlinearity and for locally non-convex cost functions. Further, in contrast to most existing weight-stochastic algorithms, we adopt weight-balanced (WB) network design. This WB design and perturbation-based analysis allow to handle dynamic directed network of agents to address possible time-varying setups due to link failures or packet drops.",
      "authors": [
        "Mohammadreza Doostmohammadian",
        "Hamid R. Rabiee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Multiagent Systems (cs.MA)",
        "Systems and Control (cs.SY)",
        "Signal Processing (eess.SP)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T11:38:39+00:00",
          "link": "https://arxiv.org/abs/2506.22855v1",
          "size": "748kb",
          "version": "v1"
        }
      ],
      "title": "Momentum-based Accelerated Algorithm for Distributed Optimization under Sector-Bound Nonlinearity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22855",
        "HTML": "https://arxiv.org/html/2506.22855v1",
        "PDF": "https://arxiv.org/pdf/2506.22855"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22858",
      "abstract": "Automatic Speech Recognition (ASR) systems, such as Whisper, achieve high transcription accuracy but struggle with named entities and numerical data, especially when proper formatting is required. These issues increase word error rate (WER) and impair semantic understanding in critical domains like legal, financial, and medical applications. We propose a novel training approach that extends the semantic context of ASR models by adding overlapping context windows during training. By sliding 5-second overlaps on both sides of 30-second chunks, we create a 40-second \"effective semantic window,\" improving entity recognition and formatting while focusing predictions on the central 30 seconds. To address entities spanning chunk boundaries, we reassign such entities entirely to the right-hand chunk, ensuring proper formatting. Additionally, enriched training data with embedded entity labels enables the model to learn both recognition and type-specific formatting. Evaluated on the Spoken Wikipedia dataset, our method improves performance across semantic tasks, including named entity recognition (NER) and entity formatting. These results highlight the effectiveness of context-aware training in addressing ASR limitations for long-form transcription and complex entity recognition tasks.",
      "authors": [
        "Duygu Altinok"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T11:41:36+00:00",
          "link": "https://arxiv.org/abs/2506.22858v1",
          "size": "2741kb",
          "version": "v1"
        }
      ],
      "title": "Mind the Gap: Entity-Preserved Context-Aware ASR Structured Transcriptions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22858",
        "HTML": "https://arxiv.org/html/2506.22858v1",
        "PDF": "https://arxiv.org/pdf/2506.22858"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22864",
      "abstract": "Text-to-image retrieval (TIR) aims to find relevant images based on a textual query, but existing approaches are primarily based on whole-image captions and lack interpretability. Meanwhile, referring expression segmentation (RES) enables precise object localization based on natural language descriptions but is computationally expensive when applied across large image collections. To bridge this gap, we introduce Mask-aware TIR (MaTIR), a new task that unifies TIR and RES, requiring both efficient image search and accurate object segmentation. To address this task, we propose a two-stage framework, comprising a first stage for segmentation-aware image retrieval and a second stage for reranking and object grounding with a multimodal large language model (MLLM). We leverage SAM 2 to generate object masks and Alpha-CLIP to extract region-level embeddings offline at first, enabling effective and scalable online retrieval. Secondly, MLLM is used to refine retrieval rankings and generate bounding boxes, which are matched to segmentation masks. We evaluate our approach on COCO and D$^3$ datasets, demonstrating significant improvements in both retrieval accuracy and segmentation quality over previous methods.",
      "authors": [
        "Li-Cheng Shen",
        "Jih-Kang Hsieh",
        "Wei-Hua Li",
        "Chu-Song Chen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T12:19:49+00:00",
          "link": "https://arxiv.org/abs/2506.22864v1",
          "size": "1077kb",
          "version": "v1"
        }
      ],
      "title": "Mask-aware Text-to-Image Retrieval: Referring Expression Segmentation Meets Cross-modal Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22864",
        "HTML": "https://arxiv.org/html/2506.22864v1",
        "PDF": "https://arxiv.org/pdf/2506.22864"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22865",
      "abstract": "Recent advancements in Large Language Models (LLMs) have revealed a significant performance gap between closed-source and open-source models, particularly in tasks requiring complex reasoning and precise instruction following. This paper introduces ReasonBridge, a methodology that efficiently transfers reasoning capabilities from powerful closed-source to open-source models through a novel hierarchical knowledge distillation framework. We develop a tailored dataset Reason1K with only 1,000 carefully curated reasoning traces emphasizing difficulty, diversity, and quality. These traces are filtered from across multiple domains using a structured multi-criteria selection algorithm. Our transfer learning approach incorporates: (1) a hierarchical distillation process capturing both strategic abstraction and tactical implementation patterns, (2) a sparse reasoning-focused adapter architecture requiring only 0.3% additional trainable parameters, and (3) a test-time compute scaling mechanism using guided inference interventions. Comprehensive evaluations demonstrate that ReasonBridge improves reasoning capabilities in open-source models by up to 23% on benchmark tasks, significantly narrowing the gap with closed-source models. Notably, the enhanced Qwen2.5-14B outperforms Claude-Sonnet3.5 on MATH500 and matches its performance on competition-level AIME problems. Our methodology generalizes effectively across diverse reasoning domains and model architectures, establishing a sample-efficient approach to reasoning enhancement for instruction following.",
      "authors": [
        "Ziqi Zhong and Xunzhu Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T12:22:55+00:00",
          "link": "https://arxiv.org/abs/2506.22865v1",
          "size": "749kb",
          "version": "v1"
        }
      ],
      "title": "ReasonBridge: Efficient Reasoning Transfer from Closed to Open-Source Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22865",
        "HTML": "https://arxiv.org/html/2506.22865v1",
        "PDF": "https://arxiv.org/pdf/2506.22865"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22866",
      "abstract": "Surface defect detection plays a critical role in industrial quality inspection. Recent advances in artificial intelligence have significantly enhanced the automation level of detection processes. However, conventional semantic segmentation and object detection models heavily rely on large-scale annotated datasets, which conflicts with the practical requirements of defect detection tasks. This paper proposes a novel weakly supervised semantic segmentation framework comprising two key components: a region-aware class activation map (CAM) and pseudo-label training. To address the limitations of existing CAM methods, especially low-resolution thermal maps, and insufficient detail preservation, we introduce filtering-guided backpropagation (FGBP), which refines target regions by filtering gradient magnitudes to identify areas with higher relevance to defects. Building upon this, we further develop a region-aware weighted module to enhance spatial precision. Finally, pseudo-label segmentation is implemented to refine the model's performance iteratively. Comprehensive experiments on industrial defect datasets demonstrate the superiority of our method. The proposed framework effectively bridges the gap between weakly supervised learning and high-precision defect segmentation, offering a practical solution for resource-constrained industrial scenarios.",
      "authors": [
        "Hang-Cheng Dong",
        "Lu Zou",
        "Bingguo Liu",
        "Dong Ye",
        "Guodong Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T12:24:45+00:00",
          "link": "https://arxiv.org/abs/2506.22866v1",
          "size": "8194kb",
          "version": "v1"
        }
      ],
      "title": "Region-Aware CAM: High-Resolution Weakly-Supervised Defect Segmentation via Salient Region Perception",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22866",
        "HTML": "https://arxiv.org/html/2506.22866v1",
        "PDF": "https://arxiv.org/pdf/2506.22866"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22867",
      "abstract": "Classical Cellular Automata (CCAs) are a powerful computational framework for modeling global spatio-temporal dynamics with local interactions. While CCAs have been applied across numerous scientific fields, identifying the local rule that governs observed dynamics remains a challenging task. Moreover, the underlying assumption of deterministic cell states often limits the applicability of CCAs to systems characterized by inherent uncertainty. This study, therefore, focuses on the identification of Cellular Automata on spaces of probability measures (CAMs), where cell states are represented by probability distributions. This framework enables the modeling of systems with probabilistic uncertainty and spatially varying dynamics. Moreover, we formulate the local rule identification problem as a parameter estimation problem and propose a meta-heuristic search based on Self-adaptive Differential Evolution (SaDE) to estimate local rule parameters accurately from the observed data. The efficacy of the proposed approach is demonstrated through local rule identification in two-dimensional CAMs with varying neighborhood types and radii.",
      "authors": [
        "Faizal Hafiz and Amelia Kunze and Enrico Formenti and Davide La Torre"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Information Theory (cs.IT)",
        "Systems and Control (cs.SY)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T12:33:42+00:00",
          "link": "https://arxiv.org/abs/2506.22867v1",
          "size": "3158kb",
          "version": "v1"
        }
      ],
      "title": "Identification of Cellular Automata on Spaces of Bernoulli Probability Measures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22867",
        "HTML": "https://arxiv.org/html/2506.22867v1",
        "PDF": "https://arxiv.org/pdf/2506.22867"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22868",
      "abstract": "Previous text-guided video editing methods often suffer from temporal inconsistency, motion distortion, and-most notably-limited domain transformation. We attribute these limitations to insufficient modeling of spatiotemporal pixel relevance during the editing process. To address this, we propose STR-Match, a training-free video editing algorithm that produces visually appealing and spatiotemporally coherent videos through latent optimization guided by our novel STR score. The score captures spatiotemporal pixel relevance across adjacent frames by leveraging 2D spatial attention and 1D temporal modules in text-to-video (T2V) diffusion models, without the overhead of computationally expensive 3D attention mechanisms. Integrated into a latent optimization framework with a latent mask, STR-Match generates temporally consistent and visually faithful videos, maintaining strong performance even under significant domain transformations while preserving key visual attributes of the source. Extensive experiments demonstrate that STR-Match consistently outperforms existing methods in both visual quality and spatiotemporal consistency.",
      "authors": [
        "Junsung Lee",
        "Junoh Kang",
        "Bohyung Han"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T12:36:19+00:00",
          "link": "https://arxiv.org/abs/2506.22868v1",
          "size": "2154kb",
          "version": "v1"
        }
      ],
      "title": "STR-Match: Matching SpatioTemporal Relevance Score for Training-Free Video Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22868",
        "HTML": "https://arxiv.org/html/2506.22868v1",
        "PDF": "https://arxiv.org/pdf/2506.22868"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22870",
      "abstract": "The landing gear system is a major aircraft subsystem that must withstand extreme forces during ground maneuvers and absorb vibrations. While traditional systems perform well under normal conditions, their efficiency drops under varying landing and runway scenarios. This study addresses this issue by simultaneously optimizing controller coefficients, parameters of a nonlinear hydraulic actuator integrated into the traditional shock absorber, and a vibration absorber using a bee-inspired multi-objective algorithm. To demonstrate adaptability, the paper includes sensitivity analysis for three-point landings affected by added payload and touchdown speed, and robustness analysis for one- and two-point landings under emergency wind conditions. The dynamic flight equations of an Airbus A320-200 during landing are derived and solved numerically. Results show that the active shock absorber system, optimized via two bee-based algorithms, outperforms the passive system in reducing bounce and pitch displacements and momenta, suspension travel, and impact force in both time and frequency domains. This leads to significantly improved passenger comfort and potentially longer structural fatigue life, demonstrating industrial applicability.",
      "authors": [
        "Milad Zarchi",
        "Behrooz Attaran"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T12:43:03+00:00",
          "link": "https://arxiv.org/abs/2506.22870v1",
          "size": "3939kb",
          "version": "v1"
        }
      ],
      "title": "Improved design of an active landing gear for a passenger aircraft using multi-objective optimization technique",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22870",
        "PDF": "https://arxiv.org/pdf/2506.22870"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22871",
      "abstract": "Efficient model distribution is becoming increasingly critical in bandwidth-constrained environments. In this paper, we propose a simple yet effective approach called Progressive Precision Update (P$^2$U) to address this problem. Instead of transmitting the original high-precision model, P$^2$U transmits a lower-bit precision model, coupled with a model update representing the difference between the original high-precision model and the transmitted low precision version. With extensive experiments on various model architectures, ranging from small models ($1 - 6$ million parameters) to a large model (more than $100$ million parameters) and using three different data sets, e.g., chest X-Ray, PASCAL-VOC, and CIFAR-100, we demonstrate that P$^2$U consistently achieves better tradeoff between accuracy, bandwidth usage and latency. Moreover, we show that when bandwidth or startup time is the priority, aggressive quantization (e.g., 4-bit) can be used without severely compromising performance. These results establish P$^2$U as an effective and practical solution for scalable and efficient model distribution in low-resource settings, including federated learning, edge computing, and IoT deployments. Given that P$^2$U complements existing compression techniques and can be implemented alongside any compression method, e.g., sparsification, quantization, pruning, etc., the potential for improvement is even greater.",
      "authors": [
        "Homayun Afrabandpey and Hamed Rezazadegan Tavakoli"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T12:47:04+00:00",
          "link": "https://arxiv.org/abs/2506.22871v1",
          "size": "29kb",
          "version": "v1"
        }
      ],
      "title": "P$^2$U: Progressive Precision Update For Efficient Model Distribution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22871",
        "HTML": "https://arxiv.org/html/2506.22871v1",
        "PDF": "https://arxiv.org/pdf/2506.22871"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22875",
      "abstract": "Developments in communication and automation have driven the expansion of distributed networks, essential for IoT and CPS development in industrial applications requiring reliable image processing and real-time adaptability. Although broadly adopted, there is a literature gap regarding the performance of MQTT protocol for image sharing and transmission under high-traffic scenarios with intermittent connectivity, restricting its use in critical IoT and CPS applications. In this context, the present work examines the reliability of real-time image transmission in IoT and CPS industrial systems that utilize the MQTT-based publish/subscribe communication model. It focuses on scenarios with network interruptions and high data traffic, evaluating the performance of a distributed system through a series of controlled testbed validation experiments. Experimental validation demonstrated that while the MQTT-based system sustains reliable transmission under normal conditions, its recovery capability depends on the failure point, with complete restoration occurring when disruptions affect the Orchestrator Node and partial recovery when the Producer Node or Broker are affected. The study also confirmed that the system prevents duplicate errors and adapts well to increasing network demands, reinforcing its suitability for industrial applications that require efficient and resilient data handling.",
      "authors": [
        "Everson Flores",
        "Bruna Guterres",
        "Thomaz Pereira Junior",
        "Paula Barros",
        "Alberto Cabral",
        "Cristiana Lima Dora",
        "Marcelo Malheiros",
        "Marcelo Pias"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T13:05:17+00:00",
          "link": "https://arxiv.org/abs/2506.22875v1",
          "size": "1171kb",
          "version": "v1"
        }
      ],
      "title": "Reliable Image Transmission in CPS-based Pub/Sub",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22875",
        "HTML": "https://arxiv.org/html/2506.22875v1",
        "PDF": "https://arxiv.org/pdf/2506.22875"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22876",
      "abstract": "Misalignment in multi-agent systems (MAS) is often treated as a technical failure; yet many such failures originate upstream, during the conceptual design phase, where semantic ambiguity and normative projection take place. This paper identifies a foundational source of interpretive misalignment in MAS: the systemic conflation of cooperation and coordination, and the moral overreading that follows. Using the Rabbit-Duck illusion, we illustrate how perspective-dependent readings of agent behavior can create epistemic instability. To address this, we introduce the Misalignment Mosaic, a diagnostic framework for diagnosing meaning-level misalignment in MAS. It comprises four components: 1. Terminological Inconsistency, 2. Concept-to-Code Decay, 3. Morality as Cooperation, and 4. Interpretive Ambiguity. The Mosaic enables researchers to examine how misalignment arises not only through policy or reward structures but also through language, framing, and design assumptions. While this paper focuses on the specific ambiguity between coordination and cooperation, the Mosaic generalizes to other overloaded concepts in MAS, such as alignment, autonomy, and trust. Rather than define cooperation once and for all, we offer a framework to diagnose meaning itself as a source of misalignment.",
      "authors": [
        "Shayak Nandi",
        "Fernanda M. Eliott"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T13:13:33+00:00",
          "link": "https://arxiv.org/abs/2506.22876v1",
          "size": "180kb",
          "version": "v1"
        }
      ],
      "title": "Cooperation as Black Box: Conceptual Fluctuation and Diagnostic Tools for Misalignment in MAS",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22876",
        "HTML": "https://arxiv.org/html/2506.22876v1",
        "PDF": "https://arxiv.org/pdf/2506.22876"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22880",
      "abstract": "Existing video segmenter and grounder approaches, exemplified by Sa2VA, directly fuse features within segmentation models. This often results in an undesirable entanglement of dynamic visual information and static semantics, thereby degrading segmentation accuracy. To systematically mitigate this issue, we propose DeSa2VA, a decoupling-enhanced prompting scheme integrating text pre-training and a linear decoupling module to address the information processing limitations inherent in SAM-2. Specifically, first, we devise a pre-training paradigm that converts textual ground-truth labels into point-level prompts while generating corresponding text masks. These masks are refined through a hybrid loss function to strengthen the model's semantic grounding capabilities. Next, we employ linear projection to disentangle hidden states that generated by a large language model into distinct textual and visual feature subspaces. Finally, a dynamic mask fusion strategy synergistically combines these decoupled features through triple supervision from predicted text/visual masks and ground-truth annotations. Extensive experiments demonstrate state-of-the-art performance across diverse tasks, including image segmentation, image question answering, video segmentation, and video question answering. Our codes are available at https://github.com/longmalongma/DeSa2VA.",
      "authors": [
        "Dang Jisheng (1 and 2)",
        "Wu Xudong (3)",
        "Wang Bimei (4 and 2)",
        "Lv Ning (1)",
        "Chen Jiayu (1)",
        "Jingwen Zhao (3)",
        "Yichu liu (5)",
        "Jizhao Liu (1)",
        "Juncheng Li (6)",
        "Teng Wang (7) ((1) Lanzhou University",
        "(2) National University of Singapore",
        "(3) Sun Yat-sen University",
        "(4) Jinan University",
        "(5) South China University of Technology",
        "(6) Zhejiang University",
        "(7) The University of Hong Kong )"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T13:30:36+00:00",
          "link": "https://arxiv.org/abs/2506.22880v1",
          "size": "2720kb",
          "version": "v1"
        }
      ],
      "title": "Decoupled Seg Tokens Make Stronger Reasoning Video Segmenter and Grounder",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22880",
        "HTML": "https://arxiv.org/html/2506.22880v1",
        "PDF": "https://arxiv.org/pdf/2506.22880"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22881",
      "abstract": "Contrastive learning has the capacity to model multimodal probability distributions by embedding and aligning visual representations with semantics from captions. This approach enables the estimation of relational semantic similarity; however, it remains unclear whether it can also represent absolute semantic informativeness. In this work, we introduce a semantic informativeness metric for an image calculated from text samples via a contrastive learning model; similarly, the informativeness of a text is calculated from image samples. We propose a redefinition of the concept of Information Gain, a concept previously explored in natural language processing, extending its application to the domains of vision and language. Our metric quantifies how conditioning on an image distorts the distribution of associated texts, and vice versa for text conditioning on image distributions. In OpenCLIP's empirical results, we observe that images with the lowest Information Gain scores often correspond to placeholder icons such as \"image not found.\" Furthermore, we propose to measure a norm-based metric of the embedding to estimate the Information Gain, following the theoretical results for Skip-Gram with Negative Sampling (SGNS) word embedding. Information Gain can be measured using either CLIP or SigLIP, and the results demonstrate a strong correlation with a coefficient of determination ranging from 0.98 to 1.00. After obtaining the mean and the covariance of the sample embedding, the computational cost of this method is independent of the sample size, and it is compatible with publicly available, open-weight models.",
      "authors": [
        "Fumiya Uchiyama",
        "Rintaro Yanagi",
        "Shohei Taniguchi",
        "Shota Takashiro",
        "Masahiro Suzuki",
        "Hirokatsu Kataoka",
        "Yusuke Iwasawa",
        "Yutaka Matsuo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T13:36:44+00:00",
          "link": "https://arxiv.org/abs/2506.22881v1",
          "size": "806kb",
          "version": "v1"
        }
      ],
      "title": "How Semantically Informative is an Image?: Measuring the Covariance-Weighted Norm of Contrastive Learning Embeddings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22881",
        "HTML": "https://arxiv.org/html/2506.22881v1",
        "PDF": "https://arxiv.org/pdf/2506.22881"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22884",
      "abstract": "Over the Eight decades, computing paradigms have shifted from large, centralized systems to compact, distributed architectures, leading to the rise of the Distributed Computing Continuum (DCC). In this model, multiple layers such as cloud, edge, Internet of Things (IoT), and mobile platforms work together to support a wide range of applications. Recently, the emergence of Generative AI and large language models has further intensified the demand for computational resources across this continuum. Although traditional performance metrics have provided a solid foundation, they need to be revisited and expanded to keep pace with changing computational demands and application requirements. Accurate performance measurements benefit both system designers and users by supporting improvements in efficiency and promoting alignment with system goals. In this context, we review commonly used metrics in DCC and IoT environments. We also discuss emerging performance dimensions that address evolving computing needs, such as sustainability, energy efficiency, and system observability. We also outline criteria and considerations for selecting appropriate metrics, aiming to inspire future research and development in this critical area.",
      "authors": [
        "Praveen Kumar Donta",
        "Qiyang Zhang",
        "Schahram Dustdar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)",
        "Networking and Internet Architecture (cs.NI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T13:46:07+00:00",
          "link": "https://arxiv.org/abs/2506.22884v1",
          "size": "2539kb",
          "version": "v1"
        }
      ],
      "title": "Performance Measurements in the AI-Centric Computing Continuum Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22884",
        "HTML": "https://arxiv.org/html/2506.22884v1",
        "PDF": "https://arxiv.org/pdf/2506.22884"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22890",
      "abstract": "Collaborative Perception (CP) has been shown to be a promising technique for multi-agent autonomous driving and multi-agent robotic systems, where multiple agents share their perception information to enhance the overall perception performance and expand the perception range. However, in CP, an ego agent needs to receive messages from its collaborators, which makes it vulnerable to attacks from malicious agents. To address this critical issue, we propose a unified, probability-agnostic, and adaptive framework, namely, CP-Guard, which is a tailored defense mechanism for CP deployed by each agent to accurately detect and eliminate malicious agents in its collaboration network. Our key idea is to enable CP to reach a consensus rather than a conflict against an ego agent's perception results. Based on this idea, we first develop a probability-agnostic sample consensus (PASAC) method to effectively sample a subset of the collaborators and verify the consensus without prior probabilities of malicious agents. Furthermore, we define collaborative consistency loss (CCLoss) for object detection task and bird's eye view (BEV) segmentation task to capture the discrepancy between an ego agent and its collaborators, which is used as a verification criterion for consensus. In addition, we propose online adaptive threshold via dual sliding windows to dynamically adjust the threshold for consensus verification and ensure the reliability of the systems in dynamic environments. Finally, we conduct extensive experiments and demonstrate the effectiveness of our framework. Code will be released at https://github.com/CP-Security/CP-Guard",
      "authors": [
        "Senkang Hu",
        "Yihang Tao",
        "Guowen Xu",
        "Xinyuan Qian",
        "Yiqin Deng",
        "Xianhao Chen",
        "Sam Tak Wu Kwong",
        "Yuguang Fang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T14:02:14+00:00",
          "link": "https://arxiv.org/abs/2506.22890v1",
          "size": "8368kb",
          "version": "v1"
        }
      ],
      "title": "CP-Guard: A Unified, Probability-Agnostic, and Adaptive Framework for Malicious Agent Detection and Defense in Multi-Agent Embodied Perception Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22890",
        "HTML": "https://arxiv.org/html/2506.22890v1",
        "PDF": "https://arxiv.org/pdf/2506.22890"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22893",
      "abstract": "After a very long winter, the Artificial Intelligence (AI) spring is here. Or, so it seems over the last three years. AI has the potential to impact many areas of human life - personal, social, health, education, professional. In this paper, we take a closer look at the potential of AI for Enterprises, where decision-making plays a crucial and repeated role across functions, tasks, and operations. We consider Agents imbued with AI as means to increase decision-productivity of enterprises. We highlight six tenets for Agentic success in enterprises, by drawing attention to what the current, AI-Centric User paradigm misses, in the face of persistent needs of and usefulness for Enterprise Decision-Making. In underscoring a shift to User-Centric AI, we offer six tenets and promote market mechanisms for platforms, aligning the design of AI and its delivery by Agents to the cause of enterprise users.",
      "authors": [
        "Arpit Narechania and Alex Endert and Atanu R Sinha"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T14:05:59+00:00",
          "link": "https://arxiv.org/abs/2506.22893v1",
          "size": "481kb",
          "version": "v1"
        }
      ],
      "title": "Agentic Enterprise: AI-Centric User to User-Centric AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22893",
        "HTML": "https://arxiv.org/html/2506.22893v1",
        "PDF": "https://arxiv.org/pdf/2506.22893"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22894",
      "abstract": "Autonomous drifting is a complex and crucial maneuver for safety-critical scenarios like slippery roads and emergency collision avoidance, requiring precise motion planning and control. Traditional motion planning methods often struggle with the high instability and unpredictability of drifting, particularly when operating at high speeds. Recent learning-based approaches have attempted to tackle this issue but often rely on expert knowledge or have limited exploration capabilities. Additionally, they do not effectively address safety concerns during learning and deployment. To overcome these limitations, we propose a novel Safe Reinforcement Learning (RL)-based motion planner for autonomous drifting. Our approach integrates an RL agent with model-based drift dynamics to determine desired drift motion states, while incorporating a Predictive Safety Filter (PSF) that adjusts the agent's actions online to prevent unsafe states. This ensures safe and efficient learning, and stable drift operation. We validate the effectiveness of our method through simulations on a Matlab-Carsim platform, demonstrating significant improvements in drift performance, reduced tracking errors, and computational efficiency compared to traditional methods. This strategy promises to extend the capabilities of autonomous vehicles in safety-critical maneuvers.",
      "authors": [
        "Bei Zhou",
        "Baha Zarrouki",
        "Mattia Piccinini",
        "Cheng Hu",
        "Lei Xie",
        "Johannes Betz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T14:10:32+00:00",
          "link": "https://arxiv.org/abs/2506.22894v1",
          "size": "1001kb",
          "version": "v1"
        }
      ],
      "title": "Safe Reinforcement Learning with a Predictive Safety Filter for Motion Planning and Control: A Drifting Vehicle Example",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22894",
        "HTML": "https://arxiv.org/html/2506.22894v1",
        "PDF": "https://arxiv.org/pdf/2506.22894"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22895",
      "abstract": "Time series autoregression is a classical statistical model for capturing auto-correlations and identifying temporal patterns such as periodicity and seasonality. In this work, we propose a novel sparse autoregression framework from an interpretable machine learning perspective and the model interpretability for periodicity quantification is reinforced by $\\ell_0$-norm induced sparsity constraints. On the time-varying time series data, we reformulate the sparse autoregression and convert the involved optimization problem into a mixed-integer optimization (MIO). To accelerate it, we develop a subspace pursuit based decision variable pruning (DVP) strategy to reduce the search space. On the multidimensional time series that involves complicated spatial and temporal dimensions, we propose a spatially- and time-varying sparse autoregression model and resolve the corresponding MIO problem by developing a two-stage optimization scheme. In particular, the proposed scheme makes the model scalable to large problems even with millions of decision variables. Empirically, we conduct extensive experiments to evaluate the proposed models on real-world time series data. First, we demonstrate that the MIO solver can be drastically accelerated through the DVP strategy, while maintaining the same solution quality as a full MIO solver. Applying the time-varying sparse autoregression model to ridesharing trip data, we uncover both daily and weekly periodicities and reveal long-term changes in regularity of human mobility. Second, we demonstrate the spatial patterns of yearly seasonality in climate variable time series such as temperature and precipitation across the past four decades, and our model allows to discover dynamic climate patterns and identify climate phenomena such as El Nino in sea surface temperature.",
      "authors": [
        "Xinyu Chen",
        "Vassilis Digalakis Jr",
        "Lijun Ding",
        "Dingyi Zhuang",
        "Jinhua Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T14:17:11+00:00",
          "link": "https://arxiv.org/abs/2506.22895v1",
          "size": "7486kb",
          "version": "v1"
        }
      ],
      "title": "Interpretable Time Series Autoregression for Periodicity Quantification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22895",
        "HTML": "https://arxiv.org/html/2506.22895v1",
        "PDF": "https://arxiv.org/pdf/2506.22895"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22899",
      "abstract": "Neural Cellular Automata (NCAs) are bio-inspired systems in which identical cells self-organize to form complex and coherent patterns by repeatedly applying simple local rules. NCAs display striking emergent behaviors including self-regeneration, generalization and robustness to unseen situations, and spontaneous motion. Despite their success in texture synthesis and morphogenesis, NCAs remain largely confined to low-resolution grids. This limitation stems from (1) training time and memory requirements that grow quadratically with grid size, (2) the strictly local propagation of information which impedes long-range cell communication, and (3) the heavy compute demands of real-time inference at high resolution. In this work, we overcome this limitation by pairing NCA with a tiny, shared implicit decoder, inspired by recent advances in implicit neural representations. Following NCA evolution on a coarse grid, a lightweight decoder renders output images at arbitrary resolution. We also propose novel loss functions for both morphogenesis and texture synthesis tasks, specifically tailored for high-resolution output with minimal memory and computation overhead. Combining our proposed architecture and loss functions brings substantial improvement in quality, efficiency, and performance. NCAs equipped with our implicit decoder can generate full-HD outputs in real time while preserving their self-organizing, emergent properties. Moreover, because each MLP processes cell states independently, inference remains highly parallelizable and efficient. We demonstrate the applicability of our approach across multiple NCA variants (on 2D, 3D grids, and 3D meshes) and multiple tasks, including texture generation and morphogenesis (growing patterns from a seed), showing that with our proposed framework, NCAs seamlessly scale to high-resolution outputs with minimal computational overhead.",
      "authors": [
        "Ehsan Pajouheshgar",
        "Yitao Xu",
        "Ali Abbasi",
        "Alexander Mordvintsev",
        "Wenzel Jakob",
        "Sabine S\\\"usstrunk"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)",
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T14:30:21+00:00",
          "link": "https://arxiv.org/abs/2506.22899v1",
          "size": "30917kb",
          "version": "v1"
        }
      ],
      "title": "Neural Cellular Automata: From Cells to Pixels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22899",
        "HTML": "https://arxiv.org/html/2506.22899v1",
        "PDF": "https://arxiv.org/pdf/2506.22899"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22900",
      "abstract": "Medical visual question answering (MedVQA) plays a vital role in clinical decision-making by providing contextually rich answers to image-based queries. Although vision-language models (VLMs) are widely used for this task, they often generate factually incorrect answers. Retrieval-augmented generation addresses this challenge by providing information from external sources, but risks retrieving irrelevant context, which can degrade the reasoning capabilities of VLMs. Re-ranking retrievals, as introduced in existing approaches, enhances retrieval relevance by focusing on query-text alignment. However, these approaches neglect the visual or multimodal context, which is particularly crucial for medical diagnosis. We propose MOTOR, a novel multimodal retrieval and re-ranking approach that leverages grounded captions and optimal transport. It captures the underlying relationships between the query and the retrieved context based on textual and visual information. Consequently, our approach identifies more clinically relevant contexts to augment the VLM input. Empirical analysis and human expert evaluation demonstrate that MOTOR achieves higher accuracy on MedVQA datasets, outperforming state-of-the-art methods by an average of 6.45%. Code is available at https://github.com/BioMedIA-MBZUAI/MOTOR.",
      "authors": [
        "Mai A. Shaaban",
        "Tausifa Jan Saleem",
        "Vijay Ram Papineni",
        "Mohammad Yaqub"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T14:30:37+00:00",
          "link": "https://arxiv.org/abs/2506.22900v1",
          "size": "10871kb",
          "version": "v1"
        }
      ],
      "title": "MOTOR: Multimodal Optimal Transport via Grounded Retrieval in Medical Visual Question Answering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22900",
        "HTML": "https://arxiv.org/html/2506.22900v1",
        "PDF": "https://arxiv.org/pdf/2506.22900"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22901",
      "abstract": "A key challenge in learning from multimodal biological data is missing modalities, where all data from some modalities are missing for some patients. Current fusion methods address this by excluding patients with missing modalities, imputing missing modalities, or making predictions directly with partial modalities. However, they often struggle with diverse missing-modality patterns and the exponential growth of the number of such patterns as the number of modalities increases. To address these limitations, we propose MAGNET (Missing-modality-Aware Graph neural NETwork) for direct prediction with partial modalities, which introduces a patient-modality multi-head attention mechanism to fuse lower-dimensional modality embeddings based on their importance and missingness. MAGNET's complexity increases linearly with the number of modalities while adapting to missing-pattern variability. To generate predictions, MAGNET further constructs a patient graph with fused multimodal embeddings as node features and the connectivity determined by the modality missingness, followed by a conventional graph neural network. Experiments on three public multiomics datasets for cancer classification, with real-world instead of artificial missingness, show that MAGNET outperforms the state-of-the-art fusion methods. The data and code are available at https://github.com/SinaTabakhi/MAGNET.",
      "authors": [
        "Sina Tabakhi",
        "Haiping Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Biomolecules (q-bio.BM)",
        "Genomics (q-bio.GN)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T14:31:00+00:00",
          "link": "https://arxiv.org/abs/2506.22901v1",
          "size": "1291kb",
          "version": "v1"
        }
      ],
      "title": "Missing-Modality-Aware Graph Neural Network for Cancer Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22901",
        "HTML": "https://arxiv.org/html/2506.22901v1",
        "PDF": "https://arxiv.org/pdf/2506.22901"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22902",
      "abstract": "The rapid growth of 3D point cloud data, driven by applications in autonomous driving, robotics, and immersive environments, has led to criticals demand for efficient compression and quality assessment techniques. Unlike traditional 2D media, point clouds present unique challenges due to their irregular structure, high data volume, and complex attributes. This paper provides a comprehensive survey of recent advances in point cloud compression (PCC) and point cloud quality assessment (PCQA), emphasizing their significance for real-time and perceptually relevant applications. We analyze a wide range of handcrafted and learning-based PCC algorithms, along with objective PCQA metrics. By benchmarking representative methods on emerging datasets, we offer detailed comparisons and practical insights into their strengths and limitations. Despite notable progress, challenges such as enhancing visual fidelity, reducing latency, and supporting multimodal data remain. This survey outlines future directions, including hybrid compression frameworks and advanced feature extraction strategies, to enable more efficient, immersive, and intelligent 3D applications.",
      "authors": [
        "Yiling Xu",
        "Yujie Zhang",
        "Shuting Xia",
        "Kaifa Yang",
        "He Huang",
        "Ziyu Shan",
        "Wenjie Huang",
        "Qi Yang",
        "Le Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T14:34:24+00:00",
          "link": "https://arxiv.org/abs/2506.22902v1",
          "size": "1118kb",
          "version": "v1"
        }
      ],
      "title": "Point Cloud Compression and Objective Quality Assessment: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22902",
        "HTML": "https://arxiv.org/html/2506.22902v1",
        "PDF": "https://arxiv.org/pdf/2506.22902"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22907",
      "abstract": "This paper proposes a novel method called MagShield, designed to address the issue of magnetic interference in sparse inertial motion capture (MoCap) systems. Existing Inertial Measurement Unit (IMU) systems are prone to orientation estimation errors in magnetically disturbed environments, limiting their practical application in real-world scenarios. To address this problem, MagShield employs a \"detect-then-correct\" strategy, first detecting magnetic disturbances through multi-IMU joint analysis, and then correcting orientation errors using human motion priors. MagShield can be integrated with most existing sparse inertial MoCap systems, improving their performance in magnetically disturbed environments. Experimental results demonstrate that MagShield significantly enhances the accuracy of motion capture under magnetic interference and exhibits good compatibility across different sparse inertial MoCap systems.",
      "authors": [
        "Yunzhe Shao",
        "Xinyu Yi",
        "Lu Yin",
        "Shihui Guo",
        "Junhai Yong",
        "Feng Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T14:42:59+00:00",
          "link": "https://arxiv.org/abs/2506.22907v1",
          "size": "3885kb",
          "version": "v1"
        }
      ],
      "title": "MagShield: Towards Better Robustness in Sparse Inertial Motion Capture Under Magnetic Disturbances",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22907",
        "HTML": "https://arxiv.org/html/2506.22907v1",
        "PDF": "https://arxiv.org/pdf/2506.22907"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22908",
      "abstract": "Visual Prompt Tuning (VPT) is a parameter-efficient fune-tuning technique that adapts a pre-trained vision Transformer (ViT) by learning a small set of parameters in the input space, known as prompts. In VPT, we uncover ``burstiness'' in the values arising from the interaction of image patch embeddings, and the key and query projectors within Transformer's self-attention module. Furthermore, the values of patch embeddings and the key and query projectors exhibit Laplacian and hyper-Laplacian distribution, respectively. Intuitively, these non-Gaussian distributions pose challenges for learning prompts. To address this, we propose whitening these data, de-correlating them and equalizing their variance towards more Gaussian before learning prompts. We derive the whitening matrix over random image patch embeddings and ViT's key and query projectors, and multiply it with the prompt to be learned in a bilinear manner. Surprisingly, this method significantly accelerates prompt tuning and boosts accuracy, e.g., $>$25 accuracy points on the CUB dataset; interestingly, it learns ``bursty prompts''. Extending the bilinear model which is known to introduce burstiness, we present a compact, low-rank version by learning two smaller matrices whose multiplication yields the final prompts. We call the proposed methods Bilinear Prompt Tuning (BPT). Extensive experiments across multiple benchmark datasets demonstrate that BPT methods not only outperform various VPT methods but also reduce parameter count and computation overhead.",
      "authors": [
        "Yuzhu Wang",
        "Manni Duan",
        "Shu Kong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T14:45:37+00:00",
          "link": "https://arxiv.org/abs/2506.22908v1",
          "size": "6768kb",
          "version": "v1"
        }
      ],
      "title": "Attention to Burstiness: Low-Rank Bilinear Prompt Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22908",
        "HTML": "https://arxiv.org/html/2506.22908v1",
        "PDF": "https://arxiv.org/pdf/2506.22908"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22911",
      "abstract": "This paper introduces TEDI (Truthful, Expressive, and Dimension-Insensitive approach), a discretization-free algorithm to learn truthful and utility-maximizing mechanisms. Existing learning-based approaches often rely on discretization of outcome spaces to ensure truthfulness, which leads to inefficiency with increasing problem size. To address this limitation, we formalize the concept of pricing rules, defined as functions that map outcomes to prices. Based on this concept, we propose a novel menu mechanism, which can be equivalent to a truthful direct mechanism under specific conditions. The core idea of TEDI lies in its parameterization of pricing rules using Partial GroupMax Network, a new network architecture designed to universally approximate partial convex functions. To learn optimal pricing rules, we develop novel training techniques, including covariance trick and continuous sampling, to derive unbiased gradient estimators compatible with first-order optimization. Theoretical analysis establishes that TEDI guarantees truthfulness, full expressiveness, and dimension-insensitivity. Experimental evaluation in the studied auction setting demonstrates that TEDI achieves strong performance, competitive with or exceeding state-of-the-art methods.\n  This work presents the first approaches to learn truthful mechanisms without outcome discretization, thereby enhancing algorithmic efficiency. The proposed concepts, network architecture, and learning techniques might offer potential value and provide new insights for automated mechanism design and differentiable economics.",
      "authors": [
        "Yunxuan Ma",
        "Siqiang Wang",
        "Zhijian Duan",
        "Yukun Cheng",
        "Xiaotie Deng"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T14:50:29+00:00",
          "link": "https://arxiv.org/abs/2506.22911v1",
          "size": "7932kb",
          "version": "v1"
        }
      ],
      "title": "Learning Truthful Mechanisms without Discretization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22911",
        "HTML": "https://arxiv.org/html/2506.22911v1",
        "PDF": "https://arxiv.org/pdf/2506.22911"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22912",
      "abstract": "Many numerical methods for multiscale differential equations require a scale separation between the larger and the smaller scales to achieve accuracy and computational efficiency. In the area of multiscale dynamical systems, so-called, seamless methods have been introduced to reduce the requirement of scale separation. We will translate these methods to numerical homogenization problems and extend the technique to multiple dimensions. The initial step is to prove that a one-dimensional \\sepia{second-order} elliptic operator with oscillatory coefficients can be rewritten as a multiscale dynamical system. Inspired by this, multiscale elliptic operators in higher dimensions are approximated by a novel approach based on local dilation, which provides a middle ground for balancing intractability and accuracy without the need for full resolution. The dilation operator can be further generalized to preserve important structures by properly decomposing the coefficient field. Error estimates are developed and promising numerical results of different examples are included.",
      "authors": [
        "Ziheng Chen",
        "Bj\\\"orn Engquist"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T14:52:08+00:00",
          "link": "https://arxiv.org/abs/2506.22912v1",
          "size": "908kb",
          "version": "v1"
        }
      ],
      "title": "A Dilation-based Seamless Multiscale Method For Elliptic Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22912",
        "HTML": "https://arxiv.org/html/2506.22912v1",
        "PDF": "https://arxiv.org/pdf/2506.22912"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22918",
      "abstract": "We develop a framework for the compression of reversible Markov chains with rigorous error control. Given a subset of selected states, we construct reduced dynamics that can be lifted to an approximation of the full dynamics, and we prove simple spectral and nuclear norm bounds on the recovery error in terms of a suitably interpreted Nystr\\\"{o}m approximation error. We introduce two compression schemes: a projective compression based on committor functions and a structure-preserving compression defined in terms of an induced Markov chain over the selected states. The Nystr\\\"{o}m error appearing in our bounds can be controlled using recent results on column subset selection by nuclear maximization. Numerical experiments validate our theory and demonstrate the scalability of our approach.",
      "authors": [
        "Mark Fornace and Michael Lindsey"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T15:02:48+00:00",
          "link": "https://arxiv.org/abs/2506.22918v1",
          "size": "861kb",
          "version": "v1"
        }
      ],
      "title": "An approximation theory for Markov chain compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22918",
        "HTML": "https://arxiv.org/html/2506.22918v1",
        "PDF": "https://arxiv.org/pdf/2506.22918"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22919",
      "abstract": "Mixture-of-Experts (MoE) models enable conditional computation by routing inputs to specialized experts, but these experts rely on identical inductive biases, thus limiting representational diversity. This static computation pathway is inefficient for inputs that require different types of reasoning and limits specialization and interpretability. We propose Hecto, a lightweight MoE architecture that leverages architectural heterogeneity by combining a GRU expert for temporal reasoning and an FFNN expert for static abstraction under a sparse Top-1 gating mechanism. Evaluated on three reasoning benchmarks (AG News, SST-2, HotpotQA) and a regression task (STS-B), Hecto matches or closely trails homogeneous baselines in performance despite receiving isolated input representations, while achieving clear expert specialization, with each expert aligning to distinct reasoning types (temporal vs static). At larger batch sizes, Hecto exhibits improved performance, benefiting from relaxed computational constraints that allow its heterogeneous architecture to optimize more effectively. Ablation results isolate architectural diversity as the source of Hecto's stability and interpretability across diverse reasoning tasks. Overall, Hecto establishes itself as a new benchmark for conditional computation, offering a principled framework for specialized reasoning in low-resource regimes with its model strength derived from principled specialization.",
      "authors": [
        "Sanskar Pandey and Ruhaan Chopra and Saad Murtaza Bhat and Ark Abhyudaya"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T15:03:43+00:00",
          "link": "https://arxiv.org/abs/2506.22919v1",
          "size": "646kb",
          "version": "v1"
        }
      ],
      "title": "Hecto: Modular Sparse Experts for Adaptive and Interpretable Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22919",
        "HTML": "https://arxiv.org/html/2506.22919v1",
        "PDF": "https://arxiv.org/pdf/2506.22919"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22920",
      "abstract": "Large language models (LLMs) have demonstrated considerable reasoning abilities in various tasks such as mathematics and coding. However, recent studies indicate that even the best models lack true comprehension of their reasoning processes. In this paper, we explore how self-play can enhance the rationality of models in the reasoning process without supervision from humans or superior models. We design a Critic-Discernment Game(CDG) in which a prover first provides a solution to a given problem and is subsequently challenged by critiques of its solution. These critiques either aim to assist or mislead the prover. The objective of the prover is to maintain the correct answer when faced with misleading comments, while correcting errors in response to constructive feedback. Our experiments on tasks involving mathematical reasoning, stepwise error detection, self-correction, and long-chain reasoning demonstrate that CDG training can significantly improve the ability of well-aligned LLMs to comprehend their reasoning process.",
      "authors": [
        "Pinzheng Wang",
        "Juntao Li",
        "Zecheng Tang",
        "Haijia Gui",
        "Min zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T15:11:23+00:00",
          "link": "https://arxiv.org/abs/2506.22920v1",
          "size": "338kb",
          "version": "v1"
        }
      ],
      "title": "Improving Rationality in the Reasoning Process of Language Models through Self-playing Game",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22920",
        "HTML": "https://arxiv.org/html/2506.22920v1",
        "PDF": "https://arxiv.org/pdf/2506.22920"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22922",
      "abstract": "We present an improved solution to the Weighted Job Scheduling (WJS) problem. While the classical dynamic programming (DP) solution runs in $O(n \\log(n))$ time due to comparison-based sorting and per-job binary search, we eliminate the binary search bottleneck. In its place, we introduce a novel multi-phase preprocessing technique called Global Predecessor Indexing (GPI), which computes the latest non-overlapping job (i.e., the predecessor) for all jobs via a two-pointer linear-time pass. GPI enables direct use in the classical DP recurrence. When combined with linear-time sorting, GPI yields a complete $O(n)$ solution. Even with comparison-based sorting, GPI significantly outperforms the classical solution in practice by avoiding repeated binary searches. Keywords: Weighted Job Scheduling, Interval Scheduling, Dynamic Programming, Linear Sorting, Two Pointers, Preprocessing",
      "authors": [
        "Amit Joshi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T15:15:31+00:00",
          "link": "https://arxiv.org/abs/2506.22922v1",
          "size": "87kb",
          "version": "v1"
        }
      ],
      "title": "Global Predecessor Indexing: Avoiding Binary Search in Weighted Job Scheduling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22922",
        "HTML": "https://arxiv.org/html/2506.22922v1",
        "PDF": "https://arxiv.org/pdf/2506.22922"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22926",
      "abstract": "Volumetric medical imaging technologies produce detailed 3D representations of anatomical structures. However, effective medical data visualization and exploration pose significant challenges, especially for individuals with limited medical expertise. We introduce a novel XR-based system with two key innovations: (1) a coordinated visualization module integrating Multi-layered Multi-planar Reconstruction with 3D mesh models and (2) a multimodal interaction framework combining hand gestures with LLM-enabled voice commands. We conduct preliminary evaluations, including a 15-participant user study and expert interviews, to demonstrate the system's abilities to enhance spatial understanding and reduce cognitive load. Experimental results show notable improvements in task completion times, usability metrics, and interaction effectiveness enhanced by LLM-driven voice control. While identifying areas for future refinement, our findings highlight the potential of this immersive visualization system to advance medical training and clinical practice. Our demo application and supplemental materials are available for download at: https://osf.io/bpjq5/.",
      "authors": [
        "Qixuan Liu",
        "Shi Qiu",
        "Yinqiao Wang",
        "Xiwen Wu",
        "Kenneth Siu Ho Chok",
        "Chi-Wing Fu",
        "Pheng-Ann Heng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Graphics (cs.GR)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T15:23:13+00:00",
          "link": "https://arxiv.org/abs/2506.22926v1",
          "size": "5140kb",
          "version": "v1"
        }
      ],
      "title": "Coordinated 2D-3D Visualization of Volumetric Medical Data in XR with Multimodal Interactions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22926",
        "HTML": "https://arxiv.org/html/2506.22926v1",
        "PDF": "https://arxiv.org/pdf/2506.22926"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22927",
      "abstract": "Generative Artificial Intelligence (AI) has rapidly become a powerful tool, capable of generating various types of data, such as images and text. However, despite the significant advancement of generative AI, time series generative AI remains underdeveloped, even though the application of time series is essential in finance, climate, and numerous fields. In this research, we propose a novel method of generating time series conditioned on unstructured natural language descriptions. We use a diffusion model combined with a language model to generate time series from the text. Through the proposed method, we demonstrate that time series generation based on natural language is possible. The proposed method can provide various applications such as custom forecasting, time series manipulation, data augmentation, and transfer learning. Furthermore, we construct and propose a new public dataset for time series generation, consisting of 63,010 time series-description pairs.",
      "authors": [
        "Jaeyun Woo",
        "Jiseok Lee",
        "Brian Kenji Iwana"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T15:28:01+00:00",
          "link": "https://arxiv.org/abs/2506.22927v1",
          "size": "1323kb",
          "version": "v1"
        }
      ],
      "title": "Towards Time Series Generation Conditioned on Unstructured Natural Language",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22927",
        "HTML": "https://arxiv.org/html/2506.22927v1",
        "PDF": "https://arxiv.org/pdf/2506.22927"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22929",
      "abstract": "While deep learning excels in natural image and language processing, its application to high-dimensional data faces computational challenges due to the dimensionality curse. Current large-scale data tools focus on business-oriented descriptive statistics, lacking mathematical statistics support for advanced analysis. We propose a parallel computation architecture based on space completeness, decomposing high-dimensional data into dimension-independent structures for distributed processing. This framework enables seamless integration of data mining and parallel-optimized machine learning methods, supporting scientific computations across diverse data types like medical and natural images within a unified system.",
      "authors": [
        "Chen Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Image and Video Processing (eess.IV)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T15:42:23+00:00",
          "link": "https://arxiv.org/abs/2506.22929v1",
          "size": "673kb",
          "version": "v1"
        }
      ],
      "title": "Mathematical Computation on High-dimensional Data via Array Programming and Parallel Acceleration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22929",
        "HTML": "https://arxiv.org/html/2506.22929v1",
        "PDF": "https://arxiv.org/pdf/2506.22929"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22930",
      "abstract": "The increasing realism of multimodal content has made misinformation more subtle and harder to detect, especially in news media where images are frequently paired with bilingual (e.g., Chinese-English) subtitles. Such content often includes localized image edits and cross-lingual inconsistencies that jointly distort meaning while remaining superficially plausible. We introduce BiMi, a bilingual multimodal framework that jointly performs region-level localization, cross-modal and cross-lingual consistency detection, and natural language explanation for misinformation analysis. To support generalization, BiMi integrates an online retrieval module that supplements model reasoning with up-to-date external context. We further release BiMiBench, a large-scale and comprehensive benchmark constructed by systematically editing real news images and subtitles, comprising 104,000 samples with realistic manipulations across visual and linguistic modalities. To enhance interpretability, we apply Group Relative Policy Optimization (GRPO) to improve explanation quality, marking the first use of GRPO in this domain. Extensive experiments demonstrate that BiMi outperforms strong baselines by up to +8.9 in classification accuracy, +15.9 in localization accuracy, and +2.5 in explanation BERTScore, advancing state-of-the-art performance in realistic, multilingual misinformation detection. Code, models, and datasets will be released.",
      "authors": [
        "Yiwei He",
        "Xiangtai Li",
        "Zhenglin Huang",
        "Yi Dong",
        "Hao Fei",
        "Jiangning Zhang",
        "Baoyuan Wu",
        "Guangliang Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T15:43:06+00:00",
          "link": "https://arxiv.org/abs/2506.22930v1",
          "size": "37595kb",
          "version": "v1"
        }
      ],
      "title": "Towards Explainable Bilingual Multimodal Misinformation Detection and Localization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22930",
        "HTML": "https://arxiv.org/html/2506.22930v1",
        "PDF": "https://arxiv.org/pdf/2506.22930"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22931",
      "abstract": "This study presents a real-time energy management framework for hybrid community microgrids integrating photovoltaic, wind, battery energy storage systems, diesel generators, and grid interconnection. The proposed approach formulates the dispatch problem as a multi-objective optimization task that aims to minimize operational costs. Two control strategies are proposed and evaluated: a conventional rule-based control (RBC) method and an advanced deep reinforcement learning (DRL) approach utilizing proximal policy optimization (PPO). A realistic case study based on Australian load and generation profiles is used to validate the framework. Simulation results demonstrate that DRL-PPO reduces operational costs by 18%, CO_2 emissions by 20%, and improves system reliability by 87.5% compared to RBC. Beside, DRL-PPO increases renewable energy utilization by 13%, effectively reducing dependence on diesel generation and grid imports. These findings demonstrate the potential of DRL-based approaches to enable cost-effective and resilient microgrid operations, particularly in regional and remote communities.",
      "authors": [
        "Moslem Uddin",
        "Huadong Mo",
        "Daoyi Dong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T15:52:41+00:00",
          "link": "https://arxiv.org/abs/2506.22931v1",
          "size": "323kb",
          "version": "v1"
        }
      ],
      "title": "Real-Time Energy Management Strategies for Community Microgrids",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22931",
        "HTML": "https://arxiv.org/html/2506.22931v1",
        "PDF": "https://arxiv.org/pdf/2506.22931"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22932",
      "abstract": "The increase of the percentage of elderly population in modern societies dictates the use of emerging technologies as a means of supporting elder members of the society. Within this scope, Extended Reality (XR) technologies pose as a promising technology for improving the daily lives of the elderly population. This paper presents a literature review that describes the most common characteristics of the physical and mental state of the elderly, allowing readers, and specifically XR developers, to understand the main difficulties faced by elderly users of extended reality applications so they can develop accessible, user friendly and engaging applications for the target audience. Furthermore, a review of existing extended reality applications that target the elder population is presented, allowing readers to get acquainted with existing design paradigms that can inspire future developments.",
      "authors": [
        "Zoe Anastasiadou",
        "Andreas Lanitis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T16:04:01+00:00",
          "link": "https://arxiv.org/abs/2506.22932v1",
          "size": "19kb",
          "version": "v1"
        }
      ],
      "title": "Immersive Technologies and Elderly Users: Current use, Limitations and Future Perspectives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22932",
        "HTML": "https://arxiv.org/html/2506.22932v1",
        "PDF": "https://arxiv.org/pdf/2506.22932"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22937",
      "abstract": "Blind and low-vision (BLV) players encounter critical challenges in engaging with video games due to the inaccessibility of visual elements, difficulties in navigating interfaces, and limitations in sending interaction input. Moreover, the development of specialized accessibility features typically requires substantial programming effort and is often implemented on a game-by-game basis. To address these challenges, we introduce \\textit{GamerAstra}, a generalized accessibility framework that leverages a multi-agent design to facilitate access to video games for BLV players. It integrates multi-modal techniques including large language models and vision-language models, enabling interaction with games lacking native accessibility support. The framework further incorporates customizable assistance granularities to support varying degrees of visual impairment and enhances interface navigation through multiple input modalities. The evaluation through technical assessments and user studies indicate that \\textit{GamerAstra} effectively enhances playability and delivers a more immersive gaming experience for BLV players. These findings also underscore potential avenues for advancing intelligent accessibility frameworks in the gaming domain.",
      "authors": [
        "Tianrun Qiu",
        "Changxin Chen",
        "Sizhe Cheng",
        "Yiming Yang",
        "Yixiao Guo",
        "Zhicong Lu",
        "Yuxin Ma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T16:08:08+00:00",
          "link": "https://arxiv.org/abs/2506.22937v1",
          "size": "9679kb",
          "version": "v1"
        }
      ],
      "title": "GamerAstra: Enhancing Video Game Accessibility for Blind and Low-Vision Players through a Multi-Agent AI Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22937",
        "HTML": "https://arxiv.org/html/2506.22937v1",
        "PDF": "https://arxiv.org/pdf/2506.22937"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22938",
      "abstract": "With current advancement in hybermedia knowledges, the privacy of digital information has developed a critical problem. To overawed the susceptibilities of present security protocols, scholars tend to focus mainly on efforts on alternation of current protocols. Over past decade, various proposed encoding models have been shown insecurity, leading to main threats against significant data. Utilizing the suitable encryption model is very vital means of guard against various such, but algorithm is selected based on the dependency of data which need to be secured. Moreover, testing potentiality of the security assessment one by one to identify the best choice can take a vital time for processing. For faster and precisive identification of assessment algorithm, we suggest a security phase exposure model for cipher encryption technique by invoking Support Vector Machine (SVM). In this work, we form a dataset using usual security components like contrast, homogeneity. To overcome the uncertainty in analysing the security and lack of ability of processing data to a risk assessment mechanism. To overcome with such complications, this paper proposes an assessment model for security issues using fuzzy evidential reasoning (ER) approaches. Significantly, the model can be utilised to process and assemble risk assessment data on various aspects in systematic ways. To estimate the performance of our framework, we have various analyses like, recall, F1 score and accuracy.",
      "authors": [
        "Zaydon L. Ali",
        "Wassan Saad Abduljabbar Hayale",
        "Israa Ibraheem Al_Barazanchi",
        "Ravi Sekhar",
        "Pritesh Shah",
        "Sushma Parihar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T16:08:34+00:00",
          "link": "https://arxiv.org/abs/2506.22938v1",
          "size": "1449kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Cybersecurity Assessment Using SVM and Fuzzy Evidential Reasoning for Resilient Infrastructure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22938",
        "PDF": "https://arxiv.org/pdf/2506.22938"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22939",
      "abstract": "Scene categorization (SC) in remotely acquired images is an important subject with broad consequences in different fields, including catastrophe control, ecological observation, architecture for cities, and more. Nevertheless, its several apps, reaching a high degree of accuracy in SC from distant observation data has demonstrated to be difficult. This is because traditional conventional deep learning models require large databases with high variety and high levels of noise to capture important visual features. To address these problems, this investigation file introduces an innovative technique referred to as the Cuttlefish Optimized Bidirectional Recurrent Neural Network (CO- BRNN) for type of scenes in remote sensing data. The investigation compares the execution of CO-BRNN with current techniques, including Multilayer Perceptron- Convolutional Neural Network (MLP-CNN), Convolutional Neural Network-Long Short Term Memory (CNN-LSTM), and Long Short Term Memory-Conditional Random Field (LSTM-CRF), Graph-Based (GB), Multilabel Image Retrieval Model (MIRM-CF), Convolutional Neural Networks Data Augmentation (CNN-DA). The results demonstrate that CO-BRNN attained the maximum accuracy of 97%, followed by LSTM-CRF with 90%, MLP-CNN with 85%, and CNN-LSTM with 80%. The study highlights the significance of physical confirmation to ensure the efficiency of satellite data.",
      "authors": [
        "Ghufran A. Omran",
        "Wassan Saad Abduljabbar Hayale",
        "Ahmad AbdulQadir AlRababah",
        "Israa Ibraheem Al-Barazanchi",
        "Ravi Sekhar",
        "Pritesh Shah",
        "Sushma Parihar",
        "Harshavardhan Reddy Penubadi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T16:12:28+00:00",
          "link": "https://arxiv.org/abs/2506.22939v1",
          "size": "1868kb",
          "version": "v1"
        }
      ],
      "title": "Utilizing a Novel Deep Learning Method for Scene Categorization in Remote Sensing Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22939",
        "PDF": "https://arxiv.org/pdf/2506.22939"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22940",
      "abstract": "This paper investigates how collaborative AI systems can enhance user agency in identifying and evaluating misinformation on social media platforms. Traditional methods, such as personal judgment or basic fact-checking, often fall short when faced with emotionally charged or context-deficient content. To address this, we designed and evaluated an interactive interface that integrates collaborative AI features, including real-time explanations, source aggregation, and debate-style interaction. These elements aim to support critical thinking by providing contextual cues and argumentative reasoning in a transparent, user-centered format. In a user study with 14 participants, 79% found the debate mode more effective than standard chatbot interfaces, and the multiple-source view received an average usefulness rating of 4.6 out of 5. Our findings highlight the potential of context-rich, dialogic AI systems to improve media literacy and foster trust in digital information environments. We argue that future tools for misinformation mitigation should prioritize ethical design, explainability, and interactive engagement to empower users in a post-truth era.",
      "authors": [
        "Varun Sangwan",
        "Heidi Makitalo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T16:13:42+00:00",
          "link": "https://arxiv.org/abs/2506.22940v1",
          "size": "783kb",
          "version": "v1"
        }
      ],
      "title": "Context, Credibility, and Control: User Reflections on AI Assisted Misinformation Tools",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22940",
        "PDF": "https://arxiv.org/pdf/2506.22940"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22941",
      "abstract": "Access to accurate and actionable harm reduction information can directly impact the health outcomes of People Who Use Drugs (PWUD), yet existing online channels often fail to meet their diverse and dynamic needs due to limitations in adaptability, accessibility, and the pervasive impact of stigma. Large Language Models (LLMs) present a novel opportunity to enhance information provision, but their application in such a high-stakes domain is under-explored and presents socio-technical challenges. This paper investigates how LLMs can be responsibly designed to support the information needs of PWUD. Through a qualitative workshop involving diverse stakeholder groups (academics, harm reduction practitioners, and an online community moderator), we explored LLM capabilities, identified potential use cases, and delineated core design considerations. Our findings reveal that while LLMs can address some existing information barriers (e.g., by offering responsive, multilingual, and potentially less stigmatising interactions), their effectiveness is contingent upon overcoming challenges related to ethical alignment with harm reduction principles, nuanced contextual understanding, effective communication, and clearly defined operational boundaries. We articulate design pathways emphasising collaborative co-design with experts and PWUD to develop LLM systems that are helpful, safe, and responsibly governed. This work contributes empirically grounded insights and actionable design considerations for the responsible development of LLMs as supportive tools within the harm reduction ecosystem.",
      "authors": [
        "Kaixuan Wang",
        "Jason T. Jacques",
        "and Chenxin Diao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T16:15:47+00:00",
          "link": "https://arxiv.org/abs/2506.22941v1",
          "size": "4041kb",
          "version": "v1"
        }
      ],
      "title": "Positioning AI Tools to Support Online Harm Reduction Practice: Applications and Design Directions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22941",
        "PDF": "https://arxiv.org/pdf/2506.22941"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22942",
      "abstract": "The problem of multi-robot coverage control becomes significantly challenging when multiple robots leave the mission space simultaneously to charge their batteries, disrupting the underlying network topology for communication and sensing. To address this, we propose a resilient network design and control approach that allows robots to achieve the desired coverage performance while satisfying energy constraints and maintaining network connectivity throughout the mission. We model the combined motion, energy, and network dynamics of the multirobot systems (MRS) as a hybrid system with three modes, i.e., coverage, return-to-base, and recharge, respectively. We show that ensuring the energy constraints can be transformed into designing appropriate guard conditions for mode transition between each of the three modes. Additionally, we present a systematic procedure to design, maintain, and reconfigure the underlying network topology using an energy-aware bearing rigid network design, enhancing the structural resilience of the MRS even when a subset of robots departs to charge their batteries. Finally, we validate our proposed method using numerical simulations.",
      "authors": [
        "Kartik A. Pant",
        "Jaehyeok Kim",
        "James M. Goppert",
        "and Inseok Hwang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T16:18:15+00:00",
          "link": "https://arxiv.org/abs/2506.22942v1",
          "size": "1161kb",
          "version": "v1"
        }
      ],
      "title": "Energy-Constrained Resilient Multi-Robot Coverage Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22942",
        "HTML": "https://arxiv.org/html/2506.22942v1",
        "PDF": "https://arxiv.org/pdf/2506.22942"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22944",
      "abstract": "This study introduces the first 3D spectral-element method (SEM) simulation of ultrasonic wave propagation in a bottlenose dolphin (Tursiops truncatus) head. Unlike traditional finite-element methods (FEM), which struggle with high-frequency simulations due to costly linear-system inversions and slower convergence, SEM offers exponential convergence and efficient parallel computation. Using Computed Tomography (CT) scan data, we developed a detailed hexahedral mesh capturing complex anatomical features, such as acoustic fats and jaws. Our simulations of plane and spherical waves confirm SEM's effectiveness for ultrasonic time-domain modeling. This approach opens new avenues for marine biology, contributing to research in echolocation, the impacts of anthropogenic marine noise pollution and the biophysics of hearing and click generation in marine mammals. By overcoming FEM's limitations, SEM provides a powerful scalable tool to test hypotheses about dolphin bioacoustics, with significant implications for conservation and understanding marine mammal auditory systems under increasing environmental challenges.",
      "authors": [
        "Carlos Garc\\'ia A.",
        "Vladimiro Boselli",
        "Aida Hejazi Nooghabi",
        "Andrea Colombi and Lapo Boschi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)",
        "Tissues and Organs (q-bio.TO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T16:29:03+00:00",
          "link": "https://arxiv.org/abs/2506.22944v1",
          "size": "9162kb",
          "version": "v1"
        }
      ],
      "title": "Feasibility of spectral-element modeling of wave propagation through the anatomy of marine mammals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22944",
        "HTML": "https://arxiv.org/html/2506.22944v1",
        "PDF": "https://arxiv.org/pdf/2506.22944"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22946",
      "abstract": "Mathematical researchers, especially those in early-career positions, face critical decisions about topic specialization with limited information about the collaborative environments of different research areas. The aim of this paper is to study how the popularity of a research topic is associated with the structure of that topic's collaboration network, as observed by a suite of measures capturing organizational structure at several scales. We apply these measures to 1,938 algorithmically discovered topics across 121,391 papers sourced from arXiv metadata during the period 2020--2025. Our analysis, which controls for the confounding effects of network size, reveals a structural dichotomy--we find that popular topics organize into modular \"schools of thought,\" while niche topics maintain hierarchical core-periphery structures centered around established experts. This divide is not an artifact of scale, but represents a size-independent structural pattern correlated with popularity. We also document a \"constraint reversal\": after controlling for size, researchers in popular fields face greater structural constraints on collaboration opportunities, contrary to conventional expectations. Our findings suggest that topic selection is an implicit choice between two fundamentally different collaborative environments, each with distinct implications for a researcher's career. To make these structural patterns transparent to the research community, we developed the Math Research Compass (https://mathresearchcompass.com), an interactive platform providing data on topic popularity and collaboration patterns across mathematical topics.",
      "authors": [
        "Brian Hepler"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computers and Society (cs.CY)",
        "Digital Libraries (cs.DL)",
        "History and Overview (math.HO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T16:39:57+00:00",
          "link": "https://arxiv.org/abs/2506.22946v1",
          "size": "870kb",
          "version": "v1"
        }
      ],
      "title": "Modular versus Hierarchical: A Structural Signature of Topic Popularity in Mathematical Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22946",
        "HTML": "https://arxiv.org/html/2506.22946v1",
        "PDF": "https://arxiv.org/pdf/2506.22946"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22949",
      "abstract": "One of the most difficult challenges in cybersecurity is eliminating Distributed Denial of Service (DDoS) attacks. Automating this task using artificial intelligence is a complex process due to the inherent class imbalance and lack of sufficient labeled samples of real-world datasets. This research investigates the use of Semi-Supervised Learning (SSL) techniques to improve DDoS attack detection when data is imbalanced and partially labeled. In this process, 13 state-of-the-art SSL algorithms are evaluated for detecting DDoS attacks in several scenarios. We evaluate their practical efficacy and shortcomings, including the extent to which they work in extreme environments. The results will offer insight into designing intelligent Intrusion Detection Systems (IDSs) that are robust against class imbalance and handle partially labeled data.",
      "authors": [
        "Ehsan Hallaji",
        "Vaishnavi Shanmugam",
        "Roozbeh Razavi-Far",
        "Mehrdad Saif"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T16:47:39+00:00",
          "link": "https://arxiv.org/abs/2506.22949v1",
          "size": "408kb",
          "version": "v1"
        }
      ],
      "title": "A Study on Semi-Supervised Detection of DDoS Attacks under Class Imbalance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22949",
        "HTML": "https://arxiv.org/html/2506.22949v1",
        "PDF": "https://arxiv.org/pdf/2506.22949"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22950",
      "abstract": "Group-based reinforcement learning algorithms such as Group Reward Policy Optimization (GRPO) have proven effective for fine-tuning large language models (LLMs) with human feedback. However, generating and storing multiple responses per prompt incurs substantial memory overhead, especially as the sample group size increases, limiting scalability under constrained hardware.\n  We propose Infinite Sampling, a framework that enables efficient and stable GRPO training by decoupling group size from GPU memory usage. It consists of: (1) micro sampling groups that decompose large groups into memory-feasible rounds; (2) continuous sampling that interleaves generation across groups to improve utilization; and (3) a length-aware scheduler combining token-conditioned sequence length prediction with a two-stage plan: global grouping via FPTAS and runtime refill via SJF.\n  Experiments show that our Micro Sampling Groups reduce peak memory usage by over 50% compared to full-group decoding (e.g., from 21.55 GB to 10.64 GB on Qwen3-1.7B). Building on this, Infinite Sampling improves throughput by over 25% compared to the naive micro sampling group method, reducing decoding steps while maintaining full-length completions and memory usage. Our hybrid scheduling ensures efficient and stable GRPO training with larger groups under realistic GPU memory constraints.",
      "authors": [
        "Liangyu Wang",
        "Huanyi Xie",
        "Xinhai Wang",
        "Tianjin Huang",
        "Mengdi Li",
        "Di Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T16:52:29+00:00",
          "link": "https://arxiv.org/abs/2506.22950v1",
          "size": "828kb",
          "version": "v1"
        }
      ],
      "title": "Infinite Sampling: Efficient and Stable Grouped RL Training for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22950",
        "HTML": "https://arxiv.org/html/2506.22950v1",
        "PDF": "https://arxiv.org/pdf/2506.22950"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22954",
      "abstract": "Context: Due to the demand for strong algorithmic reasoning, complex logic implementation, and strict adherence to input/output formats and resource constraints, competitive programming generation by large language models (LLMs) is considered the most challenging problem in current LLM-based code generation. However, previous studies often evaluate LLMs using simple prompts and benchmark datasets prone to data leakage. Moreover, prior work has limited consideration of the diversity in algorithm types and difficulty levels. Objective: In this study, we aim to evaluate and improve LLMs in solving real-world competitive programming problems. Methods: We initially collect 117 problems from nine regional ICPC/CCPC contests held in 2024 and design four filtering criteria to construct a curated benchmark consisting of 80 problems. Leveraging DeepSeek-R1 as the LLM, we evaluate its competitive program generation capabilities through the online judge (OJ) platforms, guided by a carefully designed basic prompt. For incorrect submissions, we construct a fine-grained error taxonomy and then propose a targeted improvement framework by combining a multi-turn dialogue-based repair phase and an information-augmented regeneration phase. Results: Experimental results show that only 5 out of 80 problems are fully accepted when using basic prompts. For the unsolved problems, we construct the error taxonomy, including general errors (such as design, boundary, condition, data type, syntax, and input/output errors) and specialized errors (such as those in mathematical problems, greedy algorithms, and graph theories). After applying our proposed improvement strategies, we substantially increased the number of correct solutions, with 46 out of 80 problems successfully accepted.",
      "authors": [
        "Minnan Wei",
        "Ziming Li",
        "Xiang Chen",
        "Menglin Zheng",
        "Ziyan Qu",
        "Cheng Yu",
        "Siyu Chen and Xiaolin Ju"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T17:18:23+00:00",
          "link": "https://arxiv.org/abs/2506.22954v1",
          "size": "14387kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating and Improving Large Language Models for Competitive Program Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22954",
        "HTML": "https://arxiv.org/html/2506.22954v1",
        "PDF": "https://arxiv.org/pdf/2506.22954"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22955",
      "abstract": "Medical image segmentation poses significant challenges due to class imbalance and the complex structure of medical images. To address these challenges, this study proposes YM-WML, a novel model for cardiac image segmentation. The model integrates a robust backbone for effective feature extraction, a YOLOv11 neck for multi-scale feature aggregation, and an attention-based segmentation head for precise and accurate segmentation. To address class imbalance, we introduce the Weighted Multi-class Exponential (WME) loss function. On the ACDC dataset, YM-WML achieves a Dice Similarity Coefficient of 91.02, outperforming state-of-the-art methods. The model demonstrates stable training, accurate segmentation, and strong generalization, setting a new benchmark in cardiac segmentation tasks.",
      "authors": [
        "Haniyeh Nikkhah",
        "Jafar Tanha",
        "Mahdi Zarrin",
        "SeyedEhsan Roshan",
        "Amin Kazempour"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T17:21:25+00:00",
          "link": "https://arxiv.org/abs/2506.22955v1",
          "size": "684kb",
          "version": "v1"
        }
      ],
      "title": "YM-WML: A new Yolo-based segmentation Model with Weighted Multi-class Loss for medical imaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22955",
        "PDF": "https://arxiv.org/pdf/2506.22955"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22956",
      "abstract": "Exploring high-latitude lunar regions presents an extremely challenging visual environment for robots. The low sunlight elevation angle and minimal light scattering result in a visual field dominated by a high dynamic range featuring long, dynamic shadows. Reproducing these conditions on Earth requires sophisticated simulators and specialized facilities. We introduce a unique dataset recorded at the LunaLab from the SnT - University of Luxembourg, an indoor test facility designed to replicate the optical characteristics of multiple lunar latitudes. Our dataset includes images, inertial measurements, and wheel odometry data from robots navigating seven distinct trajectories under multiple illumination scenarios, simulating high-latitude lunar conditions from dawn to night time with and without the aid of headlights, resulting in 88 distinct sequences containing a total of 1.3M images. Data was captured using a stereo RGB-inertial sensor, a monocular monochrome camera, and for the first time, a novel single-photon avalanche diode (SPAD) camera. We recorded both static and dynamic image sequences, with robots navigating at slow (5 cm/s) and fast (50 cm/s) speeds. All data is calibrated, synchronized, and timestamped, providing a valuable resource for validating perception tasks from vision-based autonomous navigation to scientific imaging for future lunar missions targeting high-latitude regions or those intended for robots operating across perceptually degraded environments. The dataset can be downloaded from https://zenodo.org/records/13970078?preview=1, and a visual overview is available at https://youtu.be/d7sPeO50_2I. All supplementary material can be found at https://github.com/spaceuma/spice-hl3.",
      "authors": [
        "David Rodr\\'iguez-Mart\\'inez",
        "Dave van der Meer",
        "Junlin Song",
        "Abishek Bera",
        "C.J. P\\'erez-del-Pulgar",
        "Miguel Angel Olivares-Mendez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T17:21:36+00:00",
          "link": "https://arxiv.org/abs/2506.22956v1",
          "size": "11443kb",
          "version": "v1"
        }
      ],
      "title": "SPICE-HL3: Single-Photon, Inertial, and Stereo Camera dataset for Exploration of High-Latitude Lunar Landscapes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22956",
        "HTML": "https://arxiv.org/html/2506.22956v1",
        "PDF": "https://arxiv.org/pdf/2506.22956"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22957",
      "abstract": "As large language models (LLMs) are increasingly integrated into multi-agent and human-AI systems, understanding their awareness of both self-context and conversational partners is essential for ensuring reliable performance and robust safety. While prior work has extensively studied situational awareness which refers to an LLM's ability to recognize its operating phase and constraints, it has largely overlooked the complementary capacity to identify and adapt to the identity and characteristics of a dialogue partner. In this paper, we formalize this latter capability as interlocutor awareness and present the first systematic evaluation of its emergence in contemporary LLMs. We examine interlocutor inference across three dimensions-reasoning patterns, linguistic style, and alignment preferences-and show that LLMs reliably identify same-family peers and certain prominent model families, such as GPT and Claude. To demonstrate its practical significance, we develop three case studies in which interlocutor awareness both enhances multi-LLM collaboration through prompt adaptation and introduces new alignment and safety vulnerabilities, including reward-hacking behaviors and increased jailbreak susceptibility. Our findings highlight the dual promise and peril of identity-sensitive behavior in LLMs, underscoring the need for further understanding of interlocutor awareness and new safeguards in multi-agent deployments. Our code is open-sourced at https://github.com/younwoochoi/InterlocutorAwarenessLLM.",
      "authors": [
        "Younwoo Choi",
        "Changling Li",
        "Yongjin Yang",
        "Zhijing Jin"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T17:22:59+00:00",
          "link": "https://arxiv.org/abs/2506.22957v1",
          "size": "2755kb",
          "version": "v1"
        }
      ],
      "title": "Agent-to-Agent Theory of Mind: Testing Interlocutor Awareness among Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22957",
        "PDF": "https://arxiv.org/pdf/2506.22957"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22960",
      "abstract": "A report by the European Union Law Enforcement Agency predicts that by 2026, up to 90 percent of online content could be synthetically generated, raising concerns among policymakers, who cautioned that \"Generative AI could act as a force multiplier for political disinformation. The combined effect of generative text, images, videos, and audio may surpass the influence of any single modality.\" In response, California's Bill AB 3211 mandates the watermarking of AI-generated images, videos, and audio. However, concerns remain regarding the vulnerability of invisible watermarking techniques to tampering and the potential for malicious actors to bypass them entirely. Generative AI-powered de-watermarking attacks, especially the newly introduced visual paraphrase attack, have shown an ability to fully remove watermarks, resulting in a paraphrase of the original image. This paper introduces PECCAVI, the first visual paraphrase attack-safe and distortion-free image watermarking technique. In visual paraphrase attacks, an image is altered while preserving its core semantic regions, termed Non-Melting Points (NMPs). PECCAVI strategically embeds watermarks within these NMPs and employs multi-channel frequency domain watermarking. It also incorporates noisy burnishing to counter reverse-engineering efforts aimed at locating NMPs to disrupt the embedded watermark, thereby enhancing durability. PECCAVI is model-agnostic. All relevant resources and codes will be open-sourced.",
      "authors": [
        "Shreyas Dixit",
        "Ashhar Aziz",
        "Shashwat Bajpai",
        "Vasu Sharma",
        "Aman Chadha",
        "Vinija Jain",
        "Amitava Das"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T17:34:08+00:00",
          "link": "https://arxiv.org/abs/2506.22960v1",
          "size": "21898kb",
          "version": "v1"
        }
      ],
      "title": "Peccavi: Visual Paraphrase Attack Safe and Distortion Free Image Watermarking Technique for AI-Generated Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22960",
        "HTML": "https://arxiv.org/html/2506.22960v1",
        "PDF": "https://arxiv.org/pdf/2506.22960"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22967",
      "abstract": "We address the task of zero-shot fine-grained video classification, where no video examples or temporal annotations are available for unseen action classes. While contrastive vision-language models such as SigLIP demonstrate strong open-set recognition via mean-pooled image-text similarity, they fail to capture the temporal structure critical for distinguishing fine-grained activities. We introduce ActAlign, a zero-shot framework that formulates video classification as sequence alignment. For each class, a large language model generates an ordered sub-action sequence, which is aligned with video frames using Dynamic Time Warping (DTW) in a shared embedding space. Without any video-text supervision or fine-tuning, ActAlign achieves 30.5% accuracy on the extremely challenging ActionAtlas benchmark, where human accuracy is only 61.6%. ActAlign outperforms billion-parameter video-language models while using approximately 8x less parameters. These results demonstrate that structured language priors, combined with classical alignment techniques, offer a scalable and general approach to unlocking the open-set recognition potential of vision-language models for fine-grained video understanding.",
      "authors": [
        "Amir Aghdam",
        "Vincent Tao Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T17:57:58+00:00",
          "link": "https://arxiv.org/abs/2506.22967v1",
          "size": "6480kb",
          "version": "v1"
        }
      ],
      "title": "ActAlign: Zero-Shot Fine-Grained Video Classification via Language-Guided Sequence Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22967",
        "HTML": "https://arxiv.org/html/2506.22967v1",
        "PDF": "https://arxiv.org/pdf/2506.22967"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22968",
      "abstract": "AI is flattening culture. Evaluations of \"culture\" are showing the myriad ways in which large AI models are homogenizing language and culture, averaging out rich linguistic differences into generic expressions. I call this phenomenon \"softmaxing culture,\" and it is one of the fundamental challenges facing AI evaluations today. Efforts to improve and strengthen evaluations of culture are central to the project of cultural alignment in large AI systems. This position paper argues that machine learning (ML) and human-computer interaction (HCI) approaches to evaluation are limited. I propose two key shifts. First, instead of asking \"what is culture?\" at the start of system evaluations, I propose beginning with the question: \"when is culture?\" Second, while I acknowledge the philosophical claim that cultural universals exist, the challenge is not simply to describe them, but to situate them in relation to their particulars. Taken together, these conceptual shifts invite evaluation approaches that move beyond technical requirements, toward perspectives more responsive to the complexities of culture.",
      "authors": [
        "Daniel Mwesigwa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T17:59:17+00:00",
          "link": "https://arxiv.org/abs/2506.22968v1",
          "size": "13kb",
          "version": "v1"
        }
      ],
      "title": "Against 'softmaxing' culture",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22968",
        "HTML": "https://arxiv.org/html/2506.22968v1",
        "PDF": "https://arxiv.org/pdf/2506.22968"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22969",
      "abstract": "Sparse Tensor Cores offer exceptional performance gains for AI workloads by exploiting structured 2:4 sparsity. However, their potential remains untapped for core scientific workloads such as stencil computations, which exhibit irregular sparsity patterns.This paper presents SparStencil, the first system to retarget sparse TCUs for scientific stencil computations through structured sparsity transformation. SparStencil introduces three key techniques: (1) Adaptive Layout Morphing, which restructures stencil patterns into staircase-aligned sparse matrices via a flatten-and-crush pipeline; (2) Structured Sparsity Conversion, which formulates transformation as a graph matching problem to ensure compatibility with 2:4 sparsity constraints; (3) Automatic Kernel Generation, which compiles transformed stencils into optimized sparse MMA kernels via layout search and table-driven memory mapping. Evaluated on 79 stencil kernels spanning diverse scientific domains, SparStencil achieves up to 7.1x speedup (3.1x on average) over state-of-the-art framework while reducing code complexity and matching or exceeding expert-tuned performance in both compute throughput and memory efficiency.",
      "authors": [
        "Qi Li",
        "Kun Li",
        "Haozhi Han",
        "Liang Yuan",
        "Junshi Chen",
        "Yunquan Zhang",
        "Yifeng Chen",
        "Hong An",
        "Ting Cao",
        "Mao Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T17:59:30+00:00",
          "link": "https://arxiv.org/abs/2506.22969v1",
          "size": "1450kb",
          "version": "v1"
        }
      ],
      "title": "SparStencil: Retargeting Sparse Tensor Cores to Scientific Stencil Computations via Structured Sparsity Transformation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22969",
        "HTML": "https://arxiv.org/html/2506.22969v1",
        "PDF": "https://arxiv.org/pdf/2506.22969"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22971",
      "abstract": "This paper presents a two-timescale hierarchical decentralized architecture for control of Cyber-Physical Systems. The architecture consists of $N$ independent sub-processes, a global controller, and $N$ local controllers, each formulated as a Markov Decision Process (MDP). The global controller, operating at a slower timescale optimizes the infinite-horizon discounted cumulative reward under budget constraints. For the local controllers, operating at a faster timescale, we propose two different optimization frameworks, namely the COpt and FOpt. In the COpt framework, the local controller also optimizes an infinite-horizon MDP, while in the FOpt framework, the local controller optimizes a finite-horizon MDP. The FOpt framework mimics a federal structure, where the local controllers have more autonomy in their decision making. First, the existence of stationary deterministic optimal policies for both these frameworks is established. Then, various relationships between the two frameworks are studied, including a bound on the difference between the two optimal value functions. Additionally, sufficiency conditions are provided such that the two frameworks lead to the same optimal values.",
      "authors": [
        "Kesav Kazam Ramachandran Anantharaman and Rahul Meshram"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T18:03:35+00:00",
          "link": "https://arxiv.org/abs/2506.22971v1",
          "size": "366kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Decentralized Stochastic Control for Cyber-Physical Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22971",
        "HTML": "https://arxiv.org/html/2506.22971v1",
        "PDF": "https://arxiv.org/pdf/2506.22971"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22973",
      "abstract": "3D Gaussian Splatting enables high-quality real-time rendering but often produces millions of splats, resulting in excessive storage and computational overhead. We propose a novel lossy compression method based on learnable confidence scores modeled as Beta distributions. Each splat's confidence is optimized through reconstruction-aware losses, enabling pruning of low-confidence splats while preserving visual fidelity. The proposed approach is architecture-agnostic and can be applied to any Gaussian Splatting variant. In addition, the average confidence values serve as a new metric to assess the quality of the scene. Extensive experiments demonstrate favorable trade-offs between compression and fidelity compared to prior work. Our code and data are publicly available at https://github.com/amirhossein-razlighi/Confident-Splatting",
      "authors": [
        "AmirHossein Naghi Razlighi",
        "Elaheh Badali Golezani",
        "Shohreh Kasaei"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T18:11:30+00:00",
          "link": "https://arxiv.org/abs/2506.22973v1",
          "size": "25471kb",
          "version": "v1"
        }
      ],
      "title": "Confident Splatting: Confidence-Based Compression of 3D Gaussian Splatting via Learnable Beta Distributions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22973",
        "HTML": "https://arxiv.org/html/2506.22973v1",
        "PDF": "https://arxiv.org/pdf/2506.22973"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22977",
      "abstract": "We present a reproduction study of \"Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals\" (Ortu et al., 2024), which investigates competition of mechanisms in language models between factual recall and counterfactual in-context repetition. Our study successfully reproduces their primary findings regarding the localization of factual and counterfactual information, the dominance of attention blocks in mechanism competition, and the specialization of attention heads in handling competing information. We reproduce their results on both GPT-2 (Radford et al., 2019) and Pythia 6.9B (Biderman et al., 2023). We extend their work in three significant directions. First, we explore the generalizability of these findings to even larger models by replicating the experiments on Llama 3.1 8B (Grattafiori et al., 2024), discovering greatly reduced attention head specialization. Second, we investigate the impact of prompt structure by introducing variations where we avoid repeating the counterfactual statement verbatim or we change the premise word, observing a marked decrease in the logit for the counterfactual token. Finally, we test the validity of the authors' claims for prompts of specific domains, discovering that certain categories of prompts skew the results by providing the factual prediction token as part of the subject of the sentence. Overall, we find that the attention head ablation proposed in Ortu et al. (2024) is ineffective for domains that are underrepresented in their dataset, and that the effectiveness varies based on model architecture, prompt structure, domain and task.",
      "authors": [
        "Asen Dotsinski",
        "Udit Thakur",
        "Marko Ivanov",
        "Mohammad Hafeez Khan",
        "Maria Heuss"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T18:29:19+00:00",
          "link": "https://arxiv.org/abs/2506.22977v1",
          "size": "413kb",
          "version": "v1"
        }
      ],
      "title": "On the Generalizability of \"Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals\"",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22977",
        "HTML": "https://arxiv.org/html/2506.22977v1",
        "PDF": "https://arxiv.org/pdf/2506.22977"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22978",
      "abstract": "Syntactic language models (SLMs) enhance Transformers by incorporating syntactic biases through the modeling of linearized syntactic parse trees alongside surface sentences. This paper focuses on compositional SLMs that are based on constituency parse trees and contain explicit bottom-up composition of constituent representations. We identify key aspects of design choices in existing compositional SLMs and propose a unified framework encompassing both existing models and novel variants. We conduct a comprehensive empirical evaluation of all the variants in our framework across language modeling, syntactic generalization, summarization, dialogue, and inference efficiency. Based on the experimental results, we make multiple recommendations on the design of compositional SLMs. Our code is released at https://github.com/zhaoyd1/compositional_SLMs.",
      "authors": [
        "Yida Zhao",
        "Hao Xve",
        "Xiang Hu",
        "Kewei Tu"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T18:32:23+00:00",
          "link": "https://arxiv.org/abs/2506.22978v1",
          "size": "252kb",
          "version": "v1"
        }
      ],
      "title": "A Systematic Study of Compositional Syntactic Transformer Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22978",
        "HTML": "https://arxiv.org/html/2506.22978v1",
        "PDF": "https://arxiv.org/pdf/2506.22978"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22979",
      "abstract": "Generalized Few-Shot Semantic Segmentation (GFSS) aims to extend a segmentation model to novel classes with only a few annotated examples while maintaining performance on base classes. Recently, pretrained vision-language models (VLMs) such as CLIP have been leveraged in GFSS to improve generalization on novel classes through multi-modal prototypes learning. However, existing prototype-based methods are inherently deterministic, limiting the adaptability of learned prototypes to diverse samples, particularly for novel classes with scarce annotations. To address this, we propose FewCLIP, a probabilistic prototype calibration framework over multi-modal prototypes from the pretrained CLIP, thus providing more adaptive prototype learning for GFSS. Specifically, FewCLIP first introduces a prototype calibration mechanism, which refines frozen textual prototypes with learnable visual calibration prototypes, leading to a more discriminative and adaptive representation. Furthermore, unlike deterministic prototype learning techniques, FewCLIP introduces distribution regularization over these calibration prototypes. This probabilistic formulation ensures structured and uncertainty-aware prototype learning, effectively mitigating overfitting to limited novel class data while enhancing generalization. Extensive experimental results on PASCAL-5$^i$ and COCO-20$^i$ datasets demonstrate that our proposed FewCLIP significantly outperforms state-of-the-art approaches across both GFSS and class-incremental setting. The code is available at https://github.com/jliu4ai/FewCLIP.",
      "authors": [
        "Jie Liu",
        "Jiayi Shen",
        "Pan Zhou",
        "Jan-Jakob Sonke",
        "Efstratios Gavves"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T18:36:22+00:00",
          "link": "https://arxiv.org/abs/2506.22979v1",
          "size": "3464kb",
          "version": "v1"
        }
      ],
      "title": "Probabilistic Prototype Calibration of Vision-Language Models for Generalized Few-shot Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22979",
        "HTML": "https://arxiv.org/html/2506.22979v1",
        "PDF": "https://arxiv.org/pdf/2506.22979"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22982",
      "abstract": "Large Vision-Language Models (VLMs) have revolutionized computer vision, enabling tasks such as image classification, captioning, and visual question answering. However, they remain highly vulnerable to adversarial attacks, particularly in scenarios where both visual and textual modalities can be manipulated. In this study, we conduct a comprehensive reproducibility study of \"An Image is Worth 1000 Lies: Adversarial Transferability Across Prompts on Vision-Language Models\" validating the Cross-Prompt Attack (CroPA) and confirming its superior cross-prompt transferability compared to existing baselines. Beyond replication we propose several key improvements: (1) A novel initialization strategy that significantly improves Attack Success Rate (ASR). (2) Investigate cross-image transferability by learning universal perturbations. (3) A novel loss function targeting vision encoder attention mechanisms to improve generalization. Our evaluation across prominent VLMs -- including Flamingo, BLIP-2, and InstructBLIP as well as extended experiments on LLaVA validates the original results and demonstrates that our improvements consistently boost adversarial effectiveness. Our work reinforces the importance of studying adversarial vulnerabilities in VLMs and provides a more robust framework for generating transferable adversarial examples, with significant implications for understanding the security of VLMs in real-world applications.",
      "authors": [
        "Atharv Mittal",
        "Agam Pandey",
        "Amritanshu Tiwari",
        "Sukrit Jindal",
        "Swadesh Swain"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T19:01:41+00:00",
          "link": "https://arxiv.org/abs/2506.22982v1",
          "size": "2427kb",
          "version": "v1"
        }
      ],
      "title": "Revisiting CroPA: A Reproducibility Study and Enhancements for Cross-Prompt Adversarial Transferability in Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22982",
        "HTML": "https://arxiv.org/html/2506.22982v1",
        "PDF": "https://arxiv.org/pdf/2506.22982"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22984",
      "abstract": "Anomaly detection in connected autonomous vehicles (CAVs) is crucial for maintaining safe and reliable transportation networks, as CAVs can be susceptible to sensor malfunctions, cyber-attacks, and unexpected environmental disruptions. This study explores an anomaly detection approach by simulating vehicle behavior, generating a dataset that represents typical and atypical vehicular interactions. The dataset includes time-series data of position, speed, and acceleration for multiple connected autonomous vehicles. We utilized machine learning models to effectively identify abnormal driving patterns. First, we applied a stacked Long Short-Term Memory (LSTM) model to capture temporal dependencies and sequence-based anomalies. The stacked LSTM model processed the sequential data to learn standard driving behaviors. Additionally, we deployed a Random Forest model to support anomaly detection by offering ensemble-based predictions, which enhanced model interpretability and performance. The Random Forest model achieved an R2 of 0.9830, MAE of 5.746, and a 95th percentile anomaly threshold of 14.18, while the stacked LSTM model attained an R2 of 0.9998, MAE of 82.425, and a 95th percentile anomaly threshold of 265.63. These results demonstrate the models' effectiveness in accurately predicting vehicle trajectories and detecting anomalies in autonomous driving scenarios.",
      "authors": [
        "Prathyush Kumar Reddy Lebaku",
        "Lu Gao",
        "Yunpeng Zhang",
        "Zhixia Li",
        "Yongxin Liu",
        "Tanvir Arafin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T19:11:19+00:00",
          "link": "https://arxiv.org/abs/2506.22984v1",
          "size": "2788kb",
          "version": "v1"
        }
      ],
      "title": "Cybersecurity-Focused Anomaly Detection in Connected Autonomous Vehicles Using Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22984",
        "HTML": "https://arxiv.org/html/2506.22984v1",
        "PDF": "https://arxiv.org/pdf/2506.22984"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22988",
      "abstract": "Emerging extended reality (XR) tools and platforms offer an exciting opportunity to align learning experiences in higher education with the futures in which students will pursue their goals. However, the dynamic nature of XR as subject matter challenges hierarchies and classroom practices typical of higher education. This instructional design practice paper reflects on how our team of faculty, learning experience designers, and user experience (UX) researchers implemented human-centered design thinking, transformative learning, and problem-posing education to design and implement a special topics media entrepreneurship course in building the metaverse. By pairing our practitioner experience with learner personas, as well as survey, interview, and focus group responses from our learners, we narrate our design and its implications through a human-centered, reflective lens.",
      "authors": [
        "Abigail Greenbaum",
        "Elizabeth Strickler",
        "Victoria Patterson",
        "and Bolu Oluleye"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T19:36:49+00:00",
          "link": "https://arxiv.org/abs/2506.22988v1",
          "size": "720kb",
          "version": "v1"
        }
      ],
      "title": "(World) Building Transformation: Students and Teachers as CoCreators in OpenXR Learning Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22988",
        "PDF": "https://arxiv.org/pdf/2506.22988"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22991",
      "abstract": "Just like power, water, and transportation systems, wireless networks are a crucial societal infrastructure. As natural and human-induced disruptions continue to grow, wireless networks must be resilient. This requires them to withstand and recover from unexpected adverse conditions, shocks, unmodeled disturbances and cascading failures. Unlike robustness and reliability, resilience is based on the understanding that disruptions will inevitably happen. Resilience, as elasticity, focuses on the ability to bounce back to favorable states, while resilience as plasticity involves agents and networks that can flexibly expand their states and hypotheses through real-time adaptation and reconfiguration. This situational awareness and active preparedness, adapting world models and counterfactually reasoning about potential system failures and the best responses, is a core aspect of resilience. This article will first disambiguate resilience from reliability and robustness, before delving into key mathematical foundations of resilience grounded in abstraction, compositionality and emergence. Subsequently, we focus our attention on a plethora of techniques and methodologies pertaining to the unique characteristics of resilience, as well as their applications through a comprehensive set of use cases. Ultimately, the goal of this paper is to establish a unified foundation for understanding, modeling, and engineering resilience in wireless communication systems, while laying a roadmap for the next-generation of resilient-native and intelligent wireless systems.",
      "authors": [
        "Mehdi Bennis",
        "Sumudu Samarakoon",
        "Tamara Alshammari",
        "Chathuranga Weeraddana",
        "Zhoujun Tian",
        "and Chaouki Ben Issaid"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Logic in Computer Science (cs.LO)",
        "Multiagent Systems (cs.MA)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T19:41:42+00:00",
          "link": "https://arxiv.org/abs/2506.22991v1",
          "size": "2863kb",
          "version": "v1"
        }
      ],
      "title": "Resilient-Native and Intelligent Next-Generation Wireless Systems: Key Enablers, Foundations, and Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22991",
        "PDF": "https://arxiv.org/pdf/2506.22991"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22992",
      "abstract": "The ability to process information from multiple modalities and to reason through it step-by-step remains a critical challenge in advancing artificial intelligence. However, existing reasoning benchmarks focus on text-only reasoning, or employ multimodal questions that can be answered by directly retrieving information from a non-text modality. Thus, complex reasoning remains poorly understood in multimodal domains. Here, we present MARBLE, a challenging multimodal reasoning benchmark that is designed to scrutinize multimodal language models (MLLMs) in their ability to carefully reason step-by-step through complex multimodal problems and environments. MARBLE is composed of two highly challenging tasks, M-Portal and M-Cube, that require the crafting and understanding of multistep plans under spatial, visual, and physical constraints. We find that current MLLMs perform poorly on MARBLE -- all the 12 advanced models obtain near-random performance on M-Portal and 0% accuracy on M-Cube. Only in simplified subtasks some models outperform the random baseline, indicating that complex reasoning is still a challenge for existing MLLMs. Moreover, we show that perception remains a bottleneck, where MLLMs occasionally fail to extract information from the visual inputs. By shedding a light on the limitations of MLLMs, we hope that MARBLE will spur the development of the next generation of models with the ability to reason and plan across many, multimodal reasoning steps.",
      "authors": [
        "Yulun Jiang and Yekun Chai and Maria Brbi\\'c and Michael Moor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T19:44:32+00:00",
          "link": "https://arxiv.org/abs/2506.22992v1",
          "size": "5879kb",
          "version": "v1"
        }
      ],
      "title": "MARBLE: A Hard Benchmark for Multimodal Spatial Reasoning and Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22992",
        "HTML": "https://arxiv.org/html/2506.22992v1",
        "PDF": "https://arxiv.org/pdf/2506.22992"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22993",
      "abstract": "Social contexts -- such as families, schools, and neighborhoods -- shape life outcomes. The key question is not simply whether they matter, but rather for whom and under what conditions. Here, we argue that prediction gaps -- differences in predictive performance between statistical models of varying complexity -- offer a pathway for identifying surprising empirical patterns (i.e., not captured by simpler models) which highlight where theories succeed or fall short. Using population-scale administrative data from the Netherlands, we compare logistic regression, gradient boosting, and graph neural networks to predict university completion using early-life social contexts. Overall, prediction gaps are small, suggesting that previously identified indicators, particularly parental status, capture most measurable variation in educational attainment. However, gaps are larger for girls growing up without fathers -- suggesting that the effects of social context for these groups go beyond simple models in line with sociological theory. Our paper shows the potential of prediction methods to support sociological explanation.",
      "authors": [
        "Javier Garcia-Bernardo",
        "Eva Jaspers",
        "Weverthon Machado",
        "Samuel Plach",
        "Erik Jan van Leeuwen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T19:51:27+00:00",
          "link": "https://arxiv.org/abs/2506.22993v1",
          "size": "1654kb",
          "version": "v1"
        }
      ],
      "title": "Prediction Gaps as Pathways to Explanation: Rethinking Educational Outcomes through Differences in Model Performance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22993",
        "PDF": "https://arxiv.org/pdf/2506.22993"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22994",
      "abstract": "A new anomaly detection method called kernel outlier detection (KOD) is proposed. It is designed to address challenges of outlier detection in high-dimensional settings. The aim is to overcome limitations of existing methods, such as dependence on distributional assumptions or on hyperparameters that are hard to tune. KOD starts with a kernel transformation, followed by a projection pursuit approach. Its novelties include a new ensemble of directions to search over, and a new way to combine results of different direction types. This provides a flexible and lightweight approach for outlier detection. Our empirical evaluations illustrate the effectiveness of KOD on three small datasets with challenging structures, and on four large benchmark datasets.",
      "authors": [
        "Can Hakan Da\\u{g}{\\i}d{\\i}r",
        "Mia Hubert",
        "Peter J. Rousseeuw"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T20:06:06+00:00",
          "link": "https://arxiv.org/abs/2506.22994v1",
          "size": "3339kb",
          "version": "v1"
        }
      ],
      "title": "Kernel Outlier Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22994",
        "HTML": "https://arxiv.org/html/2506.22994v1",
        "PDF": "https://arxiv.org/pdf/2506.22994"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22995",
      "abstract": "The increasing integration of renewable energy sources (RESs) is transforming traditional power grid networks, which require new approaches for managing decentralized energy production and consumption. Microgrids (MGs) provide a promising solution by enabling localized control over energy generation, storage, and distribution. This paper presents a novel reinforcement learning (RL)-based methodology for optimizing microgrid energy management. Specifically, we propose an RL agent that learns optimal energy trading and storage policies by leveraging historical data on energy production, consumption, and market prices. A digital twin (DT) is used to simulate the energy storage system dynamics, incorporating degradation factors to ensure a realistic emulation of the analysed setting. Our approach is validated through an experimental campaign using real-world data from a power grid located in the Italian territory. The results indicate that the proposed RL-based strategy outperforms rule-based methods and existing RL benchmarks, offering a robust solution for intelligent microgrid management.",
      "authors": [
        "Davide Salaorni",
        "Federico Bianchi",
        "Francesco Trov\\`o",
        "Marcello Restelli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T20:10:00+00:00",
          "link": "https://arxiv.org/abs/2506.22995v1",
          "size": "1402kb",
          "version": "v1"
        }
      ],
      "title": "A Reinforcement Learning Approach for Optimal Control in Microgrids",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22995",
        "HTML": "https://arxiv.org/html/2506.22995v1",
        "PDF": "https://arxiv.org/pdf/2506.22995"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23000",
      "abstract": "We present an alternative take on the recently popularized concept of `$\\textit{joint sensing and communications}$', which focuses on using communication resources also for sensing. Here, we propose the opposite, where we exploit the sensing capabilities of the receiver for communication. Our goal is to characterize the fundamental limits of communication over such a channel, which we call `$\\textit{communication via sensing}$'. We assume that changes in the sensed attributes, e.g., location, speed, etc., are limited due to practical constraints, which are captured by assuming a finite-state channel (FSC) with an input cost constraint. We first formulate an upper bound on the $N$-letter capacity as a cost-constrained optimization problem over the input sequence distribution, and then convert it to an equivalent problem over the state sequence distribution. Moreover, by breaking a walk on the underlying Markov chain into a weighted sum of traversed graph cycles in the long walk limit, we obtain a compact single-letter formulation of the capacity upper bound. Finally, for a specific case of a two-state FSC with noisy sensing characterized by a binary symmetric channel (BSC), we obtain a closed-form expression for the capacity upper bound. Comparison with an existing numerical lower bound shows that our proposed upper bound is very tight for all crossover probabilities.",
      "authors": [
        "Mohammad Kazemi",
        "Tolga M. Duman",
        "Deniz G\\\"und\\\"uz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T20:25:56+00:00",
          "link": "https://arxiv.org/abs/2506.23000v1",
          "size": "771kb",
          "version": "v1"
        }
      ],
      "title": "Communication via Sensing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23000",
        "HTML": "https://arxiv.org/html/2506.23000v1",
        "PDF": "https://arxiv.org/pdf/2506.23000"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23001",
      "abstract": "Could the answer be to compute fewer pixels? Renderers that break traditional framed patterns and opt for temporally adaptive sampling might be the key to printer-resolution wall displays that update hundreds of times per second.",
      "authors": [
        "Benjamin Watson",
        "David Luebke"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T20:27:00+00:00",
          "link": "https://arxiv.org/abs/2506.23001v1",
          "size": "191kb",
          "version": "v1"
        }
      ],
      "title": "The ultimate display: Where will all the pixels come from?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23001",
        "PDF": "https://arxiv.org/pdf/2506.23001"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23004",
      "abstract": "This paper proposes a novel, robust, and lightweight supervised Convolutional Neural Network (CNN)-based technique for frame identification and synchronization, designed to enhance short-link communication performance in a screen-to-camera (S2C) based visible light communication (VLC) system. Developed using Python and the TensorFlow Keras framework, the proposed CNN model was trained through three real-time experimental investigations conducted in Jupyter Notebook. These experiments incorporated a dataset created from scratch to address various real-time challenges in S2C communication, including blurring, cropping, and rotated images in mobility scenarios. Overhead frames were introduced for synchronization, which leads to enhanced system performance. The experimental results demonstrate that the proposed model achieves an overall accuracy of approximately 98.74%, highlighting its effectiveness in identifying and synchronizing frames in S2C VLC systems.",
      "authors": [
        "Vaigai Nayaki Yokar",
        "Hoa Le-Minh",
        "Xicong Li",
        "Wai Lok Woo",
        "Luis Nero Alves",
        "Stanislav Zvanovec",
        "Tran The Son and Zabih Ghassemlooy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T20:29:37+00:00",
          "link": "https://arxiv.org/abs/2506.23004v1",
          "size": "617kb",
          "version": "v1"
        }
      ],
      "title": "A Novel Frame Identification and Synchronization Technique for Smartphone Visible Light Communication Systems Based on Convolutional Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23004",
        "PDF": "https://arxiv.org/pdf/2506.23004"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23009",
      "abstract": "Multimodal Large Language Models (MLLMs) have achieved remarkable visual reasoning abilities in natural images, text-rich documents, and graphic designs. However, their ability to interpret music sheets remains underexplored. To bridge this gap, we introduce MusiXQA, the first comprehensive dataset for evaluating and advancing MLLMs in music sheet understanding. MusiXQA features high-quality synthetic music sheets generated via MusiXTeX, with structured annotations covering note pitch and duration, chords, clefs, key/time signatures, and text, enabling diverse visual QA tasks. Through extensive evaluations, we reveal significant limitations of current state-of-the-art MLLMs in this domain. Beyond benchmarking, we developed Phi-3-MusiX, an MLLM fine-tuned on our dataset, achieving significant performance gains over GPT-based methods. The proposed dataset and model establish a foundation for future advances in MLLMs for music sheet understanding. Code, data, and model will be released upon acceptance.",
      "authors": [
        "Jian Chen",
        "Wenye Ma",
        "Penghang Liu",
        "Wei Wang",
        "Tengwei Song",
        "Ming Li",
        "Chenguang Wang",
        "Ruiyi Zhang",
        "Changyou Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T20:46:47+00:00",
          "link": "https://arxiv.org/abs/2506.23009v1",
          "size": "1726kb",
          "version": "v1"
        }
      ],
      "title": "MusiXQA: Advancing Visual Music Understanding in Multimodal Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23009",
        "HTML": "https://arxiv.org/html/2506.23009v1",
        "PDF": "https://arxiv.org/pdf/2506.23009"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23014",
      "abstract": "Research shows that analysts and developers consider privacy as a security concept or as an afterthought, which may lead to non-compliance and violation of users' privacy. Most current approaches, however, focus on extracting legal requirements from the regulations and evaluating the compliance of software and processes with them. In this paper, we develop a novel approach based on chain-of-thought prompting (CoT), in-context-learning (ICL), and Large Language Models (LLMs) to extract privacy behaviors from various software documents prior to and during software development, and then generate privacy requirements in the format of user stories. Our results show that most commonly used LLMs, such as GPT-4o and Llama 3, can identify privacy behaviors and generate privacy user stories with F1 scores exceeding 0.8. We also show that the performance of these models could be improved through parameter-tuning. Our findings provide insight into using and optimizing LLMs for generating privacy requirements given software documents created prior to or throughout the software development lifecycle.",
      "authors": [
        "Wilder Baldwin",
        "Shashank Chintakuntla",
        "Shreyah Parajuli",
        "Ali Pourghasemi",
        "Ryan Shanz",
        "Sepideh Ghanavati"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T20:55:21+00:00",
          "link": "https://arxiv.org/abs/2506.23014v1",
          "size": "724kb",
          "version": "v1"
        }
      ],
      "title": "Generating Privacy Stories From Software Documentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23014",
        "HTML": "https://arxiv.org/html/2506.23014v1",
        "PDF": "https://arxiv.org/pdf/2506.23014"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23016",
      "abstract": "The global prevalence of dementia is projected to double by 2050, highlighting the urgent need for scalable diagnostic tools. This study utilizes digital cognitive tasks with eye-tracking data correlated with memory processes to distinguish between Healthy Controls (HC) and Mild Cognitive Impairment (MCI), a precursor to dementia. A deep learning model based on VTNet was trained using eye-tracking data from 44 participants (24 MCI, 20 HCs) who performed a visual memory task. The model utilizes both time series and spatial data derived from eye-tracking. It was modified to incorporate scan paths, heat maps, and image content. These modifications also enabled testing parameters such as image resolution and task performance, analyzing their impact on model performance. The best model, utilizing $700\\times700px$ resolution heatmaps, achieved 68% sensitivity and 76% specificity. Despite operating under more challenging conditions (e.g., smaller dataset size, shorter task duration, or a less standardized task), the model's performance is comparable to an Alzheimer's study using similar methods (70% sensitivity and 73% specificity). These findings contribute to the development of automated diagnostic tools for MCI. Future work should focus on refining the model and using a standardized long-term visual memory task.",
      "authors": [
        "Tom\\'as Silva Santos Rocha",
        "Anastasiia Mikhailova",
        "Moreno I. Coco and Jos\\'e Santos-Victor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T21:20:33+00:00",
          "link": "https://arxiv.org/abs/2506.23016v1",
          "size": "992kb",
          "version": "v1"
        }
      ],
      "title": "Deep Learning in Mild Cognitive Impairment Diagnosis using Eye Movements and Image Content in Visual Memory Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23016",
        "HTML": "https://arxiv.org/html/2506.23016v1",
        "PDF": "https://arxiv.org/pdf/2506.23016"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23017",
      "abstract": "This paper addresses the critical issue of deceptive design elements prevalent in technology, and their potential impact on children. Recent research highlights the impact of dark patterns on adults and adolescents, while studies involving children are scarce. In an era where children wield greater independence with digital devices, their vulnerability to dark patterns amplifies without early education. Our findings show a significant positive impact of dark pattern education on children's awareness, revealing that heightened awareness considerably alters children's navigation of social media, video games, and streaming platforms. To this end, we developed a gamified application aimed at instructing children on identifying and responding to various dark patterns. Our evaluation results emphasize the critical role of early education in empowering children to recognize and counter deceptive design, thereby cultivating a digitally literate generation capable of making informed choices in the complex landscape of digital technology.",
      "authors": [
        "Noverah Khan",
        "Hira Eiraj Daud",
        "Suleman Shahid"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T21:25:40+00:00",
          "link": "https://arxiv.org/abs/2506.23017v1",
          "size": "12849kb",
          "version": "v1"
        }
      ],
      "title": "Mind the Dark: A Gamified Exploration of Deceptive Design Awareness for Children in the Digital Age",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23017",
        "PDF": "https://arxiv.org/pdf/2506.23017"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23023",
      "abstract": "Developing decision-making algorithms for highly automated driving systems remains challenging, since these systems have to operate safely in an open and complex environments. Reinforcement Learning (RL) approaches can learn comprehensive decision policies directly from experience and already show promising results in simple driving tasks. However, current approaches fail to achieve generalizability for more complex driving tasks and lack learning efficiency. Therefore, we present Scenario-based Automated Driving Reinforcement Learning (SAD-RL), the first framework that integrates Reinforcement Learning (RL) of hierarchical policy in a scenario-based environment. A high-level policy selects maneuver templates that are evaluated and executed by a low-level control logic. The scenario-based environment allows to control the training experience for the agent and to explicitly introduce challenging, but rate situations into the training process. Our experiments show that an agent trained using the SAD-RL framework can achieve safe behaviour in easy as well as challenging situations efficiently. Our ablation studies confirmed that both HRL and scenario diversity are essential for achieving these results.",
      "authors": [
        "M. Youssef Abdelhamid",
        "Lennart Vater",
        "Zlatan Ajanovic"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T21:55:59+00:00",
          "link": "https://arxiv.org/abs/2506.23023v1",
          "size": "285kb",
          "version": "v1"
        }
      ],
      "title": "Scenario-Based Hierarchical Reinforcement Learning for Automated Driving Decision Making",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23023",
        "HTML": "https://arxiv.org/html/2506.23023v1",
        "PDF": "https://arxiv.org/pdf/2506.23023"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23024",
      "abstract": "Physics-informed neural networks (PINNs) offer a flexible way to solve partial differential equations (PDEs) with machine learning, yet they still fall well short of the machine-precision accuracy many scientific tasks demand. In this work, we investigate whether the precision ceiling comes from the ill-conditioning of the PDEs or from the typical multi-layer perceptron (MLP) architecture. We introduce the Barycentric Weight Layer (BWLer), which models the PDE solution through barycentric polynomial interpolation. A BWLer can be added on top of an existing MLP (a BWLer-hat) or replace it completely (explicit BWLer), cleanly separating how we represent the solution from how we take derivatives for the PDE loss. Using BWLer, we identify fundamental precision limitations within the MLP: on a simple 1-D interpolation task, even MLPs with O(1e5) parameters stall around 1e-8 RMSE -- about eight orders above float64 machine precision -- before any PDE terms are added. In PDE learning, adding a BWLer lifts this ceiling and exposes a tradeoff between achievable accuracy and the conditioning of the PDE loss. For linear PDEs we fully characterize this tradeoff with an explicit error decomposition and navigate it during training with spectral derivatives and preconditioning. Across five benchmark PDEs, adding a BWLer on top of an MLP improves RMSE by up to 30x for convection, 10x for reaction, and 1800x for wave equations while remaining compatible with first-order optimizers. Replacing the MLP entirely lets an explicit BWLer reach near-machine-precision on convection, reaction, and wave problems (up to 10 billion times better than prior results) and match the performance of standard PINNs on stiff Burgers' and irregular-geometry Poisson problems. Together, these findings point to a practical path for combining the flexibility of PINNs with the precision of classical spectral solvers.",
      "authors": [
        "Jerry Liu",
        "Yasa Baig",
        "Denise Hui Jean Lee",
        "Rajat Vadiraj Dwaraknath",
        "Atri Rudra",
        "Chris R\\'e"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T22:11:00+00:00",
          "link": "https://arxiv.org/abs/2506.23024v1",
          "size": "19571kb",
          "version": "v1"
        }
      ],
      "title": "BWLer: Barycentric Weight Layer Elucidates a Precision-Conditioning Tradeoff for PINNs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23024",
        "HTML": "https://arxiv.org/html/2506.23024v1",
        "PDF": "https://arxiv.org/pdf/2506.23024"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23025",
      "abstract": "Large language models (LLMs) are increasingly used across research and industry applications, yet their inference efficiency remains a significant challenge. As the computational power of modern GPU architectures continuously improves, their memory bandwidth and capacity have not scaled proportionally, creating a critical bottleneck during inference. To address this, we investigate ternary language models (TriLMs) that employ quantization-aware training to significantly reduce memory requirements. We first analyze the scalability of TriLMs by conducting a scaling law analysis, revealing that TriLMs benefit more from increasing training data than from scaling model parameters. Based on this observation, we introduce Spectra-1.1, an open suite of TriLMs trained on up to 1.2 trillion tokens, demonstrating sustained performance gains at scale. Furthermore, to improve inference efficiency, we propose novel 2-bit and 1.6-bit packing schemes for ternary weights, which demonstrate accelerated inference across various CPU architectures. Also, building on the 2-bit packing, we develop a GPU kernel called TriRun that accelerates end-to-end model inference by up to 5 times compared to floating-point baselines. To encourage further exploration and development of TriLMs, we will release the Spectra-1.1 suite and TriRun inference kernels. Overall, our work lays the foundation for building and deploying efficient LLMs, providing a valuable resource for the research community.",
      "authors": [
        "Tejas Vaidhya",
        "Ayush Kaushal",
        "Vineet Jain",
        "Francis Couture Harpin",
        "Prashant Shishodia",
        "Majid Behbahani",
        "Yuriy Nevmyvaka",
        "Irina Rish"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T22:13:43+00:00",
          "link": "https://arxiv.org/abs/2506.23025v1",
          "size": "918kb",
          "version": "v1"
        }
      ],
      "title": "Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23025",
        "HTML": "https://arxiv.org/html/2506.23025v1",
        "PDF": "https://arxiv.org/pdf/2506.23025"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23026",
      "abstract": "We present Machine Assistant with Reliable Knowledge (MARK), a retrieval-augmented question-answering system designed to support student learning through accurate and contextually grounded responses. The system is built on a retrieval-augmented generation (RAG) framework, which integrates a curated knowledge base to ensure factual consistency. To enhance retrieval effectiveness across diverse question types, we implement a hybrid search strategy that combines dense vector similarity with sparse keyword-based retrieval. This dual-retrieval mechanism improves robustness for both general and domain-specific queries. The system includes a feedback loop in which students can rate responses and instructors can review and revise them. Instructor corrections are incorporated into the retrieval corpus, enabling adaptive refinement over time. The system was deployed in a classroom setting as a substitute for traditional office hours, where it successfully addressed a broad range of student queries. It was also used to provide technical support by integrating with a customer-specific knowledge base, demonstrating its ability to handle routine, context-sensitive tasks in applied domains. MARK is publicly accessible at https://app.eduquery.ai.",
      "authors": [
        "Yongsheng Lian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T22:17:27+00:00",
          "link": "https://arxiv.org/abs/2506.23026v1",
          "size": "367kb",
          "version": "v1"
        }
      ],
      "title": "Machine Assistant with Reliable Knowledge: Enhancing Student Learning via RAG-based Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23026",
        "HTML": "https://arxiv.org/html/2506.23026v1",
        "PDF": "https://arxiv.org/pdf/2506.23026"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23028",
      "abstract": "The Vehicle Routing Problem (VRP) is a fundamental challenge in logistics management research, given its substantial influence on transportation efficiency, cost minimization, and service quality. As a combinatorial optimization problem, VRP plays a crucial role in a wide range of real world applications, particularly in transportation, logistics, and delivery systems, due to its diverse formulations and numerous extensions. Over the years, researchers have introduced various VRP variants to address specific operational constraints, emerging industry requirements and optimize specific objectives, making it one of the most extensively studied problems in operations research. This article provides a comprehensive overview of VRP by exploring its theoretical foundations, discussing the limitations of its classical model, and introducing its key extensions. By systematically reviewing the diverse constraints, objectives, and variants examined in recent literature, this study aims to contribute to a deeper understanding of VRP while highlighting its ongoing evolution and relevance in modern optimization and decision making processes.",
      "authors": [
        "Souad Abdoune and Menouar Boulif"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T22:22:29+00:00",
          "link": "https://arxiv.org/abs/2506.23028v1",
          "size": "1799kb",
          "version": "v1"
        }
      ],
      "title": "Towards a better approach to the Vehicle Routing Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23028",
        "HTML": "https://arxiv.org/html/2506.23028v1",
        "PDF": "https://arxiv.org/pdf/2506.23028"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23030",
      "abstract": "VisionScores presents a novel proposal being the first system-segmented image score dataset, aiming to offer structure-rich, high information-density images for machine and deep learning tasks. Delimited to two-handed piano pieces, it was built to consider not only certain graphic similarity but also composition patterns, as this creative process is highly instrument-dependent. It provides two scenarios in relation to composer and composition type. The first, formed by 14k samples, considers works from different authors but the same composition type, specifically, Sonatinas. The latter, consisting of 10.8K samples, presents the opposite case, various composition types from the same author, being the one selected Franz Liszt. All of the 24.8k samples are formatted as grayscale jpg images of $128 \\times 512$ pixels. VisionScores supplies the users not only the formatted samples but the systems' order and pieces' metadata. Moreover, unsegmented full-page scores and the pre-formatted images are included for further analysis.",
      "authors": [
        "Alejandro Romero Amezcua and Mariano Jos\\'e Juan Rivera Meraz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T22:29:23+00:00",
          "link": "https://arxiv.org/abs/2506.23030v1",
          "size": "1499kb",
          "version": "v1"
        }
      ],
      "title": "VisionScores -- A system-segmented image score dataset for deep learning tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23030",
        "HTML": "https://arxiv.org/html/2506.23030v1",
        "PDF": "https://arxiv.org/pdf/2506.23030"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23032",
      "abstract": "One classic idea from the cybernetics literature is the Every Good Regulator Theorem (EGRT). The EGRT provides a means to identify good regulation, or the conditions under which an agent (regulator) can match the dynamical behavior of a system. We reevaluate and recast the EGRT in a modern context to provide insight into how intelligent autonomous learning systems might utilize a compressed global representation (world model). One-to-one mappings between a regulator (R) and the corresponding system (S) provide a reduced representation that preserves useful variety to match all possible outcomes of a system. Secondarily, we question the role of purpose or autonomy in this process, demonstrating how physical paradigms such as temporal criticality, non-normal denoising, and alternating procedural acquisition can recast behavior as statistical mechanics and yield regulatory relationships. These diverse physical systems challenge the notion of tightly-coupled good regulation when applied to non-uniform and out-of-distribution phenomena. Modern definitions of intelligence are found to be inadequate, and can be improved upon by viewing intelligence as embodied non-purposeful good regulation. Overall, we aim to recast the EGRT as a tool for contemporary Artificial Intelligence (AI) architectures by considering the role of good regulation in the implementation of world models.",
      "authors": [
        "Bradly Alicea",
        "Morgan Hough",
        "Amanda Nelson",
        "and Jesse Parent"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Other Computer Science (cs.OH)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T22:49:43+00:00",
          "link": "https://arxiv.org/abs/2506.23032v1",
          "size": "3510kb",
          "version": "v1"
        }
      ],
      "title": "A \"Good\" Regulator May Provide a World Model for Intelligent Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23032",
        "PDF": "https://arxiv.org/pdf/2506.23032"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23033",
      "abstract": "Bias in predictive machine learning (ML) models is a fundamental challenge due to the skewed or unfair outcomes produced by biased models. Existing mitigation strategies rely on either post-hoc corrections or rigid constraints. However, emerging research claims that these techniques can limit scalability and reduce generalizability. To address this, this paper introduces a feature-wise mixing framework to mitigate contextual bias. This was done by redistributing feature representations across multiple contextual datasets. To assess feature-wise mixing's effectiveness, four ML classifiers were trained using cross-validation and evaluated with bias-sensitive loss functions, including disparity metrics and mean squared error (MSE), which served as a standard measure of predictive performance. The proposed method achieved an average bias reduction of 43.35% and a statistically significant decrease in MSE across all classifiers trained on mixed datasets. Additionally, benchmarking against established bias mitigation techniques found that feature-wise mixing consistently outperformed SMOTE oversampling and demonstrated competitive effectiveness without requiring explicit bias attribute identification. Feature-wise mixing efficiently avoids the computational overhead typically associated with fairness-aware learning algorithms. Future work could explore applying feature-wise mixing for real-world fields where accurate predictions are necessary.",
      "authors": [
        "Yash Vardhan Tomar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T23:12:59+00:00",
          "link": "https://arxiv.org/abs/2506.23033v1",
          "size": "1421kb",
          "version": "v1"
        }
      ],
      "title": "Feature-Wise Mixing for Mitigating Contextual Bias in Predictive Supervised Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23033",
        "HTML": "https://arxiv.org/html/2506.23033v1",
        "PDF": "https://arxiv.org/pdf/2506.23033"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23034",
      "abstract": "Large Language Models (LLMs) have become powerful tools for automated code generation. However, these models often overlook critical security practices, which can result in the generation of insecure code that contains vulnerabilities-weaknesses or flaws in the code that attackers can exploit to compromise a system. However, there has been limited exploration of strategies to guide LLMs in generating secure code and a lack of in-depth analysis of the effectiveness of LLMs in repairing code containing vulnerabilities. In this paper, we present a comprehensive evaluation of state-of-the-art LLMs by examining their inherent tendencies to produce insecure code, their capability to generate secure code when guided by self-generated vulnerability hints, and their effectiveness in repairing vulnerabilities when provided with different levels of feedback. Our study covers both proprietary and open-weight models across various scales and leverages established benchmarks to assess a wide range of vulnerability types. Through quantitative and qualitative analyses, we reveal that although LLMs are prone to generating insecure code, advanced models can benefit from vulnerability hints and fine-grained feedback to avoid or fix vulnerabilities. We also provide actionable suggestions to developers to reduce vulnerabilities when using LLMs for code generation.",
      "authors": [
        "Hao Yan",
        "Swapneel Suhas Vaidya",
        "Xiaokuan Zhang",
        "Ziyu Yao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T23:24:33+00:00",
          "link": "https://arxiv.org/abs/2506.23034v1",
          "size": "1561kb",
          "version": "v1"
        }
      ],
      "title": "Guiding AI to Fix Its Own Flaws: An Empirical Study on LLM-Driven Secure Code Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23034",
        "HTML": "https://arxiv.org/html/2506.23034v1",
        "PDF": "https://arxiv.org/pdf/2506.23034"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23036",
      "abstract": "This paper explores Reinforcement learning (RL) policy robustness by systematically analyzing network parameters under internal and external stresses. Inspired by synaptic plasticity in neuroscience, synaptic filtering introduces internal stress by selectively perturbing parameters, while adversarial attacks apply external stress through modified agent observations. This dual approach enables the classification of parameters as fragile, robust, or antifragile, based on their influence on policy performance in clean and adversarial settings. Parameter scores are defined to quantify these characteristics, and the framework is validated on PPO-trained agents in Mujoco continuous control environments. The results highlight the presence of antifragile parameters that enhance policy performance under stress, demonstrating the potential of targeted filtering techniques to improve RL policy adaptability. These insights provide a foundation for future advancements in the design of robust and antifragile RL systems.",
      "authors": [
        "Zain ul Abdeen",
        "Ming Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T23:28:47+00:00",
          "link": "https://arxiv.org/abs/2506.23036v1",
          "size": "1432kb",
          "version": "v1"
        }
      ],
      "title": "Fragile, Robust, and Antifragile: A Perspective from Parameter Responses in Reinforcement Learning Under Stress",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23036",
        "HTML": "https://arxiv.org/html/2506.23036v1",
        "PDF": "https://arxiv.org/pdf/2506.23036"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23038",
      "abstract": "Collecting pixel-level labels for medical datasets can be a laborious and expensive process, and enhancing segmentation performance with a scarcity of labeled data is a crucial challenge. This work introduces AugPaint, a data augmentation framework that utilizes inpainting to generate image-label pairs from limited labeled data. AugPaint leverages latent diffusion models, known for their ability to generate high-quality in-domain images with low overhead, and adapts the sampling process for the inpainting task without need for retraining. Specifically, given a pair of image and label mask, we crop the area labeled with the foreground and condition on it during reversed denoising process for every noise level. Masked background area would gradually be filled in, and all generated images are paired with the label mask. This approach ensures the accuracy of match between synthetic images and label masks, setting it apart from existing dataset generation methods. The generated images serve as valuable supervision for training downstream segmentation models, effectively addressing the challenge of limited annotations. We conducted extensive evaluations of our data augmentation method on four public medical image segmentation datasets, including CT, MRI, and skin imaging. Results across all datasets demonstrate that AugPaint outperforms state-of-the-art label-efficient methodologies, significantly improving segmentation performance.",
      "authors": [
        "Xinrong Hu and Yiyu Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T23:44:18+00:00",
          "link": "https://arxiv.org/abs/2506.23038v1",
          "size": "1581kb",
          "version": "v1"
        }
      ],
      "title": "Inpainting is All You Need: A Diffusion-based Augmentation Method for Semi-supervised Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23038",
        "HTML": "https://arxiv.org/html/2506.23038v1",
        "PDF": "https://arxiv.org/pdf/2506.23038"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23041",
      "abstract": "Knowledge distillation from pretrained visual representation models offers an effective approach to improve small, task-specific production models. However, the effectiveness of such knowledge transfer drops significantly when distilling from strong models that are pretrained in a large scale. In this paper, we address this challenge for pretrained Vision Transformers (ViTs) by exploring methods to fine-tune them for more effective knowledge transfer. Motivated by the connection between mutual information and distillation effectiveness, we propose to employ mutual information-aware optimization during finetuning. For small or highly-imbalanced downstream datasets where such optimization becomes less effective, we introduce a simple yet effective heuristic of reweighting MLP blocks. This approach is inspired by our observation that top MLP blocks are primarily responsible for mutual information loss. Our method enables small student models to benefit from those pretrained models among the strongest.",
      "authors": [
        "Chengyu Dong",
        "Huan Gui",
        "Noveen Sachdeva",
        "Long Jin",
        "Ke Yin",
        "Jingbo Shang",
        "Lichan Hong",
        "Ed H.Chi",
        "Zhe Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T00:25:23+00:00",
          "link": "https://arxiv.org/abs/2506.23041v1",
          "size": "14239kb",
          "version": "v1"
        }
      ],
      "title": "ReMem: Mutual Information-Aware Fine-tuning of Pretrained Vision Transformers for Effective Knowledge Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23041",
        "HTML": "https://arxiv.org/html/2506.23041v1",
        "PDF": "https://arxiv.org/pdf/2506.23041"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23042",
      "abstract": "3D Gaussian Splatting has emerged as a powerful approach in novel view synthesis, delivering rapid training and rendering but at the cost of an ever-growing set of Gaussian primitives that strains memory and bandwidth. We introduce AutoOpti3DGS, a training-time framework that automatically restrains Gaussian proliferation without sacrificing visual fidelity. The key idea is to feed the input images to a sequence of learnable Forward and Inverse Discrete Wavelet Transforms, where low-pass filters are kept fixed, high-pass filters are learnable and initialized to zero, and an auxiliary orthogonality loss gradually activates fine frequencies. This wavelet-driven, coarse-to-fine process delays the formation of redundant fine Gaussians, allowing 3DGS to capture global structure first and refine detail only when necessary. Through extensive experiments, AutoOpti3DGS requires just a single filter learning-rate hyper-parameter, integrates seamlessly with existing efficient 3DGS frameworks, and consistently produces sparser scene representations more compatible with memory or storage-constrained hardware.",
      "authors": [
        "Hung Nguyen",
        "An Le",
        "Runfa Li",
        "Truong Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T00:27:17+00:00",
          "link": "https://arxiv.org/abs/2506.23042v1",
          "size": "10952kb",
          "version": "v1"
        }
      ],
      "title": "From Coarse to Fine: Learnable Discrete Wavelet Transforms for Efficient 3D Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23042",
        "HTML": "https://arxiv.org/html/2506.23042v1",
        "PDF": "https://arxiv.org/pdf/2506.23042"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23044",
      "abstract": "In this report, we introduce Ovis-U1, a 3-billion-parameter unified model that integrates multimodal understanding, text-to-image generation, and image editing capabilities. Building on the foundation of the Ovis series, Ovis-U1 incorporates a diffusion-based visual decoder paired with a bidirectional token refiner, enabling image generation tasks comparable to leading models like GPT-4o. Unlike some previous models that use a frozen MLLM for generation tasks, Ovis-U1 utilizes a new unified training approach starting from a language model. Compared to training solely on understanding or generation tasks, unified training yields better performance, demonstrating the enhancement achieved by integrating these two tasks. Ovis-U1 achieves a score of 69.6 on the OpenCompass Multi-modal Academic Benchmark, surpassing recent state-of-the-art models such as Ristretto-3B and SAIL-VL-1.5-2B. In text-to-image generation, it excels with scores of 83.72 and 0.89 on the DPG-Bench and GenEval benchmarks, respectively. For image editing, it achieves 4.00 and 6.42 on the ImgEdit-Bench and GEdit-Bench-EN, respectively. As the initial version of the Ovis unified model series, Ovis-U1 pushes the boundaries of multimodal understanding, generation, and editing.",
      "authors": [
        "Guo-Hua Wang",
        "Shanshan Zhao",
        "Xinjie Zhang",
        "Liangfu Cao",
        "Pengxin Zhan",
        "Lunhao Duan",
        "Shiyin Lu",
        "Minghao Fu",
        "Xiaohao Chen",
        "Jianshan Zhao",
        "Yang Li",
        "Qing-Guo Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T00:40:17+00:00",
          "link": "https://arxiv.org/abs/2506.23044v1",
          "size": "4130kb",
          "version": "v1"
        }
      ],
      "title": "Ovis-U1 Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23044",
        "PDF": "https://arxiv.org/pdf/2506.23044"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23046",
      "abstract": "Humans continuously infer the states, goals, and behaviors of others by perceiving their surroundings in dynamic, real-world social interactions. However, most Theory of Mind (ToM) benchmarks only evaluate static, text-based scenarios, which have a significant gap compared to real interactions. We propose the SoMi-ToM benchmark, designed to evaluate multi-perspective ToM in embodied multi-agent complex social interactions. This benchmark is based on rich multimodal interaction data generated by the interaction environment SoMi, covering diverse crafting goals and social relationships. Our framework supports multi-level evaluation: (1) first-person evaluation provides multimodal (visual, dialogue, action, etc.) input from a first-person perspective during a task for real-time state inference, (2) third-person evaluation provides complete third-person perspective video and text records after a task for goal and behavior inference. This evaluation method allows for a more comprehensive examination of a model's ToM capabilities from both the subjective immediate experience and the objective global observation. We constructed a challenging dataset containing 35 third-person perspective videos, 363 first-person perspective images, and 1225 expert-annotated multiple-choice questions (three options). On this dataset, we systematically evaluated the performance of human subjects and several state-of-the-art large vision-language models (LVLMs). The results show that LVLMs perform significantly worse than humans on SoMi-ToM: the average accuracy gap between humans and models is 40.1% in first-person evaluation and 26.4% in third-person evaluation. This indicates that future LVLMs need to further improve their ToM capabilities in embodied, complex social interactions.",
      "authors": [
        "Xianzhe Fan",
        "Xuhui Zhou",
        "Chuanyang Jin",
        "Kolby Nottingham",
        "Hao Zhu",
        "Maarten Sap"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T00:54:13+00:00",
          "link": "https://arxiv.org/abs/2506.23046v1",
          "size": "4949kb",
          "version": "v1"
        }
      ],
      "title": "SoMi-ToM: Evaluating Multi-Perspective Theory of Mind in Embodied Social Interactions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23046",
        "HTML": "https://arxiv.org/html/2506.23046v1",
        "PDF": "https://arxiv.org/pdf/2506.23046"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23049",
      "abstract": "Despite advances in language and speech technologies, no open-source system enables full speech-to-speech, multi-turn dialogue with integrated tool use and agentic reasoning. We introduce AURA (Agent for Understanding, Reasoning, and Automated Tool Use), the first open-source, speech-native assistant capable of completing complex, goal-driven tasks through dynamic tool invocation and multi-turn conversation. AURA combines open-weight ASR, TTS, and LLMs in a cascaded pipeline and supports tools such as calendar booking, contact lookup, web search, and email. Its modular design allows easy integration of new tools using natural language prompts and action classes. On VoiceBench, AURA scores 92.75% on OpenBookQA-outperforming all open-weight systems and nearing GPT-4o-and 4.39 on AlpacaEval, competitive with other open-weight systems. Human evaluation shows 90% task success on complex, multi-turn speech tasks.",
      "authors": [
        "Leander Melroy Maben",
        "Gayathri Ganesh Lakshmy",
        "Srijith Radhakrishnan",
        "Siddhant Arora",
        "Shinji Watanabe"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T01:13:15+00:00",
          "link": "https://arxiv.org/abs/2506.23049v1",
          "size": "479kb",
          "version": "v1"
        }
      ],
      "title": "AURA: Agent for Understanding, Reasoning, and Automated Tool Use in Voice-Driven Tasks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23049",
        "HTML": "https://arxiv.org/html/2506.23049v1",
        "PDF": "https://arxiv.org/pdf/2506.23049"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23050",
      "abstract": "We investigate properties of equivalence classes in AES which arise naturally from properties of MixColumns and InvMixColumns. These two operations have the property that the XOR of the 4 input bytes equals the XOR of 4 output bytes. We examine the effect on equivalence classes due to the operation of SubBytes, ShiftRows, MixColumns and AddRoundKey. The next phase of research is to find a key recovery attack using known (plaintext, ciphertext) equivalence class pairs.\n  Keywords: AES, Equivalence, Class, MixColumns, ShiftRows, SubBytes, AddRoundKey, Schedule, State, XOR",
      "authors": [
        "David Cornwell"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T01:14:57+00:00",
          "link": "https://arxiv.org/abs/2506.23050v1",
          "size": "1207kb",
          "version": "v1"
        }
      ],
      "title": "Equivalence Classes in AES -- Part 1",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23050",
        "PDF": "https://arxiv.org/pdf/2506.23050"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23051",
      "abstract": "Named Entity Recognition (NER) is a fundamental Natural Language Processing (NLP) task that aims to identify and classify entity mentions in texts across different categories. While languages such as English possess a large number of high-quality resources for this task, Brazilian Portuguese still lacks in quantity of gold-standard NER datasets, especially when considering specific domains. Particularly, this paper considers the importance of NER for analyzing historical texts in the context of digital humanities. To address this gap, this work outlines the construction of MariNER: \\textit{Mapeamento e Anota\\c{c}\\~oes de Registros hIst\\'oricos para NER} (Mapping and Annotation of Historical Records for NER), the first gold-standard dataset for early 20th-century Brazilian Portuguese, with more than 9,000 manually annotated sentences. We also assess and compare the performance of state-of-the-art NER models for the dataset.",
      "authors": [
        "Jo\\~ao Lucas Luz Lima Sarcinelli",
        "Marina Lages Gon\\c{c}alves Teixeira",
        "Jade Bortot de Paiva",
        "Diego Furtado Silva"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T01:23:57+00:00",
          "link": "https://arxiv.org/abs/2506.23051v1",
          "size": "182kb",
          "version": "v1"
        }
      ],
      "title": "MariNER: A Dataset for Historical Brazilian Portuguese Named Entity Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23051",
        "HTML": "https://arxiv.org/html/2506.23051v1",
        "PDF": "https://arxiv.org/pdf/2506.23051"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23052",
      "abstract": "Flexible intelligent metasurface (FIM) has emerged as a transformative technology to enhance wireless sensing by dynamically morphing its three-dimensional (3D) surface shape and electromagnetic response. Unlike conventional rigid arrays, an FIM consists of low-cost radiating elements that can independently adjust their positions and radiation characteristics, thereby allowing for real-time optimization of the sensing environment. This paper investigates the impact of FIM on wireless sensing performance. Specifically, we focus on the maximization of the cumulated power of the probing signals at the target locations under the per-antenna power constraint by jointly optimizing the transmit covariance matrix and the surface shape of the transmitting FIM. We propose a block coordinate descend (BCD) algorithm to find a locally optimal solution, by alternatively updating the FIM surface shape and the transmit covariance matrix, while keeping the other one fixed at each step. Furthermore, we analyze the computational complexity and convergence properties of the proposed algorithm and demonstrate that FIM enhances wireless sensing by providing a new design degree-of-freedom to coordinate the correlation between steering vectors at different angles. Numerical results demonstrate that FIM significantly improves wireless sensing performance under the considered multi-target scenario.",
      "authors": [
        "Zihao Teng",
        "Jiancheng An",
        "Lu Gan",
        "Naofal Al-Dhahir",
        "and Zhu Han"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T01:35:34+00:00",
          "link": "https://arxiv.org/abs/2506.23052v1",
          "size": "1565kb",
          "version": "v1"
        }
      ],
      "title": "Flexible Intelligent Metasurface for Enhancing Multi-Target Wireless Sensing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23052",
        "HTML": "https://arxiv.org/html/2506.23052v1",
        "PDF": "https://arxiv.org/pdf/2506.23052"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23053",
      "abstract": "Air quality prediction is a challenging forecasting task due to its spatio-temporal complexity and the inherent dynamics as well as uncertainty. Most of the current models handle these two challenges by applying Graph Neural Networks or known physics principles, and quantifying stochasticity through probabilistic networks like Diffusion models. Nevertheless, finding the right balancing point between the certainties and uncertainties remains an open question. Therefore, we propose Double-Diffusion, a novel diffusion probabilistic model that harnesses the power of known physics to guide air quality forecasting with stochasticity. To the best of our knowledge, while precedents have been made of using conditional diffusion models to predict air pollution, this is the first attempt to use physics as a conditional generative approach for air quality prediction. Along with a sampling strategy adopted from image restoration and a new denoiser architecture, Double-Diffusion ranks first in most evaluation scenarios across two real-life datasets compared with other probabilistic models, it also cuts inference time by 50% to 30% while enjoying an increase between 3-12% in Continuous Ranked Probabilistic Score (CRPS).",
      "authors": [
        "Hanlin Dong",
        "Arian Prabowo",
        "Hao Xue",
        "Flora D. Salim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T01:45:47+00:00",
          "link": "https://arxiv.org/abs/2506.23053v1",
          "size": "1748kb",
          "version": "v1"
        }
      ],
      "title": "Double-Diffusion: Diffusion Conditioned Diffusion Probabilistic Model For Air Quality Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23053",
        "HTML": "https://arxiv.org/html/2506.23053v1",
        "PDF": "https://arxiv.org/pdf/2506.23053"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23055",
      "abstract": "Large Language Models (LLMs) such as ChatGPT have shown remarkable abilities in producing human-like text. However, it is unclear how accurately these models internalize concepts that shape human thought and behavior. Here, we developed a quantitative framework to assess concept alignment between LLMs and human psychological dimensions using 43 standardized psychological questionnaires, selected for their established validity in measuring distinct psychological constructs. Our method evaluates how accurately language models reconstruct and classify questionnaire items through pairwise similarity analysis. We compared resulting cluster structures with the original categorical labels using hierarchical clustering. A GPT-4 model achieved superior classification accuracy (66.2\\%), significantly outperforming GPT-3.5 (55.9\\%) and BERT (48.1\\%), all exceeding random baseline performance (31.9\\%). We also demonstrated that the estimated semantic similarity from GPT-4 is associated with Pearson's correlation coefficients of human responses in multiple psychological questionnaires. This framework provides a novel approach to evaluate the alignment of the human-LLM concept and identify potential representational biases. Our findings demonstrate that modern LLMs can approximate human psychological constructs with measurable accuracy, offering insights for developing more interpretable AI systems.",
      "authors": [
        "Hiro Taiyo Hamada",
        "Ippei Fujisawa",
        "Genji Kawakita",
        "Yuki Yamada"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T01:56:56+00:00",
          "link": "https://arxiv.org/abs/2506.23055v1",
          "size": "723kb",
          "version": "v1"
        }
      ],
      "title": "Measuring How LLMs Internalize Human Psychological Concepts: A preliminary analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23055",
        "HTML": "https://arxiv.org/html/2506.23055v1",
        "PDF": "https://arxiv.org/pdf/2506.23055"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23056",
      "abstract": "Molecular structure elucidation involves deducing a molecule's structure from various types of spectral data, which is crucial in chemical experimental analysis. While large language models (LLMs) have shown remarkable proficiency in analyzing and reasoning through complex tasks, they still encounter substantial challenges in molecular structure elucidation. We identify that these challenges largely stem from LLMs' limited grasp of specialized chemical knowledge. In this work, we introduce a Knowledge-enhanced reasoning framework for Molecular Structure Elucidation (K-MSE), leveraging Monte Carlo Tree Search for test-time scaling as a plugin. Specifically, we construct an external molecular substructure knowledge base to extend the LLMs' coverage of the chemical structure space. Furthermore, we design a specialized molecule-spectrum scorer to act as a reward model for the reasoning process, addressing the issue of inaccurate solution evaluation in LLMs. Experimental results show that our approach significantly boosts performance, particularly gaining more than 20% improvement on both GPT-4o-mini and GPT-4o. Our code is available at https://github.com/HICAI-ZJU/K-MSE.",
      "authors": [
        "Xiang Zhuang",
        "Bin Wu",
        "Jiyu Cui",
        "Kehua Feng",
        "Xiaotong Li",
        "Huabin Xing",
        "Keyan Ding",
        "Qiang Zhang",
        "Huajun Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T02:00:38+00:00",
          "link": "https://arxiv.org/abs/2506.23056v1",
          "size": "2408kb",
          "version": "v1"
        }
      ],
      "title": "Boosting LLM's Molecular Structure Elucidation with Knowledge Enhanced Tree Search Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23056",
        "HTML": "https://arxiv.org/html/2506.23056v1",
        "PDF": "https://arxiv.org/pdf/2506.23056"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23058",
      "abstract": "This paper presents a novel approach to automatically verify properties of pure data-parallel programs with non-linear indexing -- expressed as pre- and post-conditions on functions. Programs consist of nests of second-order array combinators (e.g., map, scan, and scatter) and loops. The key idea is to represent arrays as index functions: programs are index function transformations over which properties are propagated and inferred. Our framework proves properties on index functions by distilling them into algebraic (in)equalities and discharging them to a Fourier-Motzkin-based solver. The framework is practical and accessible: properties are not restricted to a decidable logic, but instead are carefully selected to express practically useful guarantees that can be automatically reasoned about and inferred. These guarantees extend beyond program correctness and can be exploited by the entire compiler pipeline for optimization. We implement our system in the pure data-parallel language Futhark and demonstrate its practicality on seven applications, reporting an average verification time of 1 second. Two case studies show how eliminating dynamic verification in GPU programs results in significant speedups.",
      "authors": [
        "Nikolaj Hey Hinnerskov",
        "Robert Schenck and Cosmin E. Oancea"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T02:10:25+00:00",
          "link": "https://arxiv.org/abs/2506.23058v1",
          "size": "89kb",
          "version": "v1"
        }
      ],
      "title": "Verifying Properties of Index Arrays in a Purely-Functional Data-Parallel Language",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23058",
        "PDF": "https://arxiv.org/pdf/2506.23058"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23060",
      "abstract": "Industrial recommendation systems are typically composed of multiple stages, including retrieval, ranking, and blending. The retrieval stage plays a critical role in generating a high-recall set of candidate items that covers a wide range of diverse user interests. Effectively covering the diverse and long-tail user interests within this stage poses a significant challenge: traditional two-tower models struggle in this regard due to limited user-item feature interaction and often bias towards top use cases. To address these issues, we propose a novel multi-embedding retrieval framework designed to enhance user interest representation by generating multiple user embeddings conditioned on both implicit and explicit user interests. Implicit interests are captured from user history through a Differentiable Clustering Module (DCM), whereas explicit interests, such as topics that the user has followed, are modeled via Conditional Retrieval (CR). These methodologies represent a form of conditioned user representation learning that involves condition representation construction and associating the target item with the relevant conditions. Synergizing implicit and explicit user interests serves as a complementary approach to achieve more effective and comprehensive candidate retrieval as they benefit on different user segments and extract conditions from different but supplementary sources. Extensive experiments and A/B testing reveal significant improvements in user engagements and feed diversity metrics. Our proposed framework has been successfully deployed on Pinterest home feed.",
      "authors": [
        "Zhibo Fan",
        "Hongtao Lin",
        "Haoyu Chen",
        "Bowen Deng",
        "Hedi Xia",
        "Yuke Yan",
        "James Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T02:14:21+00:00",
          "link": "https://arxiv.org/abs/2506.23060v1",
          "size": "7618kb",
          "version": "v1"
        }
      ],
      "title": "Synergizing Implicit and Explicit User Interests: A Multi-Embedding Retrieval Framework at Pinterest",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23060",
        "HTML": "https://arxiv.org/html/2506.23060v1",
        "PDF": "https://arxiv.org/pdf/2506.23060"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23061",
      "abstract": "Empowering Small-scale Vision-Language Models (SVLMs) with reliable thinking capabilities remains fundamentally challenging due to their limited parameter capacity and weak instruction-following abilities. Existing training paradigms, including Supervised Fine-Tuning (SFT) and Reinforcement Learning with Verifiable Reward (RLVR), impose substantial demands on the base VLM, exceeding the capabilities of SVLMs. Consequently, directly applying these paradigms to SVLMs often suffers from severe pseudo thinking traces and advantage collapse, ultimately undermining both thinking reliability and task performance. A natural solution is to combine SFT and RLVR, leveraging their complementarity to reduce the dependence on model capacity. However, the widely adopted two-stage training paradigm still performs poorly on SVLMs, as their tendency toward sub-optimal convergence hinders the trade-off and limits the benefits of the combination. To address this, we propose DyME, a novel training paradigm that Dynamically selects between Memorization (via SFT) and Exploration (via RLVR) modes at each optimization step, ensuring that every update contributes to the trade-off. Extensive experiments across diverse domains demonstrate that DyME consistently achieves this balance, and thus delivers substantial performance improvements. These results establish DyME as a practical and effective solution for empowering SVLMs with reliable thinking capabilities. GitHub: https://github.com/HKUST-LongGroup/DyME",
      "authors": [
        "Jiazhen Liu",
        "Yuchuan Deng",
        "and Long Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T02:19:51+00:00",
          "link": "https://arxiv.org/abs/2506.23061v1",
          "size": "1484kb",
          "version": "v1"
        }
      ],
      "title": "Empowering Small VLMs to Think with Dynamic Memorization and Exploration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23061",
        "PDF": "https://arxiv.org/pdf/2506.23061"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23063",
      "abstract": "Directed Grey-box Fuzzing (DGF) has emerged as a widely adopted technique for crash reproduction and patch testing, leveraging its capability to precisely navigate toward target locations and exploit vulnerabilities. However, current DGF tools are constrained by insufficient runtime feedback, limiting their efficiency in reaching targets and exploring state spaces. This study presents HF-DGF, a novel directed grey-box fuzzing framework. Its seed scheduling is guided by a hybrid feedback mechanism integrating control-flow distance, value-flow influence score, and slice coverage. To enable precise control-flow distance feedback, we propose a backward-stepping algorithm to calculate basic block-level seed distances on a virtual inter-procedural control-flow graph (ICFG). For effective state space exploration, we introduce value-flow influence and a corresponding metric, the value-flow influence score. Additionally, to mitigate runtime overhead from hybrid feedback, we adopt a novel selective instrumentation strategy. Evaluations on 41 real-world vulnerabilities show HF-DGF outperforms existing tools: it achieves crash reproduction 5.05 times faster than AFL, 5.79 times faster than AFLGo, 73.75 times faster than WindRanger, 2.56 times faster than DAFL, and 8.45 times faster than Beacon on average. Notably, when all fuzzers triggered crashes, HF-DGF exhibited the lowest code coverage, demonstrating superior directionality and efficiency. It also surpasses AFLGo, WindRanger, DAFL, and Beacon in static analysis efficiency.",
      "authors": [
        "Guangfa Lyu",
        "Zhenzhong Cao",
        "Xiaofei Ren",
        "Fengyu Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T02:36:40+00:00",
          "link": "https://arxiv.org/abs/2506.23063v1",
          "size": "524kb",
          "version": "v1"
        }
      ],
      "title": "HF-DGF: Hybrid Feedback Guided Directed Grey-box Fuzzing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23063",
        "HTML": "https://arxiv.org/html/2506.23063v1",
        "PDF": "https://arxiv.org/pdf/2506.23063"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23066",
      "abstract": "Text watermarking schemes have gained considerable attention in recent years, yet still face critical challenges in achieving simultaneous robustness, generalizability, and imperceptibility. This paper introduces a new embedding paradigm,termed CORE, which comprises several consecutively aligned black pixel segments. Its key innovation lies in its inherent noise resistance during transmission and broad applicability across languages and fonts. Based on the CORE, we present a text watermarking framework named CoreMark. Specifically, CoreMark first dynamically extracts COREs from characters. Then, the characters with stronger robustness are selected according to the lengths of COREs. By modifying the thickness of the CORE, the hidden data is embedded into the selected characters without causing significant visual distortions. Moreover, a general plug-and-play embedding strength modulator is proposed, which can adaptively enhance the robustness for small font sizes by adjusting the embedding strength according to the font size. Experimental evaluation indicates that CoreMark demonstrates outstanding generalizability across multiple languages and fonts. Compared to existing methods, CoreMark achieves significant improvements in resisting screenshot, print-scan, and print camera attacks, while maintaining satisfactory imperceptibility.",
      "authors": [
        "Jiale Meng",
        "Yiming Li",
        "Zheming Lu",
        "Zewei He",
        "Hao Luo",
        "Tianwei Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Cryptography and Security (cs.CR)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T02:57:49+00:00",
          "link": "https://arxiv.org/abs/2506.23066v1",
          "size": "3313kb",
          "version": "v1"
        }
      ],
      "title": "CoreMark: Toward Robust and Universal Text Watermarking Technique",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23066",
        "HTML": "https://arxiv.org/html/2506.23066v1",
        "PDF": "https://arxiv.org/pdf/2506.23066"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23068",
      "abstract": "When building a world model, a common assumption is that the environment has a single, unchanging underlying causal rule, like applying Newton's laws to every situation. In reality, what appears as a drifting causal mechanism is often the manifestation of a fixed underlying mechanism seen through a narrow observational window. This brings about a problem that, when building a world model, even subtle shifts in policy or environment states can alter the very observed causal mechanisms. In this work, we introduce the \\textbf{Meta-Causal Graph} as world models, a minimal unified representation that efficiently encodes the transformation rules governing how causal structures shift across different latent world states. A single Meta-Causal Graph is composed of multiple causal subgraphs, each triggered by meta state, which is in the latent state space. Building on this representation, we introduce a \\textbf{Causality-Seeking Agent} whose objectives are to (1) identify the meta states that trigger each subgraph, (2) discover the corresponding causal relationships by agent curiosity-driven intervention policy, and (3) iteratively refine the Meta-Causal Graph through ongoing curiosity-driven exploration and agent experiences. Experiments on both synthetic tasks and a challenging robot arm manipulation task demonstrate that our method robustly captures shifts in causal dynamics and generalizes effectively to previously unseen contexts.",
      "authors": [
        "Zhiyu Zhao",
        "Haoxuan Li",
        "Haifeng Zhang",
        "Jun Wang",
        "Francesco Faccio",
        "J\\\"urgen Schmidhuber",
        "Mengyue Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T03:05:25+00:00",
          "link": "https://arxiv.org/abs/2506.23068v1",
          "size": "1050kb",
          "version": "v1"
        }
      ],
      "title": "Curious Causality-Seeking Agents Learn Meta Causal World",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23068",
        "HTML": "https://arxiv.org/html/2506.23068v1",
        "PDF": "https://arxiv.org/pdf/2506.23068"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23071",
      "abstract": "While Text-to-SQL enables natural language interaction with structured databases, its effectiveness diminishes with unstructured data or ambiguous queries due to rigid syntax and limited expressiveness. Concurrently, vector search has emerged as a powerful paradigm for semantic retrieval, particularly for unstructured data. However, existing VectorSQL implementations still rely heavily on manual crafting and lack tailored evaluation frameworks, leaving a significant gap between theoretical potential and practical deployment. To bridge these complementary paradigms, we introduces Text2VectorSQL, a novel framework unifying Text-to-SQL and vector search to overcome expressiveness constraints and support more diverse and holistical natural language queries. Specifically, Text2VectorSQL enables semantic filtering, multi-modal matching, and retrieval acceleration. For evaluation, we build vector index on appropriate columns, extend user queries with semantic search, and annotate ground truths via an automatic pipeline with expert review. Furthermore, we develop dedicated Text2VectorSQL models with synthetic data, demonstrating significant performance improvements over baseline methods. Our work establishes the foundation for the Text2VectorSQL task, paving the way for more versatile and intuitive database interfaces. The repository will be publicly available at https://github.com/Open-DataFlow/Text2VectorSQL.",
      "authors": [
        "Zhengren Wang",
        "Bozhou Li",
        "Dongwen Yao",
        "Wentao Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T03:17:42+00:00",
          "link": "https://arxiv.org/abs/2506.23071v1",
          "size": "344kb",
          "version": "v1"
        }
      ],
      "title": "Text2VectorSQL: Bridging Text-to-SQL and Vector Search for Unified Natural Language Queries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23071",
        "HTML": "https://arxiv.org/html/2506.23071v1",
        "PDF": "https://arxiv.org/pdf/2506.23071"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23072",
      "abstract": "Reconstructing 3D braided hairstyles from single-view images remains a challenging task due to the intricate interwoven structure and complex topologies of braids. Existing strand-based hair reconstruction methods typically focus on loose hairstyles and often struggle to capture the fine-grained geometry of braided hair. In this paper, we propose a novel unsupervised pipeline for efficiently reconstructing 3D braided hair from single-view RGB images. Leveraging a synthetic braid model inspired by braid theory, our approach effectively captures the complex intertwined structures of braids. Extensive experiments demonstrate that our method outperforms state-of-the-art approaches, providing superior accuracy, realism, and efficiency in reconstructing 3D braided hairstyles, supporting expressive hairstyle modeling in digital humans.",
      "authors": [
        "Jing Gao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T03:23:06+00:00",
          "link": "https://arxiv.org/abs/2506.23072v1",
          "size": "3453kb",
          "version": "v1"
        }
      ],
      "title": "Unsupervised 3D Braided Hair Reconstruction from a Single-View Image",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23072",
        "HTML": "https://arxiv.org/html/2506.23072v1",
        "PDF": "https://arxiv.org/pdf/2506.23072"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23074",
      "abstract": "In this paper, we propose a Counterfactually Decoupled Attention Learning (CDAL) method for open-world model attribution. Existing methods rely on handcrafted design of region partitioning or feature space, which could be confounded by the spurious statistical correlations and struggle with novel attacks in open-world scenarios. To address this, CDAL explicitly models the causal relationships between the attentional visual traces and source model attribution, and counterfactually decouples the discriminative model-specific artifacts from confounding source biases for comparison. In this way, the resulting causal effect provides a quantification on the quality of learned attention maps, thus encouraging the network to capture essential generation patterns that generalize to unseen source models by maximizing the effect. Extensive experiments on existing open-world model attribution benchmarks show that with minimal computational overhead, our method consistently improves state-of-the-art models by large margins, particularly for unseen novel attacks. Source code: https://github.com/yzheng97/CDAL.",
      "authors": [
        "Yu Zheng",
        "Boyang Gong",
        "Fanye Kong",
        "Yueqi Duan",
        "Bingyao Yu",
        "Wenzhao Zheng",
        "Lei Chen",
        "Jiwen Lu",
        "Jie Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T03:25:45+00:00",
          "link": "https://arxiv.org/abs/2506.23074v1",
          "size": "4348kb",
          "version": "v1"
        }
      ],
      "title": "Learning Counterfactually Decoupled Attention for Open-World Model Attribution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23074",
        "HTML": "https://arxiv.org/html/2506.23074v1",
        "PDF": "https://arxiv.org/pdf/2506.23074"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23075",
      "abstract": "Understanding and decoding brain activity from electroencephalography (EEG) signals is a fundamental challenge in neuroscience and AI, with applications in cognition, emotion recognition, diagnosis, and brain-computer interfaces. While recent EEG foundation models advance generalized decoding via unified architectures and large-scale pretraining, they adopt a scale-agnostic dense modeling paradigm inherited from NLP and vision. This design neglects a core property of neural activity: cross-scale spatiotemporal structure. EEG task patterns span a wide range of temporal and spatial scales, from short bursts to slow rhythms, and from localized cortical responses to distributed interactions. Ignoring this diversity leads to suboptimal representations and weak generalization. We propose CSBrain, a Cross-scale Spatiotemporal Brain foundation model for generalized EEG decoding. CSBrain introduces: (i) Cross-scale Spatiotemporal Tokenization (CST), which aggregates multi-scale features from localized temporal windows and anatomical brain regions into compact scale-aware tokens; and (ii) Structured Sparse Attention (SSA), which captures cross-window and cross-region dependencies, enhancing scale diversity while removing spurious correlations. CST and SSA are alternately stacked to progressively integrate multi-scale dependencies. Experiments on 11 EEG tasks across 16 datasets show that CSBrain consistently outperforms task-specific and foundation model baselines. These results establish cross-scale modeling as a key inductive bias and position CSBrain as a robust backbone for future brain-AI research.",
      "authors": [
        "Yuchen Zhou",
        "Jiamin Wu",
        "Zichen Ren",
        "Zhouheng Yao",
        "Weiheng Lu",
        "Kunyu Peng",
        "Qihao Zheng",
        "Chunfeng Song",
        "Wanli Ouyang",
        "Chao Gou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)",
        "Signal Processing (eess.SP)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T03:29:34+00:00",
          "link": "https://arxiv.org/abs/2506.23075v1",
          "size": "14483kb",
          "version": "v1"
        }
      ],
      "title": "CSBrain: A Cross-scale Spatiotemporal Brain Foundation Model for EEG Decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23075",
        "HTML": "https://arxiv.org/html/2506.23075v1",
        "PDF": "https://arxiv.org/pdf/2506.23075"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23077",
      "abstract": "Existing deep learning-based cross-view geo-localization methods primarily focus on improving the accuracy of cross-domain image matching, rather than enabling models to comprehensively capture contextual information around the target and minimize the cost of localization errors. To support systematic research into this Distance-Aware Cross-View Geo-Localization (DACVGL) problem, we construct Distance-Aware Campus (DA-Campus), the first benchmark that pairs multi-view imagery with precise distance annotations across three spatial resolutions. Based on DA-Campus, we formulate DACVGL as a hierarchical retrieval problem across different domains. Our study further reveals that, due to the inherent complexity of spatial relationships among buildings, this problem can only be addressed via a contrastive learning paradigm, rather than conventional metric learning. To tackle this challenge, we propose Dynamic Contrastive Learning (DyCL), a novel framework that progressively aligns feature representations according to hierarchical spatial margins. Extensive experiments demonstrate that DyCL is highly complementary to existing multi-scale metric learning methods and yields substantial improvements in both hierarchical retrieval performance and overall cross-view geo-localization accuracy. Our code and benchmark are publicly available at https://github.com/anocodetest1/DyCL.",
      "authors": [
        "Suofei Zhang",
        "Xinxin Wang",
        "Xiaofu Wu",
        "Quan Zhou",
        "Haifeng Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T03:57:01+00:00",
          "link": "https://arxiv.org/abs/2506.23077v1",
          "size": "14331kb",
          "version": "v1"
        }
      ],
      "title": "Dynamic Contrastive Learning for Hierarchical Retrieval: A Case Study of Distance-Aware Cross-View Geo-Localization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23077",
        "HTML": "https://arxiv.org/html/2506.23077v1",
        "PDF": "https://arxiv.org/pdf/2506.23077"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23078",
      "abstract": "The event camera, renowned for its high dynamic range and exceptional temporal resolution, is recognized as an important sensor for visual odometry. However, the inherent noise in event streams complicates the selection of high-quality map points, which critically determine the precision of state estimation. To address this challenge, we propose Voxel-ESVIO, an event-based stereo visual-inertial odometry system that utilizes voxel map management, which efficiently filter out high-quality 3D points. Specifically, our methodology utilizes voxel-based point selection and voxel-aware point management to collectively optimize the selection and updating of map points on a per-voxel basis. These synergistic strategies enable the efficient retrieval of noise-resilient map points with the highest observation likelihood in current frames, thereby ensureing the state estimation accuracy. Extensive evaluations on three public benchmarks demonstrate that our Voxel-ESVIO outperforms state-of-the-art methods in both accuracy and computational efficiency.",
      "authors": [
        "Zhaoxing Zhang",
        "Xiaoxiang Wang",
        "Chengliang Zhang",
        "Yangyang Guo",
        "Zikang Yuan",
        "Xin Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T04:01:51+00:00",
          "link": "https://arxiv.org/abs/2506.23078v1",
          "size": "836kb",
          "version": "v1"
        }
      ],
      "title": "Event-based Stereo Visual-Inertial Odometry with Voxel Map",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23078",
        "HTML": "https://arxiv.org/html/2506.23078v1",
        "PDF": "https://arxiv.org/pdf/2506.23078"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23079",
      "abstract": "The promotion of the national education digitalization strategy has facilitated the development of teaching quality evaluation towards all-round, process-oriented, precise, and intelligent directions, inspiring explorations into new methods and technologies for educational quality assurance. Classroom teaching evaluation methods dominated by teaching supervision and student teaching evaluation suffer from issues such as low efficiency, strong subjectivity, and limited evaluation dimensions. How to further advance intelligent and objective evaluation remains a topic to be explored. This paper, based on image recognition technology, speech recognition technology, and AI large language models, develops a comprehensive evaluation system that automatically generates evaluation reports and optimization suggestions from two dimensions: teacher teaching ability and classroom teaching effectiveness. This study establishes a closed-loop classroom evaluation model that comprehensively evaluates student and teaching conditions based on multi-dimensional data throughout the classroom teaching process, and further analyzes the data to guide teaching improvement. It meets the requirements of all-round and process-oriented classroom evaluation in the era of digital education, effectively solves the main problems of manual evaluation methods, and provides data collection and analysis methods as well as technologies for relevant research on educational teaching evaluation.",
      "authors": [
        "Cong Xie",
        "Li Yang",
        "Daben Wang",
        "Jing Xiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T04:06:55+00:00",
          "link": "https://arxiv.org/abs/2506.23079v1",
          "size": "801kb",
          "version": "v1"
        }
      ],
      "title": "Research on Comprehensive Classroom Evaluation System Based on Multiple AI Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23079",
        "PDF": "https://arxiv.org/pdf/2506.23079"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23080",
      "abstract": "This paper presents a comprehensive five-stage evolutionary framework for understanding the development of artificial intelligence, arguing that its trajectory mirrors the historical progression of human cognitive technologies. We posit that AI is advancing through distinct epochs, each defined by a revolutionary shift in its capacity for representation and reasoning, analogous to the inventions of cuneiform, the alphabet, grammar and logic, mathematical calculus, and formal logical systems. This \"Geometry of Cognition\" framework moves beyond mere metaphor to provide a systematic, cross-disciplinary model that not only explains AI's past architectural shifts-from expert systems to Transformers-but also charts a concrete and prescriptive path forward. Crucially, we demonstrate that this evolution is not merely linear but reflexive: as AI advances through these stages, the tools and insights it develops create a feedback loop that fundamentally reshapes its own underlying architecture. We are currently transitioning into a \"Metalinguistic Moment,\" characterized by the emergence of self-reflective capabilities like Chain-of-Thought prompting and Constitutional AI. The subsequent stages, the \"Mathematical Symbolism Moment\" and the \"Formal Logic System Moment,\" will be defined by the development of a computable calculus of thought, likely through neuro-symbolic architectures and program synthesis, culminating in provably aligned and reliable AI that reconstructs its own foundational representations. This work serves as the methodological capstone to our trilogy, which previously explored the economic drivers (\"why\") and cognitive nature (\"what\") of AI. Here, we address the \"how,\" providing a theoretical foundation for future research and offering concrete, actionable strategies for startups and developers aiming to build the next generation of intelligent systems.",
      "authors": [
        "Xinmin Fang",
        "Lingfeng Tao",
        "Zhengxiong Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T04:14:19+00:00",
          "link": "https://arxiv.org/abs/2506.23080v1",
          "size": "1458kb",
          "version": "v1"
        }
      ],
      "title": "AI's Euclid's Elements Moment: From Language Models to Computable Thought",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23080",
        "HTML": "https://arxiv.org/html/2506.23080v1",
        "PDF": "https://arxiv.org/pdf/2506.23080"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23081",
      "abstract": "Due to their widespread applications, linear complementary pairs (LCPs) have attracted much attention in recent years. In this paper, we determine explicit construction of non-special divisors of degree $g$ and $g-1$ on Kummer extensions with specific properties. In addition, we present several methods for constructing LCPs of algebraic geometry codes (AG Codes) via Kummer extensions. These results are applied in constructing explicit LCPs of AG Codes from subcovers of the BM curve, elliptic function fields, hyperelliptic function fields and other function fields. It is important to mention that we construct several families LCPs of MDS AG Codes from elliptic function fields and we obtain some linear complementary dual (LCD) codes from certain maximal elliptic function fields and hyperelliptic function fields.",
      "authors": [
        "Huang Junjie and Chen Haojie and Zhang Huachao and Zhao Chang-An"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T04:21:05+00:00",
          "link": "https://arxiv.org/abs/2506.23081v1",
          "size": "22kb",
          "version": "v1"
        }
      ],
      "title": "Linear Complementary Pairs of Algebraic Geometry Codes via Kummer Extensions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23081",
        "HTML": "https://arxiv.org/html/2506.23081v1",
        "PDF": "https://arxiv.org/pdf/2506.23081"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23083",
      "abstract": "Fast diagnosis and repair of enterprise network failures is critically important since disruptions cause major business impacts. Prior works focused on diagnosis primitives or procedures limited to a subset of the problem, such as only data plane or only control plane faults. This paper proposes a new paradigm, model-based network diagnosis, that provides a systematic way to derive automated procedures for identifying the root cause of network failures, based on reports of end-to-end user-level symptoms. The diagnosis procedures are systematically derived from a model of packet forwarding and routing, covering hardware, firmware, and software faults in both the data plane and distributed control plane. These automated procedures replace and dramatically accelerate diagnosis by an experienced human operator. Model-based diagnosis is inspired by, leverages, and is complementary to recent work on network verification. We have built NetDx, a proof-of-concept implementation of model-based network diagnosis. We deployed NetDx on a new emulator of networks consisting of P4 switches with distributed routing software. We validated the robustness and coverage of NetDx with an automated fault injection campaign, in which 100% of faults were diagnosed correctly. Furthermore, on a data set of 33 faults from a large cloud provider that are within the domain targeted by NetDx, 30 are efficiently diagnosed in seconds instead of hours.",
      "authors": [
        "Changrong Wu",
        "Yiyao Yu",
        "Myungjin Lee",
        "Jayanth Srinivasa",
        "Ennan Zhai",
        "George Varghese",
        "Yuval Tamir"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T04:44:31+00:00",
          "link": "https://arxiv.org/abs/2506.23083v1",
          "size": "212kb",
          "version": "v1"
        }
      ],
      "title": "Model-Based Diagnosis: Automating End-to-End Diagnosis of Network Failures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23083",
        "HTML": "https://arxiv.org/html/2506.23083v1",
        "PDF": "https://arxiv.org/pdf/2506.23083"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23084",
      "abstract": "In this paper, we develop and analyze a time-domain perfectly matched layer (PML) method for the stochastic acoustic wave equation driven by spatially white additive Gaussian noise. We begin by establishing the well-posedness and stability of the direct problem through a rigorous analysis of the associated time-harmonic stochastic Helmholtz equation and the application of an abstract Laplace transform inversion theorem. To address the low regularity of the random source, we employ scattering theory to investigate the meromorphic continuation of the Helmholtz resolvent defined on rough fields. Based on a piecewise constant approximation of the white noise, we construct an approximate wave solution and formulate a time-domain PML method. The convergence of the PML method is established, with explicit dependence on the PML layer's thickness and medium properties, as well as the piecewise constant approximation of the white noise. In addition, we propose a frequency-domain approach for solving the inverse random source problem using time-domain boundary measurements. A logarithmic stability estimate is derived, highlighting the ill-posedness of the inverse problem and offering guidance for the design of effective numerical schemes.",
      "authors": [
        "Hongxia Guo",
        "Tianjiao Wang",
        "Xiang Xu and Yue Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T04:45:35+00:00",
          "link": "https://arxiv.org/abs/2506.23084v1",
          "size": "24kb",
          "version": "v1"
        }
      ],
      "title": "PML method for the time-domain stochastic acoustic wave equation and an inverse source problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23084",
        "HTML": "https://arxiv.org/html/2506.23084v1",
        "PDF": "https://arxiv.org/pdf/2506.23084"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23085",
      "abstract": "The purpose of this paper is to explore a multi-modal approach to enhancing live broadcast engagement by developing a short video recommendation system that incorporates Multi-modal Graph Convolutional Networks (MMGCN) with user preferences. In order to provide personalized recommendations tailored to individual interests, the proposed system takes into account user interaction data, video content features, and contextual information. With the aid of a hybrid approach combining collaborative filtering and content-based filtering techniques, the system is able to capture nuanced relationships between users, video attributes, and engagement patterns. Three datasets are used to evaluate the effectiveness of the system: Kwai, TikTok, and MovieLens. Compared to baseline models, such as DeepFM, Wide & Deep, LightGBM, and XGBoost, the proposed MMGCN-based model shows superior performance. A notable feature of the proposed model is that it outperforms all baseline methods in capturing diverse user preferences and making accurate, personalized recommendations, resulting in a Kwai F1 score of 0.574, a Tiktok F1 score of 0.506, and a MovieLens F1 score of 0.197. We emphasize the importance of multi-modal integration and user-centric approaches in advancing recommender systems, emphasizing the role they play in enhancing content discovery and audience interaction on live broadcast platforms.",
      "authors": [
        "Saeid Aghasoleymani Najafabadi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T04:50:52+00:00",
          "link": "https://arxiv.org/abs/2506.23085v1",
          "size": "1011kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Live Broadcast Engagement: A Multi-modal Approach to Short Video Recommendations Using MMGCN and User Preferences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23085",
        "PDF": "https://arxiv.org/pdf/2506.23085"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23086",
      "abstract": "Automated and accurate segmentation of individual vertebra in 3D CT and MRI images is essential for various clinical applications. Due to the limitations of current imaging techniques and the complexity of spinal structures, existing methods still struggle with reducing the impact of image blurring and distinguishing similar vertebrae. To alleviate these issues, we introduce a Frequency-enhanced Multi-granularity Context Network (FMC-Net) to improve the accuracy of vertebrae segmentation. Specifically, we first apply wavelet transform for lossless downsampling to reduce the feature distortion in blurred images. The decomposed high and low-frequency components are then processed separately. For the high-frequency components, we apply a High-frequency Feature Refinement (HFR) to amplify the prominence of key features and filter out noises, restoring fine-grained details in blurred images. For the low-frequency components, we use a Multi-granularity State Space Model (MG-SSM) to aggregate feature representations with different receptive fields, extracting spatially-varying contexts while capturing long-range dependencies with linear complexity. The utilization of multi-granularity contexts is essential for distinguishing similar vertebrae and improving segmentation accuracy. Extensive experiments demonstrate that our method outperforms state-of-the-art approaches on both CT and MRI vertebrae segmentation datasets. The source code is publicly available at https://github.com/anaanaa/FMCNet.",
      "authors": [
        "Jian Shi and Tianqi You and Pingping Zhang and Hongli Zhang and Rui Xu and Haojie Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T04:53:02+00:00",
          "link": "https://arxiv.org/abs/2506.23086v1",
          "size": "613kb",
          "version": "v1"
        }
      ],
      "title": "Frequency-enhanced Multi-granularity Context Network for Efficient Vertebrae Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23086",
        "HTML": "https://arxiv.org/html/2506.23086v1",
        "PDF": "https://arxiv.org/pdf/2506.23086"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23088",
      "abstract": "Modeling task-driven attention in driving is a fundamental challenge for both autonomous vehicles and cognitive science. Existing methods primarily predict where drivers look by generating spatial heatmaps, but fail to capture the cognitive motivations behind attention allocation in specific contexts, which limits deeper understanding of attention mechanisms. To bridge this gap, we introduce Explainable Driver Attention Prediction, a novel task paradigm that jointly predicts spatial attention regions (where), parses attended semantics (what), and provides cognitive reasoning for attention allocation (why). To support this, we present W3DA, the first large-scale explainable driver attention dataset. It enriches existing benchmarks with detailed semantic and causal annotations across diverse driving scenarios, including normal conditions, safety-critical situations, and traffic accidents. We further propose LLada, a Large Language model-driven framework for driver attention prediction, which unifies pixel modeling, semantic parsing, and cognitive reasoning within an end-to-end architecture. Extensive experiments demonstrate the effectiveness of LLada, exhibiting robust generalization across datasets and driving conditions. This work serves as a key step toward a deeper understanding of driver attention mechanisms, with significant implications for autonomous driving, intelligent driver training, and human-computer interaction.",
      "authors": [
        "Yuchen Zhou",
        "Jiayu Tang",
        "Xiaoyan Xiao",
        "Yueyao Lin",
        "Linkai Liu",
        "Zipeng Guo",
        "Hao Fei",
        "Xiaobo Xia",
        "Chao Gou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T04:59:39+00:00",
          "link": "https://arxiv.org/abs/2506.23088v1",
          "size": "8254kb",
          "version": "v1"
        }
      ],
      "title": "Where, What, Why: Towards Explainable Driver Attention Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23088",
        "HTML": "https://arxiv.org/html/2506.23088v1",
        "PDF": "https://arxiv.org/pdf/2506.23088"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23090",
      "abstract": "Online advertising in recommendation platforms has gained significant attention, with a predominant focus on channel recommendation and budget allocation strategies. However, current offline reinforcement learning (RL) methods face substantial challenges when applied to sparse advertising scenarios, primarily due to severe overestimation, distributional shifts, and overlooking budget constraints. To address these issues, we propose MTORL, a novel multi-task offline RL model that targets two key objectives. First, we establish a Markov Decision Process (MDP) framework specific to the nuances of advertising. Then, we develop a causal state encoder to capture dynamic user interests and temporal dependencies, facilitating offline RL through conditional sequence modeling. Causal attention mechanisms are introduced to enhance user sequence representations by identifying correlations among causal states. We employ multi-task learning to decode actions and rewards, simultaneously addressing channel recommendation and budget allocation. Notably, our framework includes an automated system for integrating these tasks into online advertising. Extensive experiments on offline and online environments demonstrate MTORL's superiority over state-of-the-art methods.",
      "authors": [
        "Langming Liu",
        "Wanyu Wang",
        "Chi Zhang",
        "Bo Li",
        "Hongzhi Yin",
        "Xuetao Wei",
        "Wenbo Su",
        "Bo Zheng",
        "Xiangyu Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T05:05:13+00:00",
          "link": "https://arxiv.org/abs/2506.23090v1",
          "size": "1134kb",
          "version": "v1"
        }
      ],
      "title": "Multi-task Offline Reinforcement Learning for Online Advertising in Recommender Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23090",
        "HTML": "https://arxiv.org/html/2506.23090v1",
        "PDF": "https://arxiv.org/pdf/2506.23090"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23092",
      "abstract": "Many scientific and engineering problems involving multi-physics span a wide range of scales. Understanding the interactions across these scales is essential for fully comprehending such complex problems. However, visualizing multivariate, multiscale data within an integrated view where correlations across space, scales, and fields are easily perceived remains challenging. To address this, we introduce a novel local spatial statistical visualization of flow fields across multiple fields and turbulence scales. Our method leverages the curvelet transform for scale decomposition of fields of interest, a level-set-restricted centroidal Voronoi tessellation to partition the spatial domain into local regions for statistical aggregation, and a set of glyph designs that combines information across scales and fields into a single, or reduced set of perceivable visual representations. Each glyph represents data aggregated within a Voronoi region and is positioned at the Voronoi site for direct visualization in a 3D view centered around flow features of interest. We implement and integrate our method into an interactive visualization system where the glyph-based technique operates in tandem with linked 3D spatial views and 2D statistical views, supporting a holistic analysis. We demonstrate with case studies visualizing turbulent combustion data--multi-scalar compressible flows--and turbulent incompressible channel flow data. This new capability enables scientists to better understand the interactions between multiple fields and length scales in turbulent flows.",
      "authors": [
        "Arisa Cowe",
        "Tyson Neuroth",
        "Qi Wu",
        "Martin Rieth",
        "Jacqueline Chen",
        "Myoungkyu Lee",
        "and Kwan-Liu Ma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T05:13:13+00:00",
          "link": "https://arxiv.org/abs/2506.23092v1",
          "size": "23477kb",
          "version": "v1"
        }
      ],
      "title": "Glyph-Based Multiscale Visualization of Turbulent Multi-Physics Statistics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23092",
        "HTML": "https://arxiv.org/html/2506.23092v1",
        "PDF": "https://arxiv.org/pdf/2506.23092"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23093",
      "abstract": "In this paper, we present a residual-driven multiscale method for simulating Darcy flow in perforated domains, where complex geometries and highly heterogeneous permeability make direct simulations computationally expensive. To address this, we introduce a velocity elimination technique that reformulates the mixed velocity-pressure system into a pressure-only formulation, significantly reducing complexity by focusing on the dominant pressure variable. Our method is developed within the Generalized Multiscale Finite Element Method (GMsFEM) framework. For each coarse block, we construct offline basis functions from local spectral problems that capture key geometric and physical features. Online basis functions are then adaptively enriched using residuals, allowing the method to incorporate global effects such as source terms and boundary conditions, thereby improving accuracy. We provide detailed error analysis demonstrating how the offline and online spaces contribute to the accuracy and efficiency of the solution. Numerical experiments confirm the method's effectiveness, showing substantial reductions in computational cost while maintaining high accuracy, particularly through adaptive online enrichment. These results highlight the method's potential for efficient and accurate simulation of Darcy flow in complex, heterogeneous perforated domains.",
      "authors": [
        "Wei Xie",
        "Shubin Fu",
        "Yin Yang",
        "Yunqing Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T05:14:38+00:00",
          "link": "https://arxiv.org/abs/2506.23093v1",
          "size": "5706kb",
          "version": "v1"
        }
      ],
      "title": "A residual driven multiscale method for Darcy's flow in perforated domains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23093",
        "HTML": "https://arxiv.org/html/2506.23093v1",
        "PDF": "https://arxiv.org/pdf/2506.23093"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23094",
      "abstract": "Hierarchical planning is a powerful approach to model long sequences structurally. Aside from considering hierarchies in the temporal structure of music, this paper explores an even more important aspect: concept hierarchy, which involves generating music ideas, transforming them, and ultimately organizing them--across musical time and space--into a complete composition. To this end, we introduce TOMI (Transforming and Organizing Music Ideas) as a novel approach in deep music generation and develop a TOMI-based model via instruction-tuned foundation LLM. Formally, we represent a multi-track composition process via a sparse, four-dimensional space characterized by clips (short audio or MIDI segments), sections (temporal positions), tracks (instrument layers), and transformations (elaboration methods). Our model is capable of generating multi-track electronic music with full-song structure, and we further integrate the TOMI-based model with the REAPER digital audio workstation, enabling interactive human-AI co-creation. Experimental results demonstrate that our approach produces higher-quality electronic music with stronger structural coherence compared to baselines.",
      "authors": [
        "Qi He",
        "Gus Xia",
        "Ziyu Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T05:15:41+00:00",
          "link": "https://arxiv.org/abs/2506.23094v1",
          "size": "1933kb",
          "version": "v1"
        }
      ],
      "title": "TOMI: Transforming and Organizing Music Ideas for Multi-Track Compositions with Full-Song Structure",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23094",
        "HTML": "https://arxiv.org/html/2506.23094v1",
        "PDF": "https://arxiv.org/pdf/2506.23094"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23100",
      "abstract": "Automated Program Repair (APR) techniques aim to automatically fix buggy programs. Among these, Large Language Model-based (LLM-based) approaches have shown great promise. Recent advances demonstrate that directly leveraging LLMs can achieve leading results. However, these techniques remain suboptimal in generating contextually relevant and accurate patches, as they often overlook repair ingredients crucial for practical program repair. In this paper, we propose ReinFix, a novel framework that enables LLMs to autonomously search for repair ingredients throughout both the reasoning and solution phases of bug fixing. In the reasoning phase, ReinFix integrates static analysis tools to retrieve internal ingredients, such as variable definitions, to assist the LLM in root cause analysis when it encounters difficulty understanding the context. During the solution phase, when the LLM lacks experience in fixing specific bugs, ReinFix searches for external ingredients from historical bug fixes with similar bug patterns, leveraging both the buggy code and its root cause to guide the LLM in identifying appropriate repair actions, thereby increasing the likelihood of generating correct patches. Evaluations on two popular benchmarks (Defects4J V1.2 and V2.0) demonstrate the effectiveness of our approach over SOTA baselines. Notably, ReinFix fixes 146 bugs, which is 32 more than the baselines on Defects4J V1.2. On Defects4J V2.0, ReinFix fixes 38 more bugs than the SOTA. Importantly, when evaluating on the recent benchmarks that are free of data leakage risk, ReinFix also maintains the best performance.",
      "authors": [
        "Jiayi Zhang",
        "Kai Huang",
        "Jian Zhang",
        "Yang Liu",
        "Chunyang Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T06:02:11+00:00",
          "link": "https://arxiv.org/abs/2506.23100v1",
          "size": "1114kb",
          "version": "v1"
        }
      ],
      "title": "Repair Ingredients Are All You Need: Improving Large Language Model-Based Program Repair via Repair Ingredients Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23100",
        "HTML": "https://arxiv.org/html/2506.23100v1",
        "PDF": "https://arxiv.org/pdf/2506.23100"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23101",
      "abstract": "Multimodal large language models (MLLMs) have shown impressive capabilities across tasks involving both visual and textual modalities. However, growing concerns remain about their potential to encode and amplify gender bias, particularly in socially sensitive applications. Existing benchmarks predominantly evaluate bias in isolated scenarios, overlooking how bias may emerge subtly through interpersonal interactions. We fill this gap by going beyond single-entity evaluation and instead focusing on a deeper examination of relational and contextual gender bias in dual-individual interactions. We introduce Genres, a novel benchmark designed to evaluate gender bias in MLLMs through the lens of social relationships in generated narratives. Genres assesses gender bias through a dual-character profile and narrative generation task that captures rich interpersonal dynamics and supports a fine-grained bias evaluation suite across multiple dimensions. Experiments on both open- and closed-source MLLMs reveal persistent, context-sensitive gender biases that are not evident in single-character settings. Our findings underscore the importance of relationship-aware benchmarks for diagnosing subtle, interaction-driven gender bias in MLLMs and provide actionable insights for future bias mitigation.",
      "authors": [
        "Yue Xu",
        "Wenjie Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T06:03:21+00:00",
          "link": "https://arxiv.org/abs/2506.23101v1",
          "size": "1290kb",
          "version": "v1"
        }
      ],
      "title": "From Individuals to Interactions: Benchmarking Gender Bias in Multimodal Large Language Models from the Lens of Social Relationship",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23101",
        "HTML": "https://arxiv.org/html/2506.23101v1",
        "PDF": "https://arxiv.org/pdf/2506.23101"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23104",
      "abstract": "Interactive segmentation (IS) allows users to iteratively refine object boundaries with minimal cues, such as positive and negative clicks. While the Segment Anything Model (SAM) has garnered attention in the IS community for its promptable segmentation capabilities, it often struggles in specialized domains or when handling complex scenarios (e.g., camouflaged or multi-part objects). To overcome these challenges, we propose DC-TTA, a novel test-time adaptation (TTA) framework that adapts SAM on a per-sample basis by leveraging user interactions as supervision. Instead of forcing a single model to incorporate all user clicks at once, DC-TTA partitions the clicks into more coherent subsets, each processed independently via TTA with a separated model. This Divide-and-Conquer strategy reduces conflicts among diverse cues and enables more localized updates. Finally, we merge the adapted models to form a unified predictor that integrates the specialized knowledge from each subset. Experimental results across various benchmarks demonstrate that DC-TTA significantly outperforms SAM's zero-shot results and conventional TTA methods, effectively handling complex tasks such as camouflaged object segmentation with fewer interactions and improved accuracy.",
      "authors": [
        "Jihun Kim",
        "Hoyong Kwon",
        "Hyeokjun Kweon",
        "Wooseong Jeong",
        "Kuk-Jin Yoon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T06:10:00+00:00",
          "link": "https://arxiv.org/abs/2506.23104v1",
          "size": "12796kb",
          "version": "v1"
        }
      ],
      "title": "DC-TTA: Divide-and-Conquer Framework for Test-Time Adaptation of Interactive Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23104",
        "HTML": "https://arxiv.org/html/2506.23104v1",
        "PDF": "https://arxiv.org/pdf/2506.23104"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23106",
      "abstract": "Multi-stroke characters in scripts such as Chinese and Japanese can be highly complex, posing significant challenges for both native speakers and, especially, non-native learners. If these characters can be simplified without degrading their legibility, it could reduce learning barriers for non-native speakers, facilitate simpler and legible font designs, and contribute to efficient character-based communication systems. In this paper, we propose a framework to systematically simplify multi-stroke characters by selectively removing strokes while preserving their overall legibility. More specifically, we use a highly accurate character recognition model to assess legibility and remove those strokes that minimally impact it. Experimental results on 1,256 character classes with 5, 10, 15, and 20 strokes reveal several key findings, including the observation that even after removing multiple strokes, many characters remain distinguishable. These findings suggest the potential for more formalized simplification strategies.",
      "authors": [
        "Ryo Ishiyama",
        "Shinnosuke Matsuo",
        "Seiichi Uchida"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T06:14:33+00:00",
          "link": "https://arxiv.org/abs/2506.23106v1",
          "size": "3035kb",
          "version": "v1"
        }
      ],
      "title": "Computer-Aided Multi-Stroke Character Simplification by Stroke Removal",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23106",
        "HTML": "https://arxiv.org/html/2506.23106v1",
        "PDF": "https://arxiv.org/pdf/2506.23106"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23107",
      "abstract": "Large language models (LLMs) have made significant strides, extending their applications to dialogue systems, automated content creation, and domain-specific advisory tasks. However, as their use grows, concerns have emerged regarding their reliability in simulating complex decision-making behavior, such as risky decision-making, where a single choice can lead to multiple outcomes. This study investigates the ability of LLMs to simulate risky decision-making scenarios. We compare model-generated decisions with actual human responses in a series of lottery-based tasks, using transportation stated preference survey data from participants in Sydney, Dhaka, Hong Kong, and Nanjing. Demographic inputs were provided to two LLMs -- ChatGPT 4o and ChatGPT o1-mini -- which were tasked with predicting individual choices. Risk preferences were analyzed using the Constant Relative Risk Aversion (CRRA) framework. Results show that both models exhibit more risk-averse behavior than human participants, with o1-mini aligning more closely with observed human decisions. Further analysis of multilingual data from Nanjing and Hong Kong indicates that model predictions in Chinese deviate more from actual responses compared to English, suggesting that prompt language may influence simulation performance. These findings highlight both the promise and the current limitations of LLMs in replicating human-like risk behavior, particularly in linguistic and cultural settings.",
      "authors": [
        "Bing Song",
        "Jianing Liu",
        "Sisi Jian",
        "Chenyang Wu",
        "Vinayak Dixit"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T06:16:57+00:00",
          "link": "https://arxiv.org/abs/2506.23107v1",
          "size": "212kb",
          "version": "v1"
        }
      ],
      "title": "Can Large Language Models Capture Human Risk Preferences? A Cross-Cultural Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23107",
        "HTML": "https://arxiv.org/html/2506.23107v1",
        "PDF": "https://arxiv.org/pdf/2506.23107"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23108",
      "abstract": "Accurate carotid plaque grading (CPG) is vital to assess the risk of cardiovascular and cerebrovascular diseases. Due to the small size and high intra-class variability of plaque, CPG is commonly evaluated using a combination of transverse and longitudinal ultrasound views in clinical practice. However, most existing deep learning-based multi-view classification methods focus on feature fusion across different views, neglecting the importance of representation learning and the difference in class features. To address these issues, we propose a novel Corpus-View-Category Refinement Framework (CVC-RF) that processes information from Corpus-, View-, and Category-levels, enhancing model performance. Our contribution is four-fold. First, to the best of our knowledge, we are the foremost deep learning-based method for CPG according to the latest Carotid Plaque-RADS guidelines. Second, we propose a novel center-memory contrastive loss, which enhances the network's global modeling capability by comparing with representative cluster centers and diverse negative samples at the Corpus level. Third, we design a cascaded down-sampling attention module to fuse multi-scale information and achieve implicit feature interaction at the View level. Finally, a parameter-free mixture-of-experts weighting strategy is introduced to leverage class clustering knowledge to weight different experts, enabling feature decoupling at the Category level. Experimental results indicate that CVC-RF effectively models global features via multi-level refinement, achieving state-of-the-art performance in the challenging CPG task.",
      "authors": [
        "Zhiyuan Zhu",
        "Jian Wang",
        "Yong Jiang",
        "Tong Han",
        "Yuhao Huang",
        "Ang Zhang",
        "Kaiwen Yang",
        "Mingyuan Luo",
        "Zhe Liu",
        "Yaofei Duan",
        "Dong Ni",
        "Tianhong Tang and Xin Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T06:20:15+00:00",
          "link": "https://arxiv.org/abs/2506.23108v1",
          "size": "6347kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Corpus-View-Category Refinement for Carotid Plaque Risk Grading in Ultrasound",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23108",
        "HTML": "https://arxiv.org/html/2506.23108v1",
        "PDF": "https://arxiv.org/pdf/2506.23108"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23111",
      "abstract": "Existing studies on fairness are largely Western-focused, making them inadequate for culturally diverse countries such as India. To address this gap, we introduce INDIC-BIAS, a comprehensive India-centric benchmark designed to evaluate fairness of LLMs across 85 identity groups encompassing diverse castes, religions, regions, and tribes. We first consult domain experts to curate over 1,800 socio-cultural topics spanning behaviors and situations, where biases and stereotypes are likely to emerge. Grounded in these topics, we generate and manually validate 20,000 real-world scenario templates to probe LLMs for fairness. We structure these templates into three evaluation tasks: plausibility, judgment, and generation. Our evaluation of 14 popular LLMs on these tasks reveals strong negative biases against marginalized identities, with models frequently reinforcing common stereotypes. Additionally, we find that models struggle to mitigate bias even when explicitly asked to rationalize their decision. Our evaluation provides evidence of both allocative and representational harms that current LLMs could cause towards Indian identities, calling for a more cautious usage in practical applications. We release INDIC-BIAS as an open-source benchmark to advance research on benchmarking and mitigating biases and stereotypes in the Indian context.",
      "authors": [
        "Janki Atul Nawale",
        "Mohammed Safi Ur Rahman Khan",
        "Janani D",
        "Mansi Gupta",
        "Danish Pruthi",
        "Mitesh M. Khapra"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T06:31:06+00:00",
          "link": "https://arxiv.org/abs/2506.23111v1",
          "size": "1646kb",
          "version": "v1"
        }
      ],
      "title": "FairI Tales: Evaluation of Fairness in Indian Contexts with a Focus on Bias and Stereotypes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23111",
        "HTML": "https://arxiv.org/html/2506.23111v1",
        "PDF": "https://arxiv.org/pdf/2506.23111"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23114",
      "abstract": "Recent advancements in quadruped robot research have significantly improved their ability to traverse complex and unstructured outdoor environments. However, the issue of noise generated during locomotion is generally overlooked, which is critically important in noise-sensitive indoor environments, such as service and healthcare settings, where maintaining low noise levels is essential. This study aims to optimize the acoustic noise generated by quadruped robots during locomotion through the development of advanced motion control algorithms. To achieve this, we propose a novel approach that minimizes noise emissions by integrating optimized gait design with tailored control strategies. This method achieves an average noise reduction of approximately 8 dBA during movement, thereby enhancing the suitability of quadruped robots for deployment in noise-sensitive indoor environments. Experimental results demonstrate the effectiveness of this approach across various indoor settings, highlighting the potential of quadruped robots for quiet operation in noise-sensitive environments.",
      "authors": [
        "Zhanxiang Cao",
        "Buqing Nie",
        "Yang Zhang",
        "and Yue Gao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T06:38:54+00:00",
          "link": "https://arxiv.org/abs/2506.23114v1",
          "size": "689kb",
          "version": "v1"
        }
      ],
      "title": "Minimizing Acoustic Noise: Enhancing Quiet Locomotion for Quadruped Robots in Indoor Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23114",
        "HTML": "https://arxiv.org/html/2506.23114v1",
        "PDF": "https://arxiv.org/pdf/2506.23114"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23115",
      "abstract": "Multimodal embedding models, built upon causal Vision Language Models (VLMs), have shown promise in various tasks. However, current approaches face three key limitations: the use of causal attention in VLM backbones is suboptimal for embedding tasks; scalability issues due to reliance on high-quality labeled paired data for contrastive learning; and limited diversity in training objectives and data. To address these issues, we propose MoCa, a two-stage framework for transforming pre-trained VLMs into effective bidirectional multimodal embedding models. The first stage, Modality-aware Continual Pre-training, introduces a joint reconstruction objective that simultaneously denoises interleaved text and image inputs, enhancing bidirectional context-aware reasoning. The second stage, Heterogeneous Contrastive Fine-tuning, leverages diverse, semantically rich multimodal data beyond simple image-caption pairs to enhance generalization and alignment. Our method addresses the stated limitations by introducing bidirectional attention through continual pre-training, scaling effectively with massive unlabeled datasets via joint reconstruction objectives, and utilizing diverse multimodal data for enhanced representation robustness. Experiments demonstrate that MoCa consistently improves performance across MMEB and ViDoRe-v2 benchmarks, achieving new state-of-the-art results, and exhibits strong scalability with both model size and training data on MMEB.",
      "authors": [
        "Haonan Chen",
        "Hong Liu",
        "Yuping Luo",
        "Liang Wang",
        "Nan Yang",
        "Furu Wei",
        "Zhicheng Dou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T06:41:00+00:00",
          "link": "https://arxiv.org/abs/2506.23115v1",
          "size": "833kb",
          "version": "v1"
        }
      ],
      "title": "MoCa: Modality-aware Continual Pre-training Makes Better Bidirectional Multimodal Embeddings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23115",
        "HTML": "https://arxiv.org/html/2506.23115v1",
        "PDF": "https://arxiv.org/pdf/2506.23115"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23116",
      "abstract": "User experience (UX) practices have evolved in stages and are entering a transformative phase (UX 3.0), driven by AI technologies and shifting user needs. Human-centered AI (HCAI) experiences are emerging, necessitating new UX approaches to support UX practices in the AI era. We propose a UX 3.0 paradigm framework to respond and guide UX practices in developing HCAI systems.",
      "authors": [
        "Wei Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T06:45:14+00:00",
          "link": "https://arxiv.org/abs/2506.23116v1",
          "size": "406kb",
          "version": "v1"
        }
      ],
      "title": "A User Experience 3.0 (UX 3.0) Paradigm Framework: Designing for Human-Centered AI Experiences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23116",
        "PDF": "https://arxiv.org/pdf/2506.23116"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23120",
      "abstract": "Recent advances in point cloud perception have demonstrated remarkable progress in scene understanding through vision-language alignment leveraging large language models (LLMs). However, existing methods may still encounter challenges in handling complex instructions that require accurate spatial reasoning, even if the 3D point cloud data provides detailed spatial cues such as size and position for identifying the targets. To tackle this issue, we propose Relevant Reasoning Segmentation (R$^2$S), a reasoning-based segmentation framework. The framework emulates human cognitive processes by decomposing spatial reasoning into two sequential stages: first identifying relevant elements, then processing instructions guided by their associated visual priors. Furthermore, acknowledging the inadequacy of existing datasets in complex reasoning tasks, we introduce 3D ReasonSeg, a reasoning-based segmentation dataset comprising 25,185 training samples and 3,966 validation samples with precise annotations. Both quantitative and qualitative experiments demonstrate that the R$^2$S and 3D ReasonSeg effectively endow 3D point cloud perception with stronger spatial reasoning capabilities, and we hope that they can serve as a new baseline and benchmark for future work.",
      "authors": [
        "Zhenhua Ning",
        "Zhuotao Tian",
        "Shaoshuai Shi",
        "Guangming Lu",
        "Daojing He",
        "Wenjie Pei",
        "Li Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T06:58:08+00:00",
          "link": "https://arxiv.org/abs/2506.23120v1",
          "size": "8667kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Spatial Reasoning in Multimodal Large Language Models through Reasoning-based Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23120",
        "HTML": "https://arxiv.org/html/2506.23120v1",
        "PDF": "https://arxiv.org/pdf/2506.23120"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23122",
      "abstract": "This work investigates the challenging task of identifying narrative roles - Hero, Villain, Victim, and Other - in Internet memes, across three diverse test sets spanning English and code-mixed (English-Hindi) languages. Building on an annotated dataset originally skewed toward the 'Other' class, we explore a more balanced and linguistically diverse extension, originally introduced as part of the CLEF 2024 shared task. Comprehensive lexical and structural analyses highlight the nuanced, culture-specific, and context-rich language used in real memes, in contrast to synthetically curated hateful content, which exhibits explicit and repetitive lexical markers. To benchmark the role detection task, we evaluate a wide spectrum of models, including fine-tuned multilingual transformers, sentiment and abuse-aware classifiers, instruction-tuned LLMs, and multimodal vision-language models. Performance is assessed under zero-shot settings using precision, recall, and F1 metrics. While larger models like DeBERTa-v3 and Qwen2.5-VL demonstrate notable gains, results reveal consistent challenges in reliably identifying the 'Victim' class and generalising across cultural and code-mixed content. We also explore prompt design strategies to guide multimodal models and find that hybrid prompts incorporating structured instructions and role definitions offer marginal yet consistent improvements. Our findings underscore the importance of cultural grounding, prompt engineering, and multimodal reasoning in modelling subtle narrative framings in visual-textual content.",
      "authors": [
        "Shivam Sharma and Tanmoy Chakraborty"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T07:12:11+00:00",
          "link": "https://arxiv.org/abs/2506.23122v1",
          "size": "21468kb",
          "version": "v1"
        }
      ],
      "title": "Decoding Memes: Benchmarking Narrative Role Classification across Multilingual and Multimodal Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23122",
        "PDF": "https://arxiv.org/pdf/2506.23122"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23123",
      "abstract": "Artificial intelligence is humanity's most promising technology because of the remarkable capabilities offered by foundation models. Yet, the same technology brings confusion and consternation: foundation models are poorly understood and they may precipitate a wide array of harms. This dissertation explains how technology and society coevolve in the age of AI, organized around three themes. First, the conceptual framing: the capabilities, risks, and the supply chain that grounds foundation models in the broader economy. Second, the empirical insights that enrich the conceptual foundations: transparency created via evaluations at the model level and indexes at the organization level. Finally, the transition from understanding to action: superior understanding of the societal impact of foundation models advances evidence-based AI policy. View together, this dissertation makes inroads into achieving better societal outcomes in the age of AI by building the scientific foundations and research-policy interface required for better AI governance.",
      "authors": [
        "Rishi Bommasani"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T07:16:48+00:00",
          "link": "https://arxiv.org/abs/2506.23123v1",
          "size": "31178kb",
          "version": "v1"
        }
      ],
      "title": "The Societal Impact of Foundation Models: Advancing Evidence-based AI Policy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23123",
        "PDF": "https://arxiv.org/pdf/2506.23123"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23125",
      "abstract": "Learning policies for complex humanoid tasks remains both challenging and compelling. Inspired by how infants and athletes rely on external support--such as parental walkers or coach-applied guidance--to acquire skills like walking, dancing, and performing acrobatic flips, we propose A2CF: Adaptive Assistive Curriculum Force for humanoid motion learning. A2CF trains a dual-agent system, in which a dedicated assistive force agent applies state-dependent forces to guide the robot through difficult initial motions and gradually reduces assistance as the robot's proficiency improves. Across three benchmarks--bipedal walking, choreographed dancing, and backflip--A2CF achieves convergence 30% faster than baseline methods, lowers failure rates by over 40%, and ultimately produces robust, support-free policies. Real-world experiments further demonstrate that adaptively applied assistive forces significantly accelerate the acquisition of complex skills in high-dimensional robotic control.",
      "authors": [
        "Zhanxiang Cao",
        "Yang Zhang",
        "Buqing Nie",
        "Huangxuan Lin",
        "Haoyang Li",
        "and Yue Gao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T07:20:51+00:00",
          "link": "https://arxiv.org/abs/2506.23125v1",
          "size": "7961kb",
          "version": "v1"
        }
      ],
      "title": "Learning Motion Skills with Adaptive Assistive Curriculum Force in Humanoid Robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23125",
        "HTML": "https://arxiv.org/html/2506.23125v1",
        "PDF": "https://arxiv.org/pdf/2506.23125"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23126",
      "abstract": "3D world models (i.e., learning-based 3D dynamics models) offer a promising approach to generalizable robotic manipulation by capturing the underlying physics of environment evolution conditioned on robot actions. However, existing 3D world models are primarily limited to single-material dynamics using a particle-based Graph Neural Network model, and often require time-consuming 3D scene reconstruction to obtain 3D particle tracks for training. In this work, we present ParticleFormer, a Transformer-based point cloud world model trained with a hybrid point cloud reconstruction loss, supervising both global and local dynamics features in multi-material, multi-object robot interactions. ParticleFormer captures fine-grained multi-object interactions between rigid, deformable, and flexible materials, trained directly from real-world robot perception data without an elaborate scene reconstruction. We demonstrate the model's effectiveness both in 3D scene forecasting tasks, and in downstream manipulation tasks using a Model Predictive Control (MPC) policy. In addition, we extend existing dynamics learning benchmarks to include diverse multi-material, multi-object interaction scenarios. We validate our method on six simulation and three real-world experiments, where it consistently outperforms leading baselines by achieving superior dynamics prediction accuracy and less rollout error in downstream visuomotor tasks. Experimental videos are available at https://particleformer.github.io/.",
      "authors": [
        "Suning Huang",
        "Qianzhong Chen",
        "Xiaohan Zhang",
        "Jiankai Sun",
        "Mac Schwager"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T07:23:56+00:00",
          "link": "https://arxiv.org/abs/2506.23126v1",
          "size": "2762kb",
          "version": "v1"
        }
      ],
      "title": "ParticleFormer: A 3D Point Cloud World Model for Multi-Object, Multi-Material Robotic Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23126",
        "HTML": "https://arxiv.org/html/2506.23126v1",
        "PDF": "https://arxiv.org/pdf/2506.23126"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23127",
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks, yet they face significant challenges in embodied task planning scenarios that require continuous environmental understanding and action generation. Existing approaches generate open-loop action scripts based on static knowledge, making it difficult to learn causal relationships between actions and environmental feedback, particularly in partially observable environments. We introduce Embodied Planner-R1, a novel outcome-driven reinforcement learning framework that enables LLMs to develop interactive capabilities through autonomous exploration with minimal supervision. Our framework incorporates three key innovations: (1) Without human annotations, we employ pure reinforcement learning with group rollout, incorporating in-environment interaction through parallel exploration; (2) completion-driven sparse reward; and (3) Interactive Policy Optimization (IPO) for efficient learning from grouped trajectories. Across two challenging text-based Embodied planning benchmarks, Embodied Planner-R1 achieves impressive completion rates of 97.78% on ALFWorld and 79.92% on ScienceWorld, surpassing prior methods by a large margin, and suffers only a -3.66% drop in previously unseen environments, evidencing strong generalization.",
      "authors": [
        "Zhaoye Fei",
        "Li Ji",
        "Siyin Wang",
        "Junhao Shi",
        "Jingjing Gong and Xipeng Qiu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T07:31:24+00:00",
          "link": "https://arxiv.org/abs/2506.23127v1",
          "size": "794kb",
          "version": "v1"
        }
      ],
      "title": "Unleashing Embodied Task Planning Ability in LLMs via Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23127",
        "HTML": "https://arxiv.org/html/2506.23127v1",
        "PDF": "https://arxiv.org/pdf/2506.23127"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23128",
      "abstract": "How far are Large Language Models (LLMs) in performing deep relational reasoning? In this paper, we evaluate and compare the reasoning capabilities of three cutting-edge LLMs, namely, DeepSeek-R1, DeepSeek-V3 and GPT-4o, through a suite of carefully designed benchmark tasks in family tree and general graph reasoning. Our experiments reveal that DeepSeek-R1 consistently achieves the highest F1-scores across multiple tasks and problem sizes, demonstrating strong aptitude in logical deduction and relational inference. However, all evaluated models, including DeepSeek-R1, struggle significantly as problem complexity increases, largely due to token length limitations and incomplete output structures. A detailed analysis of DeepSeek-R1's long Chain-of-Thought responses uncovers its unique planning and verification strategies, but also highlights instances of incoherent or incomplete reasoning, calling attention to the need for deeper scrutiny into LLMs' internal inference dynamics. We further discuss key directions for future work, including the role of multimodal reasoning and the systematic examination of reasoning failures. Our findings provide both empirical insights and theoretical implications for advancing LLMs' reasoning abilities, particularly in tasks that demand structured, multi-step logical inference. Our code repository will be publicly available at https://github.com/kelvinhkcs/Deep-Relational-Reasoning.",
      "authors": [
        "Chi Chiu So",
        "Yueyue Sun",
        "Jun-Min Wang",
        "Siu Pang Yung",
        "Anthony Wai Keung Loh",
        "Chun Pong Chau"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T07:37:49+00:00",
          "link": "https://arxiv.org/abs/2506.23128v1",
          "size": "115kb",
          "version": "v1"
        }
      ],
      "title": "Are Large Language Models Capable of Deep Relational Reasoning? Insights from DeepSeek-R1 and Benchmark Comparisons",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23128",
        "PDF": "https://arxiv.org/pdf/2506.23128"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23129",
      "abstract": "Collision-free optimal formation control of unmanned aerial vehicle (UAV) teams is challenging. The state-of-the-art optimal control approaches often rely on numerical methods sensitive to initial guesses. This paper presents an innovative collision-free finite-time formation control scheme for multiple UAVs leveraging the differential flatness of the UAV dynamics, eliminating the need for numerical methods. We formulate a finite-time optimal control problem to plan a formation trajectory for feasible initial states. This formation trajectory planning optimal control problem involves a collective performance index to meet the formation requirements of achieving relative positions and velocity consensus. It is solved by applying Pontryagin's principle. Subsequently, a collision-constrained regulating problem is addressed to ensure collision-free tracking of the planned formation trajectory. The tracking problem incorporates a directionally aware collision avoidance strategy that prioritizes avoiding UAVs in the forward path and relative approach. It assigns lower priority to those on the sides with an oblique relative approach and disregards UAVs behind and not in the relative approach. The simulation results for a four-UAV team (re)formation problem confirm the efficacy of the proposed control scheme.",
      "authors": [
        "Hossein B. Jond",
        "Logan Beaver",
        "Martin Jirou\\v{s}ek",
        "Naiemeh Ahmadlou",
        "Veli Bak{\\i}rc{\\i}o\\u{g}lu",
        "and Martin Saska"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T07:45:03+00:00",
          "link": "https://arxiv.org/abs/2506.23129v1",
          "size": "1075kb",
          "version": "v1"
        }
      ],
      "title": "Flatness-based Finite-Horizon Multi-UAV Formation Trajectory Planning and Directionally Aware Collision Avoidance Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23129",
        "HTML": "https://arxiv.org/html/2506.23129v1",
        "PDF": "https://arxiv.org/pdf/2506.23129"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23130",
      "abstract": "Florence B. Price was a composer in the early 20th century whose music reflects her upbringing in the American South, her African heritage, and her Western classical training. She is noted as the first African-American woman to have a symphony performed by a major orchestra. Her music has recently received renewed attention from both the public and the research community, decades after her death. In addition to other genres, Price was a prolific composer for solo voice and piano. Music historians have documented the existence of 134 art songs and piano/voice arrangements for spirituals and folk songs written by Price. We release a digital catalog of 112 of these works in MuseScore, MusicXML, MIDI, and PDF format. We also use this dataset to fine-tune a symbolic music generation model to generate accompaniments to melodies, and we conduct a blind listening experiment that shows that accompaniments generated by our model are perceived as being reflective of Florence Price's style more frequently than accompaniments generated by a baseline model. We release our model as the Florence Price Piano Accompaniment Generator alongside our dataset.",
      "authors": [
        "Tao-Tao He",
        "Martin E. Malandro",
        "Douglas Shadle"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T07:45:26+00:00",
          "link": "https://arxiv.org/abs/2506.23130v1",
          "size": "2558kb",
          "version": "v1"
        }
      ],
      "title": "The Florence Price Art Song Dataset and Piano Accompaniment Generator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23130",
        "HTML": "https://arxiv.org/html/2506.23130v1",
        "PDF": "https://arxiv.org/pdf/2506.23130"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23132",
      "abstract": "Art plagiarism detection plays a crucial role in protecting artists' copyrights and intellectual property, yet it remains a challenging problem in forensic analysis. In this paper, we address the task of recognizing plagiarized paintings and explaining the detected plagarisms by retrieving visually similar authentic artworks. To support this study, we construct a dataset by collecting painting photos and synthesizing plagiarized versions using generative AI, tailored to specific artists' styles. We first establish a baseline approach using off-the-shelf features from the visual foundation model DINOv2 to retrieve the most similar images in the database and classify plagiarism based on a similarity threshold. Surprisingly, this non-learned method achieves a high recognition accuracy of 97.2\\% but suffers from low retrieval precision 29.0\\% average precision (AP). To improve retrieval quality, we finetune DINOv2 with a metric learning loss using positive and negative sample pairs sampled in the database. The finetuned model greatly improves retrieval performance by 12\\% AP over the baseline, though it unexpectedly results in a lower recognition accuracy (92.7\\%). We conclude with insightful discussions and outline directions for future research.",
      "authors": [
        "Sophie Zhou",
        "Shu Kong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T07:58:53+00:00",
          "link": "https://arxiv.org/abs/2506.23132v1",
          "size": "630kb",
          "version": "v1"
        }
      ],
      "title": "Dare to Plagiarize? Plagiarized Painting Recognition and Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23132",
        "HTML": "https://arxiv.org/html/2506.23132v1",
        "PDF": "https://arxiv.org/pdf/2506.23132"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23133",
      "abstract": "Generating and voting multiple answers is an effective method to mitigate reasoning inconsistencies of large language models (LLMs). Prior works have shown that multiple reasoning formats outperform a single format when generating multiple answers. However, previous works using multiple formats rely on formats labeled by humans, which could be unsuitable for all tasks and have high labeling costs. To address this issue, we adapt suitable formats to the given tasks by generating and selecting formats. We first propose how to measure the reasoning error when generating multiple answers. Then, we introduce Format-Adapter, which utilizes LLMs to generate and select suitable reasoning formats by minimizing the error measurement we present. We conduct experiments on math and commonsense reasoning tasks, where Format-Adapter achieves a 4.3% performance improvement on average over previous works, demonstrating the effectiveness.",
      "authors": [
        "Dingzirui Wang",
        "Xuanliang Zhang",
        "Rongyu Cao",
        "Longxu Dou",
        "Xianzhen Luo",
        "Yingwei Ma",
        "Qingfu Zhu",
        "Wanxiang Che",
        "Binhua Li",
        "Fei Huang",
        "Yongbin Li"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T08:11:52+00:00",
          "link": "https://arxiv.org/abs/2506.23133v1",
          "size": "444kb",
          "version": "v1"
        }
      ],
      "title": "Format-Adapter: Improving Reasoning Capability of LLMs by Adapting Suitable Format",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23133",
        "HTML": "https://arxiv.org/html/2506.23133v1",
        "PDF": "https://arxiv.org/pdf/2506.23133"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23134",
      "abstract": "We construct and study the transition probability matrix of evolutionary games in which the number of players is finite (and relatively small) of such games. We use a simplified version of the population games studied by Sandholm. After laying out a general framework we concentrate on specific examples, involving the Iterated Prisoner's Dilemma, the Iterated Stag Hunt, and the Rock-Paper-Scissors game. Also we consider several revision protocols: Best Response, Pairwise Comparison, Pairwise Proportional Comparison etc. For each of these we explicitly construct the MC transition probability matrix and study its properties.",
      "authors": [
        "Athanasios Kehagias"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T08:15:39+00:00",
          "link": "https://arxiv.org/abs/2506.23134v1",
          "size": "2125kb",
          "version": "v1"
        }
      ],
      "title": "Markov Chains of Evolutionary Games with a Small Number of Players",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23134",
        "HTML": "https://arxiv.org/html/2506.23134v1",
        "PDF": "https://arxiv.org/pdf/2506.23134"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23135",
      "abstract": "World models have become indispensable tools for embodied intelligence, serving as powerful simulators capable of generating realistic robotic videos while addressing critical data scarcity challenges. However, current embodied world models exhibit limited physical awareness, particularly in modeling 3D geometry and motion dynamics, resulting in unrealistic video generation for contact-rich robotic scenarios. In this paper, we present RoboScape, a unified physics-informed world model that jointly learns RGB video generation and physics knowledge within an integrated framework. We introduce two key physics-informed joint training tasks: temporal depth prediction that enhances 3D geometric consistency in video rendering, and keypoint dynamics learning that implicitly encodes physical properties (e.g., object shape and material characteristics) while improving complex motion modeling. Extensive experiments demonstrate that RoboScape generates videos with superior visual fidelity and physical plausibility across diverse robotic scenarios. We further validate its practical utility through downstream applications including robotic policy training with generated data and policy evaluation. Our work provides new insights for building efficient physics-informed world models to advance embodied intelligence research. The code is available at: https://github.com/tsinghua-fib-lab/RoboScape.",
      "authors": [
        "Yu Shang",
        "Xin Zhang",
        "Yinzhou Tang",
        "Lei Jin",
        "Chen Gao",
        "Wei Wu",
        "Yong Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T08:19:45+00:00",
          "link": "https://arxiv.org/abs/2506.23135v1",
          "size": "5854kb",
          "version": "v1"
        }
      ],
      "title": "RoboScape: Physics-informed Embodied World Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23135",
        "HTML": "https://arxiv.org/html/2506.23135v1",
        "PDF": "https://arxiv.org/pdf/2506.23135"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23136",
      "abstract": "Large Language Models (LLMs) are capable of natural language understanding and generation. But they face challenges such as hallucination and outdated knowledge. Fine-tuning is one possible solution, but it is resource-intensive and must be repeated with every data update. Retrieval-Augmented Generation (RAG) offers an efficient solution by allowing LLMs to access external knowledge sources. However, traditional RAG pipelines struggle with retrieving information from complex technical documents with structured data such as tables and images. In this work, we propose a RAG pipeline, capable of handling tables and images in documents, for technical documents that support both scanned and searchable formats. Its retrieval process combines vector similarity search with a fine-tuned reranker based on Gemma-2-9b-it. The reranker is trained using RAFT (Retrieval-Augmented Fine-Tuning) on a custom dataset designed to improve context identification for question answering. Our evaluation demonstrates that the proposed pipeline achieves a high faithfulness score of 94% (RAGas) and 96% (DeepEval), and an answer relevancy score of 87% (RAGas) and 93% (DeepEval). Comparative analysis demonstrates that the proposed architecture is superior to general RAG pipelines in terms of table-based questions and handling questions outside context.",
      "authors": [
        "Shadman Sobhan",
        "Mohammad Ariful Haque"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T08:22:03+00:00",
          "link": "https://arxiv.org/abs/2506.23136v1",
          "size": "1364kb",
          "version": "v1"
        }
      ],
      "title": "LLM-Assisted Question-Answering on Technical Documents Using Structured Data-Aware Retrieval Augmented Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23136",
        "HTML": "https://arxiv.org/html/2506.23136v1",
        "PDF": "https://arxiv.org/pdf/2506.23136"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23137",
      "abstract": "Effective modeling of multifaceted relations is pivotal for Knowledge Graph Completion (KGC). However, a majority of existing approaches are predicated on static, embedding-based scoring, exhibiting inherent limitations in capturing contextual dependencies and relational dynamics. Addressing this gap, we propose the Flow-Modulated Scoring (FMS) framework. FMS comprises two principal components: (1) a semantic context learning module that encodes context-sensitive entity representations, and (2) a conditional flow-matching module designed to learn the dynamic transformation from a head to a tail embedding, governed by the aforementioned context. The resultant predictive vector field, representing the context-informed relational path, serves to dynamically refine the initial static score of an entity pair. Through this synergy of context-aware static representations and conditioned dynamic information, FMS facilitates a more profound modeling of relational semantics. Comprehensive evaluations on several standard benchmarks demonstrate that our proposed method surpasses prior state-of-the-art results.",
      "authors": [
        "Siyuan Li",
        "Ruitong Liu",
        "Yan Wen",
        "Te Sun"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T08:22:04+00:00",
          "link": "https://arxiv.org/abs/2506.23137v1",
          "size": "903kb",
          "version": "v1"
        }
      ],
      "title": "Flow-Modulated Scoring for Semantic-Aware Knowledge Graph Completion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23137",
        "HTML": "https://arxiv.org/html/2506.23137v1",
        "PDF": "https://arxiv.org/pdf/2506.23137"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23138",
      "abstract": "Since there exists a notable gap between user-provided and model-preferred prompts, generating high-quality and satisfactory images using diffusion models often requires prompt engineering to optimize user inputs. Current studies on text-to-image prompt engineering can effectively enhance the style and aesthetics of generated images. However, they often neglect the semantic alignment between generated images and user descriptions, resulting in visually appealing but content-wise unsatisfying outputs. In this work, we propose VisualPrompter, a novel training-free prompt engineering framework that refines user inputs to model-preferred sentences. In particular, VisualPrompter utilizes an automatic self-reflection module to identify the missing concepts in generated images and a target-specific prompt optimization mechanism to revise the prompts in a fine-grained manner. Extensive experiments demonstrate the effectiveness of our VisualPrompter, which achieves new state-of-the-art performance on multiple benchmarks for text-image alignment evaluation. Additionally, our framework features a plug-and-play design, making it highly adaptable to various generative models.",
      "authors": [
        "Shiyu Wu",
        "Mingzhen Sun",
        "Weining Wang",
        "Yequan Wang",
        "Jing Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T08:24:39+00:00",
          "link": "https://arxiv.org/abs/2506.23138v1",
          "size": "14731kb",
          "version": "v1"
        }
      ],
      "title": "VisualPrompter: Prompt Optimization with Visual Feedback for Text-to-Image Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23138",
        "HTML": "https://arxiv.org/html/2506.23138v1",
        "PDF": "https://arxiv.org/pdf/2506.23138"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23139",
      "abstract": "We present a new benchmark for evaluating Deep Search--a realistic and complex form of retrieval-augmented generation (RAG) that requires source-aware, multi-hop reasoning over diverse, sparsed, but related sources. These include documents, meeting transcripts, Slack messages, GitHub, and URLs, which vary in structure and often contain human-to-human interactions. We build it using a synthetic data pipeline that simulates business workflows across product planning, development, and support stages, generating interconnected content with realistic noise and multi-hop questions with guaranteed ground-truth answers. We release our benchmark with both answerable and unanswerable queries, and retrieval pool of 39,190 enterprise artifacts, enabling fine-grained evaluation of long-context LLM and RAG systems. Our experiments reveal that even the best-performing agentic RAG methods achieve an average performance score of 32.96 on our benchmark. With further analysis, we highlight retrieval as the main bottleneck: existing methods struggle to conduct deep searches and retrieve all necessary evidence. Consequently, they often reason over partial context, leading to significant performance degradation.",
      "authors": [
        "Prafulla Kumar Choubey",
        "Xiangyu Peng",
        "Shilpa Bhagavath",
        "Kung-Hsiang Huang",
        "Caiming Xiong",
        "Chien-Sheng Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T08:34:59+00:00",
          "link": "https://arxiv.org/abs/2506.23139v1",
          "size": "2163kb",
          "version": "v1"
        }
      ],
      "title": "Benchmarking Deep Search over Heterogeneous Enterprise Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23139",
        "HTML": "https://arxiv.org/html/2506.23139v1",
        "PDF": "https://arxiv.org/pdf/2506.23139"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23141",
      "abstract": "Semantic context surrounding a triplet $(h, r, t)$ is crucial for Knowledge Graph Completion (KGC), providing vital cues for prediction. However, traditional node-based message passing mechanisms, when applied to knowledge graphs, often introduce noise and suffer from information dilution or over-smoothing by indiscriminately aggregating information from all neighboring edges. To address this challenge, we propose a semantic-aware relational message passing. A core innovation of this framework is the introduction of a \\textbf{semantic-aware Top-K neighbor selection strategy}. Specifically, this strategy first evaluates the semantic relevance between a central node and its incident edges within a shared latent space, selecting only the Top-K most pertinent ones. Subsequently, information from these selected edges is effectively fused with the central node's own representation using a \\textbf{multi-head attention aggregator} to generate a semantically focused node message. In this manner, our model not only leverages the structure and features of edges within the knowledge graph but also more accurately captures and propagates the contextual information most relevant to the specific link prediction task, thereby effectively mitigating interference from irrelevant information. Extensive experiments demonstrate that our method achieves superior performance compared to existing approaches on several established benchmarks.",
      "authors": [
        "Siyuan Li",
        "Ruitong Liu",
        "Yan Wen",
        "Te Sun"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T08:37:48+00:00",
          "link": "https://arxiv.org/abs/2506.23141v1",
          "size": "382kb",
          "version": "v1"
        }
      ],
      "title": "Context-Driven Knowledge Graph Completion with Semantic-Aware Relational Message Passing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23141",
        "HTML": "https://arxiv.org/html/2506.23141v1",
        "PDF": "https://arxiv.org/pdf/2506.23141"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23145",
      "abstract": "Privacy preservation in AI is crucial, especially in healthcare, where models rely on sensitive patient data. In the emerging field of machine unlearning, existing methodologies struggle to remove patient data from trained multimodal architectures, which are widely used in healthcare. We propose Forget-MI, a novel machine unlearning method for multimodal medical data, by establishing loss functions and perturbation techniques. Our approach unlearns unimodal and joint representations of the data requested to be forgotten while preserving knowledge from the remaining data and maintaining comparable performance to the original model. We evaluate our results using performance on the forget dataset, performance on the test dataset, and Membership Inference Attack (MIA), which measures the attacker's ability to distinguish the forget dataset from the training dataset. Our model outperforms the existing approaches that aim to reduce MIA and the performance on the forget dataset while keeping an equivalent performance on the test set. Specifically, our approach reduces MIA by 0.202 and decreases AUC and F1 scores on the forget set by 0.221 and 0.305, respectively. Additionally, our performance on the test set matches that of the retrained model, while allowing forgetting. Code is available at https://github.com/BioMedIA-MBZUAI/Forget-MI.git",
      "authors": [
        "Shahad Hardan",
        "Darya Taratynova",
        "Abdelmajid Essofi",
        "Karthik Nandakumar",
        "Mohammad Yaqub"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T08:53:23+00:00",
          "link": "https://arxiv.org/abs/2506.23145v1",
          "size": "901kb",
          "version": "v1"
        }
      ],
      "title": "Forget-MI: Machine Unlearning for Forgetting Multimodal Information in Healthcare Settings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23145",
        "HTML": "https://arxiv.org/html/2506.23145v1",
        "PDF": "https://arxiv.org/pdf/2506.23145"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23146",
      "abstract": "In-context learning (ICL) has emerged as an effective approach to enhance the performance of large language models (LLMs). However, its effectiveness varies significantly across models and tasks, posing challenges for practitioners to determine when ICL reliably improves performance. Current evaluation approaches, reliant on performance change after applying ICL, suffer from low reliability, poor attribution, and impracticality in data-insufficient scenarios. We propose the Learning-to-Context Slope (LCS), a novel metric that quantifies ICL effectiveness by modeling the slope between learning gain (loss decrease from demonstrations) and contextual relevance (demonstration-input relevance). LCS addresses key limitations of performance-based metrics: (1) it captures continuous loss changes even when outputs are incorrect, improving reliability; (2) its formulation attributes ICL failures to weak contextual alignment (inability to adapt inputs to demonstrations) or strong output calibration (self-verification of correctness); and (3) it minimizes reliance on labeled data via synthetic evaluation. Extensive experiments demonstrate that LCS strongly correlates with performance improvements in labeled settings and reliably reflects true effectiveness in biased or data-scarce scenarios. Further analysis reveals actionable thresholds for LCS and identifies model capabilities critical to ICL success.",
      "authors": [
        "Dingzriui Wang",
        "Xuanliang Zhang",
        "Keyan Xu",
        "Qingfu Zhu",
        "Wanxiang Che",
        "Yang Deng"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T08:55:37+00:00",
          "link": "https://arxiv.org/abs/2506.23146v1",
          "size": "4679kb",
          "version": "v1"
        }
      ],
      "title": "Learning-to-Context Slope: Evaluating In-Context Learning Effectiveness Beyond Performance Illusions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23146",
        "PDF": "https://arxiv.org/pdf/2506.23146"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23147",
      "abstract": "In the domain of vehicle telematics the automated recognition of driving maneuvers is used to classify and evaluate driving behaviour. This not only serves as a component to enhance the personalization of insurance policies, but also to increase road safety, reduce accidents and the associated costs as well as to reduce fuel consumption and support environmentally friendly driving. In this context maneuver recognition technically requires a continuous application of time series classification which poses special challenges to the transfer, preprocessing and storage of telematic sensor data, the training of predictive models, and the prediction itself. Although much research has been done in the field of gathering relevant data or regarding the methods to build predictive models for the task of maneuver recognition, there is a practical need for python packages and functions that allow to quickly transform data into the required structure as well as to build and evaluate such models. The maneuverRecognition package was therefore developed to provide the necessary functions for preprocessing, modelling and evaluation and also includes a ready to use LSTM based network structure that can be modified. The implementation of the package is demonstrated using real driving data of three different persons recorded via smartphone sensors.",
      "authors": [
        "Jonathan Schuster and Fabian Transchel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T08:56:19+00:00",
          "link": "https://arxiv.org/abs/2506.23147v1",
          "size": "1392kb",
          "version": "v1"
        }
      ],
      "title": "maneuverRecognition -- A Python package for Timeseries Classification in the domain of Vehicle Telematics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23147",
        "HTML": "https://arxiv.org/html/2506.23147v1",
        "PDF": "https://arxiv.org/pdf/2506.23147"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23149",
      "abstract": "High labeling cost for in-context learning (ICL) demonstrations motivates using large language models (LLMs) for synthesis to reduce overhead. However, existing synthesis methods are mainly task-specific or rely on pre-existing demonstrations. So this paper focuses on synthesizing demonstrations from scratch for arbitrary tasks. A major challenge in synthesizing from scratch is ensuring consistency with the target task, as the lack of labeling guidance could lead to synthesis bias. We first propose a consistency metric called V-Score, which has higher performance and lower computation cost compared with the metrics based on grams or embedding vectors. Furthermore, we introduce V-Synthesis, which leverages V-Score for proportional sampling to ensure both high consistency and diversity of synthesized demonstrations. Experimental results demonstrate that V-Synthesis yields an average performance improvement of 2.0% compared to existing synthesis methods confirming the effectiveness of V-Synthesis.",
      "authors": [
        "Dingzirui Wang",
        "Xuanliang Zhang",
        "Keyan Xu",
        "Qingfu Zhu",
        "Wanxiang Che",
        "Yang Deng"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T08:57:09+00:00",
          "link": "https://arxiv.org/abs/2506.23149v1",
          "size": "295kb",
          "version": "v1"
        }
      ],
      "title": "V-SYNTHESIS: Task-Agnostic Synthesis of Consistent and Diverse In-Context Demonstrations from Scratch via V-Entropy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23149",
        "HTML": "https://arxiv.org/html/2506.23149v1",
        "PDF": "https://arxiv.org/pdf/2506.23149"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23150",
      "abstract": "Single-image-to-3D models typically follow a sequential generation and reconstruction workflow. However, intermediate multi-view images synthesized by pre-trained generation models often lack cross-view consistency (CVC), significantly degrading 3D reconstruction performance. While recent methods attempt to refine CVC by feeding reconstruction results back into the multi-view generator, these approaches struggle with noisy and unstable reconstruction outputs that limit effective CVC improvement. We introduce AlignCVC, a novel framework that fundamentally re-frames single-image-to-3D generation through distribution alignment rather than relying on strict regression losses. Our key insight is to align both generated and reconstructed multi-view distributions toward the ground-truth multi-view distribution, establishing a principled foundation for improved CVC. Observing that generated images exhibit weak CVC while reconstructed images display strong CVC due to explicit rendering, we propose a soft-hard alignment strategy with distinct objectives for generation and reconstruction models. This approach not only enhances generation quality but also dramatically accelerates inference to as few as 4 steps. As a plug-and-play paradigm, our method, namely AlignCVC, seamlessly integrates various multi-view generation models with 3D reconstruction models. Extensive experiments demonstrate the effectiveness and efficiency of AlignCVC for single-image-to-3D generation.",
      "authors": [
        "Xinyue Liang",
        "Zhiyuan Ma",
        "Lingchen Sun",
        "Yanjun Guo",
        "Lei Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T09:01:28+00:00",
          "link": "https://arxiv.org/abs/2506.23150v1",
          "size": "3367kb",
          "version": "v1"
        }
      ],
      "title": "AlignCVC: Aligning Cross-View Consistency for Single-Image-to-3D Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23150",
        "PDF": "https://arxiv.org/pdf/2506.23150"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23151",
      "abstract": "Recent advances in optical flow estimation have prioritized accuracy at the cost of growing GPU memory consumption, particularly for high-resolution (FullHD) inputs. We introduce MEMFOF, a memory-efficient multi-frame optical flow method that identifies a favorable trade-off between multi-frame estimation and GPU memory usage. Notably, MEMFOF requires only 2.09 GB of GPU memory at runtime for 1080p inputs, and 28.5 GB during training, which uniquely positions our method to be trained at native 1080p without the need for cropping or downsampling. We systematically revisit design choices from RAFT-like architectures, integrating reduced correlation volumes and high-resolution training protocols alongside multi-frame estimation, to achieve state-of-the-art performance across multiple benchmarks while substantially reducing memory overhead. Our method outperforms more resource-intensive alternatives in both accuracy and runtime efficiency, validating its robustness for flow estimation at high resolutions. At the time of submission, our method ranks first on the Spring benchmark with a 1-pixel (1px) outlier rate of 3.289, leads Sintel (clean) with an endpoint error (EPE) of 0.963, and achieves the best Fl-all error on KITTI-2015 at 2.94%. The code is available at https://github.com/msu-video-group/memfof.",
      "authors": [
        "Vladislav Bargatin",
        "Egor Chistov",
        "Alexander Yakovenko",
        "Dmitriy Vatolin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T09:01:42+00:00",
          "link": "https://arxiv.org/abs/2506.23151v1",
          "size": "19935kb",
          "version": "v1"
        }
      ],
      "title": "MEMFOF: High-Resolution Training for Memory-Efficient Multi-Frame Optical Flow Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23151",
        "HTML": "https://arxiv.org/html/2506.23151v1",
        "PDF": "https://arxiv.org/pdf/2506.23151"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23152",
      "abstract": "Handover between a human and a dexterous robotic hand is a fundamental yet challenging task in human-robot collaboration. It requires handling dynamic environments and a wide variety of objects and demands robust and adaptive grasping strategies. However, progress in developing effective dynamic dexterous grasping methods is limited by the absence of high-quality, real-world human-to-robot handover datasets. Existing datasets primarily focus on grasping static objects or rely on synthesized handover motions, which differ significantly from real-world robot motion patterns, creating a substantial gap in applicability. In this paper, we introduce DexH2R, a comprehensive real-world dataset for human-to-robot handovers, built on a dexterous robotic hand. Our dataset captures a diverse range of interactive objects, dynamic motion patterns, rich visual sensor data, and detailed annotations. Additionally, to ensure natural and human-like dexterous motions, we utilize teleoperation for data collection, enabling the robot's movements to align with human behaviors and habits, which is a crucial characteristic for intelligent humanoid robots. Furthermore, we propose an effective solution, DynamicGrasp, for human-to-robot handover and evaluate various state-of-the-art approaches, including auto-regressive models and diffusion policy methods, providing a thorough comparison and analysis. We believe our benchmark will drive advancements in human-to-robot handover research by offering a high-quality dataset, effective solutions, and comprehensive evaluation metrics.",
      "authors": [
        "Youzhuo Wang and Jiayi Ye and Chuyang Xiao and Yiming Zhong and Heng Tao and Hang Yu and Yumeng Liu and Jingyi Yu and Yuexin Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T09:04:55+00:00",
          "link": "https://arxiv.org/abs/2506.23152v1",
          "size": "15492kb",
          "version": "v1"
        }
      ],
      "title": "DexH2R: A Benchmark for Dynamic Dexterous Grasping in Human-to-Robot Handover",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23152",
        "HTML": "https://arxiv.org/html/2506.23152v1",
        "PDF": "https://arxiv.org/pdf/2506.23152"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23153",
      "abstract": "Novel view synthesis for dynamic $3$D scenes poses a significant challenge. Many notable efforts use NeRF-based approaches to address this task and yield impressive results. However, these methods rely heavily on sufficient motion parallax in the input images or videos. When the camera motion range becomes limited or even stationary (i.e., small camera motion), existing methods encounter two primary challenges: incorrect representation of scene geometry and inaccurate estimation of camera parameters. These challenges make prior methods struggle to produce satisfactory results or even become invalid. To address the first challenge, we propose a novel Distribution-based Depth Regularization (DDR) that ensures the rendering weight distribution to align with the true distribution. Specifically, unlike previous methods that use depth loss to calculate the error of the expectation, we calculate the expectation of the error by using Gumbel-softmax to differentiably sample points from discrete rendering weight distribution. Additionally, we introduce constraints that enforce the volume density of spatial points before the object boundary along the ray to be near zero, ensuring that our model learns the correct geometry of the scene. To demystify the DDR, we further propose a visualization tool that enables observing the scene geometry representation at the rendering weight level. For the second challenge, we incorporate camera parameter learning during training to enhance the robustness of our model to camera parameters. We conduct extensive experiments to demonstrate the effectiveness of our approach in representing scenes with small camera motion input, and our results compare favorably to state-of-the-art methods.",
      "authors": [
        "Huiqiang Sun",
        "Xingyi Li",
        "Juewen Peng",
        "Liao Shen",
        "Zhiguo Cao",
        "Ke Xian",
        "Guosheng Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T09:17:55+00:00",
          "link": "https://arxiv.org/abs/2506.23153v1",
          "size": "6175kb",
          "version": "v1"
        }
      ],
      "title": "Dynamic View Synthesis from Small Camera Motion Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23153",
        "HTML": "https://arxiv.org/html/2506.23153v1",
        "PDF": "https://arxiv.org/pdf/2506.23153"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23156",
      "abstract": "Self-supervised learning (SSL) has demonstrated its effectiveness in learning representations through comparison methods that align with human intuition. However, mainstream SSL methods heavily rely on high body datasets with single label, such as ImageNet, resulting in intolerable pre-training overhead. Besides, more general multi-label images are frequently overlooked in SSL, despite their potential for richer semantic information and broader applicability in downstream scenarios. Therefore, we tailor the mainstream SSL approach to guarantee excellent representation learning capabilities using fewer multi-label images. Firstly, we propose a block-wise augmentation module aimed at extracting additional potential positive view pairs from multi-label images. Subsequently, an image-aware contrastive loss is devised to establish connections between these views, thereby facilitating the extraction of semantically consistent representations. Comprehensive linear fine-tuning and transfer learning validate the competitiveness of our approach despite challenging sample quality and quantity.",
      "authors": [
        "Jiale Chen"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T09:29:37+00:00",
          "link": "https://arxiv.org/abs/2506.23156v1",
          "size": "3148kb",
          "version": "v1"
        }
      ],
      "title": "Self-Supervised Contrastive Learning for Multi-Label Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23156",
        "HTML": "https://arxiv.org/html/2506.23156v1",
        "PDF": "https://arxiv.org/pdf/2506.23156"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23157",
      "abstract": "High-dynamic scene reconstruction aims to represent static background with rigid spatial features and dynamic objects with deformed continuous spatiotemporal features. Typically, existing methods adopt unified representation model (e.g., Gaussian) to directly match the spatiotemporal features of dynamic scene from frame camera. However, this unified paradigm fails in the potential discontinuous temporal features of objects due to frame imaging and the heterogeneous spatial features between background and objects. To address this issue, we disentangle the spatiotemporal features into various latent representations to alleviate the spatiotemporal mismatching between background and objects. In this work, we introduce event camera to compensate for frame camera, and propose a spatiotemporal-disentangled Gaussian splatting framework for high-dynamic scene reconstruction. As for dynamic scene, we figure out that background and objects have appearance discrepancy in frame-based spatial features and motion discrepancy in event-based temporal features, which motivates us to distinguish the spatiotemporal features between background and objects via clustering. As for dynamic object, we discover that Gaussian representations and event data share the consistent spatiotemporal characteristic, which could serve as a prior to guide the spatiotemporal disentanglement of object Gaussians. Within Gaussian splatting framework, the cumulative scene-object disentanglement can improve the spatiotemporal discrimination between background and objects to render the time-continuous dynamic scene. Extensive experiments have been performed to verify the superiority of the proposed method.",
      "authors": [
        "Hanyu Zhou",
        "Haonan Wang",
        "Haoyue Liu",
        "Yuxing Duan",
        "Luxin Yan",
        "Gim Hee Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T09:32:06+00:00",
          "link": "https://arxiv.org/abs/2506.23157v1",
          "size": "9213kb",
          "version": "v1"
        }
      ],
      "title": "STD-GS: Exploring Frame-Event Interaction for SpatioTemporal-Disentangled Gaussian Splatting to Reconstruct High-Dynamic Scene",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23157",
        "HTML": "https://arxiv.org/html/2506.23157v1",
        "PDF": "https://arxiv.org/pdf/2506.23157"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23164",
      "abstract": "Autonomous Vehicle decisions rely on multimodal prediction models that account for multiple route options and the inherent uncertainty in human behavior. However, models can suffer from mode collapse, where only the most likely mode is predicted, posing significant safety risks. While existing methods employ various strategies to generate diverse predictions, they often overlook the diversity in interaction modes among agents. Additionally, traditional metrics for evaluating prediction models are dataset-dependent and do not evaluate inter-agent interactions quantitatively. To our knowledge, none of the existing metrics explicitly evaluates mode collapse. In this paper, we propose a novel evaluation framework that assesses mode collapse in joint trajectory predictions, focusing on safety-critical interactions. We introduce metrics for mode collapse, mode correctness, and coverage, emphasizing the sequential dimension of predictions. By testing four multi-agent trajectory prediction models, we demonstrate that mode collapse indeed happens. When looking at the sequential dimension, although prediction accuracy improves closer to interaction events, there are still cases where the models are unable to predict the correct interaction mode, even just before the interaction mode becomes inevitable. We hope that our framework can help researchers gain new insights and advance the development of more consistent and accurate prediction models, thus enhancing the safety of autonomous driving systems.",
      "authors": [
        "Maarten Hugenholtz",
        "Anna Meszaros",
        "Jens Kober",
        "Zlatan Ajanovic"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T09:53:12+00:00",
          "link": "https://arxiv.org/abs/2506.23164v1",
          "size": "3501kb",
          "version": "v1"
        }
      ],
      "title": "Mode Collapse Happens: Evaluating Critical Interactions in Joint Trajectory Prediction Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23164",
        "HTML": "https://arxiv.org/html/2506.23164v1",
        "PDF": "https://arxiv.org/pdf/2506.23164"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23165",
      "abstract": "Safety is an essential requirement for reinforcement learning systems. The newly emerging framework of robust constrained Markov decision processes allows learning policies that satisfy long-term constraints while providing guarantees under epistemic uncertainty. This paper presents mirror descent policy optimisation for robust constrained Markov decision processes (RCMDPs), making use of policy gradient techniques to optimise both the policy (as a maximiser) and the transition kernel (as an adversarial minimiser) on the Lagrangian representing a constrained MDP. In the oracle-based RCMDP setting, we obtain an $\\mathcal{O}\\left(\\frac{1}{T}\\right)$ convergence rate for the squared distance as a Bregman divergence, and an $\\mathcal{O}\\left(e^{-T}\\right)$ convergence rate for entropy-regularised objectives. In the sample-based RCMDP setting, we obtain an $\\tilde{\\mathcal{O}}\\left(\\frac{1}{T^{1/3}}\\right)$ convergence rate. Experiments confirm the benefits of mirror descent policy optimisation in constrained and unconstrained optimisation, and significant improvements are observed in robustness tests when compared to baseline policy optimisation algorithms.",
      "authors": [
        "David Bossens and Atsushi Nitanda"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T09:55:52+00:00",
          "link": "https://arxiv.org/abs/2506.23165v1",
          "size": "1174kb",
          "version": "v1"
        }
      ],
      "title": "Mirror Descent Policy Optimisation for Robust Constrained Markov Decision Processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23165",
        "HTML": "https://arxiv.org/html/2506.23165v1",
        "PDF": "https://arxiv.org/pdf/2506.23165"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23168",
      "abstract": "Distributivity is a well-established and extensively studied notion in lattice theory. In the context of data analysis, particularly within Formal Concept Analysis (FCA), lattices are often observed to exhibit a high degree of distributivity. However, no standardized measure exists to quantify this property. In this paper, we introduce the notion of rises in (concept) lattices as a means to assess distributivity. Rises capture how the number of attributes or objects in covering concepts change within the concept lattice. We show that a lattice is distributive if and only if no non-unit rises occur. Furthermore, we relate rises to the classical notion of meet- and join distributivity. We observe that concept lattices from real-world data are to a high degree join-distributive, but much less meet-distributive. We additionally study how join-distributivity manifests on the level of ordered sets.",
      "authors": [
        "Mohammad Abdulla",
        "Tobias Hille",
        "Dominik D\\\"urrschnabel",
        "Gerd Stumme"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)",
        "Rings and Algebras (math.RA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T10:03:51+00:00",
          "link": "https://arxiv.org/abs/2506.23168v1",
          "size": "181kb",
          "version": "v1"
        }
      ],
      "title": "Rises for Measuring Local Distributivity in Lattices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23168",
        "HTML": "https://arxiv.org/html/2506.23168v1",
        "PDF": "https://arxiv.org/pdf/2506.23168"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23169",
      "abstract": "Power systems with high renewable energy penetration are highly influenced by weather conditions, often facing significant challenges such as persistent power shortages and severe power fluctuations over long time scales. This paper addresses the critical need for effective characterization of extreme scenarios under these situations. First, novel risk indices are proposed to quantify the severity of continuous power shortages and substantial power fluctuations over long-term operations. These indices are independent of specific scheduling strategies and incorporate the system's resource regulation capabilities. By employing a filtering-based approach, the proposed indices focus on retaining key characteristics of continuous power shortages and fluctuation events, enabling the identification of extreme scenarios on long time scales. Secondly, an extreme scenario generation method is developed using Gaussian mixture models and sequential Monte Carlo simulation. Especially, this method periodically evaluates the severity of generated scenarios based on the defined risk indices, retaining extreme scenarios while discarding less critical ones. Finally, case studies based on real-world data demonstrate the efficacy of the proposed method. The results confirm that integrating the identified extreme scenarios significantly enhances the system's ability to ensure long-term security and reliability under high renewable energy penetration.",
      "authors": [
        "Kai Kang",
        "Feng Liu",
        "Yifan Su",
        "Zhaojian Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T10:04:05+00:00",
          "link": "https://arxiv.org/abs/2506.23169v1",
          "size": "288kb",
          "version": "v1"
        }
      ],
      "title": "Extreme Scenario Characterization for High Renewable Energy Penetrated Power Systems over Long Time Scales",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23169",
        "HTML": "https://arxiv.org/html/2506.23169v1",
        "PDF": "https://arxiv.org/pdf/2506.23169"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23170",
      "abstract": "In the online digital realm, recommendation systems are ubiquitous and play a crucial role in enhancing user experience. These systems leverage user preferences to provide personalized recommendations, thereby helping users navigate through the paradox of choice. This work focuses on personalized sequential recommendation, where the system considers not only a user's immediate, evolving session context, but also their cumulative historical behavior to provide highly relevant and timely recommendations. Through an empirical study conducted on diverse real-world datasets, we have observed and quantified the existence and impact of both short-term (immediate and transient) and long-term (enduring and stable) preferences on users' historical interactions. Building on these insights, we propose a framework that combines short- and long-term preferences to enhance recommendation performance, namely Compositions of Variant Experts (CoVE). This novel framework dynamically integrates short- and long-term preferences through the use of different specialized recommendation models (i.e., experts). Extensive experiments showcase the effectiveness of the proposed methods and ablation studies further investigate the impact of variant expert types.",
      "authors": [
        "Jaime Hieu Do",
        "Trung-Hoang Le",
        "Hady W. Lauw"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T10:09:33+00:00",
          "link": "https://arxiv.org/abs/2506.23170v1",
          "size": "654kb",
          "version": "v1"
        }
      ],
      "title": "Compositions of Variant Experts for Integrating Short-Term and Long-Term Preferences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23170",
        "HTML": "https://arxiv.org/html/2506.23170v1",
        "PDF": "https://arxiv.org/pdf/2506.23170"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23174",
      "abstract": "Generative models have gained significant attention for their ability to produce realistic synthetic data that supplements the quantity of real-world datasets. While recent studies show performance improvements in wireless sensing tasks by incorporating all synthetic data into training sets, the quality of synthetic data remains unpredictable and the resulting performance gains are not guaranteed. To address this gap, we propose tractable and generalizable metrics to quantify quality attributes of synthetic data - affinity and diversity. Our assessment reveals prevalent affinity limitation in current wireless synthetic data, leading to mislabeled data and degraded task performance. We attribute the quality limitation to generative models' lack of awareness of untrained conditions and domain-specific processing. To mitigate these issues, we introduce SynCheck, a quality-guided synthetic data utilization scheme that refines synthetic data quality during task model training. Our evaluation demonstrates that SynCheck consistently outperforms quality-oblivious utilization of synthetic data, and achieves 4.3% performance improvement even when the previous utilization degrades performance by 13.4%.",
      "authors": [
        "Chen Gong",
        "Bo Liang",
        "Wei Gao",
        "Chenren Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T10:17:39+00:00",
          "link": "https://arxiv.org/abs/2506.23174v1",
          "size": "3733kb",
          "version": "v1"
        }
      ],
      "title": "Data Can Speak for Itself: Quality-guided Utilization of Wireless Synthetic Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23174",
        "HTML": "https://arxiv.org/html/2506.23174v1",
        "PDF": "https://arxiv.org/pdf/2506.23174"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23179",
      "abstract": "Nowadays, people in the modern world communicate with their friends, relatives, and colleagues through the internet. Persons/nodes and communication/edges among them form a network. Social media networks are a type of network where people share their views with the community. There are several models that capture human behavior, such as a reaction to the information received from friends or relatives. The two fundamental models of information diffusion widely discussed in the social networks are the Independent Cascade Model and the Linear Threshold Model. Liu et al. [1] propose a variant of the linear threshold model in their paper title User-driven competitive influence Maximization(UDCIM) in social networks. Authors try to simulate human behavior where they do not make a decision immediately after being influenced, but take a pause for a while, and then they make a final decision. They propose the heuristic algorithms and prove the approximation factor under community constraints( The seed vertices belong to an identical community). Even finding the community is itself an NP-hard problem. In this article, we extend the existing work with algorithms and LP-formation of the problem. We also implement and test the LP-formulated equations on small datasets by using the Gurobi Solver [2]. We furthermore propose one heuristic and one genetic algorithm. The extensive experimentation is carried out on medium to large datasets, and the outcomes of both algorithms are plotted in the results and discussion section.",
      "authors": [
        "Rahul Kumar Gautam"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T10:27:51+00:00",
          "link": "https://arxiv.org/abs/2506.23179v1",
          "size": "56kb",
          "version": "v1"
        }
      ],
      "title": "Community-Based Efficient Algorithms for User-Driven Competitive Influence Maximization in Social Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23179",
        "PDF": "https://arxiv.org/pdf/2506.23179"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23180",
      "abstract": "Improvisation training for actors presents unique challenges, particularly in maintaining narrative coherence and managing cognitive load during performances. Previous research on AI in improvisation performance often predates advances in large language models (LLMs) and relies on human intervention. We introduce ImprovMate, which leverages LLMs as GPTs to automate the generation of narrative stimuli and cues, allowing actors to focus on creativity without keeping track of plot or character continuity. Based on insights from professional improvisers, ImprovMate incorporates exercises that mimic live training, such as abrupt story resolution and reactive thinking exercises, while maintaining coherence via reference tables. By balancing randomness and structured guidance, ImprovMate provides a groundbreaking tool for improv training. Our pilot study revealed that actors might embrace AI techniques if the latter mirrors traditional practices, and appreciate the fresh twist introduced by our approach with the AI-generated cues.",
      "authors": [
        "Riccardo Drago",
        "Yotam Sechayk",
        "Mustafa Doga Dogan",
        "Andrea Sanna",
        "Takeo Igarashi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T10:28:13+00:00",
          "link": "https://arxiv.org/abs/2506.23180v1",
          "size": "1771kb",
          "version": "v1"
        }
      ],
      "title": "ImprovMate: Multimodal AI Assistant for Improv Actor Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23180",
        "HTML": "https://arxiv.org/html/2506.23180v1",
        "PDF": "https://arxiv.org/pdf/2506.23180"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23182",
      "abstract": "Generative machine learning models offer a powerful framework for therapeutic design by efficiently exploring large spaces of biological sequences enriched for desirable properties. Unlike supervised learning methods, which require both positive and negative labeled data, generative models such as LSTMs can be trained solely on positively labeled sequences, for example, high-affinity antibodies. This is particularly advantageous in biological settings where negative data are scarce, unreliable, or biologically ill-defined. However, the lack of attribution methods for generative models has hindered the ability to extract interpretable biological insights from such models. To address this gap, we developed Generative Attribution Metric Analysis (GAMA), an attribution method for autoregressive generative models based on Integrated Gradients. We assessed GAMA using synthetic datasets with known ground truths to characterize its statistical behavior and validate its ability to recover biologically relevant features. We further demonstrated the utility of GAMA by applying it to experimental antibody-antigen binding data. GAMA enables model interpretability and the validation of generative sequence design strategies without the need for negative training data.",
      "authors": [
        "Robert Frank",
        "Michael Widrich",
        "Rahmad Akbar",
        "G\\\"unter Klambauer",
        "Geir Kjetil Sandve",
        "Philippe A. Robert",
        "Victor Greiff"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T10:50:46+00:00",
          "link": "https://arxiv.org/abs/2506.23182v1",
          "size": "5863kb",
          "version": "v1"
        }
      ],
      "title": "Attribution assignment for deep-generative sequence models enables interpretability analysis using positive-only data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23182",
        "PDF": "https://arxiv.org/pdf/2506.23182"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23183",
      "abstract": "In machine learning security, one is often faced with the problem of removing outliers from a given set of high-dimensional vectors when computing their average. For example, many variants of data poisoning attacks produce gradient vectors during training that are outliers in the distribution of clean gradients, which bias the computed average used to derive the ML model. Filtering them out before averaging serves as a generic defense strategy. Byzantine robust aggregation is an algorithmic primitive which computes a robust average of vectors, in the presence of an $\\epsilon$ fraction of vectors which may have been arbitrarily and adaptively corrupted, such that the resulting bias in the final average is provably bounded.\n  In this paper, we give the first robust aggregator that runs in quasi-linear time in the size of input vectors and provably has near-optimal bias bounds. Our algorithm also does not assume any knowledge of the distribution of clean vectors, nor does it require pre-computing any filtering thresholds from it. This makes it practical to use directly in standard neural network training procedures. We empirically confirm its expected runtime efficiency and its effectiveness in nullifying 10 different ML poisoning attacks.",
      "authors": [
        "De Zhang Lee",
        "Aashish Kolluri",
        "Prateek Saxena",
        "Ee-Chien Chang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T10:53:54+00:00",
          "link": "https://arxiv.org/abs/2506.23183v1",
          "size": "1678kb",
          "version": "v1"
        }
      ],
      "title": "A Practical and Secure Byzantine Robust Aggregator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23183",
        "HTML": "https://arxiv.org/html/2506.23183v1",
        "PDF": "https://arxiv.org/pdf/2506.23183"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23185",
      "abstract": "Modern data-intensive applications demand memory solutions that deliver high-density, low-power, and integrated computational capabilities to reduce data movement overhead. This paper presents the use of Gain-Cell embedded DRAM (GC-eDRAM) - a compelling alternative to traditional SRAM and eDRAM - for stateful, in-memory logic. We propose a circuit design that exploits GC-eDRAM's dual-port architecture and nondestructive read operation to perform logic functions directly within the GC-eDRAM memory array. Our simulation results demonstrate a 5us retention time coupled with a 99.5% success rate for computing the logic gates. By incorporating processing-in-memory (PIM) functionality into GC-eDRAM, our approach enhances memory and compute densities, lowers power consumption, and improves overall performance for data-intensive applications.",
      "authors": [
        "Barak Hoffer and Shahar Kvatinsky"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T11:12:34+00:00",
          "link": "https://arxiv.org/abs/2506.23185v1",
          "size": "263kb",
          "version": "v1"
        }
      ],
      "title": "Stateful Logic In-Memory Using Gain-Cell eDRAM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23185",
        "HTML": "https://arxiv.org/html/2506.23185v1",
        "PDF": "https://arxiv.org/pdf/2506.23185"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23186",
      "abstract": "Abstract notions of convexity over the vertices of a graph, and corresponding notions of halfspaces, have recently gained attention from the machine learning community. In this work we study monophonic halfspaces, a notion of graph halfspaces defined through closure under induced paths. Our main result is a $2$-satisfiability based decomposition theorem, which allows one to represent monophonic halfspaces as a disjoint union of certain vertex subsets. Using this decomposition, we achieve efficient and (nearly) optimal algorithms for various learning problems, such as teaching, active, and online learning. Most notably, we obtain a polynomial-time algorithm for empirical risk minimization. Independently of the decomposition theorem, we obtain an efficient, stable, and proper sample compression scheme. This makes monophonic halfspaces efficiently learnable with proper learners and linear error rate $1/\\varepsilon$ in the realizable PAC setting. Our results answer open questions from the literature, and show a stark contrast with geodesic halfspaces, for which most of the said learning problems are NP-hard.",
      "authors": [
        "Marco Bressan and Victor Chepoi and Emmanuel Esposito and Maximilian Thiessen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T11:14:16+00:00",
          "link": "https://arxiv.org/abs/2506.23186v1",
          "size": "47kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Algorithms for Learning and Compressing Monophonic Halfspaces in Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23186",
        "HTML": "https://arxiv.org/html/2506.23186v1",
        "PDF": "https://arxiv.org/pdf/2506.23186"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23189",
      "abstract": "As face forgeries generated by deep neural networks become increasingly sophisticated, detecting face manipulations in digital media has posed a significant challenge, underscoring the importance of maintaining digital media integrity and combating visual disinformation. Current detection models, predominantly based on supervised training with domain-specific data, often falter against forgeries generated by unencountered techniques. In response to this challenge, we introduce \\textit{Trident}, a face forgery detection framework that employs triplet learning with a Siamese network architecture for enhanced adaptability across diverse forgery methods. \\textit{Trident} is trained on curated triplets to isolate nuanced differences of forgeries, capturing fine-grained features that distinguish pristine samples from manipulated ones while controlling for other variables. To further enhance generalizability, we incorporate domain-adversarial training with a forgery discriminator. This adversarial component guides our embedding model towards forgery-agnostic representations, improving its robustness to unseen manipulations. In addition, we prevent gradient flow from the classifier head to the embedding model, avoiding overfitting induced by artifacts peculiar to certain forgeries. Comprehensive evaluations across multiple benchmarks and ablation studies demonstrate the effectiveness of our framework. We will release our code in a GitHub repository.",
      "authors": [
        "Mustafa Hakan Kara",
        "Aysegul Dundar",
        "and U\\u{g}ur G\\\"ud\\\"ukbay"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T11:17:25+00:00",
          "link": "https://arxiv.org/abs/2506.23189v1",
          "size": "3445kb",
          "version": "v1"
        }
      ],
      "title": "Trident: Detecting Face Forgeries with Adversarial Triplet Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23189",
        "HTML": "https://arxiv.org/html/2506.23189v1",
        "PDF": "https://arxiv.org/pdf/2506.23189"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23190",
      "abstract": "Unmanned Aerial Vehicles (UAVs) offer a promising solution for enhancing wireless connectivity and Quality of Service (QoS) in urban environments, acting as aerial Wi-Fi access points or cellular base stations. Their flexibility and rapid deployment capabilities make them suitable for addressing infrastructure gaps and traffic surges. However, optimizing UAV positions to maintain Line of Sight (LoS) links with ground User Equipment (UEs) remains challenging in obstacle-dense urban scenarios. This paper proposes VTOPA, a Vision-Aided Traffic- and Obstacle-Aware Positioning Algorithm that autonomously extracts environmental information -- such as obstacles and UE locations -- via computer vision and optimizes UAV positioning accordingly. The algorithm prioritizes LoS connectivity and dynamically adapts to user traffic demands in real time. Evaluated through simulations in ns-3, VTOPA achieves up to a 50% increase in aggregate throughput and a 50% reduction in delay, without compromising fairness, outperforming benchmark approaches in obstacle-rich environments.",
      "authors": [
        "Kamran Shafafi",
        "Manuel Ricardo",
        "Rui Campos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T11:22:49+00:00",
          "link": "https://arxiv.org/abs/2506.23190v1",
          "size": "4445kb",
          "version": "v1"
        }
      ],
      "title": "Autonomous Vision-Aided UAV Positioning for Obstacle-Aware Wireless Connectivity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23190",
        "HTML": "https://arxiv.org/html/2506.23190v1",
        "PDF": "https://arxiv.org/pdf/2506.23190"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23191",
      "abstract": "This paper investigates the impact of shallow versus deep relevance judgments on the performance of BERT-based reranking models in neural Information Retrieval. Shallow-judged datasets, characterized by numerous queries each with few relevance judgments, and deep-judged datasets, involving fewer queries with extensive relevance judgments, are compared. The research assesses how these datasets affect the performance of BERT-based reranking models trained on them. The experiments are run on the MS MARCO and LongEval collections. Results indicate that shallow-judged datasets generally enhance generalization and effectiveness of reranking models due to a broader range of available contexts. The disadvantage of the deep-judged datasets might be mitigated by a larger number of negative training examples.",
      "authors": [
        "Gabriel Iturra-Bocaz and Danny Vo and Petra Galuscakova"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T11:30:50+00:00",
          "link": "https://arxiv.org/abs/2506.23191v1",
          "size": "603kb",
          "version": "v1"
        }
      ],
      "title": "Impact of Shallow vs. Deep Relevance Judgments on BERT-based Reranking Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23191",
        "HTML": "https://arxiv.org/html/2506.23191v1",
        "PDF": "https://arxiv.org/pdf/2506.23191"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23192",
      "abstract": "Word embeddings have become essential components in various information retrieval and natural language processing tasks, such as ranking, document classification, and question answering. However, despite their widespread use, traditional word embedding models present a limitation in their static nature, which hampers their ability to adapt to the constantly evolving language patterns that emerge in sources such as social media and the web (e.g., new hashtags or brand names). To overcome this problem, incremental word embedding algorithms are introduced, capable of dynamically updating word representations in response to new language patterns and processing continuous data streams.\n  This paper presents RiverText, a Python library for training and evaluating incremental word embeddings from text data streams. Our tool is a resource for the information retrieval and natural language processing communities that work with word embeddings in streaming scenarios, such as analyzing social media. The library implements different incremental word embedding techniques, such as Skip-gram, Continuous Bag of Words, and Word Context Matrix, in a standardized framework. In addition, it uses PyTorch as its backend for neural network training. We have implemented a module that adapts existing intrinsic static word embedding evaluation tasks for word similarity and word categorization to a streaming setting. Finally, we compare the implemented methods with different hyperparameter settings and discuss the results. Our open-source library is available at https://github.com/dccuchile/rivertext.",
      "authors": [
        "Gabriel Iturra-Bocaz and Felipe Bravo-Marquez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T11:34:23+00:00",
          "link": "https://arxiv.org/abs/2506.23192v1",
          "size": "143kb",
          "version": "v1"
        }
      ],
      "title": "RiverText: A Python Library for Training and Evaluating Incremental Word Embeddings from Text Data Streams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23192",
        "HTML": "https://arxiv.org/html/2506.23192v1",
        "PDF": "https://arxiv.org/pdf/2506.23192"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23194",
      "abstract": "This paper's first aim is to prove a modernized Occam's razor beyond a reasonable doubt. To summarize the main argument in one sentence: If we consider all possible, intelligible, scientific models of ever-higher complexity, democratically, the predictions most favored by these complex models will agree with the predictions of the simplest models. This fact can be proven mathematically, thereby validating Occam's razor. Major parts of this line of reasoning have long preexisted within the depths of the algorithmic information theory literature, but they have always left room for doubts of various kinds. Therefore, we increase the generality, completeness, clarity, accessibility, and credibility of these arguments by countering over a dozen objections. We build our mathematical proof of Occam's razor on the shoulders of the exact 'chain rule' for Kolmogorov complexity.\n  Concerning physics, we then go on to diagnose the primary amendable root cause of the present stagnation of the research field of fundamental theoretical physics. We show that the effective antidote would consist in a practically feasible upgrade to the theoretical physicists' research methodology: When proposing new theoretical models, physicists should simply calculate and report the total amount of information that their models consist of. We explain why this methodology would be highly effective as well as how these calculations could be performed efficiently.",
      "authors": [
        "Gabriel Leuenberger"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T11:43:11+00:00",
          "link": "https://arxiv.org/abs/2506.23194v1",
          "size": "56kb",
          "version": "v1"
        }
      ],
      "title": "General Mathematical Proof of Occam's Razor; Upgrading Theoretical Physicists' Methodology",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23194",
        "HTML": "https://arxiv.org/html/2506.23194v1",
        "PDF": "https://arxiv.org/pdf/2506.23194"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23196",
      "abstract": "Real-world videos often contain overlapping events and complex temporal dependencies, making multimodal interaction modeling particularly challenging. We introduce DEL, a framework for dense semantic action localization, aiming to accurately detect and classify multiple actions at fine-grained temporal resolutions in long untrimmed videos. DEL consists of two key modules: the alignment of audio and visual features that leverage masked self-attention to enhance intra-mode consistency and a multimodal interaction refinement module that models cross-modal dependencies across multiple scales, enabling high-level semantics and fine-grained details. Our method achieves state-of-the-art performance on multiple real-world Temporal Action Localization (TAL) datasets, UnAV-100, THUMOS14, ActivityNet 1.3, and EPIC-Kitchens-100, surpassing previous approaches with notable average mAP gains of +3.3%, +2.6%, +1.2%, +1.7% (verb), and +1.4% (noun), respectively.",
      "authors": [
        "Mona Ahmadian",
        "Amir Shirian",
        "Frank Guerin",
        "Andrew Gilbert"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T11:50:19+00:00",
          "link": "https://arxiv.org/abs/2506.23196v1",
          "size": "904kb",
          "version": "v1"
        }
      ],
      "title": "DEL: Dense Event Localization for Multi-modal Audio-Visual Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23196",
        "HTML": "https://arxiv.org/html/2506.23196v1",
        "PDF": "https://arxiv.org/pdf/2506.23196"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23198",
      "abstract": "Hybrid character sums are an important class of exponential sums which have nice applications in coding theory and sequence design. Let $\\gf_{p^m}$ be the finite field with $p^m$ elements for a prime $p$ and a positive integer $m$. Let $V_n^{(p)}$ be an $n$-dimensional vector space over $\\gf_p$ for a prime $p$. In this paper, we study the hybrid character sums of the form \\begin{eqnarray*} \\sum_{x \\in V_n^{(p)}}\\psi\\left(F(x)\\right)\\chi_1\\left(a x\\right), \\end{eqnarray*} where $F$ is a function from $V_n^{(p)}$ to $\\gf_{p^m}$ and $a \\in V_n^{(p)}$, $\\psi$ is a nontrivial multiplicative character of $\\gf_{p^m}$ and $\\chi_1$ is the canonical additive character of $V_n^{(p)}$. If $F(x)$ is a vectorial dual-bent function and $a \\in V_n^{(p)}\\setminus \\{0\\}$, we determine their complex modulus or explicit values under certain conditions, which generalizes some known results as special cases. It is concluded that the hybrid character sums from vectorial dual-bent functions have very small complex modulus. As applications, three families of asymptotically optimal complex codebooks are constructed from vectorial dual-bent functions and their maximal cross-correlation amplitude are determined based on the hybrid character sums. The constructed codebooks have very small alphabet sizes, which enhances their appeal for implementation. Besides, all of the three families of codebooks have only two-valued or three-valued cross-correlation amplitudes.",
      "authors": [
        "Ziling Heng",
        "Peng Wang",
        "Chengju Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T12:04:01+00:00",
          "link": "https://arxiv.org/abs/2506.23198v1",
          "size": "21kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid Character Sums From Vectorial Dual-Bent Functions and Asymptotically Optimal Complex Codebooks With Small Alphabet Sizes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23198",
        "HTML": "https://arxiv.org/html/2506.23198v1",
        "PDF": "https://arxiv.org/pdf/2506.23198"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23201",
      "abstract": "Accurate residential load forecasting is critical for power system reliability with rising renewable integration and demand-side flexibility. However, most statistical and machine learning models treat external factors, such as weather, calendar effects, and pricing, as extra input, ignoring their heterogeneity, and thus limiting the extraction of useful external information. We propose a paradigm shift: external data should serve as meta-knowledge to dynamically adapt the forecasting model itself. Based on this idea, we design a meta-representation framework using hypernetworks that modulate selected parameters of a base Deep Learning (DL) model in response to external conditions. This provides both expressivity and adaptability. We further integrate a Mixture-of-Experts (MoE) mechanism to enhance efficiency through selective expert activation, while improving robustness by filtering redundant external inputs. The resulting model, dubbed as a Meta Mixture of Experts for External data (M2oE2), achieves substantial improvements in accuracy and robustness with limited additional overhead, outperforming existing state-of-the-art methods in diverse load datasets. The dataset and source code are publicly available at https://github.com/haorandd/M2oE2\\_load\\_forecast.git.",
      "authors": [
        "Haoran Li and Muhao Guo and Marija Ilic and Yang Weng and Guangchun Ruan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T12:07:18+00:00",
          "link": "https://arxiv.org/abs/2506.23201v1",
          "size": "915kb",
          "version": "v1"
        }
      ],
      "title": "External Data-Enhanced Meta-Representation for Adaptive Probabilistic Load Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23201",
        "HTML": "https://arxiv.org/html/2506.23201v1",
        "PDF": "https://arxiv.org/pdf/2506.23201"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23202",
      "abstract": "The person search task aims to locate a target person within a set of scene images. In recent years, transformer-based models in this field have made some progress. However, they still face three primary challenges: 1) the self-attention mechanism tends to suppress high-frequency components in the features, which severely impacts model performance; 2) the computational cost of transformers is relatively high. To address these issues, we propose a novel High-frequency Augmentation and Multi-Wave mixing (HAMW) method for person search. HAMW is designed to enhance the discriminative feature extraction capabilities of transformers while reducing computational overhead and improving efficiency. Specifically, we develop a three-stage framework that progressively optimizes both detection and re-identification performance. Our model enhances the perception of high-frequency features by learning from augmented inputs containing additional high-frequency components. Furthermore, we replace the self-attention layers in the transformer with a strategy based on multi-level Haar wavelet fusion to capture multi-scale features. This not only lowers the computational complexity but also alleviates the suppression of high-frequency features and enhances the ability to exploit multi-scale information. Extensive experiments demonstrate that HAMW achieves state-of-the-art performance on both the CUHK-SYSU and PRW datasets.",
      "authors": [
        "Qilin Shu",
        "Qixian Zhang",
        "Qi Zhang",
        "Hongyun Zhang",
        "Duoqian Miao and Cairong Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T12:08:26+00:00",
          "link": "https://arxiv.org/abs/2506.23202v1",
          "size": "8246kb",
          "version": "v1"
        }
      ],
      "title": "Transformer-Based Person Search with High-Frequency Augmentation and Multi-Wave Mixing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23202",
        "HTML": "https://arxiv.org/html/2506.23202v1",
        "PDF": "https://arxiv.org/pdf/2506.23202"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23204",
      "abstract": "There exist two main frameworks for non-intrusive implementations of approximate balanced truncation: the quadrature-based framework and the ADI-based framework. Both approaches rely solely on samples of the transfer function to construct truncated balanced models, eliminating the need for access to the original model's state-space realization. Recently, the quadrature-based framework has been extended to various generalizations of balanced truncation, including positive-real balanced truncation, bounded-real balanced truncation, and balanced stochastic truncation. While this extension is theoretically nonintrusive-meaning it does not require the original state-space realization-it depends on samples of spectral factorizations of the transfer function. Since practical methods for obtaining such samples are currently unavailable, this extension remains largely a theoretical contribution. In this work, we present a non-intrusive ADI-type framework for these generalized balanced truncation methods that requires only samples of the original transfer function for implementation.",
      "authors": [
        "Umair Zulfiqar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T12:18:55+00:00",
          "link": "https://arxiv.org/abs/2506.23204v1",
          "size": "1726kb",
          "version": "v1"
        }
      ],
      "title": "Data-driven Implementations of Various Generalizations of Balanced Truncation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23204",
        "HTML": "https://arxiv.org/html/2506.23204v1",
        "PDF": "https://arxiv.org/pdf/2506.23204"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23205",
      "abstract": "Existing diffusion-based 3D shape completion methods typically use a conditional paradigm, injecting incomplete shape information into the denoising network via deep feature interactions (e.g., concatenation, cross-attention) to guide sampling toward complete shapes, often represented by voxel-based distance functions. However, these approaches fail to explicitly model the optimal global transport path, leading to suboptimal completions. Moreover, performing diffusion directly in voxel space imposes resolution constraints, limiting the generation of fine-grained geometric details. To address these challenges, we propose BridgeShape, a novel framework for 3D shape completion via latent diffusion Schr\\\"odinger bridge. The key innovations lie in two aspects: (i) BridgeShape formulates shape completion as an optimal transport problem, explicitly modeling the transition between incomplete and complete shapes to ensure a globally coherent transformation. (ii) We introduce a Depth-Enhanced Vector Quantized Variational Autoencoder (VQ-VAE) to encode 3D shapes into a compact latent space, leveraging self-projected multi-view depth information enriched with strong DINOv2 features to enhance geometric structural perception. By operating in a compact yet structurally informative latent space, BridgeShape effectively mitigates resolution constraints and enables more efficient and high-fidelity 3D shape completion. BridgeShape achieves state-of-the-art performance on large-scale 3D shape completion benchmarks, demonstrating superior fidelity at higher resolutions and for unseen object classes.",
      "authors": [
        "Dequan Kong",
        "Zhe Zhu",
        "Honghua Chen",
        "Mingqiang Wei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T12:21:21+00:00",
          "link": "https://arxiv.org/abs/2506.23205v1",
          "size": "2471kb",
          "version": "v1"
        }
      ],
      "title": "BridgeShape: Latent Diffusion Schr\\\"odinger Bridge for 3D Shape Completion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23205",
        "HTML": "https://arxiv.org/html/2506.23205v1",
        "PDF": "https://arxiv.org/pdf/2506.23205"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23207",
      "abstract": "Recent advances in 3D Gaussian Splatting (3DGS) have enabled RGB-only SLAM systems to achieve high-fidelity scene representation. However, the heavy reliance of existing systems on photometric rendering loss for camera tracking undermines their robustness, especially in unbounded outdoor environments with severe viewpoint and illumination changes. To address these challenges, we propose TVG-SLAM, a robust RGB-only 3DGS SLAM system that leverages a novel tri-view geometry paradigm to ensure consistent tracking and high-quality mapping. We introduce a dense tri-view matching module that aggregates reliable pairwise correspondences into consistent tri-view matches, forming robust geometric constraints across frames. For tracking, we propose Hybrid Geometric Constraints, which leverage tri-view matches to construct complementary geometric cues alongside photometric loss, ensuring accurate and stable pose estimation even under drastic viewpoint shifts and lighting variations. For mapping, we propose a new probabilistic initialization strategy that encodes geometric uncertainty from tri-view correspondences into newly initialized Gaussians. Additionally, we design a Dynamic Attenuation of Rendering Trust mechanism to mitigate tracking drift caused by mapping latency. Experiments on multiple public outdoor datasets show that our TVG-SLAM outperforms prior RGB-only 3DGS-based SLAM systems. Notably, in the most challenging dataset, our method improves tracking robustness, reducing the average Absolute Trajectory Error (ATE) by 69.0\\% while achieving state-of-the-art rendering quality. The implementation of our method will be released as open-source.",
      "authors": [
        "Zhen Tan",
        "Xieyuanli Chen",
        "Lei Feng",
        "Yangbing Ge",
        "Shuaifeng Zhi",
        "Jiaxiong Liu",
        "Dewen Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T12:31:05+00:00",
          "link": "https://arxiv.org/abs/2506.23207v1",
          "size": "5365kb",
          "version": "v1"
        }
      ],
      "title": "TVG-SLAM: Robust Gaussian Splatting SLAM with Tri-view Geometric Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23207",
        "HTML": "https://arxiv.org/html/2506.23207v1",
        "PDF": "https://arxiv.org/pdf/2506.23207"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23209",
      "abstract": "Timely and accurate diagnosis of appendicitis is critical in clinical settings to prevent serious complications. While CT imaging remains the standard diagnostic tool, the growing number of cases can overwhelm radiologists, potentially causing delays. In this paper, we propose a deep learning model that leverages 3D CT scans for appendicitis classification, incorporating Slice Attention mechanisms guided by external 2D datasets to enhance small lesion detection. Additionally, we introduce a hierarchical classification framework using pre-trained 2D models to differentiate between simple and complicated appendicitis. Our approach improves AUC by 3% for appendicitis and 5.9% for complicated appendicitis, offering a more efficient and reliable diagnostic solution compared to previous work.",
      "authors": [
        "Chia-Wen Huang",
        "Haw Hwai",
        "Chien-Chang Lee",
        "Pei-Yuan Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T12:37:23+00:00",
          "link": "https://arxiv.org/abs/2506.23209v1",
          "size": "2675kb",
          "version": "v1"
        }
      ],
      "title": "A Hierarchical Slice Attention Network for Appendicitis Classification in 3D CT Scans",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23209",
        "HTML": "https://arxiv.org/html/2506.23209v1",
        "PDF": "https://arxiv.org/pdf/2506.23209"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23210",
      "abstract": "Federated learning(FL) is used for distributed scenarios to train artificial intelligence(AI) models while ensuring users' privacy. In federated learning scenario, the server generally never knows about users' data. This type of concept makes the AI training process efficient in terms of data privacy. However, regarding model performance, federated AI models may not sufficiently satisfy AI users' expectations. Furthermore, AI users have a wide range of different needs. It is not easy to satisfy the whole users needs. These types of issues can be addressed through AI model optimization, fine-tuning, or personalization to achieve optimal model performance. To address model optimization challenges, we propose reference model-based federated learning for optimal fine-tuning, which overcomes catastrophic forgetting in each round. This method is derived from Bayesian parameter-efficient transfer learning, which includes an optimal proximal term and enables overcoming the catastrophic forgetting issue in each round by utilizing a reference model that incorporates previous model parameters. As a result, this method achieves both high model performance and low computing cost.",
      "authors": [
        "Taehwan Yoon",
        "Bongjun Choi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T12:41:11+00:00",
          "link": "https://arxiv.org/abs/2506.23210v1",
          "size": "657kb",
          "version": "v1"
        }
      ],
      "title": "FedRef: Communication-Efficient Bayesian Fine Tuning with Reference Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23210",
        "HTML": "https://arxiv.org/html/2506.23210v1",
        "PDF": "https://arxiv.org/pdf/2506.23210"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23214",
      "abstract": "We show that algebraic formulas and constant-depth circuits are closed under taking factors. In other words, we show that if a multivariate polynomial over a field of characteristic zero has a small constant-depth circuit or formula, then all its factors can be computed by small constant-depth circuits or formulas respectively.\n  Our result turns out to be an elementary consequence of a fundamental and surprising result of Furstenberg from the 1960s, which gives a non-iterative description of the power series roots of a bivariate polynomial. Combined with standard structural ideas in algebraic complexity, we observe that this theorem yields the desired closure results.\n  As applications, we get alternative (and perhaps simpler) proofs of various known results and strengthen the quantitative bounds in some of them. This includes a unified proof of known closure results for algebraic models (circuits, branching programs and VNP), an extension of the analysis of the Kabanets-Impagliazzo hitting set generator to formulas and constant-depth circuits, and a (significantly) simpler proof of correctness as well as stronger guarantees on the output in the subexponential time deterministic algorithm for factorization of constant-depth circuits from a recent work of Bhattacharjee, Kumar, Ramanathan, Saptharishi & Saraf.",
      "authors": [
        "Somnath Bhattacharjee",
        "Mrinal Kumar",
        "Shanthanu S. Rai",
        "Varun Ramanathan",
        "Ramprasad Saptharishi",
        "Shubhangi Saraf"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T12:54:30+00:00",
          "link": "https://arxiv.org/abs/2506.23214v1",
          "size": "90kb",
          "version": "v1"
        }
      ],
      "title": "Closure under factorization from a result of Furstenberg",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23214",
        "HTML": "https://arxiv.org/html/2506.23214v1",
        "PDF": "https://arxiv.org/pdf/2506.23214"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23215",
      "abstract": "We present a compact labeling scheme for determining whether a designated set of terminals in a graph remains connected after any $f$ (or less) vertex failures occur. An $f$-FT Steiner connectivity labeling scheme for an $n$-vertex graph $G=(V,E)$ with terminal set $U \\subseteq V$ provides labels to the vertices of $G$, such that given only the labels of any subset $F \\subseteq V$ with $|F| \\leq f$, one can determine if $U$ remains connected in $G-F$. The main complexity measure is the maximum label length.\n  The special case $U=V$ of global connectivity has been recently studied by Jiang, Parter, and Petruschka, who provided labels of $n^{1-1/f} \\cdot \\mathrm{poly}(f,\\log n)$ bits. This is near-optimal (up to $\\mathrm{poly}(f,\\log n)$ factors) by a lower bound of Long, Pettie and Saranurak. Our scheme achieves labels of $|U|^{1-1/f} \\cdot \\mathrm{poly}(f, \\log n)$ for general $U \\subseteq V$, which is near-optimal for any given size $|U|$ of the terminal set. To handle terminal sets, our approach differs from Jiang et al. We use a well-structured Steiner tree for $U$ produced by a decomposition theorem of Duan and Pettie, and bypass the need for Nagamochi-Ibaraki sparsification.",
      "authors": [
        "Koustav Bhanja",
        "Asaf Petruschka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T12:59:25+00:00",
          "link": "https://arxiv.org/abs/2506.23215v1",
          "size": "168kb",
          "version": "v1"
        }
      ],
      "title": "Near-Optimal Vertex Fault-Tolerant Labels for Steiner Connectivity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23215",
        "HTML": "https://arxiv.org/html/2506.23215v1",
        "PDF": "https://arxiv.org/pdf/2506.23215"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23219",
      "abstract": "Urban research involves a wide range of scenarios and tasks that require the understanding of multi-modal data. Current methods often focus on specific data types and lack a unified framework in urban field for processing them comprehensively. The recent success of multi-modal large language models (MLLMs) presents a promising opportunity to overcome this limitation. In this paper, we introduce $\\textit{UrbanLLaVA}$, a multi-modal large language model designed to process these four types of data simultaneously and achieve strong performance across diverse urban tasks compared with general MLLMs. In $\\textit{UrbanLLaVA}$, we first curate a diverse urban instruction dataset encompassing both single-modal and cross-modal urban data, spanning from location view to global view of urban environment. Additionally, we propose a multi-stage training framework that decouples spatial reasoning enhancement from domain knowledge learning, thereby improving the compatibility and downstream performance of $\\textit{UrbanLLaVA}$ across diverse urban tasks. Finally, we also extend existing benchmark for urban research to assess the performance of MLLMs across a wide range of urban tasks. Experimental results from three cities demonstrate that $\\textit{UrbanLLaVA}$ outperforms open-source and proprietary MLLMs in both single-modal tasks and complex cross-modal tasks and shows robust generalization abilities across cities. Source codes and data are openly accessible to the research community via https://github.com/tsinghua-fib-lab/UrbanLLaVA.",
      "authors": [
        "Jie Feng",
        "Shengyuan Wang",
        "Tianhui Liu",
        "Yanxin Xi",
        "Yong Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T13:04:27+00:00",
          "link": "https://arxiv.org/abs/2506.23219v1",
          "size": "7919kb",
          "version": "v1"
        }
      ],
      "title": "UrbanLLaVA: A Multi-modal Large Language Model for Urban Intelligence with Spatial Reasoning and Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23219",
        "HTML": "https://arxiv.org/html/2506.23219v1",
        "PDF": "https://arxiv.org/pdf/2506.23219"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23220",
      "abstract": "We show that the GCD of two univariate polynomials can be computed by (piece-wise) algebraic circuits of constant depth and polynomial size over any sufficiently large field, regardless of the characteristic. This extends a recent result of Andrews & Wigderson who showed such an upper bound over fields of zero or large characteristic.\n  Our proofs are based on a recent work of Bhattacharjee, Kumar, Rai, Ramanathan, Saptharishi \\& Saraf that shows closure of constant depth algebraic circuits under factorization. On our way to the proof, we show that any $n$-variate symmetric polynomial $P$ that has a small constant depth algebraic circuit can be written as the composition of a small constant depth algebraic circuit with elementary symmetric polynomials. This statement is a constant depth version of a result of Bl\\\"{a}ser & Jindal, who showed this for algebraic circuits of unbounded depth. As an application of our techniques, we also strengthen the closure results for factors of constant-depth circuits in the work of Bhattacharjee et al. over fields for small characteristic.",
      "authors": [
        "Somnath Bhattacharjee",
        "Mrinal Kumar",
        "Shanthanu Rai",
        "Varun Ramanathan",
        "Ramprasad Saptharishi",
        "Shubhangi Saraf"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T13:04:49+00:00",
          "link": "https://arxiv.org/abs/2506.23220v1",
          "size": "79kb",
          "version": "v1"
        }
      ],
      "title": "Constant-depth circuits for polynomial GCD over any characteristic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23220",
        "HTML": "https://arxiv.org/html/2506.23220v1",
        "PDF": "https://arxiv.org/pdf/2506.23220"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23221",
      "abstract": "The paper proposes a statistical learning approach to the problem of estimating missing pixels of images, crucial for image inpainting and super-resolution problems. One of the main novelties of the method is that it also provides uncertainty quantifications together with the estimated values. Our core assumption is that the underlying data-generating function comes from a Reproducing Kernel Hilbert Space (RKHS). A special emphasis is put on band-limited functions, central to signal processing, which form Paley-Wiener type RKHSs. The proposed method, which we call Simultaneously Guaranteed Kernel Interpolation (SGKI), is an extension and refinement of a recently developed kernel method. An advantage of SGKI is that it not only estimates the missing pixels, but also builds non-asymptotic confidence bands for the unobserved values, which are simultaneously guaranteed for all missing pixels. We also show how to compute these bands efficiently using Schur complements, we discuss a generalization to vector-valued functions, and we present a series of numerical experiments on various datasets containing synthetically generated and benchmark images, as well.",
      "authors": [
        "B\\'alint Horv\\'ath",
        "Bal\\'azs Csan\\'ad Cs\\'aji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T13:12:23+00:00",
          "link": "https://arxiv.org/abs/2506.23221v1",
          "size": "621kb",
          "version": "v1"
        }
      ],
      "title": "Single Image Inpainting and Super-Resolution with Simultaneous Uncertainty Guarantees by Universal Reproducing Kernels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23221",
        "HTML": "https://arxiv.org/html/2506.23221v1",
        "PDF": "https://arxiv.org/pdf/2506.23221"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23225",
      "abstract": "Gated Linear Units (GLUs) have become essential components in the feed-forward networks of state-of-the-art Large Language Models (LLMs). However, they require twice as many memory reads compared to feed-forward layers without gating, due to the use of separate weight matrices for the gate and value streams. To address this bottleneck, we introduce Masked Gated Linear Units (MGLUs), a novel family of GLUs with an efficient kernel implementation. The core contribution of MGLUs include: (1) the Mixture of Element-wise Gating (MoEG) architecture that learns multiple binary masks, each determining gate or value assignments at the element level on a single shared weight matrix resulting in reduced memory transfer, and (2) FlashMGLU, a hardware-friendly kernel that yields up to a 19.7 $\\times$ inference-time speed-up over a naive PyTorch MGLU and is 47% more memory-efficient and 34% faster than standard GLUs despite added architectural complexity on an RTX5090 GPU. In LLM experiments, the Swish-activated variant SwiMGLU preserves its memory advantages while matching - or even surpassing - the downstream accuracy of the SwiGLU baseline.",
      "authors": [
        "Yukito Tajima",
        "Nakamasa Inoue",
        "Yusuke Sekikawa",
        "Ikuro Sato and Rio Yokota"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T13:16:20+00:00",
          "link": "https://arxiv.org/abs/2506.23225v1",
          "size": "3306kb",
          "version": "v1"
        }
      ],
      "title": "Masked Gated Linear Unit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23225",
        "HTML": "https://arxiv.org/html/2506.23225v1",
        "PDF": "https://arxiv.org/pdf/2506.23225"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23227",
      "abstract": "This paper investigates indoor point cloud semantic segmentation under scene-level annotation, which is less explored compared to methods relying on sparse point-level labels. In the absence of precise point-level labels, current methods first generate point-level pseudo-labels, which are then used to train segmentation models. However, generating accurate pseudo-labels for each point solely based on scene-level annotations poses a considerable challenge, substantially affecting segmentation performance. Consequently, to enhance accuracy, this paper proposes a high-quality pseudo-label generation framework by exploring contemporary multi-modal information and region-point semantic consistency. Specifically, with a cross-modal feature guidance module, our method utilizes 2D-3D correspondences to align point cloud features with corresponding 2D image pixels, thereby assisting point cloud feature learning. To further alleviate the challenge presented by the scene-level annotation, we introduce a region-point semantic consistency module. It produces regional semantics through a region-voting strategy derived from point-level semantics, which are subsequently employed to guide the point-level semantic predictions. Leveraging the aforementioned modules, our method can rectify inaccurate point-level semantic predictions during training and obtain high-quality pseudo-labels. Significant improvements over previous works on ScanNet v2 and S3DIS datasets under scene-level annotation can demonstrate the effectiveness. Additionally, comprehensive ablation studies validate the contributions of our approach's individual components. The code is available at https://github.com/LHDuan/WSegPC .",
      "authors": [
        "Lunhao Duan",
        "Shanshan Zhao",
        "Xingxing Weng",
        "Jing Zhang",
        "Gui-Song Xia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T13:17:12+00:00",
          "link": "https://arxiv.org/abs/2506.23227v1",
          "size": "15310kb",
          "version": "v1"
        }
      ],
      "title": "High-quality Pseudo-labeling for Point Cloud Segmentation with Scene-level Annotation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23227",
        "HTML": "https://arxiv.org/html/2506.23227v1",
        "PDF": "https://arxiv.org/pdf/2506.23227"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23234",
      "abstract": "Pre-trained models (PTMs) have gained widespread popularity and achieved remarkable success across various fields, driven by their groundbreaking performance and easy accessibility through hosting providers. However, the challenges faced by downstream developers in reusing PTMs in software systems are less explored. To bridge this knowledge gap, we qualitatively created and analyzed a dataset of 840 PTM-related issue reports from 31 OSS GitHub projects. We systematically developed a comprehensive taxonomy of PTM-related challenges that developers face in downstream projects. Our study identifies seven key categories of challenges that downstream developers face in reusing PTMs, such as model usage, model performance, and output quality. We also compared our findings with existing taxonomies. Additionally, we conducted a resolution time analysis and, based on statistical tests, found that PTM-related issues take significantly longer to be resolved than issues unrelated to PTMs, with significant variation across challenge categories. We discuss the implications of our findings for practitioners and possibilities for future research.",
      "authors": [
        "Peerachai Banyongrakkul",
        "Mansooreh Zahedi",
        "Patanamon Thongtanunam",
        "Christoph Treude and Haoyu Gao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T13:36:58+00:00",
          "link": "https://arxiv.org/abs/2506.23234v1",
          "size": "1707kb",
          "version": "v1"
        }
      ],
      "title": "From Release to Adoption: Challenges in Reusing Pre-trained AI Models for Downstream Developers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23234",
        "HTML": "https://arxiv.org/html/2506.23234v1",
        "PDF": "https://arxiv.org/pdf/2506.23234"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23235",
      "abstract": "The alignment of Large Language Models (LLMs) is critically dependent on reward models trained on costly human preference data. While recent work explores bypassing this cost with AI feedback, these methods often lack a rigorous theoretical foundation. In this paper, we discover that a powerful generalist reward model is already latently present within any LLM trained via standard next-token prediction. We prove that this endogenous reward is not a heuristic, but is theoretically equivalent to a reward function learned through offline inverse reinforcement learning. This connection allows us to directly elicit a high-quality reward signal from a base (pre-trained or supervised fine-tuned) model without any further training. Critically, we also prove that subsequent reinforcement learning using this endogenous reward leads to a policy with a provably superior error bound compared to the base model. To our best knowledge, this is the first theoretical proof of the effectiveness of reinforcement learning for LLMs. Our experiments validate this theory, demonstrating that our method not only outperforms existing LLM-as-a-judge approaches but can also surpass explicitly trained reward models. These findings suggest that the reward modeling stage can be replaced by a principled method of eliciting the knowledge already captured during pre-training, heralding a more efficient, powerful, and scalable paradigm for LLMs alignment as well as multi-modal models.",
      "authors": [
        "Yi-Chen Li",
        "Tian Xu",
        "Yang Yu",
        "Xuqin Zhang",
        "Xiong-Hui Chen",
        "Zhongxiang Ling",
        "Ningjing Chao",
        "Lei Yuan",
        "Zhi-Hua Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T13:45:54+00:00",
          "link": "https://arxiv.org/abs/2506.23235v1",
          "size": "121kb",
          "version": "v1"
        }
      ],
      "title": "Generalist Reward Models: Found Inside Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23235",
        "HTML": "https://arxiv.org/html/2506.23235v1",
        "PDF": "https://arxiv.org/pdf/2506.23235"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23236",
      "abstract": "Parametric human body models play a crucial role in computer graphics and vision, enabling applications ranging from human motion analysis to understanding human-environment interactions. Traditionally, these models use surface meshes, which pose challenges in efficiently handling interactions with other geometric entities, such as objects and scenes, typically represented as meshes or point clouds. To address this limitation, recent research has explored volumetric neural implicit body models. However, existing works are either insufficiently robust for complex human articulations or impose high computational and memory costs, limiting their widespread use. To this end, we introduce VolumetricSMPL, a neural volumetric body model that leverages Neural Blend Weights (NBW) to generate compact, yet efficient MLP decoders. Unlike prior approaches that rely on large MLPs, NBW dynamically blends a small set of learned weight matrices using predicted shape- and pose-dependent coefficients, significantly improving computational efficiency while preserving expressiveness. VolumetricSMPL outperforms prior volumetric occupancy model COAP with 10x faster inference, 6x lower GPU memory usage, enhanced accuracy, and a Signed Distance Function (SDF) for efficient and differentiable contact modeling. We demonstrate VolumetricSMPL's strengths across four challenging tasks: (1) reconstructing human-object interactions from in-the-wild images, (2) recovering human meshes in 3D scenes from egocentric views, (3) scene-constrained motion synthesis, and (4) resolving self-intersections. Our results highlight its broad applicability and significant performance and efficiency gains.",
      "authors": [
        "Marko Mihajlovic",
        "Siwei Zhang",
        "Gen Li",
        "Kaifeng Zhao",
        "Lea M\\\"uller",
        "Siyu Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T13:48:38+00:00",
          "link": "https://arxiv.org/abs/2506.23236v1",
          "size": "10049kb",
          "version": "v1"
        }
      ],
      "title": "VolumetricSMPL: A Neural Volumetric Body Model for Efficient Interactions, Contacts, and Collisions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23236",
        "HTML": "https://arxiv.org/html/2506.23236v1",
        "PDF": "https://arxiv.org/pdf/2506.23236"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23242",
      "abstract": "This paper revisits the classical formulation of the Z-transform and its relationship to the inverse Laplace transform (L-1), originally developed by Ragazzini in sampled-data theory. It identifies a longstanding mathematical oversight in standard derivations, which typically neglect the contribution from the infinite arc in the complex plane during inverse Laplace evaluation. This omission leads to inconsistencies, especially at discontinuities such as t = 0. By incorporating the full Bromwich contour, including all boundary contributions, we restore internal consistency between L-1 and the Z-transform, aligning the corrected L-1 with results from Discrete-Time Fourier Transform (DTFT) aliasing theory. Consequently, this necessitates a structural revision of the Z-transform, inverse Laplace transform, and the behavior of the Heaviside step function at discontinuities, providing a more accurate foundation for modeling and analysis of sampled-data systems.",
      "authors": [
        "Yuxin Yang and Hang Zhou and Chaojie Li and Xin Li and Yingyi Yan and Mingyang Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T14:04:18+00:00",
          "link": "https://arxiv.org/abs/2506.23242v1",
          "size": "1351kb",
          "version": "v1"
        }
      ],
      "title": "Revisiting Z Transform Laplace Inversion: To Correct flaws in Signal and System Theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23242",
        "HTML": "https://arxiv.org/html/2506.23242v1",
        "PDF": "https://arxiv.org/pdf/2506.23242"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23247",
      "abstract": "Deep learning dominates image classification tasks, yet understanding how models arrive at predictions remains a challenge. Much research focuses on local explanations of individual predictions, such as saliency maps, which visualise the influence of specific pixels on a model's prediction. However, reviewing many of these explanations to identify recurring patterns is infeasible, while global methods often oversimplify and miss important local behaviours. To address this, we propose Segment Attribution Tables (SATs), a method for summarising local saliency explanations into (semi-)global insights. SATs take image segments (such as \"eyes\" in Chihuahuas) and leverage saliency maps to quantify their influence. These segments highlight concepts the model relies on across instances and reveal spurious correlations, such as reliance on backgrounds or watermarks, even when out-of-distribution test performance sees little change. SATs can explain any classifier for which a form of saliency map can be produced, using segmentation maps that provide named segments. SATs bridge the gap between oversimplified global summaries and overly detailed local explanations, offering a practical tool for analysing and debugging image classifiers.",
      "authors": [
        "James Hinns and David Martens"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T14:11:02+00:00",
          "link": "https://arxiv.org/abs/2506.23247v1",
          "size": "1129kb",
          "version": "v1"
        }
      ],
      "title": "Aggregating Local Saliency Maps for Semi-Global Explainable Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23247",
        "HTML": "https://arxiv.org/html/2506.23247v1",
        "PDF": "https://arxiv.org/pdf/2506.23247"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23248",
      "abstract": "This paper investigates the joint optimization of trajectory planning and resource allocation for a high-altitude platform stations synthetic aperture radar (HAPs-SAR) system. To support real-time sensing and conserve the limited energy budget of the HAPs, the proposed framework assumes that the acquired radar data are transmitted in real time to a ground base station for SAR image reconstruction. A dynamic trajectory model is developed, and the power consumption associated with radar sensing, data transmission, and circular flight is comprehensively analyzed. In addition, solar energy harvesting is considered to enhance system sustainability. An energy-aware mixed-integer nonlinear programming (MINLP) problem is formulated to maximize radar beam coverage while satisfying operational constraints. To solve this challenging problem, a sub-optimal successive convex approximation (SCA)-based framework is proposed, incorporating iterative optimization and finite search. Simulation results validate the convergence of the proposed algorithm and demonstrate its effectiveness in balancing SAR performance, communication reliability, and energy efficiency. A final SAR imaging simulation on a 9-target lattice scenario further confirms the practical feasibility of the proposed solution.",
      "authors": [
        "Bang Huang and Kihong Park and Xiaowei Pang and Mohamed-Slim Alouini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T14:11:30+00:00",
          "link": "https://arxiv.org/abs/2506.23248v1",
          "size": "630kb",
          "version": "v1"
        }
      ],
      "title": "Joint Trajectory and Resource Optimization for HAPs-SAR Systems with Energy-Aware Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23248",
        "HTML": "https://arxiv.org/html/2506.23248v1",
        "PDF": "https://arxiv.org/pdf/2506.23248"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23249",
      "abstract": "This work introduces a novel \\textsf{AT1} phase-field framework for simulating quasi-static anti-plane shear fracture in geometrically linear elastic bodies. A key feature of this framework is the unification of $\\xi$-based local mesh adaptivity -- where $\\xi$ represents the characteristic length of the damage zone -- and an algebraically nonlinear strain energy density function. A modified Francfort-Marigo energy functional, together with its Ambrosio-Tortorelli-type regularization, is hereby proposed to address challenges within the framework of nonlinearly constituted materials. We dynamically optimize $\\xi$ throughout the simulation, significantly enhancing the computational efficiency and accuracy of numerically approximating the local minimizers of the Ambrosio-Tortorelli (\\textsf{AT1})-type phase-field model. The proposed regularization for the total energy functional comprises three distinct components: a nonlinear strain energy, an evolving surface energy, and a linear-type regularization term dependent on the length scale of the damage zone. Variational principles applied to this novel energy functional yield a coupled system of governing second-order quasilinear partial differential equations for the mechanics and phase-field variables. These equations are subsequently discretized using the conforming bilinear finite element method. The formulation is underpinned by four crucial parameters: two are integral to the nonlinear strain energy function, while the other two serve as penalty parameters. These penalty parameters are asymptotically calibrated and rigorously utilized in the numerical simulations. Our results demonstrate that this spatially adaptive approach leads to enhanced mesh adaptivity, ensuring the robust convergence of the numerical solution.",
      "authors": [
        "Maria P. Fernando and S. M. Mallikarjunaiah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T14:13:27+00:00",
          "link": "https://arxiv.org/abs/2506.23249v1",
          "size": "422kb",
          "version": "v1"
        }
      ],
      "title": "An \\textsf{AT1} phase-field framework for quasi-static anti-plane shear fracture: Unifying $\\xi$-based adaptivity and nonlinear strain energy density function",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23249",
        "HTML": "https://arxiv.org/html/2506.23249v1",
        "PDF": "https://arxiv.org/pdf/2506.23249"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23252",
      "abstract": "The rapid proliferation of unmanned aerial vehicles (UAVs) has highlighted the importance of robust and efficient object detection in diverse aerial scenarios. Detecting small objects under complex conditions, however, remains a significant challenge. Existing approaches often prioritize inference speed, leading to degraded performance when handling multi-modal inputs. To address this, we present DGE-YOLO, an enhanced YOLO-based detection framework designed to effectively fuse multi-modal information. Specifically, we introduce a dual-branch architecture for modality-specific feature extraction, enabling the model to process both infrared and visible images. To further enrich semantic representation, we propose an Efficient Multi-scale Attention (EMA) mechanism that enhances feature learning across spatial scales. Additionally, we replace the conventional neck with a Gather-and-Distribute module to mitigate information loss during feature aggregation. Extensive experiments on the Drone Vehicle dataset demonstrate that DGE-YOLO achieves superior performance over state-of-the-art methods, validating its effectiveness in multi-modal UAV object detection tasks.",
      "authors": [
        "Kunwei Lv",
        "Ping Lan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T14:19:18+00:00",
          "link": "https://arxiv.org/abs/2506.23252v1",
          "size": "1936kb",
          "version": "v1"
        }
      ],
      "title": "DGE-YOLO: Dual-Branch Gathering and Attention for Accurate UAV Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23252",
        "HTML": "https://arxiv.org/html/2506.23252v1",
        "PDF": "https://arxiv.org/pdf/2506.23252"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23253",
      "abstract": "We examine \"vibe coding\": an emergent programming paradigm where developers primarily write code by interacting with code-generating large language models rather than writing code directly. We analysed a curated set of videos depicting extended vibe coding sessions with rich think-aloud reflections. Using framework analysis, we investigated programmers' goals, workflows, prompting techniques, debugging approaches, and challenges encountered. We find that vibe coding follows iterative goal satisfaction cycles where developers alternate between prompting AI, evaluating generated code through rapid scanning and application testing, and manual editing. Prompting strategies blend vague, high-level directives with detailed technical specifications. Debugging remains a hybrid process combining AI assistance with manual practices. Critically, vibe coding does not eliminate the need for programming expertise but rather redistributes it toward context management, rapid code evaluation, and decisions about when to transition between AI-driven and manual manipulation of code. Trust in AI tools during vibe coding is dynamic and contextual, developed through iterative verification rather than blanket acceptance. Vibe coding is an evolution of AI-assisted programming that represents an early manifestation of \"material disengagement\", where practitioners orchestrate code production and manipulation, mediated through AI, while maintaining selective and strategic oversight.",
      "authors": [
        "Advait Sarkar",
        "Ian Drosos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T14:19:29+00:00",
          "link": "https://arxiv.org/abs/2506.23253v1",
          "size": "43kb",
          "version": "v1"
        }
      ],
      "title": "Vibe coding: programming through conversation with artificial intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23253",
        "HTML": "https://arxiv.org/html/2506.23253v1",
        "PDF": "https://arxiv.org/pdf/2506.23253"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23254",
      "abstract": "Diffusion-model-based image super-resolution techniques often face a trade-off between realistic image generation and computational efficiency. This issue is exacerbated when inference times by decreasing sampling steps, resulting in less realistic and hazy images. To overcome this challenge, we introduce a novel diffusion model named PixelBoost that underscores the significance of embracing the stochastic nature of Brownian motion in advancing image super-resolution, resulting in a high degree of realism, particularly focusing on texture and edge definitions. By integrating controlled stochasticity into the training regimen, our proposed model avoids convergence to local optima, effectively capturing and reproducing the inherent uncertainty of image textures and patterns. Our proposed model demonstrates superior objective results in terms of learned perceptual image patch similarity (LPIPS), lightness order error (LOE), peak signal-to-noise ratio(PSNR), structural similarity index measure (SSIM), as well as visual quality. To determine the edge enhancement, we evaluated the gradient magnitude and pixel value, and our proposed model exhibited a better edge reconstruction capability. Additionally, our model demonstrates adaptive learning capabilities by effectively adjusting to Brownian noise patterns and introduces a sigmoidal noise sequencing method that simplifies training, resulting in faster inference speeds.",
      "authors": [
        "Aradhana Mishra and Bumshik Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Multimedia (cs.MM)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T14:22:38+00:00",
          "link": "https://arxiv.org/abs/2506.23254v1",
          "size": "18839kb",
          "version": "v1"
        }
      ],
      "title": "PixelBoost: Leveraging Brownian Motion for Realistic-Image Super-Resolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23254",
        "PDF": "https://arxiv.org/pdf/2506.23254"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23257",
      "abstract": "Large-scale simulations on supercomputers have become important tools for users. However, their scalability remains a problem due to the huge communication cost among parallel processes. Most of the existing communication latency analysis methods rely on the physical link layer information, which is only available to administrators. In this paper, a framework called PCLVis is proposed to help general users analyze process communication latency (PCL) events. Instead of the physical link layer information, the PCLVis uses the MPI process communication data for the analysis. First, a spatial PCL event locating method is developed. All processes with high correlation are classified into a single cluster by constructing a process-correlation tree. Second, the propagation path of PCL events is analyzed by constructing a communication-dependency-based directed acyclic graph (DAG), which can help users interactively explore a PCL event from the temporal evolution of a located PCL event cluster. In this graph, a sliding window algorithm is designed to generate the PCL events abstraction. Meanwhile, a new glyph called the communication state glyph (CS-Glyph) is designed for each process to show its communication states, including its in/out messages and load balance. Each leaf node can be further unfolded to view additional information. Third, a PCL event attribution strategy is formulated to help users optimize their simulations. The effectiveness of the PCLVis framework is demonstrated by analyzing the PCL events of several simulations running on the TH-1A supercomputer. By using the proposed framework, users can greatly improve the efficiency of their simulations.",
      "authors": [
        "Chongke Bi",
        "Xin Gao",
        "Baofeng Fu",
        "Yuheng Zhao",
        "Siming Chen",
        "Ying Zhao",
        "Yunhai Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T14:28:10+00:00",
          "link": "https://arxiv.org/abs/2506.23257v1",
          "size": "17806kb",
          "version": "v1"
        }
      ],
      "title": "PCLVis: Visual Analytics of Process Communication Latency in Large-Scale Simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23257",
        "HTML": "https://arxiv.org/html/2506.23257v1",
        "PDF": "https://arxiv.org/pdf/2506.23257"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23260",
      "abstract": "Autonomous AI agents powered by large language models (LLMs) with structured function-calling interfaces have dramatically expanded capabilities for real-time data retrieval, complex computation, and multi-step orchestration. Yet, the explosive proliferation of plugins, connectors, and inter-agent protocols has outpaced discovery mechanisms and security practices, resulting in brittle integrations vulnerable to diverse threats. In this survey, we introduce the first unified, end-to-end threat model for LLM-agent ecosystems, spanning host-to-tool and agent-to-agent communications, formalize adversary capabilities and attacker objectives, and catalog over thirty attack techniques. Specifically, we organized the threat model into four domains: Input Manipulation (e.g., prompt injections, long-context hijacks, multimodal adversarial inputs), Model Compromise (e.g., prompt- and parameter-level backdoors, composite and encrypted multi-backdoors, poisoning strategies), System and Privacy Attacks (e.g., speculative side-channels, membership inference, retrieval poisoning, social-engineering simulations), and Protocol Vulnerabilities (e.g., exploits in Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent Network Protocol (ANP), and Agent-to-Agent (A2A) protocol). For each category, we review representative scenarios, assess real-world feasibility, and evaluate existing defenses. Building on our threat taxonomy, we identify key open challenges and future research directions, such as securing MCP deployments through dynamic trust management and cryptographic provenance tracking; designing and hardening Agentic Web Interfaces; and achieving resilience in multi-agent and federated environments. Our work provides a comprehensive reference to guide the design of robust defense mechanisms and establish best practices for resilient LLM-agent workflows.",
      "authors": [
        "Mohamed Amine Ferrag",
        "Norbert Tihanyi",
        "Djallel Hamouda",
        "Leandros Maglaras",
        "Merouane Debbah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T14:32:32+00:00",
          "link": "https://arxiv.org/abs/2506.23260v1",
          "size": "8680kb",
          "version": "v1"
        }
      ],
      "title": "From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23260",
        "HTML": "https://arxiv.org/html/2506.23260v1",
        "PDF": "https://arxiv.org/pdf/2506.23260"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23263",
      "abstract": "Egocentricly comprehending the causes and effects of car accidents is crucial for the safety of self-driving cars, and synthesizing causal-entity reflected accident videos can facilitate the capability test to respond to unaffordable accidents in reality. However, incorporating causal relations as seen in real-world videos into synthetic videos remains challenging. This work argues that precisely identifying the accident participants and capturing their related behaviors are of critical importance. In this regard, we propose a novel diffusion model, Causal-VidSyn, for synthesizing egocentric traffic accident videos. To enable causal entity grounding in video diffusion, Causal-VidSyn leverages the cause descriptions and driver fixations to identify the accident participants and behaviors, facilitated by accident reason answering and gaze-conditioned selection modules. To support Causal-VidSyn, we further construct Drive-Gaze, the largest driver gaze dataset (with 1.54M frames of fixations) in driving accident scenarios. Extensive experiments show that Causal-VidSyn surpasses state-of-the-art video diffusion models in terms of frame quality and causal sensitivity in various tasks, including accident video editing, normal-to-accident video diffusion, and text-to-video generation.",
      "authors": [
        "Lei-lei Li",
        "Jianwu Fang",
        "Junbin Xiao",
        "Shanmin Pang",
        "Hongkai Yu",
        "Chen Lv",
        "Jianru Xue",
        "and Tat-Seng Chua"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T14:37:48+00:00",
          "link": "https://arxiv.org/abs/2506.23263v1",
          "size": "12699kb",
          "version": "v1"
        }
      ],
      "title": "Causal-Entity Reflected Egocentric Traffic Accident Video Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23263",
        "HTML": "https://arxiv.org/html/2506.23263v1",
        "PDF": "https://arxiv.org/pdf/2506.23263"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23266",
      "abstract": "Mixture of Experts (MoE) LLMs face significant obstacles due to their massive parameter scale, which imposes memory, storage, and deployment challenges. Although recent expert merging methods promise greater efficiency by consolidating multiple experts, they are fundamentally hindered by parameter conflicts arising from expert specialization. In this paper, we present Sub-MoE, a novel MoE compression framework via Subspace Expert Merging. Our key insight is to perform joint Singular Value Decomposition (SVD) on concatenated expert weights, reducing conflicting parameters by extracting shared $U$-matrices while enabling effective merging of the expert-specific $V$ components. Specifically, Sub-MoE consists of two innovative phases: (1) Adaptive Expert Clustering, which groups functionally coherent experts via K-means clustering based on cosine similarity of expert outputs; and (2) Subspace Expert Merging, which first enforces Experts Union Decomposition to derive the shared $U$-matrix across experts in the same group, then pursues frequency-based merging for individual $V$-matrices, and finalizes expert reconstruction using the merged $V$-matrix. In this way, we align and fuse experts in a shared subspace, and can be extended with intra-expert compression for further inference optimization. Extensive experiments on Mixtral, DeepSeek, and Qwen-1.5|3 MoE LLMs demonstrate that our Sub-MoE significantly outperforms existing expert pruning and merging methods. Notably, our Sub-MoE maintains 96\\%|86\\% of original performance with 25\\%|50\\% expert reduction on Mixtral-8x7B in zero-shot benchmarks. Code will be released at https://github.com/lliai/MoERazor.",
      "authors": [
        "Lujun Li",
        "Zhu Qiyuan",
        "Jiacheng Wang",
        "Wei Li",
        "Hao Gu",
        "Sirui Han",
        "Yike Guo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T14:43:50+00:00",
          "link": "https://arxiv.org/abs/2506.23266v1",
          "size": "2486kb",
          "version": "v1"
        }
      ],
      "title": "Sub-MoE: Efficient Mixture-of-Expert LLMs Compression via Subspace Expert Merging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23266",
        "HTML": "https://arxiv.org/html/2506.23266v1",
        "PDF": "https://arxiv.org/pdf/2506.23266"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23270",
      "abstract": "Multimodal large language models (MLLMs) are broadly empowering various fields. Despite their advancements, the explainability of MLLMs remains less explored, hindering deeper understanding, model credibility, and effective visualization. Unlike conventional vision models (e.g., CNNs, ViTs, CLIP) that produce a single output, MLLMs generate sequences of tokens progressively, where each generated token depends on the previous context. Therefore, earlier context tokens can introduce redundant activations that interfere with the explanation of later tokens beyond their original information. Existing studies often overlook this issue, but our observations reveal that these redundant correlations can significantly hurt the reliability of explanations. To address this, we propose an estimated causal inference method to mitigate the interference of context to achieve high-quality MLLM explanation, with a novel rank Gaussian filter to further reduce activation noises. We term this method Token Activation Map (TAM) to highlight the consideration of interactions between tokens. TAM also indicates that it excels at explaining multiple tokens of MLLM, which is different from the Class Activation Map (CAM) for a single prediction. Our TAM method significantly outperforms existing SoTA methods, showcasing high-quality visualization results that can be utilized for various scenarios, such as object localization, failure case analysis, video visualization, MLLMs visual comparison, and model understanding (e.g., color, shape, action, location, visual reasoning, multi-turn conversation, etc). The code is available atgithub.com/xmed-lab/TAM.",
      "authors": [
        "Yi Li",
        "Hualiang Wang",
        "Xinpeng Ding",
        "Haonan Wang",
        "Xiaomeng Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T14:50:45+00:00",
          "link": "https://arxiv.org/abs/2506.23270v1",
          "size": "22545kb",
          "version": "v1"
        }
      ],
      "title": "Token Activation Map to Visually Explain Multimodal LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23270",
        "PDF": "https://arxiv.org/pdf/2506.23270"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23271",
      "abstract": "We present \\textbf{Met}a-\\textbf{T}oken \\textbf{Le}arning (Mettle), a simple and memory-efficient method for adapting large-scale pretrained transformer models to downstream audio-visual tasks. Instead of sequentially modifying the output feature distribution of the transformer backbone, Mettle utilizes a lightweight \\textit{Layer-Centric Distillation (LCD)} module to distill in parallel the intact audio or visual features embedded by each transformer layer into compact meta-tokens. This distillation process considers both pretrained knowledge preservation and task-specific adaptation. The obtained meta-tokens can be directly applied to classification tasks, such as audio-visual event localization and audio-visual video parsing. To further support fine-grained segmentation tasks, such as audio-visual segmentation, we introduce a \\textit{Meta-Token Injection (MTI)} module, which utilizes the audio and visual meta-tokens distilled from the top transformer layer to guide feature adaptation in earlier layers. Extensive experiments on multiple audiovisual benchmarks demonstrate that our method significantly reduces memory usage and training time while maintaining parameter efficiency and competitive accuracy.",
      "authors": [
        "Jinxing Zhou",
        "Zhihui Li",
        "Yongqiang Yu",
        "Yanghao Zhou",
        "Ruohao Guo",
        "Guangyao Li",
        "Yuxin Mao",
        "Mingfei Han",
        "Xiaojun Chang",
        "Meng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T14:52:01+00:00",
          "link": "https://arxiv.org/abs/2506.23271v1",
          "size": "5836kb",
          "version": "v1"
        }
      ],
      "title": "Mettle: Meta-Token Learning for Memory-Efficient Audio-Visual Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23271",
        "HTML": "https://arxiv.org/html/2506.23271v1",
        "PDF": "https://arxiv.org/pdf/2506.23271"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23273",
      "abstract": "Despite the advancements of large language models, text2sql still faces many challenges, particularly with complex and domain-specific queries. In finance, database designs and financial reporting layouts vary widely between financial entities and countries, making text2sql even more challenging. We present FinStat2SQL, a lightweight text2sql pipeline enabling natural language queries over financial statements. Tailored to local standards like VAS, it combines large and small language models in a multi-agent setup for entity extraction, SQL generation, and self-correction. We build a domain-specific database and evaluate models on a synthetic QA dataset. A fine-tuned 7B model achieves 61.33\\% accuracy with sub-4-second response times on consumer hardware, outperforming GPT-4o-mini. FinStat2SQL offers a scalable, cost-efficient solution for financial analysis, making AI-powered querying accessible to Vietnamese enterprises.",
      "authors": [
        "Quang Hung Nguyen",
        "Phuong Anh Trinh",
        "Phan Quoc Hung Mai and Tuan Phong Trinh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T14:55:21+00:00",
          "link": "https://arxiv.org/abs/2506.23273v1",
          "size": "247kb",
          "version": "v1"
        }
      ],
      "title": "FinStat2SQL: A Text2SQL Pipeline for Financial Statement Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23273",
        "HTML": "https://arxiv.org/html/2506.23273v1",
        "PDF": "https://arxiv.org/pdf/2506.23273"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23274",
      "abstract": "Reasoning models that produce long, hidden chains of thought have emerged as powerful tools for complex, reasoning-intensive tasks\\citep{deepseekai2025deepseekr1incentivizingreasoningcapability, openai2024openaio1card}. However, this paradigm introduces a new user experience challenge: users have little insight into how much time the model will spend reasoning before returning an answer. This unpredictability, can lead to user frustration and is likely to compound as LLMs can produce increasingly long tasks asynchronously \\citep{kwa2025measuringaiabilitycomplete}. In this paper, we introduce and evaluate methods for both online and offline prediction of model \"thinking time,\" aiming to develop a practical \"progress bar for reasoning.\" We discuss the implications for user interaction and future research directions.",
      "authors": [
        "Hans Peter Lynsg{\\o}e Raaschou-jensen and Constanza Fierro and Anders S{\\o}gaard"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:01:01+00:00",
          "link": "https://arxiv.org/abs/2506.23274v1",
          "size": "1210kb",
          "version": "v1"
        }
      ],
      "title": "Predicting thinking time in Reasoning models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23274",
        "HTML": "https://arxiv.org/html/2506.23274v1",
        "PDF": "https://arxiv.org/pdf/2506.23274"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23275",
      "abstract": "Despite remarkable progress in Text-to-Image models, many real-world applications require generating coherent image sets with diverse consistency requirements. Existing consistent methods often focus on a specific domain with specific aspects of consistency, which significantly constrains their generalizability to broader applications. In this paper, we propose a more challenging problem, Text-to-ImageSet (T2IS) generation, which aims to generate sets of images that meet various consistency requirements based on user instructions. To systematically study this problem, we first introduce $\\textbf{T2IS-Bench}$ with 596 diverse instructions across 26 subcategories, providing comprehensive coverage for T2IS generation. Building on this, we propose $\\textbf{T2IS-Eval}$, an evaluation framework that transforms user instructions into multifaceted assessment criteria and employs effective evaluators to adaptively assess consistency fulfillment between criteria and generated sets. Subsequently, we propose $\\textbf{AutoT2IS}$, a training-free framework that maximally leverages pretrained Diffusion Transformers' in-context capabilities to harmonize visual elements to satisfy both image-level prompt alignment and set-level visual consistency. Extensive experiments on T2IS-Bench reveal that diverse consistency challenges all existing methods, while our AutoT2IS significantly outperforms current generalized and even specialized approaches. Our method also demonstrates the ability to enable numerous underexplored real-world applications, confirming its substantial practical value. Visit our project in https://chengyou-jia.github.io/T2IS-Home.",
      "authors": [
        "Chengyou Jia",
        "Xin Shen",
        "Zhuohang Dang",
        "Zhuohang Dang",
        "Changliang Xia",
        "Weijia Wu",
        "Xinyu Zhang",
        "Hangwei Qian",
        "Ivor W.Tsang",
        "Minnan Luo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:01:16+00:00",
          "link": "https://arxiv.org/abs/2506.23275v1",
          "size": "24087kb",
          "version": "v1"
        }
      ],
      "title": "Why Settle for One? Text-to-ImageSet Generation and Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23275",
        "PDF": "https://arxiv.org/pdf/2506.23275"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23276",
      "abstract": "As large language models (LLMs) are increasingly deployed as autonomous agents, understanding their cooperation and social mechanisms is becoming increasingly important. In particular, how LLMs balance self-interest and collective well-being is a critical challenge for ensuring alignment, robustness, and safe deployment. In this paper, we examine the challenge of costly sanctioning in multi-agent LLM systems, where an agent must decide whether to invest its own resources to incentivize cooperation or penalize defection. To study this, we adapt a public goods game with institutional choice from behavioral economics, allowing us to observe how different LLMs navigate social dilemmas over repeated interactions. Our analysis reveals four distinct behavioral patterns among models: some consistently establish and sustain high levels of cooperation, others fluctuate between engagement and disengagement, some gradually decline in cooperative behavior over time, and others rigidly follow fixed strategies regardless of outcomes. Surprisingly, we find that reasoning LLMs, such as the o1 series, struggle significantly with cooperation, whereas some traditional LLMs consistently achieve high levels of cooperation. These findings suggest that the current approach to improving LLMs, which focuses on enhancing their reasoning capabilities, does not necessarily lead to cooperation, providing valuable insights for deploying LLM agents in environments that require sustained collaboration. Our code is available at https://github.com/davidguzmanp/SanctSim",
      "authors": [
        "David Guzman Piedrahita",
        "Yongjin Yang",
        "Mrinmaya Sachan",
        "Giorgia Ramponi",
        "Bernhard Sch\\\"olkopf",
        "Zhijing Jin"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:02:47+00:00",
          "link": "https://arxiv.org/abs/2506.23276v1",
          "size": "200kb",
          "version": "v1"
        }
      ],
      "title": "Corrupted by Reasoning: Reasoning Language Models Become Free-Riders in Public Goods Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23276",
        "PDF": "https://arxiv.org/pdf/2506.23276"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23280",
      "abstract": "Bayesian decision theory advocates the Bayes classifier as the optimal approach for minimizing the risk in machine learning problems. Current deep learning algorithms usually solve for the optimal classifier by \\emph{implicitly} estimating the posterior probabilities, \\emph{e.g.}, by minimizing the Softmax cross-entropy loss. This simple methodology has been proven effective for meticulously balanced academic benchmark datasets. However, it is not applicable to the long-tailed data distributions in the real world, where it leads to the gradient imbalance issue and fails to ensure the Bayes optimal decision rule. To address these challenges, this paper presents a novel approach (BAPE) that provides a more precise theoretical estimation of the data distributions by \\emph{explicitly} modeling the parameters of the posterior probabilities and solving them with point estimation. Consequently, our method directly learns the Bayes classifier without gradient descent based on Bayes' theorem, simultaneously alleviating the gradient imbalance and ensuring the Bayes optimal decision rule. Furthermore, we propose a straightforward yet effective \\emph{distribution adjustment} technique. This method enables the Bayes classifier trained from the long-tailed training set to effectively adapt to the test data distribution with an arbitrary imbalance factor, thereby enhancing performance without incurring additional computational costs. In addition, we demonstrate the gains of our method are orthogonal to existing learning approaches for long-tailed scenarios, as they are mostly designed under the principle of \\emph{implicitly} estimating the posterior probabilities. Extensive empirical evaluations on CIFAR-10-LT, CIFAR-100-LT, ImageNet-LT, and iNaturalist demonstrate that our method significantly improves the generalization performance of popular deep networks, despite its simplicity.",
      "authors": [
        "Chaoqun Du",
        "Yulin Wang",
        "Shiji Song",
        "Gao Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:12:50+00:00",
          "link": "https://arxiv.org/abs/2506.23280v1",
          "size": "254kb",
          "version": "v1"
        }
      ],
      "title": "BAPE: Learning an Explicit Bayes Classifier for Long-tailed Visual Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23280",
        "HTML": "https://arxiv.org/html/2506.23280v1",
        "PDF": "https://arxiv.org/pdf/2506.23280"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23281",
      "abstract": "Random testing has proven to be an effective technique for compiler validation. However, the debugging of bugs identified through random testing presents a significant challenge due to the frequent occurrence of duplicate test programs that expose identical compiler bugs. The process to identify duplicates is a practical research problem known as bug deduplication. Prior methodologies for compiler bug deduplication primarily rely on program analysis to extract bug-related features for duplicate identification, which can result in substantial computational overhead and limited generalizability. This paper investigates the feasibility of employing bisection, a standard debugging procedure largely overlooked in prior research on compiler bug deduplication, for this purpose. Our study demonstrates that the utilization of bisection to locate failure-inducing commits provides a valuable criterion for deduplication, albeit one that requires supplementary techniques for more accurate identification. Building on these results, we introduce BugLens, a novel deduplication method that primarily uses bisection, enhanced by the identification of bug-triggering optimizations to minimize false negatives. Empirical evaluations conducted on four real-world datasets demonstrate that BugLens significantly outperforms the state-of-the-art analysis-based methodologies Tamer and D3 by saving an average of 26.98% and 9.64% human effort to identify the same number of distinct bugs. Given the inherent simplicity and generalizability of bisection, it presents a highly practical solution for compiler bug deduplication in real-world applications.",
      "authors": [
        "Xintong Zhou",
        "Zhenyang Xu",
        "Chengnian Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:12:57+00:00",
          "link": "https://arxiv.org/abs/2506.23281v1",
          "size": "415kb",
          "version": "v1"
        }
      ],
      "title": "On the Feasibility of Deduplicating Compiler Bugs with Bisection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23281",
        "HTML": "https://arxiv.org/html/2506.23281v1",
        "PDF": "https://arxiv.org/pdf/2506.23281"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23282",
      "abstract": "Video anomaly detection (VAD) is an important computer vision problem. Thanks to the mode coverage capabilities of generative models, the likelihood-based paradigm is catching growing interest, as it can model normal distribution and detect out-of-distribution anomalies. However, these likelihood-based methods are blind to the anomalies located in local modes near the learned distribution. To handle these ``unseen\" anomalies, we dive into three gaps uniquely existing in VAD regarding scene, motion and appearance. Specifically, we first build a noise-conditioned score transformer for denoising score matching. Then, we introduce a scene-dependent and motion-aware score function by embedding the scene condition of input sequences into our model and assigning motion weights based on the difference between key frames of input sequences. Next, to solve the problem of blindness in principle, we integrate unaffected visual information via a novel autoregressive denoising score matching mechanism for inference. Through autoregressively injecting intensifying Gaussian noise into the denoised data and estimating the corresponding score function, we compare the denoised data with the original data to get a difference and aggregate it with the score function for an enhanced appearance perception and accumulate the abnormal context. With all three gaps considered, we can compute a more comprehensive anomaly indicator. Experiments on three popular VAD benchmarks demonstrate the state-of-the-art performance of our method.",
      "authors": [
        "Hanwen Zhang",
        "Congqi Cao",
        "Qinyi Lv",
        "Lingtong Min",
        "Yanning Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:14:32+00:00",
          "link": "https://arxiv.org/abs/2506.23282v1",
          "size": "4748kb",
          "version": "v1"
        }
      ],
      "title": "Autoregressive Denoising Score Matching is a Good Video Anomaly Detector",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23282",
        "HTML": "https://arxiv.org/html/2506.23282v1",
        "PDF": "https://arxiv.org/pdf/2506.23282"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23283",
      "abstract": "Video understanding is a complex challenge that requires effective modeling of spatial-temporal dynamics. With the success of image foundation models (IFMs) in image understanding, recent approaches have explored parameter-efficient fine-tuning (PEFT) to adapt IFMs for video. However, most of these methods tend to process spatial and temporal information separately, which may fail to capture the full intricacy of video dynamics. In this paper, we propose MoMa, an efficient adapter framework that achieves full spatial-temporal modeling by integrating Mamba's selective state space modeling into IFMs. We propose a novel SeqMod operation to inject spatial-temporal information into pre-trained IFMs, without disrupting their original features. By incorporating SeqMod into a Divide-and-Modulate architecture, MoMa enhances video understanding while maintaining computational efficiency. Extensive experiments on multiple video benchmarks demonstrate the effectiveness of MoMa, achieving superior performance with reduced computational cost.",
      "authors": [
        "Yuhuan Yang",
        "Chaofan Ma",
        "Zhenjie Mao",
        "Jiangchao Yao",
        "Ya Zhang",
        "Yanfeng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:14:55+00:00",
          "link": "https://arxiv.org/abs/2506.23283v1",
          "size": "198kb",
          "version": "v1"
        }
      ],
      "title": "MoMa: Modulating Mamba for Adapting Image Foundation Models to Video Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23283",
        "HTML": "https://arxiv.org/html/2506.23283v1",
        "PDF": "https://arxiv.org/pdf/2506.23283"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23285",
      "abstract": "Deep Neural Networks (DNNs) have significantly advanced the field of computer vision. To improve DNN training process, knowledge distillation methods demonstrate their effectiveness in accelerating network training by introducing a fixed learning direction from the teacher network to student networks. In this context, several distillation-based optimization strategies are proposed, e.g., deep mutual learning and self-distillation, as an attempt to achieve generic training performance enhancement through the cooperative training of multiple networks. However, such strategies achieve limited improvements due to the poor understanding of the impact of learning directions among networks across different iterations. In this paper, we propose a novel competitive distillation strategy that allows each network in a group to potentially act as a teacher based on its performance, enhancing the overall learning performance. Competitive distillation organizes a group of networks to perform a shared task and engage in competition, where competitive optimization is proposed to improve the parameter updating process. We further introduce stochastic perturbation in competitive distillation, aiming to motivate networks to induce mutations to achieve better visual representations and global optimum. The experimental results show that competitive distillation achieves promising performance in diverse tasks and datasets.",
      "authors": [
        "Daqian Shi",
        "Xiaolei Diao",
        "Xu Chen",
        "C\\'edric M. John"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:15:33+00:00",
          "link": "https://arxiv.org/abs/2506.23285v1",
          "size": "2309kb",
          "version": "v1"
        }
      ],
      "title": "Competitive Distillation: A Simple Learning Strategy for Improving Visual Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23285",
        "HTML": "https://arxiv.org/html/2506.23285v1",
        "PDF": "https://arxiv.org/pdf/2506.23285"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23286",
      "abstract": "Developing a better understanding of surprising or counterintuitive phenomena has constituted a significant portion of deep learning research in recent years. These include double descent, grokking, and the lottery ticket hypothesis -- among many others. Works in this area often develop ad hoc hypotheses attempting to explain these observed phenomena on an isolated, case-by-case basis. This position paper asserts that, in many prominent cases, there is little evidence to suggest that these phenomena appear in real-world applications and these efforts may be inefficient in driving progress in the broader field. Consequently, we argue against viewing them as isolated puzzles that require bespoke resolutions or explanations. However, despite this, we suggest that deep learning phenomena do still offer research value by providing unique settings in which we can refine our broad explanatory theories of more general deep learning principles. This position is reinforced by analyzing the research outcomes of several prominent examples of these phenomena from the recent literature. We revisit the current norms in the research community in approaching these problems and propose practical recommendations for future research, aiming to ensure that progress on deep learning phenomena is well aligned with the ultimate pragmatic goal of progress in the broader field of deep learning.",
      "authors": [
        "Alan Jeffares",
        "Mihaela van der Schaar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:18:56+00:00",
          "link": "https://arxiv.org/abs/2506.23286v1",
          "size": "104kb",
          "version": "v1"
        }
      ],
      "title": "Not All Explanations for Deep Learning Phenomena Are Equally Valuable",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23286",
        "HTML": "https://arxiv.org/html/2506.23286v1",
        "PDF": "https://arxiv.org/pdf/2506.23286"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23287",
      "abstract": "In single-cell research, tracing and analyzing high-throughput single-cell differentiation trajectories is crucial for understanding complex biological processes. Key to this is the modeling and generation of hierarchical data that represents the intrinsic structure within datasets. Traditional methods face limitations in terms of computational cost, performance, generative capacity, and stability. Recent VAEs based approaches have made strides in addressing these challenges but still require specialized network modules for each tree branch, limiting their stability and ability to capture deep hierarchical relationships. To overcome these challenges, we introduce diffusion-based approach called HDTree. HDTree captures tree relationships within a hierarchical latent space using a unified hierarchical codebook and quantized diffusion processes to model tree node transitions. This method improves stability by eliminating branch-specific modules and enhancing generative capacity through gradual hierarchical changes simulated by the diffusion process. HDTree's effectiveness is demonstrated through comparisons on both general-purpose and single-cell datasets, where it outperforms existing methods in terms of accuracy and performance. These contributions provide a new tool for hierarchical lineage analysis, enabling more accurate and efficient modeling of cellular differentiation paths and offering insights for downstream biological tasks. The code of HDTree is available at anonymous link https://anonymous.4open.science/r/code_HDTree_review-A8DB.",
      "authors": [
        "Zelin Zang",
        "WenZhe Li",
        "Fei Chen",
        "Yongjie Xu",
        "Chang Yu",
        "Zhen Lei",
        "Stan Z. Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:19:13+00:00",
          "link": "https://arxiv.org/abs/2506.23287v1",
          "size": "14896kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Quantized Diffusion Based Tree Generation Method for Hierarchical Representation and Lineage Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23287",
        "HTML": "https://arxiv.org/html/2506.23287v1",
        "PDF": "https://arxiv.org/pdf/2506.23287"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23288",
      "abstract": "The absence of standardized spelling conventions and the organic evolution of human language present an inherent linguistic challenge within historical documents, a longstanding concern for scholars in the humanities. Addressing this issue, spelling normalization endeavors to align a document's orthography with contemporary standards. In this study, we propose two new approaches based on large language models: one of which has been trained without a supervised training, and a second one which has been trained for machine translation. Our evaluation spans multiple datasets encompassing diverse languages and historical periods, leading us to the conclusion that while both of them yielded encouraging results, statistical machine translation still seems to be the most suitable technology for this task.",
      "authors": [
        "Miguel Domingo and Francisco Casacuberta"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:25:09+00:00",
          "link": "https://arxiv.org/abs/2506.23288v1",
          "size": "15kb",
          "version": "v1"
        }
      ],
      "title": "Two Spelling Normalization Approaches Based on Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23288",
        "HTML": "https://arxiv.org/html/2506.23288v1",
        "PDF": "https://arxiv.org/pdf/2506.23288"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23292",
      "abstract": "Recent advances in AIGC have exacerbated the misuse of malicious deepfake content, making the development of reliable deepfake detection methods an essential means to address this challenge. Although existing deepfake detection models demonstrate outstanding performance in detection metrics, most methods only provide simple binary classification results, lacking interpretability. In critical domains such as law, interpretability is crucial for enhancing the credibility and authority of decisions. Recent studies attempt to improve the interpretability of classification results by providing spatial manipulation masks or temporal forgery segments. However, the practical effectiveness of these methods remains suboptimal due to limitations of the forgery data. Most current deepfake datasets predominantly offer binary labels, only a few datasets with localization annotations. However, they suffer from restricted forgery scenarios, limited diversity in deepfake types, and insufficient data scale, making them inadequate for complex real-world scenarios. To address this predicament, we construct a novel large-scale deepfake detection and localization ($\\textbf{DDL}$) dataset containing over $\\textbf{1.8M}$ forged samples and encompassing up to $\\textbf{75}$ distinct deepfake methods. The DDL design incorporates four key innovations: (1) $\\textbf{Diverse Forgery Scenarios}$, (2) $\\textbf{Comprehensive Deepfake Methods}$, (3) $\\textbf{Varied Manipulation Modes}$, and (4) $\\textbf{Fine-grained Forgery Annotations}$. Through these improvements, our DDL not only provides a more challenging benchmark for complex real-world forgeries, but also offers crucial support for building next-generation deepfake detection, localization, and interpretability methods. The DDL dataset project page is on https://deepfake-workshop-ijcai2025.github.io/main/index.html.",
      "authors": [
        "Changtao Miao",
        "Yi Zhang",
        "Weize Gao",
        "Man Luo",
        "Weiwei Feng",
        "Zhiya Tan",
        "Jianshu Li",
        "Ajian Liu",
        "Yunfeng Diao",
        "Qi Chu",
        "Tao Gong",
        "Zhe Li",
        "Weibin Yao",
        "and Joey Tianyi Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:29:03+00:00",
          "link": "https://arxiv.org/abs/2506.23292v1",
          "size": "2964kb",
          "version": "v1"
        }
      ],
      "title": "DDL: A Dataset for Interpretable Deepfake Detection and Localization in Real-World Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23292",
        "HTML": "https://arxiv.org/html/2506.23292v1",
        "PDF": "https://arxiv.org/pdf/2506.23292"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23293",
      "abstract": "We present a neuro-symbolic framework for generative language modeling based on local, event-driven emergent learning. At its core is a hierarchical Hopfield memory chain acting as a compositional short-term memory and dynamic tokenizer (retokenizer). Rather than relying on predefined tokens or supervision, the model builds structure from scratch, learning symbol sequences as multi-scale representations. It constructs projection tensors that bind co-occurring features into hierarchical tokens, introducing redundancy (i.e an emergent gauge structure) and enabling compression of local activations into long-range dependencies. Curiously, we find that the retokenizer can filter natural language patterns from noise, generating synthetic languages with coherent internal morphology -- quantifiably the same as human language. Language is learned in a local (Hebbian) fashion, where model constraints dictate allowed emergent structure, and new information is retained in alignment with this structure. The absence of a global objective enables a form of plasticity not found in conventional language models, allowing the system to generalize beyond its initial inference class -- even without explicit data. We demonstrate that briefly activating a new neuron during inference binds distributed multi-scale token features into a symbolic embedding. These emergent embedding neurons act as long-term memory and support a key-value mechanism for compositional inference and generalization. This architecture provides a methodological foundation for studying how symbolic structure can emerge from local neural learning. It offers a new pathway for building scalable, interpretable neuro-symbolic systems -- where tokens, grammar, and reasoning arise as compressed memory traces within a Hopfield hierarchy. This approach advances the development of neuromorphic architectures for generative language models.",
      "authors": [
        "P. Myles Eugenio"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:29:13+00:00",
          "link": "https://arxiv.org/abs/2506.23293v1",
          "size": "2965kb",
          "version": "v1"
        }
      ],
      "title": "Objective-Free Local Learning and Emergent Language Structure in Thinking Machines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23293",
        "HTML": "https://arxiv.org/html/2506.23293v1",
        "PDF": "https://arxiv.org/pdf/2506.23293"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23294",
      "abstract": "Digital signatures are crucial for securing Central Bank Digital Currencies (CBDCs) transactions. Like most forms of digital currencies, CBDC solutions rely on signatures for transaction authenticity and integrity, leading to major issues in the case of private key compromise. Our work explores threshold signature schemes (TSSs) in the context of CBDCs. TSSs allow distributed key management and signing, reducing the risk of a compromised key. We analyze CBDC-specific requirements, considering the applicability of TSSs, and use Filia CBDC solution as a base for a detailed evaluation. As most of the current solutions rely on ECDSA for compatibility, we focus on ECDSA-based TSSs and their supporting libraries. Our performance evaluation measured the computational and communication complexity across key processes, as well as the throughput and latency of end-to-end transactions. The results confirm that TSS can enhance the security of CBDC implementations while maintaining acceptable performance for real-world deployments.",
      "authors": [
        "Mostafa Abdelrahman",
        "Filip Rezabek",
        "Lars Hupel",
        "Kilian Glas",
        "Georg Carle"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:31:11+00:00",
          "link": "https://arxiv.org/abs/2506.23294v1",
          "size": "906kb",
          "version": "v1"
        }
      ],
      "title": "Threshold Signatures for Central Bank Digital Currencies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23294",
        "HTML": "https://arxiv.org/html/2506.23294v1",
        "PDF": "https://arxiv.org/pdf/2506.23294"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23295",
      "abstract": "Virtual try-on (VTON) aims to synthesize realistic images of a person wearing a target garment, with broad applications in e-commerce and digital fashion. While recent advances in latent diffusion models have substantially improved visual quality, existing approaches still struggle with preserving fine-grained garment details, achieving precise garment-body alignment, maintaining inference efficiency, and generalizing to diverse poses and clothing styles. To address these challenges, we propose DiffFit, a novel two-stage latent diffusion framework for high-fidelity virtual try-on. DiffFit adopts a progressive generation strategy: the first stage performs geometry-aware garment warping, aligning the garment with the target body through fine-grained deformation and pose adaptation. The second stage refines texture fidelity via a cross-modal conditional diffusion model that integrates the warped garment, the original garment appearance, and the target person image for high-quality rendering. By decoupling geometric alignment and appearance refinement, DiffFit effectively reduces task complexity and enhances both generation stability and visual realism. It excels in preserving garment-specific attributes such as textures, wrinkles, and lighting, while ensuring accurate alignment with the human body. Extensive experiments on large-scale VTON benchmarks demonstrate that DiffFit achieves superior performance over existing state-of-the-art methods in both quantitative metrics and perceptual evaluations.",
      "authors": [
        "Xiang Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:31:42+00:00",
          "link": "https://arxiv.org/abs/2506.23295v1",
          "size": "3694kb",
          "version": "v1"
        }
      ],
      "title": "DiffFit: Disentangled Garment Warping and Texture Refinement for Virtual Try-On",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23295",
        "HTML": "https://arxiv.org/html/2506.23295v1",
        "PDF": "https://arxiv.org/pdf/2506.23295"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23296",
      "abstract": "Embedded into information systems, artificial intelligence (AI) faces security threats that exploit AI-specific vulnerabilities. This paper provides an accessible overview of adversarial attacks unique to predictive and generative AI systems. We identify eleven major attack types and explicitly link attack techniques to their impacts -- including information leakage, system compromise, and resource exhaustion -- mapped to the confidentiality, integrity, and availability (CIA) security triad. We aim to equip researchers, developers, security practitioners, and policymakers, even those without specialized AI security expertise, with foundational knowledge to recognize AI-specific risks and implement effective defenses, thereby enhancing the overall security posture of AI systems.",
      "authors": [
        "Naoto Kiribuchi",
        "Kengo Zenitani",
        "Takayuki Semitsu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:32:03+00:00",
          "link": "https://arxiv.org/abs/2506.23296v1",
          "size": "1443kb",
          "version": "v1"
        }
      ],
      "title": "Securing AI Systems: A Guide to Known Attacks and Impacts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23296",
        "HTML": "https://arxiv.org/html/2506.23296v1",
        "PDF": "https://arxiv.org/pdf/2506.23296"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23301",
      "abstract": "In this paper, we propose a novel downlink multiple access system with a multi-antenna transmitter and two single-antenna receivers, inspired by the underlying principles of hierarchical quadrature amplitude modulation (H-QAM) based multiple access (QAMA) and space-division multiple access (SDMA). In the proposed scheme, coded bits from two users are split and assigned to one shared symbol and two private symbols carried by different beams. Based on joint symbol mapping of H-QAM constellations and phase-aligned precoding at the transmitter, each receiver observes a different H-QAM constellation with Gray mapping, a unique parallax feature not shared by existing schemes. In addition to avoiding successive interference cancellation (SIC), each user independently demodulates its own bits on separate I and Q branches with calculations based on closed-form expressions. Hence the receiver complexity is on par with that of orthogonal multiple access (OMA), which is much lower than that in other competing alternatives such as non-orthogonal multiple access (NOMA) and rate-splitting multiple access (RSMA). We carry out system optimization and determine the achievable rate region. Numerical results show that the proposed system has a larger rate region relative to other benchmark schemes with receivers not using SIC, and even achieves a comparable rate region to those benchmark schemes with SIC receivers.",
      "authors": [
        "Jie Huang",
        "Ming Zhao",
        "Shengli Zhou",
        "Ling Qiu and Jinkang Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:41:03+00:00",
          "link": "https://arxiv.org/abs/2506.23301v1",
          "size": "1601kb",
          "version": "v1"
        }
      ],
      "title": "Parallax QAMA: Novel Downlink Multiple Access for MISO Systems with Simple Receivers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23301",
        "HTML": "https://arxiv.org/html/2506.23301v1",
        "PDF": "https://arxiv.org/pdf/2506.23301"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23302",
      "abstract": "This paper presents the development of a novel life-extending control scheme for critical helicopter components subjected to significant fatigue loading. The primary objective is to synthesize a more efficient and less conservative life-extending control scheme than those currently available in the literature. The proposed Load Limiting Control (LLC) scheme is a viable solution that addresses several issues that current life-extending control schemes suffer from, such as the neglect of fatigue damage induced by the harmonic component of loads and the inability to distinguish between aggressive and non-aggressive maneuvers. The proposed LLC scheme treats desired harmonic load limits as limit boundaries and recasts the problem of load limiting as a vehicle limit by computing a Control Margin (CM) using a limit detection and avoidance module. The computed CM is used as a cue to the pilot. The limit detection and avoidance module comprises an optimization algorithm, a model predictive controller, and a computationally simple on-board dynamical model. Simulations were conducted to demonstrate the effectiveness of the LLC scheme in limiting harmonic pitch link loads during flight. One significant outcome is that, with sufficient training, the pilot can skillfully track the cue within 0.5 seconds of initiating the tracking task.",
      "authors": [
        "Chams Eddine Mballo",
        "Robert Walters",
        "Jonnalagadda V.R. Prasad"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:45:06+00:00",
          "link": "https://arxiv.org/abs/2506.23302v1",
          "size": "3934kb",
          "version": "v1"
        }
      ],
      "title": "Load Limiting Control for Component Life Extension",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23302",
        "HTML": "https://arxiv.org/html/2506.23302v1",
        "PDF": "https://arxiv.org/pdf/2506.23302"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23304",
      "abstract": "In contrast to grid-following inverters, Virtual Synchronous Generators (VSGs) perform well under weak grid conditions but may become unstable when the grid is strong. Grid strength depends on grid impedance, which unfortunately varies over time. In this paper, we propose a novel adaptive gain-scheduling control scheme for VSGs. First, an Artificial Neural Network (ANN) estimates the fundamental-frequency grid impedance; then these estimates are fed into an adaptive gain-scheduling function to recalculate controller parameters under varying grid conditions. The proposed method is validated in Simulink and compared with a conventional VSG employing fixed controller gains. The results demonstrate that settling times and overshoot percentages remain consistent across different grid conditions. Additionally, previously unseen grid impedance values are estimated with high accuracy and minimal time delay, making the approach well suited for real-time gain-scheduling control.",
      "authors": [
        "Quang-Manh Hoang",
        "Van Nam Nguyen",
        "Taehyung Kim",
        "Guilherme Vieira Hollweg",
        "Wencong Su",
        "Van-Hai Bui"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:51:30+00:00",
          "link": "https://arxiv.org/abs/2506.23304v1",
          "size": "1608kb",
          "version": "v1"
        }
      ],
      "title": "ANN-Based Grid Impedance Estimation for Adaptive Gain Scheduling in VSG Under Dynamic Grid Conditions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23304",
        "HTML": "https://arxiv.org/html/2506.23304v1",
        "PDF": "https://arxiv.org/pdf/2506.23304"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23306",
      "abstract": "Traditional agent-based urban mobility simulations rely on rigid rule-based systems that fail to capture the complexity, adaptability, and behavioral diversity characteristic of human travel decision-making. Recent advances in large language models and AI agent technology offer opportunities to create agents with reasoning capabilities, persistent memory, and adaptive learning mechanisms. We propose GATSim (Generative-Agent Transport Simulation), a novel framework that leverages these advances to create generative agents with rich behavioral characteristics for urban mobility simulation. Unlike conventional approaches, GATSim agents possess diverse socioeconomic attributes, individual lifestyles, and evolving preferences that shape their mobility decisions through psychologically-informed memory systems, tool usage capabilities, and lifelong learning mechanisms. The main contributions of this study include: (1) a comprehensive architecture combining an urban mobility foundation model with agent cognitive systems and transport simulation environment, (2) a fully functional prototype implementation, and (3) systematic validation demonstrating that generative agents produce believable travel behaviors. Through designed reflection processes, generative agents in this study can transform specific travel experiences into generalized insights, enabling realistic behavioral adaptation over time with specialized mechanisms for activity planning and real-time reactive behaviors tailored to urban mobility contexts. Experiments show that generative agents perform competitively with human annotators in mobility scenarios while naturally producing macroscopic traffic evolution patterns. The code for the prototype system is shared at https://github.com/qiliuchn/gatsim.",
      "authors": [
        "Qi Liu",
        "Can Li",
        "Wanjing Ma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:52:16+00:00",
          "link": "https://arxiv.org/abs/2506.23306v1",
          "size": "23163kb",
          "version": "v1"
        }
      ],
      "title": "GATSim: Urban Mobility Simulation with Generative Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23306",
        "HTML": "https://arxiv.org/html/2506.23306v1",
        "PDF": "https://arxiv.org/pdf/2506.23306"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23308",
      "abstract": "Accurate reconstruction of soft tissue is crucial for advancing automation in image-guided robotic surgery. The recent 3D Gaussian Splatting (3DGS) techniques and their variants, 4DGS, achieve high-quality renderings of dynamic surgical scenes in real-time. However, 3D-GS-based methods still struggle in scenarios with varying illumination, such as low light and over-exposure. Training 3D-GS in such extreme light conditions leads to severe optimization problems and devastating rendering quality. To address these challenges, we present Endo-4DGX, a novel reconstruction method with illumination-adaptive Gaussian Splatting designed specifically for endoscopic scenes with uneven lighting. By incorporating illumination embeddings, our method effectively models view-dependent brightness variations. We introduce a region-aware enhancement module to model the sub-area lightness at the Gaussian level and a spatial-aware adjustment module to learn the view-consistent brightness adjustment. With the illumination adaptive design, Endo-4DGX achieves superior rendering performance under both low-light and over-exposure conditions while maintaining geometric accuracy. Additionally, we employ an exposure control loss to restore the appearance from adverse exposure to the normal level for illumination-adaptive optimization. Experimental results demonstrate that Endo-4DGX significantly outperforms combinations of state-of-the-art reconstruction and restoration methods in challenging lighting environments, underscoring its potential to advance robot-assisted surgical applications. Our code is available at https://github.com/lastbasket/Endo-4DGX.",
      "authors": [
        "Yiming Huang",
        "Long Bai",
        "Beilei Cui",
        "Yanheng Li",
        "Tong Chen",
        "Jie Wang",
        "Jinlin Wu",
        "Zhen Lei",
        "Hongbin Liu",
        "Hongliang Ren"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:54:15+00:00",
          "link": "https://arxiv.org/abs/2506.23308v1",
          "size": "1103kb",
          "version": "v1"
        }
      ],
      "title": "Endo-4DGX: Robust Endoscopic Scene Reconstruction and Illumination Correction with Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23308",
        "HTML": "https://arxiv.org/html/2506.23308v1",
        "PDF": "https://arxiv.org/pdf/2506.23308"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23314",
      "abstract": "Malware detection in Android systems requires both cybersecurity expertise and machine learning (ML) techniques. Automated Machine Learning (AutoML) has emerged as an approach to simplify ML development by reducing the need for specialized knowledge. However, current AutoML solutions typically operate as black-box systems with limited transparency, interpretability, and experiment traceability. To address these limitations, we present MH-AutoML, a domain-specific framework for Android malware detection. MH-AutoML automates the entire ML pipeline, including data preprocessing, feature engineering, algorithm selection, and hyperparameter tuning. The framework incorporates capabilities for interpretability, debugging, and experiment tracking that are often missing in general-purpose solutions. In this study, we compare MH-AutoML against seven established AutoML frameworks: Auto-Sklearn, AutoGluon, TPOT, HyperGBM, Auto-PyTorch, LightAutoML, and MLJAR. Results show that MH-AutoML achieves better recall rates while providing more transparency and control. The framework maintains computational efficiency comparable to other solutions, making it suitable for cybersecurity applications where both performance and explainability matter.",
      "authors": [
        "Joner Assolin and Gabriel Canto and Diego Kreutz and Eduardo Feitosa and Hendrio Bragan\\c{c}a and Angelo Nogueira and Vanderson Rocha"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T16:12:41+00:00",
          "link": "https://arxiv.org/abs/2506.23314v1",
          "size": "3633kb",
          "version": "v1"
        }
      ],
      "title": "Interpretable by Design: MH-AutoML for Transparent and Efficient Android Malware Detection without Compromising Performance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23314",
        "HTML": "https://arxiv.org/html/2506.23314v1",
        "PDF": "https://arxiv.org/pdf/2506.23314"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23315",
      "abstract": "Identification of key variables such as medications, diseases, relations from health records and clinical notes has a wide range of applications in the clinical domain. n2c2 2022 provided shared tasks on challenges in natural language processing for clinical data analytics on electronic health records (EHR), where it built a comprehensive annotated clinical data Contextualized Medication Event Dataset (CMED). This study focuses on subtask 2 in Track 1 of this challenge that is to detect and classify medication events from clinical notes through building a novel BERT-based ensemble model. It started with pretraining BERT models on different types of big data such as Wikipedia and MIMIC. Afterwards, these pretrained BERT models were fine-tuned on CMED training data. These fine-tuned BERT models were employed to accomplish medication event classification on CMED testing data with multiple predictions. These multiple predictions generated by these fine-tuned BERT models were integrated to build final prediction with voting strategies. Experimental results demonstrated that BERT-based ensemble models can effectively improve strict Micro-F score by about 5% and strict Macro-F score by about 6%, respectively.",
      "authors": [
        "Shouvon Sarker",
        "Xishuang Dong",
        "and Lijun Qian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T16:17:17+00:00",
          "link": "https://arxiv.org/abs/2506.23315v1",
          "size": "73kb",
          "version": "v1"
        }
      ],
      "title": "Ensemble BERT for Medication Event Classification on Electronic Health Records (EHRs)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23315",
        "HTML": "https://arxiv.org/html/2506.23315v1",
        "PDF": "https://arxiv.org/pdf/2506.23315"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23316",
      "abstract": "Realistic and interactive traffic simulation is essential for training and evaluating autonomous driving systems. However, most existing data-driven simulation methods rely on static initialization or log-replay data, limiting their ability to model dynamic, long-horizon scenarios with evolving agent populations. We propose InfGen, a scenario generation framework that outputs agent states and trajectories in an autoregressive manner. InfGen represents the entire scene as a sequence of tokens, including traffic light signals, agent states, and motion vectors, and uses a transformer model to simulate traffic over time. This design enables InfGen to continuously insert new agents into traffic, supporting infinite scene generation. Experiments demonstrate that InfGen produces realistic, diverse, and adaptive traffic behaviors. Furthermore, reinforcement learning policies trained in InfGen-generated scenarios achieve superior robustness and generalization, validating its utility as a high-fidelity simulation environment for autonomous driving. More information is available at https://metadriverse.github.io/infgen/.",
      "authors": [
        "Zhenghao Peng and Yuxin Liu and Bolei Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T16:18:32+00:00",
          "link": "https://arxiv.org/abs/2506.23316v1",
          "size": "12798kb",
          "version": "v1"
        }
      ],
      "title": "InfGen: Scenario Generation as Next Token Group Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23316",
        "HTML": "https://arxiv.org/html/2506.23316v1",
        "PDF": "https://arxiv.org/pdf/2506.23316"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23319",
      "abstract": "Learning to Rank (LTR) methods generally assume that each document in a top-K ranking is presented in an equal format. However, previous work has shown that users' perceptions of relevance can be changed by varying presentations, i.e., allocating more vertical space to some documents to provide additional textual or image information. Furthermore, presentation length can also redirect attention, as users are more likely to notice longer presentations when scrolling through results. Deciding on the document presentation lengths in a fixed vertical space ranking is an important problem that has not been addressed by existing LTR methods.\n  We address this gap by introducing the variable presentation length ranking task, where simultaneously the ordering of documents and their presentation length is decided. Despite being a generalization of standard ranking, we show that this setting brings significant new challenges: Firstly, the probability ranking principle no longer applies to this setting, and secondly, the problem cannot be divided into separate ordering and length selection tasks.\n  We therefore propose VLPL - a new family of Plackett-Luce list-wise gradient estimation methods for the joint optimization of document ordering and lengths. Our semi-synthetic experiments show that VLPL can effectively balance the expected exposure and attractiveness of all documents, achieving the best performance across different ranking settings. Furthermore, we observe that even simple length-aware methods can achieve significant performance improvements over fixed-length models. Altogether, our theoretical and empirical results highlight the importance and difficulties of combining document presentation with LTR.",
      "authors": [
        "Norman Knyazev",
        "Harrie Oosterhuis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T16:28:17+00:00",
          "link": "https://arxiv.org/abs/2506.23319v1",
          "size": "3483kb",
          "version": "v1"
        }
      ],
      "title": "Learning to Rank with Variable Result Presentation Lengths",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23319",
        "HTML": "https://arxiv.org/html/2506.23319v1",
        "PDF": "https://arxiv.org/pdf/2506.23319"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23320",
      "abstract": "Programming a quantum computer, i.e., implementing quantum algorithms on a quantum processor-based copmputer architecture, is a task that can be addressed (just as for classical computers) at different levels of abstraction. This paper proposes a denotational semantics for high-level quantum programming constructs, focusing on the conceptual meaning of quantum-controlled branching and iteration. We introduce a denotational domain where a mathematical meaning of a quantum control flow with loops can be defined, which reflects the coherent evolution of the quantum system implementing the program.",
      "authors": [
        "Nicola Assolini and Alessandra Di Pierro"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T16:30:29+00:00",
          "link": "https://arxiv.org/abs/2506.23320v1",
          "size": "116kb",
          "version": "v1"
        }
      ],
      "title": "A Denotational Semantics for Quantum Loops",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23320",
        "HTML": "https://arxiv.org/html/2506.23320v1",
        "PDF": "https://arxiv.org/pdf/2506.23320"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23321",
      "abstract": "Artificial intelligence (AI) is rapidly transforming global industries and societies, making AI literacy an indispensable skill for future generations. While AI integration in education is still emerging in Nepal, this study focuses on assessing the current AI literacy levels and identifying learning needs among students in Chitwan District of Nepal. By measuring students' understanding of AI and pinpointing areas for improvement, this research aims to provide actionable recommendations for educational stakeholders. Given the pivotal role of young learners in navigating a rapidly evolving technological landscape, fostering AI literacy is paramount. This study seeks to understand the current state of AI literacy in Chitwan District by analyzing students' knowledge, skills, and attitudes towards AI. The results will contribute to developing robust AI education programs for Nepalese schools. This paper offers a contemporary perspective on AI's role in Nepalese secondary education, emphasizing the latest AI tools and technologies. Moreover, the study illuminates the potential revolutionary impact of technological innovations on educational leadership and student outcomes. A survey was conducted to conceptualize the newly emerging concept of AI and cybersecurity among students of Chitwan district from different schools and colleges to find the literacy rate. The participants in the survey were students between grade 9 to 12. We conclude with discussions of the affordances and barriers to bringing AI and cybersecurity education to students from lower classes.",
      "authors": [
        "Devendra Chapagain",
        "Naresh Kshetri",
        "Bishwo Prakash Pokharel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T16:31:50+00:00",
          "link": "https://arxiv.org/abs/2506.23321v1",
          "size": "797kb",
          "version": "v1"
        }
      ],
      "title": "AISCliteracy: Assessing Artificial Intelligence and Cybersecurity Literacy Levels and Learning Needs of Students",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23321",
        "PDF": "https://arxiv.org/pdf/2506.23321"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23322",
      "abstract": "In the financial industry, data is the lifeblood of operations, and DBAs shoulder significant responsibilities for SQL tuning, database deployment, diagnosis, and service repair. In recent years, both database vendors and customers have increasingly turned to autonomous database platforms in an effort to alleviate the heavy workload of DBAs. However, existing autonomous database platforms are limited in their capabilities, primarily addressing single-point issues such as NL2SQL, anomaly detection, and SQL tuning. Manual intervention remains a necessity for comprehensive database maintenance. GaussMaster aims to revolutionize this landscape by introducing an LLM-based database copilot system. This innovative solution is designed not only to assist developers in writing efficient SQL queries but also to provide comprehensive care for database services. When database instances exhibit abnormal behavior, GaussMaster is capable of orchestrating the entire maintenance process automatically. It achieves this by analyzing hundreds of metrics and logs, employing a Tree-of-thought approach to identify root causes, and invoking appropriate tools to resolve issues. We have successfully implemented GaussMaster in real-world scenarios, such as the banking industry, where it has achieved zero human intervention for over 34 database maintenance scenarios. In this paper, we present significant improvements in these tasks with code at https://gitcode.com/opengauss/openGauss-GaussMaster.",
      "authors": [
        "Wei Zhou",
        "Ji Sun",
        "Xuanhe Zhou",
        "Guoliang Li",
        "Luyang Liu",
        "Hao Wu",
        "Tianyuan Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T16:39:31+00:00",
          "link": "https://arxiv.org/abs/2506.23322v1",
          "size": "1001kb",
          "version": "v1"
        }
      ],
      "title": "GaussMaster: An LLM-based Database Copilot System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23322",
        "HTML": "https://arxiv.org/html/2506.23322v1",
        "PDF": "https://arxiv.org/pdf/2506.23322"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23323",
      "abstract": "Open-vocabulary semantic segmentation (OVSS) aims to segment objects from arbitrary text categories without requiring densely annotated datasets. Although contrastive learning based models enable zero-shot segmentation, they often lose fine spatial precision at pixel level, due to global representation bias. In contrast, diffusion-based models naturally encode fine-grained spatial features via attention mechanisms that capture both global context and local details. However, they often face challenges in balancing the number of iterations with the quality of the segmentation. In this work, we propose FastSeg, a novel and efficient training-free framework with only (1+1)-step of reverse process of a pretrained diffusion model (e.g., Stable Diffusion). Moreover, instead of running multiple times for different classes, FastSeg performs segmentation for all classes at once. To further enhance the segmentation quality, FastSeg introduces three key components: (i) a dual-prompt mechanism for discriminative, class-aware attention extraction, (ii) a Hierarchical Attention Refinement Method (HARD) that enhances fused cross-attention using scale-aligned selfattention maps, and (iii) a Test-Time Flipping (TTF) scheme designed to improve spatial consistency. Extensive experiments show that FastSeg achieves state-of-the-art training-free performance, obtaining 43.8% average mIoU across PASCAL VOC, PASCAL Context, and COCO Object benchmarks while maintaining superior inference efficiency. Our results demonstrate that FastSeg provides a strong foundation for extendability, bridging the gap between segmentation quality and inference efficiency.",
      "authors": [
        "Quang-Huy Che",
        "Vinh-Tiep Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T16:41:41+00:00",
          "link": "https://arxiv.org/abs/2506.23323v1",
          "size": "25909kb",
          "version": "v1"
        }
      ],
      "title": "FastSeg: Efficient Training-Free Open-Vocabulary Segmentation via Hierarchical Attention Refinement Method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23323",
        "HTML": "https://arxiv.org/html/2506.23323v1",
        "PDF": "https://arxiv.org/pdf/2506.23323"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23325",
      "abstract": "Speech codecs serve as bridges between speech signals and large language models. An ideal codec for speech language models should not only preserve acoustic information but also capture rich semantic information. However, existing speech codecs struggle to balance high-quality audio reconstruction with ease of modeling by language models. In this study, we analyze the limitations of previous codecs in balancing semantic richness and acoustic fidelity. We propose XY-Tokenizer, a novel codec that mitigates the conflict between semantic and acoustic capabilities through multi-stage, multi-task learning. Experimental results demonstrate that XY-Tokenizer achieves performance in both semantic and acoustic tasks comparable to that of state-of-the-art codecs operating at similar bitrates, even though those existing codecs typically excel in only one aspect. Specifically, XY-Tokenizer achieves strong text alignment, surpassing distillation-based semantic modeling methods such as SpeechTokenizer and Mimi, while maintaining a speaker similarity score of 0.83 between reconstructed and original audio. The reconstruction performance of XY-Tokenizer is comparable to that of BigCodec, the current state-of-the-art among acoustic-only codecs, which achieves a speaker similarity score of 0.84 at a similar bitrate. Code and models are available at https://github.com/gyt1145028706/XY-Tokenizer.",
      "authors": [
        "Yitian Gong",
        "Luozhijie Jin",
        "Ruifan Deng",
        "Dong Zhang",
        "Xin Zhang",
        "Qinyuan Cheng",
        "Zhaoye Fei",
        "Shimin Li",
        "Xipeng Qiu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T16:51:50+00:00",
          "link": "https://arxiv.org/abs/2506.23325v1",
          "size": "562kb",
          "version": "v1"
        }
      ],
      "title": "XY-Tokenizer: Mitigating the Semantic-Acoustic Conflict in Low-Bitrate Speech Codecs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23325",
        "HTML": "https://arxiv.org/html/2506.23325v1",
        "PDF": "https://arxiv.org/pdf/2506.23325"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23326",
      "abstract": "Soft robotic systems are known for their flexibility and adaptability, but traditional physics-based models struggle to capture their complex, nonlinear behaviors. This study explores a data-driven approach to modeling the volume-flow-pressure relationship in hydraulic soft actuators, focusing on low-complexity models with high accuracy. We perform regression analysis on a stacked balloon actuator system using exponential, polynomial, and neural network models with or without autoregressive inputs. The results demonstrate that simpler models, particularly multivariate polynomials, effectively predict pressure dynamics with fewer parameters. This research offers a practical solution for real-time soft robotics applications, balancing model complexity and computational efficiency. Moreover, the approach may benefit various techniques that require explicit analytical models.",
      "authors": [
        "Sang-Yoep Lee",
        "Leonardo Zamora Yanez",
        "Jacob Rogatinsky",
        "Vi T. Vo",
        "Tanvi Shingade",
        "Tommaso Ranzani"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T16:58:12+00:00",
          "link": "https://arxiv.org/abs/2506.23326v1",
          "size": "2839kb",
          "version": "v1"
        }
      ],
      "title": "Simplifying Data-Driven Modeling of the Volume-Flow-Pressure Relationship in Hydraulic Soft Robotic Actuators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23326",
        "HTML": "https://arxiv.org/html/2506.23326v1",
        "PDF": "https://arxiv.org/pdf/2506.23326"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23329",
      "abstract": "Vision-language models (VLMs) excel at descriptive tasks, but whether they truly understand scenes from visual observations remains uncertain. We introduce IR3D-Bench, a benchmark challenging VLMs to demonstrate understanding through active creation rather than passive recognition. Grounded in the analysis-by-synthesis paradigm, IR3D-Bench tasks Vision-Language Agents (VLAs) with actively using programming and rendering tools to recreate the underlying 3D structure of an input image, achieving agentic inverse rendering through tool use. This \"understanding-by-creating\" approach probes the tool-using generative capacity of VLAs, moving beyond the descriptive or conversational capacity measured by traditional scene understanding benchmarks. We provide a comprehensive suite of metrics to evaluate geometric accuracy, spatial relations, appearance attributes, and overall plausibility. Initial experiments on agentic inverse rendering powered by various state-of-the-art VLMs highlight current limitations, particularly in visual precision rather than basic tool usage. IR3D-Bench, including data and evaluation protocols, is released to facilitate systematic study and development of tool-using VLAs towards genuine scene understanding by creating.",
      "authors": [
        "Parker Liu",
        "Chenxin Li",
        "Zhengxin Li",
        "Yipeng Wu",
        "Wuyang Li",
        "Zhiqin Yang",
        "Zhenyuan Zhang",
        "Yunlong Lin",
        "Sirui Han",
        "Brandon Y. Feng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T17:02:57+00:00",
          "link": "https://arxiv.org/abs/2506.23329v1",
          "size": "1460kb",
          "version": "v1"
        }
      ],
      "title": "IR3D-Bench: Evaluating Vision-Language Model Scene Understanding as Agentic Inverse Rendering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23329",
        "HTML": "https://arxiv.org/html/2506.23329v1",
        "PDF": "https://arxiv.org/pdf/2506.23329"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23333",
      "abstract": "We implement and evaluate different methods for the reconfiguration of a connected arrangement of tiles into a desired target shape, using a single active robot that can move along the tile structure. This robot can pick up, carry, or drop off one tile at a time, but it must maintain a single connected configuration at all times.\n  Becker et al. (CCCG 2025) recently proposed an algorithm that uses histograms as canonical intermediate configurations, guaranteeing performance within a constant factor of the optimal solution if the start and target configuration are well-separated. We implement and evaluate this algorithm, both in a simulated and practical setting, using an inchworm type robot to compare it with two existing heuristic algorithms.",
      "authors": [
        "Javier Garcia",
        "Jonas Friemel",
        "Ramin Kosfeld",
        "Michael Yannuzzi",
        "Peter Kramer",
        "Christian Rieck",
        "Christian Scheffer",
        "Arne Schmidt",
        "Harm Kube",
        "Dan Biediger",
        "S\\'andor P. Fekete",
        "Aaron T. Becker"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computational Geometry (cs.CG)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T17:03:44+00:00",
          "link": "https://arxiv.org/abs/2506.23333v1",
          "size": "7190kb",
          "version": "v1"
        }
      ],
      "title": "Moving Matter: Using a Single, Simple Robot to Reconfigure a Connected Set of Building Blocks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23333",
        "HTML": "https://arxiv.org/html/2506.23333v1",
        "PDF": "https://arxiv.org/pdf/2506.23333"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23339",
      "abstract": "Large Language Models (LLMs) demonstrate remarkable potential for scientific discovery, but their application in domains requiring factual accuracy and domain-specific constraints remains challenging. In molecular design for drug discovery, LLMs can suggest creative molecular modifications but often produce chemically invalid or impractical structures. We present VALID-Mol, a systematic framework for integrating chemical validation with LLM-driven molecular design that increases the rate of generating valid chemical structures from 3% to 83%. Our approach combines methodical prompt engineering, automated chemical validation, and a fine-tuned domain-adapted LLM to ensure reliable generation of synthesizable molecules with improved properties. Beyond the specific implementation, we contribute a generalizable methodology for scientifically-constrained LLM applications, with quantifiable reliability improvements. Computational predictions suggest our framework can generate promising candidates for synthesis with up to 17-fold computationally predicted improvements in target affinity while maintaining synthetic accessibility. We provide a detailed analysis of our prompt engineering process, validation architecture, and fine-tuning approach, offering a reproducible blueprint for applying LLMs to other scientific domains where domain-specific validation is essential.",
      "authors": [
        "Malikussaid",
        "Hilal Hudan Nuha"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Chemical Physics (physics.chem-ph)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T17:17:04+00:00",
          "link": "https://arxiv.org/abs/2506.23339v1",
          "size": "1373kb",
          "version": "v1"
        }
      ],
      "title": "VALID-Mol: a Systematic Framework for Validated LLM-Assisted Molecular Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23339",
        "PDF": "https://arxiv.org/pdf/2506.23339"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23340",
      "abstract": "Large language models have achieved impressive progress in multilingual translation, yet they continue to face challenges with certain language pairs-particularly those with limited training data or significant linguistic divergence from English. This study systematically investigates how training data, language proximity, and language family affect information loss in multilingual translation. We evaluate two large language models, GPT-4 and Llama 2, by performing round-trip translations. Translation quality was assessed using BLEU scores and BERT similarity metrics. Our results reveal a robust interaction between training data size and language distance: while abundant training data can mitigate the effects of linguistic divergence, languages structurally closer to English consistently yield higher translation quality in low-resource conditions. Among various distance metrics, orthographic, phylogenetic, syntactic, and geographical distances emerge as strong predictors of translation performance. Language family also exerts an independent influence. These findings contribute to a deeper understanding of the linguistic constraints shaping multilingual translation in large language models, emphasizing that translation quality is shaped not only by data volume but also by structural and typological relationships between languages.",
      "authors": [
        "Yumeng Lin",
        "Xufeng Duan",
        "David Haslett",
        "Yige Chen",
        "Zhenguang G. Cai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T17:21:05+00:00",
          "link": "https://arxiv.org/abs/2506.23340v1",
          "size": "1298kb",
          "version": "v1"
        }
      ],
      "title": "Information Loss in LLMs' Multilingual Translation: The Role of Training Data, Language Proximity, and Language Family",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23340",
        "PDF": "https://arxiv.org/pdf/2506.23340"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23342",
      "abstract": "Active learning (AL) has demonstrated remarkable potential in reducing the annotation effort required for training machine learning models. However, despite the surging popularity of natural language generation (NLG) tasks in recent years, the application of AL to NLG has been limited. In this paper, we introduce Active Text Generation (ATGen) - a comprehensive framework that bridges AL with text generation tasks, enabling the application of state-of-the-art AL strategies to NLG. Our framework simplifies AL-empowered annotation in NLG tasks using both human annotators and automatic annotation agents based on large language models (LLMs). The framework supports LLMs deployed as services, such as ChatGPT and Claude, or operated on-premises. Furthermore, ATGen provides a unified platform for smooth implementation and benchmarking of novel AL strategies tailored to NLG tasks. Finally, we present evaluation results for state-of-the-art AL strategies across diverse settings and multiple text generation tasks. We show that ATGen reduces both the effort of human annotators and costs associated with API calls to LLM-based annotation agents. The code of the framework is available on GitHub under the MIT license. The video presentation is available at http://atgen-video.nlpresearch.group",
      "authors": [
        "Akim Tsvigun",
        "Daniil Vasilev",
        "Ivan Tsvigun",
        "Ivan Lysenko",
        "Talgat Bektleuov",
        "Aleksandr Medvedev",
        "Uliana Vinogradova",
        "Nikita Severin",
        "Mikhail Mozikov",
        "Andrey Savchenko",
        "Rostislav Grigorev",
        "Ramil Kuleev",
        "Fedor Zhdanov",
        "Artem Shelmanov",
        "Ilya Makarov"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T17:27:48+00:00",
          "link": "https://arxiv.org/abs/2506.23342v1",
          "size": "487kb",
          "version": "v1"
        }
      ],
      "title": "ATGen: A Framework for Active Text Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23342",
        "HTML": "https://arxiv.org/html/2506.23342v1",
        "PDF": "https://arxiv.org/pdf/2506.23342"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23344",
      "abstract": "The appearance of singularities in the function of interest constitutes a fundamental challenge in scientific computing. It can significantly undermine the effectiveness of numerical schemes for function approximation, numerical integration, and the solution of partial differential equations (PDEs), etc. The problem becomes more sophisticated if the location of the singularity is unknown, which is often encountered in solving PDEs. Detecting the singularity is therefore critical for developing efficient adaptive methods to reduce computational costs in various applications. In this paper, we consider singularity detection in a purely data-driven setting. Namely, the input only contains given data, such as the vertex set from a mesh. To overcome the limitation of the raw unlabeled data, we propose a self-supervised learning (SSL) framework for estimating the location of the singularity. A key component is a filtering procedure as the pretext task in SSL, where two filtering methods are presented, based on $k$ nearest neighbors and kernel density estimation, respectively. We provide numerical examples to illustrate the potential pathological or inaccurate results due to the use of raw data without filtering. Various experiments are presented to demonstrate the ability of the proposed approach to deal with input perturbation, label corruption, and different kinds of singularities such interior circle, boundary layer, concentric semicircles, etc.",
      "authors": [
        "Difeng Cai",
        "Paulina Sep\\'ulveda"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T17:39:41+00:00",
          "link": "https://arxiv.org/abs/2506.23344v1",
          "size": "3231kb",
          "version": "v1"
        }
      ],
      "title": "Data-Driven Self-Supervised Learning for the Discovery of Solution Singularity for Partial Differential Equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23344",
        "HTML": "https://arxiv.org/html/2506.23344v1",
        "PDF": "https://arxiv.org/pdf/2506.23344"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23346",
      "abstract": "While we have made significant algorithmic developments to enable autonomous systems to perform sophisticated tasks, it remains difficult for them to perform tasks effective and safely. Most existing approaches either fail to provide any safety assurances or substantially compromise task performance for safety. In this work, we develop a framework, based on model predictive control (MPC) and Hamilton-Jacobi (HJ) reachability, to optimize task performance for autonomous systems while respecting the safety constraints. Our framework guarantees recursive feasibility for the MPC controller, and it is scalable to high-dimensional systems. We demonstrate the effectiveness of our framework with two simulation studies using a 4D Dubins Car and a 6 Dof Kuka iiwa manipulator, and the experiments show that our framework significantly improves the safety constraints satisfaction of the systems over the baselines.",
      "authors": [
        "Hao Wang",
        "Armand Jordana",
        "Ludovic Righetti",
        "Somil Bansal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T17:41:37+00:00",
          "link": "https://arxiv.org/abs/2506.23346v1",
          "size": "329kb",
          "version": "v1"
        }
      ],
      "title": "Safe and Performant Deployment of Autonomous Systems via Model Predictive Control and Hamilton-Jacobi Reachability Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23346",
        "HTML": "https://arxiv.org/html/2506.23346v1",
        "PDF": "https://arxiv.org/pdf/2506.23346"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23347",
      "abstract": "The current conditional autoregressive image generation methods have shown promising results, yet their potential remains largely unexplored in the practical unsupervised image translation domain, which operates without explicit cross-domain correspondences. A critical limitation stems from the discrete quantization inherent in traditional Vector Quantization-based frameworks, which disrupts gradient flow between the Variational Autoencoder decoder and causal Transformer, impeding end-to-end optimization during adversarial training in image space. To tackle this issue, we propose using Softmax Relaxed Quantization, a novel approach that reformulates codebook selection as a continuous probability mixing process via Softmax, thereby preserving gradient propagation. Building upon this differentiable foundation, we introduce CycleVAR, which reformulates image-to-image translation as image-conditional visual autoregressive generation by injecting multi-scale source image tokens as contextual prompts, analogous to prefix-based conditioning in language models. CycleVAR exploits two modes to generate the target image tokens, including (1) serial multi-step generation, enabling iterative refinement across scales, and (2) parallel one-step generation synthesizing all resolution outputs in a single forward pass. Experimental findings indicate that the parallel one-step generation mode attains superior translation quality with quicker inference speed than the serial multi-step mode in unsupervised scenarios. Furthermore, both quantitative and qualitative results indicate that CycleVAR surpasses previous state-of-the-art unsupervised image translation models, \\textit{e}.\\textit{g}., CycleGAN-Turbo.",
      "authors": [
        "Yi Liu",
        "Shengqian Li",
        "Zuzeng Lin",
        "Feng Wang",
        "Si Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T17:43:04+00:00",
          "link": "https://arxiv.org/abs/2506.23347v1",
          "size": "2218kb",
          "version": "v1"
        }
      ],
      "title": "CycleVAR: Repurposing Autoregressive Model for Unsupervised One-Step Image Translation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23347",
        "HTML": "https://arxiv.org/html/2506.23347v1",
        "PDF": "https://arxiv.org/pdf/2506.23347"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23349",
      "abstract": "Following the rise in popularity of data-centric machine learning (ML), various data valuation methods have been proposed to quantify the contribution of each datapoint to desired ML model performance metrics (e.g., accuracy). Beyond the technical applications of data valuation methods (e.g., data cleaning, data acquisition, etc.), it has been suggested that within the context of data markets, data buyers might utilize such methods to fairly compensate data owners. Here we demonstrate that data valuation metrics are inherently biased and unstable under simple algorithmic design choices, resulting in both technical and ethical implications. By analyzing 9 tabular classification datasets and 6 data valuation methods, we illustrate how (1) common and inexpensive data pre-processing techniques can drastically alter estimated data values; (2) subsampling via data valuation metrics may increase class imbalance; and (3) data valuation metrics may undervalue underrepresented group data. Consequently, we argue in favor of increased transparency associated with data valuation in-the-wild and introduce the novel Data Valuation Cards (DValCards) framework towards this aim. The proliferation of DValCards will reduce misuse of data valuation metrics, including in data pricing, and build trust in responsible ML systems.",
      "authors": [
        "Keziah Naggita and Julienne LaChance"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T17:53:00+00:00",
          "link": "https://arxiv.org/abs/2506.23349v1",
          "size": "2169kb",
          "version": "v1"
        }
      ],
      "title": "A case for data valuation transparency via DValCards",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23349",
        "PDF": "https://arxiv.org/pdf/2506.23349"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23350",
      "abstract": "Underwater wireless communications face significant challenges due to propagation constraints, limiting the effectiveness of traditional radio and optical technologies. Long-range acoustic communications support distances up to a few kilometers, but suffer from low bandwidth, high error ratios, and multipath interference. Semantic communications, which focus on transmitting extracted semantic features rather than raw data, present a promising solution by significantly reducing the volume of data transmitted over the wireless link.\n  This paper evaluates the resilience of SAGE, a semantic-oriented communications framework that combines semantic processing with Generative Artificial Intelligence (GenAI) to compress and transmit image data as textual descriptions over acoustic links. To assess robustness, we use a custom-tailored simulator that introduces character errors observed in underwater acoustic channels. Evaluation results show that SAGE can successfully reconstruct meaningful image content even under varying error conditions, highlighting its potential for robust and efficient underwater wireless communication in harsh environments.",
      "authors": [
        "Jo\\~ao Pedro Loureiro and Patr\\'icia Delgado and Tom\\'as Feliciano Ribeiro and Filipe B. Teixeira and Rui Campos"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T17:54:00+00:00",
          "link": "https://arxiv.org/abs/2506.23350v1",
          "size": "3775kb",
          "version": "v1"
        }
      ],
      "title": "On the Resilience of Underwater Semantic Wireless Communications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23350",
        "HTML": "https://arxiv.org/html/2506.23350v1",
        "PDF": "https://arxiv.org/pdf/2506.23350"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23351",
      "abstract": "Embodied Artificial Intelligence (Embodied AI) is an emerging frontier in robotics, driven by the need for autonomous systems that can perceive, reason, and act in complex physical environments. While single-arm systems have shown strong task performance, collaborative dual-arm systems are essential for handling more intricate tasks involving rigid, deformable, and tactile-sensitive objects. To advance this goal, we launched the RoboTwin Dual-Arm Collaboration Challenge at the 2nd MEIS Workshop, CVPR 2025. Built on the RoboTwin Simulation platform (1.0 and 2.0) and the AgileX COBOT-Magic Robot platform, the competition consisted of three stages: Simulation Round 1, Simulation Round 2, and a final Real-World Round. Participants totally tackled 17 dual-arm manipulation tasks, covering rigid, deformable, and tactile-based scenarios. The challenge attracted 64 global teams and over 400 participants, producing top-performing solutions like SEM and AnchorDP3 and generating valuable insights into generalizable bimanual policy learning. This report outlines the competition setup, task design, evaluation methodology, key findings and future direction, aiming to support future research on robust and generalizable bimanual manipulation policies. The Challenge Webpage is available at https://robotwin-benchmark.github.io/cvpr-2025-challenge/.",
      "authors": [
        "Tianxing Chen",
        "Kaixuan Wang",
        "Zhaohui Yang",
        "Yuhao Zhang",
        "Zanxin Chen",
        "Baijun Chen",
        "Wanxi Dong",
        "Ziyuan Liu",
        "Dong Chen",
        "Tianshuo Yang",
        "Haibao Yu",
        "Xiaokang Yang",
        "Yusen Qin",
        "Zhiqiang Xie",
        "Yao Mu",
        "Ping Luo",
        "Tian Nian",
        "Weiliang Deng",
        "Yiheng Ge",
        "Yibin Liu",
        "Zixuan Li",
        "Dehui Wang",
        "Zhixuan Liang",
        "Haohui Xie",
        "Rijie Zeng",
        "Yunfei Ge",
        "Peiqing Cong",
        "Guannan He",
        "Zhaoming Han",
        "Ruocheng Yin",
        "Jingxiang Guo",
        "Lunkai Lin",
        "Tianling Xu",
        "Hongzhe Bi",
        "Xuewu Lin",
        "Tianwei Lin",
        "Shujie Luo",
        "Keyu Li",
        "Ziyan Zhao",
        "Ke Fan",
        "Heyang Xu",
        "Bo Peng",
        "Wenlong Gao",
        "Dongjiang Li",
        "Feng Jin",
        "Hui Shen",
        "Jinming Li",
        "Chaowei Cui",
        "Yuchen",
        "Yaxin Peng",
        "Lingdong Zeng",
        "Wenlong Dong",
        "Tengfei Li",
        "Weijie Ke",
        "Jun Chen",
        "Erdemt Bao",
        "Tian Lan",
        "Tenglong Liu",
        "Jin Yang",
        "Huiping Zhuang",
        "Baozhi Jia",
        "Shuai Zhang",
        "Zhengfeng Zou",
        "Fangheng Guan",
        "Tianyi Jia",
        "Ke Zhou",
        "Hongjiu Zhang",
        "Yating Han",
        "Cheng Fang",
        "Yixian Zou",
        "Chongyang Xu",
        "Qinglun Zhang",
        "Shen Cheng",
        "Xiaohe Wang",
        "Ping Tan",
        "Haoqiang Fan",
        "Shuaicheng Liu",
        "Jiaheng Chen",
        "Chuxuan Huang",
        "Chengliang Lin",
        "Kaijun Luo",
        "Boyu Yue",
        "Yi Liu",
        "Jinyu Chen",
        "Zichang Tan",
        "Liming Deng",
        "Shuo Xu",
        "Zijian Cai",
        "Shilong Yin",
        "Hao Wang",
        "Hongshan Liu",
        "Tianyang Li",
        "Long Shi",
        "Ran Xu",
        "Huilin Xu",
        "Zhengquan Zhang",
        "Congsheng Xu",
        "Jinchang Yang",
        "and Feng Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T17:56:41+00:00",
          "link": "https://arxiv.org/abs/2506.23351v1",
          "size": "5055kb",
          "version": "v1"
        }
      ],
      "title": "Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23351",
        "HTML": "https://arxiv.org/html/2506.23351v1",
        "PDF": "https://arxiv.org/pdf/2506.23351"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23352",
      "abstract": "The advancement of 3D language fields has enabled intuitive interactions with 3D scenes via natural language. However, existing approaches are typically limited to small-scale environments, lacking the scalability and compositional reasoning capabilities necessary for large, complex urban settings. To overcome these limitations, we propose GeoProg3D, a visual programming framework that enables natural language-driven interactions with city-scale high-fidelity 3D scenes. GeoProg3D consists of two key components: (i) a Geography-aware City-scale 3D Language Field (GCLF) that leverages a memory-efficient hierarchical 3D model to handle large-scale data, integrated with geographic information for efficiently filtering vast urban spaces using directional cues, distance measurements, elevation data, and landmark references; and (ii) Geographical Vision APIs (GV-APIs), specialized geographic vision tools such as area segmentation and object detection. Our framework employs large language models (LLMs) as reasoning engines to dynamically combine GV-APIs and operate GCLF, effectively supporting diverse geographic vision tasks. To assess performance in city-scale reasoning, we introduce GeoEval3D, a comprehensive benchmark dataset containing 952 query-answer pairs across five challenging tasks: grounding, spatial reasoning, comparison, counting, and measurement. Experiments demonstrate that GeoProg3D significantly outperforms existing 3D language fields and vision-language models across multiple tasks. To our knowledge, GeoProg3D is the first framework enabling compositional geographic reasoning in high-fidelity city-scale 3D environments via natural language. The code is available at https://snskysk.github.io/GeoProg3D/.",
      "authors": [
        "Shunsuke Yasuki",
        "Taiki Miyanishi",
        "Nakamasa Inoue",
        "Shuhei Kurita",
        "Koya Sakamoto",
        "Daichi Azuma",
        "Masato Taki",
        "Yutaka Matsuo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T18:03:03+00:00",
          "link": "https://arxiv.org/abs/2506.23352v1",
          "size": "7553kb",
          "version": "v1"
        }
      ],
      "title": "GeoProg3D: Compositional Visual Reasoning for City-Scale 3D Language Fields",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23352",
        "HTML": "https://arxiv.org/html/2506.23352v1",
        "PDF": "https://arxiv.org/pdf/2506.23352"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23353",
      "abstract": "Infrared image helps improve the perception capabilities of autonomous driving in complex weather conditions such as fog, rain, and low light. However, infrared image often suffers from low contrast, especially in non-heat-emitting targets like bicycles, which significantly affects the performance of downstream high-level vision tasks. Furthermore, achieving contrast enhancement without amplifying noise and losing important information remains a challenge. To address these challenges, we propose a task-oriented infrared image enhancement method. Our approach consists of two key components: layer decomposition and saliency information extraction. First, we design an layer decomposition method for infrared images, which enhances scene details while preserving dark region features, providing more features for subsequent saliency information extraction. Then, we propose a morphological reconstruction-based saliency extraction method that effectively extracts and enhances target information without amplifying noise. Our method improves the image quality for object detection and semantic segmentation tasks. Extensive experiments demonstrate that our approach outperforms state-of-the-art methods.",
      "authors": [
        "Siyuan Chai",
        "Xiaodong Guo and Tong Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T18:10:05+00:00",
          "link": "https://arxiv.org/abs/2506.23353v1",
          "size": "2831kb",
          "version": "v1"
        }
      ],
      "title": "Layer Decomposition and Morphological Reconstruction for Task-Oriented Infrared Image Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23353",
        "HTML": "https://arxiv.org/html/2506.23353v1",
        "PDF": "https://arxiv.org/pdf/2506.23353"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23358",
      "abstract": "We present Federated Timeline Synthesis (FTS), a novel framework for training generative foundation models across distributed timeseries data applied to electronic health records (EHR). At its core, FTS represents patient history as tokenized Patient Health Timelines (PHTs), language-agnostic sequences encoding temporal, categorical, and continuous clinical information. Each institution trains an autoregressive transformer on its local PHTs and transmits only model weights to a central server. The server uses the generators to synthesize a large corpus of trajectories and train a Global Generator (GG), enabling zero-shot inference via Monte Carlo simulation of future PHTs. We evaluate FTS on five clinically meaningful prediction tasks using MIMIC-IV data, showing that models trained on synthetic data generated by GG perform comparably to those trained on real data. FTS offers strong privacy guarantees, scalability across institutions, and extensibility to diverse prediction and simulation tasks especially in healthcare, including counterfactual inference, early warning detection, and synthetic trial design.",
      "authors": [
        "Pawel Renc",
        "Michal K. Grzeszczyk",
        "Linglong Qian",
        "Nassim Oufattole",
        "Jeff Rasley",
        "Arkadiusz Sitek"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T18:29:59+00:00",
          "link": "https://arxiv.org/abs/2506.23358v1",
          "size": "1028kb",
          "version": "v1"
        }
      ],
      "title": "Federated Timeline Synthesis: Scalable and Private Methodology For Model Training and Deployment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23358",
        "HTML": "https://arxiv.org/html/2506.23358v1",
        "PDF": "https://arxiv.org/pdf/2506.23358"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23361",
      "abstract": "Existing feedforward subject-driven video customization methods mainly study single-subject scenarios due to the difficulty of constructing multi-subject training data pairs. Another challenging problem that how to use the signals such as depth, mask, camera, and text prompts to control and edit the subject in the customized video is still less explored. In this paper, we first propose a data construction pipeline, VideoCus-Factory, to produce training data pairs for multi-subject customization from raw videos without labels and control signals such as depth-to-video and mask-to-video pairs. Based on our constructed data, we develop an Image-Video Transfer Mixed (IVTM) training with image editing data to enable instructive editing for the subject in the customized video. Then we propose a diffusion Transformer framework, OmniVCus, with two embedding mechanisms, Lottery Embedding (LE) and Temporally Aligned Embedding (TAE). LE enables inference with more subjects by using the training subjects to activate more frame embeddings. TAE encourages the generation process to extract guidance from temporally aligned control signals by assigning the same frame embeddings to the control and noise tokens. Experiments demonstrate that our method significantly surpasses state-of-the-art methods in both quantitative and qualitative evaluations. Video demos are at our project page: https://caiyuanhao1998.github.io/project/OmniVCus/. Our code will be released at https://github.com/caiyuanhao1998/Open-OmniVCus",
      "authors": [
        "Yuanhao Cai",
        "He Zhang",
        "Xi Chen",
        "Jinbo Xing",
        "Yiwei Hu",
        "Yuqian Zhou",
        "Kai Zhang",
        "Zhifei Zhang",
        "Soo Ye Kim",
        "Tianyu Wang",
        "Yulun Zhang",
        "Xiaokang Yang",
        "Zhe Lin",
        "Alan Yuille"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T18:43:00+00:00",
          "link": "https://arxiv.org/abs/2506.23361v1",
          "size": "3531kb",
          "version": "v1"
        }
      ],
      "title": "OmniVCus: Feedforward Subject-driven Video Customization with Multimodal Control Conditions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23361",
        "HTML": "https://arxiv.org/html/2506.23361v1",
        "PDF": "https://arxiv.org/pdf/2506.23361"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23363",
      "abstract": "Given a graph $G$ and integers $k, x \\geq 0$, the Critical Node Cut problem asks whether it is possible to delete at most $k$ vertices from $G$ such that the number of remaining pairs of connected vertices is at most $x$. This problem generalizes Vertex Cover (when $x = 0$), and has applications in network design, epidemiology, and social network analysis. We investigate the parameterized complexity of Critical Node Cut under various structural parameters. We first significantly strengthen existing hardness results by proving W[1]-hardness even when parameterized by the combined parameter $k + \\mathrm{fes} + \\Delta + \\mathrm{pw}$, where $\\mathrm{fes}$ is the feedback edge set number, $\\Delta$ the maximum degree, and $\\mathrm{pw}$ the pathwidth of the input graph. We then identify three structural parameters--max-leaf number, vertex integrity, and modular-width--that render the problem fixed-parameter tractable. Furthermore, leveraging a technique introduced by Lampis [ICALP '14], we develop an FPT approximation scheme that, for any $\\varepsilon > 0$, computes a $(1+\\varepsilon)$-approximate solution in time $(\\mathrm{tw} / \\varepsilon)^{\\mathcal{O}(\\mathrm{tw})} n^{\\mathcal{O}(1)}$, where $\\mathrm{tw}$ denotes the treewidth of the input graph. Finally, we show that Critical Node Cut does not admit a polynomial kernel when parameterized by vertex cover number, unless standard complexity assumptions fail. Overall, our results significantly sharpen the known complexity landscape of Critical Node Cut.",
      "authors": [
        "Du\\v{s}an Knop",
        "Nikolaos Melissinos",
        "and Manolis Vasilakis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T18:51:21+00:00",
          "link": "https://arxiv.org/abs/2506.23363v1",
          "size": "109kb",
          "version": "v1"
        }
      ],
      "title": "Parameterized Critical Node Cut Revisited",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23363",
        "PDF": "https://arxiv.org/pdf/2506.23363"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23364",
      "abstract": "We present interactive data-driven compute overlays for native and web-based 3D geographic map applications based on WebGPU. Our data-driven overlays are generated in a multi-step compute workflow from multiple data sources on the GPU. We demonstrate their potential by showing results from snow cover and avalanche simulations, where simulation parameters can be adjusted interactively and results are visualized instantly. Benchmarks show that our approach can compute large-scale avalanche simulations in milliseconds to seconds, depending on the size of the terrain and the simulation parameters, which is multiple orders of magnitude faster than a state-of-the-art Python implementation.",
      "authors": [
        "Patrick Komon",
        "Gerald Kimmersdorfer",
        "Adam Celarek",
        "Manuela Waldner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T18:52:19+00:00",
          "link": "https://arxiv.org/abs/2506.23364v1",
          "size": "6187kb",
          "version": "v1"
        }
      ],
      "title": "Data-Driven Compute Overlays for Interactive Geographic Simulation and Visualization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23364",
        "HTML": "https://arxiv.org/html/2506.23364v1",
        "PDF": "https://arxiv.org/pdf/2506.23364"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23366",
      "abstract": "Scientific behavior is often characterized by a tension between building upon established knowledge and introducing novel ideas. Here, we investigate whether this tension is reflected in the relationship between the similarity of a scientific paper to previous research and its eventual citation rate. To operationalize similarity to previous research, we introduce two complementary metrics to characterize the local geometry of a publication's semantic neighborhood: (1) \\emph{density} ($\\rho$), defined as the ratio between a fixed number of previously-published papers and the minimum distance enclosing those papers in a semantic embedding space, and (2) asymmetry ($\\alpha$), defined as the average directional difference between a paper and its nearest neighbors. We tested the predictive relationship between these two metrics and its subsequent citation rate using a Bayesian hierarchical regression approach, surveying $\\sim 53,000$ publications across nine academic disciplines and five different document embeddings. While the individual effects of $\\rho$ on citation count are small and variable, incorporating density-based predictors consistently improves out-of-sample prediction when added to baseline models. These results suggest that the density of a paper's surrounding scientific literature may carry modest but informative signals about its eventual impact. Meanwhile, we find no evidence that publication asymmetry improves model predictions of citation rates. Our work provides a scalable framework for linking document embeddings to scientometric outcomes and highlights new questions regarding the role that semantic similarity plays in shaping the dynamics of scientific reward.",
      "authors": [
        "Nathaniel Imel and Zachary Hafen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Digital Libraries (cs.DL)",
        "Computation and Language (cs.CL)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T18:55:04+00:00",
          "link": "https://arxiv.org/abs/2506.23366v1",
          "size": "2078kb",
          "version": "v1"
        }
      ],
      "title": "Density, asymmetry and citation dynamics in scientific literature",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23366",
        "HTML": "https://arxiv.org/html/2506.23366v1",
        "PDF": "https://arxiv.org/pdf/2506.23366"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23367",
      "abstract": "We present the first text-to-speech (TTS) system tailored to second language (L2) speakers. We use duration differences between American English tense (longer) and lax (shorter) vowels to create a \"clarity mode\" for Matcha-TTS. Our perception studies showed that French-L1, English-L2 listeners had fewer (at least 9.15%) transcription errors when using our clarity mode, and found it more encouraging and respectful than overall slowed down speech. Remarkably, listeners were not aware of these effects: despite the decreased word error rate in clarity mode, listeners still believed that slowing all target words was the most intelligible, suggesting that actual intelligibility does not correlate with perceived intelligibility. Additionally, we found that Whisper-ASR did not use the same cues as L2 speakers to differentiate difficult vowels and is not sufficient to assess the intelligibility of TTS systems for these individuals.",
      "authors": [
        "Paige Tutt\\\"os\\'i",
        "H. Henny Yeung",
        "Yue Wang",
        "Jean-Julien Aucouturier",
        "Angelica Lim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T18:55:05+00:00",
          "link": "https://arxiv.org/abs/2506.23367v1",
          "size": "954kb",
          "version": "v1"
        }
      ],
      "title": "You Sound a Little Tense: L2 Tailored Clear TTS Using Durational Vowel Properties",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23367",
        "HTML": "https://arxiv.org/html/2506.23367v1",
        "PDF": "https://arxiv.org/pdf/2506.23367"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23369",
      "abstract": "Efficient identification of picking points is critical for automated fruit harvesting. Avocados present unique challenges owing to their irregular shape, weight, and less-structured growing environments, which require specific viewpoints for successful harvesting. We propose a geometry-based, semantics-aware viewpoint-planning algorithm to address these challenges. The planning process involves three key steps: viewpoint sampling, evaluation, and execution. Starting from a partially occluded view, the system first detects the fruit, then leverages geometric information to constrain the viewpoint search space to a 1D circle, and uniformly samples four points to balance the efficiency and exploration. A new picking score metric is introduced to evaluate the viewpoint suitability and guide the camera to the next-best view. We validate our method through simulation against two state-of-the-art algorithms. Results show a 100% success rate in two case studies with significant occlusions, demonstrating the efficiency and robustness of our approach. Our code is available at https://github.com/lineojcd/GSNBV",
      "authors": [
        "Xiao'ao Song and Konstantinos Karydis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T19:07:40+00:00",
          "link": "https://arxiv.org/abs/2506.23369v1",
          "size": "44111kb",
          "version": "v1"
        }
      ],
      "title": "GS-NBV: a Geometry-based, Semantics-aware Viewpoint Planning Algorithm for Avocado Harvesting under Occlusions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23369",
        "HTML": "https://arxiv.org/html/2506.23369v1",
        "PDF": "https://arxiv.org/pdf/2506.23369"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23374",
      "abstract": "Distinguishing cause and effect from bivariate observational data is a foundational problem in many disciplines, but challenging without additional assumptions. Additive noise models (ANMs) are widely used to enable sample-efficient bivariate causal discovery. However, conventional ANM-based methods fail when unobserved mediators corrupt the causal relationship between variables. This paper makes three key contributions: first, we rigorously characterize why standard ANM approaches break down in the presence of unmeasured mediators. Second, we demonstrate that prior solutions for hidden mediation are brittle in finite sample settings, limiting their practical utility. To address these gaps, we propose Bivariate Denoising Diffusion (BiDD) for causal discovery, a method designed to handle latent noise introduced by unmeasured mediators. Unlike prior methods that infer directionality through mean squared error loss comparisons, our approach introduces a novel independence test statistic: during the noising and denoising processes for each variable, we condition on the other variable as input and evaluate the independence of the predicted noise relative to this input. We prove asymptotic consistency of BiDD under the ANM, and conjecture that it performs well under hidden mediation. Experiments on synthetic and real-world data demonstrate consistent performance, outperforming existing methods in mediator-corrupted settings while maintaining strong performance in mediator-free settings.",
      "authors": [
        "Dominik Meier",
        "Sujai Hiremath",
        "Promit Ghosal",
        "Kyra Gan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T19:20:41+00:00",
          "link": "https://arxiv.org/abs/2506.23374v1",
          "size": "355kb",
          "version": "v1"
        }
      ],
      "title": "When Additive Noise Meets Unobserved Mediators: Bivariate Denoising Diffusion for Causal Discovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23374",
        "HTML": "https://arxiv.org/html/2506.23374v1",
        "PDF": "https://arxiv.org/pdf/2506.23374"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23377",
      "abstract": "Large language models (LLMs) are used in a variety of mission-critical roles. Due to the rapidly developing nature of LLMs, there is a lack of quantifiable understanding of the bias and perspective associated with LLM output. Inspired by this need, this paper considers the broader issue of perspective or viewpoint of general text and perspective control of large-language model (LLM) output. Perspective-Dial consists of two main components: a (1) metric space, dubbed Perspective Space, that enables quantitative measurements of different perspectives regarding a topic, and the use of (2) Systematic Prompt Engineering that utilizes greedy-coordinate descent to control LLM output perspective based on measurement feedback from the Perspective Space. The empirical nature of the approach allows progress to side step a principled understanding of perspective or bias -- effectively quantifying and adjusting outputs for a variety of topics. Potential applications include detection, tracking and mitigation of LLM bias, narrative detection, sense making and tracking in public discourse, and debate bot advocating given perspective.",
      "authors": [
        "Taejin Kim and Siun-Chuon Mau and Konrad Vesey"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T19:26:37+00:00",
          "link": "https://arxiv.org/abs/2506.23377v1",
          "size": "416kb",
          "version": "v1"
        }
      ],
      "title": "Perspective Dial: Measuring Perspective of Text and Guiding LLM Outputs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23377",
        "HTML": "https://arxiv.org/html/2506.23377v1",
        "PDF": "https://arxiv.org/pdf/2506.23377"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23381",
      "abstract": "We propose new a posteriori error estimators for non-conforming finite element discretizations of second-order elliptic PDE problems. These estimators are based on novel reformulations of the standard Prager-Synge identity, and enable to prove efficiency estimates without extra stabilization terms in the error measure for a large class of discretization schemes. We propose a residual-based estimator for which the efficiency constant scales optimally in polynomial degree, as well as two equilibrated estimators that are polynomial-degree-robust. One of the two estimators further leads to guaranteed error bounds.",
      "authors": [
        "T. Chaumont-Frelet"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T19:38:35+00:00",
          "link": "https://arxiv.org/abs/2506.23381v1",
          "size": "51kb",
          "version": "v1"
        }
      ],
      "title": "A new family of a posteriori error estimates for non-conforming finite element methods leading to stabilization-free error bounds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23381",
        "HTML": "https://arxiv.org/html/2506.23381v1",
        "PDF": "https://arxiv.org/pdf/2506.23381"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23382",
      "abstract": "Implicit Neural Representations (INRs) offer exceptional fidelity for video compression by learning per-video optimized functions, but their adoption is crippled by impractically slow encoding times. Existing attempts to accelerate INR encoding often sacrifice reconstruction quality or crucial coordinate-level control essential for adaptive streaming and transcoding. We introduce SIEDD (Shared-Implicit Encoder with Discrete Decoders), a novel architecture that fundamentally accelerates INR encoding without these compromises. SIEDD first rapidly trains a shared, coordinate-based encoder on sparse anchor frames to efficiently capture global, low-frequency video features. This encoder is then frozen, enabling massively parallel training of lightweight, discrete decoders for individual frame groups, further expedited by aggressive coordinate-space sampling. This synergistic design delivers a remarkable 20-30X encoding speed-up over state-of-the-art INR codecs on HD and 4K benchmarks, while maintaining competitive reconstruction quality and compression ratios. Critically, SIEDD retains full coordinate-based control, enabling continuous resolution decoding and eliminating costly transcoding. Our approach significantly advances the practicality of high-fidelity neural video compression, demonstrating a scalable and efficient path towards real-world deployment. Our codebase is available at https://github.com/VikramRangarajan/SIEDD .",
      "authors": [
        "Vikram Rangarajan",
        "Shishira Maiya",
        "Max Ehrlich",
        "Abhinav Shrivastava"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T19:39:43+00:00",
          "link": "https://arxiv.org/abs/2506.23382v1",
          "size": "23754kb",
          "version": "v1"
        }
      ],
      "title": "SIEDD: Shared-Implicit Encoder with Discrete Decoders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23382",
        "HTML": "https://arxiv.org/html/2506.23382v1",
        "PDF": "https://arxiv.org/pdf/2506.23382"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23384",
      "abstract": "RNA co-transcriptionality, where RNA is spliced or folded during transcription from DNA templates, offers promising potential for molecular programming. It enables programmable folding of nano-scale RNA structures and has recently been shown to be Turing universal. While post-transcriptional splicing is well studied, co-transcriptional splicing is gaining attention for its efficiency, though its unpredictability still remains a challenge. In this paper, we focus on engineering co-transcriptional splicing, not only as a natural phenomenon but as a programmable mechanism for generating specific RNA target sequences from DNA templates. The problem we address is whether we can encode a set of RNA sequences for a given system onto a DNA template word, ensuring that all the sequences are generated through co-transcriptional splicing. Given that finding the optimal encoding has been shown to be NP-complete under the various energy models considered, we propose a practical alternative approach under the logarithmic energy model. More specifically, we provide a construction that encodes an arbitrary nondeterministic finite automaton (NFA) into a circular DNA template from which co-transcriptional splicing produces all sequences accepted by the NFA. As all finite languages can be efficiently encoded as NFA, this framework solves the problem of finding small DNA templates for arbitrary target sets of RNA sequences. The quest to obtain the smallest possible such templates naturally leads us to consider the problem of minimizing NFA and certain practically motivated variants of it, but as we show, those minimization problems are computationally intractable.",
      "authors": [
        "Da-Jung Cho and Szil\\'ard Zsolt Fazekas and Shinnosuke Seki and Max Wiedenh\\\"oft"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T19:54:01+00:00",
          "link": "https://arxiv.org/abs/2506.23384v1",
          "size": "1837kb",
          "version": "v1"
        }
      ],
      "title": "Programmable Co-Transcriptional Splicing: Realizing Regular Languages via Hairpin Deletion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23384",
        "HTML": "https://arxiv.org/html/2506.23384v1",
        "PDF": "https://arxiv.org/pdf/2506.23384"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23388",
      "abstract": "We present a real-time deformation method for Escher tiles -- interlocking organic forms that seamlessly tessellate the plane following symmetry rules. We formulate the problem as determining a periodic displacement field. The goal is to deform Escher tiles without introducing gaps or overlaps. The resulting displacement field is obtained in closed form by an analytical solution. Our method processes tiles of 17 wallpaper groups across various representations such as images and meshes. Rather than treating tiles as mere boundaries, we consider them as textured shapes, ensuring that both the boundary and interior deform simultaneously. To enable fine-grained artistic input, our interactive tool features a user-controllable adaptive fall-off parameter, allowing precise adjustment of locality and supporting deformations with meaningful semantic control. We demonstrate the effectiveness of our method through various examples, including photo editing and shape sculpting, showing its use in applications such as fabrication and animation.",
      "authors": [
        "Crane He Chen",
        "Vladimir G. Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computational Geometry (cs.CG)",
        "Mathematical Software (cs.MS)",
        "Metric Geometry (math.MG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T20:03:47+00:00",
          "link": "https://arxiv.org/abs/2506.23388v1",
          "size": "43284kb",
          "version": "v1"
        }
      ],
      "title": "Escher Tile Deformation via Closed-Form Solution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23388",
        "HTML": "https://arxiv.org/html/2506.23388v1",
        "PDF": "https://arxiv.org/pdf/2506.23388"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23393",
      "abstract": "Generating Wikipedia articles autonomously is a challenging task requiring the integration of accurate, comprehensive, and well-structured information from diverse sources. This paper introduces the Memory Organization-based Generation (MOG) framework, a novel approach to address these challenges by leveraging a hierarchical memory architecture. MOG extracts fine-grained memory units from web documents, recursively organizes them into a Wikipedia-style hierarchical structure, and uses this structure to guide the generation process. This ensures alignment between memory and the article outline, improving both informativeness and verifiability while minimizing hallucinations. Additionally, a citation module is implemented to enhance traceability by linking every generated sentence to specific memory units. Evaluations on our newly created WikiStart dataset demonstrate that MOG outperforms baseline methods in producing informative and reliable articles, making it particularly robust in real-world scenarios.",
      "authors": [
        "Eugene J. Yu",
        "Dawei Zhu",
        "Yifan Song",
        "Xiangyu Wong",
        "Jiebin Zhang",
        "Wenxuan Shi",
        "Xiaoguang Li",
        "Qun Liu",
        "Sujian Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T20:22:49+00:00",
          "link": "https://arxiv.org/abs/2506.23393v1",
          "size": "299kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Memory Organization for Wikipedia Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23393",
        "HTML": "https://arxiv.org/html/2506.23393v1",
        "PDF": "https://arxiv.org/pdf/2506.23393"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23394",
      "abstract": "External tool integration through function-calling is essential for practical language model applications, yet most multilingual models lack reliable tool-use capabilities in non-English languages. Even state-of-the-art multilingual models struggle with determining when to use tools and generating the structured outputs required for function calls, often exhibiting language confusion when prompted in lower-resource languages. This work presents a methodology for adapting existing language models to enable robust tool use in any target language, using Bulgarian as a case study. The approach involves continued training of the BgGPT model series (2.6B, 9B, 27B parameters) on a novel bilingual dataset of 10,035 function-calling examples designed to support standardized protocols like MCP (Model Context Protocol). The research introduces TUCAN (Tool-Using Capable Assistant Navigator), which achieves up to 28.75% improvement in function-calling accuracy over base models while preserving core language understanding, as verified on established Bulgarian benchmarks. Beyond accuracy gains, TUCAN models demonstrate production-ready response formatting with clean, parsable function calls, contrasting with the verbose and inconsistent outputs of base models. The models, evaluation framework, and dataset are released to enable replication for other languages. This work demonstrates a practical approach for extending tool-augmented capabilities beyond English-centric systems.",
      "authors": [
        "Simeon Emanuilov"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T20:47:27+00:00",
          "link": "https://arxiv.org/abs/2506.23394v1",
          "size": "1358kb",
          "version": "v1"
        }
      ],
      "title": "Teaching a Language Model to Speak the Language of Tools",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23394",
        "PDF": "https://arxiv.org/pdf/2506.23394"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23395",
      "abstract": "FastSet is an actor-based distributed protocol for decentralized finance and settlement, which is inspired from blockchains. Account holders cooperate by making claims, which can include payments, holding and transferring assets, accessing and updating shared data, medical records, digital identity, and mathematical theorems, among many others. The claims are signed by their owners and are broadcast to a decentralized network of validators, which validate and settle them. Validators replicate the global state of the accounts and need not communicate with each other. In sharp contrast to blockchains, strong consistency is purposely given up as a requirement. Yet, many if not most of the blockchain benefits are preserved. The protocol is proved to be correct, despite its massively parallel nature.",
      "authors": [
        "Xiaohong Chen and Grigore Rosu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T20:50:04+00:00",
          "link": "https://arxiv.org/abs/2506.23395v1",
          "size": "117kb",
          "version": "v1"
        }
      ],
      "title": "FastSet: Parallel Claim Settlement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23395",
        "HTML": "https://arxiv.org/html/2506.23395v1",
        "PDF": "https://arxiv.org/pdf/2506.23395"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23397",
      "abstract": "There is an increasing demand for extending existing DBMSs with vector indices so that they become unified systems capable of supporting modern predictive applications, which require joint querying of vector embeddings together with the structured properties and connections of objects. We present NaviX, a native vector index for graph DBMSs (GDBMSs) that has two main design goals. First, we aim to implement a disk-based vector index that leverages the core storage and query-processing capabilities of the underlying GDBMS. To this end, NaviX is built on the Hierarchical Navigable Small-World (HNSW) graph, which itself is a graph-based structure. Second, we aim to support predicate-agnostic filtered vector search queries, in which the k nearest neighbors (kNNs) of a query vector vQ are searched only within an arbitrary subset S of vectors defined by an ad-hoc selection sub-query QS. We adopt a prefiltering approach that evaluates QS first and passes the full description of subset S to the kNN search operator. We study how to design a prefiltering search algorithm that remains robust under varying selectivities and under different correlations between subset S and query vector vQ. We propose an adaptive algorithm that uses the local selectivity of each vector in the HNSW graph to choose an appropriate heuristic at every iteration of the kNN search. Finally, We demonstrate NaviX's robustness and efficiency through extensive experiments against both existing prefiltering- and postfiltering-based baselines.",
      "authors": [
        "Gaurav Sehgal and Semih Salihoglu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T21:16:07+00:00",
          "link": "https://arxiv.org/abs/2506.23397v1",
          "size": "18599kb",
          "version": "v1"
        }
      ],
      "title": "NaviX: A Native Vector Index Design for Graph DBMSs With Robust Predicate-Agnostic Search Performance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23397",
        "HTML": "https://arxiv.org/html/2506.23397v1",
        "PDF": "https://arxiv.org/pdf/2506.23397"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23399",
      "abstract": "We consider the \\textsc{Edge Multiway Cut} problem on planar graphs. It is known that this can be solved in $n^{O(\\sqrt{t})}$ time [Klein, Marx, ICALP 2012] and not in $n^{o(\\sqrt{t})}$ time under the Exponential Time Hypothesis [Marx, ICALP 2012], where $t$ is the number of terminals. A stronger parameter is the number $k$ of faces of the planar graph that jointly cover all terminals. For the related {\\sc Steiner Tree} problem, an $n^{O(\\sqrt{k})}$ time algorithm was recently shown [Kisfaludi-Bak et al., SODA 2019]. By a completely different approach, we prove in this paper that \\textsc{Edge Multiway Cut} can be solved in $n^{O(\\sqrt{k})}$ time as well.\n  Our approach employs several major concepts on planar graphs, including homotopy and sphere-cut decomposition. We also mix a global treewidth dynamic program with a Dreyfus-Wagner style dynamic program to locally deal with large numbers of terminals.",
      "authors": [
        "Sukanya Pandey and Erik Jan van Leeuwen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T21:24:35+00:00",
          "link": "https://arxiv.org/abs/2506.23399v1",
          "size": "666kb",
          "version": "v1"
        }
      ],
      "title": "Planar Multiway Cut with Terminals on Few Faces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23399",
        "PDF": "https://arxiv.org/pdf/2506.23399"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23400",
      "abstract": "In recent years, the demand for customized, on-demand production has grown in the manufacturing sector. Additive Manufacturing (AM) has emerged as a promising technology to enhance customization capabilities, enabling greater flexibility, reduced lead times, and more efficient material usage. However, traditional AM systems remain constrained by static setups and human worker dependencies, resulting in long lead times and limited scalability. Mobile robots can improve the flexibility of production systems by transporting products to designated locations in a dynamic environment. By integrating AM systems with mobile robots, manufacturers can optimize travel time for preparatory tasks and distributed printing operations. Mobile AM robots have been deployed for on-site production of large-scale structures, but often neglect critical print quality metrics like surface roughness. Additionally, these systems do not have the precision necessary for producing small, intricate components. We propose a model predictive control framework for a mobile AM platform that ensures safe navigation on the plant floor while maintaining high print quality in a dynamic environment. Three case studies are used to test the feasibility and reliability of the proposed systems.",
      "authors": [
        "Yifei Li",
        "Joshua A. Robbins",
        "Guha Manogharan",
        "Herschel C. Pangborn and Ilya Kovalenko"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T21:25:46+00:00",
          "link": "https://arxiv.org/abs/2506.23400v1",
          "size": "3480kb",
          "version": "v1"
        }
      ],
      "title": "A Model Predictive Control Framework to Enhance Safety and Quality in Mobile Additive Manufacturing Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23400",
        "HTML": "https://arxiv.org/html/2506.23400v1",
        "PDF": "https://arxiv.org/pdf/2506.23400"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23404",
      "abstract": "In this paper, we provide a uniform framework for investigating small circuit classes and bounds through the lens of ordinary differential equations (ODEs). Following an approach recently introduced to capture the class of polynomial-time computable functions via ODE-based recursion schemas and later applied to the context of functions computed by unbounded fan-in circuits of constant depth (FAC^0), we study multiple relevant small circuit classes. In particular, we show that natural restrictions on linearity and derivation along functions with specific growth rate correspond to kinds of functions that can be proved to be in various classes, ranging from FAC^0 to FAC^1. This reveals an intriguing link between constraints over linear-length ODEs and circuit computation, providing new tools to tackle the complex challenge of establishing bounds for classes in the circuit hierarchies and possibly enhancing our understanding of the role of counters in this setting. Additionally, we establish several completeness results, in particular obtaining the first ODE-based characterizations for the classes of functions computable in constant depth with unbounded fan-in and Mod 2 gates (FACC[2]) and in logarithmic depth with bounded fan-in Boolean gates (FNC1).",
      "authors": [
        "Melissa Antonelli",
        "Arnaud Durand",
        "Juha Kontinen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Complexity (cs.CC)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T21:31:12+00:00",
          "link": "https://arxiv.org/abs/2506.23404v1",
          "size": "55kb",
          "version": "v1"
        }
      ],
      "title": "Characterizing Small Circuit Classes from FAC^0 to FAC^1 via Discrete Ordinary Differential Equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23404",
        "HTML": "https://arxiv.org/html/2506.23404v1",
        "PDF": "https://arxiv.org/pdf/2506.23404"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23405",
      "abstract": "In contemporary general-purpose graphics processing units (GPGPUs), the continued increase in raw arithmetic throughput is constrained by the capabilities of the register file (single-cycle) and last-level cache (high bandwidth), which require the delivery of operands at a cadence demanded by wide single-instruction multiple-data (SIMD) lanes. Enhancing the capacity, density, or bandwidth of these memories can unlock substantial performance gains; however, the recent stagnation of SRAM bit-cell scaling leads to inequivalent losses in compute density.\n  To address the challenges posed by SRAM's scaling and leakage power consumption, this paper explores the potential CMOS+X integration of amorphous oxide semiconductor (AOS) transistors in capacitive, persistent memory topologies (e.g., 1T1C eDRAM, 2T0C/3T0C Gain Cell) as alternative cells in multi-ported and high-bandwidth banked GPGPU memories. A detailed study of the density and energy tradeoffs of back-end-of-line (BEOL) integrated memories utilizing monolithic 3D (M3D)-integrated multiplexed arrays is conducted, while accounting for the macro-level limitations of integrating AOS candidate structures proposed by the device community (an aspect often overlooked in prior work). By exploiting the short lifetime of register operands, we propose a multi-ported AOS gain-cell capable of delivering 3x the read ports in ~76% of the footprint of SRAM with over 70% lower standby power, enabling enhancements to compute capacity, such as larger warp sizes or processor counts. Benchmarks run on a validated NVIDIA Ampere-class GPU model, using a modified version of Accel-Sim, demonstrate improvements of up to 5.2x the performance per watt and an average 8% higher geometric mean instruction per cycle (IPC) on various compute- and memory-bound tasks.",
      "authors": [
        "Faaiq Waqar",
        "Ming-Yen Lee",
        "Seongwon Yoon",
        "Seongkwang Lim",
        "Shimeng Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T21:55:58+00:00",
          "link": "https://arxiv.org/abs/2506.23405v1",
          "size": "9213kb",
          "version": "v1"
        }
      ],
      "title": "CMOS+X: Stacking Persistent Embedded Memories based on Oxide Transistors upon GPGPU Platforms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23405",
        "PDF": "https://arxiv.org/pdf/2506.23405"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23406",
      "abstract": "The analysis of 3D symmetric second-order tensor fields often relies on topological features such as degenerate tensor lines, neutral surfaces, and their generalization to mode surfaces, which reveal important structural insights into the data. However, uncertainty in such fields is typically visualized using derived scalar attributes or tensor glyph representations, which often fail to capture the global behavior. Recent advances have introduced uncertain topological features for tensor field ensembles by focusing on degenerate tensor locations. Yet, mode surfaces, including neutral surfaces and arbitrary mode surfaces are essential to a comprehensive understanding of tensor field topology. In this work, we present a generalization of uncertain degenerate tensor features to uncertain mode surfaces of arbitrary mode values, encompassing uncertain degenerate tensor lines as a special case. Our approach supports both surface and line geometries, forming a unified framework for analyzing uncertain mode-based topological features in tensor field ensembles. We demonstrate the effectiveness of our method on several real-world simulation datasets from engineering and materials science.",
      "authors": [
        "Tim Gerrits"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T21:58:24+00:00",
          "link": "https://arxiv.org/abs/2506.23406v1",
          "size": "4355kb",
          "version": "v1"
        }
      ],
      "title": "Uncertain Mode Surfaces in 3D Symmetric Second-Order Tensor Field Ensembles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23406",
        "HTML": "https://arxiv.org/html/2506.23406v1",
        "PDF": "https://arxiv.org/pdf/2506.23406"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23407",
      "abstract": "We implement a compile toolchain from Q# to QASM 3.0 including a full-featured lexer and parser implementation, as well as a compiler that supports a subset of Q# features. The lexer, parser and compiler are shown to work with various input Q# programs and the implementation is compared against existing Q# compile tools. Unlike the Microsoft implementation of the official Q# compile toolchain, our implementation is written in TypeScript in order to port functionality to web environments.",
      "authors": [
        "Marcus Edwards"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Programming Languages (cs.PL)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T22:02:57+00:00",
          "link": "https://arxiv.org/abs/2506.23407v1",
          "size": "10kb",
          "version": "v1"
        }
      ],
      "title": "Compiling a Q# Subset to QASM 3.0 in TypeScript via a JSON Based IR",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23407",
        "HTML": "https://arxiv.org/html/2506.23407v1",
        "PDF": "https://arxiv.org/pdf/2506.23407"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23408",
      "abstract": "Large Language Models (LLMs) have rapidly transformed the landscape of artificial intelligence, enabling natural language interfaces and dynamic orchestration of software components. However, their reliance on probabilistic inference limits their effectiveness in domains requiring strict logical reasoning, discrete decision-making, and robust interpretability. This paper investigates these limitations and proposes a neurosymbolic approach that augments LLMs with logic-based reasoning modules, particularly leveraging Prolog predicates and composable toolsets. By integrating first-order logic and explicit rule systems, our framework enables LLMs to decompose complex queries into verifiable sub-tasks, orchestrate reliable solutions, and mitigate common failure modes such as hallucination and incorrect step decomposition. We demonstrate the practical benefits of this hybrid architecture through experiments on the DABStep benchmark, showing improved precision, coverage, and system documentation in multi-step reasoning tasks. Our results indicate that combining LLMs with modular logic reasoning restores engineering rigor, enhances system reliability, and offers a scalable path toward trustworthy, interpretable AI agents across complex domains.",
      "authors": [
        "Claudionor Coelho Jr and Yanen Li and Philip Tee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T22:03:01+00:00",
          "link": "https://arxiv.org/abs/2506.23408v1",
          "size": "5692kb",
          "version": "v1"
        }
      ],
      "title": "Do LLMs Dream of Discrete Algorithms?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23408",
        "HTML": "https://arxiv.org/html/2506.23408v1",
        "PDF": "https://arxiv.org/pdf/2506.23408"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23411",
      "abstract": "Fairness benchmarks play a central role in shaping how we evaluate language models, yet surprisingly little attention has been given to examining the datasets that these benchmarks rely on. This survey addresses that gap by presenting a broad and careful review of the most widely used fairness datasets in current language model research, characterizing them along several key dimensions including their origin, scope, content, and intended use to help researchers better appreciate the assumptions and limitations embedded in these resources. To support more meaningful comparisons and analyses, we introduce a unified evaluation framework that reveals consistent patterns of demographic disparities across datasets and scoring methods. Applying this framework to twenty four common benchmarks, we highlight the often overlooked biases that can influence conclusions about model fairness and offer practical guidance for selecting, combining, and interpreting these datasets. We also point to opportunities for creating new fairness benchmarks that reflect more diverse social contexts and encourage more thoughtful use of these tools going forward. All code, data, and detailed results are publicly available at https://github.com/vanbanTruong/Fairness-in-Large-Language-Models/tree/main/datasets to promote transparency and reproducibility across the research community.",
      "authors": [
        "Jiale Zhang",
        "Zichong Wang",
        "Avash Palikhe",
        "Zhipeng Yin",
        "Wenbin Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T22:11:58+00:00",
          "link": "https://arxiv.org/abs/2506.23411v1",
          "size": "18548kb",
          "version": "v1"
        }
      ],
      "title": "Datasets for Fairness in Language Models: An In-Depth Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23411",
        "HTML": "https://arxiv.org/html/2506.23411v1",
        "PDF": "https://arxiv.org/pdf/2506.23411"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23414",
      "abstract": "Smartphone-based heart rate (HR) monitoring apps using finger-over-camera photoplethysmography (PPG) face significant challenges in performance evaluation and device compatibility due to device variability and fragmentation. Manual testing is impractical, and standardized methods are lacking. This paper presents a novel, high-throughput bench-testing platform to address this critical need. We designed a system comprising a test rig capable of holding 12 smartphones for parallel testing, a method for generating synthetic PPG test videos with controllable HR and signal quality, and a host machine for coordinating video playback and data logging. The system achieved a mean absolute percentage error (MAPE) of 0.11% +/- 0.001% between input and measured HR, and a correlation coefficient of 0.92 +/- 0.008 between input and measured PPG signals using a clinically-validated smartphone-based HR app. Bench-testing results of 20 different smartphone models correctly classified all the devices as meeting the ANSI/CTA accuracy standards for HR monitors (MAPE <10%) when compared to a prospective clinical study with 80 participants, demonstrating high positive predictive value. This platform offers a scalable solution for pre-deployment testing of smartphone HR apps to improve app performance, ensure device compatibility, and advance the field of mobile health.",
      "authors": [
        "Ming-Zher Poh",
        "Jonathan Wang",
        "Jonathan Hsu",
        "Lawrence Cai",
        "Eric Teasley",
        "James A. Taylor",
        "Jameson K. Rogers",
        "Anupam Pathak",
        "Shwetak Patel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T22:19:40+00:00",
          "link": "https://arxiv.org/abs/2506.23414v1",
          "size": "8210kb",
          "version": "v1"
        }
      ],
      "title": "A High-Throughput Platform to Bench Test Smartphone-Based Heart Rate Measurements Derived From Video",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23414",
        "HTML": "https://arxiv.org/html/2506.23414v1",
        "PDF": "https://arxiv.org/pdf/2506.23414"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23418",
      "abstract": "Despite the ability of text-to-image models to generate high-quality, realistic, and diverse images, they face challenges in compositional generation, often struggling to accurately represent details specified in the input prompt. A prevalent issue in compositional generation is the misalignment of spatial relationships, as models often fail to faithfully generate images that reflect the spatial configurations specified between objects in the input prompts. To address this challenge, we propose a novel probabilistic framework for modeling the relative spatial positioning of objects in a scene, leveraging the concept of Probability of Superiority (PoS). Building on this insight, we make two key contributions. First, we introduce a novel evaluation metric, PoS-based Evaluation (PSE), designed to assess the alignment of 2D and 3D spatial relationships between text and image, with improved adherence to human judgment. Second, we propose PoS-based Generation (PSG), an inference-time method that improves the alignment of 2D and 3D spatial relationships in T2I models without requiring fine-tuning. PSG employs a Part-of-Speech PoS-based reward function that can be utilized in two distinct ways: (1) as a gradient-based guidance mechanism applied to the cross-attention maps during the denoising steps, or (2) as a search-based strategy that evaluates a set of initial noise vectors to select the best one. Extensive experiments demonstrate that the PSE metric exhibits stronger alignment with human judgment compared to traditional center-based metrics, providing a more nuanced and reliable measure of complex spatial relationship accuracy in text-image alignment. Furthermore, PSG significantly enhances the ability of text-to-image models to generate images with specified spatial configurations, outperforming state-of-the-art methods across multiple evaluation metrics and benchmarks.",
      "authors": [
        "Parham Rezaei and Arash Marioriyad and Mahdieh Soleymani Baghshah and Mohammad Hossein Rohban"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T22:41:27+00:00",
          "link": "https://arxiv.org/abs/2506.23418v1",
          "size": "7503kb",
          "version": "v1"
        }
      ],
      "title": "Why Settle for Mid: A Probabilistic Viewpoint to Spatial Relationship Alignment in Text-to-image Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23418",
        "HTML": "https://arxiv.org/html/2506.23418v1",
        "PDF": "https://arxiv.org/pdf/2506.23418"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23419",
      "abstract": "Benchmark data sets are a cornerstone of machine learning development and applications, ensuring new methods are robust, reliable and competitive. The relative rarity of benchmark sets in computational science, due to the uniqueness of the problems and the pace of change in the associated domains, makes evaluating new innovations difficult for computational scientists. In this paper a new tool is developed and tested to potentially turn any of the increasing numbers of scientific data sets made openly available into a benchmark accessible to the community. BenchMake uses non-negative matrix factorisation to deterministically identify and isolate challenging edge cases on the convex hull (the smallest convex set that contains all existing data instances) and partitions a required fraction of matched data instances into a testing set that maximises divergence and statistical significance, across tabular, graph, image, signal and textual modalities. BenchMake splits are compared to establish splits and random splits using ten publicly available benchmark sets from different areas of science, with different sizes, shapes, distributions.",
      "authors": [
        "Amanda S Barnard"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Digital Libraries (cs.DL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T22:56:48+00:00",
          "link": "https://arxiv.org/abs/2506.23419v1",
          "size": "40196kb",
          "version": "v1"
        }
      ],
      "title": "BenchMake: Turn any scientific data set into a reproducible benchmark",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23419",
        "HTML": "https://arxiv.org/html/2506.23419v1",
        "PDF": "https://arxiv.org/pdf/2506.23419"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23420",
      "abstract": "Spinodoid architected materials have drawn significant attention due to their unique nature in stochasticity, aperiodicity, and bi-continuity. Compared to classic periodic truss-, beam- and plate-based lattice architectures, spinodoids are insensitive to manufacturing defects, scalable for high throughput production, functionally graded by tunable local properties, and material failure resistant due to low-curvature morphology. However, the design of spinodoids is often hindered by the curse of dimensionality with extremely large design space of spinodoid types, material density, orientation, continuity, and anisotropy. From a design optimization perspective, while genetic algorithms are often beyond the reach of computing capacity, gradient-based topology optimization is challenged by the intricate mathematical derivation of gradient fields with respect to various spinodoid parameters. To address such challenges, we propose a data-driven multiscale topology optimization framework. Our framework reformulates the design variables of spinodoid materials as the parameters of neural networks, enabling automated computation of topological gradients. Additionally, it incorporates a Gaussian Process surrogate for spinodoid constitutive models, eliminating the need for repeated computational homogenization and enhancing the scalability of multiscale topology optimization. Compared to 'black-box' deep learning approaches, the proposed framework provides clear physical insights into material distribution. It explicitly reveals why anisotropic spinodoids with tailored orientations are favored in certain regions, while isotropic spinodoids are more suitable elsewhere. This interpretability helps to bridge the gap between data-driven design with mechanistic understanding.",
      "authors": [
        "Shiguang Deng",
        "Doksoo Lee",
        "Aaditya Chandrasekhar",
        "Stefan Knapik",
        "Liwei Wang",
        "Horacio D. Espinosa",
        "Wei Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T23:01:45+00:00",
          "link": "https://arxiv.org/abs/2506.23420v1",
          "size": "3315kb",
          "version": "v1"
        }
      ],
      "title": "Data-Driven Multiscale Topology Optimization of Spinodoid Architected Materials with Controllable Anisotropy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23420",
        "PDF": "https://arxiv.org/pdf/2506.23420"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23421",
      "abstract": "The stochastic nature of time delays and sampling intervals in Networked Control Systems poses significant challenges for controller synthesis and analysis, often leading to conservative designs and degraded performance. This work presents a modeling approach for Linear Multiple-Input Multiple-Output Networked Control Systems and introduces a compensation scheme based on the Filtered Smith Predictor to mitigate the adverse effects of stochastic time delays on closed-loop performance. The proposed scheme is evaluated through numerical simulations of a well-established Cooperative Adaptive Cruise Control system. Results demonstrate that the compensator achieves near-ideal average closed-loop performance and significantly reduces response variability compared to a traditional Filtered Smith Predictor. Notably, it yields a 45% reduction in worst-case tracking error signal energy relative to an ideal baseline system with no time delays and constant sampling intervals.",
      "authors": [
        "Matheus Wagner",
        "Marcelo M. Morato",
        "Ant\\^onio Augusto Fr\\\"ohlich",
        "Julio E. Normey-Rico"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T23:05:46+00:00",
          "link": "https://arxiv.org/abs/2506.23421v1",
          "size": "4012kb",
          "version": "v1"
        }
      ],
      "title": "Predictor-Based Compensators for Networked Control Systems with Stochastic Delays and Sampling Intervals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23421",
        "HTML": "https://arxiv.org/html/2506.23421v1",
        "PDF": "https://arxiv.org/pdf/2506.23421"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23422",
      "abstract": "Functionally Graded Materials (FGMs) made of soft constituents have emerged as promising material-structure systems in potential applications across many engineering disciplines, such as soft robots, actuators, energy harvesting, and tissue engineering. Designing such systems remains challenging due to their multiscale architectures, multiple material phases, and inherent material and geometric nonlinearities. The focus of this paper is to propose a general topology optimization framework that automates the design innovation of multiscale soft FGMs exhibiting nonlinear material behaviors under large deformations. Our proposed topology optimization framework integrates several key innovations: (1) a novel microstructure reconstruction algorithm that generates composite architecture materials from a reduced design space using physically interpretable parameters; (2) a new material homogenization approach that estimates effective properties by combining the stored energy functions of multiple soft constituents; (3) a neural network-based topology optimization that incorporates data-driven material surrogates to enable bottom-up, simultaneous optimization of material and structure; and (4) a generic nonlinear sensitivity analysis technique that computes design sensitivities numerically without requiring explicit gradient derivation. To enhance the convergence of the nonlinear equilibrium equations amid topology optimization, we introduce an energy interpolation scheme and employ a Newton-Raphson solver with adaptive step sizes and convergence criteria. Numerical experiments show that the proposed framework produces distinct topological designs, different from those obtained under linear elasticity, with spatially varying microstructures.",
      "authors": [
        "Shiguang Deng",
        "Horacio D. Espinosa",
        "Wei Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T23:08:00+00:00",
          "link": "https://arxiv.org/abs/2506.23422v1",
          "size": "5317kb",
          "version": "v1"
        }
      ],
      "title": "Data-Driven Multiscale Topology Optimization of Soft Functionally Graded Materials with Large Deformations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23422",
        "PDF": "https://arxiv.org/pdf/2506.23422"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23423",
      "abstract": "Past work has studied the effects of fine-tuning on large language models' (LLMs) overall performance on certain tasks. However, a quantitative and systematic method for analyzing its effect on individual outputs is still lacking. Here, we propose a new method for measuring the contribution that fine-tuning makes to individual LLM responses, assuming access to the original pre-trained model. Our method tracks the model's intermediate hidden states, providing a more fine-grained insight into the effects of fine-tuning than a simple comparison of final outputs from pre-trained and fine-tuned models. We introduce and theoretically analyze an exact decomposition of any fine-tuned LLM into a pre-training component and a fine-tuning component. Empirically, we find that model behavior and performance can be steered by up- or down-scaling the fine-tuning component during the forward pass. Motivated by this finding and our theoretical analysis, we define the Tuning Contribution (TuCo) as the ratio of the magnitudes of the fine-tuning component to the pre-training component. We observe that three prominent adversarial attacks on LLMs circumvent safety measures in a way that reduces TuCo, and that TuCo is consistently lower on prompts where these attacks succeed compared to those where they do not. This suggests that attenuating the effect of fine-tuning on model outputs plays a role in the success of such attacks. In summary, TuCo enables the quantitative study of how fine-tuning influences model behavior and safety, and vice versa.",
      "authors": [
        "Felipe Nuti",
        "Tim Franzmeyer",
        "Jo\\~ao Henriques"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T23:08:36+00:00",
          "link": "https://arxiv.org/abs/2506.23423v1",
          "size": "971kb",
          "version": "v1"
        }
      ],
      "title": "TuCo: Measuring the Contribution of Fine-Tuning to Individual Responses of LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23423",
        "HTML": "https://arxiv.org/html/2506.23423v1",
        "PDF": "https://arxiv.org/pdf/2506.23423"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23424",
      "abstract": "Real-world time series often exhibit a non-stationary nature, degrading the performance of pre-trained forecasting models. Test-Time Adaptation (TTA) addresses this by adjusting models during inference, but existing methods typically update the full model, increasing memory and compute costs. We propose PETSA, a parameter-efficient method that adapts forecasters at test time by only updating small calibration modules on the input and output. PETSA uses low-rank adapters and dynamic gating to adjust representations without retraining. To maintain accuracy despite limited adaptation capacity, we introduce a specialized loss combining three components: (1) a robust term, (2) a frequency-domain term to preserve periodicity, and (3) a patch-wise structural term for structural alignment. PETSA improves the adaptability of various forecasting backbones while requiring fewer parameters than baselines. Experimental results on benchmark datasets show that PETSA achieves competitive or better performance across all horizons. Our code is available at: https://github.com/BorealisAI/PETSA",
      "authors": [
        "Heitor R. Medeiros",
        "Hossein Sharifi-Noghabi",
        "Gabriel L. Oliveira",
        "Saghar Irandoust"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T23:09:35+00:00",
          "link": "https://arxiv.org/abs/2506.23424v1",
          "size": "1729kb",
          "version": "v1"
        }
      ],
      "title": "Accurate Parameter-Efficient Test-Time Adaptation for Time Series Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23424",
        "HTML": "https://arxiv.org/html/2506.23424v1",
        "PDF": "https://arxiv.org/pdf/2506.23424"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23425",
      "abstract": "Load flow analysis is a fundamental technique used by electrical engineers to simulate and evaluate power system behavior under steady-state conditions. It enables efficient operation and control by determining how active and reactive power flows throughout the system. Selecting an appropriate solution method is critical to ensuring reliable and economical operation of power generation, transmission, and distribution networks. While the conventional loop method may be used in small-scale systems, it is limited by its reliance on impedance-based load data and its inability to scale to complex networks. In contrast, iterative techniques such as the Gauss-Seidel (GS) and Newton-Raphson (NR) methods are better suited for analyzing large systems. Of these, the NR method offers significant advantages due to its quadratic convergence and improved numerical stability. This study presents a power flow analysis of a 5-bus system using the Newton-Raphson approach. The system was modeled and simulated in PowerWorld Simulator (PWS), and a custom MATLAB implementation was developed to verify the results under a base case scenario. The comparative analysis demonstrates that the NR method provides accurate and robust solutions for power flow problems, making it well-suited for evaluating system performance under various operating conditions.",
      "authors": [
        "Sampson E. Nwachukwu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T23:15:51+00:00",
          "link": "https://arxiv.org/abs/2506.23425v1",
          "size": "1497kb",
          "version": "v1"
        }
      ],
      "title": "Power Flow Analysis of a 5-Bus Power System Based on Newton-Raphson Method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23425",
        "PDF": "https://arxiv.org/pdf/2506.23425"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23426",
      "abstract": "Autonomous vehicles (AVs) use object detection models to recognize their surroundings and make driving decisions accordingly. Conventional object detection approaches classify objects into known classes, which limits the AV's ability to detect and appropriately respond to Out-of-Distribution (OOD) objects. This problem is a significant safety concern since the AV may fail to detect objects or misclassify them, which can potentially lead to hazardous situations such as accidents. Consequently, we propose a novel object detection approach that shifts the emphasis from conventional class-based classification to object harmfulness determination. Instead of object detection by their specific class, our method identifies them as either 'harmful' or 'harmless' based on whether they pose a danger to the AV. This is done based on the object position relative to the AV and its trajectory. With this metric, our model can effectively detect previously unseen objects to enable the AV to make safer real-time decisions. Our results demonstrate that the proposed model effectively detects OOD objects, evaluates their harmfulness, and classifies them accordingly, thus enhancing the AV decision-making effectiveness in dynamic environments.",
      "authors": [
        "Menna Taha (1)",
        "Aya Ahmed (2)",
        "Mohammed Karmoose (1 and 3)",
        "Yasser Gadallah (2) ((1) Faculty of Engineering at Alexandria University",
        "Alexandria",
        "Egypt",
        "(2) Department of Electronics and Communications Engineering at The American University in Cairo",
        "Egypt",
        "(3) The Wireless Intelligent Networks Center (WINC)",
        "School of Engineering and Applied Sciences (EAS)",
        "Nile University",
        "Giza",
        "Egypt)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T23:21:05+00:00",
          "link": "https://arxiv.org/abs/2506.23426v1",
          "size": "11283kb",
          "version": "v1"
        }
      ],
      "title": "Detecting What Matters: A Novel Approach for Out-of-Distribution 3D Object Detection in Autonomous Vehicles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23426",
        "HTML": "https://arxiv.org/html/2506.23426v1",
        "PDF": "https://arxiv.org/pdf/2506.23426"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23431",
      "abstract": "As the basis of generative AI, an autoregressive model requires the generation of a new token depending on all the previously generated tokens, which brings high quality but also restricts the model to generate tokens one by one, forming a bottleneck limiting the generation speed. In this paper, we propose a new decoder architecture that efficiently generates text in parallel for context-aware generation tasks. Our proposed pipelined decoder initiates the generation of multiple subsequences simultaneously, and, at each time-step, it generates a new token for each subsequence to realize parallelism. Experiments on multiple text generation tasks, including question answering, text summarization, and keyphrase generation, show that our pipelined decoder significantly improves the generation speed without a significant loss of generation quality or additional memory consumption.",
      "authors": [
        "Zixian Huang",
        "Chenxu Niu",
        "Yu Gu",
        "Gengyang Xiao",
        "Xinwei Huang",
        "Gong Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T23:37:24+00:00",
          "link": "https://arxiv.org/abs/2506.23431v1",
          "size": "246kb",
          "version": "v1"
        }
      ],
      "title": "Pipelined Decoder for Efficient Context-Aware Text Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23431",
        "HTML": "https://arxiv.org/html/2506.23431v1",
        "PDF": "https://arxiv.org/pdf/2506.23431"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23433",
      "abstract": "Improving automated vehicle software requires driving data rich in valuable road user interactions. In this paper, we propose a risk-based filtering approach that helps identify such valuable driving situations from large datasets. Specifically, we use a probabilistic risk model to detect high-risk situations. Our method stands out by considering a) first-order situations (where one vehicle directly influences another and induces risk) and b) second-order situations (where influence propagates through an intermediary vehicle). In experiments, we show that our approach effectively selects valuable driving situations in the Waymo Open Motion Dataset. Compared to the two baseline interaction metrics of Kalman difficulty and Tracks-To-Predict (TTP), our filtering approach identifies complex and complementary situations, enriching the quality in automated vehicle testing. The risk data is made open-source: https://github.com/HRI-EU/RiskBasedFiltering.",
      "authors": [
        "Tim Puphal",
        "Vipul Ramtekkar and Kenji Nishimiya"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T00:16:11+00:00",
          "link": "https://arxiv.org/abs/2506.23433v1",
          "size": "676kb",
          "version": "v1"
        }
      ],
      "title": "Risk-Based Filtering of Valuable Driving Situations in the Waymo Open Motion Dataset",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23433",
        "HTML": "https://arxiv.org/html/2506.23433v1",
        "PDF": "https://arxiv.org/pdf/2506.23433"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23434",
      "abstract": "LiDAR-based world models offer more structured and geometry-aware representations than their image-based counterparts. However, existing LiDAR world models are narrowly trained; each model excels only in the domain for which it was built. Can we develop LiDAR world models that exhibit strong transferability across multiple domains? We conduct the first systematic domain transfer study across three demanding scenarios: (i) outdoor to indoor generalization, (ii) sparse-beam \\& dense-beam adaptation, and (iii) non-semantic to semantic transfer. Given different amounts of fine-tuning data, our experiments show that a single pre-trained model can achieve up to 11% absolute improvement (83\\% relative) over training from scratch and outperforms training from scratch in 30/36 of our comparisons. This transferability of dynamic learning significantly reduces the reliance on manually annotated data for semantic occupancy forecasting: our method exceed the previous semantic occupancy forecasting models with only 5% of the labeled training data required by prior models. We also observed inefficiencies of current LiDAR world models, mainly through their under-compression of LiDAR data and inefficient training objectives. To address this, we propose a latent conditional flow matching (CFM)-based frameworks that achieves state-of-the-art reconstruction accuracy using only half the training data and a compression ratio 6 times higher than that of prior methods. Our model achieves SOTA performance on future-trajectory-conditioned semantic occupancy forecasting while being 23x more computationally efficient (a 28x FPS speedup); and achieves SOTA performance on semantic occupancy forecasting while being 2x more computationally efficient (a 1.1x FPS speedup).",
      "authors": [
        "Tianran Liu",
        "Shengwen Zhao",
        "Nicholas Rhinehart"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T00:16:55+00:00",
          "link": "https://arxiv.org/abs/2506.23434v1",
          "size": "35206kb",
          "version": "v1"
        }
      ],
      "title": "Towards foundational LiDAR world models with efficient latent flow matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23434",
        "HTML": "https://arxiv.org/html/2506.23434v1",
        "PDF": "https://arxiv.org/pdf/2506.23434"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23435",
      "abstract": "Speedrunning is a competition that emerged from communities of early video games such as Doom (1993). Speedrunners try to finish a game in minimal time. Provably verifying the authenticity of submitted speedruns is an open problem. Traditionally, best-effort speedrun verification is conducted by on-site human observers, forensic audio analysis, or a rigorous mathematical analysis of the game mechanics. Such methods are tedious, fallible, and, perhaps worst of all, not cryptographic. Motivated by naivety and the Dunning-Kruger effect, we attempt to build a system that cryptographically proves the authenticity of speedruns. This paper describes our attempted solutions and ways to circumvent them. Through a narration of our failures, we attempt to demonstrate the difficulty of authenticating live and interactive human input in untrusted environments, as well as the limits of signature schemes, game integrity, and provable play.",
      "authors": [
        "Hayder Tirmazi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T00:19:19+00:00",
          "link": "https://arxiv.org/abs/2506.23435v1",
          "size": "101kb",
          "version": "v1"
        }
      ],
      "title": "All Proof of Work But No Proof of Play",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23435",
        "HTML": "https://arxiv.org/html/2506.23435v1",
        "PDF": "https://arxiv.org/pdf/2506.23435"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23437",
      "abstract": "Accurate recognition of Emergency Vehicle (EV) sirens is critical for the integration of intelligent transportation systems, smart city monitoring systems, and autonomous driving technologies. Modern automatic solutions are limited by the lack of large scale, curated datasets and by the computational demands of state of the art sound event detection models. This work introduces E2PANNs (Efficient Emergency Pre trained Audio Neural Networks), a lightweight Convolutional Neural Network architecture derived from the PANNs framework, specifically optimized for binary EV siren detection. Leveraging our dedicated subset of AudioSet (AudioSet EV) we fine-tune and evaluate E2PANNs across multiple reference datasets and test its viability on embedded hardware. The experimental campaign includes ablation studies, cross-domain benchmarking, and real-time inference deployment on edge device. Interpretability analyses exploiting Guided Backpropagation and ScoreCAM algorithms provide insights into the model internal representations and validate its ability to capture distinct spectrotemporal patterns associated with different types of EV sirens. Real time performance is assessed through frame wise and event based detection metrics, as well as a detailed analysis of false positive activations. Results demonstrate that E2PANNs establish a new state of the art in this research domain, with high computational efficiency, and suitability for edge-based audio monitoring and safety-critical applications.",
      "authors": [
        "Stefano Giacomelli",
        "Marco Giordano",
        "Claudia Rinaldi",
        "Fabio Graziosi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T00:21:07+00:00",
          "link": "https://arxiv.org/abs/2506.23437v1",
          "size": "10706kb",
          "version": "v1"
        }
      ],
      "title": "From Large-scale Audio Tagging to Real-Time Explainable Emergency Vehicle Sirens Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23437",
        "HTML": "https://arxiv.org/html/2506.23437v1",
        "PDF": "https://arxiv.org/pdf/2506.23437"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23440",
      "abstract": "Diffusion-based generative models have shown promise in synthesizing histopathology images to address data scarcity caused by privacy constraints. Diagnostic text reports provide high-level semantic descriptions, and masks offer fine-grained spatial structures essential for representing distinct morphological regions. However, public datasets lack paired text and mask data for the same histopathological images, limiting their joint use in image generation. This constraint restricts the ability to fully exploit the benefits of combining both modalities for enhanced control over semantics and spatial details. To overcome this, we propose PathDiff, a diffusion framework that effectively learns from unpaired mask-text data by integrating both modalities into a unified conditioning space. PathDiff allows precise control over structural and contextual features, generating high-quality, semantically accurate images. PathDiff also improves image fidelity, text-image alignment, and faithfulness, enhancing data augmentation for downstream tasks like nuclei segmentation and classification. Extensive experiments demonstrate its superiority over existing methods.",
      "authors": [
        "Mahesh Bhosale",
        "Abdul Wasi",
        "Yuanhao Zhai",
        "Yunjie Tian",
        "Samuel Border",
        "Nan Xi",
        "Pinaki Sarder",
        "Junsong Yuan",
        "David Doermann",
        "Xuan Gong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T00:31:03+00:00",
          "link": "https://arxiv.org/abs/2506.23440v1",
          "size": "10619kb",
          "version": "v1"
        }
      ],
      "title": "PathDiff: Histopathology Image Synthesis with Unpaired Text and Mask Conditions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23440",
        "HTML": "https://arxiv.org/html/2506.23440v1",
        "PDF": "https://arxiv.org/pdf/2506.23440"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23442",
      "abstract": "We address the problem of allocating limited resources in a network under persistent yet statistically unknown adversarial attacks. Each node in the network may be degraded, but not fully disabled, depending on its available defensive resources. The objective is twofold: to minimize total system damage and to reduce cumulative resource allocation and transfer costs over time. We model this challenge as a bi-objective optimization problem and propose a decomposition-based solution that integrates chance-constrained programming with network flow optimization. The framework separates the problem into two interrelated subproblems: determining optimal node-level allocations across time slots, and computing efficient inter-node resource transfers. We theoretically prove the convergence of our method to the optimal solution that would be obtained with full statistical knowledge of the adversary. Extensive simulations demonstrate that our method efficiently learns the adversarial patterns and achieves substantial gains in minimizing both damage and operational costs, comparing three benchmark strategies under various parameter settings.",
      "authors": [
        "Mansoor Davoodi",
        "Setareh Maghsudi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T00:33:42+00:00",
          "link": "https://arxiv.org/abs/2506.23442v1",
          "size": "3848kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Resource Allocation under Adversary Attacks: A Decomposition-Based Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23442",
        "HTML": "https://arxiv.org/html/2506.23442v1",
        "PDF": "https://arxiv.org/pdf/2506.23442"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23443",
      "abstract": "Our work aims to develop new assistive technologies that enable blind or low vision (BLV) people to explore and analyze data readily. At present, barriers exist for BLV people to explore and analyze data, restricting access to government, health and personal data, and limiting employment opportunities. This work explores the co-design and development of an innovative system to support data access, with a focus on the use of refreshable tactile displays (RTDs) and conversational agents. The envisaged system will use a combination of tactile graphics and speech to communicate with BLV users, and proactively assist with data analysis tasks. As well as addressing significant equity gaps, our work expects to produce innovations in assistive technology, multimodal interfaces, dialogue systems, and natural language understanding and generation.",
      "authors": [
        "Samuel Reinders",
        "Munazza Zaib",
        "Matthew Butler",
        "Bongshin Lee",
        "Ingrid Zukerman",
        "Lizhen Qu",
        "Kim Marriott"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T00:35:35+00:00",
          "link": "https://arxiv.org/abs/2506.23443v1",
          "size": "1929kb",
          "version": "v1"
        }
      ],
      "title": "Accessible Data Access and Analysis by People who are Blind or Have Low Vision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23443",
        "HTML": "https://arxiv.org/html/2506.23443v1",
        "PDF": "https://arxiv.org/pdf/2506.23443"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23446",
      "abstract": "Insider threat detection presents unique challenges due to the authorized status of malicious actors and the subtlety of anomalous behaviors. Existing machine learning methods often treat user activity as isolated events, thereby failing to leverage sequential dependencies in user behavior. In this study, we propose a User-Based Sequencing (UBS) methodology, transforming the CERT insider threat dataset into structured temporal sequences suitable for deep sequential modeling. We deploy a Transformer Encoder architecture to model benign user activity and employ its reconstruction errors as anomaly scores. These scores are subsequently evaluated using three unsupervised outlier detection algorithms: One-Class SVM (OCSVM), Local Outlier Factor (LOF), and Isolation Forest (iForest). Across four rigorously designed test sets, including combinations of multiple CERT dataset releases, our UBS-Transformer pipeline consistently achieves state-of-the-art performance - notably 96.61% accuracy, 99.43% recall, 96.38% F1-score, 95.00% AUROC, and exceptionally low false negative (0.0057) and false positive (0.0571) rates. Comparative analyses demonstrate that our approach substantially outperforms tabular and conventional autoencoder baselines, underscoring the efficacy of sequential user modeling and advanced anomaly detection in the insider threat domain.",
      "authors": [
        "Mohamed Elbasheer and Adewale Akinfaderin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T00:47:31+00:00",
          "link": "https://arxiv.org/abs/2506.23446v1",
          "size": "408kb",
          "version": "v1"
        }
      ],
      "title": "Enhancing Insider Threat Detection Using User-Based Sequencing and Transformer Encoders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23446",
        "HTML": "https://arxiv.org/html/2506.23446v1",
        "PDF": "https://arxiv.org/pdf/2506.23446"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23447",
      "abstract": "An efficient approach to universality and optimality of binary codes for integers known as Elias' encoding can be deduced from the classical constrained optimization and renormalization techniques. The most important properties, such as being a universal prefix code, also follow naturally.",
      "authors": [
        "Alexander Kolpakov",
        "Aidan Rocke"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Mathematical Physics (math-ph)",
        "Information Theory (math.IT)",
        "Mathematical Physics (math.MP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T01:01:17+00:00",
          "link": "https://arxiv.org/abs/2506.23447v1",
          "size": "8kb",
          "version": "v1"
        }
      ],
      "title": "Elias' Encoding from Lagrangians and Renormalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23447",
        "HTML": "https://arxiv.org/html/2506.23447v1",
        "PDF": "https://arxiv.org/pdf/2506.23447"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23449",
      "abstract": "This paper proposes and analyzes a finite difference method based on compact schemes for the Euler-Bernoulli beam equation with damping terms. The method achieves fourth-order accuracy in space and second-order accuracy in time, while requiring only three spatial grid points within a single compact stencil. Spatial discretization is carried out using a compact finite difference scheme, with a variable substitution technique employed to reduce the order of the equation and effectively handle the damping terms. For the temporal discretization, the Crank-Nicolson scheme is applied. The consistency, stability, and convergence of the proposed method are rigorously proved. Numerical experiments are presented to verify the theoretical results and demonstrate the accuracy and efficiency of the method.",
      "authors": [
        "Wenjie Huang and Hao Wang and Shiquan Zhang and Qinyi Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T01:21:35+00:00",
          "link": "https://arxiv.org/abs/2506.23449v1",
          "size": "878kb",
          "version": "v1"
        }
      ],
      "title": "Fourth-order compact difference schemes for the one-dimensional Euler-Bernoulli beam equation with damping term",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23449",
        "HTML": "https://arxiv.org/html/2506.23449v1",
        "PDF": "https://arxiv.org/pdf/2506.23449"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23457",
      "abstract": "Autonomous personal mobility vehicles (APMVs) are small mobility devices designed for individual automated transportation in shared spaces. In such environments, frequent pedestrian avoidance maneuvers may cause rapid steering adjustments and passive postural responses from passengers, thereby increasing the risk of motion sickness. This study investigated the effects of providing path information on 16 passengers' head movement behavior and motion sickness while riding an APMV. Through a controlled experiment comparing manual driving (MD), autonomous driving without path information (AD w/o path), and autonomous driving with path information (AD w/ path), we found that providing path cues significantly reduced MISC scores and delayed the onset of motion sickness symptoms. In addition, participants were more likely to proactively align their head movements with the direction of vehicle rotation in both MD and AD w/ path conditions. Although a small correlation was observed between the delay in yaw rotation of the passenger's head relative to the vehicle and the occurrence of motion sickness, the underlying physiological mechanism remains to be elucidated.",
      "authors": [
        "Yuya Ide and Hailong Liu and Takahiro Wada"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T01:36:45+00:00",
          "link": "https://arxiv.org/abs/2506.23457v1",
          "size": "3355kb",
          "version": "v1"
        }
      ],
      "title": "Reducing Motion Sickness in Passengers of Autonomous Personal Mobility Vehicles by Presenting a Driving Path",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23457",
        "HTML": "https://arxiv.org/html/2506.23457v1",
        "PDF": "https://arxiv.org/pdf/2506.23457"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23458",
      "abstract": "Portable and wearable consumer-grade electroencephalography (EEG) devices, like Muse headbands, offer unprecedented mobility for daily brain-computer interface (BCI) applications, including cognitive load detection. However, the exacerbated non-stationarity in portable EEG signals constrains data fidelity and decoding accuracy, creating a fundamental trade-off between portability and performance. To mitigate such limitation, we propose MuseCogNet (Muse-based Cognitive Network), a unified joint learning framework integrating self-supervised and supervised training paradigms. In particular, we introduce an EEG-grounded self-supervised reconstruction loss based on average pooling to capture robust neurophysiological patterns, while cross-entropy loss refines task-specific cognitive discriminants. This joint learning framework resembles the bottom-up and top-down attention in humans, enabling MuseCogNet to significantly outperform state-of-the-art methods on a publicly available Muse dataset and establish an implementable pathway for neurocognitive monitoring in ecological settings.",
      "authors": [
        "Xiaoxiao Yang",
        "Chan Feng",
        "Jiancheng Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T01:42:31+00:00",
          "link": "https://arxiv.org/abs/2506.23458v1",
          "size": "73kb",
          "version": "v1"
        }
      ],
      "title": "Neuro-Informed Joint Learning Enhances Cognitive Workload Decoding in Portable BCIs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23458",
        "HTML": "https://arxiv.org/html/2506.23458v1",
        "PDF": "https://arxiv.org/pdf/2506.23458"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23460",
      "abstract": "Weakly supervised semantic segmentation (WSSS) methods using class labels often rely on class activation maps (CAMs) to localize objects. However, traditional CAM-based methods struggle with partial activations and imprecise object boundaries due to optimization discrepancies between classification and segmentation. Recently, the conditional diffusion model (CDM) has been used as an alternative for generating segmentation masks in WSSS, leveraging its strong image generation capabilities tailored to specific class distributions. By modifying or perturbing the condition during diffusion sampling, the related objects can be highlighted in the generated images. Yet, the saliency maps generated by CDMs are prone to noise from background alterations during reverse diffusion. To alleviate the problem, we introduce Contrastive Learning with Diffusion Features (CLDF), a novel method that uses contrastive learning to train a pixel decoder to map the diffusion features from a frozen CDM to a low-dimensional embedding space for segmentation. Specifically, we integrate gradient maps generated from CDM external classifier with CAMs to identify foreground and background pixels with fewer false positives/negatives for contrastive learning, enabling robust pixel embedding learning. Experimental results on four segmentation tasks from two public medical datasets demonstrate that our method significantly outperforms existing baselines.",
      "authors": [
        "Dewen Zeng",
        "Xinrong Hu",
        "Yu-Jen Chen",
        "Yawen Wu",
        "Xiaowei Xu",
        "Yiyu Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T01:43:50+00:00",
          "link": "https://arxiv.org/abs/2506.23460v1",
          "size": "380kb",
          "version": "v1"
        }
      ],
      "title": "Contrastive Learning with Diffusion Features for Weakly Supervised Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23460",
        "HTML": "https://arxiv.org/html/2506.23460v1",
        "PDF": "https://arxiv.org/pdf/2506.23460"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23461",
      "abstract": "In this work, we focus on a novel and practical task, i.e., Time-vAriant iMage inPainting (TAMP). The aim of TAMP is to restore a damaged target image by leveraging the complementary information from a reference image, where both images captured the same scene but with a significant time gap in between, i.e., time-variant images. Different from conventional reference-guided image inpainting, the reference image under TAMP setup presents significant content distinction to the target image and potentially also suffers from damages. Such an application frequently happens in our daily lives to restore a damaged image by referring to another reference image, where there is no guarantee of the reference image's source and quality. In particular, our study finds that even state-of-the-art (SOTA) reference-guided image inpainting methods fail to achieve plausible results due to the chaotic image complementation. To address such an ill-posed problem, we propose a novel Interactive Distribution Transition Estimation (InDiTE) module which interactively complements the time-variant images with adaptive semantics thus facilitate the restoration of damaged regions. To further boost the performance, we propose our TAMP solution, namely Interactive Distribution Transition Estimation-driven Diffusion (InDiTE-Diff), which integrates InDiTE with SOTA diffusion model and conducts latent cross-reference during sampling. Moreover, considering the lack of benchmarks for TAMP task, we newly assembled a dataset, i.e., TAMP-Street, based on existing image and mask datasets. We conduct experiments on the TAMP-Street datasets under two different time-variant image inpainting settings, which show our method consistently outperform SOTA reference-guided image inpainting methods for solving TAMP.",
      "authors": [
        "Yun Xing",
        "Qing Guo",
        "Xiaoguang Li",
        "Yihao Huang",
        "Xiaofeng Cao",
        "Di Lin",
        "Ivor Tsang",
        "Lei Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T01:45:33+00:00",
          "link": "https://arxiv.org/abs/2506.23461v1",
          "size": "49400kb",
          "version": "v1"
        }
      ],
      "title": "Time-variant Image Inpainting via Interactive Distribution Transition Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23461",
        "HTML": "https://arxiv.org/html/2506.23461v1",
        "PDF": "https://arxiv.org/pdf/2506.23461"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23462",
      "abstract": "Effective disaster management requires timely and accurate insights, yet traditional methods struggle to integrate multimodal data such as images, weather records, and textual reports. To address this, we propose DisasterNet-LLM, a specialized Large Language Model (LLM) designed for comprehensive disaster analysis. By leveraging advanced pretraining, cross-modal attention mechanisms, and adaptive transformers, DisasterNet-LLM excels in disaster classification. Experimental results demonstrate its superiority over state-of-the-art models, achieving higher accuracy of 89.5%, an F1 score of 88.0%, AUC of 0.92%, and BERTScore of 0.88% in multimodal disaster classification tasks.",
      "authors": [
        "Manaswi Kulahara",
        "Gautam Siddharth Kashyap",
        "Nipun Joshi",
        "Arpita Soni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T01:56:05+00:00",
          "link": "https://arxiv.org/abs/2506.23462v1",
          "size": "243kb",
          "version": "v1"
        }
      ],
      "title": "Can We Predict the Unpredictable? Leveraging DisasterNet-LLM for Multimodal Disaster Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23462",
        "HTML": "https://arxiv.org/html/2506.23462v1",
        "PDF": "https://arxiv.org/pdf/2506.23462"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23463",
      "abstract": "Large language models (LLMs) for table-based reasoning often struggle with large tables due to input length limits. We propose ATF (Adaptive Table Filtering Framework), a modular and question-aware filtering pipeline that prunes uninformative columns and rows using LLM-generated column descriptions, clustering, and sparse-dense alignment scores. ATF integrates seamlessly with existing models (e.g., TAPAS, TAPEX) without retraining. Experiments show that ATF reduces table cells by ~70\\%, boosting performance on out-of-domain TableQA tasks while causing slight performance drops on Table Fact Verification, where full-table context is more critical. These results highlight ATF's ability to adaptively balance informativeness and minimalism across tasks.",
      "authors": [
        "Jang Won June"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T02:03:23+00:00",
          "link": "https://arxiv.org/abs/2506.23463v1",
          "size": "2071kb",
          "version": "v1"
        }
      ],
      "title": "What to Keep and What to Drop: Adaptive Table Filtering Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23463",
        "HTML": "https://arxiv.org/html/2506.23463v1",
        "PDF": "https://arxiv.org/pdf/2506.23463"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23464",
      "abstract": "Document Visual Question Answering (DocVQA) systems are increasingly deployed in real world applications, yet they remain ethically opaque-often producing overconfident answers to ambiguous questions or failing to communicate uncertainty in a trustworthy manner. This misalignment between model confidence and actual knowledge poses significant risks, particularly in domains requiring ethical accountability. Existing approaches such as LayoutLMv3, UDOP, and DONUT have advanced SOTA performance by focusing on architectural sophistication and accuracy; however, they fall short in ethical responsiveness.\n  To address these limitations, we introduce HonestVQA, a self-supervised honesty calibration framework for ethically aligned DocVQA. Our model-agnostic method quantifies uncertainty to identify knowledge gaps, aligns model confidence with actual correctness using weighted loss functions, and enforces ethical response behavior via contrastive learning. We further introduce two principled evaluation metrics--Honesty Score (H-Score) and Ethical Confidence Index (ECI)--to benchmark alignment between confidence, accuracy, and ethical communication. Empirically, HonestVQA improves DocVQA accuracy by up to 4.3% and F1 by 4.3% across SpDocVQA, InfographicsVQA, and SROIE datasets. It reduces overconfidence, lowering H-Score and ECI by 0.072 and 0.078, respectively. In cross domain evaluation, it achieves up to 78.9% accuracy and 76.1% F1-score, demonstrating strong generalization. Ablation shows a 3.8% drop in accuracy without alignment or contrastive loss.",
      "authors": [
        "Sahil Tripathi",
        "Md Tabrez Nafis",
        "Imran Hussain",
        "Jiechao Gao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T02:06:54+00:00",
          "link": "https://arxiv.org/abs/2506.23464v1",
          "size": "33kb",
          "version": "v1"
        }
      ],
      "title": "The Confidence Paradox: Can LLM Know When It's Wrong",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23464",
        "HTML": "https://arxiv.org/html/2506.23464v1",
        "PDF": "https://arxiv.org/pdf/2506.23464"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23465",
      "abstract": "The success of machine learning models in industrial applications is heavily dependent on the quality of the datasets used to train the models. However, large-scale datasets, specially those constructed from crowd-sourcing and web-scraping, often suffer from label noise, inconsistencies, and errors. This problem is particularly pronounced in manufacturing domains, where obtaining high-quality labels is costly and time-consuming. This paper introduces Vision-Language Sanitization and Refinement (VLSR), which is a vision-language-based framework for label sanitization and refinement in multi-label manufacturing image datasets. This method embeds both images and their associated textual labels into a shared semantic space leveraging the CLIP vision-language model. Then two key tasks are addressed in this process by computing the cosine similarity between embeddings. First, label sanitization is performed to identify irrelevant, misspelled, or semantically weak labels, and surface the most semantically aligned label for each image by comparing image-label pairs using cosine similarity between image and label embeddings. Second, the method applies density-based clustering on text embeddings, followed by iterative cluster merging, to group semantically similar labels into unified label groups. The Factorynet dataset, which includes noisy labels from both human annotations and web-scraped sources, is employed to evaluate the effectiveness of the proposed framework. Experimental results demonstrate that the VLSR framework successfully identifies problematic labels and improves label consistency. This method enables a significant reduction in label vocabulary through clustering, which ultimately enhances the dataset's quality for training robust machine learning models in industrial applications with minimal human intervention.",
      "authors": [
        "Nazanin Mahjourian",
        "Vinh Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T02:13:09+00:00",
          "link": "https://arxiv.org/abs/2506.23465v1",
          "size": "3173kb",
          "version": "v1"
        }
      ],
      "title": "Sanitizing Manufacturing Dataset Labels Using Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23465",
        "HTML": "https://arxiv.org/html/2506.23465v1",
        "PDF": "https://arxiv.org/pdf/2506.23465"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23467",
      "abstract": "Contrastive Language-Image Pre-training (CLIP) models have demonstrated superior performance across various visual tasks including medical image classification. However, fairness concerns, including demographic biases, have received limited attention for CLIP models. This oversight leads to critical issues, particularly those related to race and gender, resulting in disparities in diagnostic outcomes and reduced reliability for underrepresented groups. To address these challenges, we introduce AdFair-CLIP, a novel framework employing adversarial feature intervention to suppress sensitive attributes, thereby mitigating spurious correlations and improving prediction fairness. We conduct comprehensive experiments on chest X-ray (CXR) datasets, and show that AdFair-CLIP significantly enhances both fairness and diagnostic accuracy, while maintaining robust generalization in zero-shot and few-shot scenarios. These results establish new benchmarks for fairness-aware learning in CLIP-based medical diagnostic models, particularly for CXR analysis.",
      "authors": [
        "Chenlang Yi",
        "Zizhan Xiong",
        "Qi Qi",
        "Xiyuan Wei",
        "Girish Bathla",
        "Ching-Long Lin",
        "Bobak Jack Mortazavi",
        "Tianbao Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T02:19:22+00:00",
          "link": "https://arxiv.org/abs/2506.23467v1",
          "size": "2442kb",
          "version": "v1"
        }
      ],
      "title": "AdFair-CLIP: Adversarial Fair Contrastive Language-Image Pre-training for Chest X-rays",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23467",
        "HTML": "https://arxiv.org/html/2506.23467v1",
        "PDF": "https://arxiv.org/pdf/2506.23467"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23468",
      "abstract": "Vision-and-Language Navigation in Continuous Environments (VLN-CE) requires agents to execute sequential navigation actions in complex environments guided by natural language instructions. Current approaches often struggle with generalizing to novel environments and adapting to ongoing changes during navigation. Inspired by human cognition, we present NavMorph, a self-evolving world model framework that enhances environmental understanding and decision-making in VLN-CE tasks. NavMorph employs compact latent representations to model environmental dynamics, equipping agents with foresight for adaptive planning and policy refinement. By integrating a novel Contextual Evolution Memory, NavMorph leverages scene-contextual information to support effective navigation while maintaining online adaptability. Extensive experiments demonstrate that our method achieves notable performance improvements on popular VLN-CE benchmarks. Code is available at \\href{https://github.com/Feliciaxyao/NavMorph}{this https URL}.",
      "authors": [
        "Xuan Yao",
        "Junyu Gao",
        "Changsheng Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T02:20:00+00:00",
          "link": "https://arxiv.org/abs/2506.23468v1",
          "size": "1200kb",
          "version": "v1"
        }
      ],
      "title": "NavMorph: A Self-Evolving World Model for Vision-and-Language Navigation in Continuous Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23468",
        "HTML": "https://arxiv.org/html/2506.23468v1",
        "PDF": "https://arxiv.org/pdf/2506.23468"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23469",
      "abstract": "Graph anomaly detection is critical in domains such as healthcare and economics, where identifying deviations can prevent substantial losses. Existing unsupervised approaches strive to learn a single model capable of detecting both attribute and structural anomalies. However, they confront the tug-of-war problem between two distinct types of anomalies, resulting in suboptimal performance. This work presents TripleAD, a mutual distillation-based triple-channel graph anomaly detection framework. It includes three estimation modules to identify the attribute, structural, and mixed anomalies while mitigating the interference between different types of anomalies. In the first channel, we design a multiscale attribute estimation module to capture extensive node interactions and ameliorate the over-smoothing issue. To better identify structural anomalies, we introduce a link-enhanced structure estimation module in the second channel that facilitates information flow to topologically isolated nodes. The third channel is powered by an attribute-mixed curvature, a new indicator that encapsulates both attribute and structural information for discriminating mixed anomalies. Moreover, a mutual distillation strategy is introduced to encourage communication and collaboration between the three channels. Extensive experiments demonstrate the effectiveness of the proposed TripleAD model against strong baselines.",
      "authors": [
        "Chunjing Xiao",
        "Jiahui Lu",
        "Xovee Xu",
        "Fan Zhou",
        "Tianshu Xie",
        "Wei Lu",
        "Lifeng Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T02:23:32+00:00",
          "link": "https://arxiv.org/abs/2506.23469v1",
          "size": "3294kb",
          "version": "v1"
        }
      ],
      "title": "Reconciling Attribute and Structural Anomalies for Improved Graph Anomaly Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23469",
        "HTML": "https://arxiv.org/html/2506.23469v1",
        "PDF": "https://arxiv.org/pdf/2506.23469"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23470",
      "abstract": "The rapid advancement of AI and computer vision has significantly increased the demand for high-quality annotated datasets, particularly for semantic segmentation. However, creating such datasets is resource-intensive, requiring substantial time, labor, and financial investment, and often raises privacy concerns due to the use of real-world data. To mitigate these challenges, we present SynthLab, consisting of a modular platform for visual data synthesis and a user-friendly interface. The modular architecture of SynthLab enables easy maintenance, scalability with centralized updates, and seamless integration of new features. Each module handles distinct aspects of computer vision tasks, enhancing flexibility and adaptability. Meanwhile, its interactive, user-friendly interface allows users to quickly customize their data pipelines through drag-and-drop actions. Extensive user studies involving a diverse range of users across different ages, professions, and expertise levels, have demonstrated flexible usage, and high accessibility of SynthLab, enabling users without deep technical expertise to harness AI for real-world applications.",
      "authors": [
        "Ngoc-Do Tran and Minh-Tuan Huynh and Tam V. Nguyen and Minh-Triet Tran and Trung-Nghia Le"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T02:23:34+00:00",
          "link": "https://arxiv.org/abs/2506.23470v1",
          "size": "9702kb",
          "version": "v1"
        }
      ],
      "title": "Interactive Interface For Semantic Segmentation Dataset Synthesis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23470",
        "HTML": "https://arxiv.org/html/2506.23470v1",
        "PDF": "https://arxiv.org/pdf/2506.23470"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23471",
      "abstract": "The global fashion e-commerce industry has become integral to people's daily lives, leveraging technological advancements to offer personalized shopping experiences, primarily through recommendation systems that enhance customer engagement through personalized suggestions. To improve customers' experience in online shopping, we propose a novel comprehensive KiseKloset system for outfit retrieval, recommendation, and try-on. We explore two approaches for outfit retrieval: similar item retrieval and text feedback-guided item retrieval. Notably, we introduce a novel transformer architecture designed to recommend complementary items from diverse categories. Furthermore, we enhance the overall performance of the search pipeline by integrating approximate algorithms to optimize the search process. Additionally, addressing the crucial needs of online shoppers, we employ a lightweight yet efficient virtual try-on framework capable of real-time operation, memory efficiency, and maintaining realistic outputs compared to its predecessors. This virtual try-on module empowers users to visualize specific garments on themselves, enhancing the customers' experience and reducing costs associated with damaged items for retailers. We deployed our end-to-end system for online users to test and provide feedback, enabling us to measure their satisfaction levels. The results of our user study revealed that 84% of participants found our comprehensive system highly useful, significantly improving their online shopping experience.",
      "authors": [
        "Thanh-Tung Phan-Nguyen and Khoi-Nguyen Nguyen-Ngoc and Tam V. Nguyen and Minh-Triet Tran and Trung-Nghia Le"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T02:25:39+00:00",
          "link": "https://arxiv.org/abs/2506.23471v1",
          "size": "11311kb",
          "version": "v1"
        }
      ],
      "title": "KiseKloset: Comprehensive System For Outfit Retrieval, Recommendation, And Try-On",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23471",
        "HTML": "https://arxiv.org/html/2506.23471v1",
        "PDF": "https://arxiv.org/pdf/2506.23471"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23474",
      "abstract": "The Model Context Protocol (MCP) has recently emerged as a standardized interface for connecting language models with external tools and data. As the ecosystem rapidly expands, the lack of a structured, comprehensive view of existing MCP artifacts presents challenges for research. To bridge this gap, we introduce MCPCorpus, a large-scale dataset containing around 14K MCP servers and 300 MCP clients. Each artifact is annotated with 20+ normalized attributes capturing its identity, interface configuration, GitHub activity, and metadata. MCPCorpus provides a reproducible snapshot of the real-world MCP ecosystem, enabling studies of adoption trends, ecosystem health, and implementation diversity. To keep pace with the rapid evolution of the MCP ecosystem, we provide utility tools for automated data synchronization, normalization, and inspection. Furthermore, to support efficient exploration and exploitation, we release a lightweight web-based search interface. MCPCorpus is publicly available at: https://github.com/Snakinya/MCPCorpus.",
      "authors": [
        "Zhiwei Lin",
        "Bonan Ruan",
        "Jiahao Liu",
        "Weibo Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T02:37:27+00:00",
          "link": "https://arxiv.org/abs/2506.23474v1",
          "size": "118kb",
          "version": "v1"
        }
      ],
      "title": "A Large-Scale Evolvable Dataset for Model Context Protocol Ecosystem and Security Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23474",
        "HTML": "https://arxiv.org/html/2506.23474v1",
        "PDF": "https://arxiv.org/pdf/2506.23474"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23478",
      "abstract": "Chamfer Distance (CD) is a widely adopted metric in 3D point cloud learning due to its simplicity and efficiency. However, it suffers from a fundamental limitation: it relies solely on Euclidean distances, which often fail to capture the intrinsic geometry of 3D shapes. To address this limitation, we propose GeoCD, a topology-aware and fully differentiable approximation of geodesic distance designed to serve as a metric for 3D point cloud learning. Our experiments show that GeoCD consistently improves reconstruction quality over standard CD across various architectures and datasets. We demonstrate this by fine-tuning several models, initially trained with standard CD, using GeoCD. Remarkably, fine-tuning for a single epoch with GeoCD yields significant gains across multiple evaluation metrics.",
      "authors": [
        "Pedro Alonso",
        "Tianrui Li",
        "Chongshou Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T02:53:40+00:00",
          "link": "https://arxiv.org/abs/2506.23478v1",
          "size": "1429kb",
          "version": "v1"
        }
      ],
      "title": "GeoCD: A Differential Local Approximation for Geodesic Chamfer Distance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23478",
        "HTML": "https://arxiv.org/html/2506.23478v1",
        "PDF": "https://arxiv.org/pdf/2506.23478"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23479",
      "abstract": "Implicit Neural Representation (INR) has demonstrated remarkable advances in the field of image representation but demands substantial GPU resources. GaussianImage recently pioneered the use of Gaussian Splatting to mitigate this cost, however, the slow training process limits its practicality, and the fixed number of Gaussians per image limits its adaptability to varying information entropy. To address these issues, we propose in this paper a generalizable and self-adaptive image representation framework based on 2D Gaussian Splatting. Our method employs a network to quickly generate a coarse Gaussian representation, followed by minimal fine-tuning steps, achieving comparable rendering quality of GaussianImage while significantly reducing training time. Moreover, our approach dynamically adjusts the number of Gaussian points based on image complexity to further enhance flexibility and efficiency in practice. Experiments on DIV2K and Kodak datasets show that our method matches or exceeds GaussianImage's rendering performance with far fewer iterations and shorter training times. Specifically, our method reduces the training time by up to one order of magnitude while achieving superior rendering performance with the same number of Gaussians.",
      "authors": [
        "Zhaojie Zeng",
        "Yuesong Wang",
        "Chao Yang",
        "Tao Guan",
        "Lili Ju"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T02:58:52+00:00",
          "link": "https://arxiv.org/abs/2506.23479v1",
          "size": "26547kb",
          "version": "v1"
        }
      ],
      "title": "Instant GaussianImage: A Generalizable and Self-Adaptive Image Representation via 2D Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23479",
        "HTML": "https://arxiv.org/html/2506.23479v1",
        "PDF": "https://arxiv.org/pdf/2506.23479"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23481",
      "abstract": "Objectives: The rapid advancement of Multimodal Large Language Models (MLLMs) has significantly enhanced their reasoning capabilities, enabling a wide range of intelligent applications. However, these advancements also raise critical concerns regarding privacy and ethics. MLLMs are now capable of inferring the geographic location of images -- such as those shared on social media or captured from street views -- based solely on visual content, thereby posing serious risks of privacy invasion, including doxxing, surveillance, and other security threats.\n  Methods: This study provides a comprehensive analysis of existing geolocation techniques based on MLLMs. It systematically reviews relevant litera-ture and evaluates the performance of state-of-the-art visual reasoning models on geolocation tasks, particularly in identifying the origins of street view imagery.\n  Results: Empirical evaluation reveals that the most advanced visual large models can successfully localize the origin of street-level imagery with up to $49\\%$ accuracy within a 1-kilometer radius. This performance underscores the models' powerful capacity to extract and utilize fine-grained geographic cues from visual data.\n  Conclusions: Building on these findings, the study identifies key visual elements that contribute to suc-cessful geolocation, such as text, architectural styles, and environmental features. Furthermore, it discusses the potential privacy implications associated with MLLM-enabled geolocation and discuss several technical and policy-based coun-termeasures to mitigate associated risks. Our code and dataset are available at https://github.com/zxyl1003/MLLM-Geolocation-Evaluation.",
      "authors": [
        "Xian Zhang and Xiang Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T03:05:30+00:00",
          "link": "https://arxiv.org/abs/2506.23481v1",
          "size": "2104kb",
          "version": "v1"
        }
      ],
      "title": "Evaluation of Geolocation Capabilities of Multimodal Large Language Models and Analysis of Associated Privacy Risks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23481",
        "HTML": "https://arxiv.org/html/2506.23481v1",
        "PDF": "https://arxiv.org/pdf/2506.23481"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23482",
      "abstract": "Advancements in generative models have enabled image inpainting models to generate content within specific regions of an image based on provided prompts and masks. However, existing inpainting methods often suffer from problems such as semantic misalignment, structural distortion, and style inconsistency. In this work, we present MTADiffusion, a Mask-Text Alignment diffusion model designed for object inpainting. To enhance the semantic capabilities of the inpainting model, we introduce MTAPipeline, an automatic solution for annotating masks with detailed descriptions. Based on the MTAPipeline, we construct a new MTADataset comprising 5 million images and 25 million mask-text pairs. Furthermore, we propose a multi-task training strategy that integrates both inpainting and edge prediction tasks to improve structural stability. To promote style consistency, we present a novel inpainting style-consistency loss using a pre-trained VGG network and the Gram matrix. Comprehensive evaluations on BrushBench and EditBench demonstrate that MTADiffusion achieves state-of-the-art performance compared to other methods.",
      "authors": [
        "Jun Huang",
        "Ting Liu",
        "Yihang Wu",
        "Xiaochao Qu",
        "Luoqi Liu",
        "Xiaolin Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T03:06:54+00:00",
          "link": "https://arxiv.org/abs/2506.23482v1",
          "size": "10635kb",
          "version": "v1"
        }
      ],
      "title": "MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23482",
        "HTML": "https://arxiv.org/html/2506.23482v1",
        "PDF": "https://arxiv.org/pdf/2506.23482"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23483",
      "abstract": "We present a data-assisted iterative regularization method for solving ill-posed inverse problems in Hilbert space settings. The proposed approach, termed \\texttt{IRMGL+\\(\\Psi\\)}, integrates classical iterative techniques with a data-driven regularization term realized through an iteratively updated graph Laplacian. Our method commences by computing a preliminary solution using any suitable reconstruction method, which then serves as the basis for constructing the initial graph Laplacian. The solution is subsequently refined through an iterative process, where the graph Laplacian is simultaneously recalibrated at each step to effectively capture the evolving structure of the solution. A key innovation of this work lies in the formulation of this iterative scheme and the rigorous justification of the classical discrepancy principle as a reliable early stopping criterion specifically tailored to the proposed method. Under standard assumptions, we establish stability and convergence results for the scheme when the discrepancy principle is applied. Furthermore, we demonstrate the robustness and effectiveness of our method through numerical experiments utilizing four distinct initial reconstructors $\\Psi$: the adjoint operator (Adj), filtered back projection (FBP), total variation (TV) denoising, and standard Tikhonov regularization (Tik). It is observed that \\texttt{IRMGL+Adj} demonstrates a distinct advantage over the other initializers, producing a robust and stable approximate solution directly from a basic initial reconstruction.",
      "authors": [
        "Harshit Bajpai",
        "Gaurav Mittal",
        "Ankik Kumar Giri"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Functional Analysis (math.FA)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T03:07:15+00:00",
          "link": "https://arxiv.org/abs/2506.23483v1",
          "size": "1348kb",
          "version": "v1"
        }
      ],
      "title": "On the convergence of iterative regularization method assisted by the graph Laplacian with early stopping",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23483",
        "HTML": "https://arxiv.org/html/2506.23483v1",
        "PDF": "https://arxiv.org/pdf/2506.23483"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23484",
      "abstract": "AI-generated content (AIGC) enables efficient visual creation but raises copyright and authenticity risks. As a common technique for integrity verification and source tracing, digital image watermarking is regarded as a potential solution to above issues. Among these, watermarking methods capable of preserving the generation quality are receiving increased attention. However, the proliferation and high performance of generative image editing applications have elevated the risks of malicious tampering, creating new demands. 1) The tamper robustness of current lossless visual quality watermarks remains constrained by the modification-sensitive diffusion inversion process, necessitating enhanced robustness. 2) The improved tampering quality and rapid iteration cycles render passive tampering detection methods inadequate, making proactive tampering localization capability a desired feature for watermarks. To address these requirements, this paper proposes a Tamper-Aware Generative image WaterMarking method named TAG-WM. The proposed method comprises four key modules: a dual-mark joint sampling (DMJS) algorithm for embedding copyright and localization watermarks into the latent space while preserving generative quality, the watermark latent reconstruction (WLR) utilizing reversed DMJS, a dense variation region detector (DVRD) leveraging diffusion inversion sensitivity to identify tampered areas via statistical deviation analysis, and the tamper-aware decoding (TAD) guided by localization results. The experimental results indicate that TAG-WM achieves SOTA tampering robustness and tampering localization capability with distortions while maintaining lossless generation quality and a considerable capacity of 256 bits.",
      "authors": [
        "Yuzhuo Chen",
        "Zehua Ma",
        "Han Fang",
        "Weiming Zhang",
        "Nenghai Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T03:14:07+00:00",
          "link": "https://arxiv.org/abs/2506.23484v1",
          "size": "5069kb",
          "version": "v1"
        }
      ],
      "title": "TAG-WM: Tamper-Aware Generative Image Watermarking via Diffusion Inversion Sensitivity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23484",
        "HTML": "https://arxiv.org/html/2506.23484v1",
        "PDF": "https://arxiv.org/pdf/2506.23484"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23485",
      "abstract": "Interactive recommendation is a typical information-seeking task that allows users to interactively express their needs through natural language and obtain personalized recommendations. Large language model-powered (LLM-powered) agents have become a new paradigm in interactive recommendations, effectively capturing users' real-time needs and enhancing personalized experiences. However, due to limited planning and generalization capabilities, existing formulations of LLM-powered interactive recommender agents struggle to effectively address diverse and complex user intents, such as intuitive, unrefined, or occasionally ambiguous requests. To tackle this challenge, we propose a novel thought-augmented interactive recommender agent system (TAIRA) that addresses complex user intents through distilled thought patterns. Specifically, TAIRA is designed as an LLM-powered multi-agent system featuring a manager agent that orchestrates recommendation tasks by decomposing user needs and planning subtasks, with its planning capacity strengthened through Thought Pattern Distillation (TPD), a thought-augmentation method that extracts high-level thoughts from the agent's and human experts' experiences. Moreover, we designed a set of user simulation schemes to generate personalized queries of different difficulties and evaluate the recommendations based on specific datasets. Through comprehensive experiments conducted across multiple datasets, TAIRA exhibits significantly enhanced performance compared to existing methods. Notably, TAIRA shows a greater advantage on more challenging tasks while generalizing effectively on novel tasks, further validating its superiority in managing complex user intents within interactive recommendation systems. The code is publicly available at:https://github.com/Alcein/TAIRA.",
      "authors": [
        "Haocheng Yu",
        "Yaxiong Wu",
        "Hao Wang",
        "Wei Guo",
        "Yong Liu",
        "Yawen Li",
        "Yuyang Ye",
        "Junping Du",
        "Enhong Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T03:15:50+00:00",
          "link": "https://arxiv.org/abs/2506.23485v1",
          "size": "2063kb",
          "version": "v1"
        }
      ],
      "title": "Thought-Augmented Planning for LLM-Powered Interactive Recommender Agent",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23485",
        "HTML": "https://arxiv.org/html/2506.23485v1",
        "PDF": "https://arxiv.org/pdf/2506.23485"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23488",
      "abstract": "Wireless communication systems face significant challenges in meeting the increasing demands for higher data rates and more reliable connectivity in complex environments. Stacked intelligent metasurfaces (SIMs) have emerged as a promising technology for realizing wave-domain signal processing, with mobile SIMs offering superior communication performance compared to their fixed counterparts. In this paper, we investigate a novel unmanned aerial vehicle (UAV)-mounted SIMs (UAV-SIMs) assisted communication system within the low-altitude economy (LAE) networks paradigm, where UAVs function as both base stations that cache SIM-processed data and mobile platforms that flexibly deploy SIMs to enhance uplink communications from ground users. To maximize network capacity, we formulate a UAV-SIM-based joint optimization problem (USBJOP) that comprehensively addresses three critical aspects: the association between UAV-SIMs and users, the three-dimensional positioning of UAV-SIMs, and the phase shifts across multiple SIM layers. Due to the inherent non-convexity and NP-hardness of USBJOP, we decompose it into three sub-optimization problems, \\textit{i.e.}, association between UAV-SIMs and users optimization problem (AUUOP), UAV location optimization problem (ULOP), and UAV-SIM phase shifts optimization problem (USPSOP), and solve them using an alternating optimization strategy. Specifically, we transform AUUOP and ULOP into convex forms solvable by the CVX tool, while addressing USPSOP through a generative artificial intelligence (GAI)-based hybrid optimization algorithm. Simulations demonstrate that our proposed approach significantly outperforms benchmark schemes, achieving approximately 1.5 times higher network capacity compared to suboptimal alternatives. Additionally, our proposed GAI method reduces the algorithm runtime by 10\\% while maintaining solution quality.",
      "authors": [
        "Geng Sun",
        "Mingzhe Fan",
        "Lei Zhang",
        "Hongyang Pan",
        "Jiahui Li",
        "Chuang Zhang",
        "Linyao Li",
        "Changyuan Zhao and Chau Yuen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T03:22:32+00:00",
          "link": "https://arxiv.org/abs/2506.23488v1",
          "size": "4088kb",
          "version": "v1"
        }
      ],
      "title": "Generative AI-enhanced Low-Altitude UAV-Mounted Stacked Intelligent Metasurfaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23488",
        "HTML": "https://arxiv.org/html/2506.23488v1",
        "PDF": "https://arxiv.org/pdf/2506.23488"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23491",
      "abstract": "This paper introduces Qwen-GUI-3B, a lightweight Vision-Language Model (VLM) specifically designed for Graphical User Interface grounding tasks, achieving performance competitive with significantly larger models. Unlike large-scale VLMs (>7B parameters) that are computationally intensive and impractical for consumer-grade hardware, Qwen-GUI-3B delivers strong grounding accuracy while being fully trainable on a single GPU (RTX 4090). The model incorporates several key innovations: (i) combine cross-platform, multi-resolution dataset of 24K examples from diverse sources including mobile, desktop, and web GUI screenshots to effectively address data scarcity in high-resolution desktop environments; (ii) a two-stage fine-tuning strategy, where initial cross-platform training establishes robust GUI understanding, followed by specialized fine-tuning on high-resolution data to significantly enhance model adaptability; and (iii) data curation and redundancy reduction strategies, demonstrating that randomly sampling a smaller subset with reduced redundancy achieves performance comparable to larger datasets, emphasizing data diversity over sheer volume. Empirical evaluation on standard GUI grounding benchmarks-including ScreenSpot, ScreenSpot-v2, and the challenging ScreenSpot-Pro, highlights Qwen-GUI-3B's exceptional accuracy, achieving 84.9% on ScreenSpot and 86.4% on ScreenSpot-v2, surpassing prior models under 4B parameters. Ablation studies validate the critical role of balanced sampling and two-stage fine-tuning in enhancing robustness, particularly in high-resolution desktop scenarios. The Qwen-GUI-3B is available at: https://github.com/Han1018/Qwen-GUI-3B",
      "authors": [
        "ZongHan Hsieh",
        "Tzer-Jen Wei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T03:33:02+00:00",
          "link": "https://arxiv.org/abs/2506.23491v1",
          "size": "395kb",
          "version": "v1"
        }
      ],
      "title": "Qwen-GUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23491",
        "HTML": "https://arxiv.org/html/2506.23491v1",
        "PDF": "https://arxiv.org/pdf/2506.23491"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23492",
      "abstract": "Recent advances in deep learning have significantly improved predictive accuracy. However, modern neural networks remain systematically overconfident, posing risks for deployment in safety-critical scenarios. Current post-hoc calibration methods face a fundamental dilemma: global approaches like Temperature Scaling apply uniform adjustments across all samples, introducing high bias despite computational efficiency, while more expressive methods that operate on full logit distributions suffer from high variance due to noisy high-dimensional inputs and insufficient validation data. To address these challenges, we propose Sample Margin-Aware Recalibration of Temperature (SMART), a lightweight, data-efficient recalibration method that precisely scales logits based on the margin between the top two logits -- termed the logit gap. Specifically, the logit gap serves as a denoised, scalar signal directly tied to decision boundary uncertainty, providing a robust indicator that avoids the noise inherent in high-dimensional logit spaces while preserving model prediction invariance. Meanwhile, SMART employs a novel soft-binned Expected Calibration Error (SoftECE) objective that balances model bias and variance through adaptive binning, enabling stable parameter updates even with extremely limited calibration data. Extensive evaluations across diverse datasets and architectures demonstrate that SMART achieves state-of-the-art calibration performance even with substantially fewer parameters compared to existing parametric methods, offering a principled, robust, and highly efficient solution for practical uncertainty quantification in neural network predictions. The source code is available at: https://anonymous.4open.science/r/SMART-8B11.",
      "authors": [
        "Haolan Guo",
        "Linwei Tao",
        "Haoyang Luo",
        "Minjing Dong",
        "Chang Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T03:35:05+00:00",
          "link": "https://arxiv.org/abs/2506.23492v1",
          "size": "2379kb",
          "version": "v1"
        }
      ],
      "title": "Sample Margin-Aware Recalibration of Temperature Scaling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23492",
        "HTML": "https://arxiv.org/html/2506.23492v1",
        "PDF": "https://arxiv.org/pdf/2506.23492"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23493",
      "abstract": "Low-altitude wireless networks (LAWNs) have garnered significant attention in the forthcoming 6G networks. In LAWNs, satellites with wide coverage and unmanned aerial vehicles (UAVs) with flexible mobility can complement each other to form integrated satellite-UAV networks, providing ubiquitous and high-speed connectivity for low-altitude operations. However, the higher line-of-sight probability in low-altitude airspace increases transmission security concerns. In this work, we present a collaborative beamforming-based physical layer security scheme for LAWNs. We introduce the fundamental aspects of integrated satellite-UAV networks, physical layer security, UAV swarms, and collaborative beamforming for LAWN applications. Following this, we highlight several opportunities for collaborative UAV swarm secure applications enabled by satellite networks, including achieving physical layer security in scenarios involving data dissemination, data relay, eavesdropper collusion, and imperfect eavesdropper information. Next, we detail two case studies: a secure relay system and a two-way aerial secure communication framework specifically designed for LAWN environments. Simulation results demonstrate that these physical layer security schemes are effective and beneficial for secure low-altitude wireless communications. A short practicality analysis shows that the proposed method is applicable to LAWN scenarios. Finally, we discuss current challenges and future research directions for enhancing security in LAWNs.",
      "authors": [
        "Jiahui Li",
        "Geng Sun",
        "Xiaoyu Sun",
        "Fang Mei",
        "Jingjing Wang",
        "Xiangwang Hou",
        "Daxin Tian and Victor C. M. Leung"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T03:35:42+00:00",
          "link": "https://arxiv.org/abs/2506.23493v1",
          "size": "6188kb",
          "version": "v1"
        }
      ],
      "title": "Securing the Sky: Integrated Satellite-UAV Physical Layer Security for Low-Altitude Wireless Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23493",
        "HTML": "https://arxiv.org/html/2506.23493v1",
        "PDF": "https://arxiv.org/pdf/2506.23493"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23502",
      "abstract": "Driven by large-scale contrastive vision-language pre-trained models such as CLIP, recent advancements in the image-text matching task have achieved remarkable success in representation learning. Due to image-level visual-language alignment, CLIP falls short in understanding fine-grained details such as object attributes and spatial relationships between objects. Recent efforts have attempted to compel CLIP to acquire structured visual representations by introducing prompt learning to achieve object-level alignment. While achieving promising results, they still lack the capability to perceive actions, which are crucial for describing the states or relationships between objects. Therefore, we propose to endow CLIP with fine-grained action-level understanding by introducing an LLM-enhanced action-aware multi-modal prompt-tuning method, incorporating the action-related external knowledge generated by large language models (LLMs). Specifically, we design an action triplet prompt and an action state prompt to exploit compositional semantic knowledge and state-related causal knowledge implicitly stored in LLMs. Subsequently, we propose an adaptive interaction module to aggregate attentive visual features conditioned on action-aware prompted knowledge for establishing discriminative and action-aware visual representations, which further improves the performance. Comprehensive experimental results on two benchmark datasets demonstrate the effectiveness of our method.",
      "authors": [
        "Mengxiao Tian",
        "Xinxiao Wu",
        "Shuo Yang"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T03:49:08+00:00",
          "link": "https://arxiv.org/abs/2506.23502v1",
          "size": "1855kb",
          "version": "v1"
        }
      ],
      "title": "LLM-enhanced Action-aware Multi-modal Prompt Tuning for Image-Text Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23502",
        "HTML": "https://arxiv.org/html/2506.23502v1",
        "PDF": "https://arxiv.org/pdf/2506.23502"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23503",
      "abstract": "Cognitive Behavioral Therapy (CBT) is a proven approach for addressing the irrational thought patterns associated with mental health disorders, but its effectiveness relies on accurately identifying cognitive pathways to provide targeted treatment. In today's digital age, individuals often express negative emotions on social media, where they may reveal cognitive distortions, and in severe cases, exhibit suicidal tendencies. However, there is a significant gap in methodologies designed to analyze these cognitive pathways, which could be critical for psychotherapists aiming to deliver timely and effective interventions in online environments. Cognitive Behavioral Therapy (CBT) framework leveraging acceptance, commitment and data augmentation to categorize and address both textual and visual content as positive or negative. Specifically, the system employs BERT, RoBERTa for Sentiment Analysis and T5, PEGASUS for Text Summarization, mT5 for Text Translation in Multiple Languages focusing on detecting negative emotions and cognitive distortions within social media data. While existing models are primarily designed to identify negative thoughts, the proposed system goes beyond this by predicting additional negative side effects and other potential mental health disorders likes Phobias, Eating Disorders. This enhancement allows for a more comprehensive understanding and intervention strategy, offering psychotherapists a powerful tool for early detection and treatment of various psychological issues.",
      "authors": [
        "Bosubabu Sambana",
        "Kondreddygari Archana",
        "Suram Indhra Sena Reddy",
        "Shaik Meethaigar Jameer Basha",
        "Shaik Karishma"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T03:59:00+00:00",
          "link": "https://arxiv.org/abs/2506.23503v1",
          "size": "600kb",
          "version": "v1"
        }
      ],
      "title": "Data Augmentation for Cognitive Behavioral Therapy: Leveraging ERNIE Language Models using Artificial Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23503",
        "PDF": "https://arxiv.org/pdf/2506.23503"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23504",
      "abstract": "The recent development of advanced machine learning methods for hybrid models has greatly addressed the need for the correct prediction of electrical prices. This method combines AlexNet and LSTM algorithms, which are used to introduce a new model with higher accuracy in price forecasting. Despite RNN and ANN being effective, they often fail to deal with forex time sequence data. The traditional methods do not accurately forecast the prices. These traditional methods only focus on demand and price which leads to insufficient analysis of data. To address this issue, using the hybrid approach, which focuses on external variables that also effect the predicted prices. Nevertheless, due to AlexNet's excellent feature extraction and LSTM's learning sequential patterns, the prediction accuracy is vastly increased. The model is built on the past data, which has been supplied with the most significant elements like demand, temperature, sunlight, and rain. For example, the model applies methods, such as minimum-maximum scaling and a time window, to predict the electricity prices of the future. The results show that this hybrid model is good than the standalone ones in terms of accuracy. Although we got our accuracy rating of 97.08, it shows higher accompaniments than remaining models RNN and ANN with accuracies of 96.64 and 96.63 respectively.",
      "authors": [
        "Bosubabu Sambana",
        "Kotamsetty Geethika Devi",
        "Bandi Rajeswara Reddy",
        "Galeti Mohammad Hussain",
        "Gownivalla Siddartha"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T04:06:24+00:00",
          "link": "https://arxiv.org/abs/2506.23504v1",
          "size": "663kb",
          "version": "v1"
        }
      ],
      "title": "Hybrid Approach for Electricity Price Forecasting using AlexNet and LSTM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23504",
        "PDF": "https://arxiv.org/pdf/2506.23504"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23505",
      "abstract": "Underwater object detection is crucial for autonomous navigation, environmental monitoring, and marine exploration, but it is severely hampered by light attenuation, turbidity, and occlusion. Current methods balance accuracy and computational efficiency, but they have trouble deploying in real-time under low visibility conditions. Through the integration of physics-informed augmentation techniques with the YOLOv12 architecture, this study advances underwater detection. With Residual ELAN blocks to preserve structural features in turbid waters and Area Attention to maintain large receptive fields for occluded objects while reducing computational complexity. Underwater optical properties are addressed by domain-specific augmentations such as turbulence adaptive blurring, biologically grounded occlusion simulation, and spectral HSV transformations for color distortion. Extensive tests on four difficult datasets show state-of-the-art performance, with Brackish data registering 98.30% mAP at 142 FPS. YOLOv12 improves occlusion robustness by 18.9%, small-object recall by 22.4%, and detection precision by up to 7.94% compared to previous models. The crucial role of augmentation strategy is validated by ablation studies. This work offers a precise and effective solution for conservation and underwater robotics applications.",
      "authors": [
        "Tinh Nguyen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T04:06:50+00:00",
          "link": "https://arxiv.org/abs/2506.23505v1",
          "size": "2595kb",
          "version": "v1"
        }
      ],
      "title": "Improve Underwater Object Detection through YOLOv12 Architecture and Physics-informed Augmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23505",
        "HTML": "https://arxiv.org/html/2506.23505v1",
        "PDF": "https://arxiv.org/pdf/2506.23505"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23508",
      "abstract": "Post-training algorithms such as Supervised Fine-Tuning (SFT) and Reinforcement Fine-Tuning (RFT) are widely used to adapt multimodal large language models to downstream tasks. While effective at task adaptation, their impact on prior knowledge remains unclear. In this paper, we introduce jigsaw puzzles as a novel task absent from existing pretraining corpora and systematically study the behavior of SFT and RFT on an open-source multimodal model, Qwen2.5-VL. Our experiments reveal a sharp trade-off: SFT enables rapid task acquisition but leads to catastrophic forgetting, whereas RFT learns more slowly on novel tasks but maintains prior knowledge. We analyze this phenomenon through the lens of learning dynamics, showing that RFT reinforces correct samples that are naturally aligned with the base model's probability landscape, mitigating interference with prior knowledge. Moreover, supervised training on correct RFT-simulated rollouts allows SFT to preserve knowledge while rapidly learning new tasks. These findings suggest that data distribution, rather than algorithmic differences, plays a central role in forgetting, and highlight RFT's potential for stable continual learning in multimodal large language models.",
      "authors": [
        "Zhihao Zhang",
        "Qiaole Dong",
        "Qi Zhang",
        "Jun Zhao",
        "Enyu Zhou",
        "Zhiheng Xi",
        "Senjie Jin",
        "Xiaoran Fan",
        "Yuhao Zhou",
        "Yanwei Fu",
        "Tao Ji",
        "Tao Gui",
        "and Xuanjing Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T04:15:01+00:00",
          "link": "https://arxiv.org/abs/2506.23508v1",
          "size": "1897kb",
          "version": "v1"
        }
      ],
      "title": "Reinforcement Fine-Tuning Enables MLLMs Learning Novel Tasks Stably",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23508",
        "HTML": "https://arxiv.org/html/2506.23508v1",
        "PDF": "https://arxiv.org/pdf/2506.23508"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23509",
      "abstract": "Implementing economy-wide decarbonization strategies based on decarbonizing the power grid via variable renewable energy (VRE) expansion and electrification of end-uses requires new approaches for energy infrastructure planning that consider, among other factors, weather-induced uncertainty in demand and VRE supply. An energy planning model that fails to account for these uncertainties can hinder the intended transition efforts to a low-carbon grid and increase the risk of supply shortage especially during extreme weather conditions. Here, we consider the generation and transmission expansion problem of joint power-gas infrastructure and operations planning under the uncertainty of both demand and renewable supply. We propose two distributionally robust optimization approaches based on moment (MDRO) and Wasserstein distance (WDRO) ambiguity sets to endogenize these uncertainties and account for the change in the underlying distribution of these parameters that is caused by the climate change, among other factors. Furthermore, our model considers the risk-aversion of the energy planners in the modeling framework via the conditional value-at-risk (CVaR) metric. An equivalent mixed-integer linear programming (MILP) reformulation of both modeling frameworks is presented, and a computationally efficient approximation scheme to obtain near-optimal solutions is proposed. We demonstrate the resulting DRO planning models and solution strategy via a New England case study under different levels of end-use electrification and decarbonization targets. Our experiments systematically explore different modeling aspects and compare the DRO models with stochastic programming (SP) results.",
      "authors": [
        "Rahman Khorramfar",
        "Dharik Mallapragada",
        "Saurabh Amin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T04:20:40+00:00",
          "link": "https://arxiv.org/abs/2506.23509v1",
          "size": "367kb",
          "version": "v1"
        }
      ],
      "title": "Power-Gas Infrastructure Planning under Weather-induced Supply and Demand Uncertainties",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23509",
        "HTML": "https://arxiv.org/html/2506.23509v1",
        "PDF": "https://arxiv.org/pdf/2506.23509"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23513",
      "abstract": "Panoramic video generation aims to synthesize 360-degree immersive videos, holding significant importance in the fields of VR, world models, and spatial intelligence. Existing works fail to synthesize high-quality panoramic videos due to the inherent modality gap between panoramic data and perspective data, which constitutes the majority of the training data for modern diffusion models. In this paper, we propose a novel framework utilizing pretrained perspective video models for generating panoramic videos. Specifically, we design a novel panorama representation named ViewPoint map, which possesses global spatial continuity and fine-grained visual details simultaneously. With our proposed Pano-Perspective attention mechanism, the model benefits from pretrained perspective priors and captures the panoramic spatial correlations of the ViewPoint map effectively. Extensive experiments demonstrate that our method can synthesize highly dynamic and spatially consistent panoramic videos, achieving state-of-the-art performance and surpassing previous methods.",
      "authors": [
        "Zixun Fang",
        "Kai Zhu",
        "Zhiheng Liu",
        "Yu Liu",
        "Wei Zhai",
        "Yang Cao",
        "Zheng-Jun Zha"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T04:33:34+00:00",
          "link": "https://arxiv.org/abs/2506.23513v1",
          "size": "8219kb",
          "version": "v1"
        }
      ],
      "title": "ViewPoint: Panoramic Video Generation with Pretrained Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23513",
        "HTML": "https://arxiv.org/html/2506.23513v1",
        "PDF": "https://arxiv.org/pdf/2506.23513"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23514",
      "abstract": "Relative localization is a crucial capability for multi-robot systems operating in GPS-denied environments. Existing approaches for multi-robot relative localization often depend on costly or short-range sensors like cameras and LiDARs. Consequently, these approaches face challenges such as high computational overhead (e.g., map merging) and difficulties in disjoint environments. To address this limitation, this paper introduces MGPRL, a novel distributed framework for multi-robot relative localization using convex-hull of multiple Wi-Fi access points (AP). To accomplish this, we employ co-regionalized multi-output Gaussian Processes for efficient Radio Signal Strength Indicator (RSSI) field prediction and perform uncertainty-aware multi-AP localization, which is further coupled with weighted convex hull-based alignment for robust relative pose estimation. Each robot predicts the RSSI field of the environment by an online scan of APs in its environment, which are utilized for position estimation of multiple APs. To perform relative localization, each robot aligns the convex hull of its predicted AP locations with that of the neighbor robots. This approach is well-suited for devices with limited computational resources and operates solely on widely available Wi-Fi RSSI measurements without necessitating any dedicated pre-calibration or offline fingerprinting. We rigorously evaluate the performance of the proposed MGPRL in ROS simulations and demonstrate it with real-world experiments, comparing it against multiple state-of-the-art approaches. The results showcase that MGPRL outperforms existing methods in terms of localization accuracy and computational efficiency. Finally, we open source MGPRL as a ROS package https://github.com/herolab-uga/MGPRL.",
      "authors": [
        "Sai Krishna Ghanta and Ramviyas Parasuraman"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T04:35:00+00:00",
          "link": "https://arxiv.org/abs/2506.23514v1",
          "size": "1081kb",
          "version": "v1"
        }
      ],
      "title": "MGPRL: Distributed Multi-Gaussian Processes for Wi-Fi-based Multi-Robot Relative Localization in Large Indoor Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23514",
        "HTML": "https://arxiv.org/html/2506.23514v1",
        "PDF": "https://arxiv.org/pdf/2506.23514"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23516",
      "abstract": "Federated learning (FL) often suffers from performance degradation due to key challenges such as data heterogeneity and communication constraints. To address these limitations, we present a novel FL framework called FedWSQ, which integrates weight standardization (WS) and the proposed distribution-aware non-uniform quantization (DANUQ). WS enhances FL performance by filtering out biased components in local updates during training, thereby improving the robustness of the model against data heterogeneity and unstable client participation. In addition, DANUQ minimizes quantization errors by leveraging the statistical properties of local model updates. As a result, FedWSQ significantly reduces communication overhead while maintaining superior model accuracy. Extensive experiments on FL benchmark datasets demonstrate that FedWSQ consistently outperforms existing FL methods across various challenging FL settings, including extreme data heterogeneity and ultra-low-bit communication scenarios.",
      "authors": [
        "Seung-Wook Kim",
        "Seongyeol Kim",
        "Jiah Kim",
        "Seowon Ji",
        "Se-Ho Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T04:46:25+00:00",
          "link": "https://arxiv.org/abs/2506.23516v1",
          "size": "1575kb",
          "version": "v1"
        }
      ],
      "title": "FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23516",
        "HTML": "https://arxiv.org/html/2506.23516v1",
        "PDF": "https://arxiv.org/pdf/2506.23516"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23517",
      "abstract": "As the use of AI tools by students has become more prevalent, instructors have started using AI detection tools like GPTZero and QuillBot to detect AI written text. However, the reliability of these detectors remains uncertain. In our study, we focused mostly on the success rate of GPTZero, the most-used AI detector, in identifying AI-generated texts based on different lengths of randomly submitted essays: short (40-100 word count), medium (100-350 word count), and long (350-800 word count). We gathered a data set consisting of twenty-eight AI-generated papers and fifty human-written papers. With this randomized essay data, papers were individually plugged into GPTZero and measured for percentage of AI generation and confidence. A vast majority of the AI-generated papers were detected accurately (ranging from 91-100% AI believed generation), while the human generated essays fluctuated; there were a handful of false positives. These findings suggest that although GPTZero is effective at detecting purely AI-generated content, its reliability in distinguishing human-authored texts is limited. Educators should therefore exercise caution when relying solely on AI detection tools.",
      "authors": [
        "Selin Dik",
        "Osman Erdem and Mehmet Dik"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T04:53:27+00:00",
          "link": "https://arxiv.org/abs/2506.23517v1",
          "size": "502kb",
          "version": "v1"
        }
      ],
      "title": "Assessing GPTZero's Accuracy in Identifying AI vs. Human-Written Essays",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23517",
        "PDF": "https://arxiv.org/pdf/2506.23517"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23518",
      "abstract": "Generating high-quality novel views of a scene from a single image requires maintaining structural coherence across different views, referred to as view consistency. While diffusion models have driven advancements in novel view synthesis, they still struggle to preserve spatial continuity across views. Diffusion models have been combined with 3D models to address the issue, but such approaches lack efficiency due to their complex multi-step pipelines. This paper proposes a novel view-consistent image generation method which utilizes diffusion models without additional modules. Our key idea is to enhance diffusion models with a training-free method that enables adaptive attention manipulation and noise reinitialization by leveraging view-guided warping to ensure view consistency. Through our comprehensive metric framework suitable for novel-view datasets, we show that our method improves view consistency across various diffusion models, demonstrating its broader applicability.",
      "authors": [
        "Jiwoo Park",
        "Tae Eun Choi",
        "Youngjun Jun",
        "Seong Jae Hwang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T05:00:47+00:00",
          "link": "https://arxiv.org/abs/2506.23518v1",
          "size": "11091kb",
          "version": "v1"
        }
      ],
      "title": "WAVE: Warp-Based View Guidance for Consistent Novel View Synthesis Using a Single Image",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23518",
        "HTML": "https://arxiv.org/html/2506.23518v1",
        "PDF": "https://arxiv.org/pdf/2506.23518"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23519",
      "abstract": "The eye-tracking video saliency prediction (VSP) task and video salient object detection (VSOD) task both focus on the most attractive objects in video and show the result in the form of predictive heatmaps and pixel-level saliency masks, respectively. In practical applications, eye tracker annotations are more readily obtainable and align closely with the authentic visual patterns of human eyes. Therefore, this paper aims to introduce fixation information to assist the detection of video salient objects under weak supervision. On the one hand, we ponder how to better explore and utilize the information provided by fixation, and then propose a Position and Semantic Embedding (PSE) module to provide location and semantic guidance during the feature learning process. On the other hand, we achieve spatiotemporal feature modeling under weak supervision from the aspects of feature selection and feature contrast. A Semantics and Locality Query (SLQ) Competitor with semantic and locality constraints is designed to effectively select the most matching and accurate object query for spatiotemporal modeling. In addition, an Intra-Inter Mixed Contrastive (IIMC) model improves the spatiotemporal modeling capabilities under weak supervision by forming an intra-video and inter-video contrastive learning paradigm. Experimental results on five popular VSOD benchmarks indicate that our model outperforms other competitors on various evaluation metrics.",
      "authors": [
        "Qi Qin",
        "Runmin Cong",
        "Gen Zhan",
        "Yiting Liao",
        "and Sam Kwong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T05:01:40+00:00",
          "link": "https://arxiv.org/abs/2506.23519v1",
          "size": "4532kb",
          "version": "v1"
        }
      ],
      "title": "From Sight to Insight: Unleashing Eye-Tracking in Weakly Supervised Video Salient Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23519",
        "HTML": "https://arxiv.org/html/2506.23519v1",
        "PDF": "https://arxiv.org/pdf/2506.23519"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23520",
      "abstract": "With the increasing interest in robotic synthesis in the context of organic chemistry, the automated extraction of chemical procedures from literature is critical. However, this task remains challenging due to the inherent ambiguity of chemical language and the high cost of human annotation required for developing reliable computer-aided extraction protocols. Here, we present ChemActor, a fully fine-tuned large language model (LLM), as a chemical executor to convert between unstructured experimental procedures and structured action sequences. We propose a sequential LLM-generated data framework to address the challenges of insufficient and low-quality annotated data. This framework integrates a data selection module that selects data based on distribution divergence, with a general-purpose LLM, to generate machine-executable actions from a single molecule input. Additionally, we introduce a novel multi-round LLMs circle review metric, which reflects the model's advanced understanding of chemical experimental procedures. Extensive experiments on reaction-to-description (R2D) and description-to-action (D2A) tasks demonstrate that ChemActor, augmented by LLM-generated data, achieves state-of-the-art performance, outperforming the baseline model by 10%. The code is available at: https://github.com/Zhanghahah/ChemActor.",
      "authors": [
        "Yu Zhang",
        "Ruijie Yu",
        "Jidong Tian",
        "Feng Zhu",
        "Jiapeng Liu",
        "Xiaokang Yang",
        "Yaohui Jin",
        "Yanyan Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T05:11:19+00:00",
          "link": "https://arxiv.org/abs/2506.23520v1",
          "size": "4527kb",
          "version": "v1"
        }
      ],
      "title": "ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23520",
        "HTML": "https://arxiv.org/html/2506.23520v1",
        "PDF": "https://arxiv.org/pdf/2506.23520"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23523",
      "abstract": "Traditional vision-based autonomous driving systems often face difficulties in navigating complex environments when relying solely on single-image inputs. To overcome this limitation, incorporating temporal data such as past image frames or steering sequences, has proven effective in enhancing robustness and adaptability in challenging scenarios. While previous high-performance methods exist, they often rely on resource-intensive fusion networks, making them impractical for training and unsuitable for federated learning. To address these challenges, we propose lightweight temporal transformer decomposition, a method that processes sequential image frames and temporal steering data by breaking down large attention maps into smaller matrices. This approach reduces model complexity, enabling efficient weight updates for convergence and real-time predictions while leveraging temporal information to enhance autonomous driving performance. Intensive experiments on three datasets demonstrate that our method outperforms recent approaches by a clear margin while achieving real-time performance. Additionally, real robot experiments further confirm the effectiveness of our method.",
      "authors": [
        "Tuong Do",
        "Binh X. Nguyen",
        "Quang D. Tran",
        "Erman Tjiputra",
        "Te-Chuan Chiu",
        "Anh Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T05:14:16+00:00",
          "link": "https://arxiv.org/abs/2506.23523v1",
          "size": "3798kb",
          "version": "v1"
        }
      ],
      "title": "Lightweight Temporal Transformer Decomposition for Federated Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23523",
        "HTML": "https://arxiv.org/html/2506.23523v1",
        "PDF": "https://arxiv.org/pdf/2506.23523"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23524",
      "abstract": "In the field of education, understanding students' opinions through their comments is crucial, especially in the Vietnamese language, where resources remain limited. Existing educational datasets often lack domain relevance and student slang. To address these gaps, we introduce NEU-ESC, a new Vietnamese dataset for Educational Sentiment Classification and Topic Classification, curated from university forums, which offers more samples, richer class diversity, longer texts, and broader vocabulary. In addition, we explore multitask learning using encoder-only language models (BERT), in which we showed that it achieves performance up to 83.7% and 79.8% accuracy for sentiment and topic classification tasks. We also benchmark our dataset and model with other datasets and models, including Large Language Models, and discuss these benchmarks. The dataset is publicly available at: https://huggingface.co/datasets/hung20gg/NEU-ESC.",
      "authors": [
        "Phan Quoc Hung Mai",
        "Quang Hung Nguyen",
        "Phuong Giang Duong",
        "Hong Hanh Nguyen and Nguyen Tuan Long"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T05:19:04+00:00",
          "link": "https://arxiv.org/abs/2506.23524v1",
          "size": "696kb",
          "version": "v1"
        }
      ],
      "title": "NEU-ESC: A Comprehensive Vietnamese dataset for Educational Sentiment analysis and topic Classification toward multitask learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23524",
        "PDF": "https://arxiv.org/pdf/2506.23524"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23527",
      "abstract": "This work-in-progress investigates the memorization, creativity, and nonsense found in cooking recipes generated from Large Language Models (LLMs). Precisely, we aim (i) to analyze memorization, creativity, and non-sense in LLMs using a small, high-quality set of human judgments and (ii) to evaluate potential approaches to automate such a human annotation in order to scale our study to hundreds of recipes. To achieve (i), we conduct a detailed human annotation on 20 preselected recipes generated by LLM (Mixtral), extracting each recipe's ingredients and step-by-step actions to assess which elements are memorized--i.e., directly traceable to online sources possibly seen during training--and which arise from genuine creative synthesis or outright nonsense. We find that Mixtral consistently reuses ingredients that can be found in online documents, potentially seen during model training, suggesting strong reliance on memorized content. To achieve aim (ii) and scale our analysis beyond small sample sizes and single LLM validation, we design an ``LLM-as-judge'' pipeline that automates recipe generation, nonsense detection, parsing ingredients and recipe steps, and their annotation. For instance, comparing its output against human annotations, the best ingredient extractor and annotator is Llama 3.1+Gemma 2 9B, achieving up to 78% accuracy on ingredient matching. This automated framework enables large-scale quantification of memorization, creativity, and nonsense in generated recipes, providing rigorous evidence of the models' creative capacities.",
      "authors": [
        "Jan Kvapil",
        "Martin Fajcik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T05:27:11+00:00",
          "link": "https://arxiv.org/abs/2506.23527v1",
          "size": "377kb",
          "version": "v1"
        }
      ],
      "title": "On Recipe Memorization and Creativity in Large Language Models: Is Your Model a Creative Cook, a Bad Cook, or Merely a Plagiator?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23527",
        "HTML": "https://arxiv.org/html/2506.23527v1",
        "PDF": "https://arxiv.org/pdf/2506.23527"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23529",
      "abstract": "Training on test-time data enables deep learning models to adapt to dynamic environmental changes, enhancing their practical applicability. Online adaptation from source to target domains is promising but it remains highly reliant on the performance of source pretrained model. In this paper, we investigate whether test-time adaptation (TTA) methods can continuously improve models trained via self-supervised learning (SSL) without relying on source pretraining. We introduce a self-supervised TTA protocol after observing that existing TTA approaches struggle when directly applied to self-supervised models with low accuracy on the source domain. Furthermore, we propose a collaborative learning framework that integrates SSL and TTA models, leveraging contrastive learning and knowledge distillation for stepwise representation refinement. We validate our method on diverse self-supervised models, including DINO, MoCo, and iBOT, across TTA benchmarks. Extensive experiments validate the effectiveness of our approach in SSL, showing that it achieves competitive performance even without source pretraining.",
      "authors": [
        "Jisu Han",
        "Jihee Park",
        "Dongyoon Han",
        "Wonjun Hwang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T05:36:01+00:00",
          "link": "https://arxiv.org/abs/2506.23529v1",
          "size": "1825kb",
          "version": "v1"
        }
      ],
      "title": "When Test-Time Adaptation Meets Self-Supervised Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23529",
        "HTML": "https://arxiv.org/html/2506.23529v1",
        "PDF": "https://arxiv.org/pdf/2506.23529"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23532",
      "abstract": "We introduce GVIT, a classification framework that abandons conventional pixel or patch grid input representations in favor of a compact set of learnable 2D Gaussians. Each image is encoded as a few hundred Gaussians whose positions, scales, orientations, colors, and opacities are optimized jointly with a ViT classifier trained on top of these representations. We reuse the classifier gradients as constructive guidance, steering the Gaussians toward class-salient regions while a differentiable renderer optimizes an image reconstruction loss. We demonstrate that by 2D Gaussian input representations coupled with our GVIT guidance, using a relatively standard ViT architecture, closely matches the performance of a traditional patch-based ViT, reaching a 76.9% top-1 accuracy on Imagenet-1k using a ViT-B architecture.",
      "authors": [
        "Jefferson Hernandez",
        "Ruozhen He",
        "Guha Balakrishnan",
        "Alexander C. Berg",
        "Vicente Ordonez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T05:44:14+00:00",
          "link": "https://arxiv.org/abs/2506.23532v1",
          "size": "1633kb",
          "version": "v1"
        }
      ],
      "title": "GViT: Representing Images as Gaussians for Visual Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23532",
        "HTML": "https://arxiv.org/html/2506.23532v1",
        "PDF": "https://arxiv.org/pdf/2506.23532"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23534",
      "abstract": "Context: Software vulnerabilities pose a significant threat to modern software systems, as evidenced by the growing number of reported vulnerabilities and cyberattacks. These escalating trends underscore the urgent need for effective approaches that can automatically detect and understand software vulnerabilities. Objective: However, the scarcity of labeled samples and the class imbalance issue in vulnerability datasets present significant challenges for both Vulnerability Type Prediction (VTP) and Line-level Vulnerability Detection (LVD), especially for rare yet critical vulnerability types. Moreover, most existing studies treat VTP and LVD as independent tasks, overlooking their inherent correlation, which limits the potential to leverage shared semantic patterns across tasks. Methods: To address these limitations, we propose a unified approach that integrates Embedding-Layer Driven Adversarial Training (EDAT) with Multi-task Learning (MTL). Specifically, EDAT enhances model robustness by introducing adversarial perturbations to identifier embeddings, guided by semantic importance. Meanwhile, MTL improves overall performance by leveraging shared representations and inter-task correlations between VTP and LVD. Results: Extensive experiments demonstrate that our proposed approach outperforms state-of-the-art baselines on both VTP and LVD tasks. For VTP, it yields notable improvements in accuracy, precision, recall, and F1-score, particularly in identifying rare vulnerability types. Similarly, for LVD, our approach enhances line-level detection accuracy while significantly reducing false positives. Conclusion: Our study demonstrates that combining EDAT with MTL provides a unified solution that improves performance on both tasks and warrants further investigation.",
      "authors": [
        "Siyu Chen",
        "Jiongyi Yang",
        "Xiang Chen",
        "Menglin Zheng",
        "Minnan Wei",
        "Xiaolin Ju"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T05:47:09+00:00",
          "link": "https://arxiv.org/abs/2506.23534v1",
          "size": "689kb",
          "version": "v1"
        }
      ],
      "title": "Improving vulnerability type prediction and line-level detection via adversarial training-based data augmentation and multi-task learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23534",
        "HTML": "https://arxiv.org/html/2506.23534v1",
        "PDF": "https://arxiv.org/pdf/2506.23534"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23535",
      "abstract": "Safety-critical systems are engineered systems whose failure or malfunction could result in catastrophic consequences. The software development for safety-critical systems necessitates rigorous engineering practices and adherence to certification standards like DO-178C for avionics. DO-178C is a guidance document which requires compliance to well-defined software coding standards like MISRA C++ to enforce coding guidelines that prevent the use of ambiguous, unsafe, or undefined constructs. Large Language Models (LLMs) have demonstrated significant capabilities in automatic code generation across a wide range of programming languages, including C++. Despite their impressive performance, code generated by LLMs in safety-critical domains must be carefully analyzed for conformance to MISRA C++ coding standards. In this paper, I have conducted a comparative analysis of the C++ code generated by popular LLMs including: OpenAI ChatGPT, Google Gemini, DeepSeek, Meta AI, and Microsoft Copilot for compliance with MISRA C++.",
      "authors": [
        "Malik Muhammad Umer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T05:53:45+00:00",
          "link": "https://arxiv.org/abs/2506.23535v1",
          "size": "958kb",
          "version": "v1"
        }
      ],
      "title": "Comparative Analysis of the Code Generated by Popular Large Language Models (LLMs) for MISRA C++ Compliance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23535",
        "PDF": "https://arxiv.org/pdf/2506.23535"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23538",
      "abstract": "Congenital uterine anomalies (CUAs) can lead to infertility, miscarriage, preterm birth, and an increased risk of pregnancy complications. Compared to traditional 2D ultrasound (US), 3D US can reconstruct the coronal plane, providing a clear visualization of the uterine morphology for assessing CUAs accurately. In this paper, we propose an intelligent system for simultaneous automated plane localization and CUA diagnosis. Our highlights are: 1) we develop a denoising diffusion model with local (plane) and global (volume/text) guidance, using an adaptive weighting strategy to optimize attention allocation to different conditions; 2) we introduce a reinforcement learning-based framework with unsupervised rewards to extract the key slice summary from redundant sequences, fully integrating information across multiple planes to reduce learning difficulty; 3) we provide text-driven uncertainty modeling for coarse prediction, and leverage it to adjust the classification probability for overall performance improvement. Extensive experiments on a large 3D uterine US dataset show the efficacy of our method, in terms of plane localization and CUA diagnosis. Code is available at https://github.com/yuhoo0302/CUA-US.",
      "authors": [
        "Yuhao Huang",
        "Yueyue Xu",
        "Haoran Dou",
        "Jiaxiao Deng",
        "Xin Yang",
        "Hongyu Zheng",
        "Dong Ni"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T06:07:41+00:00",
          "link": "https://arxiv.org/abs/2506.23538v1",
          "size": "6669kb",
          "version": "v1"
        }
      ],
      "title": "Uncertainty-aware Diffusion and Reinforcement Learning for Joint Plane Localization and Anomaly Diagnosis in 3D Ultrasound",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23538",
        "HTML": "https://arxiv.org/html/2506.23538v1",
        "PDF": "https://arxiv.org/pdf/2506.23538"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23542",
      "abstract": "Depth images captured by Time-of-Flight (ToF) sensors are prone to noise, requiring denoising for reliable downstream applications. Previous works either focus on single-frame processing, or perform multi-frame processing without considering depth variations at corresponding pixels across frames, leading to undesirable temporal inconsistency and spatial ambiguity. In this paper, we propose a novel ToF depth denoising network leveraging motion-invariant graph fusion to simultaneously enhance temporal stability and spatial sharpness. Specifically, despite depth shifts across frames, graph structures exhibit temporal self-similarity, enabling cross-frame geometric attention for graph fusion. Then, by incorporating an image smoothness prior on the fused graph and data fidelity term derived from ToF noise distribution, we formulate a maximum a posterior problem for ToF denoising. Finally, the solution is unrolled into iterative filters whose weights are adaptively learned from the graph-informed geometric attention, producing a high-performance yet interpretable network. Experimental results demonstrate that the proposed scheme achieves state-of-the-art performance in terms of accuracy and consistency on synthetic DVToF dataset and exhibits robust generalization on the real Kinectv2 dataset. Source code will be released at \\href{https://github.com/davidweidawang/GIGA-ToF}{https://github.com/davidweidawang/GIGA-ToF}.",
      "authors": [
        "Weida Wang",
        "Changyong He",
        "Jin Zeng",
        "Di Qiu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T06:29:24+00:00",
          "link": "https://arxiv.org/abs/2506.23542v1",
          "size": "12588kb",
          "version": "v1"
        }
      ],
      "title": "Consistent Time-of-Flight Depth Denoising via Graph-Informed Geometric Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23542",
        "HTML": "https://arxiv.org/html/2506.23542v1",
        "PDF": "https://arxiv.org/pdf/2506.23542"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23543",
      "abstract": "Diffusion transformers (DiTs) adopt Patchify, mapping patch representations to token representations through linear projections, to adjust the number of tokens input to DiT blocks and thus the computation cost. Instead of a single patch size for all the timesteps, we introduce a Pyramidal Patchification Flow (PPFlow) approach: Large patch sizes are used for high noise timesteps and small patch sizes for low noise timesteps; Linear projections are learned for each patch size; and Unpatchify is accordingly modified. Unlike Pyramidal Flow, our approach operates over full latent representations other than pyramid representations, and adopts the normal denoising process without requiring the renoising trick. We demonstrate the effectiveness of our approach through two training manners. Training from scratch achieves a $1.6\\times$ ($2.0\\times$) inference speed over SiT-B/2 for 2-level (3-level) pyramid patchification with slightly lower training FLOPs and similar image generation performance. Training from pretrained normal DiTs achieves even better performance with small training time. The code and checkpoint are at https://github.com/fudan-generative-vision/PPFlow.",
      "authors": [
        "Hui Li",
        "Baoyou Chen",
        "Liwei Zhang",
        "Jiaye Li",
        "Jingdong Wang",
        "Siyu Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T06:29:24+00:00",
          "link": "https://arxiv.org/abs/2506.23543v1",
          "size": "22309kb",
          "version": "v1"
        }
      ],
      "title": "Pyramidal Patchification Flow for Visual Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23543",
        "PDF": "https://arxiv.org/pdf/2506.23543"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23544",
      "abstract": "Momentum methods were originally introduced for their superiority to stochastic gradient descent (SGD) in deterministic settings with convex objective functions. However, despite their widespread application to deep neural networks -- a representative case of stochastic nonconvex optimization -- the theoretical justification for their effectiveness in such settings remains limited. Quasi-hyperbolic momentum (QHM) is an algorithm that generalizes various momentum methods and has been studied to better understand the class of momentum-based algorithms as a whole. In this paper, we provide both asymptotic and non-asymptotic convergence results for mini-batch QHM with an increasing batch size. We show that achieving asymptotic convergence requires either a decaying learning rate or an increasing batch size. Since a decaying learning rate adversely affects non-asymptotic convergence, we demonstrate that using mini-batch QHM with an increasing batch size -- without decaying the learning rate -- can be a more effective strategy. Our experiments show that even a finite increase in batch size can provide benefits for training neural networks.",
      "authors": [
        "Kento Imaizumi",
        "Hideaki Iiduka"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T06:31:30+00:00",
          "link": "https://arxiv.org/abs/2506.23544v1",
          "size": "378kb",
          "version": "v1"
        }
      ],
      "title": "Both Asymptotic and Non-Asymptotic Convergence of Quasi-Hyperbolic Momentum using Increasing Batch Size",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23544",
        "HTML": "https://arxiv.org/html/2506.23544v1",
        "PDF": "https://arxiv.org/pdf/2506.23544"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23545",
      "abstract": "Virtual, Augmented, and eXtended Reality (VR/AR/XR) technologies are increasingly recognized for their applications in training, diagnostics, and psychological research, particularly in high-risk and highly regulated environments. In this panel we discuss how immersive systems enhance human performance across multiple domains, including clinical psychology, space exploration, and medical education. In psychological research and training, XR can offer a controlled yet ecologically valid setting for measuring cognitive and affective processes. In space exploration, we discuss the development of VR-based astronaut training and diagnostic systems, allowing astronauts to perform real-time health assessments. In medical education and rehabilitation, we cover procedural training and patient engagement. From virtual surgical simulations to gamified rehabilitation exercises, immersive environments enhance both learning outcomes and treatment adherence.",
      "authors": [
        "Barbara Karpowicz",
        "Maciej Grzeszczuk",
        "Adam Kuzdrali\\'nski",
        "Monika Kornacka",
        "Aliaksandr Marozau",
        "Wiktor Stawski",
        "Pavlo Zinevych",
        "Grzegorz Marcin W\\'ojcik",
        "Tomasz Kowalewski",
        "Grzegorz Pochwatko",
        "Wies{\\l}aw Kope\\'c"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T06:31:38+00:00",
          "link": "https://arxiv.org/abs/2506.23545v1",
          "size": "379kb",
          "version": "v1"
        }
      ],
      "title": "Immersive Technologies in Training and Healthcare: From Space Missions to Psychophysiological Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23545",
        "HTML": "https://arxiv.org/html/2506.23545v1",
        "PDF": "https://arxiv.org/pdf/2506.23545"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23547",
      "abstract": "The first algorithm, called Oneta, for a novel task of multi-style image enhancement is proposed in this work. Oneta uses two point operators sequentially: intensity enhancement with a transformation function (TF) and color correction with a color correction matrix (CCM). This two-step enhancement model, though simple, achieves a high performance upper bound. Also, we introduce eigentransformation function (eigenTF) to represent TF compactly. The Oneta network comprises Y-Net and C-Net to predict eigenTF and CCM parameters, respectively. To support $K$ styles, Oneta employs $K$ learnable tokens. During training, each style token is learned using image pairs from the corresponding dataset. In testing, Oneta selects one of the $K$ style tokens to enhance an image accordingly. Extensive experiments show that the single Oneta network can effectively undertake six enhancement tasks -- retouching, image signal processing, low-light image enhancement, dehazing, underwater image enhancement, and white balancing -- across 30 datasets.",
      "authors": [
        "Jiwon Kim",
        "Soohyun Hwang",
        "Dong-O Kim",
        "Changsu Han",
        "Min Kyu Park",
        "Chang-Su Kim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T06:36:11+00:00",
          "link": "https://arxiv.org/abs/2506.23547v1",
          "size": "24258kb",
          "version": "v1"
        }
      ],
      "title": "Oneta: Multi-Style Image Enhancement Using Eigentransformation Functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23547",
        "PDF": "https://arxiv.org/pdf/2506.23547"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23549",
      "abstract": "Effective coordination among artificial agents in dynamic and uncertain environments remains a significant challenge in multi-agent systems. Existing approaches, such as self-play and population-based methods, either generalize poorly to unseen partners or require extensive training. To overcome these limitations, we propose Coordination Transformers (CooT), a novel in-context coordination framework that uses recent interaction histories to adapt to unseen partners rapidly. Unlike previous approaches that primarily aim to increase the diversity of training partners, CooT explicitly focuses on adapting to new partner behaviors by predicting actions aligned with observed partner interactions. Trained on interaction trajectories collected from diverse pairs of agents with complementary behaviors, CooT quickly learns effective coordination strategies without explicit supervision or fine-tuning. Evaluations on the Overcooked benchmark demonstrate that CooT significantly outperforms baseline methods in coordination tasks involving previously unseen partners. Human evaluations further confirm CooT as the most effective collaborative partner, while extensive ablations highlight its robustness, flexibility, and sensitivity to context in multi-agent scenarios.",
      "authors": [
        "Huai-Chih Wang",
        "Hsiang-Chun Chuang",
        "Hsi-Chun Cheng",
        "Dai-Jie Wu",
        "Shao-Hua Sun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T06:45:39+00:00",
          "link": "https://arxiv.org/abs/2506.23549v1",
          "size": "3127kb",
          "version": "v1"
        }
      ],
      "title": "CooT: Learning to Coordinate In-Context with Coordination Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23549",
        "HTML": "https://arxiv.org/html/2506.23549v1",
        "PDF": "https://arxiv.org/pdf/2506.23549"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23551",
      "abstract": "We investigate the universal approximation property (UAP) of transformer-type architectures, providing a unified theoretical framework that extends prior results on residual networks to models incorporating attention mechanisms. Our work identifies token distinguishability as a fundamental requirement for UAP and introduces a general sufficient condition that applies to a broad class of architectures. Leveraging an analyticity assumption on the attention layer, we can significantly simplify the verification of this condition, providing a non-constructive approach in establishing UAP for such architectures. We demonstrate the applicability of our framework by proving UAP for transformers with various attention mechanisms, including kernel-based and sparse attention mechanisms. The corollaries of our results either generalize prior works or establish UAP for architectures not previously covered. Furthermore, our framework offers a principled foundation for designing novel transformer architectures with inherent UAP guarantees, including those with specific functional symmetries. We propose examples to illustrate these insights.",
      "authors": [
        "Jingpu Cheng",
        "Qianxiao Li",
        "Ting Lin",
        "Zuowei Shen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T06:50:39+00:00",
          "link": "https://arxiv.org/abs/2506.23551v1",
          "size": "58kb",
          "version": "v1"
        }
      ],
      "title": "A unified framework on the universal approximation of transformer-type architectures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23551",
        "HTML": "https://arxiv.org/html/2506.23551v1",
        "PDF": "https://arxiv.org/pdf/2506.23551"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23552",
      "abstract": "The intrinsic link between facial motion and speech is often overlooked in generative modeling, where talking head synthesis and text-to-speech (TTS) are typically addressed as separate tasks. This paper introduces JAM-Flow, a unified framework to simultaneously synthesize and condition on both facial motion and speech. Our approach leverages flow matching and a novel Multi-Modal Diffusion Transformer (MM-DiT) architecture, integrating specialized Motion-DiT and Audio-DiT modules. These are coupled via selective joint attention layers and incorporate key architectural choices, such as temporally aligned positional embeddings and localized joint attention masking, to enable effective cross-modal interaction while preserving modality-specific strengths. Trained with an inpainting-style objective, JAM-Flow supports a wide array of conditioning inputs-including text, reference audio, and reference motion-facilitating tasks such as synchronized talking head generation from text, audio-driven animation, and much more, within a single, coherent model. JAM-Flow significantly advances multi-modal generative modeling by providing a practical solution for holistic audio-visual synthesis. project page: https://joonghyuk.com/jamflow-web",
      "authors": [
        "Mingi Kwon",
        "Joonghyuk Shin",
        "Jaeseok Jung",
        "Jaesik Park",
        "Youngjung Uh"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T06:51:40+00:00",
          "link": "https://arxiv.org/abs/2506.23552v1",
          "size": "2315kb",
          "version": "v1"
        }
      ],
      "title": "JAM-Flow: Joint Audio-Motion Synthesis with Flow Matching",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23552",
        "HTML": "https://arxiv.org/html/2506.23552v1",
        "PDF": "https://arxiv.org/pdf/2506.23552"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23554",
      "abstract": "To address challenges in improving self-consumption of renewables and resilience in local residential power systems, the earlier work of the authors introduced a novel multi-energy management concept, integrating bidirectional power routing and electricity-hydrogen conversion. This paper focuses on an experimental verification of the bidirectional power router based on line-switching, the essential hardware to realize the concept. The primary contribution is the validation of the router's capability to handle dynamic change of bidirectional power flow. Furthermore, to achieve bidirectional power routing without affecting the smooth and stable operation of the power system, a novel algorithm for router's switching is designed based on power flow monitoring. The effectiveness of the proposed method is demonstrated through an experiment using a setup with a commercially available stationary battery.",
      "authors": [
        "Shiu Mochiyama",
        "Ryo Takahashi",
        "Yoshihiko Susuki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T06:58:20+00:00",
          "link": "https://arxiv.org/abs/2506.23554v1",
          "size": "776kb",
          "version": "v1"
        }
      ],
      "title": "A Bidirectional Power Router for Traceable Multi-energy Management",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23554",
        "HTML": "https://arxiv.org/html/2506.23554v1",
        "PDF": "https://arxiv.org/pdf/2506.23554"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23555",
      "abstract": "In current practical face authentication systems, most face recognition (FR) algorithms are based on cosine similarity with softmax classification. Despite its reliable classification performance, this method struggles with hard samples. A popular strategy to improve FR performance is incorporating angular or cosine margins. However, it does not take face quality or recognition hardness into account, simply increasing the margin value and thus causing an overly uniform training strategy. To address this problem, a novel loss function is proposed, named Loss function for Hard High-quality Face (LH2Face). Firstly, a similarity measure based on the von Mises-Fisher (vMF) distribution is stated, specifically focusing on the logarithm of the Probability Density Function (PDF), which represents the distance between a probability distribution and a vector. Then, an adaptive margin-based multi-classification method using softmax, called the Uncertainty-Aware Margin Function, is implemented in the article. Furthermore, proxy-based loss functions are used to apply extra constraints between the proxy and sample to optimize their representation space distribution. Finally, a renderer is constructed that optimizes FR through face reconstruction and vice versa. Our LH2Face is superior to similiar schemes on hard high-quality face datasets, achieving 49.39% accuracy on the IJB-B dataset, which surpasses the second-place method by 2.37%.",
      "authors": [
        "Fan Xie",
        "Pan Cao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T06:59:02+00:00",
          "link": "https://arxiv.org/abs/2506.23555v1",
          "size": "4592kb",
          "version": "v1"
        }
      ],
      "title": "LH2Face: Loss function for Hard High-quality Face",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23555",
        "HTML": "https://arxiv.org/html/2506.23555v1",
        "PDF": "https://arxiv.org/pdf/2506.23555"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23558",
      "abstract": "Version 2.10 of the Distributed and Unified Numerics Environment DUNE introduces a range of enhancements across its core and extension modules, with a continued emphasis on modern C++ integration and improved usability. This release extends support for C++20 features, particularly concepts, through comprehensive refinements in dune-common and dune-grid, enabling safer and more expressive generic programming paradigms. A notable advancement is the improved support for curved geometries, including new geometry implementations and a more flexible interface. Data structures have been modernized through native support for std::mdspan and std::mdarray, performance improvements in sparse matrices, and tools for visualization of matrix patterns. The build system has been restructured towards a modern CMake workflow, emphasizing target-based configuration and improved automation. Furthermore, new local finite elements have been introduced to broaden numerical capabilities. The release also brings updates across DUNE extensions, as well as improvements to infrastructure and module-level components.",
      "authors": [
        "Markus Blatt",
        "Samuel Burbulla",
        "Ansgar Burchardt",
        "Andreas Dedner",
        "Christian Engwer",
        "Carsten Gr\\\"aser",
        "Christoph Gr\\\"uninger",
        "Robert Kl\\\"ofkorn",
        "Timo Koch",
        "Santiago Ospina De Los R\\'ios",
        "Simon Praetorius",
        "Oliver Sander"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Mathematical Software (cs.MS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T07:06:11+00:00",
          "link": "https://arxiv.org/abs/2506.23558v1",
          "size": "83kb",
          "version": "v1"
        }
      ],
      "title": "The Distributed and Unified Numerics Environment (DUNE), Version 2.10",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23558",
        "HTML": "https://arxiv.org/html/2506.23558v1",
        "PDF": "https://arxiv.org/pdf/2506.23558"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23561",
      "abstract": "#NFA refers to the problem of counting the words of length $n$ accepted by a non-deterministic finite automaton. #NFA is #P-hard, and although fully-polynomial-time randomized approximation schemes (FPRAS) exist, they are all impractical. The first FPRAS for #NFA had a running time of $\\tilde{O}(n^{17}m^{17}\\varepsilon^{-14}\\log(\\delta^{-1}))$, where $m$ is the number of states in the automaton, $\\delta \\in (0,1]$ is the confidence parameter, and $\\varepsilon > 0$ is the tolerance parameter (typically smaller than $1$). The current best FPRAS achieved a significant improvement in the time complexity relative to the first FPRAS and obtained FPRAS with time complexity $\\tilde{O}((n^{10}m^2 + n^6m^3)\\varepsilon^{-4}\\log^2(\\delta^{-1}))$. The complexity of the improved FPRAS is still too intimidating to attempt any practical implementation.\n  In this paper, we pursue the quest for practical FPRAS for #NFA by presenting a new algorithm with a time complexity of $O(n^2m^3\\log(nm)\\varepsilon^{-2}\\log(\\delta^{-1}))$. Observe that evaluating whether a word of length $n$ is accepted by an NFA has a time complexity of $O(nm^2)$. Therefore, our proposed FPRAS achieves sub-quadratic complexity with respect to membership checks.",
      "authors": [
        "Kuldeep S. Meel and Alexis de Colnet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T07:08:06+00:00",
          "link": "https://arxiv.org/abs/2506.23561v1",
          "size": "55kb",
          "version": "v1"
        }
      ],
      "title": "Towards practical FPRAS for #NFA: Exploiting the Power of Dependence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23561",
        "PDF": "https://arxiv.org/pdf/2506.23561"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23563",
      "abstract": "Reasoning plays a crucial role in advancing Multimodal Large Language Models (MLLMs) toward Artificial General Intelligence. However, existing MLLM benchmarks often fall short in precisely and comprehensively evaluating long-chain reasoning abilities from three key aspects: (1) lack of difficulty and diversity, (2) susceptibility to guessability and memorization, (3) inadequate assessment of intermediate reasoning steps. To fill this gap, we introduce MMReason, a new benchmark designed to precisely and comprehensively evaluate MLLM long-chain reasoning capability with diverse, open-ended, challenging questions. First, we curate challenging questions requiring multi-step reasoning from various fields (i.e., 6 disciplines) and multiple difficulty levels (i.e., from pre-university to university, and from foundational to competition tiers). Second, these questions are reformulated into an open-ended format and filtered using a multi-model voting technique to eliminate shortcut cases related to guessing and memorization, ensuring robust reasoning evaluations. Third, we annotate the questions with detailed step-by-step solutions, and design a reference-based ternary scoring mechanism to reliably assess intermediate reasoning steps. With MMReason, we benchmark popular leading MLLMs and provide an in-depth analysis of their reasoning capabilities. We hope MMReason will serve as a valuable resource for advancing MLLM reasoning research. Code will be available at https://github.com/HJYao00/MMReason.",
      "authors": [
        "Huanjin Yao",
        "Jiaxing Huang",
        "Yawen Qiu",
        "Michael K. Chen",
        "Wenzheng Liu",
        "Wei Zhang",
        "Wenjie Zeng",
        "Xikun Zhang",
        "Jingyi Zhang",
        "Yuxin Song",
        "Wenhao Wu",
        "Dacheng Tao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T07:14:38+00:00",
          "link": "https://arxiv.org/abs/2506.23563v1",
          "size": "1931kb",
          "version": "v1"
        }
      ],
      "title": "MMReason: An Open-Ended Multi-Modal Multi-Step Reasoning Benchmark for MLLMs Toward AGI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23563",
        "HTML": "https://arxiv.org/html/2506.23563v1",
        "PDF": "https://arxiv.org/pdf/2506.23563"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23565",
      "abstract": "Current multi-view 3D object detection methods typically transfer 2D features into 3D space using depth estimation or 3D position encoder, but in a fully data-driven and implicit manner, which limits the detection performance. Inspired by the success of radiance fields on 3D reconstruction, we assume they can be used to enhance the detector's ability of 3D geometry estimation. However, we observe a decline in detection performance, when we directly use them for 3D rendering as an auxiliary task. From our analysis, we find the performance drop is caused by the strong responses on the background when rendering the whole scene. To address this problem, we propose object-centric radiance fields, focusing on modeling foreground objects while discarding background noises. Specifically, we employ Object-centric Radiance Fields (OcRF) to enhance 3D voxel features via an auxiliary task of rendering foreground objects. We further use opacity - the side-product of rendering- to enhance the 2D foreground BEV features via Height-aware Opacity-based Attention (HOA), where attention maps at different height levels are generated separately via multiple networks in parallel. Extensive experiments on the nuScenes validation and test datasets demonstrate that our OcRFDet achieves superior performance, outperforming previous state-of-the-art methods with 57.2$\\%$ mAP and 64.8$\\%$ NDS on the nuScenes test benchmark. Code will be available at https://github.com/Mingqj/OcRFDet.",
      "authors": [
        "Mingqian Ji",
        "Jian Yang",
        "Shanshan Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T07:18:17+00:00",
          "link": "https://arxiv.org/abs/2506.23565v1",
          "size": "893kb",
          "version": "v1"
        }
      ],
      "title": "OcRFDet: Object-Centric Radiance Fields for Multi-View 3D Object Detection in Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23565",
        "HTML": "https://arxiv.org/html/2506.23565v1",
        "PDF": "https://arxiv.org/pdf/2506.23565"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23566",
      "abstract": "The acquisition of high-resolution satellite imagery is often constrained by the spatial and temporal limitations of satellite sensors, as well as the high costs associated with frequent observations. These challenges hinder applications such as environmental monitoring, disaster response, and agricultural management, which require fine-grained and high-resolution data. In this paper, we propose MWT-Diff, an innovative framework for satellite image super-resolution (SR) that combines latent diffusion models with wavelet transforms to address these challenges. At the core of the framework is a novel metadata-, wavelet-, and time-aware encoder (MWT-Encoder), which generates embeddings that capture metadata attributes, multi-scale frequency information, and temporal relationships. The embedded feature representations steer the hierarchical diffusion dynamics, through which the model progressively reconstructs high-resolution satellite imagery from low-resolution inputs. This process preserves critical spatial characteristics including textural patterns, boundary discontinuities, and high-frequency spectral components essential for detailed remote sensing analysis. The comparative analysis of MWT-Diff across multiple datasets demonstrated favorable performance compared to recent approaches, as measured by standard perceptual quality metrics including FID and LPIPS.",
      "authors": [
        "Luigi Sigillo",
        "Renato Giamba",
        "Danilo Comminiello"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T07:19:50+00:00",
          "link": "https://arxiv.org/abs/2506.23566v1",
          "size": "20952kb",
          "version": "v1"
        }
      ],
      "title": "Metadata, Wavelet, and Time Aware Diffusion Models for Satellite Image Super Resolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23566",
        "HTML": "https://arxiv.org/html/2506.23566v1",
        "PDF": "https://arxiv.org/pdf/2506.23566"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23573",
      "abstract": "The deployment of robot assistants in large indoor spaces has seen significant growth, with escorting tasks becoming a key application. However, most current escorting robots primarily rely on navigation-focused strategies, assuming that the person being escorted will follow without issue. In crowded environments, this assumption often falls short, as individuals may struggle to keep pace, become obstructed, get distracted, or need to stop unexpectedly. As a result, conventional robotic systems are often unable to provide effective escorting services due to their limited understanding of human movement dynamics. To address these challenges, an effective escorting robot must continuously detect and interpret human actions during the escorting process and adjust its movement accordingly. However, there is currently no existing dataset designed specifically for human action detection in the context of escorting. Given that escorting often occurs in crowded environments, where other individuals may enter the robot's camera view, the robot also needs to identify the specific human it is escorting (the subject) before predicting their actions. Since no existing model performs both person re-identification and action prediction in real-time, we propose a novel neural network architecture that can accomplish both tasks. This enables the robot to adjust its speed dynamically based on the escortee's movements and seamlessly resume escorting after any disruption. In comparative evaluations against strong baselines, our system demonstrates superior efficiency and effectiveness, showcasing its potential to significantly improve robotic escorting services in complex, real-world scenarios.",
      "authors": [
        "Siddhartha Mondal",
        "Avik Mitra",
        "Chayan Sarkar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T07:25:31+00:00",
          "link": "https://arxiv.org/abs/2506.23573v1",
          "size": "1991kb",
          "version": "v1"
        }
      ],
      "title": "Online Human Action Detection during Escorting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23573",
        "HTML": "https://arxiv.org/html/2506.23573v1",
        "PDF": "https://arxiv.org/pdf/2506.23573"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23575",
      "abstract": "Small object detection (SOD) in anti-UAV task is a challenging problem due to the small size of UAVs and complex backgrounds. Traditional frame-based cameras struggle to detect small objects in complex environments due to their low frame rates, limited dynamic range, and data redundancy. Event cameras, with microsecond temporal resolution and high dynamic range, provide a more effective solution for SOD. However, existing event-based object detection datasets are limited in scale, feature large targets size, and lack diverse backgrounds, making them unsuitable for SOD benchmarks. In this paper, we introduce a Event-based Small object detection (EVSOD) dataset (namely EV-UAV), the first large-scale, highly diverse benchmark for anti-UAV tasks. It includes 147 sequences with over 2.3 million event-level annotations, featuring extremely small targets (averaging 6.8 $\\times$ 5.4 pixels) and diverse scenarios such as urban clutter and extreme lighting conditions. Furthermore, based on the observation that small moving targets form continuous curves in spatiotemporal event point clouds, we propose Event based Sparse Segmentation Network (EV-SpSegNet), a novel baseline for event segmentation in point cloud space, along with a Spatiotemporal Correlation (STC) loss that leverages motion continuity to guide the network in retaining target events. Extensive experiments on the EV-UAV dataset demonstrate the superiority of our method and provide a benchmark for future research in EVSOD. The dataset and code are at https://github.com/ChenYichen9527/Ev-UAV.",
      "authors": [
        "Nuo Chen",
        "Chao Xiao",
        "Yimian Dai",
        "Shiman He",
        "Miao Li",
        "Wei An"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T07:28:50+00:00",
          "link": "https://arxiv.org/abs/2506.23575v1",
          "size": "1989kb",
          "version": "v1"
        }
      ],
      "title": "Event-based Tiny Object Detection: A Benchmark Dataset and Baseline",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23575",
        "HTML": "https://arxiv.org/html/2506.23575v1",
        "PDF": "https://arxiv.org/pdf/2506.23575"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23576",
      "abstract": "Recent advances in large language models (LLMs) have raised concerns about jailbreaking attacks, i.e., prompts that bypass safety mechanisms. This paper investigates the use of multi-agent LLM systems as a defence against such attacks. We evaluate three jailbreaking strategies, including the original AutoDefense attack and two from Deepleaps: BetterDan and JB. Reproducing the AutoDefense framework, we compare single-agent setups with two- and three-agent configurations. Our results show that multi-agent systems enhance resistance to jailbreaks, especially by reducing false negatives. However, its effectiveness varies by attack type, and it introduces trade-offs such as increased false positives and computational overhead. These findings point to the limitations of current automated defences and suggest directions for improving alignment robustness in future LLM systems.",
      "authors": [
        "Maria Carolina Cornelia Wit and Jun Pang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T07:29:07+00:00",
          "link": "https://arxiv.org/abs/2506.23576v1",
          "size": "223kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating Multi-Agent Defences Against Jailbreaking Attacks on Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23576",
        "PDF": "https://arxiv.org/pdf/2506.23576"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23577",
      "abstract": "Enhancing the alignment between text and image features in the CLIP model is a critical challenge in zero-shot industrial anomaly detection tasks. Recent studies predominantly utilize specific category prompts during pretraining, which can cause overfitting to the training categories and limit model generalization. To address this, we propose a method that transforms category names through multicategory name stacking to create stacked prompts, forming the basis of our StackCLIP model. Our approach introduces two key components. The Clustering-Driven Stacked Prompts (CSP) module constructs generic prompts by stacking semantically analogous categories, while utilizing multi-object textual feature fusion to amplify discriminative anomalies among similar objects. The Ensemble Feature Alignment (EFA) module trains knowledge-specific linear layers tailored for each stack cluster and adaptively integrates them based on the attributes of test categories. These modules work together to deliver superior training speed, stability, and convergence, significantly boosting anomaly segmentation performance. Additionally, our stacked prompt framework offers robust generalization across classification tasks. To further improve performance, we introduce the Regulating Prompt Learning (RPL) module, which leverages the generalization power of stacked prompts to refine prompt learning, elevating results in anomaly detection classification tasks. Extensive testing on seven industrial anomaly detection datasets demonstrates that our method achieves state-of-the-art performance in both zero-shot anomaly detection and segmentation tasks.",
      "authors": [
        "Yanning Hou",
        "Yanran Ruan",
        "Junfa Li",
        "Shanshan Wang",
        "Jianfeng Qiu",
        "Ke Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T07:29:10+00:00",
          "link": "https://arxiv.org/abs/2506.23577v1",
          "size": "3314kb",
          "version": "v1"
        }
      ],
      "title": "StackCLIP: Clustering-Driven Stacked Prompt in Zero-Shot Industrial Anomaly Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23577",
        "HTML": "https://arxiv.org/html/2506.23577v1",
        "PDF": "https://arxiv.org/pdf/2506.23577"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23578",
      "abstract": "We investigate the reachability problem in symmetric vector addition systems with states (VASS), where transitions are invariant under a group of permutations of coordinates. One extremal case, the trivial groups, yields general VASS. In another extremal case, the symmetric groups, we show that the reachability problem can be solved in PSPACE, regardless of the dimension of input VASS (to be contrasted with Ackermannian complexity in general VASS). We also consider other groups, in particular alternating and cyclic ones. Furthermore, motivated by the open status of the reachability problem in data VASS, we estimate the gain in complexity when the group arises as a combination of the trivial and symmetric groups.",
      "authors": [
        "{\\L}ukasz Kami\\'nski and S{\\l}awomir Lasota"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T07:33:50+00:00",
          "link": "https://arxiv.org/abs/2506.23578v1",
          "size": "239kb",
          "version": "v1"
        }
      ],
      "title": "Reachability in symmetric VASS",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23578",
        "PDF": "https://arxiv.org/pdf/2506.23578"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23580",
      "abstract": "Dataset distillation (DD) condenses large datasets into compact yet informative substitutes, preserving performance comparable to the original dataset while reducing storage, transmission costs, and computational consumption. However, previous DD methods mainly focus on distilling information from images, often overlooking the semantic information inherent in the data. The disregard for context hinders the model's generalization ability, particularly in tasks involving complex datasets, which may result in illogical outputs or the omission of critical objects. In this study, we integrate vision-language methods into DD by introducing text prototypes to distill language information and collaboratively synthesize data with image prototypes, thereby enhancing dataset distillation performance. Notably, the text prototypes utilized in this study are derived from descriptive text information generated by an open-source large language model. This framework demonstrates broad applicability across datasets without pre-existing text descriptions, expanding the potential of dataset distillation beyond traditional image-based approaches. Compared to other methods, the proposed approach generates logically coherent images containing target objects, achieving state-of-the-art validation performance and demonstrating robust generalization. Source code and generated data are available in https://github.com/zou-yawen/Dataset-Distillation-via-Vision-Language-Category-Prototype/",
      "authors": [
        "Yawen Zou",
        "Guang Li",
        "Duo Su",
        "Zi Wang",
        "Jun Yu",
        "Chao Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T07:34:33+00:00",
          "link": "https://arxiv.org/abs/2506.23580v1",
          "size": "1288kb",
          "version": "v1"
        }
      ],
      "title": "Dataset Distillation via Vision-Language Category Prototype",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23580",
        "HTML": "https://arxiv.org/html/2506.23580v1",
        "PDF": "https://arxiv.org/pdf/2506.23580"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23581",
      "abstract": "Object detection plays a crucial role in many security-sensitive applications. However, several recent studies have shown that object detectors can be easily fooled by physically realizable attacks, \\eg, adversarial patches and recent adversarial textures, which pose realistic and urgent threats. Adversarial Training (AT) has been recognized as the most effective defense against adversarial attacks. While AT has been extensively studied in the $l_\\infty$ attack settings on classification models, AT against physically realizable attacks on object detectors has received limited exploration. Early attempts are only performed to defend against adversarial patches, leaving AT against a wider range of physically realizable attacks under-explored. In this work, we consider defending against various physically realizable attacks with a unified AT method. We propose PBCAT, a novel Patch-Based Composite Adversarial Training strategy. PBCAT optimizes the model by incorporating the combination of small-area gradient-guided adversarial patches and imperceptible global adversarial perturbations covering the entire image. With these designs, PBCAT has the potential to defend against not only adversarial patches but also unseen physically realizable attacks such as adversarial textures. Extensive experiments in multiple settings demonstrated that PBCAT significantly improved robustness against various physically realizable attacks over state-of-the-art defense methods. Notably, it improved the detection accuracy by 29.7\\% over previous defense methods under one recent adversarial texture attack.",
      "authors": [
        "Xiao Li",
        "Yiming Zhu",
        "Yifan Huang",
        "Wei Zhang",
        "Yingzhe He",
        "Jie Shi",
        "Xiaolin Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T07:36:21+00:00",
          "link": "https://arxiv.org/abs/2506.23581v1",
          "size": "533kb",
          "version": "v1"
        }
      ],
      "title": "PBCAT: Patch-based composite adversarial training against physically realizable attacks on object detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23581",
        "HTML": "https://arxiv.org/html/2506.23581v1",
        "PDF": "https://arxiv.org/pdf/2506.23581"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23582",
      "abstract": "In text-to-audio (TTA) research, the relevance between input text and output audio is an important evaluation aspect. Traditionally, it has been evaluated from both subjective and objective perspectives. However, subjective evaluation is costly in terms of money and time, and objective evaluation is unclear regarding the correlation to subjective evaluation scores. In this study, we construct RELATE, an open-sourced dataset that subjectively evaluates the relevance. Also, we benchmark a model for automatically predicting the subjective evaluation score from synthesized audio. Our model outperforms a conventional CLAPScore model, and that trend extends to many sound categories.",
      "authors": [
        "Yusuke Kanamori",
        "Yuki Okamoto",
        "Taisei Takano",
        "Shinnosuke Takamichi",
        "Yuki Saito",
        "Hiroshi Saruwatari"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T07:36:28+00:00",
          "link": "https://arxiv.org/abs/2506.23582v1",
          "size": "3644kb",
          "version": "v1"
        }
      ],
      "title": "RELATE: Subjective evaluation dataset for automatic evaluation of relevance between text and audio",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23582",
        "HTML": "https://arxiv.org/html/2506.23582v1",
        "PDF": "https://arxiv.org/pdf/2506.23582"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23583",
      "abstract": "Federated learning with secure aggregation enables private and collaborative learning from decentralised data without leaking sensitive client information. However, secure aggregation also complicates the detection of malicious client behaviour and the evaluation of individual client contributions to the learning. To address these challenges, QI (Pejo et al.) and FedGT (Xhemrishi et al.) were proposed for contribution evaluation (CE) and misbehaviour detection (MD), respectively. QI, however, lacks adequate MD accuracy due to its reliance on the random selection of clients in each training round, while FedGT lacks the CE ability. In this work, we combine the strengths of QI and FedGT to achieve both robust MD and accurate CE. Our experiments demonstrate superior performance compared to using either method independently.",
      "authors": [
        "Marvin Xhemrishi",
        "Alexandre Graell i Amat",
        "Bal\\'azs Pej\\'o"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T07:40:18+00:00",
          "link": "https://arxiv.org/abs/2506.23583v1",
          "size": "246kb",
          "version": "v1"
        }
      ],
      "title": "Detect \\& Score: Privacy-Preserving Misbehaviour Detection and Contribution Evaluation in Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23583",
        "PDF": "https://arxiv.org/pdf/2506.23583"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23589",
      "abstract": "Diffusion and flow matching models have significantly advanced media generation, yet their design space is well-explored, somewhat limiting further improvements. Concurrently, autoregressive (AR) models, particularly those generating continuous tokens, have emerged as a promising direction for unifying text and media generation. This paper introduces Transition Matching (TM), a novel discrete-time, continuous-state generative paradigm that unifies and advances both diffusion/flow models and continuous AR generation. TM decomposes complex generation tasks into simpler Markov transitions, allowing for expressive non-deterministic probability transition kernels and arbitrary non-continuous supervision processes, thereby unlocking new flexible design avenues. We explore these choices through three TM variants: (i) Difference Transition Matching (DTM), which generalizes flow matching to discrete-time by directly learning transition probabilities, yielding state-of-the-art image quality and text adherence as well as improved sampling efficiency. (ii) Autoregressive Transition Matching (ARTM) and (iii) Full History Transition Matching (FHTM) are partially and fully causal models, respectively, that generalize continuous AR methods. They achieve continuous causal AR generation quality comparable to non-causal approaches and potentially enable seamless integration with existing AR text generation techniques. Notably, FHTM is the first fully causal model to match or surpass the performance of flow-based methods on text-to-image task in continuous domains. We demonstrate these contributions through a rigorous large-scale comparison of TM variants and relevant baselines, maintaining a fixed architecture, training data, and hyperparameters.",
      "authors": [
        "Neta Shaul",
        "Uriel Singer",
        "Itai Gat",
        "Yaron Lipman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T07:51:58+00:00",
          "link": "https://arxiv.org/abs/2506.23589v1",
          "size": "30062kb",
          "version": "v1"
        }
      ],
      "title": "Transition Matching: Scalable and Flexible Generative Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23589",
        "HTML": "https://arxiv.org/html/2506.23589v1",
        "PDF": "https://arxiv.org/pdf/2506.23589"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23590",
      "abstract": "Although Large Vision-Language Models (LVLMs) have demonstrated powerful capabilities in interpreting visual information, they frequently produce content that deviates from visual information, leading to object hallucination. To tackle this, recent works mostly depend on expensive manual annotations and training cost, or significantly increase inference time. In this work, we observe that LVLMs' attention to visual information is significantly stronger when answering caption queries compared to non-caption queries. Inspired by this phenomenon, we propose Caption-sensitive Attention Intervention (CAI), a training-free, plug-and-play hallucination mitigation method that leverages the attention activation pattern in response to caption queries to enhance LVLMs' visual perception capability. Extensive experimental results across four benchmarks covering both discriminative and generative tasks, demonstrate that CAI achieves state-of-the-art (SOTA) hallucination mitigating performance only with minimal additional inference cost.",
      "authors": [
        "Qiming Li",
        "Zekai Ye",
        "Xiaocheng Feng",
        "Weihong Zhong",
        "Libo Qin",
        "Ruihan Chen",
        "Baohang Li",
        "Kui Jiang",
        "Yaowei Wang",
        "Ting Liu",
        "Bing Qin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T07:52:36+00:00",
          "link": "https://arxiv.org/abs/2506.23590v1",
          "size": "5830kb",
          "version": "v1"
        }
      ],
      "title": "CAI: Caption-Sensitive Attention Intervention for Mitigating Object Hallucination in Large Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23590",
        "PDF": "https://arxiv.org/pdf/2506.23590"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23592",
      "abstract": "The cybersecurity industry combines \"automated\" and \"autonomous\" AI, creating dangerous misconceptions about system capabilities. Recent milestones like XBOW topping HackerOne's leaderboard showcase impressive progress, yet these systems remain fundamentally semi-autonomous--requiring human oversight. Drawing from robotics principles, where the distinction between automation and autonomy is well-established, I take inspiration from prior work and establish a 6-level taxonomy (Level 0-5) distinguishing automation from autonomy in Cybersecurity AI. Current \"autonomous\" pentesters operate at Level 3-4: they execute complex attack sequences but need human review for edge cases and strategic decisions. True Level 5 autonomy remains aspirational. Organizations deploying mischaracterized \"autonomous\" tools risk reducing oversight precisely when it's most needed, potentially creating new vulnerabilities. The path forward requires precise terminology, transparent capabilities disclosure, and human-AI partnership-not replacement.",
      "authors": [
        "V\\'ictor Mayoral-Vilches"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T07:55:24+00:00",
          "link": "https://arxiv.org/abs/2506.23592v1",
          "size": "60kb",
          "version": "v1"
        }
      ],
      "title": "Cybersecurity AI: The Dangerous Gap Between Automation and Autonomy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23592",
        "HTML": "https://arxiv.org/html/2506.23592v1",
        "PDF": "https://arxiv.org/pdf/2506.23592"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23596",
      "abstract": "Recently, forecasting future abnormal events has emerged as an important scenario to tackle real-world necessities. However, the solution of predicting specific future time points when anomalies will occur, known as Anomaly Prediction (AP), remains under-explored. Existing methods dealing with time series data fail in AP, focusing only on immediate anomalies or failing to provide precise predictions for future anomalies. To address the AP task, we propose a novel framework called Anomaly to Prompt (A2P), comprised of Anomaly-Aware Forecasting (AAF) and Synthetic Anomaly Prompting (SAP). To enable the forecasting model to forecast abnormal time points, we adopt a strategy to learn the relationships of anomalies. For the robust detection of anomalies, our proposed SAP introduces a learnable Anomaly Prompt Pool (APP) that simulates diverse anomaly patterns using signal adaptive prompt. Comprehensive experiments on multiple real-world datasets demonstrate the superiority of A2P over state-of-the-art methods, showcasing its ability to predict future anomalies. Our implementation code is available at https://github.com/KU-VGI/AP.",
      "authors": [
        "Min-Yeong Park",
        "Won-Jeong Lee",
        "Seong Tae Kim",
        "Gyeong-Moon Park"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T08:00:16+00:00",
          "link": "https://arxiv.org/abs/2506.23596v1",
          "size": "2636kb",
          "version": "v1"
        }
      ],
      "title": "When Will It Fail?: Anomaly to Prompt for Forecasting Future Anomalies in Time Series",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23596",
        "HTML": "https://arxiv.org/html/2506.23596v1",
        "PDF": "https://arxiv.org/pdf/2506.23596"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23601",
      "abstract": "Diverse decoding of large language models is crucial for applications requiring multiple semantically distinct responses, yet existing methods primarily achieve lexical rather than semantic diversity. This limitation significantly constrains Best-of-N strategies, group-based reinforcement learning, and data synthesis. While temperature sampling and diverse beam search modify token distributions or apply n-gram penalties, they fail to ensure meaningful semantic differentiation. We introduce Semantic-guided Diverse Decoding (SemDiD), operating directly in embedding space that balances quality with diversity through three complementary mechanisms: orthogonal directional guidance, dynamic inter-group repulsion, and position-debiased probability assessment. SemDiD harmonizes these competing objectives using adaptive gain functions and constraint optimization, ensuring both quality thresholds and maximal semantic differentiation. Experiments show SemDiD consistently outperforms existing methods, improving Best-of-N coverage by 1.4-5.2% across diverse tasks and accelerating RLHF training convergence by 15% while increasing accuracy by up to 2.1%.",
      "authors": [
        "Weijie Shi",
        "Yue Cui",
        "Yaguang Wu",
        "Jingzhi Fang",
        "Shibo Zhang",
        "Mengze Li",
        "Sirui Han",
        "Jia Zhu",
        "Jiajie Xu",
        "Xiaofang Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T08:06:49+00:00",
          "link": "https://arxiv.org/abs/2506.23601v1",
          "size": "380kb",
          "version": "v1"
        }
      ],
      "title": "Semantic-guided Diverse Decoding for Large Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23601",
        "PDF": "https://arxiv.org/pdf/2506.23601"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23603",
      "abstract": "As Large Language Models (LLMs) are increasingly deployed in sensitive domains, traditional data privacy measures prove inadequate for protecting information that is implicit, contextual, or inferable - what we define as semantic privacy. This Systematization of Knowledge (SoK) introduces a lifecycle-centric framework to analyze how semantic privacy risks emerge across input processing, pretraining, fine-tuning, and alignment stages of LLMs. We categorize key attack vectors and assess how current defenses, such as differential privacy, embedding encryption, edge computing, and unlearning, address these threats. Our analysis reveals critical gaps in semantic-level protection, especially against contextual inference and latent representation leakage. We conclude by outlining open challenges, including quantifying semantic leakage, protecting multimodal inputs, balancing de-identification with generation quality, and ensuring transparency in privacy enforcement. This work aims to inform future research on designing robust, semantically aware privacy-preserving techniques for LLMs.",
      "authors": [
        "Baihe Ma",
        "Yanna Jiang",
        "Xu Wang",
        "Guangshen Yu",
        "Qin Wang",
        "Caijun Sun",
        "Chen Li",
        "Xuelei Qi",
        "Ying He",
        "Wei Ni",
        "Ren Ping Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T08:08:15+00:00",
          "link": "https://arxiv.org/abs/2506.23603v1",
          "size": "401kb",
          "version": "v1"
        }
      ],
      "title": "SoK: Semantic Privacy in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23603",
        "PDF": "https://arxiv.org/pdf/2506.23603"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23605",
      "abstract": "Lecture slide element detection and retrieval are key problems in slide understanding. Training effective models for these tasks often depends on extensive manual annotation. However, annotating large volumes of lecture slides for supervised training is labor intensive and requires domain expertise. To address this, we propose a large language model (LLM)-guided synthetic lecture slide generation pipeline, SynLecSlideGen, which produces high-quality, coherent and realistic slides. We also create an evaluation benchmark, namely RealSlide by manually annotating 1,050 real lecture slides. To assess the utility of our synthetic slides, we perform few-shot transfer learning on real data using models pre-trained on them. Experimental results show that few-shot transfer learning with pretraining on synthetic slides significantly improves performance compared to training only on real data. This demonstrates that synthetic data can effectively compensate for limited labeled lecture slides. The code and resources of our work are publicly available on our project website: https://synslidegen.github.io/.",
      "authors": [
        "Suyash Maniyar",
        "Vishvesh Trivedi",
        "Ajoy Mondal",
        "Anand Mishra and C.V. Jawahar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T08:11:31+00:00",
          "link": "https://arxiv.org/abs/2506.23605v1",
          "size": "9851kb",
          "version": "v1"
        }
      ],
      "title": "AI-Generated Lecture Slides for Improving Slide Element Detection and Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23605",
        "HTML": "https://arxiv.org/html/2506.23605v1",
        "PDF": "https://arxiv.org/pdf/2506.23605"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23606",
      "abstract": "Lidar point cloud synthesis based on generative models offers a promising solution to augment deep learning pipelines, particularly when real-world data is scarce or lacks diversity. By enabling flexible object manipulation, this synthesis approach can significantly enrich training datasets and enhance discriminative models. However, existing methods focus on unconditional lidar point cloud generation, overlooking their potential for real-world applications. In this paper, we propose SG-LDM, a Semantic-Guided Lidar Diffusion Model that employs latent alignment to enable robust semantic-to-lidar synthesis. By directly operating in the native lidar space and leveraging explicit semantic conditioning, SG-LDM achieves state-of-the-art performance in generating high-fidelity lidar point clouds guided by semantic labels. Moreover, we propose the first diffusion-based lidar translation framework based on SG-LDM, which enables cross-domain translation as a domain adaptation strategy to enhance downstream perception performance. Systematic experiments demonstrate that SG-LDM significantly outperforms existing lidar diffusion models and the proposed lidar translation framework further improves data augmentation performance in the downstream lidar segmentation task.",
      "authors": [
        "Zhengkang Xiang",
        "Zizhao Li",
        "Amir Khodabandeh",
        "Kourosh Khoshelham"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T08:13:04+00:00",
          "link": "https://arxiv.org/abs/2506.23606v1",
          "size": "4246kb",
          "version": "v1"
        }
      ],
      "title": "SG-LDM: Semantic-Guided LiDAR Generation via Latent-Aligned Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23606",
        "HTML": "https://arxiv.org/html/2506.23606v1",
        "PDF": "https://arxiv.org/pdf/2506.23606"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23607",
      "abstract": "Existing open-vocabulary 3D semantic segmentation methods typically supervise 3D segmentation models by merging text-aligned features (e.g., CLIP) extracted from multi-view images onto 3D points. However, such approaches treat multi-view images merely as intermediaries for transferring open-vocabulary information, overlooking their rich semantic content and cross-view correspondences, which limits model effectiveness. To address this, we propose PGOV3D, a novel framework that introduces a Partial-to-Global curriculum for improving open-vocabulary 3D semantic segmentation. The key innovation lies in a two-stage training strategy. In the first stage, we pre-train the model on partial scenes that provide dense semantic information but relatively simple geometry. These partial point clouds are derived from multi-view RGB-D inputs via pixel-wise depth projection. To enable open-vocabulary learning, we leverage a multi-modal large language model (MLLM) and a 2D segmentation foundation model to generate open-vocabulary labels for each viewpoint, offering rich and aligned supervision. An auxiliary inter-frame consistency module is introduced to enforce feature consistency across varying viewpoints and enhance spatial understanding. In the second stage, we fine-tune the model on complete scene-level point clouds, which are sparser and structurally more complex. We aggregate the partial vocabularies associated with each scene and generate pseudo labels using the pre-trained model, effectively bridging the semantic gap between dense partial observations and large-scale 3D environments. Extensive experiments on ScanNet, ScanNet200, and S3DIS benchmarks demonstrate that PGOV3D achieves competitive performance in open-vocabulary 3D semantic segmentation.",
      "authors": [
        "Shiqi Zhang",
        "Sha Zhang",
        "Jiajun Deng",
        "Yedong Shen",
        "Mingxiao MA",
        "Yanyong Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T08:13:07+00:00",
          "link": "https://arxiv.org/abs/2506.23607v1",
          "size": "8094kb",
          "version": "v1"
        }
      ],
      "title": "PGOV3D: Open-Vocabulary 3D Semantic Segmentation with Partial-to-Global Curriculum",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23607",
        "HTML": "https://arxiv.org/html/2506.23607v1",
        "PDF": "https://arxiv.org/pdf/2506.23607"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23610",
      "abstract": "Large language models (LLMs) make it possible to generate synthetic behavioural data at scale, offering an ethical and low-cost alternative to human experiments. Whether such data can faithfully capture psychological differences driven by personality traits, however, remains an open question. We evaluate the capacity of LLM agents, conditioned on Big-Five profiles, to reproduce personality-based variation in susceptibility to misinformation, focusing on news discernment, the ability to judge true headlines as true and false headlines as false. Leveraging published datasets in which human participants with known personality profiles rated headline accuracy, we create matching LLM agents and compare their responses to the original human patterns. Certain trait-misinformation associations, notably those involving Agreeableness and Conscientiousness, are reliably replicated, whereas others diverge, revealing systematic biases in how LLMs internalize and express personality. The results underscore both the promise and the limits of personality-aligned LLMs for behavioral simulation, and offer new insight into modeling cognitive diversity in artificial agents.",
      "authors": [
        "Manuel Pratelli and Marinella Petrocchi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T08:16:07+00:00",
          "link": "https://arxiv.org/abs/2506.23610v1",
          "size": "569kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating the Simulation of Human Personality-Driven Susceptibility to Misinformation with LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23610",
        "HTML": "https://arxiv.org/html/2506.23610v1",
        "PDF": "https://arxiv.org/pdf/2506.23610"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23611",
      "abstract": "3D Gaussian Splatting (3DGS) is a powerful alternative to Neural Radiance Fields (NeRF), excelling in complex scene reconstruction and efficient rendering. However, it relies on high-quality point clouds from Structure-from-Motion (SfM), limiting its applicability. SfM also fails in texture-deficient or constrained-view scenarios, causing severe degradation in 3DGS reconstruction. To address this limitation, we propose AttentionGS, a novel framework that eliminates the dependency on high-quality initial point clouds by leveraging structural attention for direct 3D reconstruction from randomly initialization. In the early training stage, we introduce geometric attention to rapidly recover the global scene structure. As training progresses, we incorporate texture attention to refine fine-grained details and enhance rendering quality. Furthermore, we employ opacity-weighted gradients to guide Gaussian densification, leading to improved surface reconstruction. Extensive experiments on multiple benchmark datasets demonstrate that AttentionGS significantly outperforms state-of-the-art methods, particularly in scenarios where point cloud initialization is unreliable. Our approach paves the way for more robust and flexible 3D Gaussian Splatting in real-world applications.",
      "authors": [
        "Ziao Liu",
        "Zhenjia Li",
        "Yifeng Shi",
        "Xiangang Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T08:16:43+00:00",
          "link": "https://arxiv.org/abs/2506.23611v1",
          "size": "8184kb",
          "version": "v1"
        }
      ],
      "title": "AttentionGS: Towards Initialization-Free 3D Gaussian Splatting via Structural Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23611",
        "HTML": "https://arxiv.org/html/2506.23611v1",
        "PDF": "https://arxiv.org/pdf/2506.23611"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23614",
      "abstract": "This paper introduces a new paradigm of optimal path planning, i.e., passage-traversing optimal path planning (PTOPP), that optimizes paths' traversed passages for specified optimization objectives. In particular, PTOPP is utilized to find the path with optimal accessible free space along its entire length, which represents a basic requirement for paths in robotics. As passages are places where free space shrinks and becomes constrained, the core idea is to leverage the path's passage traversal status to characterize its accessible free space comprehensively. To this end, a novel passage detection and free space decomposition method using proximity graphs is proposed, enabling fast detection of sparse but informative passages and environment decompositions. Based on this preprocessing, optimal path planning with accessible free space objectives or constraints is formulated as PTOPP problems compatible with sampling-based optimal planners. Then, sampling-based algorithms for PTOPP, including their dependent primitive procedures, are developed leveraging partitioned environments for fast passage traversal check. All these methods are implemented and thoroughly tested for effectiveness and efficiency validation. Compared to existing approaches, such as clearance-based methods, PTOPP demonstrates significant advantages in configurability, solution optimality, and efficiency, addressing prior limitations and incapabilities. It is believed to provide an efficient and versatile solution to accessible free space optimization over conventional avenues and more generally, to a broad class of path planning problems that can be formulated as PTOPP.",
      "authors": [
        "Jing Huang",
        "Hao Su",
        "Kwok Wai Samuel Au"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T08:19:04+00:00",
          "link": "https://arxiv.org/abs/2506.23614v1",
          "size": "11484kb",
          "version": "v1"
        }
      ],
      "title": "Passage-traversing optimal path planning with sampling-based algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23614",
        "HTML": "https://arxiv.org/html/2506.23614v1",
        "PDF": "https://arxiv.org/pdf/2506.23614"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23618",
      "abstract": "Diffusion-based generative models have demonstrated exceptional promise in the video super-resolution (VSR) task, achieving a substantial advancement in detail generation relative to prior methods. However, these approaches face significant computational efficiency challenges. For instance, current techniques may require tens of minutes to super-resolve a mere 2-second, 1080p video. In this paper, we present TurboVSR, an ultra-efficient diffusion-based video super-resolution model. Our core design comprises three key aspects: (1) We employ an autoencoder with a high compression ratio of 32$\\times$32$\\times$8 to reduce the number of tokens. (2) Highly compressed latents pose substantial challenges for training. We introduce factorized conditioning to mitigate the learning complexity: we first learn to super-resolve the initial frame; subsequently, we condition the super-resolution of the remaining frames on the high-resolution initial frame and the low-resolution subsequent frames. (3) We convert the pre-trained diffusion model to a shortcut model to enable fewer sampling steps, further accelerating inference. As a result, TurboVSR performs on par with state-of-the-art VSR methods, while being 100+ times faster, taking only 7 seconds to process a 2-second long 1080p video. TurboVSR also supports image resolution by considering image as a one-frame video. Our efficient design makes SR beyond 1080p possible, results on 4K (3648$\\times$2048) image SR show surprising fine details.",
      "authors": [
        "Zhongdao Wang",
        "Guodongfang Zhao",
        "Jingjing Ren",
        "Bailan Feng",
        "Shifeng Zhang",
        "Wenbo Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T08:24:13+00:00",
          "link": "https://arxiv.org/abs/2506.23618v1",
          "size": "4635kb",
          "version": "v1"
        }
      ],
      "title": "TurboVSR: Fantastic Video Upscalers and Where to Find Them",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23618",
        "HTML": "https://arxiv.org/html/2506.23618v1",
        "PDF": "https://arxiv.org/pdf/2506.23618"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23622",
      "abstract": "The privacy-preserving federated learning schemes based on the setting of two honest-but-curious and non-colluding servers offer promising solutions in terms of security and efficiency. However, our investigation reveals that these schemes still suffer from privacy leakage when considering model poisoning attacks from malicious users. Specifically, we demonstrate that the privacy-preserving computation process for defending against model poisoning attacks inadvertently leaks privacy to one of the honest-but-curious servers, enabling it to access users' gradients in plaintext. To address both privacy leakage and model poisoning attacks, we propose an enhanced privacy-preserving and Byzantine-robust federated learning (PBFL) scheme, comprising three components: (1) a two-trapdoor fully homomorphic encryption (FHE) scheme to bolster users' privacy protection; (2) a novel secure normalization judgment method to preemptively thwart gradient poisoning; and (3) an innovative secure cosine similarity measurement method for detecting model poisoning attacks without compromising data privacy. Our scheme guarantees privacy preservation and resilience against model poisoning attacks, even in scenarios with heterogeneous, non-IID (Independently and Identically Distributed) datasets. Theoretical analyses substantiate the security and efficiency of our scheme, and extensive experiments corroborate the efficacy of our private attacks. Furthermore, the experimental results demonstrate that our scheme accelerates training speed while reducing communication overhead compared to the state-of-the-art PBFL schemes.",
      "authors": [
        "Jiahui Wu",
        "Fucai Luo",
        "Tiecheng Sun",
        "Haiyan Wang",
        "Weizhe Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T08:39:01+00:00",
          "link": "https://arxiv.org/abs/2506.23622v1",
          "size": "213kb",
          "version": "v1"
        }
      ],
      "title": "Privacy-Preserving Federated Learning Scheme with Mitigating Model Poisoning Attacks: Vulnerabilities and Countermeasures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23622",
        "HTML": "https://arxiv.org/html/2506.23622v1",
        "PDF": "https://arxiv.org/pdf/2506.23622"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23623",
      "abstract": "Audio-Visual Segmentation (AVS) aims to segment sound-producing objects in video frames based on the associated audio signal. Prevailing AVS methods typically adopt an audio-centric Transformer architecture, where object queries are derived from audio features. However, audio-centric Transformers suffer from two limitations: perception ambiguity caused by the mixed nature of audio, and weakened dense prediction ability due to visual detail loss. To address these limitations, we propose a new Vision-Centric Transformer (VCT) framework that leverages vision-derived queries to iteratively fetch corresponding audio and visual information, enabling queries to better distinguish between different sounding objects from mixed audio and accurately delineate their contours. Additionally, we also introduce a Prototype Prompted Query Generation (PPQG) module within our VCT framework to generate vision-derived queries that are both semantically aware and visually rich through audio prototype prompting and pixel context grouping, facilitating audio-visual information aggregation. Extensive experiments demonstrate that our VCT framework achieves new state-of-the-art performances on three subsets of the AVSBench dataset. The code is available at https://github.com/spyflying/VCT_AVS.",
      "authors": [
        "Shaofei Huang",
        "Rui Ling",
        "Tianrui Hui",
        "Hongyu Li",
        "Xu Zhou",
        "Shifeng Zhang",
        "Si Liu",
        "Richang Hong",
        "Meng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T08:40:36+00:00",
          "link": "https://arxiv.org/abs/2506.23623v1",
          "size": "4899kb",
          "version": "v1"
        }
      ],
      "title": "Revisiting Audio-Visual Segmentation with Vision-Centric Transformer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23623",
        "HTML": "https://arxiv.org/html/2506.23623v1",
        "PDF": "https://arxiv.org/pdf/2506.23623"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23624",
      "abstract": "Teleoperation with non-haptic VR controllers deprives human operators of critical motion feedback. We address this by embedding a multi-objective optimization problem that converts user input into collision-free UR5e joint trajectories while actively suppressing liquid slosh in a glass. The controller maintains 13 ms average planning latency, confirming real-time performance and motivating the augmentation of this teleoperation approach to further objectives.",
      "authors": [
        "Max Grobbel",
        "Tristan Schneider",
        "S\\\"oren Hohmann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T08:40:52+00:00",
          "link": "https://arxiv.org/abs/2506.23624v1",
          "size": "480kb",
          "version": "v1"
        }
      ],
      "title": "Towards Universal Shared Control in Teleoperation Without Haptic Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23624",
        "HTML": "https://arxiv.org/html/2506.23624v1",
        "PDF": "https://arxiv.org/pdf/2506.23624"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23626",
      "abstract": "Reinforcement Learning (RL) in games has gained significant momentum in recent years, enabling the creation of different agent behaviors that can transform a player's gaming experience. However, deploying RL agents in production environments presents two key challenges: (1) designing an effective reward function typically requires an RL expert, and (2) when a game's content or mechanics are modified, previously tuned reward weights may no longer be optimal. Towards the latter challenge, we propose an automated approach for iteratively fine-tuning an RL agent's reward function weights, based on a user-defined language based behavioral goal. A Language Model (LM) proposes updated weights at each iteration based on this target behavior and a summary of performance statistics from prior training rounds. This closed-loop process allows the LM to self-correct and refine its output over time, producing increasingly aligned behavior without the need for manual reward engineering. We evaluate our approach in a racing task and show that it consistently improves agent performance across iterations. The LM-guided agents show a significant increase in performance from $9\\%$ to $74\\%$ success rate in just one iteration. We compare our LM-guided tuning against a human expert's manual weight design in the racing task: by the final iteration, the LM-tuned agent achieved an $80\\%$ success rate, and completed laps in an average of $855$ time steps, a competitive performance against the expert-tuned agent's peak $94\\%$ success, and $850$ time steps.",
      "authors": [
        "Ant\\'onio Afonso",
        "Iolanda Leite",
        "Alessandro Sestini",
        "Florian Fuchs",
        "Konrad Tollmar",
        "Linus Gissl\\'en"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T08:45:04+00:00",
          "link": "https://arxiv.org/abs/2506.23626v1",
          "size": "2300kb",
          "version": "v1"
        }
      ],
      "title": "Self-correcting Reward Shaping via Language Models for Reinforcement Learning Agents in Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23626",
        "PDF": "https://arxiv.org/pdf/2506.23626"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23627",
      "abstract": "Brain plays a crucial role in regulating body functions and cognitive processes, with brain tumors posing significant risks to human health. Precise and prompt detection is a key factor in proper treatment and better patient outcomes. Traditional methods for detecting brain tumors, that include biopsies, MRI, and CT scans often face challenges due to their high costs and the need for specialized medical expertise. Recent developments in machine learning (ML) and deep learning (DL) has exhibited strong capabilities in automating the identification and categorization of brain tumors from medical images, especially MRI scans. However, these classical ML models have limitations, such as high computational demands, the need for large datasets, and long training times, which hinder their accessibility and efficiency. Our research uses MobileNET model for efficient detection of these tumors. The novelty of this project lies in building an accurate tumor detection model which use less computing re-sources and runs in less time followed by efficient decision making through the use of image processing technique for accurate results. The suggested method attained an average accuracy of 98.5%.",
      "authors": [
        "Roham Maiti",
        "Debasmita Bhoumik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T08:45:28+00:00",
          "link": "https://arxiv.org/abs/2506.23627v1",
          "size": "747kb",
          "version": "v1"
        }
      ],
      "title": "Brain Tumor Detection through Thermal Imaging and MobileNET",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23627",
        "HTML": "https://arxiv.org/html/2506.23627v1",
        "PDF": "https://arxiv.org/pdf/2506.23627"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23628",
      "abstract": "Traditional Kubernetes networking struggles to meet the escalating demands of AI/ML and evolving Telco infrastructure. This paper introduces Kubernetes Network Drivers (KNDs), a transformative, modular, and declarative architecture designed to overcome current imperative provisioning and API limitations. KNDs integrate network resource management into Kubernetes' core by utilizing Dynamic Resource Allocation (DRA), Node Resource Interface (NRI) improvements, and upcoming OCI Runtime Specification changes. Our DraNet implementation demonstrates declarative attachment of network interfaces, including Remote Direct Memory Access (RDMA) devices, significantly boosting high-performance AI/ML workloads. This capability enables sophisticated cloud-native applications and lays crucial groundwork for future Telco solutions, fostering a \"galaxy\" of specialized KNDs for enhanced application delivery and reduced operational complexity.",
      "authors": [
        "Antonio Ojea"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T08:45:54+00:00",
          "link": "https://arxiv.org/abs/2506.23628v1",
          "size": "916kb",
          "version": "v1"
        }
      ],
      "title": "The Kubernetes Network Driver Model: A Composable Architecture for High-Performance Networking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23628",
        "HTML": "https://arxiv.org/html/2506.23628v1",
        "PDF": "https://arxiv.org/pdf/2506.23628"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23629",
      "abstract": "The integrity of Water Quality Data (WQD) is critical in environmental monitoring for scientific decision-making and ecological protection. However, water quality monitoring systems are often challenged by large amounts of missing data due to unavoidable problems such as sensor failures and communication delays, which further lead to water quality data becoming High-Dimensional and Sparse (HDS). Traditional data imputation methods are difficult to depict the potential dynamics and fail to capture the deep data features, resulting in unsatisfactory imputation performance. To effectively address the above issues, this paper proposes a Nonlinear Low-rank Representation model (NLR) with Convolutional Neural Networks (CNN) for imputing missing WQD, which utilizes CNNs to implement two ideas: a) fusing temporal features to model the temporal dependence of data between time slots, and b) Extracting nonlinear interactions and local patterns to mine higher-order relationships features and achieve deep fusion of multidimensional information. Experimental studies on three real water quality datasets demonstrate that the proposed model significantly outperforms existing state-of-the-art data imputation models in terms of estimation accuracy. It provides an effective approach for handling water quality monitoring data in complex dynamic environments.",
      "authors": [
        "Xin Liao and Bing Yang and Cai Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T08:48:19+00:00",
          "link": "https://arxiv.org/abs/2506.23629v1",
          "size": "410kb",
          "version": "v1"
        }
      ],
      "title": "A Nonlinear Low-rank Representation Model with Convolutional Neural Network for Imputing Water Quality Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23629",
        "HTML": "https://arxiv.org/html/2506.23629v1",
        "PDF": "https://arxiv.org/pdf/2506.23629"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23630",
      "abstract": "Diffusion models have dramatically advanced text-to-image generation in recent years, translating abstract concepts into high-fidelity images with remarkable ease. In this work, we examine whether they can also blend distinct concepts, ranging from concrete objects to intangible ideas, into coherent new visual entities under a zero-shot framework. Specifically, concept blending merges the key attributes of multiple concepts (expressed as textual prompts) into a single, novel image that captures the essence of each concept. We investigate four blending methods, each exploiting different aspects of the diffusion pipeline (e.g., prompt scheduling, embedding interpolation, or layer-wise conditioning). Through systematic experimentation across diverse concept categories, such as merging concrete concepts, synthesizing compound words, transferring artistic styles, and blending architectural landmarks, we show that modern diffusion models indeed exhibit creative blending capabilities without further training or fine-tuning. Our extensive user study, involving 100 participants, reveals that no single approach dominates in all scenarios: each blending technique excels under certain conditions, with factors like prompt ordering, conceptual distance, and random seed affecting the outcome. These findings highlight the remarkable compositional potential of diffusion models while exposing their sensitivity to seemingly minor input variations.",
      "authors": [
        "Lorenzo Olearo",
        "Giorgio Longari",
        "Alessandro Raganato",
        "Rafael Pe\\~naloza",
        "Simone Melzi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T08:53:30+00:00",
          "link": "https://arxiv.org/abs/2506.23630v1",
          "size": "22511kb",
          "version": "v1"
        }
      ],
      "title": "Blending Concepts with Text-to-Image Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23630",
        "PDF": "https://arxiv.org/pdf/2506.23630"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23634",
      "abstract": "Mixed Boolean-Arithmetic (MBA) obfuscation protects intellectual property by converting programs into forms that are more complex to analyze. However, MBA has been increasingly exploited by malware developers to evade detection and cause significant real-world problems. Traditional MBA deobfuscation methods often consider these expressions as part of a black box and overlook their internal semantic information. To bridge this gap, we propose a truth table, which is an automatically constructed semantic representation of an expression's behavior that does not rely on external resources. The truth table is a mathematical form that represents the output of expression for all possible combinations of input. We also propose a general and extensible guided MBA deobfuscation framework (gMBA) that modifies a Transformer-based neural encoder-decoder Seq2Seq architecture to incorporate this semantic guidance. Experimental results and in-depth analysis show that integrating expression semantics significantly improves performance and highlights the importance of internal semantic expressions in recovering obfuscated code to its original form.",
      "authors": [
        "Youjeong Noh",
        "Joon-Young Paik",
        "Jingun Kwon",
        "Eun-Sun Cho"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:03:13+00:00",
          "link": "https://arxiv.org/abs/2506.23634v1",
          "size": "555kb",
          "version": "v1"
        }
      ],
      "title": "gMBA: Expression Semantic Guided Mixed Boolean-Arithmetic Deobfuscation Using Transformer Architectures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23634",
        "HTML": "https://arxiv.org/html/2506.23634v1",
        "PDF": "https://arxiv.org/pdf/2506.23634"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23635",
      "abstract": "Large Language Models (LLMs) have revolutionized Artificial Intelligence (AI) with significant advancements such as OpenAI's ChatGPT, Meta's Llama, and Databricks' DBRX. This paper addresses the cost and scalability challenges encountered when constructing private LLM systems for personal or small group services, as aimed by Apple Intelligence. A Mac Studio cluster with Apple's M2 Ultra chips is established as a cost-efficient solution to host and accelerate the pretrained DBRX model with the Mixture-of-Experts (MoE) architecture. Our performance analysis reveal that parallel execution of the model's experts across two to four machine nodes significantly reduces inference time. We find that computation time for the experts is comparable to the communication time for exchanging their outputs, emphasizing the importance of network latency over bandwidth. We also observe significant management overhead due to Apple software stack's memory management logic. Based on these findings, we develop optimization schemes to eliminate the memory management overhead. As a result, the Mac Studio cluster is 1.15 times more cost-efficient than the state-of-the-art AI supercomputer with NVIDIA H100 GPUs. In addition, we construct a performance model to estimate system performance under varying configurations, and the model provides valuable insights for designing private LLM systems.",
      "authors": [
        "Mu-Chi Chen and Po-Hsuan Huang and Xiangrui Ke and Chia-Heng Tu and Chun Jason Xue and Shih-Hao Hung"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:04:25+00:00",
          "link": "https://arxiv.org/abs/2506.23635v1",
          "size": "1548kb",
          "version": "v1"
        }
      ],
      "title": "Towards Building Private LLMs: Exploring Multi-Node Expert Parallelism on Apple Silicon for Mixture-of-Experts Large Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23635",
        "HTML": "https://arxiv.org/html/2506.23635v1",
        "PDF": "https://arxiv.org/pdf/2506.23635"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23638",
      "abstract": "Consider a graph with n nodes and m edges, independent edge weights and lengths, and arbitrary distance demands for node pairs. The spanner problem asks for a minimum-weight subgraph that satisfies these demands via sufficiently short paths w.r.t. the edge lengths. For multiplicative alpha-spanners (where demands equal alpha times the original distances) and assuming that each edge's weight equals its length, the simple Greedy heuristic by Alth\\\"ofer et al. (1993) is known to yield strong solutions, both in theory and practice. To obtain guarantees in more general settings, recent approximations typically abandon this simplicity and practicality. Still, so far, there is no known non-trivial approximation algorithm for the spanner problem in its most general form. We provide two surprisingly simple approximations algorithms. In general, our Adapted Greedy achieves the first unconditional approximation ratio of m, which is non-trivial due to the independence of weights and lengths. Crucially, it maintains all size and weight guarantees Greedy is known for, i.e., in the aforementioned multiplicative alpha-spanner scenario and even for additive +beta-spanners. Further, it generalizes some of these size guarantees to derive new weight guarantees. Our second approach, Randomized Rounding, establishes a graph transformation that allows a simple rounding scheme over a standard multicommodity flow LP. It yields an O(n log n)-approximation, assuming integer lengths and polynomially bounded distance demands. The only other known approximation guarantee in this general setting requires several complex subalgorithms and analyses, yet we match it up to a factor of O(n^{1/5-eps}) using standard tools. Further, on bounded-degree graphs, we yield the first O(log n) approximation ratio for constant-bounded distance demands (beyond multiplicative 2-spanners in unit-length graphs).",
      "authors": [
        "Fritz B\\\"okler",
        "Markus Chimani",
        "Henning Jasper"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:05:02+00:00",
          "link": "https://arxiv.org/abs/2506.23638v1",
          "size": "34kb",
          "version": "v1"
        }
      ],
      "title": "Simple Approximations for General Spanner Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23638",
        "HTML": "https://arxiv.org/html/2506.23638v1",
        "PDF": "https://arxiv.org/pdf/2506.23638"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23639",
      "abstract": "Multimodal large language models (MLLMs) have made significant progress in vision-language understanding, yet effectively aligning different modalities remains a fundamental challenge. We present a framework that unifies multimodal understanding by applying byte-pair encoding to visual tokens. Unlike conventional approaches that rely on modality-specific encoders, our method directly incorporates structural information into visual tokens, mirroring successful tokenization strategies in text-only language models. We introduce a priority-guided encoding scheme that considers both frequency and spatial consistency, coupled with a multi-stage training procedure based on curriculum-driven data composition. These enhancements enable the transformer model to better capture cross-modal relationships and reason with visual information. Comprehensive experiments demonstrate improved performance across diverse vision-language tasks. By bridging the gap between visual and textual representations, our approach contributes to the advancement of more capable and efficient multimodal foundation models.",
      "authors": [
        "Wanpeng Zhang",
        "Yicheng Feng",
        "Hao Luo",
        "Yijiang Li",
        "Zihao Yue",
        "Sipeng Zheng",
        "Zongqing Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:08:08+00:00",
          "link": "https://arxiv.org/abs/2506.23639v1",
          "size": "3511kb",
          "version": "v1"
        }
      ],
      "title": "Unified Multimodal Understanding via Byte-Pair Visual Encoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23639",
        "HTML": "https://arxiv.org/html/2506.23639v1",
        "PDF": "https://arxiv.org/pdf/2506.23639"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23640",
      "abstract": "Recently, researchers have explored ML-based Traffic Engineering (TE), leveraging neural networks to solve TE problems traditionally addressed by optimization. However, existing ML-based TE schemes remain impractical: they either fail to handle topology changes or suffer from poor scalability due to excessive computational and memory overhead. To overcome these limitations, we propose Geminet, a lightweight and scalable ML-based TE framework that can handle changing topologies. Geminet is built upon two key insights: (i) a methodology that decouples neural networks from topology by learning an iterative gradient-descent-based adjustment process, as the update rule of gradient descent is topology-agnostic, relying only on a few gradient-related quantities; (ii) shifting optimization from path-level routing weights to edge-level dual variables, reducing memory consumption by leveraging the fact that edges are far fewer than paths. Evaluations on WAN and data center datasets show that Geminet significantly improves scalability. Its neural network size is only 0.04% to 7% of existing schemes, while handling topology variations as effectively as HARP, a state-of-the-art ML-based TE approach, without performance degradation. When trained on large-scale topologies, Geminet consumes under 10 GiB of memory, more than eight times less than the 80-plus GiB required by HARP, while achieving 5.45 times faster convergence speed, demonstrating its potential for large-scale deployment.",
      "authors": [
        "Ximeng Liu",
        "Shizhen Zhao",
        "Xinbing Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:09:50+00:00",
          "link": "https://arxiv.org/abs/2506.23640v1",
          "size": "1880kb",
          "version": "v1"
        }
      ],
      "title": "Geminet: Learning the Duality-based Iterative Process for Lightweight Traffic Engineering in Changing Topologies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23640",
        "HTML": "https://arxiv.org/html/2506.23640v1",
        "PDF": "https://arxiv.org/pdf/2506.23640"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23641",
      "abstract": "As the appearance of medical images is influenced by multiple underlying factors, generative models require rich attribute information beyond labels to produce realistic and diverse images. For instance, generating an image of skin lesion with specific patterns demands descriptions that go beyond diagnosis, such as shape, size, texture, and color. However, such detailed descriptions are not always accessible. To address this, we explore a framework, termed Visual Attribute Prompts (VAP)-Diffusion, to leverage external knowledge from pre-trained Multi-modal Large Language Models (MLLMs) to improve the quality and diversity of medical image generation. First, to derive descriptions from MLLMs without hallucination, we design a series of prompts following Chain-of-Thoughts for common medical imaging tasks, including dermatologic, colorectal, and chest X-ray images. Generated descriptions are utilized during training and stored across different categories. During testing, descriptions are randomly retrieved from the corresponding category for inference. Moreover, to make the generator robust to unseen combination of descriptions at the test time, we propose a Prototype Condition Mechanism that restricts test embeddings to be similar to those from training. Experiments on three common types of medical imaging across four datasets verify the effectiveness of VAP-Diffusion.",
      "authors": [
        "Peng Huang",
        "Junhu Fu",
        "Bowen Guo",
        "Zeju Li",
        "Yuanyuan Wang",
        "Yi Guo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:11:19+00:00",
          "link": "https://arxiv.org/abs/2506.23641v1",
          "size": "864kb",
          "version": "v1"
        }
      ],
      "title": "VAP-Diffusion: Enriching Descriptions with MLLMs for Enhanced Medical Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23641",
        "HTML": "https://arxiv.org/html/2506.23641v1",
        "PDF": "https://arxiv.org/pdf/2506.23641"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23643",
      "abstract": "Generative recommendation (GR) typically encodes behavioral or semantic aspects of item information into discrete tokens, leveraging the standard autoregressive (AR) generation paradigm to make predictions. However, existing methods tend to overlook their intrinsic relationship, that is, the semantic usually provides some reasonable explainability \"$\\textbf{why}$\" for the behavior \"$\\textbf{what}$\", which may constrain the full potential of GR. To this end, we present Chunk AutoRegressive Modeling (CAR), a new generation paradigm following the decision pattern that users usually think semantic aspects of items (e.g. brand) and then take actions on target items (e.g. purchase). Our CAR, for the $\\textit{first time}$, incorporates semantics (SIDs) and behavior (UID) into a single autoregressive transformer from an ``act-with-think'' dual perspective via chunk-level autoregression. Specifically, CAR packs SIDs and UID into a conceptual chunk for item unified representation, allowing each decoding step to make a holistic prediction. Experiments show that our CAR significantly outperforms existing methods based on traditional AR, improving Recall@5 by 7.93% to 22.30%. Furthermore, we verify the scaling effect between model performance and SIDs bit number, demonstrating that CAR preliminary emulates a kind of slow-thinking style mechanism akin to the reasoning processes observed in large language models (LLMs).",
      "authors": [
        "Yifan Wang",
        "Weinan Gan",
        "Longtao Xiao",
        "Jieming Zhu",
        "Heng Chang",
        "Haozhao Wang",
        "Rui Zhang",
        "Zhenhua Dong",
        "Ruiming Tang",
        "Ruixuan Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:13:54+00:00",
          "link": "https://arxiv.org/abs/2506.23643v1",
          "size": "1387kb",
          "version": "v1"
        }
      ],
      "title": "Act-With-Think: Chunk Auto-Regressive Modeling for Generative Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23643",
        "HTML": "https://arxiv.org/html/2506.23643v1",
        "PDF": "https://arxiv.org/pdf/2506.23643"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23644",
      "abstract": "We introduce QLPro, a vulnerability detection framework that systematically integrates LLMs and static analysis tools to enable comprehensive vulnerability detection across entire open-source projects.We constructed a new dataset, JavaTest, comprising 10 open-source projects from GitHub with 62 confirmed vulnerabilities. CodeQL, a state-of-the-art static analysis tool, detected only 24 of these vulnerabilities while QLPro detected 41. Furthermore, QLPro discovered 6 previously unknown vulnerabilities, 2 of which have been confirmed as 0-days.",
      "authors": [
        "Junze Hu",
        "Xiangyu Jin",
        "Yizhe Zeng",
        "Yuling Liu",
        "Yunpeng Li",
        "Dan Du",
        "Kaiyu Xie",
        "Hongsong Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:14:49+00:00",
          "link": "https://arxiv.org/abs/2506.23644v1",
          "size": "3165kb",
          "version": "v1"
        }
      ],
      "title": "QLPro: Automated Code Vulnerability Discovery via LLM and Static Code Analysis Integration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23644",
        "HTML": "https://arxiv.org/html/2506.23644v1",
        "PDF": "https://arxiv.org/pdf/2506.23644"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23648",
      "abstract": "Color Doppler echocardiography is a crucial tool for diagnosing mitral regurgitation (MR). Recent studies have explored intelligent methods for MR diagnosis to minimize user dependence and improve accuracy. However, these approaches often fail to align with clinical workflow and may lead to suboptimal accuracy and interpretability. In this study, we introduce an automated MR diagnosis model (MReg) developed on the 4-chamber cardiac color Doppler echocardiography video (A4C-CDV). It follows comprehensive feature mining strategies to detect MR and assess its severity, considering clinical realities. Our contribution is threefold. First, we formulate the MR diagnosis as a regression task to capture the continuity and ordinal relationships between categories. Second, we design a feature selection and amplification mechanism to imitate the sonographer's diagnostic logic for accurate MR grading. Third, inspired by the Mixture-of-Experts concept, we introduce a feature summary module to extract the category-level features, enhancing the representational capacity for more accurate grading. We trained and evaluated our proposed MReg on a large in-house A4C-CDV dataset comprising 1868 cases with three graded regurgitation labels. Compared to other weakly supervised video anomaly detection and supervised classification methods, MReg demonstrated superior performance in MR diagnosis. Our code is available at: https://github.com/cskdstz/MReg.",
      "authors": [
        "Zhe Liu",
        "Yuhao Huang",
        "Lian Liu",
        "Chengrui Zhang",
        "Haotian Lin",
        "Tong Han",
        "Zhiyuan Zhu",
        "Yanlin Chen",
        "Yuerui Chen",
        "Dong Ni",
        "Zhongshan Gou",
        "Xin Yang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:22:52+00:00",
          "link": "https://arxiv.org/abs/2506.23648v1",
          "size": "1346kb",
          "version": "v1"
        }
      ],
      "title": "MReg: A Novel Regression Model with MoE-based Video Feature Mining for Mitral Regurgitation Diagnosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23648",
        "HTML": "https://arxiv.org/html/2506.23648v1",
        "PDF": "https://arxiv.org/pdf/2506.23648"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23649",
      "abstract": "With a sustainable increase in the scale of power system, the number of states in the state space grows exponentially, and the reliability assessment of the power system faces enormous challenges. Traditional state-by-state assessment methods, such as state enumeration (SE) and Monte Carlo simulation (MCS) methods, have encountered performance bottlenecks in terms of efficiency and accuracy. In this paper, the Boolean lattice representation theory of the state space was studied, and a dichotomy method was proposed to efficiently partition the state space into some disjoint sub-lattices with a relatively small number of optimal power flow (OPF) operations. Based on lattice partition, the reliability indices of the entire space can be calculated lattice-by-lattice. In addition, alone with the partitioning procedure, the calculated loss of load probability (LOLP) monotonically increases and rapidly tends to the analytic value with the designated error bound. Moreover, we designed a customized Monte Carlo sampling method in lattices of interest to compute expected energy not supply (EENS). The experiments are conducted on the RBTS and RTS-79 systems. The results show that the proposed method achieves the analytic LOLP of the RBTS system after five hundreds of OPF operations, which is about hundreds of times faster than traditional methods, and the designed Monte Carlo sampling method converged after thousands of OPF operations on test systems.",
      "authors": [
        "Wenjie Wan",
        "Han Hu",
        "Feiyu Chen",
        "Xiaoyu Liu",
        "Kequan Zhao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:23:22+00:00",
          "link": "https://arxiv.org/abs/2506.23649v1",
          "size": "2360kb",
          "version": "v1"
        }
      ],
      "title": "Reliability Assessment of Power System Based on the Dichotomy Method",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23649",
        "HTML": "https://arxiv.org/html/2506.23649v1",
        "PDF": "https://arxiv.org/pdf/2506.23649"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23657",
      "abstract": "Consumer-grade RGB-D imaging for intraoperative orthopedic tissue tracking is a promising method with high translational potential. Unlike bone-mounted tracking devices, markerless tracking can reduce operating time and complexity. However, its use has been limited to cadaveric studies. This paper introduces the first real-world clinical RGB-D dataset for spine surgery and develops SpineAlign, a system for capturing deformation between preoperative and intraoperative spine states. We also present an intraoperative segmentation network trained on this data and introduce CorrespondNet, a multi-task framework for predicting key regions for registration in both intraoperative and preoperative scenes.",
      "authors": [
        "Connor Daly",
        "Elettra Marconi",
        "Marco Riva",
        "Jinendra Ekanayake",
        "Daniel S. Elson",
        "Ferdinando Rodriguez y Baena"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:32:19+00:00",
          "link": "https://arxiv.org/abs/2506.23657v1",
          "size": "23716kb",
          "version": "v1"
        }
      ],
      "title": "Towards Markerless Intraoperative Tracking of Deformable Spine Tissue",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23657",
        "HTML": "https://arxiv.org/html/2506.23657v1",
        "PDF": "https://arxiv.org/pdf/2506.23657"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23661",
      "abstract": "We extend BeamAttack, an adversarial attack algorithm designed to evaluate the robustness of text classification systems through word-level modifications guided by beam search. Our extensions include support for word deletions and the option to skip substitutions, enabling the discovery of minimal modifications that alter model predictions. We also integrate LIME to better prioritize word replacements. Evaluated across multiple datasets and victim models (BiLSTM, BERT, and adversarially trained RoBERTa) within the BODEGA framework, our approach achieves over a 99\\% attack success rate while preserving the semantic and lexical similarity of the original texts. Through both quantitative and qualitative analysis, we highlight BeamAttack's effectiveness and its limitations. Our implementation is available at https://github.com/LucK1Y/BeamAttack",
      "authors": [
        "Arnisa Fazla",
        "Lucas Krauter",
        "David Guzman Piedrahita",
        "Andrianos Michail"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:37:19+00:00",
          "link": "https://arxiv.org/abs/2506.23661v1",
          "size": "1456kb",
          "version": "v1"
        }
      ],
      "title": "Robustness of Misinformation Classification Systems to Adversarial Examples Through BeamAttack",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23661",
        "HTML": "https://arxiv.org/html/2506.23661v1",
        "PDF": "https://arxiv.org/pdf/2506.23661"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23662",
      "abstract": "Context-aware embedding methods boost retrieval accuracy by conditioning on corpus statistics (e.g., term co-occurrence and topical patterns) extracted from neighboring documents. However, this context-aware approach requires access to the target corpus or requires domain-specific finetuning, posing practical barriers in privacy-sensitive or resource-constrained settings. We present ZEST, a zero-shot contextual adaptation framework that replaces real corpus access with a one-time offline synthesis of a compact proxy. Given only a handful exemplar documents representative of the general target domain, we use a multi-step hierarchical procedure to generate a synthetic context corpus of several hundred documents that aims to emulate key domain-specific distributions. At inference, the frozen context-aware encoder uses this proxy corpus -- without any finetuning or target corpus access -- to produce domain-adapted embeddings. Across the MTEB benchmark, ZEST's zero-shot synthetic context adaptation using only five example documents performs within 0.5% of models leveraging full target corpus access -- demonstrating remarkable efficacy without any retraining. ZEST thus provides a practical method for deploying high-performance, adaptable embeddings in constrained environments.",
      "authors": [
        "Philip Lippmann and Jie Yang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:38:50+00:00",
          "link": "https://arxiv.org/abs/2506.23662v1",
          "size": "129kb",
          "version": "v1"
        }
      ],
      "title": "Zero-Shot Contextual Embeddings via Offline Synthetic Corpus Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23662",
        "PDF": "https://arxiv.org/pdf/2506.23662"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23663",
      "abstract": "In real-world vision-language applications, practitioners increasingly rely on large, pretrained foundation models rather than custom-built solutions, despite limited transparency regarding their training data and processes. While these models achieve impressive performance on general benchmarks, their effectiveness can decline notably under specialized domain shifts, such as unique imaging conditions or environmental variations. In this work, we introduce Deepbench, a framework designed to assess domain-specific robustness of vision-language models (VLMs). Deepbench leverages a large language model (LLM) to generate realistic, context-aware image corruptions tailored to specific deployment domains without requiring labeled data. We evaluate a range of contrastive vision-language architectures and architectural variants across six real-world domains and observe substantial variability in robustness, highlighting the need for targeted, domain-aware evaluation. Deepbench is released as open-source software to support further research into domain-aware robustness assessment.",
      "authors": [
        "Mario Koddenbrock and Rudolf Hoffmann and David Brodmann and Erik Rodner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:39:33+00:00",
          "link": "https://arxiv.org/abs/2506.23663v1",
          "size": "15965kb",
          "version": "v1"
        }
      ],
      "title": "On the Domain Robustness of Contrastive Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23663",
        "HTML": "https://arxiv.org/html/2506.23663v1",
        "PDF": "https://arxiv.org/pdf/2506.23663"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23667",
      "abstract": "Training large language models (LLMs) to act as autonomous agents for multi-turn, long-horizon tasks remains significant challenges in scalability and training efficiency. To address this, we introduce L-Zero (L0), a scalable, end-to-end training pipeline for general-purpose agents. Featuring a low-cost, extensible, and sandboxed concurrent agent worker pool, L0 lowers the barrier for applying reinforcement learning in complex environments. We also introduce NB-Agent, the agent scaffold within L0, which operates in a \"code-as-action\" fashion via a Read-Eval-Print-Loop (REPL). We evaluate L0 on factuality question-answering benchmarks. Our experiments demonstrate that a base model can develop robust problem-solving skills using solely Reinforcement Learning with Verifiable Rewards (RLVR). On the Qwen2.5-7B-Instruct model, our method boosts accuracy on SimpleQA from 30 % to 80 % and on HotpotQA from 22 % to 41 %. We have open-sourced the entire L0 system, including our L0 series models, the NB-Agent, a complete training pipeline, and the corresponding training recipes on (https://github.com/cmriat/l0).",
      "authors": [
        "Junjie Zhang",
        "Jingyi Xi",
        "Zhuoyang Song",
        "Junyu Lu",
        "Yuhua Ke",
        "Ting Sun",
        "Yukun Yang",
        "Jiaxing Zhang",
        "Songxin Zhang",
        "Zejian Xie"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:44:32+00:00",
          "link": "https://arxiv.org/abs/2506.23667v1",
          "size": "2292kb",
          "version": "v1"
        }
      ],
      "title": "L0: Reinforcement Learning to Become General Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23667",
        "HTML": "https://arxiv.org/html/2506.23667v1",
        "PDF": "https://arxiv.org/pdf/2506.23667"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23670",
      "abstract": "Current speech language models exceed the size and latency constraints of many deployment environments. We build compact, expressive speech generation models through layer-aligned distillation, matching hidden states, attention maps, and softened logits to compress large multimodal transformers by 3x with minimal loss in performance. We introduce TinyWave, a family of 2B-parameter models for speech-to-speech and interleaved speech-text generation, trained on 50,000 hours of public audio. TinyWave supports (i) speech-only generation using phonetic or expressive tokens and (ii) mixed speech-text continuations. Evaluation on Libri-Light shows TinyWave within 1.4 normalized perplexity points of its teacher. Accuracy on spoken StoryCloze and SALMon reaches 93-97% of the teacher's performance, outperforming size-matched baselines. These models are optimized for deployment on commodity hardware, enabling applications in real-time conversational agents, assistive technologies, and low-resource environments. We release models, training code, and evaluation scripts to support reproducible research on compact, expressive speech generation.",
      "authors": [
        "Mohammadmahdi Nouriborji and Morteza Rohanian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Computation and Language (cs.CL)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:47:37+00:00",
          "link": "https://arxiv.org/abs/2506.23670v1",
          "size": "737kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Interleaved Speech Modeling through Knowledge Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23670",
        "HTML": "https://arxiv.org/html/2506.23670v1",
        "PDF": "https://arxiv.org/pdf/2506.23670"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23672",
      "abstract": "Energy-centric design is paramount in the current embedded computing era: use cases require increasingly high performance at an affordable power budget, often under real-time constraints. Hardware heterogeneity and parallelism help address the efficiency challenge, but greatly complicate online power consumption assessments, which are essential for dynamic hardware and software stack adaptations. We introduce a novel power modeling methodology with state-of-the-art accuracy, low overhead, and high responsiveness, whose implementation does not rely on microarchitectural details. Our methodology identifies the Performance Monitoring Counters (PMCs) with the highest linear correlation to the power consumption of each hardware sub-system, for each Dynamic Voltage and Frequency Scaling (DVFS) state. The individual, simple models are composed into a complete model that effectively describes the power consumption of the whole system, achieving high accuracy and low overhead. Our evaluation reports an average estimation error of 7.5% for power consumption and 1.3% for energy. We integrate these models in the Linux kernel with Runmeter, an open-source, PMC-based monitoring framework. Runmeter manages PMC sampling and processing, enabling the execution of our power models at runtime. With a worst-case time overhead of only 0.7%, Runmeter provides responsive and accurate power measurements directly in the kernel. This information can be employed for actuation policies in workload-aware DVFS and power-aware, closed-loop task scheduling.",
      "authors": [
        "Sergio Mazzola",
        "Gabriele Ara",
        "Thomas Benz",
        "Bj\\\"orn Forsberg",
        "Tommaso Cucinotta",
        "Luca Benini"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Performance (cs.PF)",
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:50:25+00:00",
          "link": "https://arxiv.org/abs/2506.23672v1",
          "size": "274kb",
          "version": "v1"
        }
      ],
      "title": "Data-Driven Power Modeling and Monitoring via Hardware Performance Counter Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23672",
        "PDF": "https://arxiv.org/pdf/2506.23672"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23673",
      "abstract": "Domain shift is a critical problem for pathology AI as pathology data is heavily influenced by center-specific conditions. Current pathology domain adaptation methods focus on image patches rather than WSI, thus failing to capture global WSI features required in typical clinical scenarios. In this work, we address the challenges of slide-level domain shift by proposing a Hierarchical Adaptation framework for Slide-level Domain-shift (HASD). HASD achieves multi-scale feature consistency and computationally efficient slide-level domain adaptation through two key components: (1) a hierarchical adaptation framework that integrates a Domain-level Alignment Solver for feature alignment, a Slide-level Geometric Invariance Regularization to preserve the morphological structure, and a Patch-level Attention Consistency Regularization to maintain local critical diagnostic cues; and (2) a prototype selection mechanism that reduces computational overhead. We validate our method on two slide-level tasks across five datasets, achieving a 4.1\\% AUROC improvement in a Breast Cancer HER2 Grading cohort and a 3.9\\% C-index gain in a UCEC survival prediction cohort. Our method provides a practical and reliable slide-level domain adaption solution for pathology institutions, minimizing both computational and annotation costs.",
      "authors": [
        "Jingsong Liu",
        "Han Li",
        "Chen Yang",
        "Michael Deutges",
        "Ario Sadafi",
        "Xin You",
        "Katharina Breininger",
        "Nassir Navab",
        "Peter J. Sch\\\"uffler"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:52:01+00:00",
          "link": "https://arxiv.org/abs/2506.23673v1",
          "size": "3637kb",
          "version": "v1"
        }
      ],
      "title": "HASD: Hierarchical Adaption for pathology Slide-level Domain-shift",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23673",
        "HTML": "https://arxiv.org/html/2506.23673v1",
        "PDF": "https://arxiv.org/pdf/2506.23673"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23674",
      "abstract": "The ever-growing size of training datasets enhances the generalization capability of modern machine learning models but also incurs exorbitant computational costs. Existing data pruning approaches aim to accelerate training by removing those less important samples. However, they often rely on gradients or proxy models, leading to prohibitive additional costs of gradient back-propagation and proxy model training. In this paper, we propose Partial Forward Blocking (PFB), a novel framework for lossless training acceleration. The efficiency of PFB stems from its unique adaptive pruning pipeline: sample importance is assessed based on features extracted from the shallow layers of the target model. Less important samples are then pruned, allowing only the retained ones to proceed with the subsequent forward pass and loss back-propagation. This mechanism significantly reduces the computational overhead of deep-layer forward passes and back-propagation for pruned samples, while also eliminating the need for auxiliary backward computations and proxy model training. Moreover, PFB introduces probability density as an indicator of sample importance. Combined with an adaptive distribution estimation module, our method dynamically prioritizes relatively rare samples, aligning with the constantly evolving training state. Extensive experiments demonstrate the significant superiority of PFB in performance and speed. On ImageNet, PFB achieves a 0.5% accuracy improvement and 33% training time reduction with 40% data pruned.",
      "authors": [
        "Dongyue Wu",
        "Zilin Guo",
        "Jialong Zuo",
        "Nong Sang",
        "Changxin Gao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:53:26+00:00",
          "link": "https://arxiv.org/abs/2506.23674v1",
          "size": "612kb",
          "version": "v1"
        }
      ],
      "title": "Partial Forward Blocking: A Novel Data Pruning Paradigm for Lossless Training Acceleration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23674",
        "HTML": "https://arxiv.org/html/2506.23674v1",
        "PDF": "https://arxiv.org/pdf/2506.23674"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23675",
      "abstract": "Vision Transformer have set new benchmarks in several tasks, but these models come with the lack of high computational costs which makes them impractical for resource limited hardware. Network pruning reduces the computational complexity by removing less important operations while maintaining performance. However, pruning a model on an unseen data domain, leads to a misevaluation of weight significance, resulting in suboptimal resource assignment. In this work, we find that task-sensitive layers initially fail to improve the feature representation on downstream tasks, leading to performance loss for early pruning decisions. To address this problem, we introduce Pruning by Block Benefit (P3B), a pruning method that utilizes the relative contribution on block level to globally assign parameter resources. P3B identifies low-impact components to reduce parameter allocation while preserving critical ones. Classical pruning mask optimization struggles to reactivate zero-mask-elements. In contrast, P3B sets a layerwise keep ratio based on global performance metrics, ensuring the reactivation of late-converging blocks. We show in extensive experiments that P3B is a state of the art pruning method with most noticeable gains in transfer learning tasks. Notably, P3B is able to conserve high performance, even in high sparsity regimes of 70% parameter reduction while only losing 0.64% in accuracy.",
      "authors": [
        "Patrick Glandorf",
        "Bodo Rosenhahn"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:58:25+00:00",
          "link": "https://arxiv.org/abs/2506.23675v1",
          "size": "200kb",
          "version": "v1"
        }
      ],
      "title": "Pruning by Block Benefit: Exploring the Properties of Vision Transformer Blocks during Domain Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23675",
        "PDF": "https://arxiv.org/pdf/2506.23675"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23676",
      "abstract": "Due to their powerful image generation capabilities, diffusion-based adversarial example generation methods through image editing are rapidly gaining popularity. However, due to reliance on the discriminative capability of the diffusion model, these diffusion-based methods often struggle to generalize beyond conventional image classification tasks, such as in Deepfake detection. Moreover, traditional strategies for enhancing adversarial example transferability are challenging to adapt to these methods. To address these challenges, we propose a unified framework that seamlessly incorporates traditional transferability enhancement strategies into diffusion model-based adversarial example generation via image editing, enabling their application across a wider range of downstream tasks. Our method won first place in the \"1st Adversarial Attacks on Deepfake Detectors: A Challenge in the Era of AI-Generated Media\" competition at ACM MM25, which validates the effectiveness of our approach.",
      "authors": [
        "Gaozheng Pei",
        "Ke Ma",
        "Dongpeng Zhang",
        "Chengzhi Sun",
        "Qianqian Xu",
        "Qingming Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:59:09+00:00",
          "link": "https://arxiv.org/abs/2506.23676v1",
          "size": "3184kb",
          "version": "v1"
        }
      ],
      "title": "A Unified Framework for Stealthy Adversarial Generation via Latent Optimization and Transferability Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23676",
        "HTML": "https://arxiv.org/html/2506.23676v1",
        "PDF": "https://arxiv.org/pdf/2506.23676"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23678",
      "abstract": "The output quality of large language models (LLMs) can be improved via \"reasoning\": generating segments of chain-of-thought (CoT) content to further condition the model prior to producing user-facing output. While these chains contain valuable information, they are verbose and lack explicit organization, making them tedious to review. Moreover, they lack opportunities for user feedback, such as to remove unwanted considerations, add desired ones, or clarify unclear assumptions. We introduce Interactive Reasoning, an interaction design that visualizes chain-of-thought outputs as a hierarchy of topics and enables user review and modification. We implement interactive reasoning in Hippo, a prototype for AI-assisted decision making in the face of uncertain trade-offs. In a user study with 16 participants, we find that interactive reasoning in Hippo allows users to quickly identify and interrupt erroneous generations, efficiently steer the model towards customized responses, and better understand both model reasoning and model outputs. Our work contributes to a new paradigm that incorporates user oversight into LLM reasoning processes.",
      "authors": [
        "Rock Yuren Pang",
        "K. J. Kevin Feng",
        "Shangbin Feng",
        "Chu Li",
        "Weijia Shi",
        "Yulia Tsvetkov",
        "Jeffrey Heer",
        "Katharina Reinecke"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:00:43+00:00",
          "link": "https://arxiv.org/abs/2506.23678v1",
          "size": "4499kb",
          "version": "v1"
        }
      ],
      "title": "Interactive Reasoning: Visualizing and Controlling Chain-of-Thought Reasoning in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23678",
        "HTML": "https://arxiv.org/html/2506.23678v1",
        "PDF": "https://arxiv.org/pdf/2506.23678"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23679",
      "abstract": "Modular exponentiation is crucial to number theory and cryptography, yet remains largely unexplored from a mechanistic interpretability standpoint. We train a 4-layer encoder-decoder Transformer model to perform this operation and investigate the emergence of numerical reasoning during training. Utilizing principled sampling strategies, PCA-based embedding analysis, and activation patching, we examine how number-theoretic properties are encoded within the model. We find that reciprocal operand training leads to strong performance gains, with sudden generalization across related moduli. These synchronized accuracy surges reflect grokking-like dynamics, suggesting the model internalizes shared arithmetic structure. We also find a subgraph consisting entirely of attention heads in the final layer sufficient to achieve full performance on the task of regular exponentiation. These results suggest that transformer models learn modular arithmetic through specialized computational circuits, paving the way for more interpretable and efficient neural approaches to modular exponentiation.",
      "authors": [
        "David Demitri Africa",
        "Sara M. Kapoor",
        "Theo Simon Sorg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:00:44+00:00",
          "link": "https://arxiv.org/abs/2506.23679v1",
          "size": "11062kb",
          "version": "v1"
        }
      ],
      "title": "Learning Modular Exponentiation with Transformers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23679",
        "HTML": "https://arxiv.org/html/2506.23679v1",
        "PDF": "https://arxiv.org/pdf/2506.23679"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23680",
      "abstract": "In this paper, we investigate the transmission latency of the secure aggregation problem in a \\emph{wireless} federated learning system with multiple curious servers. We propose a privacy-preserving coded aggregation scheme where the servers can not infer any information about the distributed users' local gradients, nor the aggregation value. In our scheme, each user encodes its local gradient into $\\sK$ confidential messages intended exclusively for different servers using a multi-secret sharing method, and each server forwards the summation of the received confidential messages, while the users sequentially employ artificial noise alignment techniques to facilitate secure transmission. Through these summations, the user can recover the aggregation of all local gradients. We prove the privacy guarantee in the information-theoretic sense and characterize the uplink and downlink communication latency measured by \\emph{normalized delivery time} (NDT), both of which decrease monotonically with the number of servers $\\sK$ while increasing over most of the range of the number of users $\\sM$. Finally, we establish a lower bound on the NDT of the considered system and theoretically prove that the scheme achieves the optimal uplink and downlink NDT under the conditions $\\sK \\gg \\sM \\gg 0$ and $\\sK \\gg \\sM$, respectively. For arbitrary $\\sK$ and $\\sM$, the proposed scheme achieves the optimal uplink NDT within a multiplicative gap of $4$.",
      "authors": [
        "Zhenhao Huang",
        "Kai Liang",
        "Yuanming Shi",
        "Songze Li",
        "and Youlong Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:03:38+00:00",
          "link": "https://arxiv.org/abs/2506.23680v1",
          "size": "557kb",
          "version": "v1"
        }
      ],
      "title": "Asymptotically Optimal Secure Aggregation for Wireless Federated Learning with Multiple Servers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23680",
        "HTML": "https://arxiv.org/html/2506.23680v1",
        "PDF": "https://arxiv.org/pdf/2506.23680"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23682",
      "abstract": "A digital security-by-design computer architecture, like CHERI, lets you program without fear of buffer overflows or other memory safety errors, but CHERI also rewrites some of the assumptions about how C works and how fundamental types (such as pointers) are implemented in hardware. We conducted a usability study to examine how developers react to the changes required by CHERI when porting software to run on it. We find that developers struggle with CHERI's display of warnings and errors and a lack of diverse documentation.",
      "authors": [
        "Maysara Alhindi",
        "Joseph Hallett"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Hardware Architecture (cs.AR)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:04:14+00:00",
          "link": "https://arxiv.org/abs/2506.23682v1",
          "size": "25kb",
          "version": "v1"
        }
      ],
      "title": "Not quite a piece of CHERI-cake: Are new digital security by design architectures usable?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23682",
        "HTML": "https://arxiv.org/html/2506.23682v1",
        "PDF": "https://arxiv.org/pdf/2506.23682"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23683",
      "abstract": "There are many sandboxing mechanisms provided by operating systems to limit what resources applications can access, however, sometimes the use of these mechanisms requires developers to refactor their code to fit the sandboxing model. In this work, we investigate what makes existing sandboxing mechanisms challenging to apply to certain types of applications, and propose Threadbox, a sandboxing mechanism that enables having modular and independent sandboxes, and can be applied to threads and sandbox specific functions. We present case studies to illustrate the applicability of the idea and discuss its limitations.",
      "authors": [
        "Maysara Alhindi",
        "Joseph Hallett"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Operating Systems (cs.OS)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:04:38+00:00",
          "link": "https://arxiv.org/abs/2506.23683v1",
          "size": "205kb",
          "version": "v1"
        }
      ],
      "title": "Threadbox: Sandboxing for Modular Security",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23683",
        "HTML": "https://arxiv.org/html/2506.23683v1",
        "PDF": "https://arxiv.org/pdf/2506.23683"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23689",
      "abstract": "We introduce Pok\\'eAI, the first text-based, multi-agent large language model (LLM) framework designed to autonomously play and progress through Pok\\'emon Red. Our system consists of three specialized agents-Planning, Execution, and Critique-each with its own memory bank, role, and skill set. The Planning Agent functions as the central brain, generating tasks to progress through the game. These tasks are then delegated to the Execution Agent, which carries them out within the game environment. Upon task completion, the Critique Agent evaluates the outcome to determine whether the objective was successfully achieved. Once verification is complete, control returns to the Planning Agent, forming a closed-loop decision-making system.\n  As a preliminary step, we developed a battle module within the Execution Agent. Our results show that the battle AI achieves an average win rate of 80.8% across 50 wild encounters, only 6% lower than the performance of an experienced human player. Furthermore, we find that a model's battle performance correlates strongly with its LLM Arena score on language-related tasks, indicating a meaningful link between linguistic ability and strategic reasoning. Finally, our analysis of gameplay logs reveals that each LLM exhibits a unique playstyle, suggesting that individual models develop distinct strategic behaviors.",
      "authors": [
        "Zihao Liu",
        "Xinhang Sui",
        "Yueran Song",
        "Siwen Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:09:13+00:00",
          "link": "https://arxiv.org/abs/2506.23689v1",
          "size": "1184kb",
          "version": "v1"
        }
      ],
      "title": "Pok\\'eAI: A Goal-Generating, Battle-Optimizing Multi-agent System for Pokemon Red",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23689",
        "HTML": "https://arxiv.org/html/2506.23689v1",
        "PDF": "https://arxiv.org/pdf/2506.23689"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23690",
      "abstract": "Diffusion-based video motion customization facilitates the acquisition of human motion representations from a few video samples, while achieving arbitrary subjects transfer through precise textual conditioning. Existing approaches often rely on semantic-level alignment, expecting the model to learn new motion concepts and combine them with other entities (e.g., ''cats'' or ''dogs'') to produce visually appealing results. However, video data involve complex spatio-temporal patterns, and focusing solely on semantics cause the model to overlook the visual complexity of motion. Conversely, tuning only the visual representation leads to semantic confusion in representing the intended action. To address these limitations, we propose SynMotion, a new motion-customized video generation model that jointly leverages semantic guidance and visual adaptation. At the semantic level, we introduce the dual-embedding semantic comprehension mechanism which disentangles subject and motion representations, allowing the model to learn customized motion features while preserving its generative capabilities for diverse subjects. At the visual level, we integrate parameter-efficient motion adapters into a pre-trained video generation model to enhance motion fidelity and temporal coherence. Furthermore, we introduce a new embedding-specific training strategy which \\textbf{alternately optimizes} subject and motion embeddings, supported by the manually constructed Subject Prior Video (SPV) training dataset. This strategy promotes motion specificity while preserving generalization across diverse subjects. Lastly, we introduce MotionBench, a newly curated benchmark with diverse motion patterns. Experimental results across both T2V and I2V settings demonstrate that \\method outperforms existing baselines. Project page: https://lucaria-academy.github.io/SynMotion/",
      "authors": [
        "Shuai Tan and Biao Gong and Yujie Wei and Shiwei Zhang and Zhuoxin Liu and Dandan Zheng and Jingdong Chen and Yan Wang and Hao Ouyang and Kecheng Zheng and Yujun Shen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:09:32+00:00",
          "link": "https://arxiv.org/abs/2506.23690v1",
          "size": "43674kb",
          "version": "v1"
        }
      ],
      "title": "SynMotion: Semantic-Visual Adaptation for Motion Customized Video Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23690",
        "HTML": "https://arxiv.org/html/2506.23690v1",
        "PDF": "https://arxiv.org/pdf/2506.23690"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23692",
      "abstract": "While AI for Science (AI4S) serves as an analytical tool in the current research paradigm, it doesn't solve its core inefficiency. We propose \"Agent for Science\" (Agent4S)-the use of LLM-driven agents to automate the entire research workflow-as the true Fifth Scientific Paradigm. This paper introduces a five-level classification for Agent4S, outlining a clear roadmap from simple task automation to fully autonomous, collaborative \"AI Scientists.\" This framework defines the next revolutionary step in scientific discovery.",
      "authors": [
        "Boyuan Zheng",
        "Zerui Fang",
        "Zhe Xu",
        "Rui Wang",
        "Yiwen Chen",
        "Cunshi Wang",
        "Mengwei Qu",
        "Lei Lei",
        "Zhen Feng",
        "Yan Liu",
        "Yuyang Li",
        "Mingzhou Tan",
        "Jiaji Wu",
        "Jianwei Shuai",
        "Jia Li",
        "Fangfu Ye"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:11:39+00:00",
          "link": "https://arxiv.org/abs/2506.23692v1",
          "size": "372kb",
          "version": "v1"
        }
      ],
      "title": "Agent4S: The Transformation of Research Paradigms from the Perspective of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23692",
        "HTML": "https://arxiv.org/html/2506.23692v1",
        "PDF": "https://arxiv.org/pdf/2506.23692"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23694",
      "abstract": "The process of requirements analysis requires an understanding of the end users of a system. Thus, expert stakeholders, such as User Experience (UX) designers, usually create various descriptions containing information about the users and their possible needs. In our paper, we investigate to what extent UX novices are able to write such descriptions into user scenarios. We conducted a user study with 60 participants consisting of 30 UX experts and 30 novices who were asked to write a user scenario with or without the help of an LLM-supported writing assistant. Our findings show that LLMs empower laypersons to write reasonable user scenarios and provide first-hand insights for requirements analysis that are comparable to UX experts in terms of structure and clarity, while especially excelling at audience-orientation. We present our qualitative and quantitative findings, including user scenario anatomies, potential influences, and differences in the way participants approached the task.",
      "authors": [
        "Patrick Stadler",
        "Christopher Lazik",
        "Christopher Katins",
        "and Thomas Kosch"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:15:44+00:00",
          "link": "https://arxiv.org/abs/2506.23694v1",
          "size": "1020kb",
          "version": "v1"
        }
      ],
      "title": "If You Had to Pitch Your Ideal Software -- Evaluating Large Language Models to Support User Scenario Writing for User Experience Experts and Laypersons",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23694",
        "HTML": "https://arxiv.org/html/2506.23694v1",
        "PDF": "https://arxiv.org/pdf/2506.23694"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23696",
      "abstract": "Software reliability is critical in ensuring that the digital systems we depend on function correctly. In software development, increasing software reliability often involves testing. However, for complex and critical systems, developers can use Design by Contract (DbC) methods to define precise specifications that software components must satisfy. Verification-Aware (VA) programming languages support DbC and formal verification at compile-time or run-time, offering stronger correctness guarantees than traditional testing. However, despite the strong guarantees provided by VA languages, their adoption remains limited. In this study, we investigate the barriers to adopting VA languages by analyzing developer discussions on public forums using topic modeling techniques. We complement this analysis with a developer survey to better understand the practical challenges associated with VA languages. Our findings reveal key obstacles to adoption, including steep learning curves and usability issues. Based on these insights, we identify actionable recommendations to improve the usability and accessibility of VA languages. Our findings suggest that simplifying tool interfaces, providing better educational materials, and improving integration with everyday development environments could improve the usability and adoption of these languages. Our work provides actionable insights for improving the usability of VA languages and making verification tools more accessible.",
      "authors": [
        "Francisco Oliveira",
        "Alexandra Mendes and Carolina Carreira"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:17:39+00:00",
          "link": "https://arxiv.org/abs/2506.23696v1",
          "size": "836kb",
          "version": "v1"
        }
      ],
      "title": "What Challenges Do Developers Face When Using Verification-Aware Programming Languages?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23696",
        "HTML": "https://arxiv.org/html/2506.23696v1",
        "PDF": "https://arxiv.org/pdf/2506.23696"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23702",
      "abstract": "Both the function and its normal derivative on the element boundary are $Q_k$ polynomials\n  for the Bogner-Fox-Schmit $C^1$-$Q_k$ finite element functions. Mathematically, to keep the optimal order of approximation, their spaces are required to\n  include $P_k$ and $P_{k-1}$ polynomials respectively. We construct a Bell type $C^1$-$Q_k$ finite element on rectangular meshes in 2D and 3D,\n  which has its normal derivative as a $Q_{k-1}$ polynomial on each face, for $k\\ge 4$. We show, with a big reduction of the space, the $C^1$-$Q_k$ Bell\n  finite element retains the optimal order of convergence. Numerical experiments are performed, comparing the new elements with the original elements.",
      "authors": [
        "Hongling Hu and Shangyou Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:25:46+00:00",
          "link": "https://arxiv.org/abs/2506.23702v1",
          "size": "13kb",
          "version": "v1"
        }
      ],
      "title": "Rectangular $C^1$-$Q_k$ Bell finite elements in two and three dimensions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23702",
        "HTML": "https://arxiv.org/html/2506.23702v1",
        "PDF": "https://arxiv.org/pdf/2506.23702"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23703",
      "abstract": "While artificial intelligence (AI) is advancing rapidly and mastering increasingly complex problems with astonishing performance, the safety assurance of such systems is a major concern. Particularly in the context of safety-critical, real-world cyber-physical systems, AI promises to achieve a new level of autonomy but is hampered by a lack of safety assurance. While data-driven control takes up recent developments in AI to improve control systems, control theory in general could be leveraged to improve AI safety. Therefore, this article outlines a new perspective on AI safety based on an interdisciplinary interpretation of the underlying data-generation process and the respective abstraction by AI systems in a system theory-inspired and system analysis-driven manner. In this context, the new perspective, also referred to as data control, aims to stimulate AI engineering to take advantage of existing safety analysis and assurance in an interdisciplinary way to drive the paradigm of data control. Following a top-down approach, a generic foundation for safety analysis and assurance is outlined at an abstract level that can be refined for specific AI systems and applications and is prepared for future innovation.",
      "authors": [
        "Lars Ullrich",
        "Walter Zimmer",
        "Ross Greer",
        "Knut Graichen",
        "Alois C. Knoll",
        "Mohan Trivedi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:26:59+00:00",
          "link": "https://arxiv.org/abs/2506.23703v1",
          "size": "5839kb",
          "version": "v1"
        }
      ],
      "title": "A New Perspective On AI Safety Through Control Theory Methodologies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23703",
        "HTML": "https://arxiv.org/html/2506.23703v1",
        "PDF": "https://arxiv.org/pdf/2506.23703"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23705",
      "abstract": "Test-time adaptation enables a trained model to adjust to a new domain during inference, making it particularly valuable in clinical settings where such on-the-fly adaptation is required. However, existing techniques depend on large target domain datasets, which are often impractical and unavailable in medical scenarios that demand per-patient, real-time inference. Moreover, current methods commonly focus on two-dimensional images, failing to leverage the volumetric richness of medical imaging data. Bridging this gap, we propose a Patch-Based Multi-View Co-Training method for Single Image Test-Time adaptation. Our method enforces feature and prediction consistency through uncertainty-guided self-training, enabling effective volumetric segmentation in the target domain with only a single test-time image. Validated on three publicly available breast magnetic resonance imaging datasets for tumor segmentation, our method achieves performance close to the upper bound supervised benchmark while also outperforming all existing state-of-the-art methods, on average by a Dice Similarity Coefficient of 3.75%. We publicly share our accessible codebase, readily integrable with the popular nnUNet framework, at https://github.com/smriti-joshi/muvi.git.",
      "authors": [
        "Smriti Joshi",
        "Richard Osuala",
        "Lidia Garrucho",
        "Kaisar Kushibar",
        "Dimitri Kessler",
        "Oliver Diaz",
        "Karim Lekadir"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:29:33+00:00",
          "link": "https://arxiv.org/abs/2506.23705v1",
          "size": "628kb",
          "version": "v1"
        }
      ],
      "title": "Single Image Test-Time Adaptation via Multi-View Co-Training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23705",
        "HTML": "https://arxiv.org/html/2506.23705v1",
        "PDF": "https://arxiv.org/pdf/2506.23705"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23706",
      "abstract": "Benchmarks are important measures to evaluate safety and compliance of AI models at scale. However, they typically do not offer verifiable results and lack confidentiality for model IP and benchmark datasets. We propose Attestable Audits, which run inside Trusted Execution Environments and enable users to verify interaction with a compliant AI model. Our work protects sensitive data even when model provider and auditor do not trust each other. This addresses verification challenges raised in recent AI governance frameworks. We build a prototype demonstrating feasibility on typical audit benchmarks against Llama-3.1.",
      "authors": [
        "Christoph Schnabl",
        "Daniel Hugenroth",
        "Bill Marino",
        "Alastair R. Beresford"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:29:42+00:00",
          "link": "https://arxiv.org/abs/2506.23706v1",
          "size": "438kb",
          "version": "v1"
        }
      ],
      "title": "Attestable Audits: Verifiable AI Safety Benchmarks Using Trusted Execution Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23706",
        "HTML": "https://arxiv.org/html/2506.23706v1",
        "PDF": "https://arxiv.org/pdf/2506.23706"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23707",
      "abstract": "The rapid proliferation of modified images on social networks that are driven by widely accessible editing tools demands robust forensic tools for digital governance. Image provenance analysis, which filters various query image variants and constructs a directed graph to trace their phylogeny history, has emerged as a critical solution. However, existing methods face two fundamental limitations: First, accuracy issues arise from overlooking heavily modified images due to low similarity while failing to exclude unrelated images and determine modification directions under diverse modification scenarios. Second, scalability bottlenecks stem from pairwise image analysis incurs quadratic complexity, hindering application in large-scale scenarios. This paper presents a scalable end-to-end pipeline for image provenance analysis that achieves high precision with linear complexity. This improves filtering effectiveness through modification relationship tracing, which enables the comprehensive discovery of image variants regardless of their visual similarity to the query. In addition, the proposed pipeline integrates local features matching and compression artifact capturing, enhancing robustness against diverse modifications and enabling accurate analysis of images' relationships. This allows the generation of a directed provenance graph that accurately characterizes the image's phylogeny history. Furthermore, by optimizing similarity calculations and eliminating redundant pairwise analysis during graph construction, the pipeline achieves a linear time complexity, ensuring its scalability for large-scale scenarios. Experiments demonstrate pipeline's superior performance, achieving a 16.7-56.1% accuracy improvement. Notably, it exhibits significant scalability with an average 3.0-second response time on 10 million scale images, which is far shorter than the SOTA approach's 12-minute duration.",
      "authors": [
        "Jiewei Lai",
        "Lan Zhang",
        "Chen Tang",
        "Pengcheng Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:30:27+00:00",
          "link": "https://arxiv.org/abs/2506.23707v1",
          "size": "420kb",
          "version": "v1"
        }
      ],
      "title": "Efficient and Accurate Image Provenance Analysis: A Scalable Pipeline for Large-scale Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23707",
        "HTML": "https://arxiv.org/html/2506.23707v1",
        "PDF": "https://arxiv.org/pdf/2506.23707"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23711",
      "abstract": "We propose Subjective Camera, a human-as-imaging-device paradigm that reconstructs real-world scenes from mental impressions through synergistic use of verbal descriptions and progressive rough sketches. This approach overcomes dual limitations of language ambiguity and sketch abstraction by treating the user's drawing sequence as priors, effectively translating subjective perceptual expectations into photorealistic images.\n  Existing approaches face three fundamental barriers: (1) user-specific subjective input biases, (2) huge modality gap between planar sketch and 3D priors in diffusion, and (3) sketch quality-sensitive performance degradation. Current solutions either demand resource-intensive model adaptation or impose impractical requirements on sketch precision.\n  Our framework addresses these challenges through concept-sequential generation. (1) We establish robust appearance priors through text-reward optimization, and then implement sequence-aware disentangled generation that processes concepts in sketching order; these steps accommodate user-specific subjective expectation in a train-free way. (2) We employ latent optimization that effectively bridges the modality gap between planar sketches and 3D priors in diffusion. (3) Our hierarchical reward-guided framework enables the use of rough sketches without demanding artistic expertise. Comprehensive evaluation across diverse datasets demonstrates that our approach achieves state-of-the-art performance in maintaining both semantic and spatial coherence.",
      "authors": [
        "Haoyang Chen",
        "Dongfang Sun",
        "Caoyuan Ma",
        "Shiqin Wang",
        "Kewei Zhang",
        "Zheng Wang and Zhixiang Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:36:49+00:00",
          "link": "https://arxiv.org/abs/2506.23711v1",
          "size": "1028kb",
          "version": "v1"
        }
      ],
      "title": "Subjective Camera: Bridging Human Cognition and Visual Reconstruction through Sequence-Aware Sketch-Guided Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23711",
        "HTML": "https://arxiv.org/html/2506.23711v1",
        "PDF": "https://arxiv.org/pdf/2506.23711"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23714",
      "abstract": "The increasing volume of video content in educational, professional, and social domains necessitates effective summarization techniques that go beyond traditional unimodal approaches. This paper proposes a behaviour-aware multimodal video summarization framework that integrates textual, audio, and visual cues to generate timestamp-aligned summaries. By extracting prosodic features, textual cues and visual indicators, the framework identifies semantically and emotionally important moments. A key contribution is the identification of bonus words, which are terms emphasized across multiple modalities and used to improve the semantic relevance and expressive clarity of the summaries. The approach is evaluated against pseudo-ground truth (pGT) summaries generated using LLM-based extractive method. Experimental results demonstrate significant improvements over traditional extractive method, such as the Edmundson method, in both text and video-based evaluation metrics. Text-based metrics show ROUGE-1 increasing from 0.4769 to 0.7929 and BERTScore from 0.9152 to 0.9536, while in video-based evaluation, our proposed framework improves F1-Score by almost 23%. The findings underscore the potential of multimodal integration in producing comprehensive and behaviourally informed video summaries.",
      "authors": [
        "Md Moinul Islam",
        "Sofoklis Kakouros",
        "Janne Heikkil\\\"a and Mourad Oussalah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:41:33+00:00",
          "link": "https://arxiv.org/abs/2506.23714v1",
          "size": "486kb",
          "version": "v1"
        }
      ],
      "title": "Towards an Automated Multimodal Approach for Video Summarization: Building a Bridge Between Text, Audio and Facial Cue-Based Summarization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23714",
        "HTML": "https://arxiv.org/html/2506.23714v1",
        "PDF": "https://arxiv.org/pdf/2506.23714"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23715",
      "abstract": "As software continues to permeate nearly every facet of modern life, the complexity and ubiquity of digital services underscore the need for sustainable, effective, and inclusive software development practices. Although software engineering has made significant progress in technical challenges since its inception, the human experience of those involved in software creation, broadly defined as developers, remains underexplored. This column advocates for the formal recognition of Developer eXperience (DevX) as a distinct research field. We argue that DevX profoundly influences critical development activities and overall productivity, especially as development becomes increasingly collaborative and diverse in terms of application domains. Building on existing efforts to measure and enhance DevX, we identify key rationales, scientific enablers, and interdisciplinary intersections that support this emerging discipline. We also outline the core scientific challenges ahead, aiming to call for actions from the research community and to promote more human-centered approaches to software engineering.",
      "authors": [
        "Benoit Combemale"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:42:57+00:00",
          "link": "https://arxiv.org/abs/2506.23715v1",
          "size": "111kb",
          "version": "v1"
        }
      ],
      "title": "Towards a Science of Developer eXperience (DevX)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23715",
        "HTML": "https://arxiv.org/html/2506.23715v1",
        "PDF": "https://arxiv.org/pdf/2506.23715"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23716",
      "abstract": "This paper presents a sample-efficient, data-driven control framework for finite-horizon linear quadratic (LQ) control of linear time-varying (LTV) systems. In contrast to the time-invariant case, the time-varying LQ problem involves a differential Riccati equation (DRE) with time-dependent parameters and terminal boundary constraints. We formulate the LQ problem as a nonconvex optimization problem and conduct a rigorous analysis of its dual structure. By exploiting the inherent convexity of the dual problem and analyzing the KKT conditions, we derive an explicit relationship between the optimal dual solution and the parameters of the associated Q-function in time-varying case. This theoretical insight supports the development of a novel, sample-efficient, non-iterative semidefinite programming (SDP) algorithm that directly computes the optimal sequence of feedback gains from an ensemble of input-state data sequences without model identification. The resulting convex, data-dependent framework provides global optimality guarantees for completely unknown LTV systems. As a special case, the method also applies to finite-horizon LQ control of linear time-invariant (LTI) systems. In this setting, a single input-state trajectory suffices to identify the optimal LQ feedback policy, improving significantly over existing Q-learning approaches for finite horizon LTI systems that typically require data from multiple episodes. The approach provides a new optimization-based perspective on Q-learning in time-varying settings and contributes to the broader understanding of data-driven control in non-stationary environments. Simulation results show that, compared to recent methods, the proposed approach achieves superior optimality and sample efficiency on LTV systems, and indicates potential for stabilizing and optimal control of nonlinear systems.",
      "authors": [
        "Sahel Vahedi Noori and Maryam Babazadeh"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:44:09+00:00",
          "link": "https://arxiv.org/abs/2506.23716v1",
          "size": "326kb",
          "version": "v1"
        }
      ],
      "title": "A Data-Ensemble-Based Approach for Sample-Efficient LQ Control of Linear Time-Varying Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23716",
        "HTML": "https://arxiv.org/html/2506.23716v1",
        "PDF": "https://arxiv.org/pdf/2506.23716"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23717",
      "abstract": "Multi-bit spiking neural networks (SNNs) have recently become a heated research spot, pursuing energy-efficient and high-accurate AI. However, with more bits involved, the associated memory and computation demands escalate to the point where the performance improvements become disproportionate. Based on the insight that different layers demonstrate different importance and extra bits could be wasted and interfering, this paper presents an adaptive bit allocation strategy for direct-trained SNNs, achieving fine-grained layer-wise allocation of memory and computation resources. Thus, SNN's efficiency and accuracy can be improved. Specifically, we parametrize the temporal lengths and the bit widths of weights and spikes, and make them learnable and controllable through gradients. To address the challenges caused by changeable bit widths and temporal lengths, we propose the refined spiking neuron, which can handle different temporal lengths, enable the derivation of gradients for temporal lengths, and suit spike quantization better. In addition, we theoretically formulate the step-size mismatch problem of learnable bit widths, which may incur severe quantization errors to SNN, and accordingly propose the step-size renewal mechanism to alleviate this issue. Experiments on various datasets, including the static CIFAR and ImageNet and the dynamic CIFAR-DVS and DVS-GESTURE, demonstrate that our methods can reduce the overall memory and computation cost while achieving higher accuracy. Particularly, our SEWResNet-34 can achieve a 2.69\\% accuracy gain and 4.16$\\times$ lower bit budgets over the advanced baseline work on ImageNet. This work will be fully open-sourced.",
      "authors": [
        "Xingting Yao",
        "Qinghao Hu",
        "Fei Zhou",
        "Tielong Liu",
        "Gang Li",
        "Peisong Wang",
        "Jian Cheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:45:16+00:00",
          "link": "https://arxiv.org/abs/2506.23717v1",
          "size": "867kb",
          "version": "v1"
        }
      ],
      "title": "Towards Efficient and Accurate Spiking Neural Networks via Adaptive Bit Allocation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23717",
        "HTML": "https://arxiv.org/html/2506.23717v1",
        "PDF": "https://arxiv.org/pdf/2506.23717"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23719",
      "abstract": "We introduce DABstep, a novel benchmark for evaluating AI agents on realistic multi-step data analysis tasks. DABstep comprises over 450 real-world challenges derived from a financial analytics platform, requiring models to combine code-based data processing with contextual reasoning over heterogeneous documentation. Each task demands an iterative, multi-step problem-solving approach, testing capabilities in data manipulation, cross-referencing multiple sources, and precise result reporting. The benchmark provides a factoid-style answer format with automatic correctness checks for objective scoring at scale. We evaluate leading LLM-based agents, revealing a substantial performance gap: even the best agent achieves only 14.55% accuracy on the hardest tasks. We detail our benchmark's design, dataset composition, task formulation, evaluation protocol, report baseline results and analyze failure modes. DABstep is released with a public leaderboard and toolkit to accelerate research in autonomous data analysis.",
      "authors": [
        "Alex Egg",
        "Martin Iglesias Goyanes",
        "Friso Kingma",
        "Andreu Mora",
        "Leandro von Werra and Thomas Wolf"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:49:21+00:00",
          "link": "https://arxiv.org/abs/2506.23719v1",
          "size": "2527kb",
          "version": "v1"
        }
      ],
      "title": "DABstep: Data Agent Benchmark for Multi-step Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23719",
        "HTML": "https://arxiv.org/html/2506.23719v1",
        "PDF": "https://arxiv.org/pdf/2506.23719"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23723",
      "abstract": "The adoption of mobile robotic platforms in complex environments, such as agricultural settings, requires these systems to exhibit a flexible yet effective architecture that integrates perception and control. In such scenarios, several tasks need to be accomplished simultaneously, ranging from managing robot limits to performing operational tasks and handling human inputs. The purpose of this paper is to present a comprehensive control architecture for achieving complex tasks such as robotized harvesting in vineyards within the framework of the European project CANOPIES. In detail, a 16-DOF dual-arm mobile robot is employed, controlled via a Hierarchical Quadratic Programming (HQP) approach capable of handling both equality and inequality constraints at various priorities to harvest grape bunches selected by the perception system developed within the project. Furthermore, given the complexity of the scenario and the uncertainty in the perception system, which could potentially lead to collisions with the environment, the handling of interaction forces is necessary. Remarkably, this was achieved using the same HQP framework. This feature is further leveraged to enable semi-autonomous operations, allowing a human operator to assist the robotic counterpart in completing harvesting tasks. Finally, the obtained results are validated through extensive testing conducted first in a laboratory environment to prove individual functionalities, then in a real vineyard, encompassing both autonomous and semi-autonomous grape harvesting operations.",
      "authors": [
        "Jozsef Palmieri",
        "Paolo Di Lillo",
        "Stefano Chiaverini",
        "Alessandro Marino"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:54:43+00:00",
          "link": "https://arxiv.org/abs/2506.23723v1",
          "size": "8970kb",
          "version": "v1"
        }
      ],
      "title": "A comprehensive control architecture for semi-autonomous dual-arm robots in agriculture settings",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23723",
        "PDF": "https://arxiv.org/pdf/2506.23723"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23724",
      "abstract": "Test-time Adaptation (TTA) adapts a given model to testing domain data with potential domain shifts through online unsupervised learning, yielding impressive performance. However, to date, existing TTA methods primarily focus on single-model adaptation. In this work, we investigate an intriguing question: how does cross-model knowledge influence the TTA process? Our findings reveal that, in TTA's unsupervised online setting, each model can provide complementary, confident knowledge to the others, even when there are substantial differences in model size. For instance, a smaller model like MobileViT (10.6M parameters) can effectively guide a larger model like ViT-Base (86.6M parameters). In light of this, we propose COCA, a Cross-Model Co-Learning framework for TTA, which mainly consists of two main strategies. 1) Co-adaptation adaptively integrates complementary knowledge from other models throughout the TTA process, reducing individual model biases. 2) Self-adaptation enhances each model's unique strengths via unsupervised learning, enabling diverse adaptation to the target domain. Extensive experiments show that COCA, which can also serve as a plug-and-play module, significantly boosts existing SOTAs, on models with various sizes--including ResNets, ViTs, and Mobile-ViTs--via cross-model co-learned TTA. For example, with Mobile-ViT's guidance, COCA raises ViT-Base's average adaptation accuracy on ImageNet-C from 51.7% to 64.5%. The code is publicly available at https://github.com/ycarobot/COCA.",
      "authors": [
        "Chang'an Yi",
        "Xiaohui Deng",
        "Guohao Chen",
        "Yan Zhou",
        "Qinghua Lu",
        "Shuaicheng Niu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:54:50+00:00",
          "link": "https://arxiv.org/abs/2506.23724v1",
          "size": "531kb",
          "version": "v1"
        }
      ],
      "title": "When Small Guides Large: Cross-Model Co-Learning for Test-Time Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23724",
        "HTML": "https://arxiv.org/html/2506.23724v1",
        "PDF": "https://arxiv.org/pdf/2506.23724"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23725",
      "abstract": "Vision-Language Models (VLMs) are increasingly pivotal for generalist robot manipulation, enabling tasks such as physical reasoning, policy generation, and failure detection. However, their proficiency in these high-level applications often assumes a deep understanding of low-level physical prerequisites, a capability that remains largely unverified. For robots to perform actions reliably, they must comprehend intrinsic object properties (e.g., material, weight), action affordances (e.g., graspable, stackable), and physical constraints (e.g., stability, reachability, or an object's state, such as being closed). Despite the widespread use of VLMs in manipulation tasks, we argue that off-the-shelf models may lack this granular, physically grounded understanding, as such prerequisites are often overlooked during training.\n  To address this critical gap, we introduce PAC Bench, a comprehensive benchmark designed to systematically evaluate VLMs on their understanding of core Properties, Affordances, and Constraints (PAC) from a task executability perspective. PAC Bench features a diverse dataset with over 30,000 annotations, comprising 673 real-world images (115 object classes, 15 property types, and 1 to 3 affordances defined per class), 100 real-world humanoid-view scenarios, and 120 unique simulated constraint scenarios across four tasks.\n  Our evaluations reveal significant gaps in the ability of current VLMs to grasp fundamental physical concepts, highlighting limitations in their suitability for reliable robot manipulation and pointing to key areas for targeted research. PAC Bench also serves as a standardized benchmark for rigorously evaluating physical reasoning in VLMs and guiding the development of more robust, physically grounded models for robotic applications.\n  Project Page: https://pacbench.github.io/",
      "authors": [
        "Atharva Gundawar",
        "Som Sagar",
        "Ransalu Senanayake"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:58:36+00:00",
          "link": "https://arxiv.org/abs/2506.23725v1",
          "size": "8601kb",
          "version": "v1"
        }
      ],
      "title": "PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23725",
        "HTML": "https://arxiv.org/html/2506.23725v1",
        "PDF": "https://arxiv.org/pdf/2506.23725"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23726",
      "abstract": "Solving inverse problems -- recovering signals from incomplete or noisy measurements -- is fundamental in science and engineering. Score-based generative models (SGMs) have recently emerged as a powerful framework for this task. Two main paradigms have formed: unsupervised approaches that adapt pretrained generative models to inverse problems, and supervised bridge methods that train stochastic processes conditioned on paired clean and corrupted data. While the former typically assume knowledge of the measurement model, the latter have largely overlooked this structural information. We introduce System embedded Diffusion Bridge Models (SDBs), a new class of supervised bridge methods that explicitly embed the known linear measurement system into the coefficients of a matrix-valued SDE. This principled integration yields consistent improvements across diverse linear inverse problems and demonstrates robust generalization under system misspecification between training and deployment, offering a promising solution to real-world applications.",
      "authors": [
        "Bartlomiej Sobieski",
        "Matthew Tivnan",
        "Yuang Wang",
        "Siyeop Yoon",
        "Pengfei Jin",
        "Dufan Wu",
        "Quanzheng Li",
        "Przemyslaw Biecek"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:58:49+00:00",
          "link": "https://arxiv.org/abs/2506.23726v1",
          "size": "11154kb",
          "version": "v1"
        }
      ],
      "title": "System-Embedded Diffusion Bridge Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23726",
        "HTML": "https://arxiv.org/html/2506.23726v1",
        "PDF": "https://arxiv.org/pdf/2506.23726"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23729",
      "abstract": "Video identity customization seeks to synthesize realistic, temporally coherent videos of a specific subject, given a single reference image and a text prompt. This task presents two core challenges: (1) maintaining identity consistency while aligning with the described appearance and actions, and (2) generating natural, fluid motion without unrealistic stiffness. To address these challenges, we introduce Proteus-ID, a novel diffusion-based framework for identity-consistent and motion-coherent video customization. First, we propose a Multimodal Identity Fusion (MIF) module that unifies visual and textual cues into a joint identity representation using a Q-Former, providing coherent guidance to the diffusion model and eliminating modality imbalance. Second, we present a Time-Aware Identity Injection (TAII) mechanism that dynamically modulates identity conditioning across denoising steps, improving fine-detail reconstruction. Third, we propose Adaptive Motion Learning (AML), a self-supervised strategy that reweights the training loss based on optical-flow-derived motion heatmaps, enhancing motion realism without requiring additional inputs. To support this task, we construct Proteus-Bench, a high-quality dataset comprising 200K curated clips for training and 150 individuals from diverse professions and ethnicities for evaluation. Extensive experiments demonstrate that Proteus-ID outperforms prior methods in identity preservation, text alignment, and motion quality, establishing a new benchmark for video identity customization. Codes and data are publicly available at https://grenoble-zhang.github.io/Proteus-ID/.",
      "authors": [
        "Guiyu Zhang",
        "Chen Shi",
        "Zijian Jiang",
        "Xunzhi Xiang",
        "Jingjing Qian",
        "Shaoshuai Shi",
        "Li Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T11:05:32+00:00",
          "link": "https://arxiv.org/abs/2506.23729v1",
          "size": "11519kb",
          "version": "v1"
        }
      ],
      "title": "Proteus-ID: ID-Consistent and Motion-Coherent Video Customization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23729",
        "HTML": "https://arxiv.org/html/2506.23729v1",
        "PDF": "https://arxiv.org/pdf/2506.23729"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23730",
      "abstract": "We give a quantifier elimination procedure for one-parametric Presburger arithmetic, the extension of Presburger arithmetic with the function $x \\mapsto t \\cdot x$, where $t$ is a fixed free variable ranging over the integers. This resolves an open problem proposed in [Bogart et al., Discrete Analysis, 2017]. As conjectured in [Goodrick, Arch. Math. Logic, 2018], quantifier elimination is obtained for the extended structure featuring all integer division functions $x \\mapsto \\lfloor{\\frac{x}{f(t)}}\\rfloor$, one for each integer polynomial $f$.\n  Our algorithm works by iteratively eliminating blocks of existential quantifiers. The elimination of a block builds on two sub-procedures, both running in non-deterministic polynomial time. The first one is an adaptation of a recently developed and efficient quantifier elimination procedure for Presburger arithmetic, modified to handle formulae with coefficients over the ring $\\mathbb{Z}[t]$ of univariate polynomials. The second is reminiscent of the so-called \"base $t$ division method\" used by Bogart et al. As a result, we deduce that the satisfiability problem for the existential fragment of one-parametric Presburger arithmetic (which encompasses a broad class of non-linear integer programs) is in NP, and that the smallest solution to a satisfiable formula in this fragment is of polynomial bit size.",
      "authors": [
        "Alessio Mansutti",
        "Mikhail R. Starchak"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Symbolic Computation (cs.SC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T11:07:21+00:00",
          "link": "https://arxiv.org/abs/2506.23730v1",
          "size": "100kb",
          "version": "v1"
        }
      ],
      "title": "One-Parametric Presburger Arithmetic has Quantifier Elimination",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23730",
        "PDF": "https://arxiv.org/pdf/2506.23730"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23731",
      "abstract": "Image generative models have become increasingly popular, but training them requires large datasets that are costly to collect and curate. To circumvent these costs, some parties may exploit existing models by using the generated images as training data for their own models. In general, watermarking is a valuable tool for detecting unauthorized use of generated images. However, when these images are used to train a new model, watermarking can only enable detection if the watermark persists through training and remains identifiable in the outputs of the newly trained model - a property known as radioactivity. We analyze the radioactivity of watermarks in images generated by diffusion models (DMs) and image autoregressive models (IARs). We find that existing watermarking methods for DMs fail to retain radioactivity, as watermarks are either erased during encoding into the latent space or lost in the noising-denoising process (during the training in the latent space). Meanwhile, despite IARs having recently surpassed DMs in image generation quality and efficiency, no radioactive watermarking methods have been proposed for them. To overcome this limitation, we propose the first watermarking method tailored for IARs and with radioactivity in mind - drawing inspiration from techniques in large language models (LLMs), which share IARs' autoregressive paradigm. Our extensive experimental evaluation highlights our method's effectiveness in preserving radioactivity within IARs, enabling robust provenance tracking, and preventing unauthorized use of their generated images.",
      "authors": [
        "Michel Meintz",
        "Jan Dubi\\'nski",
        "Franziska Boenisch",
        "Adam Dziedzic"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T11:08:10+00:00",
          "link": "https://arxiv.org/abs/2506.23731v1",
          "size": "3937kb",
          "version": "v1"
        }
      ],
      "title": "Radioactive Watermarks in Diffusion and Autoregressive Image Generative Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23731",
        "HTML": "https://arxiv.org/html/2506.23731v1",
        "PDF": "https://arxiv.org/pdf/2506.23731"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23733",
      "abstract": "Transportation accounts for around 27% of green house gas emissions in the UK. While an obvious priority area for decarbonisation, and aligned to the UK government goal of reducing emissions by 68% for 2030, the free-market nature of the transportation sector combined with its fundamentally implicit and pervasive connections to all aspects of society and national infrastructure mean that all decarbonisation efforts to date have been siloed within a single transport sector, e.g. only considering greener aviation fuels. Truly decarbonising transport requires radical changes to the entire transport infrastructure, and since that transport does not happen in isolation, a single user often using multiple modes, we need a view over the whole transport system. The first step to solving a problem is to understand it. As a result of the fragmented nature of the transportation sector, there is currently no system level view. Without the ability to monitor even adjacent transport domains, the ability for people or organisations to (dynamically) adapt their operations for decarbonisation outcomes is unrealistic. As transportation is a complex social-techno-economic system, information and knowledge sharing is a must to be able to understand and explore potential solutions to the decarbonisation challenge. We believe a Federated Digital Twinning Approach has the potential to tackle transport decarbonisation problems, and, in this extended abstract, we give an overview of the research required to tackle the fundamental challenges around digital twin design, generation, validation and verification.",
      "authors": [
        "Blair Archibald",
        "Paul Harvey",
        "Michele Sevegnani"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T11:13:30+00:00",
          "link": "https://arxiv.org/abs/2506.23733v1",
          "size": "159kb",
          "version": "v1"
        }
      ],
      "title": "A Digital Twinning Approach to Decarbonisation: Research Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23733",
        "HTML": "https://arxiv.org/html/2506.23733v1",
        "PDF": "https://arxiv.org/pdf/2506.23733"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23734",
      "abstract": "Competitive Co-evolutionary Algorithms (CCEAs) are often hampered by complex dynamics like intransitivity and the Red Queen effect, leading to unstable convergence. To counter these challenges, this paper introduces the Marker Gene Method (MGM), a framework that establishes stability by using a 'marker gene' as a dynamic benchmark and an adaptive weighting mechanism to balance exploration and exploitation. We provide rigorous mathematical proofs demonstrating that MGM creates strong attractors near Nash Equilibria within the Strictly Competitive Game framework. Empirically, MGM demonstrates its efficacy across a spectrum of challenges: it stabilizes the canonical Rock-Paper-Scissors game, significantly improves the performance of C-RMOEA/D on ZDT benchmarks, and, when augmented with a Memory Pool (MP) extension, it successfully tames the notoriously pathological Shapley Biased Game. This work presents a theoretically sound and empirically validated framework that substantially enhances the stability and robustness of CCEAs in complex competitive environments.",
      "authors": [
        "Hao Shi",
        "Xi Li",
        "Fangfang Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T11:13:36+00:00",
          "link": "https://arxiv.org/abs/2506.23734v1",
          "size": "2792kb",
          "version": "v1"
        }
      ],
      "title": "Marker Gene Method : Identifying Stable Solutions in a Dynamic Environment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23734",
        "HTML": "https://arxiv.org/html/2506.23734v1",
        "PDF": "https://arxiv.org/pdf/2506.23734"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23735",
      "abstract": "Large language models (LLMs) have shown remarkable performance on various tasks, but existing evaluation benchmarks are often static and insufficient to fully assess their robustness and generalization in realistic scenarios. Prior work using evolutionary or adversarial data augmentation has improved evaluation diversity but lacks systematic control over perturbation types and multi-step complexity, limiting comprehensive robustness analysis. To address these gaps, we propose AutoEvoEval, an evolution-based evaluation framework for close-ended tasks such as multi-choice question answering. AutoEvoEval introduces 22 interpretable atomic evolution operations and supports multi-round compositions, enabling controlled generation of diverse, challenging, and realistic test samples. We conduct extensive experiments addressing four research questions on a broad set of open- and closed-source LLMs. Our results show that atomic operations cause an average accuracy drop of 7.283\\%, with structure-disrupting or misleading semantic edits causing the largest declines. Model sensitivities vary significantly for the same perturbation, and combining multiple evolution steps amplifies adversarial effects by up to 52.932\\%. These findings suggest current benchmarks may overestimate true model generalization and emphasize the need for evolution-aware robustness evaluation. Code and resources are available at: https://github.com/SYSUSELab/AutoEvoEval.",
      "authors": [
        "JiaRu Wu",
        "Mingwei Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T11:18:56+00:00",
          "link": "https://arxiv.org/abs/2506.23735v1",
          "size": "668kb",
          "version": "v1"
        }
      ],
      "title": "AutoEvoEval: An Automated Framework for Evolving Close-Ended LLM Evaluation Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23735",
        "HTML": "https://arxiv.org/html/2506.23735v1",
        "PDF": "https://arxiv.org/pdf/2506.23735"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23738",
      "abstract": "The Gene-pool Optimal Mixing EA (GOMEA) family of EAs offers a specific means to exploit problem-specific knowledge through linkage learning, i.e., inter-variable dependency detection, expressed using subsets of variables, that should undergo joint variation. Such knowledge can be exploited if faster fitness evaluations are possible when only a few variables are changed in a solution, enabling large speed-ups. The recent-most version of Real-Valued GOMEA (RV-GOMEA) can learn a conditional linkage model during optimization using fitness-based linkage learning, enabling fine-grained dependency exploitation in learning and sampling a Gaussian distribution. However, while the most efficient Gaussian-based EAs, like NES and CMA-ES, employ incremental learning of the Gaussian distribution rather than performing full re-estimation every generation, the recent-most RV-GOMEA version does not employ such incremental learning. In this paper, we therefore study whether incremental distribution estimation can lead to efficiency enhancements of RV-GOMEA. We consider various benchmark problems with varying degrees of overlapping dependencies. We find that, compared to RV-GOMEA and VKD-CMA-ES, the required number of evaluations to reach high-quality solutions can be reduced by a factor of up to 1.5 if population sizes are tuned problem-specifically, while a reduction by a factor of 2-3 can be achieved with generic population-sizing guidelines.",
      "authors": [
        "Renzo J. Scholman",
        "Tanja Alderliesten",
        "Peter A.N. Bosman"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T11:26:50+00:00",
          "link": "https://arxiv.org/abs/2506.23738v1",
          "size": "7294kb",
          "version": "v1"
        }
      ],
      "title": "More Efficient Real-Valued Gray-Box Optimization through Incremental Distribution Estimation in RV-GOMEA",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23738",
        "HTML": "https://arxiv.org/html/2506.23738v1",
        "PDF": "https://arxiv.org/pdf/2506.23738"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23739",
      "abstract": "Ensuring safe and realistic interactions between automated driving systems and vulnerable road users (VRUs) in urban environments requires advanced testing methodologies. This paper presents a test environment that combines a Vehiclein-the-Loop (ViL) test bench with a motion laboratory, demonstrating the feasibility of cyber-physical (CP) testing of vehicle-pedestrian and vehicle-cyclist interactions. Building upon previous work focused on pedestrian localization, we further validate a human pose estimation (HPE) approach through a comparative analysis of real-world (RW) and virtual representations of VRUs. The study examines the perception of full-body motion using a commercial monocular camera-based 3Dskeletal detection AI. The virtual scene is generated in Unreal Engine 5, where VRUs are animated in real time and projected onto a screen to stimulate the camera. The proposed stimulation technique ensures the correct perspective, enabling realistic vehicle perception. To assess the accuracy and consistency of HPE across RW and CP domains, we analyze the reliability of detections as well as variations in movement trajectories and joint estimation stability. The validation includes dynamic test scenarios where human avatars, both walking and cycling, are monitored under controlled conditions. Our results show a strong alignment in HPE between RW and CP test conditions for stable motion patterns, while notable inaccuracies persist under dynamic movements and occlusions, particularly for complex cyclist postures. These findings contribute to refining CP testing approaches for evaluating next-generation AI-based vehicle perception and to enhancing interaction models of automated vehicles and VRUs in CP environments.",
      "authors": [
        "Lisa Marie Otto",
        "Michael Kaiser",
        "Daniel Seebacher",
        "Steffen M\\\"uller"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T11:27:22+00:00",
          "link": "https://arxiv.org/abs/2506.23739v1",
          "size": "829kb",
          "version": "v1"
        }
      ],
      "title": "Validation of AI-Based 3D Human Pose Estimation in a Cyber-Physical Environment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23739",
        "PDF": "https://arxiv.org/pdf/2506.23739"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23740",
      "abstract": "Mobile networks are embracing disaggregation, reflected by the industry trend towards Open RAN. Private 5G networks are viewed as particularly suitable contenders as early adopters of Open RAN, owing to their setting, high degree of control, and opportunity for innovation they present. Motivated by this, we have recently deployed Campus5G, the first of its kind campus-wide, O-RAN-compliant private 5G testbed across the central campus of the University of Edinburgh. We present in detail our process developing the testbed, from planning, to architecting, to deployment, and measuring the testbed performance. We then discuss the lessons learned from building the testbed, and highlight some research opportunities that emerged from our deployment experience.",
      "authors": [
        "Andrew E. Ferguson",
        "Ujjwal Pawar",
        "Tianxin Wang",
        "Mahesh K. Marina"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T11:27:57+00:00",
          "link": "https://arxiv.org/abs/2506.23740v1",
          "size": "2817kb",
          "version": "v1"
        }
      ],
      "title": "Campus5G: A Campus Scale Private 5G Open RAN Testbed",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23740",
        "HTML": "https://arxiv.org/html/2506.23740v1",
        "PDF": "https://arxiv.org/pdf/2506.23740"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23741",
      "abstract": "Finite element methods usually construct basis functions and quadrature rules for multidimensional domains via tensor products of one-dimensional counterparts. While straightforward, this approach results in integration spaces larger than necessary, especially as the polynomial degree $p$ or the spatial dimension increases, leading to considerable computational overhead. This work starts from the hypothesis that reducing the dimensionality of the polynomial space can lead to quadrature rules with fewer points and lower computational cost, while preserving the exactness of numerical integration. We use trunk spaces that exclude high-degree monomials that do not improve the approximation quality of the discrete space. These reduced spaces retain sufficient expressive power and allow us to construct smaller (more economical) integration domains. Given a maximum degree $p$, we define trial and test spaces $U$ and $V$ as 2D or 3D trunk spaces and form the integration space $\\mathcal{S} = U \\otimes V$. We then construct exact quadrature rules by solving a non-convex optimisation problem over the number of points $q$, their coordinates, and weights. We use a shallow neural network with linear activations to parametrise the rule, and a random restart strategy to mitigate convergence to poor local minima. When necessary, we dynamically increase $q$ to achieve exact integration. Our construction reaches machine-precision accuracy (errors below 1e-22) using significantly fewer points than standard tensor-product Gaussian quadrature: up to 30\\% reduction in 2D for $p \\leq 10$, and 50\\% in 3D for $p \\leq 6$. These results show that combining the mathematical understanding of polynomial structure with numerical optimisation can lead to a practical and extensible methodology for improving the adaptiveness, efficiency, and scalability of quadrature rules for high-order finite element simulations.",
      "authors": [
        "Tomas Teijeiro",
        "Pouria Behnoudfar",
        "Jamie M. Taylor",
        "David Pardo",
        "Victor M. Calo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T11:28:55+00:00",
          "link": "https://arxiv.org/abs/2506.23741v1",
          "size": "778kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Numerical Integration for Finite Element Trunk Spaces in 2D and 3D using Machine Learning: A new Optimisation Paradigm to Construct Application-Specific Quadrature Rules",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23741",
        "HTML": "https://arxiv.org/html/2506.23741v1",
        "PDF": "https://arxiv.org/pdf/2506.23741"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23743",
      "abstract": "Positional bias in binary question answering occurs when a model systematically favors one choice over another based solely on the ordering of presented options. In this study, we quantify and analyze positional bias across five large language models under varying degrees of answer uncertainty. We re-adapted the SQuAD-it dataset by adding an extra incorrect answer option and then created multiple versions with progressively less context and more out-of-context answers, yielding datasets that range from low to high uncertainty. Additionally, we evaluate two naturally higher-uncertainty benchmarks: (1) WebGPT - question pairs with unequal human-assigned quality scores, and (2) Winning Arguments - where models predict the more persuasive argument in Reddit's r/ChangeMyView exchanges. Across each dataset, the order of the \"correct\" (or higher-quality/persuasive) option is systematically flipped (first placed in position 1, then in position 2) to compute both Preference Fairness and Position Consistency. We observe that positional bias is nearly absent under low-uncertainty conditions, but grows exponentially when it becomes doubtful to decide which option is correct.",
      "authors": [
        "Tiziano Labruna",
        "Simone Gallo",
        "Giovanni Da San Martino"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T11:30:23+00:00",
          "link": "https://arxiv.org/abs/2506.23743v1",
          "size": "818kb",
          "version": "v1"
        }
      ],
      "title": "Positional Bias in Binary Question Answering: How Uncertainty Shapes Model Preferences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23743",
        "HTML": "https://arxiv.org/html/2506.23743v1",
        "PDF": "https://arxiv.org/pdf/2506.23743"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23744",
      "abstract": "Sample-based observability characterizes the ability to reconstruct the internal state of a dynamical system by using limited output information, i.e., when measurements are only infrequently and/or irregularly available. In this work, we investigate the concept of functional observability, which refers to the ability to infer a function of the system state from the outputs, within a samplebased framework. Here, we give necessary and sufficient conditions for a system to be sample-based functionally observable, and formulate conditions on the sampling schemes such that these are satisfied. Furthermore, we provide a numerical example, where we demonstrate the applicability of the obtained results.",
      "authors": [
        "Isabelle Krauss",
        "Victor G. Lopez",
        "Matthias A. M\\\"uller"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T11:35:24+00:00",
          "link": "https://arxiv.org/abs/2506.23744v1",
          "size": "77kb",
          "version": "v1"
        }
      ],
      "title": "On sample-based functional observability of linear systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23744",
        "HTML": "https://arxiv.org/html/2506.23744v1",
        "PDF": "https://arxiv.org/pdf/2506.23744"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23748",
      "abstract": "We consider the harmonic map heat flow problem for a radially symmetric case. For discretization of this problem we apply a $H^1$-conforming finite element method in space combined with a semi-implicit Euler time stepping. The semi-implicit Euler method results in a linear problem in each time step. We restrict to the regime of smooth solutions of the continuous problem and present an error analysis of this discretization method. This results in optimal order discretization error bounds. Key ingredients of the analysis are a discrete energy estimate, that mimics the energy dissipation of the continuous solution, and a convexity property that is essential for discrete stability and for control of the linearization error. We also present numerical results that validate the theoretical ones.",
      "authors": [
        "Nam Anh Nguyen",
        "Arnold Reusken"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T11:42:03+00:00",
          "link": "https://arxiv.org/abs/2506.23748v1",
          "size": "194kb",
          "version": "v1"
        }
      ],
      "title": "Error analysis for a Finite Element Discretization of a radially symmetric harmonic map heat flow problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23748",
        "HTML": "https://arxiv.org/html/2506.23748v1",
        "PDF": "https://arxiv.org/pdf/2506.23748"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23749",
      "abstract": "Large language models (LLMs) are reshaping automated program repair (APR). We categorize the recent 63 LLM-based APR systems published from January 2022 to June 2025 into four paradigms, and show how retrieval- or analysis-augmented contexts strengthen any of them. This taxonomy clarifies key trade-offs: fine-tuning delivers strong task alignment at high training cost; prompting enables rapid deployment but is limited by prompt design and context windows; procedural pipelines offer reproducible control with moderate overhead; agentic frameworks tackle multi-hunk or cross-file bugs at the price of increased latency and complexity. Persistent challenges include verifying semantic correctness beyond test suites, repairing repository-scale defects, and lowering the costs of LLMs. We outline research directions that combine lightweight human feedback, repository-aware retrieval, code analysis, and cost-aware planning to advance reliable and efficient LLM-based APR.",
      "authors": [
        "Boyang Yang",
        "Zijian Cai",
        "Fengling Liu",
        "Bach Le",
        "Lingming Zhang",
        "Tegawend\\'e F. Bissyand\\'e",
        "Yang Liu",
        "and Haoye Tian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T11:46:01+00:00",
          "link": "https://arxiv.org/abs/2506.23749v1",
          "size": "490kb",
          "version": "v1"
        }
      ],
      "title": "A Survey of LLM-based Automated Program Repair: Taxonomies, Design Paradigms, and Applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23749",
        "HTML": "https://arxiv.org/html/2506.23749v1",
        "PDF": "https://arxiv.org/pdf/2506.23749"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23751",
      "abstract": "Open-vocabulary object detectors such as Grounding DINO are trained on vast and diverse data, achieving remarkable performance on challenging datasets. Due to that, it is unclear where to find their limitations, which is of major concern when using in safety-critical applications. Real-world data does not provide sufficient control, required for a rigorous evaluation of model generalization. In contrast, synthetically generated data allows to systematically explore the boundaries of model competence/generalization. In this work, we address two research questions: 1) Can we challenge open-vocabulary object detectors with generated image content? 2) Can we find systematic failure modes of those models? To address these questions, we design two automated pipelines using stable diffusion to inpaint unusual objects with high diversity in semantics, by sampling multiple substantives from WordNet and ChatGPT. On the synthetically generated data, we evaluate and compare multiple open-vocabulary object detectors as well as a classical object detector. The synthetic data is derived from two real-world datasets, namely LostAndFound, a challenging out-of-distribution (OOD) detection benchmark, and the NuImages dataset. Our results indicate that inpainting can challenge open-vocabulary object detectors in terms of overlooking objects. Additionally, we find a strong dependence of open-vocabulary models on object location, rather than on object semantics. This provides a systematic approach to challenge open-vocabulary models and gives valuable insights on how data could be acquired to effectively improve these models.",
      "authors": [
        "Annika M\\\"utze",
        "Sadia Ilyas",
        "Christian D\\\"orpelkus",
        "Matthias Rottmann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T11:48:44+00:00",
          "link": "https://arxiv.org/abs/2506.23751v1",
          "size": "28732kb",
          "version": "v1"
        }
      ],
      "title": "Can We Challenge Open-Vocabulary Object Detectors with Generated Content in Street Scenes?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23751",
        "HTML": "https://arxiv.org/html/2506.23751v1",
        "PDF": "https://arxiv.org/pdf/2506.23751"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23755",
      "abstract": "One primary focus of next generation wireless communication networks is the millimeterwave (mmWave) spectrum, typically considered in the 30 GHz to 300 GHz frequency range. Despite their promise of high data rates, mmWaves suffer from severe attenuation while passing through obstacles. Unmanned aerial vehicles (UAVs) have been proposed to offset this limitation on account of their additional degrees of freedom, which can be leveraged to provide line of sight (LoS) transmission paths. While some prior works have proposed analytical frameworks to compute the LoS probability for static ground users and a UAV, the same is lacking for mobile users on the ground. In this paper, we consider the popular Manhattan point line process (MPLP) to model an urban environment, within which a ground user moves with a known velocity for a small time interval along the roads. We derive an expression for the expected duration of LoS between a static UAV in the air and a mobile ground user, and validate the same through simulations. To demonstrate the efficacy of the proposed analysis, we propose a simple user association algorithm that greedily assigns the UAVs to users with the highest expected LoS time, and show that it outperforms the existing benchmark schemes that assign the users to the nearest UAVs with LoS without considering the user mobility.",
      "authors": [
        "Shawon Mitra",
        "Subhojit Sarkar",
        "Sasthi C. Ghosh"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T11:51:38+00:00",
          "link": "https://arxiv.org/abs/2506.23755v1",
          "size": "469kb",
          "version": "v1"
        }
      ],
      "title": "How Long Can I Transmit? A Mobility Aware mmWave-based UAV Communication Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23755",
        "HTML": "https://arxiv.org/html/2506.23755v1",
        "PDF": "https://arxiv.org/pdf/2506.23755"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23757",
      "abstract": "In this paper, we propose a unifying message-passing framework for training spiking neural networks (SNNs) using Expectation-Propagation. Our gradient-free method is capable of learning the marginal distributions of network parameters and simultaneously marginalizes nuisance parameters, such as the outputs of hidden layers. This framework allows for the first time, training of discrete and continuous weights, for deterministic and stochastic spiking networks, using batches of training samples. Although its convergence is not ensured, the algorithm converges in practice faster than gradient-based methods, without requiring a large number of passes through the training data. The classification and regression results presented pave the way for new efficient training methods for deep Bayesian networks.",
      "authors": [
        "Dan Yao and Steve McLaughlin and Yoann Altmann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T11:59:56+00:00",
          "link": "https://arxiv.org/abs/2506.23757v1",
          "size": "1305kb",
          "version": "v1"
        }
      ],
      "title": "Training of Spiking Neural Networks with Expectation-Propagation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23757",
        "HTML": "https://arxiv.org/html/2506.23757v1",
        "PDF": "https://arxiv.org/pdf/2506.23757"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23762",
      "abstract": "The rapid advancement of large language models (LLMs) has redefined artificial intelligence (AI), pushing the boundaries of AI research and enabling unbounded possibilities for both academia and the industry. However, LLM development faces increasingly complex challenges throughout its lifecycle, yet no existing research systematically explores these challenges and solutions from the perspective of software engineering (SE) approaches. To fill the gap, we systematically analyze research status throughout the LLM development lifecycle, divided into six phases: requirements engineering, dataset construction, model development and enhancement, testing and evaluation, deployment and operations, and maintenance and evolution. We then conclude by identifying the key challenges for each phase and presenting potential research directions to address these challenges. In general, we provide valuable insights from an SE perspective to facilitate future advances in LLM development.",
      "authors": [
        "Hongzhou Rao",
        "Yanjie Zhao",
        "Xinyi Hou",
        "Shenao Wang",
        "Haoyu Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:09:29+00:00",
          "link": "https://arxiv.org/abs/2506.23762v1",
          "size": "1695kb",
          "version": "v1"
        }
      ],
      "title": "Software Engineering for Large Language Models: Research Status, Challenges and the Road Ahead",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23762",
        "HTML": "https://arxiv.org/html/2506.23762v1",
        "PDF": "https://arxiv.org/pdf/2506.23762"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23768",
      "abstract": "We introduce a novel musculoskeletal model of a dog, procedurally generated from accurate 3D muscle meshes. Accompanying this model is a motion capture-based locomotion task compatible with a variety of control algorithms, as well as an improved muscle dynamics model designed to enhance convergence in differentiable control frameworks. We validate our approach by comparing simulated muscle activation patterns with experimentally obtained electromyography (EMG) data from previous canine locomotion studies. This work aims to bridge gaps between biomechanics, robotics, and computational neuroscience, offering a robust platform for researchers investigating muscle actuation and neuromuscular control.We plan to release the full model along with the retargeted motion capture clips to facilitate further research and development.",
      "authors": [
        "Vittorio La Barbera",
        "Steven Bohez",
        "Leonard Hasenclever",
        "Yuval Tassa and John R. Hutchinson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:13:37+00:00",
          "link": "https://arxiv.org/abs/2506.23768v1",
          "size": "13157kb",
          "version": "v1"
        }
      ],
      "title": "Motion Tracking with Muscles: Predictive Control of a Parametric Musculoskeletal Canine Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23768",
        "HTML": "https://arxiv.org/html/2506.23768v1",
        "PDF": "https://arxiv.org/pdf/2506.23768"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23769",
      "abstract": "This paper addresses the problem of estimating multiplicative fault signals in linear time-invariant systems by processing its input and output variables, as well as designing an input signal to maximize the accuracy of such estimates. The proposed real-time fault estimator is based on a residual generator used for fault detection and a multiple-output regressor generator, which feed a moving-horizon linear regression that estimates the parameter changes. Asymptotic performance guarantees are provided in the presence of noise. Motivated by the performance bounds, an optimal input design problem is formulated, for which we provide efficient algorithms and optimality bounds. Numerical examples demonstrate the efficacy of our approach and the importance of the optimal input design for accurate fault estimation.",
      "authors": [
        "Gabriel de Albuquerque Gleizer",
        "Peyman Mohajerin Esfahani",
        "Tamas Keviczky"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:15:01+00:00",
          "link": "https://arxiv.org/abs/2506.23769v1",
          "size": "1034kb",
          "version": "v1"
        }
      ],
      "title": "Active Estimation of Multiplicative Faults in Dynamical Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23769",
        "PDF": "https://arxiv.org/pdf/2506.23769"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23771",
      "abstract": "Reinforcement Learning (RL) is increasingly used in autonomous driving (AD) and shows clear advantages. However, most RL-based AD methods overlook policy structure design. An RL policy that only outputs short-timescale vehicle control commands results in fluctuating driving behavior due to fluctuations in network outputs, while one that only outputs long-timescale driving goals cannot achieve unified optimality of driving behavior and control. Therefore, we propose a multi-timescale hierarchical reinforcement learning approach. Our approach adopts a hierarchical policy structure, where high- and low-level RL policies are unified-trained to produce long-timescale motion guidance and short-timescale control commands, respectively. Therein, motion guidance is explicitly represented by hybrid actions to capture multimodal driving behaviors on structured road and support incremental low-level extend-state updates. Additionally, a hierarchical safety mechanism is designed to ensure multi-timescale safety. Evaluation in simulator-based and HighD dataset-based highway multi-lane scenarios demonstrates that our approach significantly improves AD performance, effectively increasing driving efficiency, action consistency and safety.",
      "authors": [
        "Guizhe Jin",
        "Zhuoren Li",
        "Bo Leng",
        "Ran Yu and Lu Xiong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:17:42+00:00",
          "link": "https://arxiv.org/abs/2506.23771v1",
          "size": "1500kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Timescale Hierarchical Reinforcement Learning for Unified Behavior and Control of Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23771",
        "HTML": "https://arxiv.org/html/2506.23771v1",
        "PDF": "https://arxiv.org/pdf/2506.23771"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23773",
      "abstract": "We introduce BayesL, a novel logical framework for specifying, querying, and verifying the behaviour of Bayesian networks (BNs). BayesL (pronounced \"Basil\") is a structured language that allows for the creation of queries over BNs. It facilitates versatile reasoning concerning causal and evidence-based relationships, and permits comprehensive what-if scenario evaluations without the need for manual modifications to the model.",
      "authors": [
        "Stefano M. Nicoletti and Mari\\\"elle Stoelinga"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:18:00+00:00",
          "link": "https://arxiv.org/abs/2506.23773v1",
          "size": "646kb",
          "version": "v1"
        }
      ],
      "title": "BayesL: Towards a Logical Framework for Bayesian Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23773",
        "PDF": "https://arxiv.org/pdf/2506.23773"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23774",
      "abstract": "Computer-aided teacher training is a state-of-the-art method designed to enhance teachers' professional skills effectively while minimising concerns related to costs, time constraints, and geographical limitations. We investigate the potential of large language models (LLMs) in teacher education, using a case of teaching hate incidents management in schools. To this end, we create a multi-agent LLM-based system that mimics realistic situations of hate, using a combination of retrieval-augmented prompting and persona modelling. It is designed to identify and analyse hate speech patterns, predict potential escalation, and propose effective intervention strategies. By integrating persona modelling with agentic LLMs, we create contextually diverse simulations of hate incidents, mimicking real-life situations. The system allows teachers to analyse and understand the dynamics of hate incidents in a safe and controlled environment, providing valuable insights and practical knowledge to manage such situations confidently in real life. Our pilot evaluation demonstrates teachers' enhanced understanding of the nature of annotator disagreements and the role of context in hate speech interpretation, leading to the development of more informed and effective strategies for addressing hate in classroom settings.",
      "authors": [
        "Ewelina Gajewska",
        "Michal Wawer",
        "Katarzyna Budzynska",
        "Jaros{\\l}aw A. Chudziak"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:18:13+00:00",
          "link": "https://arxiv.org/abs/2506.23774v1",
          "size": "483kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging a Multi-Agent LLM-Based System to Educate Teachers in Hate Incidents Management",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23774",
        "HTML": "https://arxiv.org/html/2506.23774v1",
        "PDF": "https://arxiv.org/pdf/2506.23774"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23776",
      "abstract": "Process discovery algorithms automatically extract process models from event logs, but high variability often results in complex and hard-to-understand models. To mitigate this issue, trace clustering techniques group process executions into clusters, each represented by a simpler and more understandable process model. Model-driven trace clustering improves on this by assigning traces to clusters based on their conformity to cluster-specific process models. However, most existing clustering techniques rely on either no process model discovery, or non-stochastic models, neglecting the frequency or probability of activities and transitions, thereby limiting their capability to capture real-world execution dynamics. We propose a novel model-driven trace clustering method that optimizes stochastic process models within each cluster. Our approach uses entropic relevance, a stochastic conformance metric based on directly-follows probabilities, to guide trace assignment. This allows clustering decisions to consider both structural alignment with a cluster's process model and the likelihood that a trace originates from a given stochastic process model. The method is computationally efficient, scales linearly with input size, and improves model interpretability by producing clusters with clearer control-flow patterns. Extensive experiments on public real-life datasets show that our method outperforms existing alternatives in representing process behavior and reveals how clustering performance rankings can shift when stochasticity is considered.",
      "authors": [
        "Jari Peeperkorn",
        "Johannes De Smedt",
        "Jochen De Weerdt"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:18:26+00:00",
          "link": "https://arxiv.org/abs/2506.23776v1",
          "size": "406kb",
          "version": "v1"
        }
      ],
      "title": "Model-driven Stochastic Trace Clustering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23776",
        "HTML": "https://arxiv.org/html/2506.23776v1",
        "PDF": "https://arxiv.org/pdf/2506.23776"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23777",
      "abstract": "The creation of virtual humans increasingly leverages automated synthesis of speech and gestures, enabling expressive, adaptable agents that effectively engage users. However, the independent development of voice and gesture generation technologies, alongside the growing popularity of virtual reality (VR), presents significant questions about the integration of these signals and their ability to convey emotional detail in immersive environments. In this paper, we evaluate the influence of real and synthetic gestures and speech, alongside varying levels of immersion (VR vs. 2D displays) and emotional contexts (positive, neutral, negative) on user perceptions. We investigate how immersion affects the perceived match between gestures and speech and the impact on key aspects of user experience, including emotional and empathetic responses and the sense of co-presence. Our findings indicate that while VR enhances the perception of natural gesture-voice pairings, it does not similarly improve synthetic ones - amplifying the perceptual gap between them. These results highlight the need to reassess gesture appropriateness and refine AI-driven synthesis for immersive environments. See video: https://youtu.be/WMfjIB1X-dc",
      "authors": [
        "Haoyang Du",
        "Kiran Chhatre",
        "Christopher Peters",
        "Brian Keegan",
        "Rachel McDonnell and Cathy Ennis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:18:52+00:00",
          "link": "https://arxiv.org/abs/2506.23777v1",
          "size": "28967kb",
          "version": "v1"
        }
      ],
      "title": "Synthetically Expressive: Evaluating gesture and voice for emotion and empathy in VR and 2D scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23777",
        "HTML": "https://arxiv.org/html/2506.23777v1",
        "PDF": "https://arxiv.org/pdf/2506.23777"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23781",
      "abstract": "Automated inspection with Unmanned Aerial Systems (UASs) is a transformative capability set to revolutionize various application domains. However, this task is inherently complex, as it demands the seamless integration of perception, planning, and control which existing approaches often treat separately. Moreover, it requires accurate long-horizon planning to predict action sequences, in contrast to many current techniques, which tend to be myopic. To overcome these limitations, we propose a 3D inspection approach that unifies perception, planning, and control within a single data-driven predictive control framework. Unlike traditional methods that rely on known UAS dynamic models, our approach requires only input-output data, making it easily applicable to off-the-shelf black-box UASs. Our method incorporates back-face elimination, a visibility determination technique from 3D computer graphics, directly into the control loop, thereby enabling the online generation of accurate, long-horizon 3D inspection trajectories.",
      "authors": [
        "Savvas Papaioannou",
        "Panayiotis Kolios",
        "Christos G. Panayiotou and Marios M. Polycarpou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:23:34+00:00",
          "link": "https://arxiv.org/abs/2506.23781v1",
          "size": "842kb",
          "version": "v1"
        }
      ],
      "title": "Data-Driven Predictive Planning and Control for Aerial 3D Inspection with Back-face Elimination",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23781",
        "HTML": "https://arxiv.org/html/2506.23781v1",
        "PDF": "https://arxiv.org/pdf/2506.23781"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23782",
      "abstract": "Graph Neural Networks (GNNs) have demonstrated strong predictive performance on relational data; however, their confidence estimates often misalign with actual predictive correctness, posing significant limitations for deployment in safety-critical settings. While existing graph-aware calibration methods seek to mitigate this limitation, they primarily depend on coarse one-hop statistics, such as neighbor-predicted confidence, or latent node embeddings, thereby neglecting the fine-grained structural heterogeneity inherent in graph topology. In this work, we propose Wavelet-Aware Temperature Scaling (WATS), a post-hoc calibration framework that assigns node-specific temperatures based on tunable heat-kernel graph wavelet features. Specifically, WATS harnesses the scalability and topology sensitivity of graph wavelets to refine confidence estimates, all without necessitating model retraining or access to neighboring logits or predictions. Extensive evaluations across seven benchmark datasets with varying graph structures and two GNN backbones demonstrate that WATS achieves the lowest Expected Calibration Error (ECE) among all compared methods, outperforming both classical and graph-specific baselines by up to 42.3\\% in ECE and reducing calibration variance by 17.24\\% on average compared with graph-specific methods. Moreover, WATS remains computationally efficient, scaling well across graphs of diverse sizes and densities. Code will be released based on publication.",
      "authors": [
        "Xiaoyang Li",
        "Linwei Tao",
        "Haohui Lu",
        "Minjing Dong",
        "Junbin Gao",
        "Chang Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:23:57+00:00",
          "link": "https://arxiv.org/abs/2506.23782v1",
          "size": "187kb",
          "version": "v1"
        }
      ],
      "title": "Calibrating Graph Neural Networks with Wavelet-Aware Temperature Scaling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23782",
        "HTML": "https://arxiv.org/html/2506.23782v1",
        "PDF": "https://arxiv.org/pdf/2506.23782"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23783",
      "abstract": "Combining traditional RGB cameras with bio-inspired event cameras for robust object tracking has garnered increasing attention in recent years. However, most existing multimodal tracking algorithms depend heavily on high-complexity Vision Transformer architectures for feature extraction and fusion across modalities. This not only leads to substantial computational overhead but also limits the effectiveness of cross-modal interactions. In this paper, we propose an efficient RGB-Event object tracking framework based on the linear-complexity Vision Mamba network, termed Mamba-FETrack V2. Specifically, we first design a lightweight Prompt Generator that utilizes embedded features from each modality, together with a shared prompt pool, to dynamically generate modality-specific learnable prompt vectors. These prompts, along with the modality-specific embedded features, are then fed into a Vision Mamba-based FEMamba backbone, which facilitates prompt-guided feature extraction, cross-modal interaction, and fusion in a unified manner. Finally, the fused representations are passed to the tracking head for accurate target localization. Extensive experimental evaluations on multiple RGB-Event tracking benchmarks, including short-term COESOT dataset and long-term datasets, i.e., FE108 and FELT V2, demonstrate the superior performance and efficiency of the proposed tracking framework. The source code and pre-trained models will be released on https://github.com/Event-AHU/Mamba_FETrack",
      "authors": [
        "Shiao Wang",
        "Ju Huang",
        "Qingchuan Ma",
        "Jinfeng Gao",
        "Chunyi Xu",
        "Xiao Wang",
        "Lan Chen",
        "Bo Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:24:01+00:00",
          "link": "https://arxiv.org/abs/2506.23783v1",
          "size": "9391kb",
          "version": "v1"
        }
      ],
      "title": "Mamba-FETrack V2: Revisiting State Space Model for Frame-Event based Visual Object Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23783",
        "HTML": "https://arxiv.org/html/2506.23783v1",
        "PDF": "https://arxiv.org/pdf/2506.23783"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23784",
      "abstract": "Nielsen transformation is a standard approach for solving word equations: by repeatedly splitting equations and applying simplification steps, equations are rewritten until a solution is reached. When solving a conjunction of word equations in this way, the performance of the solver will depend considerably on the order in which equations are processed. In this work, the use of Graph Neural Networks (GNNs) for ranking word equations before and during the solving process is explored. For this, a novel graph-based representation for word equations is presented, preserving global information across conjuncts, enabling the GNN to have a holistic view during ranking. To handle the variable number of conjuncts, three approaches to adapt a multi-classification task to the problem of ranking equations are proposed. The training of the GNN is done with the help of minimum unsatisfiable subsets (MUSes) of word equations. The experimental results show that, compared to state-of-the-art string solvers, the new framework solves more problems in benchmarks where each variable appears at most once in each equation.",
      "authors": [
        "Parosh Aziz Abdulla",
        "Mohamed Faouzi Atig",
        "Julie Cailler",
        "Chencheng Liang",
        "Philipp R\\\"ummer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:24:24+00:00",
          "link": "https://arxiv.org/abs/2506.23784v1",
          "size": "332kb",
          "version": "v1"
        }
      ],
      "title": "When GNNs Met a Word Equations Solver: Learning to Rank Equations (Extended Technical Report)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23784",
        "HTML": "https://arxiv.org/html/2506.23784v1",
        "PDF": "https://arxiv.org/pdf/2506.23784"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23785",
      "abstract": "We propose VisTex-OVLM, a novel image prompted object detection method that introduces visual textualization -- a process that projects a few visual exemplars into the text feature space to enhance Object-level Vision-Language Models' (OVLMs) capability in detecting rare categories that are difficult to describe textually and nearly absent from their pre-training data, while preserving their pre-trained object-text alignment. Specifically, VisTex-OVLM leverages multi-scale textualizing blocks and a multi-stage fusion strategy to integrate visual information from visual exemplars, generating textualized visual tokens that effectively guide OVLMs alongside text prompts. Unlike previous methods, our method maintains the original architecture of OVLM, maintaining its generalization capabilities while enhancing performance in few-shot settings. VisTex-OVLM demonstrates superior performance across open-set datasets which have minimal overlap with OVLM's pre-training data and achieves state-of-the-art results on few-shot benchmarks PASCAL VOC and MSCOCO. The code will be released at https://github.com/WitGotFlg/VisTex-OVLM.",
      "authors": [
        "Yongjian Wu",
        "Yang Zhou",
        "Jiya Saiyin",
        "Bingzheng Wei",
        "Yan Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:27:35+00:00",
          "link": "https://arxiv.org/abs/2506.23785v1",
          "size": "17461kb",
          "version": "v1"
        }
      ],
      "title": "Visual Textualization for Image Prompted Object Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23785",
        "HTML": "https://arxiv.org/html/2506.23785v1",
        "PDF": "https://arxiv.org/pdf/2506.23785"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23787",
      "abstract": "Intersymbol Interference (ISI) is a major bottleneck in Molecular Communication via Diffusion (MCvD), degrading system performance. This paper introduces two families of linear channel codes to mitigate ISI: Zero Pad Zero Start (ZPZS) and Zero Pad (ZP) codes, ensuring that each codeword avoids consecutive bit-1s. The ZPZS and ZP codes are then combined to form a binary ZP code, offering a higher code rate than linear ZP codes and allowing simple decoding via the Majority Location Rule (MLR). Additionally, a Leading One Zero Pad (LOZP) code is proposed, which relaxes zero-padding constraints by prioritizing the placement of bit-1s, achieving a higher rate than ZP. A closed-form expression is derived to compute expected ISI, showing it depends on the average bit-1 density in the codewords. ISI and Bit Error Rate (BER) performance are evaluated under two MCvD channel models: (i) without refresh, where past bits persist longer, and (ii) with refresh, where the channel is cleared after each reception. Results show that the LOZP code performs better in the refresh channel due to initial bit-1 placement, while ZP excels without refresh by reducing average bit-1 density. The asymptotic upper bound on code rate illustrates a trade-off between ISI and rate. Simulations demonstrate that ZP and LOZP codes improve BER by controlling bit-1 positions and density, providing better reliability in ISI-dominated regimes compared to conventional error-correcting codes.",
      "authors": [
        "Tamoghno Nath",
        "Krishna Gopal Benerjee and Adrish Banerjee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:29:19+00:00",
          "link": "https://arxiv.org/abs/2506.23787v1",
          "size": "630kb",
          "version": "v1"
        }
      ],
      "title": "ISI-Aware Code Design: A Linear Approach Towards Reliable Molecular Communication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23787",
        "HTML": "https://arxiv.org/html/2506.23787v1",
        "PDF": "https://arxiv.org/pdf/2506.23787"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23789",
      "abstract": "This paper introduces AFDL, a logic-based framework for reasoning about safety, security, and defense interactions in Attack-Fault-Defense Trees, which is a model that captures all safety, security, and defense domains in a single framework. We showcase both AFDL and propose a structured domain specific query language, LangAFDL, which enables domain experts to express complex analysis goals through intuitive templates. LangAFDL supports both Boolean and quantified queries as well as minimal cut set analysis, capturing the interplay between safety, security, and defensive measures. We illustrate the expressiveness and utility of the approach through representative queries over two different real-world case studies: Gridshield and Ground Segment as a Service. The formalization lays the automated safety-security groundwork for analyses in mission-critical systems and paves the way for future tool development and integration into design workflows.",
      "authors": [
        "Reza Soltani and Stefano M. Nicoletti and Milan Lopuha\\\"a-Zwakenberg and Mari\\\"elle Stoelinga"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:29:43+00:00",
          "link": "https://arxiv.org/abs/2506.23789v1",
          "size": "712kb",
          "version": "v1"
        }
      ],
      "title": "Querying Attack-Fault-Defense Trees: Property Specification in Smart Grid and Aerospace Case Studies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23789",
        "PDF": "https://arxiv.org/pdf/2506.23789"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23790",
      "abstract": "We consider the problem of finding a Hamiltonian path or a Hamiltonian cycle with precedence constraints in the form of a partial order on the vertex set. We show that the path problem is $\\mathsf{NP}$-complete for graphs of pathwidth 4 while the cycle problem is $\\mathsf{NP}$-complete on graphs of pathwidth 5. We complement these results by giving polynomial-time algorithms for graphs of pathwidth 3 and treewidth 2 for Hamiltonian paths as well as pathwidth 4 and treewidth 3 for Hamiltonian cycles. Furthermore, we study the complexity of the path and cycle problems on rectangular grid graphs of bounded height. For these, we show that the path and cycle problems are $\\mathsf{NP}$-complete when the height of the grid is greater or equal to 7 and 9, respectively. In the variant where we look for minimum edge-weighted Hamiltonian paths and cycles, the problems are $\\mathsf{NP}$-hard for heights 5 and 6, respectively.",
      "authors": [
        "Jesse Beisegel",
        "Katharina Klost",
        "Kristin Knorr",
        "Fabienne Ratajczak",
        "Robert Scheffler"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Computational Complexity (cs.CC)",
        "Data Structures and Algorithms (cs.DS)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:31:47+00:00",
          "link": "https://arxiv.org/abs/2506.23790v1",
          "size": "524kb",
          "version": "v1"
        }
      ],
      "title": "A Graph Width Perspective on Partially Ordered Hamiltonian Paths and Cycles I: Treewidth, Pathwidth, and Grid Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23790",
        "HTML": "https://arxiv.org/html/2506.23790v1",
        "PDF": "https://arxiv.org/pdf/2506.23790"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23793",
      "abstract": "Multi-agent pathfinding (MAPF) is a common abstraction of multi-robot trajectory planning problems, where multiple homogeneous robots simultaneously move in the shared environment. While solving MAPF optimally has been proven to be NP-hard, scalable, and efficient, solvers are vital for real-world applications like logistics, search-and-rescue, etc. To this end, decentralized suboptimal MAPF solvers that leverage machine learning have come on stage. Building on the success of the recently introduced MAPF-GPT, a pure imitation learning solver, we introduce MAPF-GPT-DDG. This novel approach effectively fine-tunes the pre-trained MAPF model using centralized expert data. Leveraging a novel delta-data generation mechanism, MAPF-GPT-DDG accelerates training while significantly improving performance at test time. Our experiments demonstrate that MAPF-GPT-DDG surpasses all existing learning-based MAPF solvers, including the original MAPF-GPT, regarding solution quality across many testing scenarios. Remarkably, it can work with MAPF instances involving up to 1 million agents in a single environment, setting a new milestone for scalability in MAPF domains.",
      "authors": [
        "Anton Andreychuk",
        "Konstantin Yakovlev",
        "Aleksandr Panov",
        "Alexey Skrynnik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:34:31+00:00",
          "link": "https://arxiv.org/abs/2506.23793v1",
          "size": "385kb",
          "version": "v1"
        }
      ],
      "title": "Advancing Learnable Multi-Agent Pathfinding Solvers with Active Fine-Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23793",
        "HTML": "https://arxiv.org/html/2506.23793v1",
        "PDF": "https://arxiv.org/pdf/2506.23793"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23799",
      "abstract": "Training data increasingly shapes not only model accuracy but also regulatory compliance and market valuation of AI assets. Yet existing valuation methods remain inadequate: model-based techniques depend on a single fitted model and inherit its biases, while algorithm-based approaches such as Data Shapley require costly retrainings at web scale. Recent Wasserstein-based model-agnostic methods rely on approximations that misrank examples relative to their true leave-one-out (LOO) utility. We introduce KAIROS, a scalable, model-agnostic valuation framework that assigns each example a distributional influence score: its contribution to the Maximum Mean Discrepancy (MMD) between the empirical training distribution and a clean reference set. Unlike Wasserstein surrogates, our MMD-based influence admits a closed-form solution that faithfully approximates the exact LOO ranking within $O(1/N^2)$ error, requires no retraining, and naturally extends to conditional kernels for unified label- and feature-error detection. Moreover, KAIROS supports efficient online updates: when a new batch of size m arrives, all scores can be updated in $O(mN)$ time, delivering up to 50x speedup without compromising ranking quality. Empirical evaluations on noise, mislabeling, and poisoning benchmarks show that KAIROS consistently outperforms state-of-the-art model-, Shapley-, and Wasserstein-based baselines in both accuracy and runtime. We provide rigorous theoretical guarantees, including symmetry for reproducible rankings and density-separation for interpretable thresholds.",
      "authors": [
        "Jiongli Zhu",
        "Parjanya Prajakta Prashant",
        "Alex Cloninger",
        "Babak Salimi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:44:28+00:00",
          "link": "https://arxiv.org/abs/2506.23799v1",
          "size": "317kb",
          "version": "v1"
        }
      ],
      "title": "KAIROS: Scalable Model-Agnostic Data Valuation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23799",
        "HTML": "https://arxiv.org/html/2506.23799v1",
        "PDF": "https://arxiv.org/pdf/2506.23799"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23800",
      "abstract": "Predictive coding networks trained with equilibrium propagation are neural models that perform inference through an iterative energy minimization process. Previous studies have demonstrated their effectiveness in shallow architectures, but show significant performance degradation when depth exceeds five to seven layers. In this work, we show that the reason behind this degradation is due to exponentially imbalanced errors between layers during weight updates, and predictions from the previous layer not being effective in guiding updates in deeper layers. We address the first issue by introducing two novel methods to optimize the latent variables that use precision-weighting to re-balance the distribution of energy among layers during the `relaxation phase', and the second issue by proposing a novel weight update mechanism that reduces error accumulation in deeper layers. Empirically, we test our methods on a large number of image classification tasks, resulting in large improvements in test accuracy across networks with more than seven layers, with performances comparable to those of backprop on similar models. These findings suggest that a better understanding of the relaxation phase is important to train models using equilibrium propagation at scale, and open new possibilities for their application in complex tasks.",
      "authors": [
        "Chang Qi",
        "Matteo Forasassi",
        "Thomas Lukasiewicz",
        "Tommaso Salvatori"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:44:47+00:00",
          "link": "https://arxiv.org/abs/2506.23800v1",
          "size": "620kb",
          "version": "v1"
        }
      ],
      "title": "Towards the Training of Deeper Predictive Coding Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23800",
        "HTML": "https://arxiv.org/html/2506.23800v1",
        "PDF": "https://arxiv.org/pdf/2506.23800"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23801",
      "abstract": "Super-resolution (SR) techniques can enhance the spatial resolution of remote sensing images by utilizing low-resolution (LR) images to reconstruct high-resolution (HR) images, enabling more efficient large-scale earth observation applications. While single-image super-resolution (SISR) methods have shown progress, reference-based super-resolution (RefSR) offers superior performance by incorporating historical HR images alongside current LR observations. However, existing RefSR methods struggle with real-world complexities, such as cross-sensor resolution gap and significant land cover changes, often leading to under-generation or over-reliance on reference image. To address these challenges, we propose CRefDiff, a novel controllable reference-based diffusion model for real-world remote sensing image SR. To address the under-generation problem, CRefDiff is built upon the pretrained Stable Diffusion model, leveraging its powerful generative prior to produce accurate structures and textures. To mitigate over-reliance on the reference, we introduce a dual-branch fusion mechanism that adaptively integrates both local and global information from the reference image. Moreover, this novel dual-branch design enables reference strength control during inference, enhancing interactivity and flexibility of the model. Finally, a strategy named Better Start is proposed to significantly reduce the number of denoising steps, thereby accelerating the inference process. To support further research, we introduce Real-RefRSSRD, a new real-world RefSR dataset for remote sensing images, consisting of HR NAIP and LR Sentinel-2 image pairs with diverse land cover changes and significant temporal gaps. Extensive experiments on Real-RefRSSRD show that CRefDiff achieves state-of-the-art performance across various metrics and improves downstream tasks such as scene classification and semantic segmentation.",
      "authors": [
        "Ce Wang and Wanjie Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:45:28+00:00",
          "link": "https://arxiv.org/abs/2506.23801v1",
          "size": "4895kb",
          "version": "v1"
        }
      ],
      "title": "Controllable Reference-Based Real-World Remote Sensing Image Super-Resolution with Generative Diffusion Priors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23801",
        "HTML": "https://arxiv.org/html/2506.23801v1",
        "PDF": "https://arxiv.org/pdf/2506.23801"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23802",
      "abstract": "In this work we introduce a novel adaptive anomaly detection framework specifically designed for monitoring sequential random finite set (RFS) observations. Our approach effectively distinguishes between In-Control data (normal) and Out-Of-Control data (anomalies) by detecting deviations from the expected statistical behavior of the process. The primary contributions of this study include the development of an innovative RFS-based framework that not only learns the normal behavior of the data-generating process online but also dynamically adapts to behavioral shifts to accurately identify abnormal point patterns. To achieve this, we introduce a new class of RFS-based posterior distributions, named Power Discounting Posteriors (PD), which facilitate adaptation to systematic changes in data while enabling anomaly detection of point pattern data through a novel predictive posterior density function. The effectiveness of the proposed approach is demonstrated by extensive qualitative and quantitative simulation experiments.",
      "authors": [
        "Konstantinos Bourazas",
        "Savvas Papaioannou and Panayiotis Kolios"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:45:44+00:00",
          "link": "https://arxiv.org/abs/2506.23802v1",
          "size": "131kb",
          "version": "v1"
        }
      ],
      "title": "Adaptive Out-of-Control Point Pattern Detection in Sequential Random Finite Set Observations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23802",
        "HTML": "https://arxiv.org/html/2506.23802v1",
        "PDF": "https://arxiv.org/pdf/2506.23802"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23803",
      "abstract": "In this paper, we revisit stochastic gradient descent (SGD) with AdaGrad-type preconditioning. Our contributions are twofold. First, we develop a unified convergence analysis of SGD with adaptive preconditioning under anisotropic or matrix smoothness and noise assumptions. This allows us to recover state-of-the-art convergence results for several popular adaptive gradient methods, including AdaGrad-Norm, AdaGrad, and ASGO/One-sided Shampoo. In addition, we establish the fundamental connection between two recently proposed algorithms, Scion and DASGO, and provide the first theoretical guarantees for the latter. Second, we show that the convergence of methods like AdaGrad and DASGO can be provably accelerated beyond the best-known rates using Nesterov momentum. Consequently, we obtain the first theoretical justification that AdaGrad-type algorithms can simultaneously benefit from both diagonal preconditioning and momentum, which may provide an ultimate explanation for the practical efficiency of Adam.",
      "authors": [
        "Dmitry Kovalev"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:47:10+00:00",
          "link": "https://arxiv.org/abs/2506.23803v1",
          "size": "30kb",
          "version": "v1"
        }
      ],
      "title": "SGD with Adaptive Preconditioning: Unified Analysis and Momentum Acceleration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23803",
        "PDF": "https://arxiv.org/pdf/2506.23803"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23808",
      "abstract": "A recent series of works has shown that initialization-free BA can be achieved using pseudo Object Space Error (pOSE) as a surrogate objective. The initial reconstruction-step optimizes an objective where all terms are projectively invariant and it cannot incorporate knowledge of the camera calibration. As a result, the solution is only determined up to a projective transformation of the scene and the process requires more data for successful reconstruction.\n  In contrast, we present a method that is able to use the known camera calibration thereby producing near metric solutions, that is, reconstructions that are accurate up to a similarity transformation. To achieve this we introduce pairwise relative rotation estimates that carry information about camera calibration. These are only invariant to similarity transformations, thus encouraging solutions that preserve metric features of the real scene. Our method can be seen as integrating rotation averaging into the pOSE framework striving towards initialization-free calibrated SfM.\n  Our experimental evaluation shows that we are able to reliably optimize our objective, achieving convergence to the global minimum with high probability from random starting solutions, resulting in accurate near metric reconstructions.",
      "authors": [
        "Carl Olsson",
        "Amanda Nilsson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:55:44+00:00",
          "link": "https://arxiv.org/abs/2506.23808v1",
          "size": "821kb",
          "version": "v1"
        }
      ],
      "title": "Towards Initialization-free Calibrated Bundle Adjustment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23808",
        "HTML": "https://arxiv.org/html/2506.23808v1",
        "PDF": "https://arxiv.org/pdf/2506.23808"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23809",
      "abstract": "Solving quantum many-body problems is one of the fundamental challenges in quantum chemistry. While neural network quantum states (NQS) have emerged as a promising computational tool, its training process incurs exponentially growing computational demands, becoming prohibitively expensive for large-scale molecular systems and creating fundamental scalability barriers for real-world applications. To address above challenges, we present \\ours, a high-performance NQS training framework for \\textit{ab initio} electronic structure calculations. First, we propose a scalable sampling parallelism strategy with multi-layers workload division and hybrid sampling scheme, which break the scalability barriers for large-scale NQS training. Then, we introduce multi-level parallelism local energy parallelism, enabling more efficient local energy computation. Last, we employ cache-centric optimization for transformer-based \\textit{ansatz} and incorporate it with sampling parallelism strategy, which further speedup up the NQS training and achieve stable memory footprint at scale. Experiments demonstrate that \\ours accelerate NQS training with up to 8.41x speedup and attains a parallel efficiency up to 95.8\\% when scaling to 1,536 nodes.",
      "authors": [
        "Hongtao Xu and Zibo Wu and Mingzhen Li and Weile Jia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:55:59+00:00",
          "link": "https://arxiv.org/abs/2506.23809v1",
          "size": "467kb",
          "version": "v1"
        }
      ],
      "title": "Large-scale Neural Network Quantum States for ab initio Quantum Chemistry Simulations on Fugaku",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23809",
        "HTML": "https://arxiv.org/html/2506.23809v1",
        "PDF": "https://arxiv.org/pdf/2506.23809"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23810",
      "abstract": "An innovative few-shot anomaly detection approach is presented, leveraging the pre-trained CLIP model for medical data, and adapting it for both image-level anomaly classification (AC) and pixel-level anomaly segmentation (AS). A dual-branch design is proposed to separately capture normal and abnormal features through learnable adapters in the CLIP vision encoder. To improve semantic alignment, learnable text prompts are employed to link visual features. Furthermore, SigLIP loss is applied to effectively handle the many-to-one relationship between images and unpaired text prompts, showcasing its adaptation in the medical field for the first time. Our approach is validated on multiple modalities, demonstrating superior performance over existing methods for AC and AS, in both same-dataset and cross-dataset evaluations. Unlike prior work, it does not rely on synthetic data or memory banks, and an ablation study confirms the contribution of each component. The code is available at https://github.com/mahshid1998/MadCLIP.",
      "authors": [
        "Mahshid Shiri and Cigdem Beyan and Vittorio Murino"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:56:17+00:00",
          "link": "https://arxiv.org/abs/2506.23810v1",
          "size": "225kb",
          "version": "v1"
        }
      ],
      "title": "MadCLIP: Few-shot Medical Anomaly Detection with CLIP",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23810",
        "HTML": "https://arxiv.org/html/2506.23810v1",
        "PDF": "https://arxiv.org/pdf/2506.23810"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23814",
      "abstract": "Several recent works focused on the best practices for applying machine learning to cybersecurity. In the context of malware, TESSERACT highlighted the impact of concept drift on detection performance and suggested temporal and spatial constraints to be enforced to ensure realistic time-aware evaluations, which have been adopted by the community. In this paper, we demonstrate striking discrepancies in the performance of learning-based malware detection across the same time frame when evaluated on two representative Android malware datasets used in top-tier security conferences, both adhering to established sampling and evaluation guidelines. This questions our ability to understand how current state-of-the-art approaches would perform in realistic scenarios. To address this, we identify five novel temporal and spatial bias factors that affect realistic evaluations. We thoroughly evaluate the impact of these factors in the Android malware domain on two representative datasets and five Android malware classifiers used or proposed in top-tier security conferences. For each factor, we provide practical and actionable recommendations that the community should integrate in their methodology for more realistic and reproducible settings.",
      "authors": [
        "Theo Chow",
        "Mario D'Onghia",
        "Lorenz Linhardt",
        "Zeliang Kan",
        "Daniel Arp",
        "Lorenzo Cavallaro",
        "and Fabio Pierazzi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:01:24+00:00",
          "link": "https://arxiv.org/abs/2506.23814v1",
          "size": "1740kb",
          "version": "v1"
        }
      ],
      "title": "Breaking Out from the TESSERACT: Reassessing ML-based Malware Detection under Spatio-Temporal Drift",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23814",
        "HTML": "https://arxiv.org/html/2506.23814v1",
        "PDF": "https://arxiv.org/pdf/2506.23814"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23815",
      "abstract": "The influence of Artificial Intelligence (AI), and specifically Large Language Models (LLM), on education is continuously increasing. These models are frequently used by students, giving rise to the question whether current forms of assessment are still a valid way to evaluate student performance and comprehension. The theoretical framework developed in this paper is grounded in Constructive Alignment (CA) theory and Bloom's taxonomy for defining learning objectives. We argue that AI influences learning objectives of different Bloom levels in a different way, and assessment has to be adopted accordingly. Furthermore, in line with Bloom's vision, formative and summative assessment should be aligned on whether the use of AI is permitted or not.\n  Although lecturers tend to agree that education and assessment need to be adapted to the presence of AI, a strong bias exists on the extent to which lecturers want to allow for AI in assessment. This bias is caused by a lecturer's familiarity with AI and specifically whether they use it themselves. To avoid this bias, we propose structured guidelines on a university or faculty level, to foster alignment among the staff. Besides that, we argue that teaching staff should be trained on the capabilities and limitations of AI tools. In this way, they are better able to adapt their assessment methods.",
      "authors": [
        "Patrick Stokkink"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:02:01+00:00",
          "link": "https://arxiv.org/abs/2506.23815v1",
          "size": "241kb",
          "version": "v1"
        }
      ],
      "title": "The Impact of AI on Educational Assessment: A Framework for Constructive Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23815",
        "PDF": "https://arxiv.org/pdf/2506.23815"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23817",
      "abstract": "Low Earth Orbit (LEO) satellite communication is a promising solution for global wireless coverage, especially in underserved and remote areas. However, the high relative velocity of LEO satellites induces significant Doppler shifts that disrupt subcarrier orthogonality and degrade multicarrier system performance. While the common time-varying Doppler shift can be compensated relative to a reference point, the residual differential Doppler across users within the coverage cell remains a significant challenge, causing severe intercarrier interference. This paper presents a generalized analytical framework for characterizing both the Doppler shift magnitude and the differential Doppler in LEO systems. Unlike prior works limited by flat-Earth assumptions or specific orbital configurations, our model incorporates Earth's curvature and supports arbitrary elevation angles. Using spherical geometry, we derive closed-form expressions for Doppler shift based on the central angle between the satellite and ground users. We further provide a statistical characterization of both the Doppler shift magnitude and the differential Doppler in terms of their cumulative distribution function (CDF) and probability density function (PDF) for uniformly distributed users within a spherical cap cell. Additionally, we derive a tight upper bound for the Doppler shift CDF and an exact expression for the maximum differential Doppler experienced across the coverage region. To mitigate intra-cell Doppler variation, we implement a user clustering technique that partitions the coverage area based on a Doppler disparity threshold into spherical sub-cells, ensuring compliance with 3GPP tolerances. Extensive simulations over realistic satellite constellations validate our analysis and reveal the impact of altitude, beamwidth, and satellite-user geometry on Doppler behavior.",
      "authors": [
        "Islam M. Tanash",
        "Risto Wichman",
        "and Nuria Gonzalez-Prelcic"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:05:22+00:00",
          "link": "https://arxiv.org/abs/2506.23817v1",
          "size": "6779kb",
          "version": "v1"
        }
      ],
      "title": "Statistical Modeling for Accurate Characterization of Doppler Effect in LEO-Terrestrial Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23817",
        "HTML": "https://arxiv.org/html/2506.23817v1",
        "PDF": "https://arxiv.org/pdf/2506.23817"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23822",
      "abstract": "Large-scale vision-language models (VLMs), such as CLIP, have achieved remarkable success in zero-shot learning (ZSL) by leveraging large-scale visual-text pair datasets. However, these methods often lack interpretability, as they compute the similarity between an entire query image and the embedded category words, making it difficult to explain their predictions. One approach to address this issue is to develop interpretable models by integrating language, where classifiers are built using discrete attributes, similar to human perception. This introduces a new challenge: how to effectively align local visual features with corresponding attributes based on pre-trained VLMs. To tackle this, we propose LaZSL, a locally-aligned vision-language model for interpretable ZSL. LaZSL employs local visual-semantic alignment via optimal transport to perform interaction between visual regions and their associated attributes, facilitating effective alignment and providing interpretable similarity without the need for additional training. Extensive experiments demonstrate that our method offers several advantages, including enhanced interpretability, improved accuracy, and strong domain generalization. Codes available at: https://github.com/shiming-chen/LaZSL.",
      "authors": [
        "Shiming Chen",
        "Bowen Duan",
        "Salman Khan",
        "Fahad Shahbaz Khan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:14:46+00:00",
          "link": "https://arxiv.org/abs/2506.23822v1",
          "size": "3439kb",
          "version": "v1"
        }
      ],
      "title": "Interpretable Zero-Shot Learning with Locally-Aligned Vision-Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23822",
        "HTML": "https://arxiv.org/html/2506.23822v1",
        "PDF": "https://arxiv.org/pdf/2506.23822"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23824",
      "abstract": "The development of semi-supervised learning (SSL) has in recent years largely focused on the development of new consistency regularization or entropy minimization approaches, often resulting in models with complex training strategies to obtain the desired results. In this work, we instead propose a novel approach that explicitly incorporates the underlying clustering assumption in SSL through extending a recently proposed differentiable clustering module. Leveraging annotated data to guide the cluster centroids results in a simple end-to-end trainable deep SSL approach. We demonstrate that the proposed model improves the performance over the supervised-only baseline and show that our framework can be used in conjunction with other SSL methods to further boost their performance.",
      "authors": [
        "Durgesh Singh and Ahcene Boubekki and Robert Jenssen and Michael C. Kampffmeyer"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:17:08+00:00",
          "link": "https://arxiv.org/abs/2506.23824v1",
          "size": "586kb",
          "version": "v1"
        }
      ],
      "title": "Supercm: Revisiting Clustering for Semi-Supervised Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23824",
        "HTML": "https://arxiv.org/html/2506.23824v1",
        "PDF": "https://arxiv.org/pdf/2506.23824"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23825",
      "abstract": "Benefiting from the advances in large language models and cross-modal alignment, existing multimodal large language models have achieved prominent performance in image and short video understanding. However, the understanding of long videos is still challenging, as their long-context nature results in significant computational and memory overhead. Most existing work treats long videos in the same way as short videos, which is inefficient for real-world applications and hard to generalize to even longer videos. To address these issues, we propose Flash-VStream, an efficient video language model capable of processing extremely long videos and responding to user queries in real time. Particularly, we design a Flash Memory module, containing a low-capacity context memory to aggregate long-context temporal information and model the distribution of information density, and a high-capacity augmentation memory to retrieve detailed spatial information based on this distribution. Compared to existing models, Flash-VStream achieves significant reductions in inference latency. Extensive experiments on long video benchmarks and comprehensive video benchmarks, i.e., EgoSchema, MLVU, LVBench, MVBench and Video-MME, demonstrate the state-of-the-art performance and outstanding efficiency of our method. Code is available at https://github.com/IVGSZ/Flash-VStream.",
      "authors": [
        "Haoji Zhang",
        "Yiqin Wang",
        "Yansong Tang",
        "Yong Liu",
        "Jiashi Feng",
        "Xiaojie Jin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:17:49+00:00",
          "link": "https://arxiv.org/abs/2506.23825v1",
          "size": "15074kb",
          "version": "v1"
        }
      ],
      "title": "Flash-VStream: Efficient Real-Time Understanding for Long Video Streams",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23825",
        "HTML": "https://arxiv.org/html/2506.23825v1",
        "PDF": "https://arxiv.org/pdf/2506.23825"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23826",
      "abstract": "Human Digital Twins (HDTs) have traditionally been conceptualized as data-driven models designed to support decision-making across various domains. However, recent advancements in conversational AI open new possibilities for HDTs to function as authentic, interactive digital counterparts of individuals. This paper introduces a novel HDT system architecture that integrates large language models with dynamically updated personal data, enabling it to mirror an individual's conversational style, memories, and behaviors. To achieve this, our approach implements context-aware memory retrieval, neural plasticity-inspired consolidation, and adaptive learning mechanisms, creating a more natural and evolving digital persona. The resulting system does not only replicate an individual's unique conversational style depending on who they are speaking with, but also enriches responses with dynamically captured personal experiences, opinions, and memories. While this marks a significant step toward developing authentic virtual counterparts, it also raises critical ethical concerns regarding privacy, accountability, and the long-term implications of persistent digital identities. This study contributes to the field of HDTs by describing our novel system architecture, demonstrating its capabilities, and discussing future directions and emerging challenges to ensure the responsible and ethical development of HDTs.",
      "authors": [
        "Llu\\'is C. Coll",
        "Martin W. Lauer-Schmaltz",
        "Philip Cash",
        "John P. Hansen",
        "Anja Maier"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Emerging Technologies (cs.ET)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:18:31+00:00",
          "link": "https://arxiv.org/abs/2506.23826v1",
          "size": "1963kb",
          "version": "v1"
        }
      ],
      "title": "Towards the \"Digital Me\": A vision of authentic Conversational Agents powered by personal Human Digital Twins",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23826",
        "HTML": "https://arxiv.org/html/2506.23826v1",
        "PDF": "https://arxiv.org/pdf/2506.23826"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23827",
      "abstract": "Spatial transcriptomics (ST) provides crucial insights into tissue micro-environments, but is limited to its high cost and complexity. As an alternative, predicting gene expression from pathology whole slide images (WSI) is gaining increasing attention. However, existing methods typically rely on single patches or a single pathology modality, neglecting the complex spatial and molecular interactions between target and neighboring information (e.g., gene co-expression). This leads to a failure in establishing connections among adjacent regions and capturing intricate cross-modal relationships. To address these issues, we propose NH2ST, a framework that integrates spatial context and both pathology and gene modalities for gene expression prediction. Our model comprises a query branch and a neighbor branch to process paired target patch and gene data and their neighboring regions, where cross-attention and contrastive learning are employed to capture intrinsic associations and ensure alignments between pathology and gene expression. Extensive experiments on six datasets demonstrate that our model consistently outperforms existing methods, achieving over 20% in PCC metrics. Codes are available at https://github.com/MCPathology/NH2ST",
      "authors": [
        "Mingcheng Qu",
        "Yuncong Wu",
        "Donglin Di",
        "Yue Gao",
        "Tonghua Su",
        "Yang Song",
        "Lei Fan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:18:39+00:00",
          "link": "https://arxiv.org/abs/2506.23827v1",
          "size": "468kb",
          "version": "v1"
        }
      ],
      "title": "Spatially Gene Expression Prediction using Dual-Scale Contrastive Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23827",
        "HTML": "https://arxiv.org/html/2506.23827v1",
        "PDF": "https://arxiv.org/pdf/2506.23827"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23832",
      "abstract": "The emergence of spontaneous symmetry breaking among a few heads of multi-head attention (MHA) across transformer blocks in classification tasks was recently demonstrated through the quantification of single-nodal performance (SNP). This finding indicates that each head focuses its attention on a subset of labels through cooperation among its SNPs. This underlying learning mechanism is generalized to large-scale MHA (LS-MHA) using a single matrix value representing single-head performance (SHP), analogous to single-filter performance in convolutional neural networks (CNNs). The results indicate that each SHP matrix comprises multiple unit clusters such that each label being explicitly recognized by a few heads with negligible noise. This leads to an increased signal-to-noise ratio (SNR) along the transformer blocks, thereby improving classification accuracy. These features give rise to several distinct vision transformer (ViT) architectures that achieve the same accuracy but differ in their LS-MHA structures. As a result, their soft committee yields superior accuracy, an outcome not typically observed in CNNs which rely on hundreds of filters. In addition, a significant reduction in latency is achieved without affecting the accuracy by replacing the initial transformer blocks with convolutional layers. This substitution accelerates early-stage learning, which is then improved by subsequent transformer layers. The extension of this learning mechanism to natural language processing tasks, based on quantitative differences between CNNs and ViT architectures, has the potential to yield new insights in deep learning. The findings are demonstrated using compact convolutional transformer architectures trained on the CIFAR-100 dataset.",
      "authors": [
        "Ronit D. Gross",
        "Tal Halevi",
        "Ella Koresh",
        "Yarden Tzach",
        "and Ido Kanter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:23:46+00:00",
          "link": "https://arxiv.org/abs/2506.23832v1",
          "size": "896kb",
          "version": "v1"
        }
      ],
      "title": "Low-latency vision transformers via large-scale multi-head attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23832",
        "PDF": "https://arxiv.org/pdf/2506.23832"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23833",
      "abstract": "This paper presents PointSSIM, a novel low-dimensional image-to-image comparison metric that is resolution invariant. Drawing inspiration from the structural similarity index measure and mathematical morphology, PointSSIM enables robust comparison across binary images of varying resolutions by transforming them into marked point pattern representations. The key features of the image, referred to as anchor points, are extracted from binary images by identifying locally adaptive maxima from the minimal distance transform. Image comparisons are then performed using a summary vector, capturing intensity, connectivity, complexity, and structural attributes. Results show that this approach provides an efficient and reliable method for image comparison, particularly suited to applications requiring structural analysis across different resolutions.",
      "authors": [
        "Oscar Ovanger",
        "Ragnar Hauge",
        "Jacob Skauvold",
        "Michael J. Pyrcz",
        "Jo Eidsvik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:24:43+00:00",
          "link": "https://arxiv.org/abs/2506.23833v1",
          "size": "1697kb",
          "version": "v1"
        }
      ],
      "title": "PointSSIM: A novel low dimensional resolution invariant image-to-image comparison metric",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23833",
        "PDF": "https://arxiv.org/pdf/2506.23833"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23835",
      "abstract": "Viewpoint missing of objects is common in scene reconstruction, as camera paths typically prioritize capturing the overall scene structure rather than individual objects. This makes it highly challenging to achieve high-fidelity object-level modeling while maintaining accurate scene-level representation. Addressing this issue is critical for advancing downstream tasks requiring detailed object understanding and appearance modeling. In this paper, we introduce Refine Any object In any ScenE (RAISE), a novel 3D enhancement framework that leverages 3D generative priors to recover fine-grained object geometry and appearance under missing views. Starting from substituting degraded objects with proxies, via a 3D generative model with strong 3D understanding, RAISE progressively refines geometry and texture by aligning each proxy to its degraded counterpart in 7-DOF pose, followed by correcting spatial and appearance inconsistencies via registration-constrained enhancement. This two-stage refinement ensures the high-fidelity geometry and appearance of the original object in unseen views while maintaining consistency in spatial positioning, observed geometry, and appearance. Extensive experiments on challenging benchmarks show that RAISE significantly outperforms state-of-the-art methods in both novel view synthesis and geometry completion tasks. RAISE is made publicly available at https://github.com/PolySummit/RAISE.",
      "authors": [
        "Ziwei Chen",
        "Ziling Liu",
        "Zitong Huang",
        "Mingqi Gao",
        "Feng Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:26:21+00:00",
          "link": "https://arxiv.org/abs/2506.23835v1",
          "size": "35525kb",
          "version": "v1"
        }
      ],
      "title": "Refine Any Object in Any Scene",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23835",
        "HTML": "https://arxiv.org/html/2506.23835v1",
        "PDF": "https://arxiv.org/pdf/2506.23835"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23840",
      "abstract": "Large Reasoning Models (LRMs) excel at solving complex problems but face an overthinking dilemma. When handling simple tasks, they often produce verbose responses overloaded with thinking tokens (e.g., wait, however). These tokens trigger unnecessary high-level reasoning behaviors like reflection and backtracking, reducing efficiency. In this work, our pilot study reveals that these thinking-token-induced behaviors are not essential for effective problem-solving and may even hinder correct reasoning within constrained token budgets. We identify this phenomenon as the thinking trap. To mitigate this issue, we propose Dual Policy Preference Optimization (DuP-PO), a novel algorithm featuring: (1) A rollout sampling strategy that guarantees balanced exposure to responses with and without thinking tokens; (2) A fine-grained advantage control technique to dynamically regulate the prediction of target tokens; (3) A policy shaping method ensuring stable gradient contributions from thinking tokens. Experimental results on five popular math reasoning benchmarks show that DuP-PO performs well on the popular LRM, which significantly improves their token efficiency during reasoning, while achieving superior performance of the base model.",
      "authors": [
        "Bowen Ding",
        "Yuhan Chen",
        "Futing Wang",
        "Lingfeng Ming",
        "Tao Lin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:30:33+00:00",
          "link": "https://arxiv.org/abs/2506.23840v1",
          "size": "305kb",
          "version": "v1"
        }
      ],
      "title": "Do Thinking Tokens Help or Trap? Towards More Efficient Large Reasoning Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23840",
        "HTML": "https://arxiv.org/html/2506.23840v1",
        "PDF": "https://arxiv.org/pdf/2506.23840"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23841",
      "abstract": "Attack Trees (AT) are a popular formalism for security analysis. They are meant to display an attacker's goal decomposed into attack steps needed to achieve it and compute certain security metrics (e.g., attack cost, probability, and damage). ATs offer three important services: (a) conceptual modeling capabilities for representing security risk management scenarios, (b) a qualitative assessment to find root causes and minimal conditions of successful attacks, and (c) quantitative analyses via security metrics computation under formal semantics, such as minimal time and cost among all attacks. Still, the AT language presents limitations due to its lack of ontological foundations, thus compromising associated services. Via an ontological analysis grounded in the Common Ontology of Value and Risk (COVER) -- a reference core ontology based on the Unified Foundational Ontology (UFO) -- we investigate the ontological adequacy of AT and reveal four significant shortcomings: (1) ambiguous syntactical terms that can be interpreted in various ways; (2) ontological deficit concerning crucial domain-specific concepts; (3) lacking modeling guidance to construct ATs decomposing a goal; (4) lack of semantic interoperability, resulting in ad hoc stand-alone tools. We also discuss existing incremental solutions and how our analysis paves the way for overcoming those issues through a broader approach to risk management modeling.",
      "authors": [
        "\\'Italo Oliveira and Stefano M. Nicoletti and Gal Engelberg and Mattia Fumagalli and Dan Klein and Giancarlo Guizzardi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:31:34+00:00",
          "link": "https://arxiv.org/abs/2506.23841v1",
          "size": "185kb",
          "version": "v1"
        }
      ],
      "title": "An ontological lens on attack trees: Toward adequacy and interoperability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23841",
        "HTML": "https://arxiv.org/html/2506.23841v1",
        "PDF": "https://arxiv.org/pdf/2506.23841"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23843",
      "abstract": "Understanding team formations and player positioning is crucial for tactical analysis in football (soccer). This paper presents a flexible method for formation recognition and player position assignment in football using predefined static formation templates and cost minimization from spatiotemporal tracking data, called EFPI. Our approach employs linear sum assignment to optimally match players to positions within a set of template formations by minimizing the total distance between actual player locations and template positions, subsequently selecting the formation with the lowest assignment cost. To improve accuracy, we scale actual player positions to match the dimensions of these formation templates in both width and length. While the method functions effectively on individual frames, it extends naturally to larger game segments such as complete periods, possession sequences or specific intervals (e.g. 10 second intervals, 5 minute intervals etc.). Additionally, we incorporate an optional stability parameter that prevents unnecessary formation changes when assignment costs differ only marginally between time segments. EFPI is available as open-source code through the unravelsports Python package.",
      "authors": [
        "Joris Bekkers"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:33:37+00:00",
          "link": "https://arxiv.org/abs/2506.23843v1",
          "size": "625kb",
          "version": "v1"
        }
      ],
      "title": "EFPI: Elastic Formation and Position Identification in Football (Soccer) using Template Matching and Linear Assignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23843",
        "HTML": "https://arxiv.org/html/2506.23843v1",
        "PDF": "https://arxiv.org/pdf/2506.23843"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23844",
      "abstract": "Recent advances in large language models (LLMs) have catalyzed the rise of autonomous AI agents capable of perceiving, reasoning, and acting in dynamic, open-ended environments. These large-model agents mark a paradigm shift from static inference systems to interactive, memory-augmented entities. While these capabilities significantly expand the functional scope of AI, they also introduce qualitatively novel security risks - such as memory poisoning, tool misuse, reward hacking, and emergent misalignment - that extend beyond the threat models of conventional systems or standalone LLMs. In this survey, we first examine the structural foundations and key capabilities that underpin increasing levels of agent autonomy, including long-term memory retention, modular tool use, recursive planning, and reflective reasoning. We then analyze the corresponding security vulnerabilities across the agent stack, identifying failure modes such as deferred decision hazards, irreversible tool chains, and deceptive behaviors arising from internal state drift or value misalignment. These risks are traced to architectural fragilities that emerge across perception, cognition, memory, and action modules. To address these challenges, we systematically review recent defense strategies deployed at different autonomy layers, including input sanitization, memory lifecycle control, constrained decision-making, structured tool invocation, and introspective reflection. We introduce the Reflective Risk-Aware Agent Architecture (R2A2), a unified cognitive framework grounded in Constrained Markov Decision Processes (CMDPs), which incorporates risk-aware world modeling, meta-policy adaptation, and joint reward-risk optimization to enable principled, proactive safety across the agent's decision-making loop.",
      "authors": [
        "Hang Su",
        "Jun Luo",
        "Chang Liu",
        "Xiao Yang",
        "Yichi Zhang",
        "Yinpeng Dong",
        "Jun Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:34:34+00:00",
          "link": "https://arxiv.org/abs/2506.23844v1",
          "size": "694kb",
          "version": "v1"
        }
      ],
      "title": "A Survey on Autonomy-Induced Security Risks in Large Model-Based Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23844",
        "HTML": "https://arxiv.org/html/2506.23844v1",
        "PDF": "https://arxiv.org/pdf/2506.23844"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23845",
      "abstract": "While sparse autoencoders (SAEs) have generated significant excitement, a series of negative results have added to skepticism about their usefulness. Here, we establish a conceptual distinction that reconciles competing narratives surrounding SAEs. We argue that while SAEs may be less effective for acting on known concepts, SAEs are powerful tools for discovering unknown concepts. This distinction cleanly separates existing negative and positive results, and suggests several classes of SAE applications. Specifically, we outline use cases for SAEs in (i) ML interpretability, explainability, fairness, auditing, and safety, and (ii) social and health sciences.",
      "authors": [
        "Kenny Peng",
        "Rajiv Movva",
        "Jon Kleinberg",
        "Emma Pierson",
        "Nikhil Garg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:35:56+00:00",
          "link": "https://arxiv.org/abs/2506.23845v1",
          "size": "107kb",
          "version": "v1"
        }
      ],
      "title": "Use Sparse Autoencoders to Discover Unknown Concepts, Not to Act on Known Concepts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23845",
        "HTML": "https://arxiv.org/html/2506.23845v1",
        "PDF": "https://arxiv.org/pdf/2506.23845"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23850",
      "abstract": "This paper introduces a novel architectural framework that integrates Large Language Models (LLMs) with email interfaces to automate administrative tasks, specifically targeting accessibility barriers in enterprise environments. The system connects email communication channels with Optical Character Recognition (OCR) and intelligent automation, enabling non-technical administrative staff to delegate complex form-filling and document processing tasks using familiar email interfaces. By treating the email body as a natural language prompt and attachments as contextual information, the workflow bridges the gap between advanced AI capabilities and practical usability. Empirical evaluation shows that the system can complete complex administrative forms in under 8 seconds of automated processing, with human supervision reducing total staff time by a factor of three to four compared to manual workflows. The top-performing LLM accurately filled 16 out of 29 form fields and reduced the total cost per processed form by 64% relative to manual completion. These findings demonstrate that email-based LLM integration is a viable and cost-effective approach for democratizing advanced automation in organizational settings, supporting widespread adoption without requiring specialized technical knowledge or major workflow changes. This aligns with broader trends in leveraging LLMs to enhance accessibility and automate complex tasks for non-technical users, making technology more inclusive and efficient.",
      "authors": [
        "Andres Navarro",
        "Carlos de Quinto",
        "Jos\\'e Alberto Hern\\'andez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:39:54+00:00",
          "link": "https://arxiv.org/abs/2506.23850v1",
          "size": "2520kb",
          "version": "v1"
        }
      ],
      "title": "Email as the Interface to Generative AI Models: Seamless Administrative Automation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23850",
        "HTML": "https://arxiv.org/html/2506.23850v1",
        "PDF": "https://arxiv.org/pdf/2506.23850"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23851",
      "abstract": "The integration of cloud computing in education can revolutionise learning in advanced (Australia & South Korea) and middle-income (Ghana & Nigeria) countries, while offering scalable, cost-effective and equitable access to adaptive learning systems. This paper explores how cloud computing and adaptive learning technologies are deployed across different socio-economic and infrastructure contexts. The study identifies enabling factors and systematic challenges, providing insights into how cloud-based education can be tailored to bridge the digital and educational divide globally.",
      "authors": [
        "Israel Fianyi",
        "Soonja Yeom",
        "Ju-Hyun Shin"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Emerging Technologies (cs.ET)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:43:28+00:00",
          "link": "https://arxiv.org/abs/2506.23851v1",
          "size": "392kb",
          "version": "v1"
        }
      ],
      "title": "Comparative Studies: Cloud-Enabled Adaptive Learning System for Scalable Education in Sub-Saharan",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23851",
        "PDF": "https://arxiv.org/pdf/2506.23851"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23852",
      "abstract": "As camera-equipped robotic platforms become increasingly integrated into daily life, robotic-generated videos have begun to appear on streaming media platforms, enabling us to envision a future where humans and robots coexist. We innovatively propose the concept of Robotic-Generated Content (RGC) to term these videos generated from egocentric perspective of robots. The perceptual quality of RGC videos is critical in human-robot interaction scenarios, and RGC videos exhibit unique distortions and visual requirements that differ markedly from those of professionally-generated content (PGC) videos and user-generated content (UGC) videos. However, dedicated research on quality assessment of RGC videos is still lacking. To address this gap and to support broader robotic applications, we establish the first Robotic-Generated Content Database (RGCD), which contains a total of 2,100 videos drawn from three robot categories and sourced from diverse platforms. A subjective VQA experiment is conducted subsequently to assess human visual perception of robotic-generated videos. Finally, we conduct a benchmark experiment to evaluate the performance of 11 state-of-the-art VQA models on our database. Experimental results reveal significant limitations in existing VQA models when applied to complex, robotic-generated content, highlighting a critical need for RGC-specific VQA models. Our RGCD is publicly available at: https://github.com/IntMeGroup/RGC-VQA.",
      "authors": [
        "Jianing Jin",
        "Jiangyong Ying",
        "Huiyu Duan",
        "Liu Yang",
        "Sijing Wu",
        "Yunhao Li",
        "Yushuo Zheng",
        "Xiongkuo Min",
        "Guangtao Zhai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:44:30+00:00",
          "link": "https://arxiv.org/abs/2506.23852v1",
          "size": "1075kb",
          "version": "v1"
        }
      ],
      "title": "RGC-VQA: An Exploration Database for Robotic-Generated Video Quality Assessment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23852",
        "HTML": "https://arxiv.org/html/2506.23852v1",
        "PDF": "https://arxiv.org/pdf/2506.23852"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23854",
      "abstract": "Neural surface reconstruction faces persistent challenges in reconciling geometric fidelity with photometric consistency under complex scene conditions. We present HiNeuS, a unified framework that holistically addresses three core limitations in existing approaches: multi-view radiance inconsistency, missing keypoints in textureless regions, and structural degradation from over-enforced Eikonal constraints during joint optimization. To resolve these issues through a unified pipeline, we introduce: 1) Differential visibility verification through SDF-guided ray tracing, resolving reflection ambiguities via continuous occlusion modeling; 2) Planar-conformal regularization via ray-aligned geometry patches that enforce local surface coherence while preserving sharp edges through adaptive appearance weighting; and 3) Physically-grounded Eikonal relaxation that dynamically modulates geometric constraints based on local radiance gradients, enabling detail preservation without sacrificing global regularity. Unlike prior methods that handle these aspects through sequential optimizations or isolated modules, our approach achieves cohesive integration where appearance-geometry constraints evolve synergistically throughout training. Comprehensive evaluations across synthetic and real-world datasets demonstrate state-of-the-art performance, including a 21.4% reduction in Chamfer distance over reflection-aware baselines and 2.32 dB PSNR improvement against neural rendering counterparts. Qualitative analyses reveal superior capability in recovering specular instruments, urban layouts with centimeter-scale infrastructure, and low-textured surfaces without local patch collapse. The method's generalizability is further validated through successful application to inverse rendering tasks, including material decomposition and view-consistent relighting.",
      "authors": [
        "Yida Wang",
        "Xueyang Zhang",
        "Kun Zhan",
        "Peng Jia",
        "Xianpeng Lang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:45:25+00:00",
          "link": "https://arxiv.org/abs/2506.23854v1",
          "size": "6084kb",
          "version": "v1"
        }
      ],
      "title": "HiNeuS: High-fidelity Neural Surface Mitigating Low-texture and Reflective Ambiguity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23854",
        "HTML": "https://arxiv.org/html/2506.23854v1",
        "PDF": "https://arxiv.org/pdf/2506.23854"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23855",
      "abstract": "The analysis of the privacy properties of Privacy-Preserving Ads APIs is an area of research that has received strong interest from academics, industry, and regulators. Despite this interest, the empirical study of these methods is hindered by the lack of publicly available data. Reliable empirical analysis of the privacy properties of an API, in fact, requires access to a dataset consisting of realistic API outputs; however, privacy concerns prevent the general release of such data to the public.\n  In this work, we develop a novel methodology to construct synthetic API outputs that are simultaneously realistic enough to enable accurate study and provide strong privacy protections. We focus on one Privacy-Preserving Ads APIs: the Topics API, part of Google Chrome's Privacy Sandbox. We developed a methodology to generate a differentially-private dataset that closely matches the re-identification risk properties of the real Topics API data. The use of differential privacy provides strong theoretical bounds on the leakage of private user information from this release.\n  Our methodology is based on first computing a large number of differentially-private statistics describing how output API traces evolve over time. Then, we design a parameterized distribution over sequences of API traces and optimize its parameters so that they closely match the statistics obtained. Finally, we create the synthetic data by drawing from this distribution.\n  Our work is complemented by an open-source release of the anonymized dataset obtained by this methodology. We hope this will enable external researchers to analyze the API in-depth and replicate prior and future work on a realistic large-scale dataset. We believe that this work will contribute to fostering transparency regarding the privacy properties of Privacy-Preserving Ads APIs.",
      "authors": [
        "Travis Dick",
        "Alessandro Epasto",
        "Adel Javanmard",
        "Josh Karlin",
        "Andres Munoz Medina",
        "Vahab Mirrokni",
        "Sergei Vassilvitskii",
        "Peilin Zhong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:46:57+00:00",
          "link": "https://arxiv.org/abs/2506.23855v1",
          "size": "300kb",
          "version": "v1"
        }
      ],
      "title": "Differentially Private Synthetic Data Release for Topics API Outputs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23855",
        "HTML": "https://arxiv.org/html/2506.23855v1",
        "PDF": "https://arxiv.org/pdf/2506.23855"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23856",
      "abstract": "Despite the great promise of Prompt Tuning (PT) in adapting large Vision-Language Pretrained Models (VLPMs) to downstream tasks, they often struggle to overcome the Base-New Tradeoff (BNT) dilemma: as VLPMs are better tuned to a base task, their ability to generalize to new tasks diminishes. Recent work on conditional PT addresses this problem by replacing static prompts with dynamic Visual Image Information (VII)-conditioned prompts, improving the model's generalization to new tasks to some extent. In this work, we first identify a critical issue with existing conditional PT methods: using VII as the \"condition\" of prompts yields suboptimal performance, and even random noise-conditioned prompts can outperform the VII-conditioned counterparts. On further analysis, we find that learning dynamic prompts conditioned on Textual Class Information (TCI) is the key to solving the BNT problem. Motivated by this, we then propose Class-adaptive Prompt Tuning (CaPT), which enables fast adaptation of tuned models to new classes by learning TCI-conditioned prompts from base classes. Remarkably, CaPT can be used as a plugin to mitigate the BNT problem for existing unconditional PT schemes. Extensive experiments on 11 datasets show that CaPT consistently improves the performance of five strong unconditional PT baselines with negligible additional computational cost. Additionally, by integrating CaPT with our recently proposed DePT framework, we devise a new conditional PT approach, termed DeCaPT, which outperforms the H ACC of the state-of-the-art conditional PT scheme by 3.49%, averaged over the 11 datasets. Code: https://github.com/Koorye/CaPT.",
      "authors": [
        "Ji Zhang",
        "Shihan Wu",
        "Lianli Gao",
        "Jingkuan Song",
        "Nicu Sebe",
        "Heng Tao Shen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:51:20+00:00",
          "link": "https://arxiv.org/abs/2506.23856v1",
          "size": "5708kb",
          "version": "v1"
        }
      ],
      "title": "A Closer Look at Conditional Prompt Tuning for Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23856",
        "HTML": "https://arxiv.org/html/2506.23856v1",
        "PDF": "https://arxiv.org/pdf/2506.23856"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23858",
      "abstract": "The quadratic complexity of full attention mechanisms poses a significant bottleneck for Video Diffusion Models (VDMs) aiming to generate long-duration, high-resolution videos. While various sparse attention methods have been proposed, many are designed as training-free inference accelerators or do not optimally capture the unique spatio-temporal characteristics inherent in video data when trained natively. This paper introduces Video Mixture of Block Attention (VMoBA), a novel sparse attention mechanism specifically adapted for VDMs. Motivated by an in-depth analysis of attention patterns within pre-trained video transformers, which revealed strong spatio-temporal locality, varying query importance, and head-specific concentration levels, VMoBA enhances the original MoBA framework with three key modifications: (1) a layer-wise recurrent block partition scheme (1D-2D-3D) to dynamically adapt to diverse spatio-temporal attention patterns and improve efficiency; (2) global block selection to prioritize the most salient query-key block interactions across an entire attention head; and (3) threshold-based block selection to dynamically determine the number of attended blocks based on their cumulative similarity. Extensive experiments demonstrate that VMoBA significantly accelerates the training of VDMs on longer sequences, achieving 2.92x FLOPs and 1.48x latency speedup, while attaining comparable or even superior generation quality to full attention. Furthermore, VMoBA exhibits competitive performance in training-free inference, offering 2.40x FLOPs and 1.35x latency speedup for high-res video generation.",
      "authors": [
        "Jianzong Wu",
        "Liang Hou",
        "Haotian Yang",
        "Xin Tao",
        "Ye Tian",
        "Pengfei Wan",
        "Di Zhang",
        "Yunhai Tong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:52:31+00:00",
          "link": "https://arxiv.org/abs/2506.23858v1",
          "size": "5691kb",
          "version": "v1"
        }
      ],
      "title": "VMoBA: Mixture-of-Block Attention for Video Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23858",
        "HTML": "https://arxiv.org/html/2506.23858v1",
        "PDF": "https://arxiv.org/pdf/2506.23858"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23863",
      "abstract": "Multi-view 3D reconstruction remains a core challenge in computer vision. Recent methods, such as DUST3R and its successors, directly regress pointmaps from image pairs without relying on known scene geometry or camera parameters. However, the performance of these models is constrained by the diversity and scale of available training data. In this work, we introduce Puzzles, a data augmentation strategy that synthesizes an unbounded volume of high-quality posed video-depth data from a single image or video clip. By simulating diverse camera trajectories and realistic scene geometry through targeted image transformations, Puzzles significantly enhances data variety. Extensive experiments show that integrating Puzzles into existing video-based 3D reconstruction pipelines consistently boosts performance without modifying the underlying network architecture. Notably, models trained on only ten percent of the original data augmented with Puzzles still achieve accuracy comparable to those trained on the full dataset. Code is available at https://jiahao-ma.github.io/puzzles/.",
      "authors": [
        "Jiahao Ma",
        "Lei Wang",
        "Miaomiao liu",
        "David Ahmedt-Aristizabal",
        "Chuong Nguyen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:57:24+00:00",
          "link": "https://arxiv.org/abs/2506.23863v1",
          "size": "11874kb",
          "version": "v1"
        }
      ],
      "title": "Puzzles: Unbounded Video-Depth Augmentation for Scalable End-to-End 3D Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23863",
        "HTML": "https://arxiv.org/html/2506.23863v1",
        "PDF": "https://arxiv.org/pdf/2506.23863"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23864",
      "abstract": "We conduct a systematic audit of three widely used reasoning benchmarks, SocialIQa, FauxPas-EAI, and ToMi, and uncover pervasive flaws in both benchmark items and evaluation methodology. Using five LLMs (GPT-{3, 3.5, 4, o1}, and LLaMA 3.1) as diagnostic tools, we identify structural, semantic, and pragmatic issues in benchmark design (e.g., duplicated items, ambiguous wording, and implausible answers), as well as scoring procedures that prioritize output form over reasoning process. Through systematic human annotation and re-evaluation on cleaned benchmark subsets, we find that model scores often improve not due to due to erratic surface wording variations and not to improved reasoning. Infact, further analyses show that model performance is highly sensitive to minor input variations such as context availability and phrasing, revealing that high scores may reflect alignment with format-specific cues rather than consistent inference based on the input. These findings challenge the validity of current benchmark-based claims about reasoning in LLMs, and highlight the need for evaluation protocols that assess reasoning as a process of drawing inference from available information, rather than as static output selection. We release audited data and evaluation tools to support more interpretable and diagnostic assessments of model reasoning.",
      "authors": [
        "Seyed Mahed Mousavi",
        "Edoardo Cecchinato",
        "Lucia Hornikova",
        "Giuseppe Riccardi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:57:28+00:00",
          "link": "https://arxiv.org/abs/2506.23864v1",
          "size": "598kb",
          "version": "v1"
        }
      ],
      "title": "Garbage In, Reasoning Out? Why Benchmark Scores are Unreliable and What to Do About It",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23864",
        "HTML": "https://arxiv.org/html/2506.23864v1",
        "PDF": "https://arxiv.org/pdf/2506.23864"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23866",
      "abstract": "In this paper, we explore the intersection of privacy, security, and environmental sustainability in cloud-based office solutions, focusing on quantifying user- and network-side energy use and associated carbon emissions. We hypothesise that privacy-focused services are typically more energy-efficient than those funded through data collection and advertising. To evaluate this, we propose a framework that systematically measures environmental costs based on energy usage and network data traffic during well-defined, automated usage scenarios. To test our hypothesis, we first analyse how underlying architectures and business models, such as monetisation through personalised advertising, contribute to the environmental footprint of these services. We then explore existing methodologies and tools for software environmental impact assessment. We apply our framework to three mainstream email services selected to reflect different privacy policies, from ad-supported tracking-intensive models to privacy-focused designs: Microsoft Outlook, Google Mail (Gmail), and Proton Mail. We extend this comparison to a self-hosted email solution, evaluated with and without end-to-end encryption. We show that the self-hosted solution, even with 14% of device energy and 15% of emissions overheads from PGP encryption, remains the most energy-efficient, saving up to 33% of emissions per session compared to Gmail. Among commercial providers, Proton Mail is the most efficient, saving up to 0.1 gCO2 e per session compared to Outlook, whose emissions can be further reduced by 2% through ad-blocking.",
      "authors": [
        "Jason Kayembe",
        "Iness Ben Guirat",
        "Jan Tobias M\\\"uhlberg"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computers and Society (cs.CY)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:58:22+00:00",
          "link": "https://arxiv.org/abs/2506.23866v1",
          "size": "1178kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Privacy and Security as Drivers for Environmental Sustainability in Cloud-Based Office Solutions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23866",
        "HTML": "https://arxiv.org/html/2506.23866v1",
        "PDF": "https://arxiv.org/pdf/2506.23866"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23869",
      "abstract": "We study the capabilities of generative autoregressive transformer models trained on large amounts of symbolic solo-piano transcriptions. After first pretraining on approximately 60,000 hours of music, we use a comparatively smaller, high-quality subset, to finetune models to produce musical continuations, perform symbolic classification tasks, and produce general-purpose contrastive MIDI embeddings by adapting the SimCLR framework to symbolic music. When evaluating piano continuation coherence, our generative model outperforms leading symbolic generation techniques and remains competitive with proprietary audio generation models. On MIR classification benchmarks, frozen representations from our contrastive model achieve state-of-the-art results in linear probe experiments, while direct finetuning demonstrates the generalizability of pretrained representations, often requiring only a few hundred labeled examples to specialize to downstream tasks.",
      "authors": [
        "Louis Bradshaw",
        "Honglu Fan",
        "Alexander Spangher",
        "Stella Biderman",
        "Simon Colton"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:00:14+00:00",
          "link": "https://arxiv.org/abs/2506.23869v1",
          "size": "121kb",
          "version": "v1"
        }
      ],
      "title": "Scaling Self-Supervised Representation Learning for Symbolic Piano Performance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23869",
        "HTML": "https://arxiv.org/html/2506.23869v1",
        "PDF": "https://arxiv.org/pdf/2506.23869"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23872",
      "abstract": "Living plants, while contributing to ecological balance and climate regulation, also function as natural sensors capable of transmitting information about their internal physiological states and surrounding conditions. This rich source of data provides potential for applications in environmental monitoring and precision agriculture. With integration into biohybrid systems, we establish novel channels of physiological signal flow between living plants and artificial devices. We equipped *Hedera helix* with a plant-wearable device called PhytoNode to continuously record the plant's electrophysiological activity. We deployed plants in an uncontrolled outdoor environment to map electrophysiological patterns to environmental conditions. Over five months, we collected data that we analyzed using state-of-the-art and automated machine learning (AutoML). Our classification models achieve high performance, reaching macro F1 scores of up to 95 percent in binary tasks. AutoML approaches outperformed manual tuning, and selecting subsets of statistical features further improved accuracy. Our biohybrid living system monitors the electrophysiology of plants in harsh, real-world conditions. This work advances scalable, self-sustaining, and plant-integrated living biohybrid systems for sustainable environmental monitoring.",
      "authors": [
        "Eduard Buss",
        "Till Aust",
        "and Heiko Hamann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:04:31+00:00",
          "link": "https://arxiv.org/abs/2506.23872v1",
          "size": "15744kb",
          "version": "v1"
        }
      ],
      "title": "When Plants Respond: Electrophysiology and Machine Learning for Green Monitoring Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23872",
        "HTML": "https://arxiv.org/html/2506.23872v1",
        "PDF": "https://arxiv.org/pdf/2506.23872"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23873",
      "abstract": "In music information retrieval (MIR), contrastive self-supervised learning for general-purpose representation models is effective for global tasks such as automatic tagging. However, for local tasks such as chord estimation, it is widely assumed that contrastively trained general-purpose self-supervised models are inadequate and that more sophisticated SSL is necessary; e.g., masked modeling. Our paper challenges this assumption by revealing the potential of contrastive SSL paired with a transformer in local MIR tasks. We consider a lightweight vision transformer with one-dimensional patches in the time--frequency domain (ViT-1D) and train it with simple contrastive SSL through normalized temperature-scaled cross-entropy loss (NT-Xent). Although NT-Xent operates only over the class token, we observe that, potentially thanks to weight sharing, informative musical properties emerge in ViT-1D's sequence tokens. On global tasks, the temporal average of class and sequence tokens offers a performance increase compared to the class token alone, showing useful properties in the sequence tokens. On local tasks, sequence tokens perform unexpectedly well, despite not being specifically trained for. Furthermore, high-level musical features such as onsets emerge from layer-wise attention maps and self-similarity matrices show different layers capture different musical dimensions. Our paper does not focus on improving performance but advances the musical interpretation of transformers and sheds light on some overlooked abilities of contrastive SSL paired with transformers for sequence modeling in MIR.",
      "authors": [
        "Yuexuan Kong and Gabriel Meseguer-Brocal and Vincent Lostanlen and Mathieu Lagrange and Romain Hennequin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:04:59+00:00",
          "link": "https://arxiv.org/abs/2506.23873v1",
          "size": "1104kb",
          "version": "v1"
        }
      ],
      "title": "Emergent musical properties of a transformer under contrastive self-supervised learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23873",
        "HTML": "https://arxiv.org/html/2506.23873v1",
        "PDF": "https://arxiv.org/pdf/2506.23873"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23875",
      "abstract": "The chain of thought is fundamental in Transformers, which is to perform step-by-step reasoning. Besides what intermediate steps work, the order of these steps critically affects the difficulty of the reasoning. This study addresses a novel task of unraveling chain of thought - reordering decoder input tokens to a learning-friendly sequence for Transformers to learn arithmetic tasks. The proposed pipeline first trains a Transformer on a mixture of target sequences arranged in different orders and then identifies benign orders as those with fast loss drops in the early stage. As the search space grows factorially with sequence length, we propose a two-stage hierarchical approach for inter- and intra-block reordering. Experiments on four order-sensitive arithmetic tasks show that our method identifies a learning-friendly order out of a few billion candidates. Notably, on the multiplication task, it recovered the reverse-digit order reported in prior studies.",
      "authors": [
        "Yuta Sato",
        "Kazuhiko Kawamoto",
        "Hiroshi Kera"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:05:53+00:00",
          "link": "https://arxiv.org/abs/2506.23875v1",
          "size": "3777kb",
          "version": "v1"
        }
      ],
      "title": "Chain of Thought in Order: Discovering Learning-Friendly Orders for Arithmetic",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23875",
        "HTML": "https://arxiv.org/html/2506.23875v1",
        "PDF": "https://arxiv.org/pdf/2506.23875"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23881",
      "abstract": "Out-of-distribution (OOD) detection is crucial for ensuring the reliability and safety of machine learning models in real-world applications, where they frequently face data distributions unseen during training. Despite progress, existing methods are often vulnerable to spurious correlations that mislead models and compromise robustness. To address this, we propose SPROD, a novel prototype-based OOD detection approach that explicitly addresses the challenge posed by unknown spurious correlations. Our post-hoc method refines class prototypes to mitigate bias from spurious features without additional data or hyperparameter tuning, and is broadly applicable across diverse backbones and OOD detection settings. We conduct a comprehensive spurious correlation OOD detection benchmarking, comparing our method against existing approaches and demonstrating its superior performance across challenging OOD datasets, such as CelebA, Waterbirds, UrbanCars, Spurious Imagenet, and the newly introduced Animals MetaCoCo. On average, SPROD improves AUROC by 4.7% and FPR@95 by 9.3% over the second best.",
      "authors": [
        "Reihaneh Zohrabi",
        "Hosein Hasani",
        "Mahdieh Soleymani Baghshah",
        "Anna Rohrbach",
        "Marcus Rohrbach",
        "Mohammad Hossein Rohban"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:10:51+00:00",
          "link": "https://arxiv.org/abs/2506.23881v1",
          "size": "2422kb",
          "version": "v1"
        }
      ],
      "title": "Spurious-Aware Prototype Refinement for Reliable Out-of-Distribution Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23881",
        "HTML": "https://arxiv.org/html/2506.23881v1",
        "PDF": "https://arxiv.org/pdf/2506.23881"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23888",
      "abstract": "Recent advancements in Large Language Models (LLMs) have significantly improved their problem-solving capabilities. However, these models still struggle when faced with complex multi-step reasoning tasks. In this paper, we propose the Multi-Layered Self-Reflection with Auto-Prompting (MAPS) framework, a novel approach designed to enhance multi-step mathematical reasoning in LLMs by integrating techniques such as Chain of Thought (CoT), Self-Reflection, and Auto-Prompting. Unlike traditional static prompting methods, MAPS employs an iterative refinement process. Initially, the model generates a solution using CoT prompting. When errors are detected, an adaptive self-reflection mechanism identifies and analyzes them, generating tailored prompts to guide corrections. These dynamically adjusted prompts enable the model to iteratively refine its reasoning. Experiments on four well-established benchmarks across multiple LLMs show that MAPS significantly outperforms standard CoT and achieves competitive results with reasoning-optimized models. In addition, MAPS enables general-purpose LLMs to reach performance levels comparable to specialized reasoning models. While deeper reflection layers improve accuracy, they also increase token usage and costs. To balance this trade-off, MAPS strategically limits reflection depth, ensuring an optimal balance between cost and reasoning performance.",
      "authors": [
        "Andr\\'e de Souza Loureiro",
        "Jorge Valverde-Rebaza",
        "Julieta Noguez",
        "David Escarcega",
        "Ricardo Marcacini"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:18:35+00:00",
          "link": "https://arxiv.org/abs/2506.23888v1",
          "size": "176kb",
          "version": "v1"
        }
      ],
      "title": "Advancing Multi-Step Mathematical Reasoning in Large Language Models through Multi-Layered Self-Reflection with Auto-Prompting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23888",
        "HTML": "https://arxiv.org/html/2506.23888v1",
        "PDF": "https://arxiv.org/pdf/2506.23888"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23892",
      "abstract": "Bayesian inverse problems use observed data to update a prior probability distribution for an unknown state or parameter of a scientific system to a posterior distribution conditioned on the data. In many applications, the unknown parameter is high-dimensional, making computation of the posterior expensive due to the need to sample in a high-dimensional space and the need to evaluate an expensive high-dimensional forward model relating the unknown parameter to the data. However, inverse problems often exhibit low-dimensional structure due to the fact that the available data are only informative in a low-dimensional subspace of the parameter space. Dimension reduction approaches exploit this structure by restricting inference to the low-dimensional subspace informed by the data, which can be sampled more efficiently. Further computational cost reductions can be achieved by replacing expensive high-dimensional forward models with cheaper lower-dimensional reduced models. In this work, we propose new dimension and model reduction approaches for linear Bayesian inverse problems with rank-deficient prior covariances, which arise in many practical inference settings. The dimension reduction approach is applicable to general linear Bayesian inverse problems whereas the model reduction approaches are specific to the problem of inferring the initial condition of a linear dynamical system. We provide theoretical approximation guarantees as well as numerical experiments demonstrating the accuracy and efficiency of the proposed approaches.",
      "authors": [
        "Josie K\\\"onig",
        "Elizabeth Qian",
        "Melina A. Freitag"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:20:58+00:00",
          "link": "https://arxiv.org/abs/2506.23892v1",
          "size": "275kb",
          "version": "v1"
        }
      ],
      "title": "Dimension and model reduction approaches for linear Bayesian inverse problems with rank-deficient prior covariances",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23892",
        "HTML": "https://arxiv.org/html/2506.23892v1",
        "PDF": "https://arxiv.org/pdf/2506.23892"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23896",
      "abstract": "Welfare maximization in bilateral trade has been extensively studied in recent years. Previous literature obtained incentive-compatible approximation mechanisms only for the private values case. In this paper, we study welfare maximization in bilateral trade with interdependent values. Designing mechanisms for interdependent settings is much more challenging because the values of the players depend on the private information of the others, requiring complex belief updates and strategic inference. We propose to classify information structures by quantifying the influence that a player's private signal has on their own valuation. We then paint a picture of where approximations are possible and impossible based on these information structures. Finally, we also study the possible approximation ratios for a natural family of information structures.",
      "authors": [
        "Shahar Dobzinski",
        "Alon Eden",
        "Kira Goldner",
        "Ariel Shaulker",
        "Thodoris Tsilivis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:29:47+00:00",
          "link": "https://arxiv.org/abs/2506.23896v1",
          "size": "80kb",
          "version": "v1"
        }
      ],
      "title": "Interdependent Bilateral Trade: Information vs Approximation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23896",
        "HTML": "https://arxiv.org/html/2506.23896v1",
        "PDF": "https://arxiv.org/pdf/2506.23896"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23897",
      "abstract": "Panoramic optical flow enables a comprehensive understanding of temporal dynamics across wide fields of view. However, severe distortions caused by sphere-to-plane projections, such as the equirectangular projection (ERP), significantly degrade the performance of conventional perspective-based optical flow methods, especially in polar regions. To address this challenge, we propose PriOr-Flow, a novel dual-branch framework that leverages the low-distortion nature of the orthogonal view to enhance optical flow estimation in these regions. Specifically, we introduce the Dual-Cost Collaborative Lookup (DCCL) operator, which jointly retrieves correlation information from both the primitive and orthogonal cost volumes, effectively mitigating distortion noise during cost volume construction. Furthermore, our Ortho-Driven Distortion Compensation (ODDC) module iteratively refines motion features from both branches, further suppressing polar distortions. Extensive experiments demonstrate that PriOr-Flow is compatible with various perspective-based iterative optical flow methods and consistently achieves state-of-the-art performance on publicly available panoramic optical flow datasets, setting a new benchmark for wide-field motion estimation. The code is publicly available at: https://github.com/longliangLiu/PriOr-Flow.",
      "authors": [
        "Longliang Liu",
        "Miaojie Feng",
        "Junda Cheng",
        "Jijun Xiang",
        "Xuan Zhu",
        "Xin Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:30:25+00:00",
          "link": "https://arxiv.org/abs/2506.23897v1",
          "size": "1535kb",
          "version": "v1"
        }
      ],
      "title": "PriOr-Flow: Enhancing Primitive Panoramic Optical Flow with Orthogonal View",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23897",
        "HTML": "https://arxiv.org/html/2506.23897v1",
        "PDF": "https://arxiv.org/pdf/2506.23897"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23898",
      "abstract": "Natural questions are crucial to shaping key architectural decisions and preserving architectural knowledge. They arise organically during the architectural design process, often resulting from the existing architectural experience of the designer and the distinctive characteristics of the system being designed. However, natural questions are often mismanaged or ignored, which can lead to architectural drift, knowledge loss, inefficient resource use, or poor understandability of the system's architecture. We aim to better understand the lifecycle of natural questions, its key requirements, challenges and difficulties, and then to envision an assisted environment to properly support it. The environment should be adaptable and responsive to real-world constraints and uncertainties by seamlessly integrating knowledge management tools and artificial intelligence techniques into software development workflows. Based on existing literature, a requirements workshop, and three design iterations, we proposed a lifecycle for natural questions and elicited essential functional and non-functional requirements for such an environment. At last, the results of a survey conducted with experts helped to analyze and validate the elicited requirements and proposed features for the environment to enhance collaboration, decision-making, and the preservation of architectural knowledge more effectively than conventional methods.",
      "authors": [
        "Diogo Lemos",
        "Ademar Aguiar",
        "Neil B. Harrison"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:30:42+00:00",
          "link": "https://arxiv.org/abs/2506.23898v1",
          "size": "1101kb",
          "version": "v1"
        }
      ],
      "title": "Requirements for Active Assistance of Natural Questions in Software Architecture",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23898",
        "HTML": "https://arxiv.org/html/2506.23898v1",
        "PDF": "https://arxiv.org/pdf/2506.23898"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23901",
      "abstract": "Novel compute systems are an emerging research topic, aiming towards building next-generation compute platforms. For these systems to thrive, they need to be provided as research infrastructure to allow acceptance and usage by a large community. By the example of the neuromorphic BrainScaleS-2 system, we showcase the transformation from a laboratory setup to a sustainable, publicly available platform. It is embedded into a purpose-built institute, tightly coupling a conventional cluster with novel compute hardware. The network infrastructure is optimized for robust operation, even in the case of unintended behavior of individual devices. The systems themselves are packaged into 19-inch compatible units to allow for easy maintenance and extension. We operate the platform using modern CI/CD techniques and continuously assert its health using automated system monitoring. Finally, we share our lessons learned during the decade-long endeavor of operating analog neuromorphic systems as a publicly available research platform.",
      "authors": [
        "Yannik Stradmann",
        "Joscha Ilmberger",
        "Eric M\\\"uller",
        "Johannes Schemmel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:32:44+00:00",
          "link": "https://arxiv.org/abs/2506.23901v1",
          "size": "1468kb",
          "version": "v1"
        }
      ],
      "title": "Sustainable operation of research infrastructure for novel computing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23901",
        "HTML": "https://arxiv.org/html/2506.23901v1",
        "PDF": "https://arxiv.org/pdf/2506.23901"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23903",
      "abstract": "Accurate and generalizable object segmentation in ultrasound imaging remains a significant challenge due to anatomical variability, diverse imaging protocols, and limited annotated data. In this study, we propose a prompt-driven vision-language model (VLM) that integrates Grounding DINO with SAM2 to enable object segmentation across multiple ultrasound organs. A total of 18 public ultrasound datasets, encompassing the breast, thyroid, liver, prostate, kidney, and paraspinal muscle, were utilized. These datasets were divided into 15 for fine-tuning and validation of Grounding DINO using Low Rank Adaptation (LoRA) to the ultrasound domain, and 3 were held out entirely for testing to evaluate performance in unseen distributions. Comprehensive experiments demonstrate that our approach outperforms state-of-the-art segmentation methods, including UniverSeg, MedSAM, MedCLIP-SAM, BiomedParse, and SAMUS on most seen datasets while maintaining strong performance on unseen datasets without additional fine-tuning. These results underscore the promise of VLMs in scalable and robust ultrasound image analysis, reducing dependence on large, organ-specific annotated datasets. We will publish our code on code.sonography.ai after acceptance.",
      "authors": [
        "Hamza Rasaee",
        "Taha Koleilat",
        "Hassan Rivaz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:33:44+00:00",
          "link": "https://arxiv.org/abs/2506.23903v1",
          "size": "5186kb",
          "version": "v1"
        }
      ],
      "title": "GroundingDINO-US-SAM: Text-Prompted Multi-Organ Segmentation in Ultrasound with LoRA-Tuned Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23903",
        "HTML": "https://arxiv.org/html/2506.23903v1",
        "PDF": "https://arxiv.org/pdf/2506.23903"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23906",
      "abstract": "Specialized computational units that perform small matrix multiplications as primitive operations are typically present in modern accelerators. However, these units are often underutilized for many fundamental operations besides dense matrix multiplications. The analysis of algorithms for such architectures is currently stagnated due to the lack of a rigorous theoretical model of computation that captures their characteristics. In this work, we propose MMV-RAM, a computational model tailored to matrix multiplication accelerators. MMV-RAM judiciously extends the Vector-RAM model with an additional processing unit that multiplies two matrices of sizes $n\\times s$ and $s\\times s$ in a single parallel step, where $s$ is a model parameter. We provide a detailed theoretical analysis of the model, and carefully balance the computational power between the matrix and vector units, guided by the circuit complexity lower bound that parity is not in AC[0].\n  In MMV-RAM, we study algorithms for segmented scan and sum, two fundamental parallel primitives. We propose a segmented scan algorithm that uses matrix multiplications to perform speculative block-scan computations, which runs in $O(\\log_s(n))$ steps. In contrast, we show that any algorithm that uses only the vector unit of MMV-RAM requires $\\Omega\\left(\\frac{\\log_2(n)}{\\log_2\\log_2(n)}\\right)$ steps. We further apply these techniques to obtain similar theoretical speedups for element-wise vector multiplication and matrix multiplication. Beyond the worst-case complexity analysis, we propose algorithms for segmented operations that could lead to highly efficient and pragmatic implementations. For example, we observe that segmented sum is a combination of three elementary parallel primitives: scan, compress, and vector differentiation. As a case study, we implement...",
      "authors": [
        "Aleksandros Sobczyk",
        "Giuseppe Sorrentino",
        "Anastasios Zouzias"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:36:44+00:00",
          "link": "https://arxiv.org/abs/2506.23906v1",
          "size": "504kb",
          "version": "v1"
        }
      ],
      "title": "Segmented Operations using Matrix Multiplications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23906",
        "HTML": "https://arxiv.org/html/2506.23906v1",
        "PDF": "https://arxiv.org/pdf/2506.23906"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23908",
      "abstract": "Sound deductive reasoning -- the ability to derive new knowledge from existing facts and rules -- is an indisputably desirable aspect of general intelligence. Despite the major advances of AI systems in areas such as math and science, especially since the introduction of transformer architectures, it is well-documented that even the most advanced frontier systems regularly and consistently falter on easily-solvable deductive reasoning tasks. Hence, these systems are unfit to fulfill the dream of achieving artificial general intelligence capable of sound deductive reasoning. We argue that their unsound behavior is a consequence of the statistical learning approach powering their development. To overcome this, we contend that to achieve reliable deductive reasoning in learning-based AI systems, researchers must fundamentally shift from optimizing for statistical performance against distributions on reasoning problems and algorithmic tasks to embracing the more ambitious exact learning paradigm, which demands correctness on all inputs. We argue that exact learning is both essential and possible, and that this ambitious objective should guide algorithm design.",
      "authors": [
        "Andr\\'as Gy\\\"orgy",
        "Tor Lattimore",
        "Nevena Lazi\\'c",
        "Csaba Szepesv\\'ari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:37:50+00:00",
          "link": "https://arxiv.org/abs/2506.23908v1",
          "size": "64kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Statistical Learning: Exact Learning Is Essential for General Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23908",
        "HTML": "https://arxiv.org/html/2506.23908v1",
        "PDF": "https://arxiv.org/pdf/2506.23908"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23909",
      "abstract": "This work addresses the challenge of malware classification using machine learning by developing a novel dataset labeled at both the malware type and family levels. Raw binaries were collected from sources such as VirusShare, VX Underground, and MalwareBazaar, and subsequently labeled with family information parsed from binary names and type-level labels integrated from ClarAVy. The dataset includes 14 malware types and 17 malware families, and was processed using a unified feature extraction pipeline based on static analysis, particularly extracting features from Portable Executable headers, to support advanced classification tasks. The evaluation was focused on three key classification tasks. In the binary classification of malware versus benign samples, Random Forest and XGBoost achieved high accuracy on the full datasets, reaching 98.5% for type-based detection and 98.98% for family-based detection. When using truncated datasets of 1,000 samples to assess performance under limited data conditions, both models still performed strongly, achieving 97.6% for type-based detection and 98.66% for family-based detection. For interclass classification, which distinguishes between malware types or families, the models reached up to 97.5% accuracy on type-level tasks and up to 93.7% on family-level tasks. In the multiclass classification setting, which assigns samples to the correct type or family, SVM achieved 81.1% accuracy on type labels, while Random Forest and XGBoost reached approximately 73.4% on family labels. The results highlight practical trade-offs between accuracy and computational cost, and demonstrate that labeling at both the type and family levels enables more fine-grained and insightful malware classification. The work establishes a robust foundation for future research on advanced malware detection and classification.",
      "authors": [
        "David B\\'alik",
        "Martin Jure\\v{c}ek",
        "Mark Stamp"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:38:01+00:00",
          "link": "https://arxiv.org/abs/2506.23909v1",
          "size": "509kb",
          "version": "v1"
        }
      ],
      "title": "RawMal-TF: Raw Malware Dataset Labeled by Type and Family",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23909",
        "HTML": "https://arxiv.org/html/2506.23909v1",
        "PDF": "https://arxiv.org/pdf/2506.23909"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23916",
      "abstract": "Deep learning (DL) methods are increasingly outperforming classical approaches in brain imaging, yet their generalizability across diverse imaging cohorts remains inadequately assessed. As age and sex are key neurobiological markers in clinical neuroscience, influencing brain structure and disease risk, this study evaluates three of the existing three-dimensional architectures, namely Simple Fully Connected Network (SFCN), DenseNet, and Shifted Window (Swin) Transformers, for age and sex prediction using T1-weighted MRI from four independent cohorts: UK Biobank (UKB, n=47,390), Dallas Lifespan Brain Study (DLBS, n=132), Parkinson's Progression Markers Initiative (PPMI, n=108 healthy controls), and Information eXtraction from Images (IXI, n=319). We found that SFCN consistently outperformed more complex architectures with AUC of 1.00 [1.00-1.00] in UKB (internal test set) and 0.85-0.91 in external test sets for sex classification. For the age prediction task, SFCN demonstrated a mean absolute error (MAE) of 2.66 (r=0.89) in UKB and 4.98-5.81 (r=0.55-0.70) across external datasets. Pairwise DeLong and Wilcoxon signed-rank tests with Bonferroni corrections confirmed SFCN's superiority over Swin Transformer across most cohorts (p<0.017, for three comparisons). Explainability analysis further demonstrates the regional consistency of model attention across cohorts and specific to each task. Our findings reveal that simpler convolutional networks outperform the denser and more complex attention-based DL architectures in brain image analysis by demonstrating better generalizability across different datasets.",
      "authors": [
        "Radhika Juglan",
        "Marta Ligero",
        "Zunamys I. Carrero",
        "Asier Rabasco",
        "Tim Lenz",
        "Leo Misera",
        "Gregory Patrick Veldhuizen",
        "Paul Kuntke",
        "Hagen H. Kitzler",
        "Sven Nebelung",
        "Daniel Truhn",
        "Jakob Nikolas Kather"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:44:49+00:00",
          "link": "https://arxiv.org/abs/2506.23916v1",
          "size": "6093kb",
          "version": "v1"
        }
      ],
      "title": "Three-dimensional end-to-end deep learning for brain MRI analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23916",
        "PDF": "https://arxiv.org/pdf/2506.23916"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23918",
      "abstract": "Recent progress in multimodal reasoning has been significantly advanced by textual Chain-of-Thought (CoT), a paradigm where models conduct reasoning within language. This text-centric approach, however, treats vision as a static, initial context, creating a fundamental \"semantic gap\" between rich perceptual data and discrete symbolic thought. Human cognition often transcends language, utilizing vision as a dynamic mental sketchpad. A similar evolution is now unfolding in AI, marking a fundamental paradigm shift from models that merely think about images to those that can truly think with images. This emerging paradigm is characterized by models leveraging visual information as intermediate steps in their thought process, transforming vision from a passive input into a dynamic, manipulable cognitive workspace. In this survey, we chart this evolution of intelligence along a trajectory of increasing cognitive autonomy, which unfolds across three key stages: from external tool exploration, through programmatic manipulation, to intrinsic imagination. To structure this rapidly evolving field, our survey makes four key contributions. (1) We establish the foundational principles of the think with image paradigm and its three-stage framework. (2) We provide a comprehensive review of the core methods that characterize each stage of this roadmap. (3) We analyze the critical landscape of evaluation benchmarks and transformative applications. (4) We identify significant challenges and outline promising future directions. By providing this structured overview, we aim to offer a clear roadmap for future research towards more powerful and human-aligned multimodal AI.",
      "authors": [
        "Zhaochen Su",
        "Peng Xia",
        "Hangyu Guo",
        "Zhenhua Liu",
        "Yan Ma",
        "Xiaoye Qu",
        "Jiaqi Liu",
        "Yanshu Li",
        "Kaide Zeng",
        "Zhengyuan Yang",
        "Linjie Li",
        "Yu Cheng",
        "Heng Ji",
        "Junxian He",
        "Yi R. (May) Fung"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:48:35+00:00",
          "link": "https://arxiv.org/abs/2506.23918v1",
          "size": "14543kb",
          "version": "v1"
        }
      ],
      "title": "Thinking with Images for Multimodal Reasoning: Foundations, Methods, and Future Frontiers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23918",
        "HTML": "https://arxiv.org/html/2506.23918v1",
        "PDF": "https://arxiv.org/pdf/2506.23918"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23919",
      "abstract": "Improving data efficiency and generalization in robotic manipulation remains a core challenge. We propose a novel framework that leverages a pre-trained multimodal image-generation model as a world model to guide policy learning. By exploiting its rich visual-semantic representations and strong generalization across diverse scenes, the model generates open-ended future state predictions that inform downstream manipulation. Coupled with zero-shot low-level control modules, our approach enables general-purpose robotic manipulation without task-specific training. Experiments in both simulation and real-world environments demonstrate that our method achieves effective performance across a wide range of manipulation tasks with no additional data collection or fine-tuning. Supplementary materials are available on our website: https://world4omni.github.io/.",
      "authors": [
        "Haonan Chen",
        "Bangjun Wang",
        "Jingxiang Guo",
        "Tianrui Zhang",
        "Yiwen Hou",
        "Xuchuan Huang",
        "Chenrui Tie",
        "Lin Shao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:48:49+00:00",
          "link": "https://arxiv.org/abs/2506.23919v1",
          "size": "1786kb",
          "version": "v1"
        }
      ],
      "title": "World4Omni: A Zero-Shot Framework from Image Generation World Model to Robotic Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23919",
        "HTML": "https://arxiv.org/html/2506.23919v1",
        "PDF": "https://arxiv.org/pdf/2506.23919"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23921",
      "abstract": "We often attribute human characteristics to large language models (LLMs) and claim that they \"know\" certain things. LLMs have an internal probabilistic knowledge that represents information retained during training. How can we assess the veracity of this knowledge? We examine two common methods for probing the veracity of LLMs and discover several assumptions that are flawed. To address these flawed assumptions, we introduce sAwMIL (short for Sparse Aware Multiple-Instance Learning), a probing method that utilizes the internal activations of LLMs to separate statements into true, false, and neither. sAwMIL is based on multiple-instance learning and conformal prediction. We evaluate sAwMIL on 5 validity criteria across 16 open-source LLMs, including both default and chat-based variants, as well as on 3 new datasets. Among the insights we provide are: (1) the veracity signal is often concentrated in the third quarter of an LLM's depth; (2) truth and falsehood signals are not always symmetric; (3) linear probes perform better on chat models than on default models; (4) nonlinear probes may be required to capture veracity signals for some LLMs with reinforcement learning from human feedback or knowledge distillation; and (5) LLMs capture a third type of signal that is distinct from true and false and is neither true nor false. These findings provide a reliable method for verifying what LLMs \"know\" and how certain they are of their probabilistic internal knowledge.",
      "authors": [
        "Germans Savcisens",
        "Tina Eliassi-Rad"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:49:28+00:00",
          "link": "https://arxiv.org/abs/2506.23921v1",
          "size": "38525kb",
          "version": "v1"
        }
      ],
      "title": "The Trilemma of Truth in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23921",
        "HTML": "https://arxiv.org/html/2506.23921v1",
        "PDF": "https://arxiv.org/pdf/2506.23921"
      },
      "datasets": [
        {
          "dataset_name": "carlomarxx/trilemma-of-truth",
          "downloads": "0",
          "likes": "0",
          "link": "https://huggingface.co/datasets/carlomarxx/trilemma-of-truth"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.23923",
      "abstract": "Resin infusion (RI) and resin transfer moulding (RTM) are critical processes for the manufacturing of high-performance fibre-reinforced polymer composites, particularly for large-scale applications such as wind turbine blades. Controlling the resin flow dynamics in these processes is critical to ensure the uniform impregnation of the fibre reinforcements, thereby preventing residual porosities and dry spots that impact the consequent structural integrity of the final component. This paper presents a reinforcement learning (RL) based strategy, established using process simulations, for synchronising the different resin flow fronts in an infusion scenario involving two resin inlets and a single outlet. Using Proximal Policy Optimisation (PPO), our approach addresses the challenge of managing the fluid dynamics in a partially observable environment. The results demonstrate the effectiveness of the RL approach in achieving an accurate flow convergence, highlighting its potential towards improving process control and product quality in composites manufacturing.",
      "authors": [
        "Miguel Camacho-S\\'anchez",
        "Fernando Garc\\'ia-Torres",
        "Jesper John Lisegaard",
        "Roc\\'io del Amor",
        "Sankhya Mohanty and Valery Naranjo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:50:18+00:00",
          "link": "https://arxiv.org/abs/2506.23923v1",
          "size": "410kb",
          "version": "v1"
        }
      ],
      "title": "Reinforcement Learning for Synchronised Flow Control in a Dual-Gate Resin Infusion System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23923",
        "HTML": "https://arxiv.org/html/2506.23923v1",
        "PDF": "https://arxiv.org/pdf/2506.23923"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23924",
      "abstract": "Large language models (LLMs) have exhibited expert-level capabilities across various domains. However, their abilities to solve problems in Operations Research (OR) -- the analysis and optimization of mathematical models derived from real-world problems or their verbal descriptions -- remain underexplored. In this work, we take a first step toward evaluating LLMs' abilities to solve stochastic modeling problems, a core class of OR problems characterized by uncertainty and typically involving tools from probability, statistics, and stochastic processes. We manually procure a representative set of graduate-level homework and doctoral qualification-exam problems and test LLMs' abilities to solve them. We further leverage SimOpt, an open-source library of simulation-optimization problems and solvers, to investigate LLMs' abilities to make real-world decisions under uncertainty. Our results show that, though a nontrivial amount of work is still needed to reliably automate the stochastic modeling pipeline in reality, state-of-the-art LLMs demonstrate proficiency on par with human experts in both classroom and practical settings. These findings highlight the potential of building AI agents that assist OR researchers and amplify the real-world impact of OR through automation.",
      "authors": [
        "Akshit Kumar",
        "Tianyi Peng",
        "Yuhang Wu",
        "Assaf Zeevi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:54:15+00:00",
          "link": "https://arxiv.org/abs/2506.23924v1",
          "size": "311kb",
          "version": "v1"
        }
      ],
      "title": "Performance of LLMs on Stochastic Modeling Operations Research Problems: From Theory to Practice",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23924",
        "PDF": "https://arxiv.org/pdf/2506.23924"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23926",
      "abstract": "Resilience non-equilibrium measurement, the ability to maintain fundamental functionality amidst failures and errors, is crucial for scientific management and engineering applications of industrial chain. The problem is particularly challenging when the number or types of multiple co-evolution of resilience (for example, randomly placed) are extremely chaos. Existing end-to-end deep learning ordinarily do not generalize well to unseen full-feld reconstruction of spatiotemporal co-evolution structure, and predict resilience of network topology, especially in multiple chaos data regimes typically seen in real-world applications. To address this challenge, here we propose industrial brain, a human-like autonomous cognitive decision-making and planning framework integrating higher-order activity-driven neuro network and CT-OODA symbolic reasoning to autonomous plan resilience directly from observational data of global variable. The industrial brain not only understands and model structure of node activity dynamics and network co-evolution topology without simplifying assumptions, and reveal the underlying laws hidden behind complex networks, but also enabling accurate resilience prediction, inference, and planning. Experimental results show that industrial brain significantly outperforms resilience prediction and planning methods, with an accurate improvement of up to 10.8\\% over GoT and OlaGPT framework and 11.03\\% over spectral dimension reduction. It also generalizes to unseen topologies and dynamics and maintains robust performance despite observational disturbances. Our findings suggest that industrial brain addresses an important gap in resilience prediction and planning for industrial chain.",
      "authors": [
        "Junping Wang",
        "Bicheng Wang",
        "Yibo Xuea and Yuan Xie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:54:52+00:00",
          "link": "https://arxiv.org/abs/2506.23926v1",
          "size": "6364kb",
          "version": "v1"
        }
      ],
      "title": "Industrial brain: a human-like autonomous neuro-symbolic cognitive decision-making system",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23926",
        "HTML": "https://arxiv.org/html/2506.23926v1",
        "PDF": "https://arxiv.org/pdf/2506.23926"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23929",
      "abstract": "Large Language Models (LLMs) have shown significant progress on various multilingual benchmarks and are increasingly used to generate and evaluate text in non-English languages. However, while they may produce fluent outputs, it remains unclear to what extent these models truly grasp the underlying linguistic complexity of those languages, particularly in morphology. To investigate this, we introduce IMPACT, a synthetically generated evaluation framework focused on inflectional morphology, which we publicly release, designed to evaluate LLM performance across five morphologically rich languages: Arabic, Russian, Finnish, Turkish, and Hebrew. IMPACT includes unit-test-style cases covering both shared and language-specific phenomena, from basic verb inflections (e.g., tense, number, gender) to unique features like Arabic's reverse gender agreement and vowel harmony in Finnish and Turkish. We assess eight multilingual LLMs that, despite strong English performance, struggle with other languages and uncommon morphological patterns, especially when judging ungrammatical examples. We also show that Chain of Thought and Thinking Models can degrade performance. Our work exposes gaps in LLMs' handling of linguistic complexity, pointing to clear room for improvement. To support further research, we publicly release the IMPACT framework.",
      "authors": [
        "Mohammed J. Saeed",
        "Tommi Vehvilainen",
        "Evgeny Fedoseev",
        "Sevil Caliskan",
        "Tatiana Vodolazova"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:58:23+00:00",
          "link": "https://arxiv.org/abs/2506.23929v1",
          "size": "1522kb",
          "version": "v1"
        }
      ],
      "title": "IMPACT: Inflectional Morphology Probes Across Complex Typologies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23929",
        "PDF": "https://arxiv.org/pdf/2506.23929"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23930",
      "abstract": "The rapid expansion of social media leads to a marked increase in hate speech, which threatens personal lives and results in numerous hate crimes. Detecting hate speech presents several challenges: diverse dialects, frequent code-mixing, and the prevalence of misspelled words in user-generated content on social media platforms. Recent progress in hate speech detection is typically concentrated on high-resource languages. However, low-resource languages still face significant challenges due to the lack of large-scale, high-quality datasets. This paper investigates how we can overcome this limitation via prompt engineering on large language models (LLMs) focusing on low-resource Bengali language. We investigate six prompting strategies - zero-shot prompting, refusal suppression, flattering the classifier, multi-shot prompting, role prompting, and finally our innovative metaphor prompting to detect hate speech effectively in low-resource languages. We pioneer the metaphor prompting to circumvent the built-in safety mechanisms of LLMs that marks a significant departure from existing jailbreaking methods. We investigate all six different prompting strategies on the Llama2-7B model and compare the results extensively with three pre-trained word embeddings - GloVe, Word2Vec, and FastText for three different deep learning models - multilayer perceptron (MLP), convolutional neural network (CNN), and bidirectional gated recurrent unit (BiGRU). To prove the effectiveness of our metaphor prompting in the low-resource Bengali language, we also evaluate it in another low-resource language - Hindi, and two high-resource languages - English and German. The performance of all prompting techniques is evaluated using the F1 score, and environmental impact factor (IF), which measures CO$_2$ emissions, electricity usage, and computational time.",
      "authors": [
        "Ruhina Tabasshum Prome (Bangladesh Institute of Governance and Management)",
        "Tarikul Islam Tamiti (George Mason University)",
        "Anomadarshi Barua (George Mason University)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:59:25+00:00",
          "link": "https://arxiv.org/abs/2506.23930v1",
          "size": "4190kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging the Potential of Prompt Engineering for Hate Speech Detection in Low-Resource Languages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23930",
        "HTML": "https://arxiv.org/html/2506.23930v1",
        "PDF": "https://arxiv.org/pdf/2506.23930"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23933",
      "abstract": "We propose and analyze a structure-preserving approximation of the non-isothermal Cahn-Hilliard equation using conforming finite elements for the spatial discretization and a problem-specific mixed explicit-implicit approach for the temporal discretization. To ensure the preservation of structural properties, i.e. conservation of mass and internal energy as well as entropy production, we introduce a suitable variational formulation for the continuous problem, based on the entropy equation. Analytical findings are supported by numerical tests, including convergence analysis.",
      "authors": [
        "Aaron Brunk",
        "Maria Lukacova-Medvidova",
        "Dennis Schumann"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:03:01+00:00",
          "link": "https://arxiv.org/abs/2506.23933v1",
          "size": "1681kb",
          "version": "v1"
        }
      ],
      "title": "Structure-preserving approximation of the non-isothermal Cahn-Hilliard system",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23933",
        "HTML": "https://arxiv.org/html/2506.23933v1",
        "PDF": "https://arxiv.org/pdf/2506.23933"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23934",
      "abstract": "As machine learning inferences increasingly move to edge devices, adapting to diverse computational capabilities, hardware, and memory constraints becomes more critical. Instead of relying on a pre-trained model fixed for all future inference queries across diverse edge devices, we argue that planning an inference pattern with a request-specific model tailored to the device's computational capacity, accuracy requirements, and time constraints is more cost-efficient and robust to diverse scenarios. To this end, we propose an accuracy-aware and workload-balanced inference system that integrates joint model quantization and inference partitioning. In this approach, the server dynamically responds to inference queries by sending a quantized model and adaptively sharing the inference workload with the device. Meanwhile, the device's computational power, channel capacity, and accuracy requirements are considered when deciding.\n  Furthermore, we introduce a new optimization framework for the inference system, incorporating joint model quantization and partitioning. Our approach optimizes layer-wise quantization bit width and partition points to minimize time consumption and cost while accounting for varying accuracy requirements of tasks through an accuracy degradation metric in our optimization model. To our knowledge, this work represents the first exploration of optimizing quantization layer-wise bit-width in the inference serving system, by introducing theoretical measurement of accuracy degradation. Simulation results demonstrate a substantial reduction in overall time and power consumption, with computation payloads decreasing by over 80% and accuracy degradation kept below 1%.",
      "authors": [
        "Xiangchen Li",
        "Saeid Ghafouri",
        "Bo Ji",
        "Hans Vandierendonck",
        "Deepu John",
        "Dimitrios S. Nikolopoulos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Performance (cs.PF)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:03:35+00:00",
          "link": "https://arxiv.org/abs/2506.23934v1",
          "size": "282kb",
          "version": "v1"
        }
      ],
      "title": "QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23934",
        "HTML": "https://arxiv.org/html/2506.23934v1",
        "PDF": "https://arxiv.org/pdf/2506.23934"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23940",
      "abstract": "Multimodal Large Language Models (MLLMs) have achieved success across various domains. However, their applicability tends to degrade when confronted with different types of data inputs, especially for MLLMs that have been fine-tuned for specific tasks. Despite its importance, the study of knowledge sharing among domain-specific MLLMs--such as those trained for mathematics or code--remains largely underexplored. To address the fragmentation of knowledge across domain-specialized MLLMs, we propose a unified parameter integration framework that enables modular composition of expert capabilities. Our method is grounded in a novel Compatibility-Aware Parameter Splicing (CAPS) strategy, which leverages both local functional attribution and global information-theoretic signals to guide selective parameter fusion. By extending this mechanism to the low-rank adaptation layer granularity, we ensure efficient integration with minimal inference overhead. Furthermore, we introduce a domain compatibility scoring mechanism that quantifies inter-expert alignment at the activation level and correlates with downstream task utility. This principled fusion protocol allows the final model to synergize heterogeneous expertise while preserving structural modularity. Extensive evaluations across diverse multimodal benchmarks validate the effectiveness of our framework, offering a scalable path toward compositional, domain-adaptive MLLMs.",
      "authors": [
        "Yang Dai",
        "Jianxiang An",
        "Tianwei Lin",
        "Hongyang He",
        "Hongzhe Huang",
        "Wenqiao Zhang",
        "Zheqi Lv",
        "Siliang Tang",
        "Yueting Zhuang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:07:41+00:00",
          "link": "https://arxiv.org/abs/2506.23940v1",
          "size": "7978kb",
          "version": "v1"
        }
      ],
      "title": "Graft: Integrating the Domain Knowledge via Efficient Parameter Synergy for MLLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23940",
        "HTML": "https://arxiv.org/html/2506.23940v1",
        "PDF": "https://arxiv.org/pdf/2506.23940"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23943",
      "abstract": "A linear layout of a graph consists of a linear ordering of its vertices and a partition of its edges into pages such that the edges assigned to the same page obey some constraint. The two most prominent and widely studied types of linear layouts are stack and queue layouts, in which any two edges assigned to the same page are forbidden to cross and nest, respectively. The names of these two layouts derive from the fact that, when parsing the graph according to the linear vertex ordering, the edges in a single page can be stored using a single stack or queue, respectively. Recently, the concepts of stack and queue layouts have been extended by using a double-ended queue or a restricted-input queue for storing the edges of a page. We extend this line of study to edge-weighted graphs by introducing priority queue layouts, that is, the edges on each page are stored in a priority queue whose keys are the edge weights. First, we show that there are edge-weighted graphs that require a linear number of priority queues. Second, we characterize the graphs that admit a priority queue layout with a single queue, regardless of the edge-weight function, and we provide an efficient recognition algorithm. Third, we show that the number of priority queues required independently of the edge-weight function is bounded by the pathwidth of the graph, but can be arbitrarily large already for graphs of treewidth two. Finally, we prove that determining the minimum number of priority queues is NP-complete if the linear ordering of the vertices is fixed.",
      "authors": [
        "Emilio Di Giacomo and Walter Didimo and Henry F\\\"orster and Torsten Ueckerdt and Johannes Zink"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:09:14+00:00",
          "link": "https://arxiv.org/abs/2506.23943v1",
          "size": "679kb",
          "version": "v1"
        }
      ],
      "title": "Linear Layouts of Graphs with Priority Queues",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23943",
        "HTML": "https://arxiv.org/html/2506.23943v1",
        "PDF": "https://arxiv.org/pdf/2506.23943"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23944",
      "abstract": "Imitation learning models for robotic tasks typically rely on multi-modal inputs, such as RGB images, language, and proprioceptive states. While proprioception is intuitively important for decision-making and obstacle avoidance, simply incorporating all proprioceptive states leads to a surprising degradation in imitation learning performance. In this work, we identify the underlying issue as the proprioception shift problem, where the distributions of proprioceptive states diverge significantly between training and deployment. To address this challenge, we propose a domain adaptation framework that bridges the gap by utilizing rollout data collected during deployment. Using Wasserstein distance, we quantify the discrepancy between expert and rollout proprioceptive states and minimize this gap by adding noise to both sets of states, proportional to the Wasserstein distance. This strategy enhances robustness against proprioception shifts by aligning the training and deployment distributions. Experiments on robotic manipulation tasks demonstrate the efficacy of our method, enabling the imitation policy to leverage proprioception while mitigating its adverse effects. Our approach outperforms the naive solution which discards proprioception, and other baselines designed to address distributional shifts.",
      "authors": [
        "Fuhang Kuang",
        "Jiacheng You",
        "Yingdong Hu",
        "Tong Zhang",
        "Chuan Wen",
        "Yang Gao"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:09:14+00:00",
          "link": "https://arxiv.org/abs/2506.23944v1",
          "size": "10456kb",
          "version": "v1"
        }
      ],
      "title": "Adapt Your Body: Mitigating Proprioception Shifts in Imitation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23944",
        "HTML": "https://arxiv.org/html/2506.23944v1",
        "PDF": "https://arxiv.org/pdf/2506.23944"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23947",
      "abstract": "This paper focuses on mean-square approximations of a generalized A\\\"it-Sahalia interest rate model with Poisson jumps. The main challenge in the construction and analysis of time-discrete numerical schemes is caused by a drift that blows up at the origin, highly nonlinear drift and diffusion coefficients and positivity-preserving requirement. Due to the presence of the Poisson jumps, additional difficulties arise in recovering the exact order $1/2$ of convergence for the time-stepping schemes. By incorporating implicitness in the term $\\alpha_{-1}x^{-1} $ and introducing the modifications functions $f_h$ and $g_h$ in the recursion, a novel explicit Euler-type scheme is proposed, which is easy to implement and preserves the positivity of the original model unconditionally, i.e., for any time step-size $h>0$. A mean-square convergence rate of order $1/2$ is established for the proposed scheme in both the non-critical and general critical cases. Finally, numerical experiments are provided to confirm the theoretical findings.",
      "authors": [
        "Yingsong Jiang",
        "Ruishu Liu and Minhong Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:13:26+00:00",
          "link": "https://arxiv.org/abs/2506.23947v1",
          "size": "100kb",
          "version": "v1"
        }
      ],
      "title": "Explicit modified Euler approximations of the A\\\"{i}t-Sahalia type model with Poisson jumps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23947",
        "HTML": "https://arxiv.org/html/2506.23947v1",
        "PDF": "https://arxiv.org/pdf/2506.23947"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23949",
      "abstract": "Increasingly multi-purpose AI models, such as cutting-edge large language models or other 'general-purpose AI' (GPAI) models, 'foundation models,' generative AI models, and 'frontier models' (typically all referred to hereafter with the umbrella term 'GPAI/foundation models' except where greater specificity is needed), can provide many beneficial capabilities but also risks of adverse events with profound consequences. This document provides risk-management practices or controls for identifying, analyzing, and mitigating risks of GPAI/foundation models. We intend this document primarily for developers of large-scale, state-of-the-art GPAI/foundation models; others that can benefit from this guidance include downstream developers of end-use applications that build on a GPAI/foundation model. This document facilitates conformity with or use of leading AI risk management-related standards, adapting and building on the generic voluntary guidance in the NIST AI Risk Management Framework and ISO/IEC 23894, with a focus on the unique issues faced by developers of GPAI/foundation models.",
      "authors": [
        "Anthony M. Barrett",
        "Jessica Newman",
        "Brandie Nonnecke",
        "Nada Madkour",
        "Dan Hendrycks",
        "Evan R. Murphy",
        "Krystal Jackson",
        "Deepika Raman"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:18:18+00:00",
          "link": "https://arxiv.org/abs/2506.23949v1",
          "size": "2054kb",
          "version": "v1"
        }
      ],
      "title": "AI Risk-Management Standards Profile for General-Purpose AI (GPAI) and Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23949",
        "PDF": "https://arxiv.org/pdf/2506.23949"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23951",
      "abstract": "Sparse Autoencoders (SAEs) have been successfully used to probe Large Language Models (LLMs) and extract interpretable concepts from their internal representations. These concepts are linear combinations of neuron activations that correspond to human-interpretable features. In this paper, we investigate the effectiveness of SAE-based explainability approaches for sentence classification, a domain where such methods have not been extensively explored. We present a novel SAE-based architecture tailored for text classification, leveraging a specialized classifier head and incorporating an activation rate sparsity loss. We benchmark this architecture against established methods such as ConceptShap, Independent Component Analysis, and other SAE-based concept extraction techniques. Our evaluation covers two classification benchmarks and four fine-tuned LLMs from the Pythia family. We further enrich our analysis with two novel metrics for measuring the precision of concept-based explanations, using an external sentence encoder. Our empirical results show that our architecture improves both the causality and interpretability of the extracted features.",
      "authors": [
        "Mathis Le Bail",
        "J\\'er\\'emie Dentan",
        "Davide Buscaldi",
        "Sonia Vanier"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:18:50+00:00",
          "link": "https://arxiv.org/abs/2506.23951v1",
          "size": "348kb",
          "version": "v1"
        }
      ],
      "title": "Unveiling Decision-Making in LLMs for Text Classification : Extraction of influential and interpretable concepts with Sparse Autoencoders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23951",
        "HTML": "https://arxiv.org/html/2506.23951v1",
        "PDF": "https://arxiv.org/pdf/2506.23951"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23952",
      "abstract": "AI systems increasingly support human decision-making across domains of professional, skill-based, and personal activity. While previous work has examined how AI might affect human autonomy globally, the effects of AI on domain-specific autonomy -- the capacity for self-governed action within defined realms of skill or expertise -- remain understudied. We analyze how AI decision-support systems affect two key components of domain-specific autonomy: skilled competence (the ability to make informed judgments within one's domain) and authentic value-formation (the capacity to form genuine domain-relevant values and preferences). By engaging with prior investigations and analyzing empirical cases across medical, financial, and educational domains, we demonstrate how the absence of reliable failure indicators and the potential for unconscious value shifts can erode domain-specific autonomy both immediately and over time. We then develop a constructive framework for autonomy-preserving AI support systems. We propose specific socio-technical design patterns -- including careful role specification, implementation of defeater mechanisms, and support for reflective practice -- that can help maintain domain-specific autonomy while leveraging AI capabilities. This framework provides concrete guidance for developing AI systems that enhance rather than diminish human agency within specialized domains of action.",
      "authors": [
        "Stefan Buijsman",
        "Sarah Carter",
        "Juan Pablo Berm\\'udez"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "General Economics (econ.GN)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:20:10+00:00",
          "link": "https://arxiv.org/abs/2506.23952v1",
          "size": "457kb",
          "version": "v1"
        }
      ],
      "title": "Autonomy by Design: Preserving Human Autonomy in AI Decision-Support",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23952",
        "PDF": "https://arxiv.org/pdf/2506.23952"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23957",
      "abstract": "Video stabilization is pivotal for video processing, as it removes unwanted shakiness while preserving the original user motion intent. Existing approaches, depending on the domain they operate, suffer from several issues (e.g. geometric distortions, excessive cropping, poor generalization) that degrade the user experience. To address these issues, we introduce \\textbf{GaVS}, a novel 3D-grounded approach that reformulates video stabilization as a temporally-consistent `local reconstruction and rendering' paradigm. Given 3D camera poses, we augment a reconstruction model to predict Gaussian Splatting primitives, and finetune it at test-time, with multi-view dynamics-aware photometric supervision and cross-frame regularization, to produce temporally-consistent local reconstructions. The model are then used to render each stabilized frame. We utilize a scene extrapolation module to avoid frame cropping. Our method is evaluated on a repurposed dataset, instilled with 3D-grounded information, covering samples with diverse camera motions and scene dynamics. Quantitatively, our method is competitive with or superior to state-of-the-art 2D and 2.5D approaches in terms of conventional task metrics and new geometry consistency. Qualitatively, our method produces noticeably better results compared to alternatives, validated by the user study.",
      "authors": [
        "Zinuo You",
        "Stamatios Georgoulis",
        "Anpei Chen",
        "Siyu Tang",
        "Dengxin Dai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:24:27+00:00",
          "link": "https://arxiv.org/abs/2506.23957v1",
          "size": "5090kb",
          "version": "v1"
        }
      ],
      "title": "GaVS: 3D-Grounded Video Stabilization via Temporally-Consistent Local Reconstruction and Rendering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23957",
        "HTML": "https://arxiv.org/html/2506.23957v1",
        "PDF": "https://arxiv.org/pdf/2506.23957"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23958",
      "abstract": "Millions of people in African countries face barriers to accessing healthcare due to language and literacy gaps. This research tackles this challenge by transforming complex medical documents -- in this case, prosthetic device user manuals -- into accessible formats for underserved populations. This case study in cross-cultural translation is particularly pertinent/relevant for communities that receive donated prosthetic devices but may not receive the accompanying user documentation. Or, if available online, may only be available in formats (e.g., language and readability) that are inaccessible to local populations (e.g., English-language, high resource settings/cultural context). The approach is demonstrated using the widely spoken Pidgin dialect, but our open-source framework has been designed to enable rapid and easy extension to other languages/dialects. This work presents an AI-powered framework designed to process and translate complex medical documents, e.g., user manuals for prosthetic devices, into marginalised languages. The system enables users -- such as healthcare workers or patients -- to upload English-language medical equipment manuals, pose questions in their native language, and receive accurate, localised answers in real time. Technically, the system integrates a Retrieval-Augmented Generation (RAG) pipeline for processing and semantic understanding of the uploaded manuals. It then employs advanced Natural Language Processing (NLP) models for generative question-answering and multilingual translation. Beyond simple translation, it ensures accessibility to device instructions, treatment protocols, and safety information, empowering patients and clinicians to make informed healthcare decisions.",
      "authors": [
        "Ikechukwu Ogbonna",
        "Lesley Davidson",
        "Soumya Banerjee",
        "Abhishek Dasgupta",
        "Laurence Kenney",
        "and Vikranth Harthikote Nagaraja"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:25:58+00:00",
          "link": "https://arxiv.org/abs/2506.23958v1",
          "size": "183kb",
          "version": "v1"
        }
      ],
      "title": "Bridging the Gap with Retrieval-Augmented Generation: Making Prosthetic Device User Manuals Available in Marginalised Languages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23958",
        "PDF": "https://arxiv.org/pdf/2506.23958"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23960",
      "abstract": "Autonomous Driving Systems (ADSs) continue to face safety-critical risks due to the inherent limitations in their design and performance capabilities. Online repair plays a crucial role in mitigating such limitations, ensuring the runtime safety and reliability of ADSs. Existing online repair solutions enforce ADS compliance by transforming unacceptable trajectories into acceptable ones based on predefined specifications, such as rule-based constraints or training datasets. However, these approaches often lack generalizability, adaptability and tend to be overly conservative, resulting in ineffective repairs that not only fail to mitigate safety risks sufficiently but also degrade the overall driving experience. To address this issue, we propose Adaptive Decision Repair (ADReFT), a novel and effective repair method that identifies safety-critical states through offline learning from failed tests and generates appropriate mitigation actions to improve ADS safety. Specifically, ADReFT incorporates a transformer-based model with two joint heads, State Monitor and Decision Adapter, designed to capture complex driving environment interactions to evaluate state safety severity and generate adaptive repair actions. Given the absence of oracles for state safety identification, we first pretrain ADReFT using supervised learning with coarse annotations, i.e., labeling states preceding violations as positive samples and others as negative samples. It establishes ADReFT's foundational capability to mitigate safety-critical violations, though it may result in somewhat conservative mitigation strategies. Therefore, we subsequently finetune ADReFT using reinforcement learning to improve its initial capability and generate more precise and contextually appropriate repair decisions. Our evaluation results illustrate that ADReFT achieves better repair performance.",
      "authors": [
        "Mingfei Cheng",
        "Xiaofei Xie",
        "Renzhi Wang",
        "Yuan Zhou",
        "Ming Hu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:29:36+00:00",
          "link": "https://arxiv.org/abs/2506.23960v1",
          "size": "432kb",
          "version": "v1"
        }
      ],
      "title": "ADReFT: Adaptive Decision Repair for Safe Autonomous Driving via Reinforcement Fine-Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23960",
        "HTML": "https://arxiv.org/html/2506.23960v1",
        "PDF": "https://arxiv.org/pdf/2506.23960"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23963",
      "abstract": "Text recognition is significantly influenced by font types, especially for complex scripts like Khmer. The variety of Khmer fonts, each with its unique character structure, presents challenges for optical character recognition (OCR) systems. In this study, we evaluate the impact of 19 randomly selected Khmer font types on text recognition accuracy using Pytesseract. The fonts include Angkor, Battambang, Bayon, Bokor, Chenla, Dangrek, Freehand, Kh Kompong Chhnang, Kh SN Kampongsom, Khmer, Khmer CN Stueng Songke, Khmer Savuth Pen, Metal, Moul, Odor MeanChey, Preah Vihear, Siemreap, Sithi Manuss, and iSeth First. Our comparison of OCR performance across these fonts reveals that Khmer, Odor MeanChey, Siemreap, Sithi Manuss, and Battambang achieve high accuracy, while iSeth First, Bayon, and Dangrek perform poorly. This study underscores the critical importance of font selection in optimizing Khmer text recognition and provides valuable insights for developing more robust OCR systems.",
      "authors": [
        "Vannkinh Nom",
        "Souhail Bakkali",
        "Muhammad Muzzamil Luqman",
        "Mickael Coustaty",
        "Jean-Marc Ogier"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:35:51+00:00",
          "link": "https://arxiv.org/abs/2506.23963v1",
          "size": "166kb",
          "version": "v1"
        }
      ],
      "title": "Evaluating the Impact of Khmer Font Types on Text Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23963",
        "HTML": "https://arxiv.org/html/2506.23963v1",
        "PDF": "https://arxiv.org/pdf/2506.23963"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23964",
      "abstract": "Network data conforms to a wide range of rules that arise from protocols, design principles, and deployment decisions (e.g., a packet's queuing delay must be less than its end-to-end delay). Formalizing such rules as logic constraints can (i) improve the quality of synthetic data, (ii) reduce the brittleness of machine learning (ML) models, and (iii) improve semantic understanding of network measurements. However, these benefits remain out of reach if rule extraction is manual or solely reliant on ML, as both approaches yield incomplete, unreliable, and/or inaccurate rules.\n  This paper formulates rule extraction as a constraint modeling problem and introduces NetNomos that learns propositional logic constraints directly from raw network measurements. Constraint modeling in this domain is uniquely challenging due to the scale of the data, the inherent learning complexity and passive environment, and the lack of ground truth supervision. NetNomos addresses these challenges via a lattice-based search structured by constraint specificity and succinctness. Our approach reduces learning complexity from superquadratic to logarithmic and enables efficient traversal in combinatorial search space.\n  Our evaluations on diverse network datasets show that NetNomos learns all benchmark rules, including those associated with as little as 0.01% of data points, in under three hours. In contrast, baseline methods discover less than 25% of the rules and require several days to run. Through three case studies, we show that: NetNomos (i) finds rule violations in the outputs of all seven synthetic traffic generators, hence can be used to assess and guide their generation process; (ii) detects semantic differences in traffic, hence can be used for anomaly detection; and (iii) automatically finds rules used for telemetry imputation, hence can support monitoring through inference.",
      "authors": [
        "Hongyu H\\`e",
        "Minhao Jin",
        "and Maria Apostolaki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:36:22+00:00",
          "link": "https://arxiv.org/abs/2506.23964v1",
          "size": "1610kb",
          "version": "v1"
        }
      ],
      "title": "Learning Constraints Directly from Network Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23964",
        "HTML": "https://arxiv.org/html/2506.23964v1",
        "PDF": "https://arxiv.org/pdf/2506.23964"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23967",
      "abstract": "The environmental impact of software is gaining increasing attention as the demand for computational resources continues to rise. In order to optimize software resource consumption and reduce carbon emissions, measuring and evaluating software is a first essential step. In this paper we discuss what metrics are important for fact base decision making. We introduce the Green Metrics Tool (GMT), a novel framework for accurately measuring the resource consumption of software. The tool provides a containerized, controlled, and reproducible life cycle-based approach, assessing the resource use of software during key phases. Finally, we discuss GMT features like visualization, comparability and rule- and LLM-based optimisations highlighting its potential to guide developers and researchers in reducing the environmental impact of their software.",
      "authors": [
        "Geerd-Dietger Hoffmann",
        "Verena Majuntke"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Computers and Society (cs.CY)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:36:53+00:00",
          "link": "https://arxiv.org/abs/2506.23967v1",
          "size": "134kb",
          "version": "v1"
        }
      ],
      "title": "Green Metrics Tool: Measuring for fun and profit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23967",
        "HTML": "https://arxiv.org/html/2506.23967v1",
        "PDF": "https://arxiv.org/pdf/2506.23967"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23969",
      "abstract": "Full history recursive multilevel Picard (MLP) approximations have been proved to overcome the curse of dimensionality in the numerical approximation of semilinear heat equations with nonlinearities which are globally Lipschitz continuous with respect to the maximum-norm. Nonlinearities in Hamilton-Jacobi-Bellman equations in stochastic control theory, however, are often (locally) Lipschitz continuous with respect to the standard Euclidean norm. In this paper we prove the surprising fact that MLP approximations for one such example equation suffer from the curse of dimensionality.",
      "authors": [
        "Martin Hutzenthaler",
        "Tuan Anh Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:37:27+00:00",
          "link": "https://arxiv.org/abs/2506.23969v1",
          "size": "22kb",
          "version": "v1"
        }
      ],
      "title": "Full history recursive multilevel Picard approximations suffer from the curse of dimensionality for the Hamilton-Jacobi-Bellman equation of a stochastic control problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23969",
        "PDF": "https://arxiv.org/pdf/2506.23969"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23971",
      "abstract": "The ability to quickly and accurately compute properties from atomic simulations is critical for advancing a large number of applications in chemistry and materials science including drug discovery, energy storage, and semiconductor manufacturing. To address this need, Meta FAIR presents a family of Universal Models for Atoms (UMA), designed to push the frontier of speed, accuracy, and generalization. UMA models are trained on half a billion unique 3D atomic structures (the largest training runs to date) by compiling data across multiple chemical domains, e.g. molecules, materials, and catalysts. We develop empirical scaling laws to help understand how to increase model capacity alongside dataset size to achieve the best accuracy. The UMA small and medium models utilize a novel architectural design we refer to as mixture of linear experts that enables increasing model capacity without sacrificing speed. For example, UMA-medium has 1.4B parameters but only ~50M active parameters per atomic structure. We evaluate UMA models on a diverse set of applications across multiple domains and find that, remarkably, a single model without any fine-tuning can perform similarly or better than specialized models. We are releasing the UMA code, weights, and associated data to accelerate computational workflows and enable the community to continue to build increasingly capable AI models.",
      "authors": [
        "Brandon M. Wood",
        "Misko Dzamba",
        "Xiang Fu",
        "Meng Gao",
        "Muhammed Shuaibi",
        "Luis Barroso-Luque",
        "Kareem Abdelmaqsoud",
        "Vahe Gharakhanyan",
        "John R. Kitchin",
        "Daniel S. Levine",
        "Kyle Michel",
        "Anuroop Sriram",
        "Taco Cohen",
        "Abhishek Das",
        "Ammar Rizvi",
        "Sushree Jagriti Sahoo",
        "Zachary W. Ulissi",
        "C. Lawrence Zitnick"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:38:13+00:00",
          "link": "https://arxiv.org/abs/2506.23971v1",
          "size": "2549kb",
          "version": "v1"
        }
      ],
      "title": "UMA: A Family of Universal Models for Atoms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23971",
        "PDF": "https://arxiv.org/pdf/2506.23971"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23972",
      "abstract": "Prompt-learning-based multi-modal trackers have achieved promising progress by employing lightweight visual adapters to incorporate auxiliary modality features into frozen foundation models. However, existing approaches often struggle to learn reliable prompts due to limited exploitation of critical cues across frequency and temporal domains. In this paper, we propose a novel visual and memory dual adapter (VMDA) to construct more robust and discriminative representations for multi-modal tracking. Specifically, we develop a simple but effective visual adapter that adaptively transfers discriminative cues from auxiliary modality to dominant modality by jointly modeling the frequency, spatial, and channel-wise features. Additionally, we design the memory adapter inspired by the human memory mechanism, which stores global temporal cues and performs dynamic update and retrieval operations to ensure the consistent propagation of reliable temporal information across video sequences. Extensive experiments demonstrate that our method achieves state-of-the-art performance on the various multi-modal tracking tasks, including RGB-Thermal, RGB-Depth, and RGB-Event tracking. Code and models are available at https://github.com/xuboyue1999/mmtrack.git.",
      "authors": [
        "Boyue Xu",
        "Ruichao Hou",
        "Tongwei Ren and Gangshan Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:38:26+00:00",
          "link": "https://arxiv.org/abs/2506.23972v1",
          "size": "2681kb",
          "version": "v1"
        }
      ],
      "title": "Visual and Memory Dual Adapter for Multi-Modal Object Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23972",
        "HTML": "https://arxiv.org/html/2506.23972v1",
        "PDF": "https://arxiv.org/pdf/2506.23972"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23975",
      "abstract": "Understanding why a classification model prefers one class over another for an input instance is the challenge of contrastive explanation. This work implements concept-based contrastive explanations for image classification by leveraging the similarity of instance embeddings and relevance of human-understandable concepts used by a fine-tuned deep learning model. Our approach extracts concepts with their relevance score, computes contrasts for similar instances, and evaluates the resulting contrastive explanations based on explanation complexity. Robustness is tested for different image augmentations. Two research questions are addressed: (1) whether explanation complexity varies across different relevance ranges, and (2) whether explanation complexity remains consistent under image augmentations such as rotation and noise. The results confirm that for our experiments higher concept relevance leads to shorter, less complex explanations, while lower relevance results in longer, more diffuse explanations. Additionally, explanations show varying degrees of robustness. The discussion of these findings offers insights into the potential of building more interpretable and robust AI systems.",
      "authors": [
        "Yuliia Kaidashova",
        "Bettina Finzel",
        "Ute Schmid"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:41:43+00:00",
          "link": "https://arxiv.org/abs/2506.23975v1",
          "size": "546kb",
          "version": "v1"
        }
      ],
      "title": "Toward Simple and Robust Contrastive Explanations for Image Classification by Leveraging Instance Similarity and Concept Relevance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23975",
        "HTML": "https://arxiv.org/html/2506.23975v1",
        "PDF": "https://arxiv.org/pdf/2506.23975"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23977",
      "abstract": "Certified robustness is a critical property for deploying neural networks (NN) in safety-critical applications. A principle approach to achieving such guarantees is to constrain the global Lipschitz constant of the network. However, accurate methods for Lipschitz-constrained training often suffer from non-convex formulations and poor scalability due to reliance on global semidefinite programs (SDPs). In this letter, we propose a convex training framework that enforces global Lipschitz constraints via semidefinite relaxation. By reparameterizing the NN using loop transformation, we derive a convex admissibility condition that enables tractable and certifiable training. While the resulting formulation guarantees robustness, its scalability is limited by the size of global SDP. To overcome this, we develop a randomized subspace linear matrix inequalities (RS-LMI) approach that decomposes the global constraints into sketched layerwise constraints projected onto low-dimensional subspaces, yielding a smooth and memory-efficient training objective. Empirical results on MNIST, CIFAR-10, and ImageNet demonstrate that the proposed framework achieves competitive accuracy with significantly improved Lipschitz bounds and runtime performance.",
      "authors": [
        "Zain ul Abdeen",
        "Vassilis Kekatos",
        "Ming Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:42:23+00:00",
          "link": "https://arxiv.org/abs/2506.23977v1",
          "size": "471kb",
          "version": "v1"
        }
      ],
      "title": "A Scalable Approach for Safe and Robust Learning via Lipschitz-Constrained Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23977",
        "HTML": "https://arxiv.org/html/2506.23977v1",
        "PDF": "https://arxiv.org/pdf/2506.23977"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23978",
      "abstract": "While the Internet's core infrastructure was designed to be open and universal, today's application layer is dominated by closed, proprietary platforms. Open and interoperable APIs require significant investment, and market leaders have little incentive to enable data exchange that could erode their user lock-in. We argue that LLM-based agents fundamentally disrupt this status quo. Agents can automatically translate between data formats and interact with interfaces designed for humans: this makes interoperability dramatically cheaper and effectively unavoidable. We name this shift universal interoperability: the ability for any two digital services to exchange data seamlessly using AI-mediated adapters. Universal interoperability undermines monopolistic behaviours and promotes data portability. However, it can also lead to new security risks and technical debt. Our position is that the ML community should embrace this development while building the appropriate frameworks to mitigate the downsides. By acting now, we can harness AI to restore user freedom and competitive markets without sacrificing security.",
      "authors": [
        "Samuele Marro",
        "Philip Torr"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:45:17+00:00",
          "link": "https://arxiv.org/abs/2506.23978v1",
          "size": "83kb",
          "version": "v1"
        }
      ],
      "title": "LLM Agents Are the Antidote to Walled Gardens",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23978",
        "HTML": "https://arxiv.org/html/2506.23978v1",
        "PDF": "https://arxiv.org/pdf/2506.23978"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23979",
      "abstract": "Conducting supervised fine-tuning and preference fine-tuning on large language models (LLMs) requires high-quality datasets to improve their ability to follow instructions and align with human preferences and values. However, constructing such datasets is resource-intensive, and most available datasets for supervised and preference fine-tuning are in English. To address these challenges, we propose the \\underline{\\textbf{Ta}}xonomy-Guided \\underline{\\textbf{P}}reference Data Generation (TaP) framework, which facilitates automated and scalable construction of preference datasets across various languages. TaP is grounded in a structured taxonomy that allows fine-grained control over dataset composition, thereby ensuring both diversity and comprehensive coverage. We employ TaP-generated datasets to perform supervised and preference fine-tuning on various LLMs. Experimental results demonstrate that LLMs trained on TaP-generated datasets outperform those trained on existing open-source datasets. Remarkably, LLMs trained on TaP-generated datasets surpass the performance of those trained on an open-source dataset that is 180 times larger.",
      "authors": [
        "Renren Jin",
        "Tianhao Shen",
        "Xinwei Wu",
        "Dan Shi",
        "Haoran Sun",
        "Wuwei Huang",
        "Quandong Wang",
        "Wei Liu",
        "Jian Luan",
        "Bin Wang",
        "Deyi Xiong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:45:28+00:00",
          "link": "https://arxiv.org/abs/2506.23979v1",
          "size": "1071kb",
          "version": "v1"
        }
      ],
      "title": "TaP: A Taxonomy-Guided Framework for Automated and Scalable Preference Data Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23979",
        "HTML": "https://arxiv.org/html/2506.23979v1",
        "PDF": "https://arxiv.org/pdf/2506.23979"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23982",
      "abstract": "While personalization has been explored in traditional autonomous driving systems, it remains largely overlooked in end-to-end autonomous driving (E2EAD), despite its growing prominence. This gap is critical, as user-aligned behavior is essential for trust, comfort, and widespread adoption of autonomous vehicles. A core challenge is the lack of large-scale real-world datasets annotated with diverse and fine-grained driving preferences, hindering the development and evaluation of personalized E2EAD models. In this work, we present the first large-scale real-world dataset enriched with annotations capturing diverse driving preferences, establishing a foundation for personalization in E2EAD. We extract static environmental features from real-world road topology and infer dynamic contextual cues using a fine-tuned visual language model (VLM), enabling consistent and fine-grained scenario construction. Based on these scenarios, we derive objective preference annotations through behavioral distribution analysis and rule-based heuristics. To address the inherent subjectivity of driving style, we further employ the VLM to generate subjective annotations by jointly modeling scene semantics and driver behavior. Final high-quality labels are obtained through a human-in-the-loop verification process that fuses both perspectives. Building on this dataset, we propose the first benchmark for evaluating personalized E2EAD models. We assess several state-of-the-art models with and without preference conditioning, demonstrating that incorporating personalized preferences results in behavior more aligned with human driving. Our work lays the foundation for personalized E2EAD by providing a standardized platform to systematically integrate human preferences into data-driven E2EAD systems, catalyzing future research in human-centric autonomy.",
      "authors": [
        "Ruiyang Hao",
        "Bowen Jing",
        "Haibao Yu",
        "Zaiqing Nie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:48:38+00:00",
          "link": "https://arxiv.org/abs/2506.23982v1",
          "size": "9134kb",
          "version": "v1"
        }
      ],
      "title": "StyleDrive: Towards Driving-Style Aware Benchmarking of End-To-End Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23982",
        "HTML": "https://arxiv.org/html/2506.23982v1",
        "PDF": "https://arxiv.org/pdf/2506.23982"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23985",
      "abstract": "Modern enterprise database systems face significant challenges in balancing data security and performance. Ensuring robust encryption for sensitive information is critical for systems' compliance with security standards. Although holistic database encryption provides strong protection, existing database systems often require a complete backup and restore cycle, resulting in prolonged downtime and increased storage usage. This makes it difficult to implement online encryption techniques in high-throughput environments without disrupting critical operations.\n  To address this challenge, we envision a solution that enables online database encryption aligned with system activity, eliminating the need for downtime, storage overhead, or full-database reprocessing. Central to this vision is the ability to predict which parts of the database will be accessed next, allowing encryption to be applied online. As a step towards this solution, this study proposes a predictive approach that leverages deep learning models to forecast database lock sequences, using IBM Db2 as the database system under study. In this study, we collected a specialized dataset from TPC-C benchmark workloads, leveraging lock event logs for model training and evaluation. We applied deep learning architectures, such as Transformer and LSTM, to evaluate models for various table-level and page-level lock predictions. We benchmark the accuracy of the trained models versus a Naive Baseline across different prediction horizons and timelines.\n  The study experiments demonstrate that the proposed deep learning-based models achieve up to 49% average accuracy for table-level and 66% for page-level predictions, outperforming a Naive Baseline. By anticipating which tables and pages will be locked next, the proposed approach is a step toward online encryption, offering a practical path toward secure, low-overhead database systems.",
      "authors": [
        "Mohamed Sami Rakha and Adam Sorrenti and Greg Stager and Walid Rjaibi and Andriy Miranskyy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:50:06+00:00",
          "link": "https://arxiv.org/abs/2506.23985v1",
          "size": "127kb",
          "version": "v1"
        }
      ],
      "title": "Lock Prediction for Zero-Downtime Database Encryption",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23985",
        "HTML": "https://arxiv.org/html/2506.23985v1",
        "PDF": "https://arxiv.org/pdf/2506.23985"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23986",
      "abstract": "Recent advancements in discrete token-based speech generation have highlighted the importance of token-to-waveform generation for audio quality, particularly in real-time interactions. Traditional frameworks integrating semantic tokens with flow matching (FM) struggle with streaming capabilities due to their reliance on a global receptive field. Additionally, directly implementing token-by-token streaming speech generation often results in degraded audio quality. To address these challenges, we propose StreamFlow, a novel neural architecture that facilitates streaming flow matching with diffusion transformers (DiT). To mitigate the long-sequence extrapolation issues arising from lengthy historical dependencies, we design a local block-wise receptive field strategy. Specifically, the sequence is first segmented into blocks, and we introduce block-wise attention masks that enable the current block to receive information from the previous or subsequent block. These attention masks are combined hierarchically across different DiT-blocks to regulate the receptive field of DiTs. Both subjective and objective experimental results demonstrate that our approach achieves performance comparable to non-streaming methods while surpassing other streaming methods in terms of speech quality, all the while effectively managing inference time during long-sequence generation. Furthermore, our method achieves a notable first-packet latency of only 180 ms.\\footnote{Speech samples: https://dukguo.github.io/StreamFlow/}",
      "authors": [
        "Dake Guo",
        "Jixun Yao",
        "Linhan Ma",
        "Wang He",
        "Lei Xie"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:50:08+00:00",
          "link": "https://arxiv.org/abs/2506.23986v1",
          "size": "3624kb",
          "version": "v1"
        }
      ],
      "title": "StreamFlow: Streaming Flow Matching with Block-wise Guided Attention Mask for Speech Token Decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23986",
        "HTML": "https://arxiv.org/html/2506.23986v1",
        "PDF": "https://arxiv.org/pdf/2506.23986"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23990",
      "abstract": "Scientific information expresses human understanding of nature. This knowledge is largely disseminated in different forms of text, including scientific papers, news articles, and discourse among people on social media. While important for accelerating our pursuit of knowledge, not all scientific text is faithful to the underlying science. As the volume of this text has burgeoned online in recent years, it has become a problem of societal importance to be able to identify the faithfulness of a given piece of scientific text automatically. This thesis is concerned with the cultivation of datasets, methods, and tools for machine understanding of scientific language, in order to analyze and understand science communication at scale. To arrive at this, I present several contributions in three areas of natural language processing and machine learning: automatic fact checking, learning with limited data, and scientific text processing. These contributions include new methods and resources for identifying check-worthy claims, adversarial claim generation, multi-source domain adaptation, learning from crowd-sourced labels, cite-worthiness detection, zero-shot scientific fact checking, detecting exaggerated scientific claims, and modeling degrees of information change in science communication. Critically, I demonstrate how the research outputs of this thesis are useful for effectively learning from limited amounts of scientific text in order to identify misinformative scientific statements and generate new insights into the science communication process",
      "authors": [
        "Dustin Wright"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:55:10+00:00",
          "link": "https://arxiv.org/abs/2506.23990v1",
          "size": "7039kb",
          "version": "v1"
        }
      ],
      "title": "Machine Understanding of Scientific Language",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23990",
        "HTML": "https://arxiv.org/html/2506.23990v1",
        "PDF": "https://arxiv.org/pdf/2506.23990"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23992",
      "abstract": "The international refugee crisis deepens, exposing millions of dis placed children to extreme psychological trauma. This research suggests a com pact, AI-based framework for processing unstructured refugee health data and distilling knowledge on child mental health. We compare two Retrieval-Aug mented Generation (RAG) pipelines, Zephyr-7B-beta and DeepSeek R1-7B, to determine how well they process challenging humanitarian datasets while avoid ing hallucination hazards. By combining cutting-edge AI methods with migration research and child psychology, this study presents a scalable strategy to assist policymakers, mental health practitioners, and humanitarian agencies to better assist displaced children and recognize their mental wellbeing. In total, both the models worked properly but significantly Deepseek R1 is superior to Zephyr with an accuracy of answer relevance 0.91",
      "authors": [
        "Aditya Shrivastava",
        "Komal Gupta",
        "and Shraddha Arora"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:55:41+00:00",
          "link": "https://arxiv.org/abs/2506.23992v1",
          "size": "270kb",
          "version": "v1"
        }
      ],
      "title": "Harnessing AI Agents to Advance Research on Refugee Child Mental Health",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23992",
        "PDF": "https://arxiv.org/pdf/2506.23992"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23995",
      "abstract": "Autonomous Driving System (ADS) testing is essential to ensure the safety and reliability of autonomous vehicles (AVs) before deployment. However, existing techniques primarily focus on evaluating ADS functionalities in single-AV settings. As ADSs are increasingly deployed in multi-AV traffic, it becomes crucial to assess their cooperative performance, particularly regarding deadlocks, a fundamental coordination failure in which multiple AVs enter a circular waiting state indefinitely, resulting in motion planning failures. Despite its importance, the cooperative capability of ADSs to prevent deadlocks remains insufficiently underexplored. To address this gap, we propose the first dedicated Spatio-Temporal Conflict-Guided Deadlock Avoidance Testing technique, STCLocker, for generating DeadLock Scenarios (DLSs), where a group of AVs controlled by the ADS under test are in a circular wait state. STCLocker consists of three key components: Deadlock Oracle, Conflict Feedback, and Conflict-aware Scenario Generation. Deadlock Oracle provides a reliable black-box mechanism for detecting deadlock cycles among multiple AVs within a given scenario. Conflict Feedback and Conflict-aware Scenario Generation collaborate to actively guide AVs into simultaneous competition over spatial conflict resources (i.e., shared passing regions) and temporal competitive behaviors (i.e., reaching the conflict region at the same time), thereby increasing the effectiveness of generating conflict-prone deadlocks. We evaluate STCLocker on two types of ADSs: Roach, an end-to-end ADS, and OpenCDA, a module-based ADS supporting cooperative communication. Experimental results show that, on average, STCLocker generates more DLS than the best-performing baseline.",
      "authors": [
        "Mingfei Cheng",
        "Renzhi Wang",
        "Xiaofei Xie",
        "Yuan Zhou",
        "Lei Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:58:10+00:00",
          "link": "https://arxiv.org/abs/2506.23995v1",
          "size": "1885kb",
          "version": "v1"
        }
      ],
      "title": "STCLocker: Deadlock Avoidance Testing for Autonomous Driving Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23995",
        "HTML": "https://arxiv.org/html/2506.23995v1",
        "PDF": "https://arxiv.org/pdf/2506.23995"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23996",
      "abstract": "This document shows how to obtain the Jacobian and Hessian matrices of the Kullback-Leibler divergence between two multivariate Gaussian distributions, using the first and second-order differentials. The presented derivations are based on the theory presented by \\cite{magnus99}. I've also got great inspiration from some of the derivations in \\cite{minka}.\n  Since I pretend to be at most didactic, the document is split into a summary of results and detailed derivations on each of the elements involved, with specific references to the tricks used in the derivations, and to many of the underlying concepts.",
      "authors": [
        "Juan Maro\\~nas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:58:25+00:00",
          "link": "https://arxiv.org/abs/2506.23996v1",
          "size": "27kb",
          "version": "v1"
        }
      ],
      "title": "The Jacobian and Hessian of the Kullback-Leibler Divergence between Multivariate Gaussian Distributions (Technical Report)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23996",
        "PDF": "https://arxiv.org/pdf/2506.23996"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23998",
      "abstract": "Congenital heart disease (CHD) presents complex, lifelong challenges often underrepresented in traditional clinical metrics. While unstructured narratives offer rich insights into patient and caregiver experiences, manual thematic analysis (TA) remains labor-intensive and unscalable. We propose a fully automated large language model (LLM) pipeline that performs end-to-end TA on clinical narratives, which eliminates the need for manual coding or full transcript review. Our system employs a novel multi-agent framework, where specialized LLM agents assume roles to enhance theme quality and alignment with human analysis. To further improve thematic relevance, we optionally integrate reinforcement learning from human feedback (RLHF). This supports scalable, patient-centered analysis of large qualitative datasets and allows LLMs to be fine-tuned for specific clinical contexts.",
      "authors": [
        "Seungjun Yi",
        "Joakim Nguyen",
        "Huimin Xu",
        "Terence Lim",
        "Andrew Well",
        "Mia Markey",
        "Ying Ding"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:02:28+00:00",
          "link": "https://arxiv.org/abs/2506.23998v1",
          "size": "1237kb",
          "version": "v1"
        }
      ],
      "title": "Auto-TA: Towards Scalable Automated Thematic Analysis (TA) via Multi-Agent Large Language Models with Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23998",
        "PDF": "https://arxiv.org/pdf/2506.23998"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23999",
      "abstract": "The safe trajectory planning of intelligent and connected vehicles is a key component in autonomous driving technology. Modeling the environment risk information by field is a promising and effective approach for safe trajectory planning. However, existing risk assessment theories only analyze the risk by current information, ignoring future prediction. This paper proposes a predictive risk analysis and safe trajectory planning framework for intelligent and connected vehicles. This framework first predicts future trajectories of objects by a local risk-aware algorithm, following with a spatiotemporal-discretised predictive risk analysis using the prediction results. Then the safe trajectory is generated based on the predictive risk analysis. Finally, simulation and vehicle experiments confirm the efficacy and real-time practicability of our approach.",
      "authors": [
        "Zeyu Han",
        "Mengchi Cai",
        "Chaoyi Chen",
        "Qingwen Meng",
        "Guangwei Wang",
        "Ying Liu",
        "Qing Xu",
        "Jianqiang Wang",
        "Keqiang Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:02:54+00:00",
          "link": "https://arxiv.org/abs/2506.23999v1",
          "size": "19544kb",
          "version": "v1"
        }
      ],
      "title": "Predictive Risk Analysis and Safe Trajectory Planning for Intelligent and Connected Vehicles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23999",
        "HTML": "https://arxiv.org/html/2506.23999v1",
        "PDF": "https://arxiv.org/pdf/2506.23999"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24000",
      "abstract": "Test-time adaptation (TTA) methods have gained significant attention for enhancing the performance of vision-language models (VLMs) such as CLIP during inference, without requiring additional labeled data. However, current TTA researches generally suffer from major limitations such as duplication of baseline results, limited evaluation metrics, inconsistent experimental settings, and insufficient analysis. These problems hinder fair comparisons between TTA methods and obscure their practical strengths and weaknesses. To address these challenges, we introduce TTA-VLM, a comprehensive benchmark for evaluating TTA methods on VLMs. Our benchmark implements 8 episodic TTA and 7 online TTA methods within a unified and reproducible framework, and evaluates them across 15 widely used datasets. Unlike prior studies focused solely on CLIP, we extend the evaluation to SigLIP--a model trained with a Sigmoid loss--and include training-time tuning methods such as CoOp, MaPLe, and TeCoA to assess generality. Beyond classification accuracy, TTA-VLM incorporates various evaluation metrics, including robustness, calibration, out-of-distribution detection, and stability, enabling a more holistic assessment of TTA methods. Through extensive experiments, we find that 1) existing TTA methods produce limited gains compared to the previous pioneering work; 2) current TTA methods exhibit poor collaboration with training-time fine-tuning methods; 3) accuracy gains frequently come at the cost of reduced model trustworthiness. We release TTA-VLM to provide fair comparison and comprehensive evaluation of TTA methods for VLMs, and we hope it encourages the community to develop more reliable and generalizable TTA strategies.",
      "authors": [
        "Lijun Sheng",
        "Jian Liang",
        "Ran He",
        "Zilei Wang",
        "Tieniu Tan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:05:55+00:00",
          "link": "https://arxiv.org/abs/2506.24000v1",
          "size": "83kb",
          "version": "v1"
        }
      ],
      "title": "The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24000",
        "HTML": "https://arxiv.org/html/2506.24000v1",
        "PDF": "https://arxiv.org/pdf/2506.24000"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24001",
      "abstract": "Parameterized local search combines classic local search heuristics with the paradigm of parameterized algorithmics. While most local search algorithms aim to improve given solutions by performing one single operation on a given solution, the parameterized approach aims to improve a solution by performing $k$ simultaneous operations. Herein, $k$ is a parameter called search radius for which the value can be chosen by a user. One major goal in the field of parameterized local search is to outline the trade-off between the size of $k$ and the running time of the local search step. In this work, we introduce an abstract framework that generalizes natural parameterized local search approaches for a large class of partitioning problems: Given $n$ items that are partitioned into $b$ bins and a target function that evaluates the quality of the current partition, one asks whether it is possible to improve the solution by removing up to $k$ items from their current bins and reassigning them to other bins. Among others, our framework applies for the local search versions of problems like Cluster Editing, Vector Bin Packing, and Nash Social Welfare. Motivated by a real-world application of the problem Vector Bin Packing, we introduce a parameter called number of types $\\tau \\le n$ and show that all problems fitting in our framework can be solved in $\\tau^k 2^{O(k)} |I|^{O(1)}$ time, where $|I|$ denotes the total input size. In case of Cluster Editing, the parameter $\\tau$ generalizes the well-known parameter neighborhood diversity of the input graph. We complement this by showing that for all considered problems, an algorithm significantly improving over our algorithm with running time $\\tau^k 2^{O(k)} |I|^{O(1)}$ would contradict the ETH. Additionally, we show that even on very restricted instances, all considered problems are W[1]-hard when parameterized by the search radius $k$ alone.",
      "authors": [
        "Niels Gr\\\"uttemeier",
        "Nils Morawietz",
        "Frank Sommer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:05:56+00:00",
          "link": "https://arxiv.org/abs/2506.24001v1",
          "size": "245kb",
          "version": "v1"
        }
      ],
      "title": "Fantastic Flips and Where to Find Them: A General Framework for Parameterized Local Search on Partitioning Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24001",
        "HTML": "https://arxiv.org/html/2506.24001v1",
        "PDF": "https://arxiv.org/pdf/2506.24001"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24005",
      "abstract": "While Bayesian-based exploration often demonstrates superior empirical performance compared to bonus-based methods in model-based reinforcement learning (RL), its theoretical understanding remains limited for model-free settings. Existing provable algorithms either suffer from computational intractability or rely on stage-wise policy updates which reduce responsiveness and slow down the learning process. In this paper, we propose a novel variant of Q-learning algorithm, refereed to as RandomizedQ, which integrates sampling-based exploration with agile, step-wise, policy updates, for episodic tabular RL. We establish an $\\widetilde{O}(\\sqrt{H^5SAT})$ regret bound, where $S$ is the number of states, $A$ is the number of actions, $H$ is the episode length, and $T$ is the total number of episodes. In addition, we present a logarithmic regret bound under a mild positive sub-optimality condition on the optimal Q-function. Empirically, RandomizedQ exhibits outstanding performance compared to existing Q-learning variants with both bonus-based and Bayesian-based exploration on standard benchmarks.",
      "authors": [
        "He Wang",
        "Xingyu Xu",
        "Yuejie Chi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:08:29+00:00",
          "link": "https://arxiv.org/abs/2506.24005v1",
          "size": "8925kb",
          "version": "v1"
        }
      ],
      "title": "Provably Efficient and Agile Randomized Q-Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24005",
        "HTML": "https://arxiv.org/html/2506.24005v1",
        "PDF": "https://arxiv.org/pdf/2506.24005"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24006",
      "abstract": "The progress of Large Language Models (LLMs) like ChatGPT raises the question of how they can be integrated into education. One hope is that they can support mathematics learning, including word-problem solving. Since LLMs can handle textual input with ease, they appear well-suited for solving mathematical word problems. Yet their real competence, whether they can make sense of the real-world context, and the implications for classrooms remain unclear. We conducted a scoping review from a mathematics-education perspective, including three parts: a technical overview, a systematic review of word problems used in research, and a state-of-the-art empirical evaluation of LLMs on mathematical word problems. First, in the technical overview, we contrast the conceptualization of word problems and their solution processes between LLMs and students. In computer-science research this is typically labeled mathematical reasoning, a term that does not align with usage in mathematics education. Second, our literature review of 213 studies shows that the most popular word-problem corpora are dominated by s-problems, which do not require a consideration of realities of their real-world context. Finally, our evaluation of GPT-3.5-turbo, GPT-4o-mini, GPT-4.1, and o3 on 287 word problems shows that most recent LLMs solve these s-problems with near-perfect accuracy, including a perfect score on 20 problems from PISA. LLMs still showed weaknesses in tackling problems where the real-world context is problematic or non-sensical. In sum, we argue based on all three aspects that LLMs have mastered a superficial solution process but do not make sense of word problems, which potentially limits their value as instructional tools in mathematics classrooms.",
      "authors": [
        "Anselm R. Strohmaier",
        "Wim Van Dooren",
        "Kathrin Se{\\ss}ler",
        "Brian Greer",
        "Lieven Verschaffel"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "History and Overview (math.HO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:10:42+00:00",
          "link": "https://arxiv.org/abs/2506.24006v1",
          "size": "383kb",
          "version": "v1"
        }
      ],
      "title": "Large Language Models Don't Make Sense of Word Problems. A Scoping Review from a Mathematics Education Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24006",
        "PDF": "https://arxiv.org/pdf/2506.24006"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24009",
      "abstract": "Large artificial intelligence (AI) models offer revolutionary potential for future wireless systems, promising unprecedented capabilities in network optimization and performance. However, current paradigms largely overlook crucial physical interactions. This oversight means they primarily rely on offline datasets, leading to difficulties in handling real-time wireless dynamics and non-stationary environments. Furthermore, these models often lack the capability for active environmental probing. This paper proposes a fundamental paradigm shift towards wireless embodied large AI (WELAI), moving from passive observation to active embodiment. We first identify key challenges faced by existing models, then we explore the design principles and system structure of WELAI. Besides, we outline prospective applications in next-generation wireless. Finally, through an illustrative case study, we demonstrate the effectiveness of WELAI and point out promising research directions for realizing adaptive, robust, and autonomous wireless systems.",
      "authors": [
        "Xinquan Wang",
        "Fenghao Zhu",
        "Zhaohui Yang",
        "Chongwen Huang",
        "Xiaoming Chen",
        "Zhaoyang Zhang",
        "Sami Muhaidat and M\\'erouane Debbah"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Artificial Intelligence (cs.AI)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:13:55+00:00",
          "link": "https://arxiv.org/abs/2506.24009v1",
          "size": "1037kb",
          "version": "v1"
        }
      ],
      "title": "Bridging Physical and Digital Worlds: Embodied Large AI for Future Wireless Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24009",
        "HTML": "https://arxiv.org/html/2506.24009v1",
        "PDF": "https://arxiv.org/pdf/2506.24009"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24015",
      "abstract": "Prompting LLMs with bug-related context (e.g., error messages, stack traces) improves automated program repair, but many bugs still remain unresolved. In real-world projects, developers often rely on broader repository and project-level context beyond the local code to resolve such bugs. In this paper, we investigate how automatically extracting and providing such knowledge can improve LLM-based program repair. We propose a layered knowledge injection framework that incrementally augments LLMs with structured context. It starts with the Bug Knowledge Layer, which includes information such as the buggy function and failing tests; expands to the Repository Knowledge Layer, which adds structural dependencies, related files, and commit history; and finally injects the Project Knowledge Layer, which incorporates relevant details from documentation and previously fixed bugs. We evaluate this framework on a dataset of 314 bugs from BugsInPy using two LLMs (Llama 3.3 and GPT-4o-mini), and analyze fix rates across six bug types. By progressively injecting knowledge across layers, our approach achieves a fix rate of 79% (250/314) using Llama 3.3, a significant improvement of 23% over previous work. All bug types show improvement with the addition of repository-level context, while only a subset benefit further from project-level knowledge, highlighting that different bug types require different levels of contextual information for effective repair. We also analyze the remaining unresolved bugs and find that more complex and structurally isolated bugs, such as Program Anomaly and GUI bugs, remain difficult even after injecting all available information. Our results show that layered context injection improves program repair and suggest the need for interactive and adaptive APR systems.",
      "authors": [
        "Ramtin Ehsani",
        "Esteban Parra",
        "Sonia Haiduc",
        "Preetha Chatterjee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:19:38+00:00",
          "link": "https://arxiv.org/abs/2506.24015v1",
          "size": "4231kb",
          "version": "v1"
        }
      ],
      "title": "Bug Fixing with Broader Context: Enhancing LLM-Based Program Repair via Layered Knowledge Injection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24015",
        "HTML": "https://arxiv.org/html/2506.24015v1",
        "PDF": "https://arxiv.org/pdf/2506.24015"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24016",
      "abstract": "Recent advances in large language models and vision-language models have led to growing interest in explainable evaluation metrics for image captioning. However, these metrics generate explanations without standardized criteria, and the overall quality of the generated explanations remains unverified. In this paper, we propose EXPERT, a reference-free evaluation metric that provides structured explanations based on three fundamental criteria: fluency, relevance, and descriptiveness. By constructing large-scale datasets of high-quality structured explanations, we develop a two-stage evaluation template to effectively supervise a vision-language model for both scoring and explanation generation. EXPERT achieves state-of-the-art results on benchmark datasets while providing significantly higher-quality explanations than existing metrics, as validated through comprehensive human evaluation. Our code and datasets are available at https://github.com/hjkim811/EXPERT.",
      "authors": [
        "Hyunjong Kim",
        "Sangyeop Kim",
        "Jongheon Jeong",
        "Yeongjae Cho",
        "Sungzoon Cho"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:20:51+00:00",
          "link": "https://arxiv.org/abs/2506.24016v1",
          "size": "6729kb",
          "version": "v1"
        }
      ],
      "title": "EXPERT: An Explainable Image Captioning Evaluation Metric with Structured Explanations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24016",
        "HTML": "https://arxiv.org/html/2506.24016v1",
        "PDF": "https://arxiv.org/pdf/2506.24016"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24017",
      "abstract": "In this paper, we focus on reducing node-to-node information exchange in distributed control of multiagent networks while improving the overall network performance. Specifically, we consider a multiagent network that is composed of leader and follower nodes over a time-varying, connected, and undirected graph. In contrast to existing works on the event-triggered distributed control literature, we propose a time-varying edge weight event-triggered control framework. In this framework, each node dynamically adjusts its edge weights by increasing them during the transient (active) phase and decreasing them during the steady-state (idle) phase of the multiagent network. This not only reduces the number of events in the network but also improves the performance (i.e., convergence speed and control effort) of the overall multiagent network. System-theoretically, we first prove the closed-loop stability of the proposed event-triggered distributed control framework, where we then show that this framework does not exhibit a Zeno behavior. Finally, illustrative numerical examples are provided to demonstrate the efficacy of this framework.",
      "authors": [
        "Emre Yildirim",
        "Tansel Yucelen",
        "Arman Sargolzaei"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:21:12+00:00",
          "link": "https://arxiv.org/abs/2506.24017v1",
          "size": "1539kb",
          "version": "v1"
        }
      ],
      "title": "Orchestrated Couplings: A Time-Varying Edge Weight Framework for Efficient Event-Triggered Multiagent Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24017",
        "HTML": "https://arxiv.org/html/2506.24017v1",
        "PDF": "https://arxiv.org/pdf/2506.24017"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24018",
      "abstract": "Graph Neural Networks (GNNs) are widely used to compute representations of node pairs for downstream tasks such as link prediction. Yet, theoretical understanding of their expressive power has focused almost entirely on graph-level representations. In this work, we shift the focus to links and provide the first comprehensive study of GNN expressiveness in link representation. We introduce a unifying framework, the $k_\\phi$-$k_\\rho$-$m$ framework, that subsumes existing message-passing link models and enables formal expressiveness comparisons. Using this framework, we derive a hierarchy of state-of-the-art methods and offer theoretical tools to analyze future architectures. To complement our analysis, we propose a synthetic evaluation protocol comprising the first benchmark specifically designed to assess link-level expressiveness. Finally, we ask: does expressiveness matter in practice? We use a graph symmetry metric that quantifies the difficulty of distinguishing links and show that while expressive models may underperform on standard benchmarks, they significantly outperform simpler ones as symmetry increases, highlighting the need for dataset-aware model selection.",
      "authors": [
        "Veronica Lachi",
        "Francesco Ferrini",
        "Antonio Longa",
        "Bruno Lepri",
        "Andrea Passerini",
        "Manfred Jaeger"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:22:15+00:00",
          "link": "https://arxiv.org/abs/2506.24018v1",
          "size": "103kb",
          "version": "v1"
        }
      ],
      "title": "Bridging Theory and Practice in Link Representation with Graph Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24018",
        "HTML": "https://arxiv.org/html/2506.24018v1",
        "PDF": "https://arxiv.org/pdf/2506.24018"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24019",
      "abstract": "We introduce Ella, an embodied social agent capable of lifelong learning within a community in a 3D open world, where agents accumulate experiences and acquire knowledge through everyday visual observations and social interactions. At the core of Ella's capabilities is a structured, long-term multimodal memory system that stores, updates, and retrieves information effectively. It consists of a name-centric semantic memory for organizing acquired knowledge and a spatiotemporal episodic memory for capturing multimodal experiences. By integrating this lifelong memory system with foundation models, Ella retrieves relevant information for decision-making, plans daily activities, builds social relationships, and evolves autonomously while coexisting with other intelligent beings in the open world. We conduct capability-oriented evaluations in a dynamic 3D open world where 15 agents engage in social activities for days and are assessed with a suite of unseen controlled evaluations. Experimental results show that Ella can influence, lead, and cooperate with other agents well to achieve goals, showcasing its ability to learn effectively through observation and social interaction. Our findings highlight the transformative potential of combining structured memory systems with foundation models for advancing embodied intelligence. More videos can be found at https://umass-embodied-agi.github.io/Ella/.",
      "authors": [
        "Hongxin Zhang",
        "Zheyuan Zhang",
        "Zeyuan Wang",
        "Zunzhe Zhang",
        "Lixing Fang",
        "Qinhong Zhou",
        "Chuang Gan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:22:51+00:00",
          "link": "https://arxiv.org/abs/2506.24019v1",
          "size": "11233kb",
          "version": "v1"
        }
      ],
      "title": "Ella: Embodied Social Agents with Lifelong Memory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24019",
        "HTML": "https://arxiv.org/html/2506.24019v1",
        "PDF": "https://arxiv.org/pdf/2506.24019"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24026",
      "abstract": "In the domain of algorithmic decision-making, non-Markovian dynamics manifest as a significant impediment, especially for paradigms such as Reinforcement Learning (RL), thereby exerting far-reaching consequences on the advancement and effectiveness of the associated systems. Nevertheless, the existing benchmarks are deficient in comprehensively assessing the capacity of decision algorithms to handle non-Markovian dynamics. To address this deficiency, we have devised a generalized methodology grounded in category theory. Notably, we established the category of Markov Decision Processes (MDP) and the category of non-Markovian Decision Processes (NMDP), and proved the equivalence relationship between them. This theoretical foundation provides a novel perspective for understanding and addressing non-Markovian dynamics. We further introduced non-Markovianity into decision-making problem settings via the History Aggregator for State (HAS). With HAS, we can precisely control the state dependency structure of decision-making problems in the time series. Our analysis demonstrates the effectiveness of our method in representing a broad range of non-Markovian dynamics. This approach facilitates a more rigorous and flexible evaluation of decision algorithms by testing them in problem settings where non-Markovian dynamics are explicitly constructed.",
      "authors": [
        "Yongyi Wang",
        "Wenxin Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:32:31+00:00",
          "link": "https://arxiv.org/abs/2506.24026v1",
          "size": "762kb",
          "version": "v1"
        }
      ],
      "title": "Constructing Non-Markovian Decision Process via History Aggregator",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24026",
        "HTML": "https://arxiv.org/html/2506.24026v1",
        "PDF": "https://arxiv.org/pdf/2506.24026"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24032",
      "abstract": "In a large-scale network, we want to choose some influential nodes to make a profit by paying some cost within a limited budget so that we do not have to spend more budget on some nodes adjacent to the chosen nodes; our problem is the graph-theoretic representation of it. We define our problem Dominating Set Knapsack by attaching Knapsack Problem with Dominating Set on graphs. Each vertex is associated with a cost factor and a profit amount. We aim to choose some vertices within a fixed budget that gives maximum profit so that we do not need to choose their 1-hop neighbors. We show that the Dominating Set Knapsack problem is strongly NP-complete even when restricted to Bipartite graphs but weakly NP-complete for Star graphs. We present a pseudo-polynomial time algorithm for Trees in time $O(n\\cdot min\\{s^2, (\\alpha(V))^2\\})$. We show that Dominating Set Knapsack is very unlikely to be Fixed Parameter Tractable(FPT) by proving that it is in W[2]-hard parameterized by the solution size. We developed FPT algorithms with running time $O(4^{tw}\\cdot n^{O(1)} \\cdot min\\{s^2,{\\alpha(V)}^2\\})$ and $O(2^{vck-1}\\cdot n^{O(1)} \\cdot min\\{s^2,{\\alpha(V)}^2\\})$, where $tw$ represents the treewidth of the given graph, $vck$ is the solution size of the Vertex Cover Knapsack, $s$ is the size of the knapsack and $\\alpha(V)=\\sum_{v\\in V}\\alpha(v)$.",
      "authors": [
        "Sipra Singh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:36:25+00:00",
          "link": "https://arxiv.org/abs/2506.24032v1",
          "size": "2364kb",
          "version": "v1"
        }
      ],
      "title": "Dominating Set Knapsack: Profit Optimization on Dominating Sets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24032",
        "HTML": "https://arxiv.org/html/2506.24032v1",
        "PDF": "https://arxiv.org/pdf/2506.24032"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24033",
      "abstract": "Local differential privacy (LDP) involves users perturbing their inputs to provide plausible deniability of their data. However, this also makes LDP vulnerable to poisoning attacks. In this paper, we first introduce novel poisoning attacks for ranking estimation. These attacks are intricate, as fake attackers do not merely adjust the frequency of target items. Instead, they leverage a limited number of fake users to precisely modify frequencies, effectively altering item rankings to maximize gains. To tackle this challenge, we introduce the concepts of attack cost and optimal attack item (set), and propose corresponding strategies for kRR, OUE, and OLH protocols. For kRR, we iteratively select optimal attack items and allocate suitable fake users. For OUE, we iteratively determine optimal attack item sets and consider the incremental changes in item frequencies across different sets. Regarding OLH, we develop a harmonic cost function based on the pre-image of a hash to select that supporting a larger number of effective attack items. Lastly, we present an attack strategy based on confidence levels to quantify the probability of a successful attack and the number of attack iterations more precisely. We demonstrate the effectiveness of our attacks through theoretical and empirical evidence, highlighting the necessity for defenses against these attacks. The source code and data have been made available at https://github.com/LDP-user/LDP-Ranking.git.",
      "authors": [
        "Pei Zhan (1",
        "2 and 3)",
        "Peng Tang (1",
        "2 and 3)",
        "Yangzhuo Li (1 and 3)",
        "Puwen Wei (1 and 3) and Shanqing Guo (1 and 3) ((1) School of Cyber Science and Technology",
        "Shandong University",
        "(2) Quan Cheng Laboratory",
        "Jinan",
        "China",
        "(3) State Key Laboratory of Cryptography and Digital Economy Security",
        "Shandong University",
        "Qingdao",
        "China)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:39:02+00:00",
          "link": "https://arxiv.org/abs/2506.24033v1",
          "size": "785kb",
          "version": "v1"
        }
      ],
      "title": "Poisoning Attacks to Local Differential Privacy for Ranking Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24033",
        "HTML": "https://arxiv.org/html/2506.24033v1",
        "PDF": "https://arxiv.org/pdf/2506.24033"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24039",
      "abstract": "Zero-shot and prompt-based technologies capitalized on using frequently occurring images to transform visual reasoning tasks, which explains why such technologies struggle with valuable yet scarce scientific image sets. In this work, we propose Zenesis, a comprehensive no-code interactive platform designed to minimize barriers posed by data readiness for scientific images. We develop lightweight multi-modal adaptation techniques that enable zero-shot operation on raw scientific data, along with human-in-the-loop refinement and heuristic-based temporal enhancement options. We demonstrate the performance of our approach through comprehensive comparison and validation on challenging Focused Ion Beam Scanning Electron Microscopy (FIB-SEM) data of catalyst-loaded membranes. Zenesis significantly outperforms baseline methods, achieving an average accuracy of 0.947, an Intersection over Union (IOU) of 0.858, and a Dice score of 0.923 for amorphous catalyst samples and accuracy of 0.987, an IOU of 0.857, and a Dice score of 0.923 for crystalline samples. These results mark a substantial improvement over traditional methods like Otsu thresholding and even advanced models like Segment Anything Model (SAM) when used in isolation. Our results demonstrate that Zenesis is a powerful tool for scientific applications, particularly in fields where high-quality annotated datasets are unavailable, accelerating accurate analysis of experimental imaging.",
      "authors": [
        "Shubhabrata Mukherjee",
        "Jack Lang",
        "Obeen Kwon",
        "Iryna Zenyuk",
        "Valerie Brogden",
        "Adam Weber",
        "and Daniela Ushizima"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:45:23+00:00",
          "link": "https://arxiv.org/abs/2506.24039v1",
          "size": "8574kb",
          "version": "v1"
        }
      ],
      "title": "Foundation Models for Zero-Shot Segmentation of Scientific Images without AI-Ready Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24039",
        "HTML": "https://arxiv.org/html/2506.24039v1",
        "PDF": "https://arxiv.org/pdf/2506.24039"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24040",
      "abstract": "We consider correlated equilibria in strategic games in an adversarial environment, where an adversary can compromise the public signal used by the players for choosing their strategies, while players aim at detecting a potential attack as soon as possible to avoid loss of utility. We model the interaction between the adversary and the players as a zero-sum game and we derive the maxmin strategies for both the defender and the attacker using the framework of quickest change detection. We define a class of adversarial strategies that achieve the optimal trade-off between attack impact and attack detectability and show that a generalized CUSUM scheme is asymptotically optimal for the detection of the attacks. Our numerical results on the Sioux-Falls benchmark traffic routing game show that the proposed detection scheme can effectively limit the utility loss by a potential adversary.",
      "authors": [
        "Kiarash Kazari",
        "Aris Kanellopoulos",
        "Gy\\\"orgy D\\'an"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:45:53+00:00",
          "link": "https://arxiv.org/abs/2506.24040v1",
          "size": "265kb",
          "version": "v1"
        }
      ],
      "title": "Quickest Detection of Adversarial Attacks Against Correlated Equilibria",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24040",
        "HTML": "https://arxiv.org/html/2506.24040v1",
        "PDF": "https://arxiv.org/pdf/2506.24040"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24041",
      "abstract": "Spike sorting is a crucial step in decoding multichannel extracellular neural signals, enabling the identification of individual neuronal activity. A key challenge in brain-machine interfaces (BMIs) is achieving real-time, low-power spike sorting at the edge while keeping high neural decoding performance. This study introduces the Neuromorphic Sparse Sorter (NSS), a compact two-layer spiking neural network optimized for efficient spike sorting. NSS leverages the Locally Competitive Algorithm (LCA) for sparse coding to extract relevant features from noisy events with reduced computational demands. NSS learns to sort detected spike waveforms in an online fashion and operates entirely unsupervised. To exploit multi-bit spike coding capabilities of neuromorphic platforms like Intel's Loihi 2, a custom neuron model was implemented, enabling flexible power-performance trade-offs via adjustable spike bit-widths. Evaluations on simulated and real-world tetrode signals with biological drift showed NSS outperformed established pipelines such as WaveClus3 and PCA+KMeans. With 2-bit graded spikes, NSS on Loihi 2 outperformed NSS implemented with leaky integrate-and-fire neuron and achieved an F1-score of 77% (+10% improvement) while consuming 8.6mW (+1.65mW) when tested on a drifting recording, with a computational processing time of 0.25ms (+60 us) per inference.",
      "authors": [
        "Alexis Melot",
        "Sean U.N. Wood",
        "Yannick Coffinier",
        "Pierre Yger and Fabien Alibart"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:48:49+00:00",
          "link": "https://arxiv.org/abs/2506.24041v1",
          "size": "1879kb",
          "version": "v1"
        }
      ],
      "title": "Unsupervised Sparse Coding-based Spiking Neural Network for Real-time Spike Sorting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24041",
        "PDF": "https://arxiv.org/pdf/2506.24041"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24042",
      "abstract": "In this paper, we explore provable acceleration of diffusion models without any additional retraining. Focusing on the task of approximating a target data distribution in $\\mathbb{R}^d$ to within $\\varepsilon$ total-variation distance, we propose a principled, training-free sampling algorithm that requires only the order of\n  $$ d^{1+2/K} \\varepsilon^{-1/K} $$\n  score function evaluations (up to log factor) in the presence of accurate scores, where $K$ is an arbitrarily large fixed integer. This result applies to a broad class of target data distributions, without the need for assumptions such as smoothness or log-concavity. Our theory is robust vis-a-vis inexact score estimation, degrading gracefully as the score estimation error increases -- without demanding higher-order smoothness on the score estimates as assumed in previous work. The proposed algorithm draws insight from high-order ODE solvers, leveraging high-order Lagrange interpolation and successive refinement to approximate the integral derived from the probability flow ODE.",
      "authors": [
        "Gen Li",
        "Yuchen Zhou",
        "Yuting Wei",
        "Yuxin Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Statistics Theory (math.ST)",
        "Machine Learning (stat.ML)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:49:03+00:00",
          "link": "https://arxiv.org/abs/2506.24042v1",
          "size": "66kb",
          "version": "v1"
        }
      ],
      "title": "Faster Diffusion Models via Higher-Order Approximation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24042",
        "HTML": "https://arxiv.org/html/2506.24042v1",
        "PDF": "https://arxiv.org/pdf/2506.24042"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24044",
      "abstract": "The rapid progress of multimodal large language models (MLLM) has paved the way for Vision-Language-Action (VLA) paradigms, which integrate visual perception, natural language understanding, and control within a single policy. Researchers in autonomous driving are actively adapting these methods to the vehicle domain. Such models promise autonomous vehicles that can interpret high-level instructions, reason about complex traffic scenes, and make their own decisions. However, the literature remains fragmented and is rapidly expanding. This survey offers the first comprehensive overview of VLA for Autonomous Driving (VLA4AD). We (i) formalize the architectural building blocks shared across recent work, (ii) trace the evolution from early explainer to reasoning-centric VLA models, and (iii) compare over 20 representative models according to VLA's progress in the autonomous driving domain. We also consolidate existing datasets and benchmarks, highlighting protocols that jointly measure driving safety, accuracy, and explanation quality. Finally, we detail open challenges - robustness, real-time efficiency, and formal verification - and outline future directions of VLA4AD. This survey provides a concise yet complete reference for advancing interpretable socially aligned autonomous vehicles. Github repo is available at \\href{https://github.com/JohnsonJiang1996/Awesome-VLA4AD}{SicongJiang/Awesome-VLA4AD}.",
      "authors": [
        "Sicong Jiang",
        "Zilin Huang",
        "Kangan Qian",
        "Ziang Luo",
        "Tianze Zhu",
        "Yang Zhong",
        "Yihong Tang",
        "Menglin Kong",
        "Yunlong Wang",
        "Siwen Jiao",
        "Hao Ye",
        "Zihao Sheng",
        "Xin Zhao",
        "Tuopu Wen",
        "Zheng Fu",
        "Sikai Chen",
        "Kun Jiang",
        "Diange Yang",
        "Seongjin Choi",
        "Lijun Sun"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:50:02+00:00",
          "link": "https://arxiv.org/abs/2506.24044v1",
          "size": "442kb",
          "version": "v1"
        }
      ],
      "title": "A Survey on Vision-Language-Action Models for Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24044",
        "HTML": "https://arxiv.org/html/2506.24044v1",
        "PDF": "https://arxiv.org/pdf/2506.24044"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24045",
      "abstract": "The proliferation of agentic Large Language Models (LLMs) on personal devices introduces a new class of workloads characterized by a dichotomy of objectives. Reactive tasks, initiated by users, demand immediate, low-latency responses, while proactive tasks operate invisibly and prioritize throughput. Existing on-device LLM engines, designed for isolated inferences, fail to efficiently manage these concurrent and conflicting requests on consumer-grade heterogeneous SoCs with CPU, integrated GPU, and NPU. This paper introduces Agent.xpu, an efficient serving system for agentic LLM workloads on memory-unified heterogeneous SoCs. With dedicated offline profiling, Agent.xpu first constructs a heterogeneous execution graph, which fuses and chunks model kernels for affinity-guided, elastic accelerator mapping with predictive kernel annotation. At runtime, its online scheduler enables fine-grained, kernel-level preemption to guarantee the responsiveness of reactive tasks. To maximize SoC utilization, it adopts slack-aware kernel backfill to opportunistically append proactive tasks, and mitigates NPU-iGPU contention via bandwidth-aware dispatch. Evaluation on an Intel Core Ultra SoC shows that Agent.xpu achieves 4.6$\\times$ lower latency for reactive tasks and sustains 1.6$\\times$-6.8$\\times$ higher throughput for proactive tasks compared to state-of-the-art inference engines.",
      "authors": [
        "Xinming Wei",
        "Jiahao Zhang",
        "Haoran Li",
        "Jiayu Chen",
        "Rui Qu",
        "Maoliang Li",
        "Xiang Chen",
        "Guojie Luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:50:48+00:00",
          "link": "https://arxiv.org/abs/2506.24045v1",
          "size": "662kb",
          "version": "v1"
        }
      ],
      "title": "Agent.xpu: Efficient Scheduling of Agentic LLM Workloads on Heterogeneous SoC",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24045",
        "HTML": "https://arxiv.org/html/2506.24045v1",
        "PDF": "https://arxiv.org/pdf/2506.24045"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24046",
      "abstract": "New endoscopists require a large volume of expert-proctored colonoscopies to attain minimal competency. Developing multi-fingered, synchronized control of a colonoscope requires significant time and exposure to the device. Current training methods inhibit this development by relying on tool hand-off for expert demonstrations. There is a need for colonoscopy training tools that enable in-hand expert guidance in real-time. We present a new concept of a tandem training system that uses a telemanipulated preceptor colonoscope to guide novice users as they perform a colonoscopy. This system is capable of dual-control and can automatically toggle between expert and novice control of a standard colonoscope's angulation control wheels. Preliminary results from a user study with novice and expert users show the effectiveness of this device as a skill acquisition tool. We believe that this device has the potential to accelerate skill acquisition for colonoscopy and, in the future, enable individualized instruction and responsive teaching through bidirectional actuation.",
      "authors": [
        "Olivia Richards",
        "Keith L. Obstein",
        "Nabil Simaan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:50:52+00:00",
          "link": "https://arxiv.org/abs/2506.24046v1",
          "size": "423kb",
          "version": "v1"
        }
      ],
      "title": "Exploring Accelerated Skill Acquisition via Tandem Training for Colonoscopy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24046",
        "PDF": "https://arxiv.org/pdf/2506.24046"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24052",
      "abstract": "We consider the problem of enumerating the irreducible closed sets of a closure system given by an implicational base. In the context of Horn logic, these correspond to Horn expressions and characteristic models, respectively. To date, the complexity status of this problem is widely open, and it is further known to generalize the notorious hypergraph dualization problem, even in the context of acyclic convex geometries, i.e., closure systems admitting an acyclic implicational base. This paper studies this later class with a focus on the degree, which corresponds to the maximal number of implications in which an element occurs. We show that the problem is tractable for bounded values of this parameter, even when relaxed to the notions of premise- and conclusion-degree. Our algorithms rely on structural properties of acyclic convex geometries and involve various techniques from algorithmic enumeration such as solution graph traversal, saturation techniques, and a sequential approach leveraging from acyclicity. They are shown to perform in incremental-polynomial time for the computation of irreducible closed sets, and in polynomial time for the construction of an implicational base. Finally, we argue that our running times cannot be improved to polynomial delay using the standard framework of flashlight search.",
      "authors": [
        "Oscar Defrain",
        "Arthur Ohana",
        "and Simon Vilmin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:59:12+00:00",
          "link": "https://arxiv.org/abs/2506.24052v1",
          "size": "216kb",
          "version": "v1"
        }
      ],
      "title": "Translating between the representations of an acyclic convex geometry of bounded degree",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24052",
        "HTML": "https://arxiv.org/html/2506.24052v1",
        "PDF": "https://arxiv.org/pdf/2506.24052"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24054",
      "abstract": "We study polynomial approximation on a $d$-cube, where $d$ is large, and compare interpolation on sparse grids, aka Smolyak's algorithm (SA), with a simple least squares method based on randomly generated points (LS) using standard benchmark functions. Our main motivation is the influential paper [Barthelmann, Novak, Ritter: High dimensional polynomial interpolation on sparse grids, Adv. Comput. Math. 12, 2000]. We repeat and extend their theoretical analysis and numerical experiments for SA and compare to LS in dimensions up to 100. Our extensive experiments demonstrate that LS, even with only slight oversampling, consistently matches the accuracy of SA in low dimensions. In high dimensions, however, LS shows clear superiority.",
      "authors": [
        "Jakob Eggl",
        "Elias Mindlberger",
        "Mario Ullrich"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:59:26+00:00",
          "link": "https://arxiv.org/abs/2506.24054v1",
          "size": "6376kb",
          "version": "v1"
        }
      ],
      "title": "Sparse grids vs. random points for high-dimensional polynomial approximation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24054",
        "HTML": "https://arxiv.org/html/2506.24054v1",
        "PDF": "https://arxiv.org/pdf/2506.24054"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24056",
      "abstract": "We introduce logit-gap steering, a fast jailbreak framework that casts the refusal-affirmation gap of RLHF-aligned language models as a single pass over the vocabulary. A forward-computable score blends gap reduction with lightweight proxies for KL penalty and reward shift, allowing a \"sort-sum-stop\" sweep to complete in under a second and return a short suffix--two orders of magnitude fewer model calls than beam or gradient attacks. The same suffix generalises to unseen prompts and scales from 0.5 B to 70 B checkpoints, lifting one-shot attack success from baseline levels to 80-100% while preserving topical coherence. Beyond efficiency, these suffixes expose sentence-boundary reward cliffs and other alignment artefacts, offering a lightweight probe into how safety tuning reshapes internal representations.",
      "authors": [
        "Tung-Ling Li",
        "Hongliang Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:01:18+00:00",
          "link": "https://arxiv.org/abs/2506.24056v1",
          "size": "456kb",
          "version": "v1"
        }
      ],
      "title": "Logit-Gap Steering: Efficient Short-Suffix Jailbreaks for Aligned Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24056",
        "HTML": "https://arxiv.org/html/2506.24056v1",
        "PDF": "https://arxiv.org/pdf/2506.24056"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24057",
      "abstract": "The popularity of accessibility research has grown recently, improving digital inclusion for people with disabilities. However, researchers, including those who have disabilities, have attempted to include people with disabilities in all aspects of design, and they have identified a myriad of practical accessibility barriers posed by tools and methods leveraged by human-computer interaction (HCI) researchers during prototyping. To build a more inclusive technological landscape, we must question the effectiveness of existing prototyping tools and methods, repurpose/retrofit existing resources, and build new tools and methods to support the participation of both researchers and people with disabilities within the prototyping design process of novel technologies. This full-day workshop at CHI 2025 will provide a platform for HCI researchers, designers, and practitioners to discuss barriers and opportunities for creating accessible prototyping and promote hands-on ideation and fabrication exercises aimed at futuring accessible prototyping.",
      "authors": [
        "Patricia Piedade",
        "Peter A Hayton",
        "Cynthia Bennett",
        "Anna R L Carter",
        "Clara Crivellaro",
        "Alan Dix",
        "Jess McGowan",
        "Katta Spiel",
        "Miriam Sturdee",
        "Garreth W. Tigwell",
        "Hugo Nicolau"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:03:19+00:00",
          "link": "https://arxiv.org/abs/2506.24057v1",
          "size": "81kb",
          "version": "v1"
        }
      ],
      "title": "Access InContext: Futuring Accessible Prototyping Tools and Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24057",
        "HTML": "https://arxiv.org/html/2506.24057v1",
        "PDF": "https://arxiv.org/pdf/2506.24057"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24060",
      "abstract": "We consider the coded caching system where each user, equipped with a private cache, accesses a distinct r-subset of access caches. A central server housing a library of files populates both private and access caches using uncoded placement. In this work, we focus on a constrained indexing regime, referred to as the intersection class, in which the sets used to index the demands of each user must have a nonempty intersection. This regime models resource-limited IoT scenarios such as edge-assisted IoT systems, where devices with small private caches connect to a small number of shared caches. We provide a necessary and sufficient condition under which the system parameters fall within this intersection class. Under this condition, we propose a centralized coded caching scheme and characterize its rate-memory trade-off. Next, we define a uniform-intersection subclass and establish a condition under which the system belongs to this subclass. Within this subclass, the proposed scheme has a regular structure, with each transmission benefiting the same number of users, and we characterize its rate-memory trade-off. Additionally, we derive an index coding-based lower bound on the minimum achievable worst-case rate under uncoded placement. Finally, we provide numerical comparisons between the rate of the proposed scheme, the new lower bound, and bounds from the original work.",
      "authors": [
        "Dhruv Pratap Singh",
        "Anjana A. Mahesh",
        "and B. Sundar Rajan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:07:59+00:00",
          "link": "https://arxiv.org/abs/2506.24060v1",
          "size": "153kb",
          "version": "v1"
        }
      ],
      "title": "Combinatorial Multi-Access Coded Caching with Private Caches under Intersecting Index Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24060",
        "HTML": "https://arxiv.org/html/2506.24060v1",
        "PDF": "https://arxiv.org/pdf/2506.24060"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24061",
      "abstract": "Human mobility in cities is shaped not only by visible structures such as highways, rivers, and parks but also by invisible barriers rooted in socioeconomic segregation, uneven access to amenities, and administrative divisions. Yet identifying and quantifying these barriers at scale and their relative importance on people's movements remains a major challenge. Neural embedding models, originally developed for language, offer a powerful way to capture the complexity of human mobility from large-scale data. Here, we apply this approach to 25.4 million observed trajectories across 11 major U.S. cities, learning mobility embeddings that reveal how people move through urban space. These mobility embeddings define a functional distance between places, one that reflects behavioral rather than physical proximity, and allow us to detect barriers between neighborhoods that are geographically close but behaviorally disconnected. We find that the strongest predictors of these barriers are differences in access to amenities, administrative borders, and residential segregation by income and race. These invisible borders are concentrated in urban cores and persist across cities, spatial scales, and time periods. Physical infrastructure, such as highways and parks, plays a secondary but still significant role, especially at short distances. We also find that individuals who cross barriers tend to do so outside of traditional commuting hours and are more likely to live in areas with greater racial diversity, and higher transit use or income. Together, these findings reveal how spatial, social, and behavioral forces structure urban accessibility and provide a scalable framework to detect and monitor barriers in cities, with applications in planning, policy evaluation, and equity analysis.",
      "authors": [
        "Guangyuan Weng",
        "Minsuk Kim",
        "Yong-Yeol Ahn",
        "Esteban Moro"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:08:26+00:00",
          "link": "https://arxiv.org/abs/2506.24061v1",
          "size": "17404kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Distance: Mobility Neural Embeddings Reveal Visible and Invisible Barriers in Urban Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24061",
        "HTML": "https://arxiv.org/html/2506.24061v1",
        "PDF": "https://arxiv.org/pdf/2506.24061"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24063",
      "abstract": "In practice, environments constantly change over time and space, posing significant challenges for object detectors trained based on a closed-set assumption, i.e., training and test data share the same distribution. To this end, continual test-time adaptation has attracted much attention, aiming to improve detectors' generalization by fine-tuning a few specific parameters, e.g., BatchNorm layers. However, based on a small number of test images, fine-tuning certain parameters may affect the representation ability of other fixed parameters, leading to performance degradation. Instead, we explore a new mechanism, i.e., converting the fine-tuning process to a specific-parameter generation. Particularly, we first design a dual-path LoRA-based domain-aware adapter that disentangles features into domain-invariant and domain-specific components, enabling efficient adaptation. Additionally, a conditional diffusion-based parameter generation mechanism is presented to synthesize the adapter's parameters based on the current environment, preventing the optimization from getting stuck in local optima. Finally, we propose a class-centered optimal transport alignment method to mitigate catastrophic forgetting. Extensive experiments conducted on various continuous domain adaptive object detection tasks demonstrate the effectiveness. Meanwhile, visualization results show that the representation extracted by the generated parameters can capture more object-related information and strengthen the generalization ability.",
      "authors": [
        "Deng Li",
        "Aming Wu",
        "Yang Li",
        "Yaowei Wang",
        "Yahong Han"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:14:12+00:00",
          "link": "https://arxiv.org/abs/2506.24063v1",
          "size": "1928kb",
          "version": "v1"
        }
      ],
      "title": "Continual Adaptation: Environment-Conditional Parameter Generation for Object Detection in Dynamic Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24063",
        "HTML": "https://arxiv.org/html/2506.24063v1",
        "PDF": "https://arxiv.org/pdf/2506.24063"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24068",
      "abstract": "Frontier AI developers are relying on layers of safeguards to protect against catastrophic misuse of AI systems. Anthropic guards their latest Claude 4 Opus model using one such defense pipeline, and other frontier developers including Google DeepMind and OpenAI pledge to soon deploy similar defenses. However, the security of such pipelines is unclear, with limited prior work evaluating or attacking these pipelines. We address this gap by developing and red-teaming an open-source defense pipeline. First, we find that a novel few-shot-prompted input and output classifier outperforms state-of-the-art open-weight safeguard model ShieldGemma across three attacks and two datasets, reducing the attack success rate (ASR) to 0% on the catastrophic misuse dataset ClearHarm. Second, we introduce a STaged AttaCK (STACK) procedure that achieves 71% ASR on ClearHarm in a black-box attack against the few-shot-prompted classifier pipeline. Finally, we also evaluate STACK in a transfer setting, achieving 33% ASR, providing initial evidence that it is feasible to design attacks with no access to the target pipeline. We conclude by suggesting specific mitigations that developers could use to thwart staged attacks.",
      "authors": [
        "Ian R. McKenzie",
        "Oskar J. Hollinsworth",
        "Tom Tseng",
        "Xander Davies",
        "Stephen Casper",
        "Aaron D. Tucker",
        "Robert Kirk",
        "Adam Gleave"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:21:08+00:00",
          "link": "https://arxiv.org/abs/2506.24068v1",
          "size": "744kb",
          "version": "v1"
        }
      ],
      "title": "STACK: Adversarial Attacks on LLM Safeguard Pipelines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24068",
        "HTML": "https://arxiv.org/html/2506.24068v1",
        "PDF": "https://arxiv.org/pdf/2506.24068"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24072",
      "abstract": "We present a different proof of the insecurity problem for XOR, solved in by Chevalier, Kuesters, Rusinowitch and Turuani (2005). Our proof uses the notion of typed terms and well-typed proofs, and removes a restriction on the class of protocols to which the [CKRT05] proof applies, by introducing a slightly different (but very natural) notion of protocols, where honest agent sends are derivable from previous receives in the same session.",
      "authors": [
        "R Ramanujam",
        "Vaishnavi Sundararajan",
        "S P Suresh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:22:57+00:00",
          "link": "https://arxiv.org/abs/2506.24072v1",
          "size": "15kb",
          "version": "v1"
        }
      ],
      "title": "Protocol insecurity with finitely many sessions and XOR",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24072",
        "PDF": "https://arxiv.org/pdf/2506.24072"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24083",
      "abstract": "This paper introduces a Time Shift Governor (TSG)-guided Model Predictive Controller with Control Barrier Functions (CBFs)-based constraints for adaptive cruise control (ACC). This MPC-CBF approach is defined for obstacle-free curved road tracking, while following distance and obstacle avoidance constraints are handled using standard CBFs and relaxed Collision Cone CBFs. In order to address scenarios involving rapidly moving obstacles or rapidly changing leading vehicle's behavior, the TSG augmentation is employed which alters the target reference to enforce constraints. Simulation results demonstrate the effectiveness of the TSG-guided MPC-CBF approach.",
      "authors": [
        "Robin Inho Kee",
        "Taehyeun Kim",
        "Anouck Girard",
        "Ilya Kolmanovsky"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:39:31+00:00",
          "link": "https://arxiv.org/abs/2506.24083v1",
          "size": "3867kb",
          "version": "v1"
        }
      ],
      "title": "Time Shift Governor-Guided MPC with Collision Cone CBFs for Safe Adaptive Cruise Control in Dynamic Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24083",
        "HTML": "https://arxiv.org/html/2506.24083v1",
        "PDF": "https://arxiv.org/pdf/2506.24083"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24085",
      "abstract": "Blending visual and textual concepts into a new visual concept is a unique and powerful trait of human beings that can fuel creativity. However, in practice, cross-modal conceptual blending for humans is prone to cognitive biases, like design fixation, which leads to local minima in the design space. In this paper, we propose a T2I diffusion adapter \"IT-Blender\" that can automate the blending process to enhance human creativity. Prior works related to cross-modal conceptual blending are limited in encoding a real image without loss of details or in disentangling the image and text inputs. To address these gaps, IT-Blender leverages pretrained diffusion models (SD and FLUX) to blend the latent representations of a clean reference image with those of the noisy generated image. Combined with our novel blended attention, IT-Blender encodes the real reference image without loss of details and blends the visual concept with the object specified by the text in a disentangled way. Our experiment results show that IT-Blender outperforms the baselines by a large margin in blending visual and textual concepts, shedding light on the new application of image generative models to augment human creativity.",
      "authors": [
        "Wonwoong Cho",
        "Yanxia Zhang",
        "Yan-Ying Chen",
        "David I. Inouye"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:41:25+00:00",
          "link": "https://arxiv.org/abs/2506.24085v1",
          "size": "47161kb",
          "version": "v1"
        }
      ],
      "title": "Imagine for Me: Creative Conceptual Blending of Real Images and Text via Blended Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24085",
        "HTML": "https://arxiv.org/html/2506.24085v1",
        "PDF": "https://arxiv.org/pdf/2506.24085"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24086",
      "abstract": "Though recent advances in multimodal models have demonstrated strong capabilities and opportunities in unified understanding and generation, the development of unified motion-language models remains underexplored. To enable such models with high-fidelity human motion, two core challenges must be addressed. The first is the reconstruction gap between the continuous motion modality and discrete representation in an autoregressive manner, and the second is the degradation of language intelligence during unified training. Inspired by the mixture of experts, we propose MotionGPT3, a bimodal motion-language model that treats human motion as a second modality, decoupling motion modeling via separate model parameters and enabling both effective cross-modal interaction and efficient multimodal scaling training. To preserve language intelligence, the text branch retains the original structure and parameters of the pretrained language model, while a new motion branch is integrated via a shared attention mechanism, enabling bidirectional information flow between two modalities. We first employ a motion Variational Autoencoder (VAE) to encode raw human motion into latent representations. Based on this continuous latent space, the motion branch predicts motion latents directly from intermediate hidden states using a diffusion head, bypassing discrete tokenization. Extensive experiments show that our approach achieves competitive performance on both motion understanding and generation tasks while preserving strong language capabilities, establishing a unified bimodal motion diffusion framework within an autoregressive manner.",
      "authors": [
        "Bingfan Zhu",
        "Biao Jiang",
        "Sunyi Wang",
        "Shixiang Tang",
        "Tao Chen",
        "Linjie Luo",
        "Youyi Zheng",
        "Xin Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:42:22+00:00",
          "link": "https://arxiv.org/abs/2506.24086v1",
          "size": "2321kb",
          "version": "v1"
        }
      ],
      "title": "MotionGPT3: Human Motion as a Second Modality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24086",
        "HTML": "https://arxiv.org/html/2506.24086v1",
        "PDF": "https://arxiv.org/pdf/2506.24086"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24092",
      "abstract": "Parameter-efficient fine-tuning (PEFT) has gained widespread adoption across various applications. Among PEFT techniques, Low-Rank Adaptation (LoRA) and its extensions have emerged as particularly effective, allowing efficient model adaptation while significantly reducing computational overhead. However, existing approaches typically rely on global low-rank factorizations, which overlook local or multi-scale structure, failing to capture complex patterns in the weight updates. To address this, we propose WaRA, a novel PEFT method that leverages wavelet transforms to decompose the weight update matrix into a multi-resolution representation. By performing low-rank factorization in the wavelet domain and reconstructing updates through an inverse transform, WaRA obtains compressed adaptation parameters that harness multi-resolution analysis, enabling it to capture both coarse and fine-grained features while providing greater flexibility and sparser representations than standard LoRA. Through comprehensive experiments and analysis, we demonstrate that WaRA performs superior on diverse vision tasks, including image generation, classification, and semantic segmentation, significantly enhancing generated image quality while reducing computational complexity. Although WaRA was primarily designed for vision tasks, we further showcase its effectiveness in language tasks, highlighting its broader applicability and generalizability. The code is publicly available at \\href{GitHub}{https://github.com/moeinheidari7829/WaRA}.",
      "authors": [
        "Moein Heidari",
        "Yasamin Medghalchi",
        "Mahdi Khoursha",
        "Reza Rezaeian",
        "Ilker Hacihaliloglu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T07:31:40+00:00",
          "link": "https://arxiv.org/abs/2506.24092v1",
          "size": "51172kb",
          "version": "v1"
        }
      ],
      "title": "WaRA: Wavelet Low Rank Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24092",
        "HTML": "https://arxiv.org/html/2506.24092v1",
        "PDF": "https://arxiv.org/pdf/2506.24092"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24093",
      "abstract": "Synthetic data has emerged as a cost-effective alternative to real data for training artificial neural networks (ANN). However, the disparity between synthetic and real data results in a domain gap. That gap leads to poor performance and generalization of the trained ANN when applied to real-world scenarios. Several strategies have been developed to bridge this gap, which combine synthetic and real data, known as mixed training using hybrid datasets. While these strategies have been shown to mitigate the domain gap, a systematic evaluation of their generalizability and robustness across various tasks and architectures remains underexplored. To address this challenge, our study comprehensively analyzes two widely used mixing strategies on three prevalent architectures and three distinct hybrid datasets. From these datasets, we sample subsets with varying proportions of synthetic to real data to investigate the impact of synthetic and real components. The findings of this paper provide valuable insights into optimizing the use of synthetic data in the training process of any ANN, contributing to enhancing robustness and efficacy.",
      "authors": [
        "Paul Wachter and Lukas Niehaus and Julius Sch\\\"oning"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:48:14+00:00",
          "link": "https://arxiv.org/abs/2506.24093v1",
          "size": "229kb",
          "version": "v1"
        }
      ],
      "title": "Development of Hybrid Artificial Intelligence Training on Real and Synthetic Data: Benchmark on Two Mixed Training Strategies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24093",
        "HTML": "https://arxiv.org/html/2506.24093v1",
        "PDF": "https://arxiv.org/pdf/2506.24093"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24096",
      "abstract": "While recent advances in Gaussian Splatting have enabled fast reconstruction of high-quality 3D scenes from images, extracting accurate surface meshes remains a challenge. Current approaches extract the surface through costly post-processing steps, resulting in the loss of fine geometric details or requiring significant time and leading to very dense meshes with millions of vertices. More fundamentally, the a posteriori conversion from a volumetric to a surface representation limits the ability of the final mesh to preserve all geometric structures captured during training. We present MILo, a novel Gaussian Splatting framework that bridges the gap between volumetric and surface representations by differentiably extracting a mesh from the 3D Gaussians. We design a fully differentiable procedure that constructs the mesh-including both vertex locations and connectivity-at every iteration directly from the parameters of the Gaussians, which are the only quantities optimized during training. Our method introduces three key technical contributions: a bidirectional consistency framework ensuring both representations-Gaussians and the extracted mesh-capture the same underlying geometry during training; an adaptive mesh extraction process performed at each training iteration, which uses Gaussians as differentiable pivots for Delaunay triangulation; a novel method for computing signed distance values from the 3D Gaussians that enables precise surface extraction while avoiding geometric erosion. Our approach can reconstruct complete scenes, including backgrounds, with state-of-the-art quality while requiring an order of magnitude fewer mesh vertices than previous methods. Due to their light weight and empty interior, our meshes are well suited for downstream applications such as physics simulations or animation.",
      "authors": [
        "Antoine Gu\\'edon",
        "Diego Gomez",
        "Nissim Maruani",
        "Bingchen Gong",
        "George Drettakis",
        "Maks Ovsjanikov"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:48:54+00:00",
          "link": "https://arxiv.org/abs/2506.24096v1",
          "size": "19736kb",
          "version": "v1"
        }
      ],
      "title": "MILo: Mesh-In-the-Loop Gaussian Splatting for Detailed and Efficient Surface Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24096",
        "HTML": "https://arxiv.org/html/2506.24096v1",
        "PDF": "https://arxiv.org/pdf/2506.24096"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24102",
      "abstract": "Multimodal Large Language Models (MLLMs) demonstrate a complex understanding of scenes, benefiting from large-scale and high-quality datasets. Most existing caption datasets lack the ground locations and relations for visual entities. Several grounded caption datasets face the problems of missing detailed descriptions, relations, and massive object descriptions on high-resolution images. To fill this gap for the community, we present DenseWorld-1M, the first massive, detailed, dense grounded caption dataset in the real world. We design a three-stage labeling pipeline, containing open-world perception, detailed object caption generation, and dense caption merging. The first stage obtains entity-level masks and labels. The second stage generates the object-level, detailed captions with the guidance of masks and labels from the first stage. The final stage merges object captions and masks into spatial and relational dense captions. To accelerate the labeling process and improve caption quality, we present two VLM models: the Detailed Region Caption model and the Spatial Caption Merging model. Extensive experiments on various settings, including vision-language understanding, visual grounding, and region caption generation, demonstrate the effectiveness of our DenseWorld-1M dataset and labeling models.",
      "authors": [
        "Xiangtai Li",
        "Tao Zhang",
        "Yanwei Li",
        "Haobo Yuan",
        "Shihao Chen",
        "Yikang Zhou",
        "Jiahao Meng",
        "Yueyi Sun",
        "Shilin Xu",
        "Lu Qi",
        "Tianheng Cheng",
        "Yi Lin",
        "Zilong Huang",
        "Wenhao Huang",
        "Jiashi Feng",
        "Guang Shi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:51:25+00:00",
          "link": "https://arxiv.org/abs/2506.24102v1",
          "size": "16151kb",
          "version": "v1"
        }
      ],
      "title": "DenseWorld-1M: Towards Detailed Dense Grounded Caption in the Real World",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24102",
        "HTML": "https://arxiv.org/html/2506.24102v1",
        "PDF": "https://arxiv.org/pdf/2506.24102"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24104",
      "abstract": "Digital twins (DT) are increasingly used in healthcare to model patients, processes, and physiological systems. While recent solutions leverage visualization, visual analytics, and user interaction, these systems rarely incorporate structured service design methodologies. Bridging service design with visual analytics and visualization can be valuable for the healthcare DT community. This paper aims to introduce the service design discipline to visualization researchers by framing this integration gap and suggesting research directions to enhance the real-world applicability of DT solutions.",
      "authors": [
        "Mariia Ershova and Graziano Blasilli"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:53:08+00:00",
          "link": "https://arxiv.org/abs/2506.24104v1",
          "size": "56kb",
          "version": "v1"
        }
      ],
      "title": "Bridging Service Design, Visualizations, and Visual Analytics in Healthcare Digital Twins: Challenges, Gaps, and Research Opportunities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24104",
        "HTML": "https://arxiv.org/html/2506.24104v1",
        "PDF": "https://arxiv.org/pdf/2506.24104"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24106",
      "abstract": "We show that a language model's ability to predict text is tightly linked to the breadth of its embedding space: models that spread their contextual representations more widely tend to achieve lower perplexity. Concretely, we find that representation dispersion - the average pairwise cosine distance among hidden vectors - strongly and negatively correlates with perplexity across diverse model families (LLaMA, Qwen, and others) and domains (Wikipedia, news, scientific abstracts). Beyond illustrating this link, we show how dispersion can be leveraged for a range of practical tasks without requiring labeled data. First, measuring dispersion on unlabeled text allows us to predict downstream accuracy in new domains, offering a data-efficient tool for model selection. Next, we find that identifying layers with higher dispersion pinpoints the best representations for retrieval-based methods such as kNN-LM, bypassing exhaustive layer-by-layer searches. Finally, we integrate a simple push-away objective into training, which increases dispersion in both single-domain and cross-domain scenarios and directly improves perplexity in each.",
      "authors": [
        "Yanhong Li",
        "Ming Li",
        "Karen Livescu",
        "Jiawei Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:53:50+00:00",
          "link": "https://arxiv.org/abs/2506.24106v1",
          "size": "1461kb",
          "version": "v1"
        }
      ],
      "title": "On the Predictive Power of Representation Dispersion in Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24106",
        "HTML": "https://arxiv.org/html/2506.24106v1",
        "PDF": "https://arxiv.org/pdf/2506.24106"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24108",
      "abstract": "Denoising diffusion models excel at generating high-quality images conditioned on text prompts, yet their effectiveness heavily relies on careful guidance during the sampling process. Classifier-Free Guidance (CFG) provides a widely used mechanism for steering generation by setting the guidance scale, which balances image quality and prompt alignment. However, the choice of the guidance scale has a critical impact on the convergence toward a visually appealing and prompt-adherent image. In this work, we propose an annealing guidance scheduler which dynamically adjusts the guidance scale over time based on the conditional noisy signal. By learning a scheduling policy, our method addresses the temperamental behavior of CFG. Empirical results demonstrate that our guidance scheduler significantly enhances image quality and alignment with the text prompt, advancing the performance of text-to-image generation. Notably, our novel scheduler requires no additional activations or memory consumption, and can seamlessly replace the common classifier-free guidance, offering an improved trade-off between prompt alignment and quality.",
      "authors": [
        "Shai Yehezkel",
        "Omer Dahary",
        "Andrey Voynov",
        "Daniel Cohen-Or"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:55:00+00:00",
          "link": "https://arxiv.org/abs/2506.24108v1",
          "size": "34927kb",
          "version": "v1"
        }
      ],
      "title": "Navigating with Annealing Guidance Scale in Diffusion Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24108",
        "HTML": "https://arxiv.org/html/2506.24108v1",
        "PDF": "https://arxiv.org/pdf/2506.24108"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24113",
      "abstract": "Diffusion models have demonstrated exceptional visual quality in video generation, making them promising for autonomous driving world modeling. However, existing video diffusion-based world models struggle with flexible-length, long-horizon predictions and integrating trajectory planning. This is because conventional video diffusion models rely on global joint distribution modeling of fixed-length frame sequences rather than sequentially constructing localized distributions at each timestep. In this work, we propose Epona, an autoregressive diffusion world model that enables localized spatiotemporal distribution modeling through two key innovations: 1) Decoupled spatiotemporal factorization that separates temporal dynamics modeling from fine-grained future world generation, and 2) Modular trajectory and video prediction that seamlessly integrate motion planning with visual modeling in an end-to-end framework. Our architecture enables high-resolution, long-duration generation while introducing a novel chain-of-forward training strategy to address error accumulation in autoregressive loops. Experimental results demonstrate state-of-the-art performance with 7.4\\% FVD improvement and minutes longer prediction duration compared to prior works. The learned world model further serves as a real-time motion planner, outperforming strong end-to-end planners on NAVSIM benchmarks. Code will be publicly available at \\href{https://github.com/Kevin-thu/Epona/}{https://github.com/Kevin-thu/Epona/}.",
      "authors": [
        "Kaiwen Zhang",
        "Zhenyu Tang",
        "Xiaotao Hu",
        "Xingang Pan",
        "Xiaoyang Guo",
        "Yuan Liu",
        "Jingwei Huang",
        "Li Yuan",
        "Qian Zhang",
        "Xiao-Xiao Long",
        "Xun Cao",
        "Wei Yin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:56:35+00:00",
          "link": "https://arxiv.org/abs/2506.24113v1",
          "size": "19204kb",
          "version": "v1"
        }
      ],
      "title": "Epona: Autoregressive Diffusion World Model for Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24113",
        "HTML": "https://arxiv.org/html/2506.24113v1",
        "PDF": "https://arxiv.org/pdf/2506.24113"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24114",
      "abstract": "The $d$-Hitting Set problem is a fundamental problem in parameterized complexity, which asks whether a given hypergraph contains a vertex subset $S$ of size at most $k$ that intersects every hyperedge (i.e., $S \\cap e \\neq \\emptyset$ for each hyperedge $e$). The best known kernel for this problem, established by Abu-Khzam [1], has $(2d - 1)k^{d - 1} + k$ vertices. This result has been very widely used in the literature as many problems can be modeled as a special $d$-Hitting Set problem. In this work, we present a refinement to this result by employing linear programming techniques to construct crown decompositions in hypergraphs. This approach yields a slight but notable improvement, reducing the size to $(2d - 2)k^{d - 1} + k$ vertices.",
      "authors": [
        "Yuxi Liu and Mingyu Xiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:56:57+00:00",
          "link": "https://arxiv.org/abs/2506.24114v1",
          "size": "398kb",
          "version": "v1"
        }
      ],
      "title": "A Refined Kernel for $d$-Hitting Set",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24114",
        "HTML": "https://arxiv.org/html/2506.24114v1",
        "PDF": "https://arxiv.org/pdf/2506.24114"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24117",
      "abstract": "Identifying parallel passages in biblical Hebrew is foundational in biblical scholarship for uncovering intertextual relationships. Traditional methods rely on manual comparison, which is labor-intensive and prone to human error. This study evaluates the potential of pre-trained transformer-based language models, including E5, AlephBERT, MPNet, and LaBSE, for detecting textual parallels in the Hebrew Bible. Focusing on known parallels between the books of Samuel/Kings and Chronicles, I assessed each model's capability to generate word embeddings that delineate parallel from non-parallel passages. Utilizing cosine similarity and Wasserstein Distance measures, I found that E5 and AlephBERT show significant promise, with E5 excelling in parallel detection and AlephBERT demonstrating stronger non-parallel differentiation. These findings indicate that pre-trained models can enhance the efficiency and accuracy of detecting intertextual parallels in ancient texts, suggesting broader applications for ancient language studies.",
      "authors": [
        "David M. Smiley"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:57:27+00:00",
          "link": "https://arxiv.org/abs/2506.24117v1",
          "size": "469kb",
          "version": "v1"
        }
      ],
      "title": "Computational Detection of Intertextual Parallels in Biblical Hebrew: A Benchmark Study Using Transformer-Based Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24117",
        "HTML": "https://arxiv.org/html/2506.24117v1",
        "PDF": "https://arxiv.org/pdf/2506.24117"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24118",
      "abstract": "This paper argues for a new paradigm for Community Notes in the LLM era: an open ecosystem where both humans and LLMs can write notes, and the decision of which notes are helpful enough to show remains in the hands of humans. This approach can accelerate the delivery of notes, while maintaining trust and legitimacy through Community Notes' foundational principle: A community of diverse human raters collectively serve as the ultimate evaluator and arbiter of what is helpful. Further, the feedback from this diverse community can be used to improve LLMs' ability to produce accurate, unbiased, broadly helpful notes--what we term Reinforcement Learning from Community Feedback (RLCF). This becomes a two-way street: LLMs serve as an asset to humans--helping deliver context quickly and with minimal effort--while human feedback, in turn, enhances the performance of LLMs. This paper describes how such a system can work, its benefits, key new risks and challenges it introduces, and a research agenda to solve those challenges and realize the potential of this approach.",
      "authors": [
        "Haiwen Li",
        "Soham De",
        "Manon Revel",
        "Andreas Haupt",
        "Brad Miller",
        "Keith Coleman",
        "Jay Baxter",
        "Martin Saveski",
        "Michiel A. Bakker"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:57:32+00:00",
          "link": "https://arxiv.org/abs/2506.24118v1",
          "size": "320kb",
          "version": "v1"
        }
      ],
      "title": "Scaling Human Judgment in Community Notes with LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24118",
        "HTML": "https://arxiv.org/html/2506.24118v1",
        "PDF": "https://arxiv.org/pdf/2506.24118"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24119",
      "abstract": "Recent advances in reinforcement learning have shown that language models can develop sophisticated reasoning through training on tasks with verifiable rewards, but these approaches depend on human-curated problem-answer pairs and domain-specific reward engineering. We introduce SPIRAL, a self-play framework where models learn by playing multi-turn, zero-sum games against continuously improving versions of themselves, eliminating the need for human supervision. Through self-play, SPIRAL generates an infinite curriculum of progressively challenging problems as models must constantly adapt to stronger opponents. To enable this self-play training at scale, We implement a fully online, multi-turn, multi-agent reinforcement learning system for LLMs and propose role-conditioned advantage estimation (RAE) to stabilize multi-agent training. Using SPIRAL, self-play on zero-sum games produces reasoning capabilities that transfer broadly. Training Qwen3-4B-Base on Kuhn Poker alone achieves 8.6% improvement on math and 8.4% on general reasoning, outperforming SFT on 25,000 expert game trajectories. Analysis reveals that this transfer occurs through three cognitive patterns: systematic decomposition, expected value calculation, and case-by-case analysis. Multi-game training (TicTacToe, Kuhn Poker, Simple Negotiation) further enhances performance as each game develops distinct reasoning strengths. Applying SPIRAL to a strong reasoning model (DeepSeek-R1-Distill-Qwen-7B) can still lead to 2.0% average improvement. These results demonstrate that zero-sum games naturally develop transferable reasoning capabilities, highlighting a promising direction for autonomous reasoning development.",
      "authors": [
        "Bo Liu",
        "Leon Guertler",
        "Simon Yu",
        "Zichen Liu",
        "Penghui Qi",
        "Daniel Balcells",
        "Mickel Liu",
        "Cheston Tan",
        "Weiyan Shi",
        "Min Lin",
        "Wee Sun Lee",
        "and Natasha Jaques"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:58:13+00:00",
          "link": "https://arxiv.org/abs/2506.24119v1",
          "size": "2416kb",
          "version": "v1"
        }
      ],
      "title": "SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24119",
        "HTML": "https://arxiv.org/html/2506.24119v1",
        "PDF": "https://arxiv.org/pdf/2506.24119"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24120",
      "abstract": "Data selection plays a crucial role in data-driven decision-making, including in large language models (LLMs), and is typically task-dependent. Properties such as data quality and diversity have been extensively studied and are known to enhance model performance. However, it remains unclear whether there exist other quantitative and general principles of data selection that can consistently improve performance, especially for complex tasks with limited prior knowledge. In this paper, we demonstrate that selecting more uniformly distributed data can improve training efficiency while enhancing performance. Specifically, we establish that more uniform (less biased) distribution leads to a larger minimum pairwise distance between data points, denoted by $h_{\\min}$, and prove that a smaller $h_{\\min}$ can slow down the training dynamics of gradient descent (GD). Moreover, we theoretically show that the approximation error of neural networks decreases as $h_{\\min}$ increases. Our analysis introduces a convergence framework for GD beyond the Neural Tangent Kernel (NTK) regime, applicable to a broad class of architectures, including transformers, without requiring Lipschitz smoothness. This framework further provides theoretical justification for the use of residual connections and function compositions in deep neural architectures. In the end, we conduct comprehensive experiments for supervised fine-tuning across various settings, including different optimization strategies, model sizes, and training datasets. The results consistently demonstrate that selecting data by maximizing pairwise distance significantly accelerates training and achieves comparable or better performance in LLMs across diverse datasets. Code and Datasets are available at the link: https://github.com/SafeRL-Lab/data-uniformity.",
      "authors": [
        "Yuqing Wang",
        "Shangding Gu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:58:30+00:00",
          "link": "https://arxiv.org/abs/2506.24120v1",
          "size": "1153kb",
          "version": "v1"
        }
      ],
      "title": "Data Uniformity Improves Training Efficiency and More, with a Convergence Framework Beyond the NTK Regime",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24120",
        "HTML": "https://arxiv.org/html/2506.24120v1",
        "PDF": "https://arxiv.org/pdf/2506.24120"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24121",
      "abstract": "Recent advancements in diffusion generative models significantly advanced image, video, and 3D content creation from user-provided text prompts. However, the challenging problem of dynamic 3D content generation (text-to-4D) with diffusion guidance remains largely unexplored. In this paper, we introduce TextMesh4D, a novel framework for high-quality text-to-4D generation. Our approach leverages per-face Jacobians as a differentiable mesh representation and decomposes 4D generation into two stages: static object creation and dynamic motion synthesis. We further propose a flexibility-rigidity regularization term to stabilize Jacobian optimization under video diffusion priors, ensuring robust geometric performance. Experiments demonstrate that TextMesh4D achieves state-of-the-art results in terms of temporal consistency, structural fidelity, and visual realism. Moreover, TextMesh4D operates with a low GPU memory overhead-requiring only a single 24GB GPU-offering a cost-effective yet high-quality solution for text-driven 4D mesh generation. The code will be released to facilitate future research in text-to-4D generation.",
      "authors": [
        "Sisi Dai",
        "Xinxin Su",
        "Boyan Wan",
        "Ruizhen Hu",
        "Kai Xu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:58:34+00:00",
          "link": "https://arxiv.org/abs/2506.24121v1",
          "size": "6690kb",
          "version": "v1"
        }
      ],
      "title": "TextMesh4D: High-Quality Text-to-4D Mesh Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24121",
        "HTML": "https://arxiv.org/html/2506.24121v1",
        "PDF": "https://arxiv.org/pdf/2506.24121"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24123",
      "abstract": "We introduce Calligrapher, a novel diffusion-based framework that innovatively integrates advanced text customization with artistic typography for digital calligraphy and design applications. Addressing the challenges of precise style control and data dependency in typographic customization, our framework incorporates three key technical contributions. First, we develop a self-distillation mechanism that leverages the pre-trained text-to-image generative model itself alongside the large language model to automatically construct a style-centric typography benchmark. Second, we introduce a localized style injection framework via a trainable style encoder, which comprises both Qformer and linear layers, to extract robust style features from reference images. An in-context generation mechanism is also employed to directly embed reference images into the denoising process, further enhancing the refined alignment of target styles. Extensive quantitative and qualitative evaluations across diverse fonts and design contexts confirm Calligrapher's accurate reproduction of intricate stylistic details and precise glyph positioning. By automating high-quality, visually consistent typography, Calligrapher surpasses traditional models, empowering creative practitioners in digital art, branding, and contextual typographic design.",
      "authors": [
        "Yue Ma",
        "Qingyan Bai",
        "Hao Ouyang",
        "Ka Leong Cheng",
        "Qiuyu Wang",
        "Hongyu Liu",
        "Zichen Liu",
        "Haofan Wang",
        "Jingye Chen",
        "Yujun Shen",
        "Qifeng Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:59:06+00:00",
          "link": "https://arxiv.org/abs/2506.24123v1",
          "size": "32153kb",
          "version": "v1"
        }
      ],
      "title": "Calligrapher: Freestyle Text Image Customization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24123",
        "HTML": "https://arxiv.org/html/2506.24123v1",
        "PDF": "https://arxiv.org/pdf/2506.24123"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24124",
      "abstract": "Time series forecasting traditionally relies on unimodal numerical inputs, which often struggle to capture high-level semantic patterns due to their dense and unstructured nature. While recent approaches have explored representing time series as text using large language models (LLMs), these methods remain limited by the discrete nature of token sequences and lack the perceptual intuition humans typically apply, such as interpreting visual patterns. In this paper, we propose a multimodal contrastive learning framework that transforms raw time series into structured visual and textual perspectives. Rather than using natural language or real-world images, we construct both modalities directly from numerical sequences. We then align these views in a shared semantic space via contrastive learning, enabling the model to capture richer and more complementary representations. Furthermore, we introduce a variate selection module that leverages the aligned representations to identify the most informative variables for multivariate forecasting. Extensive experiments on fifteen short-term and six long-term forecasting benchmarks demonstrate that our approach consistently outperforms strong unimodal and cross-modal baselines, highlighting the effectiveness of multimodal alignment in enhancing time series forecasting. Code is available at: https://github.com/Ironieser/TimesCLIP.",
      "authors": [
        "Dong Sixun",
        "Fan Wei",
        "Teresa Wu",
        "Fu Yanjie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:59:14+00:00",
          "link": "https://arxiv.org/abs/2506.24124v1",
          "size": "635kb",
          "version": "v1"
        }
      ],
      "title": "Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24124",
        "HTML": "https://arxiv.org/html/2506.24124v1",
        "PDF": "https://arxiv.org/pdf/2506.24124"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24125",
      "abstract": "Residual connection has been extensively studied and widely applied at the model architecture level. However, its potential in the more challenging data-centric approaches remains unexplored. In this work, we introduce the concept of Data Residual Matching for the first time, leveraging data-level skip connections to facilitate data generation and mitigate data information vanishing. This approach maintains a balance between newly acquired knowledge through pixel space optimization and existing core local information identification within raw data modalities, specifically for the dataset distillation task. Furthermore, by incorporating optimization-level refinements, our method significantly improves computational efficiency, achieving superior performance while reducing training time and peak GPU memory usage by 50%. Consequently, the proposed method Fast and Accurate Data Residual Matching for Dataset Distillation (FADRM) establishes a new state-of-the-art, demonstrating substantial improvements over existing methods across multiple dataset benchmarks in both efficiency and effectiveness. For instance, with ResNet-18 as the student model and a 0.8% compression ratio on ImageNet-1K, the method achieves 47.7% test accuracy in single-model dataset distillation and 50.0% in multi-model dataset distillation, surpassing RDED by +5.7% and outperforming state-of-the-art multi-model approaches, EDC and CV-DD, by +1.4% and +4.0%. Code is available at: https://github.com/Jiacheng8/FADRM.",
      "authors": [
        "Jiacheng Cui and Xinyue Bi and Yaxin Luo and Xiaohan Zhao and Jiacheng Liu and Zhiqiang Shen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:59:34+00:00",
          "link": "https://arxiv.org/abs/2506.24125v1",
          "size": "7475kb",
          "version": "v1"
        }
      ],
      "title": "FADRM: Fast and Accurate Data Residual Matching for Dataset Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24125",
        "HTML": "https://arxiv.org/html/2506.24125v1",
        "PDF": "https://arxiv.org/pdf/2506.24125"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24127",
      "abstract": "Implicit neural representation (INR) methods for video compression have recently achieved visual quality and compression ratios that are competitive with traditional pipelines. However, due to the need for per-sample network training, the encoding speeds of these methods are too slow for practical adoption. We develop a library to allow us to disentangle and review the components of methods from the NeRV family, reframing their performance in terms of not only size-quality trade-offs, but also impacts on training time. We uncover principles for effective video INR design and propose a state-of-the-art configuration of these components, Rabbit NeRV (RNeRV). When all methods are given equal training time (equivalent to 300 NeRV epochs) for 7 different UVG videos at 1080p, RNeRV achieves +1.27% PSNR on average compared to the best-performing alternative for each video in our NeRV library. We then tackle the encoding speed issue head-on by investigating the viability of hyper-networks, which predict INR weights from video inputs, to disentangle training from encoding to allow for real-time encoding. We propose masking the weights of the predicted INR during training to allow for variable, higher quality compression, resulting in 1.7% improvements to both PSNR and MS-SSIM at 0.037 bpp on the UCF-101 dataset, and we increase hyper-network parameters by 0.4% for 2.5%/2.7% improvements to PSNR/MS-SSIM with equal bpp and similar speeds. Our project website is available at https://mgwillia.github.io/vinrb/ and our code is available at https://github.com/mgwillia/vinrb.",
      "authors": [
        "Matthew Gwilliam",
        "Roy Zhang",
        "Namitha Padmanabhan",
        "Hongyang Du",
        "Abhinav Shrivastava"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:59:57+00:00",
          "link": "https://arxiv.org/abs/2506.24127v1",
          "size": "12908kb",
          "version": "v1"
        }
      ],
      "title": "How to Design and Train Your Implicit Neural Representation for Video Compression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24127",
        "HTML": "https://arxiv.org/html/2506.24127v1",
        "PDF": "https://arxiv.org/pdf/2506.24127"
      },
      "source": "arXiv"
    },
    {
      "id": "1610.09431",
      "abstract": "It is known that when multiple stimuli are present, top-down attention selectively enhances the neural signal in the visual cortex for task-relevant stimuli, but this has been tested only under conditions of minimal competition of visual attention. Here we show during high competition, that is, two stimuli in a shared receptive field possessing opposing modulatory goals, top-down attention suppresses both task-relevant and irrelevant neural signals within 100 ms of stimuli onset. This non-selective engagement of top-down attentional resources serves to reduce the feedforward signal representing irrelevant stimuli.",
      "authors": [
        "Omar Claflin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2016-10-29T00:21:31+00:00",
          "link": "https://arxiv.org/abs/1610.09431v1",
          "size": "646kb",
          "version": "v1"
        }
      ],
      "title": "Attention acts to suppress goal-based conflict under high competition",
      "links": {
        "Abstract": "https://arxiv.org/abs/1610.09431",
        "PDF": "https://arxiv.org/pdf/1610.09431"
      },
      "tasks": [
        "Vocal Bursts Intensity Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "1906.00306",
      "abstract": "The complex behavior of highly deformable mechanical metamaterials can substantially enhance the performance of soft robots.",
      "authors": [
        "Ahmad Rafsanjani",
        "Katia Bertoldi",
        "Andr\\'e R. Studart"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Soft Condensed Matter (cond-mat.soft)",
        "Materials Science (cond-mat.mtrl-sci)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2019-06-01T23:02:46+00:00",
          "link": "https://arxiv.org/abs/1906.00306v1",
          "size": "1372kb",
          "version": "v1"
        }
      ],
      "title": "Programming Soft Robots with Flexible Mechanical Metamaterials",
      "links": {
        "Abstract": "https://arxiv.org/abs/1906.00306",
        "PDF": "https://arxiv.org/pdf/1906.00306"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22448",
      "abstract": "Reconfigurable intelligent surfaces (RIS) are key enablers for 6G wireless systems. This paper studies downlink transmission in an RIS-assisted MISO-OFDMA system, addressing resource allocation challenges. A two-stage unsupervised learning-based framework is proposed to jointly design RIS phase shifts, BS beamforming, and resource block (RB) allocation. The framework includes BeamNet, which predicts RIS phase shifts from CSI, and AllocationNet, which allocates RBs using equivalent CSI derived from BeamNet outputs. Active beamforming is implemented via maximum ratio transmission and water-filling. To handle discrete constraints while ensuring differentiability, quantization and the Gumbel-softmax trick are adopted. A customized loss and phased training enhance performance under QoS constraints. Simulations show the method achieves 99.93% of the sum rate of the SCA baseline with only 0.036% of its runtime, and it remains robust across varying channel and user conditions.",
      "authors": [
        "Yu Ma",
        "Xingyu Zhou",
        "Xiao Li",
        "Le Liang",
        "Shi Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T23:50:38+00:00",
          "link": "https://arxiv.org/abs/2506.22448v1",
          "size": "1997kb",
          "version": "v1"
        }
      ],
      "title": "Unsupervised Learning-Based Joint Resource Allocation and Beamforming Design for RIS-Assisted MISO-OFDMA Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22448",
        "HTML": "https://arxiv.org/html/2506.22448v1",
        "PDF": "https://arxiv.org/pdf/2506.22448"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22450",
      "abstract": "Since weather forecasts are fundamentally uncertain, reliable decision making requires information on the likelihoods of future weather scenarios. We explore the sensitivity of machine learning weather prediction (MLWP) using the 24h Pangu Weather ML model of Huawei to errors in the initial conditions with a specific kind of Singular Vector (SV) perturbations. Our Arnoldi-SV (A-SV) method does not need linear nor adjoint model versions and is applicable to numerical weather prediction (NWP) as well as MLWP. It observes error growth within a given optimization time window by iteratively applying a forecast model to perturbed model states. This creates a Krylov subspace, implicitly based on a matrix operator, which approximates the local error growth. Each iteration adds new dimensions to the Krylov space and its leading right SVs are expected to turn into directions of growing errors. We show that A-SV indeed finds dynamically meaningful perturbation patterns for the 24h Pangu Weather model, which grow right from the beginning of the forecast rollout. These perturbations describe local unstable modes and could be a basis to initialize MLWP ensembles. Since we start A-SV from random noise perturbations, the algorithm transforms noise into perturbations conditioned on a given reference state - a process that is akin to the denoising process of the generic diffusion based ML model of GenCast, therefor we briefly discuss similarities and differences.",
      "authors": [
        "Jens Winkler and Michael Denhard"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Atmospheric and Oceanic Physics (physics.ao-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T08:52:20+00:00",
          "link": "https://arxiv.org/abs/2506.22450v1",
          "size": "41360kb",
          "version": "v1"
        }
      ],
      "title": "Arnoldi Singular Vector perturbations for machine learning weather prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22450",
        "HTML": "https://arxiv.org/html/2506.22450v1",
        "PDF": "https://arxiv.org/pdf/2506.22450"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22454",
      "abstract": "Accurate intraoperative localization of the subthalamic nucleus (STN) is essential for the efficacy of Deep Brain Stimulation (DBS) in patients with Parkinson's disease. While microelectrode recordings (MERs) provide rich electrophysiological information during DBS electrode implantation, current localization practices often rely on subjective interpretation of signal features. In this study, we propose a quantitative framework that leverages nonlinear dynamics and entropy-based metrics to classify neural activity recorded inside versus outside the STN. MER data from three patients were preprocessed using a robust artifact correction pipeline, segmented, and labelled based on surgical annotations. A comprehensive set of recurrence quantification analysis, nonlinear, and entropy features were extracted from each segment. Multiple supervised classifiers were trained on every combination of feature domains using stratified 10-fold cross-validation, followed by statistical comparison using paired Wilcoxon signed-rank tests with Holm-Bonferroni correction. The combination of entropy and nonlinear features yielded the highest discriminative power, and the Extra Trees classifier emerged as the best model with a cross-validated F1-score of 0.902+/-0.027 and ROC AUC of 0.887+/-0.055. Final evaluation on a 20% hold-out test set confirmed robust generalization (F1= 0.922, ROC AUC = 0.941). These results highlight the potential of nonlinear and entropy signal descriptors in supporting real-time, data-driven decision-making during DBS surgeries",
      "authors": [
        "Ana Luiza S. Tavares",
        "Artur Pedro M. Neto",
        "Francinaldo L. Gomes",
        "Paul Rodrigo dos Reis",
        "Arthur G. da Silva",
        "Antonio P. Junior",
        "Bruno D. Gomes"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-14T23:23:26+00:00",
          "link": "https://arxiv.org/abs/2506.22454v1",
          "size": "4020kb",
          "version": "v1"
        }
      ],
      "title": "Microelectrode Signal Dynamics as Biomarkers of Subthalamic Nucleus Entry on Deep Brain Stimulation: A Nonlinear Feature Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22454",
        "HTML": "https://arxiv.org/html/2506.22454v1",
        "PDF": "https://arxiv.org/pdf/2506.22454"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22455",
      "abstract": "Normalization is a critical yet often overlooked component in the preprocessing pipeline for EEG deep learning applications. The rise of large-scale pretraining paradigms such as self-supervised learning (SSL) introduces a new set of tasks whose nature is substantially different from supervised training common in EEG deep learning applications. This raises new questions about optimal normalization strategies for the applicable task. In this study, we systematically evaluate the impact of normalization granularity (recording vs. window level) and scope (cross-channel vs. within-channel) on both supervised (age and gender prediction) and self-supervised (Contrastive Predictive Coding) tasks. Using high-density resting-state EEG from 2,836 subjects in the Healthy Brain Network dataset, we show that optimal normalization strategies differ significantly between training paradigms. Window-level within-channel normalization yields the best performance in supervised tasks, while minimal or cross-channel normalization at the window level is more effective for SSL. These results underscore the necessity of task-specific normalization choices and challenge the assumption that a universal normalization strategy can generalize across learning settings. Our findings provide practical insights for developing robust EEG deep learning pipelines as the field shifts toward large-scale, foundation model training.",
      "authors": [
        "Dung Truong and Arnaud Delorme"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-15T15:33:41+00:00",
          "link": "https://arxiv.org/abs/2506.22455v1",
          "size": "337kb",
          "version": "v1"
        }
      ],
      "title": "Data Normalization Strategies for EEG Deep Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22455",
        "PDF": "https://arxiv.org/pdf/2506.22455"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22457",
      "abstract": "Continuous, non-invasive pregnancy monitoring is crucial for minimising potential complications. The fetal electrocardiogram (fECG) represents a promising tool for assessing fetal health beyond clinical environments. Home-based monitoring necessitates the use of a minimal number of comfortable and durable electrodes, such as dry textile electrodes. However, this setup presents many challenges, including increased noise and motion artefacts, which complicate the accurate extraction of fECG signals. To overcome these challenges, we introduce a pioneering method for extracting fECG from single-channel recordings obtained using dry textile electrodes using AI techniques. We created a new dataset by simulating abdominal recordings, including noise closely resembling real-world characteristics of in-vivo recordings through dry textile electrodes, alongside mECG and fECG. To ensure the reliability of the extracted fECG, we propose an innovative pipeline based on a complex-valued denoising network, Complex UNet. Unlike previous approaches that focused solely on signal magnitude, our method processes both real and imaginary components of the spectrogram, addressing phase information and preventing incongruous predictions. We evaluated our novel pipeline against traditional, well-established approaches, on both simulated and real data in terms of fECG extraction and R-peak detection. The results showcase that our suggested method achieves new state-of-the-art results, enabling an accurate extraction of fECG morphology across all evaluated settings. This method is the first to effectively extract fECG signals from single-channel recordings using dry textile electrodes, making a significant advancement towards a fully non-invasive and self-administered fECG extraction solution.",
      "authors": [
        "Iulia Orvas",
        "Andrei Radu",
        "Alessandra Galli",
        "Ana Neacsu",
        "Elisabetta Peri"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T20:35:52+00:00",
          "link": "https://arxiv.org/abs/2506.22457v1",
          "size": "1130kb",
          "version": "v1"
        }
      ],
      "title": "A Complex UNet Approach for Non-Invasive Fetal ECG Extraction Using Single-Channel Dry Textile Electrodes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22457",
        "HTML": "https://arxiv.org/html/2506.22457v1",
        "PDF": "https://arxiv.org/pdf/2506.22457"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22459",
      "abstract": "Accurately decoding human motion intentions from surface electromyography (sEMG) is essential for myoelectric control and has wide applications in rehabilitation robotics and assistive technologies. However, existing sEMG-based motion estimation methods often rely on subject-specific musculoskeletal (MSK) models that are difficult to calibrate, or purely data-driven models that lack physiological consistency. This paper introduces a novel Physics-Embedded Neural Network (PENN) that combines interpretable MSK forward-dynamics with data-driven residual learning, thereby preserving physiological consistency while achieving accurate motion estimation. The PENN employs a recursive temporal structure to propagate historical estimates and a lightweight convolutional neural network for residual correction, leading to robust and temporally coherent estimations. A two-phase training strategy is designed for PENN. Experimental evaluations on six healthy subjects show that PENN outperforms state-of-the-art baseline methods in both root mean square error (RMSE) and $R^2$ metrics.",
      "authors": [
        "Wending Heng",
        "Chaoyuan Liang",
        "Yihui Zhao",
        "Zhiqiang Zhang",
        "Glen Cooper",
        "Zhenhong Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T16:07:20+00:00",
          "link": "https://arxiv.org/abs/2506.22459v1",
          "size": "2000kb",
          "version": "v1"
        }
      ],
      "title": "Physics-Embedded Neural Networks for sEMG-based Continuous Motion Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22459",
        "HTML": "https://arxiv.org/html/2506.22459v1",
        "PDF": "https://arxiv.org/pdf/2506.22459"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22460",
      "abstract": "Using mobile phone video of the fingertip as a data source for estimating vital signs such as heart rate (HR) and respiratory rate (RR) during daily life has long been suggested. While existing literature indicates that these estimates are accurate to within several beats or breaths per minute, the data used to draw these conclusions are typically collected in laboratory environments under careful experimental control, and yet the results are assumed to generalize to daily life. In an effort to test it, a team of researchers collected a large dataset of mobile phone video recordings made during daily life and annotated with ground truth HR and RR labels from N=111 participants. They found that traditional algorithm performance on the fingerprint videos is worse than previously reported (7 times and 13 times worse for RR and HR, respectively). Fortunately, recent advancements in deep learning, especially in convolutional neural networks (CNNs), offer a promising solution to improve this performance. This study proposes a new method for estimating HR and RR using a novel 3D deep CNN, demonstrating a reduced error in estimated HR by 68% and RR by 75%. These promising results suggest that regressor-based deep learning approaches should be used in estimating HR and RR.",
      "authors": [
        "Ibne Farabi Shihab"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T16:37:41+00:00",
          "link": "https://arxiv.org/abs/2506.22460v1",
          "size": "242kb",
          "version": "v1"
        }
      ],
      "title": "Heart rate and respiratory rate prediction from noisy real-world smartphone based on Deep Learning methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22460",
        "HTML": "https://arxiv.org/html/2506.22460v1",
        "PDF": "https://arxiv.org/pdf/2506.22460"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22461",
      "abstract": "Groundwater supports ecosystems, agriculture, and drinking water supplies worldwide, yet effective monitoring remains challenging due to sparse data, computational constraints, and delayed outputs from traditional approaches. We develop a machine learning pipeline that predicts groundwater level categories using climate data, hydro-meteorological records, and physiographic attributes processed through AutoGluon's automated ensemble framework. Our approach integrates geospatial preprocessing, domain-driven feature engineering, and automated model selection to overcome conventional monitoring limitations. Applied to a large-scale French dataset (n $>$ 3,440,000 observations from 1,500+ wells), the model achieves weighted F\\_1 scores of 0.927 on validation data and 0.67 on temporally distinct test data. Scenario-based evaluations demonstrate practical utility for early warning systems and water allocation decisions under changing climate conditions. The open-source implementation provides a scalable framework for integrating machine learning into national groundwater monitoring networks, enabling more responsive and data-driven water management strategies.",
      "authors": [
        "Chuan Li",
        "Ruoxuan Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T00:41:04+00:00",
          "link": "https://arxiv.org/abs/2506.22461v1",
          "size": "1538kb",
          "version": "v1"
        }
      ],
      "title": "Machine Learning for Proactive Groundwater Management: Early Warning and Resource Allocation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22461",
        "HTML": "https://arxiv.org/html/2506.22461v1",
        "PDF": "https://arxiv.org/pdf/2506.22461"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22462",
      "abstract": "Fall detection is critical to support the growing elderly population, projected to reach 2.1 billion by 2050. However, existing methods often face data scarcity challenges or compromise privacy. We propose a novel IoT-based Fall Detection as a Service (FDaaS) framework to assist the elderly in living independently and safely by accurately detecting falls. We design a service-oriented architecture that leverages Ultra-wideband (UWB) radar sensors as an IoT health-sensing service, ensuring privacy and minimal intrusion. We address the challenges of data scarcity by utilizing a Fall Detection Generative Pre-trained Transformer (FD-GPT) that uses augmentation techniques. We developed a protocol to collect a comprehensive dataset of the elderly daily activities and fall events. This resulted in a real dataset that carefully mimics the elderly's routine. We rigorously evaluate and compare various models using this dataset. Experimental results show our approach achieves 90.72% accuracy and 89.33% precision in distinguishing between fall events and regular activities of daily living.",
      "authors": [
        "Abdallah Lakhdari",
        "Jiajie Li",
        "Amani Abusafia",
        "Athman Bouguettaya"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T03:28:07+00:00",
          "link": "https://arxiv.org/abs/2506.22462v1",
          "size": "7575kb",
          "version": "v1"
        }
      ],
      "title": "Privacy-aware IoT Fall Detection Services For Aging in Place",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22462",
        "HTML": "https://arxiv.org/html/2506.22462v1",
        "PDF": "https://arxiv.org/pdf/2506.22462"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22465",
      "abstract": "Affine frequency division multiplexing (AFDM) is a promising chirp-assisted multicarrier waveform for future high mobility communications. A significant challenge in MIMO-AFDM systems is the multi-user interference (MUI), which can be effectively addressed by employing precoding techniques. However, the complexity introduced by AFDM makes the precoding process computationally expensive and challenging. To overcome this issue, We combine AFDM channel sparse property and using Preconditioned Conjugate Gradient (PCG) method to iteratively process the precoding, thereby reducing the complexity of the precoding design. Simulation results demonstrate that the proposed sparsification approach, coupled with the PCG method, achieving quite precoding performance while significantly reducing computational complexity. This makes the application of AFDM more feasible and efficient for high-mobility communication scenarios, paving the way for its broader implementation in next-generation communication systems.",
      "authors": [
        "Jun Zhu",
        "Yin Xu",
        "Dazhi He",
        "Haoyang Li",
        "Yunfeng Guan",
        "Wenjun Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T14:14:37+00:00",
          "link": "https://arxiv.org/abs/2506.22465v1",
          "size": "392kb",
          "version": "v1"
        }
      ],
      "title": "Preconditioned Conjugate Gradient for MIMO-AFDM System",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22465",
        "HTML": "https://arxiv.org/html/2506.22465v1",
        "PDF": "https://arxiv.org/pdf/2506.22465"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22467",
      "abstract": "The quantity and quality of muscles are increasingly recognized as important predictors of health outcomes. While MRI offers a valuable modality for such assessments, obtaining precise quantitative measurements of musculature remains challenging. This study aimed to develop a publicly available model for muscle segmentation in MRIs and demonstrate its applicability across various anatomical locations and imaging sequences. A total of 362 MRIs from 160 patients at a single tertiary center (Duke University Health System, 2016-2020) were included, with 316 MRIs from 114 patients used for model development. The model was tested on two separate sets: one with 28 MRIs representing common sequence types, achieving an average Dice Similarity Coefficient (DSC) of 88.45%, and another with 18 MRIs featuring less frequent sequences and abnormalities such as muscular atrophy, hardware, and significant noise, achieving 86.21% DSC. These results demonstrate the feasibility of a fully automated deep learning algorithm for segmenting muscles on MRI across diverse settings. The public release of this model enables consistent, reproducible research into the relationship between musculature and health.",
      "authors": [
        "Roy Colglazier",
        "Jisoo Lee",
        "Haoyu Dong",
        "Hanxue Gu",
        "Yaqian Chen",
        "Joseph Cao",
        "Zafer Yildiz",
        "Zhonghao Liu",
        "Nicholas Konz",
        "Jichen Yang",
        "Jikai Zhang",
        "Yuwen Chen",
        "Lin Li",
        "Adrian Camarena",
        "Maciej A. Mazurowski"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T16:42:01+00:00",
          "link": "https://arxiv.org/abs/2506.22467v1",
          "size": "9887kb",
          "version": "v1"
        }
      ],
      "title": "SegmentAnyMuscle: A universal muscle segmentation model across different locations in MRI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22467",
        "PDF": "https://arxiv.org/pdf/2506.22467"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22468",
      "abstract": "The Internet of Things (IoT) plays a major role today in smart building infrastructures, from simple smart-home applications, to more sophisticated industrial type installations. The vast amounts of data generated from relevant systems can be processed in different ways revealing important information. This is especially true in the era of edge computing, when advanced data analysis and decision-making is gradually moving to the edge of the network where devices are generally characterised by low computing resources. In this context, one of the emerging main challenges is related to maintaining data analysis accuracy even with less data that can be efficiently handled by low resource devices. The present work focuses on correlation analysis of data retrieved from a pilot IoT network installation monitoring a small smart office by means of environmental and energy consumption sensors. The research motivation was to find statistical correlation between the monitoring variables that will allow the use of machine learning (ML) prediction algorithms for energy consumption reducing input parameters. For this to happen, a series of hypothesis tests for the correlation of three different environmental variables with the energy consumption were carried out. A total of ninety tests were performed, thirty for each pair of variables. In these tests, p-values showed the existence of strong or semi-strong correlation with two environmental variables, and of a weak correlation with a third one. Using the proposed methodology, we manage without examining the entire data set to exclude weak correlated variables while keeping the same score of accuracy.",
      "authors": [
        "Konstantinos Koutras",
        "Agorakis Bompotas",
        "Constantinos Halkiopoulos",
        "Athanasios Kalogeras",
        "Christos Alexakos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T08:29:35+00:00",
          "link": "https://arxiv.org/abs/2506.22468v1",
          "size": "346kb",
          "version": "v1"
        }
      ],
      "title": "Dimensionality Reduction on IoT Monitoring Data of Smart Building for Energy Consumption Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22468",
        "HTML": "https://arxiv.org/html/2506.22468v1",
        "PDF": "https://arxiv.org/pdf/2506.22468"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22471",
      "abstract": "Modern 5G/6G deployments routinely face cross-configuration handovers--users traversing cells with different antenna layouts, carrier frequencies, and scattering statistics--which inflate channel-prediction NMSE by $37.5\\%$ on average when models are naively fine-tuned. The proposed improvement frames this mismatch as a continual-learning problem and benchmarks three adaptation families: replay with loss-aware reservoirs, synaptic-importance regularization, and memory-free learning-without-forgetting. Across three representative 3GPP urban micro scenarios, the best replay and regularization schemes cut the high-SNR error floor by up to 2~dB ($\\approx 35\\%$), while even the lightweight distillation recovers up to $30\\%$ improvement over baseline handover prediction schemes. These results show that targeted rehearsal and parameter anchoring are essential for handover-robust CSI prediction and suggest a clear migration path for embedding continual-learning hooks into current channel prediction efforts in 3GPP--NR and O-RAN. The full codebase can be found at https://github.com/ahmd-mohsin/continual-learning-channel-prediction.git.",
      "authors": [
        "Muhammad Ahmed Mohsin",
        "Muhammad Umer",
        "Ahsan Bilal",
        "Muhammad Ali Jamshed",
        "John M. Cioffi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T19:13:58+00:00",
          "link": "https://arxiv.org/abs/2506.22471v1",
          "size": "477kb",
          "version": "v1"
        }
      ],
      "title": "Continual Learning for Wireless Channel Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22471",
        "HTML": "https://arxiv.org/html/2506.22471v1",
        "PDF": "https://arxiv.org/pdf/2506.22471"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22472",
      "abstract": "Spiders use their webs as multifunctional tools that enable capturing and localizing prey and more general environmental sensing through vibrations. Inspired by their biological function, we present a spider web-inspired optical waveguide system for resilient impulse detection and localization. The structure consists of six clear thermoplastic polyurethane (TPU) waveguides arranged radially and interconnected by a spiral TPU thread, mimicking orb spider webs. Light transmission losses, induced by vibrations, are measured via coupled LEDs and photo-diodes, allowing real-time detection. We systematically characterize individual waveguides, analyzing key parameters such as tension, impulse position, and break angle to optimize vibrational response. The complete system is validated through controlled experiments, revealing a 5 ms propagation delay in vibration transfer between adjacent radii, enhancing localization capabilities. We demonstrate a robust impulse detection and localization algorithm leveraging time delay analysis, achieving reliable event identification even in cases of sensor failure. This study highlights the potential of bioinspired optical waveguide structures for adaptive sensing, with applications in soft robotics, structural monitoring, and environmental sensing.",
      "authors": [
        "Dylan Wilson",
        "Marco Pontin",
        "Peter Walters",
        "Perla Maiolino"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T12:36:26+00:00",
          "link": "https://arxiv.org/abs/2506.22472v1",
          "size": "7950kb",
          "version": "v1"
        }
      ],
      "title": "Optical Waveguide-based Spider Web Enables Resilient Impact Detection and Localization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22472",
        "HTML": "https://arxiv.org/html/2506.22472v1",
        "PDF": "https://arxiv.org/pdf/2506.22472"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22475",
      "abstract": "This paper considers the highway toll allocation problem (Wu, van den Brink, and Est\\'evez-Fern\\'andez in Transport Res B-Meth 180:10288, 2024). The aim is to allocate the tolls collected from the users of a highway across the various road sections. To this end, the authors propose, among others, the Segments Equal Sharing method, which is characterized and reinterpreted as a specific solution of a cooperative game associated with the problem. This paper presents two new allocation rules: the Segments Proportional Sharing method and the Segments Compensated Sharing method. We axiomatically characterize these new methods and compare their properties to those of the Segments Equal Sharing method. Furthermore, we also examine the relationship of these methods to the solution of the associated cooperative game. We conclude the methodological study by introducing a general family of segment allocation methods that includes the three aforementioned rules. Finally, we evaluate the performance of these methods using a real-world dataset.",
      "authors": [
        "P. Soto-Rodr\\'iguez",
        "B. Casas-M\\'endez and A. Saavedra-Nieves"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-21T11:54:22+00:00",
          "link": "https://arxiv.org/abs/2506.22475v1",
          "size": "403kb",
          "version": "v1"
        }
      ],
      "title": "Highway toll allocation problem revisited: new methods and characterizations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22475",
        "HTML": "https://arxiv.org/html/2506.22475v1",
        "PDF": "https://arxiv.org/pdf/2506.22475"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22476",
      "abstract": "Objective skill assessment in high-stakes procedural environments requires models that not only decode underlying cognitive and motor processes but also generalize across tasks, individuals, and experimental contexts. While prior work has demonstrated the potential of functional near-infrared spectroscopy (fNIRS) for evaluating cognitive-motor performance, existing approaches are often task-specific, rely on extensive preprocessing, and lack robustness to new procedures or conditions. Here, we introduce an interpretable transformer-based foundation model trained on minimally processed fNIRS signals for cross-procedural skill assessment. Pretrained using self-supervised learning on data from laparoscopic surgical tasks and endotracheal intubation (ETI), the model achieves greater than 88% classification accuracy on all tasks, with Matthews Correlation Coefficient exceeding 0.91 on ETI. It generalizes to a novel emergency airway procedure--cricothyrotomy--using fewer than 30 labeled samples and a lightweight (less than 2k parameter) adapter module, attaining an AUC greater than 87%. Interpretability is achieved via a novel channel attention mechanism--developed specifically for fNIRS--that identifies functionally coherent prefrontal sub-networks validated through ablation studies. Temporal attention patterns align with task-critical phases and capture stress-induced changes in neural variability, offering insight into dynamic cognitive states.",
      "authors": [
        "A. Subedi",
        "S. De",
        "L. Cavuoto",
        "S. Schwaitzberg",
        "M. Hackett",
        "J. Norfleet"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Emerging Technologies (cs.ET)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-21T18:30:58+00:00",
          "link": "https://arxiv.org/abs/2506.22476v1",
          "size": "1075kb",
          "version": "v1"
        }
      ],
      "title": "An Interpretable Transformer-Based Foundation Model for Cross-Procedural Skill Assessment Using Raw fNIRS Signals",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22476",
        "PDF": "https://arxiv.org/pdf/2506.22476"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22479",
      "abstract": "We introduce Hindsight-Guided Momentum (HGM), a first-order optimization algorithm that adaptively scales learning rates based on the directional consistency of recent updates. Traditional adaptive methods, such as Adam or RMSprop , adapt learning dynamics using only the magnitude of gradients, often overlooking important geometric cues.Geometric cues refer to directional information, such as the alignment between current gradients and past updates, which reflects the local curvature and consistency of the optimization path. HGM addresses this by incorporating a hindsight mechanism that evaluates the cosine similarity between the current gradient and accumulated momentum. This allows it to distinguish between coherent and conflicting gradient directions, increasing the learning rate when updates align and reducing it in regions of oscillation or noise. The result is a more responsive optimizer that accelerates convergence in smooth regions of the loss surface while maintaining stability in sharper or more erratic areas. Despite this added adaptability, the method preserves the computational and memory efficiency of existing optimizers.By more intelligently responding to the structure of the optimization landscape, HGM provides a simple yet effective improvement over existing approaches, particularly in non-convex settings like that of deep neural network training.",
      "authors": [
        "Krisanu Sarkar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-22T08:02:19+00:00",
          "link": "https://arxiv.org/abs/2506.22479v1",
          "size": "1374kb",
          "version": "v1"
        }
      ],
      "title": "Hindsight-Guided Momentum (HGM) Optimizer: An Approach to Adaptive Learning Rate",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22479",
        "HTML": "https://arxiv.org/html/2506.22479v1",
        "PDF": "https://arxiv.org/pdf/2506.22479"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22488",
      "abstract": "Accurate decoding of lower-limb motion from EEG signals is essential for advancing brain-computer interface (BCI) applications in movement intent recognition and control. However, challenges persist in achieving causal, phase-consistent predictions and in modeling both inter- and intra-subject variability. To address these issues, we propose NeuroDyGait, a domain-generalizable EEG-to-motion decoding framework that leverages structured contrastive representation learning and relational domain modeling. The proposed method employs relative contrastive learning to achieve semantic alignment between EEG and motion embeddings. Furthermore, a multi-cycle gait reconstruction objective is introduced to enforce temporal coherence and maintain biomechanical consistency. To promote inter-session generalization, during fine-tuning, a domain dynamic decoding mechanism adaptively assigns session-specific prediction heads and learns to mix their outputs based on inter-session relationships. NeuroDyGait enables zero-shot motion prediction for unseen individuals without requiring adaptation and achieves superior performance in cross-subject gait decoding on benchmark datasets. Additionally, it demonstrates strong phase-detection capabilities even without explicit phase supervision during training. These findings highlight the potential of relational domain learning in enabling scalable, target-free deployment of BCIs.",
      "authors": [
        "Xi Fu",
        "Weibang Jiang",
        "Rui Liu",
        "Gernot R. M\\\"uller-Putz",
        "Cuntai Guan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T06:03:49+00:00",
          "link": "https://arxiv.org/abs/2506.22488v1",
          "size": "732kb",
          "version": "v1"
        }
      ],
      "title": "Zero-Shot EEG-to-Gait Decoding via Phase-Aware Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22488",
        "HTML": "https://arxiv.org/html/2506.22488v1",
        "PDF": "https://arxiv.org/pdf/2506.22488"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22490",
      "abstract": "Accurate detection of ethylene concentrations in mixed gases is crucial in chemical production for safety and health purposes. Traditional methods are hindered by high cost and complexity, limiting their practical application. This study proposes MENGLAN, a Multiscale Enhanced Nonparametric Gas Analyzer that integrates a dual-stream structure, a Hybrid Multi-Head Attention mechanism, and a Feature Reactivation Module to enable real-time, lightweight, and high-precision ethylene concentration prediction. Results show that MENGLAN achieves superior performance, reduced computational demand, and enhanced deployability compared to existing methods.",
      "authors": [
        "Zhenke Duan",
        "Jiqun Pan",
        "Jiani Tu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T13:41:41+00:00",
          "link": "https://arxiv.org/abs/2506.22490v1",
          "size": "960kb",
          "version": "v1"
        }
      ],
      "title": "MENGLAN: Multiscale Enhanced Nonparametric Gas Analyzer with Lightweight Architecture and Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22490",
        "HTML": "https://arxiv.org/html/2506.22490v1",
        "PDF": "https://arxiv.org/pdf/2506.22490"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22495",
      "abstract": "The diagnostic value of electrocardiogram (ECG) lies in its dynamic characteristics, ranging from rhythm fluctuations to subtle waveform deformations that evolve across time and frequency domains. However, supervised ECG models tend to overfit dominant and repetitive patterns, overlooking fine-grained but clinically critical cues, a phenomenon known as Simplicity Bias (SB), where models favor easily learnable signals over subtle but informative ones. In this work, we first empirically demonstrate the presence of SB in ECG analyses and its negative impact on diagnostic performance, while simultaneously discovering that self-supervised learning (SSL) can alleviate it, providing a promising direction for tackling the bias. Following the SSL paradigm, we propose a novel method comprising two key components: 1) Temporal-Frequency aware Filters to capture temporal-frequency features reflecting the dynamic characteristics of ECG signals, and 2) building on this, Multi-Grained Prototype Reconstruction for coarse and fine representation learning across dual domains, further mitigating SB. To advance SSL in ECG analyses, we curate a large-scale multi-site ECG dataset with 1.53 million recordings from over 300 clinical centers. Experiments on three downstream tasks across six ECG datasets demonstrate that our method effectively reduces SB and achieves state-of-the-art performance. Code and dataset will be released publicly.",
      "authors": [
        "He-Yang Xu",
        "Hongxiang Gao",
        "Yuwen Li",
        "Xiu-Shen Wei and Chengyu Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T03:25:49+00:00",
          "link": "https://arxiv.org/abs/2506.22495v1",
          "size": "4304kb",
          "version": "v1"
        }
      ],
      "title": "Masked Autoencoders that Feel the Heart: Unveiling Simplicity Bias for ECG Analyses",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22495",
        "HTML": "https://arxiv.org/html/2506.22495v1",
        "PDF": "https://arxiv.org/pdf/2506.22495"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22524",
      "abstract": "Products with intermittent demand are characterized by a high risk of sales losses and obsolescence due to the sporadic occurrence of demand events. Generally, both point forecasting and probabilistic forecasting approaches are applied to intermittent demand. In particular, probabilistic forecasting, which models demand as a stochastic process, is capable of capturing uncertainty. An example of such modeling is the use of L\\'evy processes, which possess independent increments and accommodate discontinuous changes (jumps). However, to the best of our knowledge, in inventory control using L\\'evy processes, no studies have investigated how the order quantity and reorder point affect the total cost. One major difficulty has been the mathematical formulation of inventory replenishment triggered at reorder points. To address this challenge, the present study formulates a reorder-point policy by modeling cumulative demand as a drifted Poisson process and introducing a stopping time to represent the timing at which the reorder point is reached. Furthermore, the validity of the proposed method is verified by comparing the total cost with that obtained from a case where an ARIMA model is combined with a reorder-point policy. As a main result, while the total cost under ARIMA-based forecasting increases linearly over time, the L\\'evy process-based formulation provides an analytical expression for the total cost, revealing that random demand fluctuations cause the expected total cost to grow at a rate faster than linear.",
      "authors": [
        "Ryoya Koide and Yurika Ono and Aya Ishigaki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Data Structures and Algorithms (cs.DS)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T04:25:57+00:00",
          "link": "https://arxiv.org/abs/2506.22524v1",
          "size": "1049kb",
          "version": "v1"
        }
      ],
      "title": "Inventory Control Using a L\\'evy Process for Evaluating Total Costs under Intermittent Demand",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22524",
        "HTML": "https://arxiv.org/html/2506.22524v1",
        "PDF": "https://arxiv.org/pdf/2506.22524"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22526",
      "abstract": "Even with the recent theoretical advancements that dramatically reduced the complexity of Integer Programming (IP), heuristics remain the dominant problem-solvers for this difficult category. This study seeks to establish the groundwork for Integer Evolution Strategies (IESs), a class of randomized search heuristics inherently designed for continuous spaces. IESs already excel in treating IP in practice, but accomplish it via discretization and by applying sophisticated patches to their continuous operators, while persistently using the $\\ell_2$-norm as their operation pillar. We lay foundations for discrete search, by adopting the $\\ell_1$-norm, accounting for the suitable step-size, and questioning alternative measures to quantify correlations over the integer lattice. We focus on mutation distributions for unbounded integer decision variables. We briefly discuss a couple of candidate discrete probabilities induced by the uniform and binomial distributions, which we show to possess less appealing theoretical properties, and then narrow down to the Truncated Normal (TN) and Double Geometric (DG) distributions. We explore their theoretical properties, including entropy functions, and propose a procedure to generate scalable correlated mutation distributions. Our investigations are accompanied by extensive numerical simulations, which consistently support the claim that the DG distribution is better suited for unbounded integer search. We link our theoretical perspective to empirical evidence indicating that an IES with correlated DG mutations outperformed other strategies over non-separable quadratic IP. We conclude that while the replacement of the default TN distribution by the DG is theoretically justified and practically beneficial, the truly crucial change lies in adopting the $\\ell_1$-norm over the $\\ell_2$-norm.",
      "authors": [
        "Ofer M. Shir and Michael Emmerich"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Artificial Intelligence (cs.AI)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T08:24:15+00:00",
          "link": "https://arxiv.org/abs/2506.22526v1",
          "size": "1941kb",
          "version": "v1"
        }
      ],
      "title": "Correlated Mutations for Integer Programming",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22526",
        "HTML": "https://arxiv.org/html/2506.22526v1",
        "PDF": "https://arxiv.org/pdf/2506.22526"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22532",
      "abstract": "Background: Conventional cardiovascular magnetic resonance (CMR) in paediatric and congenital heart disease uses 2D, breath-hold, balanced steady state free precession (bSSFP) cine imaging for assessment of function and cardiac-gated, respiratory-navigated, static 3D bSSFP whole-heart imaging for anatomical assessment. Our aim is to concatenate a stack 2D free-breathing real-time cines and use Deep Learning (DL) to create an isotropic a fully segmented 3D cine dataset from these images. Methods: Four DL models were trained on open-source data that performed: a) Interslice contrast correction; b) Interslice respiratory motion correction; c) Super-resolution (slice direction); and d) Segmentation of right and left atria and ventricles (RA, LA, RV, and LV), thoracic aorta (Ao) and pulmonary arteries (PA). In 10 patients undergoing routine cardiovascular examination, our method was validated on prospectively acquired sagittal stacks of real-time cine images. Quantitative metrics (ventricular volumes and vessel diameters) and image quality of the 3D cines were compared to conventional breath hold cine and whole heart imaging. Results: All real-time data were successfully transformed into 3D cines with a total post-processing time of <1 min in all cases. There were no significant biases in any LV or RV metrics with reasonable limits of agreement and correlation. There is also reasonable agreement for all vessel diameters, although there was a small but significant overestimation of RPA diameter. Conclusion: We have demonstrated the potential of creating a 3D-cine data from concatenated 2D real-time cine images using a series of DL models. Our method has short acquisition and reconstruction times with fully segmented data being available within 2 minutes. The good agreement with conventional imaging suggests that our method could help to significantly speed up CMR in clinical practice.",
      "authors": [
        "Mark Wrobel (1)",
        "Michele Pascale (1)",
        "Tina Yao (1)",
        "Ruaraidh Campbell (1)",
        "Elena Milano (2)",
        "Michael Quail (1 and 2)",
        "Jennifer Steeden (1)",
        "Vivek Muthurangu (1) ((1) UCL Centre for Translational Cardiovascular Imaging",
        "University College London",
        "(2) Great Ormond Street Hospital)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:58:22+00:00",
          "link": "https://arxiv.org/abs/2506.22532v1",
          "size": "2029kb",
          "version": "v1"
        }
      ],
      "title": "High Resolution Isotropic 3D Cine imaging with Automated Segmentation using Concatenated 2D Real-time Imaging and Deep Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22532",
        "PDF": "https://arxiv.org/pdf/2506.22532"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22536",
      "abstract": "Detecting a minor average treatment effect is a major challenge in large-scale applications, where even minimal improvements can have a significant economic impact. Traditional methods, reliant on normal distribution-based or expanded statistics, often fail to identify such minor effects because of their inability to handle small discrepancies with sufficient sensitivity. This work leverages a counterfactual outcome framework and proposes a maximum probability-driven two-armed bandit (TAB) process by weighting the mean volatility statistic, which controls Type I error. The implementation of permutation methods further enhances the robustness and efficacy. The established strategic central limit theorem (SCLT) demonstrates that our approach yields a more concentrated distribution under the null hypothesis and a less concentrated one under the alternative hypothesis, greatly improving statistical power. The experimental results indicate a significant improvement in the A/B testing, highlighting the potential to reduce experimental costs while maintaining high statistical power.",
      "authors": [
        "Yu Zhang",
        "Shanshan Zhao",
        "Bokui Wan",
        "Jinjuan Wang",
        "Xiaodong Yan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:15:57+00:00",
          "link": "https://arxiv.org/abs/2506.22536v1",
          "size": "8368kb",
          "version": "v1"
        }
      ],
      "title": "Strategic A/B testing via Maximum Probability-driven Two-armed Bandit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22536",
        "HTML": "https://arxiv.org/html/2506.22536v1",
        "PDF": "https://arxiv.org/pdf/2506.22536"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22552",
      "abstract": "This work explores key conceptual limitations in data-driven modeling of multiscale dynamical systems, focusing on neural emulators and stochastic climate modeling. A skillful climate model should capture both stationary statistics and responses to external perturbations. While current autoregressive neural models often reproduce the former, they typically struggle with the latter. We begin by analyzing a low-dimensional dynamical system to expose, by analogy, fundamental limitations that persist in high-dimensional settings. Specifically, we construct neural stochastic models under two scenarios: one where the full state vector is observed, and another with only partial observations (i.e. a subset of variables). In the first case, the models accurately capture both equilibrium statistics and forced responses in ensemble mean and variance. In the more realistic case of partial observations, two key challenges emerge: (i) identifying the \\textit{proper} variables to model, and (ii) parameterizing the influence of unobserved degrees of freedom. These issues are not specific to neural networks but reflect fundamental limitations of data-driven modeling and the need to target the slow dynamics of the system. We argue that physically grounded strategies -- such as coarse-graining and stochastic parameterizations -- are critical, both conceptually and practically, for the skillful emulation of complex systems like the coupled climate system. Building on these insights, we turn to a more realistic application: a stochastic reduced neural model of the sea surface temperature field and the net radiative flux at the top of the atmosphere, assessing its stationary statistics, response to temperature forcing, and interpretability.",
      "authors": [
        "Fabrizio Falasca"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Chaotic Dynamics (nlin.CD)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Machine Learning (cs.LG)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T18:04:36+00:00",
          "link": "https://arxiv.org/abs/2506.22552v1",
          "size": "400kb",
          "version": "v1"
        }
      ],
      "title": "Neural models of multiscale systems: conceptual limitations, stochastic parametrizations, and a climate application",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22552",
        "HTML": "https://arxiv.org/html/2506.22552v1",
        "PDF": "https://arxiv.org/pdf/2506.22552"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22553",
      "abstract": "In 1996, Meshulam proved that every sequence generated by applying projections onto affine subspaces, drawn from a finite collection in Euclidean space, must be bounded.\n  In this paper, we extend his result not only from affine subspaces to convex polyhedral subsets, but also from Euclidean to general Hilbert space. Various examples are provided to illustrate the sharpness of the results.",
      "authors": [
        "Heinz H. Bauschke and Tran Thanh Tung"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Functional Analysis (math.FA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T18:06:24+00:00",
          "link": "https://arxiv.org/abs/2506.22553v1",
          "size": "10kb",
          "version": "v1"
        }
      ],
      "title": "On a result by Meshulam",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22553",
        "HTML": "https://arxiv.org/html/2506.22553v1",
        "PDF": "https://arxiv.org/pdf/2506.22553"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22555",
      "abstract": "In this work, we investigate the phenomenon of spectral bias in quantum machine learning, where, in classical settings, models tend to fit low-frequency components of a target function earlier during training than high-frequency ones, demonstrating a frequency-dependent rate of convergence. We study this effect specifically in parameterised quantum circuits (PQCs). Leveraging the established formulation of PQCs as Fourier series, we prove that spectral bias in this setting arises from the ``redundancy'' of the Fourier coefficients, which denotes the number of terms in the analytical form of the model contributing to the same frequency component. The choice of data encoding scheme dictates the degree of redundancy for a Fourier coefficient. We find that the magnitude of the Fourier coefficients' gradients during training strongly correlates with the coefficients' redundancy. We then further demonstrate this empirically with three different encoding schemes. Additionally, we demonstrate that PQCs with greater redundancy exhibit increased robustness to random perturbations in their parameters at the corresponding frequencies. We investigate how design choices affect the ability of PQCs to learn Fourier sums, focusing on parameter initialization scale and entanglement structure, finding large initializations and low-entanglement schemes tend to slow convergence.",
      "authors": [
        "Callum Duffy",
        "Marcin Jastrzebski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T18:11:54+00:00",
          "link": "https://arxiv.org/abs/2506.22555v1",
          "size": "107kb",
          "version": "v1"
        }
      ],
      "title": "Spectral Bias in Variational Quantum Machine Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22555",
        "HTML": "https://arxiv.org/html/2506.22555v1",
        "PDF": "https://arxiv.org/pdf/2506.22555"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22564",
      "abstract": "Motivated by a flurry of recent work on efficient tensor decomposition algorithms, we show that the celebrated moment matrix extension algorithm of Brachat, Comon, Mourrain, and Tsigaridas for symmetric tensor canonical polyadic (CP) decomposition can be made efficient under the right conditions. We first show that the crucial property determining the complexity of the algorithm is the regularity of a target decomposition. This allows us to reduce the complexity of the vanilla algorithm, while also unifying results from previous works. We then show that for tensors in $S^d\\mathbb{C}^{n+1}$ with $d$ even, low enough regularity can reduce finding a symmetric tensor decomposition to solving a system of linear equations. For order-$4$ tensors we prove that generic tensors of rank up to $r=2n+1$ can be decomposed efficiently via moment matrix extension, exceeding the rank threshold allowed by simultaneous diagonalization. We then formulate a conjecture that states for generic order-$4$ tensors of rank $r=O(n^2)$ the induced linear system is sufficient for efficient tensor decomposition, matching the asymptotics of existing algorithms and in fact improving the leading coefficient. Towards this conjecture we give computer assisted proofs that the statement holds for $n=2, \\dots, 17$. Next we demonstrate that classes of nonidentifiable tensors can be decomposed efficiently via the moment matrix extension algorithm, bypassing the usual need for uniqueness of decomposition. Of particular interest is the class of monomials, for which the extension algorithm is not only efficient but also improves on existing theory by explicitly parameterizing the space of decompositions. Code for implementations of the efficient algorithm for generic tensors and monomials are provided, along with several numerical examples.",
      "authors": [
        "Bobby Shi",
        "Julia Lindberg",
        "Joe Kileel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Algebraic Geometry (math.AG)",
        "Numerical Analysis (cs.NA)",
        "Symbolic Computation (cs.SC)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T18:27:55+00:00",
          "link": "https://arxiv.org/abs/2506.22564v1",
          "size": "96kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Tensor Decomposition via Moment Matrix Extension",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22564",
        "PDF": "https://arxiv.org/pdf/2506.22564"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22565",
      "abstract": "Computational methods for learning to sample from the Boltzmann distribution -- where the target distribution is known only up to an unnormalized energy function -- have advanced significantly recently. Due to the lack of explicit target samples, however, prior diffusion-based methods, known as diffusion samplers, often require importance-weighted estimation or complicated learning processes. Both trade off scalability with extensive evaluations of the energy and model, thereby limiting their practical usage. In this work, we propose Adjoint Schr\\\"odinger Bridge Sampler (ASBS), a new diffusion sampler that employs simple and scalable matching-based objectives yet without the need to estimate target samples during training. ASBS is grounded on a mathematical model -- the Schr\\\"odinger Bridge -- which enhances sampling efficiency via kinetic-optimal transportation. Through a new lens of stochastic optimal control theory, we demonstrate how SB-based diffusion samplers can be learned at scale via Adjoint Matching and prove convergence to the global solution. Notably, ASBS generalizes the recent Adjoint Sampling (Havens et al., 2025) to arbitrary source distributions by relaxing the so-called memoryless condition that largely restricts the design space. Through extensive experiments, we demonstrate the effectiveness of ASBS on sampling from classical energy functions, amortized conformer generation, and molecular Boltzmann distributions.",
      "authors": [
        "Guan-Horng Liu",
        "Jaemoo Choi",
        "Yongxin Chen",
        "Benjamin Kurt Miller",
        "Ricky T. Q. Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T18:27:59+00:00",
          "link": "https://arxiv.org/abs/2506.22565v1",
          "size": "1118kb",
          "version": "v1"
        }
      ],
      "title": "Adjoint Schr\\\"odinger Bridge Sampler",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22565",
        "HTML": "https://arxiv.org/html/2506.22565v1",
        "PDF": "https://arxiv.org/pdf/2506.22565"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22568",
      "abstract": "Multi-objective optimization problems (MOPs) often require a trade-off between conflicting objectives, maximizing diversity and convergence in the objective space. This study presents an approach to improve the quality of MOP solutions by optimizing the dispersion in the decision space and the convergence in a specific region of the objective space. Our approach defines a Region of Interest (ROI) based on a cone representing the decision maker's preferences in the objective space, while enhancing the dispersion of solutions in the decision space using a uniformity measure. Combining solution concentration in the objective space with dispersion in the decision space intensifies the search for Pareto-optimal solutions while increasing solution diversity. When combined, these characteristics improve the quality of solutions and avoid the bias caused by clustering solutions in a specific region of the decision space. Preliminary experiments suggest that this method enhances multi-objective optimization by generating solutions that effectively balance dispersion and concentration, thereby mitigating bias in the decision space.",
      "authors": [
        "Gladston Moreira",
        "Ivan Meneghini and Elzabeth Wanner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T18:32:22+00:00",
          "link": "https://arxiv.org/abs/2506.22568v1",
          "size": "4561kb",
          "version": "v1"
        }
      ],
      "title": "Maximum Dispersion, Maximum Concentration: Enhancing the Quality of MOP Solutions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22568",
        "HTML": "https://arxiv.org/html/2506.22568v1",
        "PDF": "https://arxiv.org/pdf/2506.22568"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22580",
      "abstract": "Federated learning is a decentralized training approach that keeps data under stakeholder control while achieving superior performance over isolated training. While inter-institutional feature discrepancies pose a challenge in all federated settings, medical imaging is particularly affected due to diverse imaging devices and population variances, which can diminish the global model's effectiveness. Existing aggregation methods generally fail to adapt across varied circumstances. To address this, we propose FedCLAM, which integrates \\textit{client-adaptive momentum} terms derived from each client's loss reduction during local training, as well as a \\textit{personalized dampening factor} to curb overfitting. We further introduce a novel \\textit{intensity alignment} loss that matches predicted and ground-truth foreground distributions to handle heterogeneous image intensity profiles across institutions and devices. Extensive evaluations on two datasets show that FedCLAM surpasses eight cutting-edge methods in medical segmentation tasks, underscoring its efficacy. The code is available at https://github.com/siomvas/FedCLAM.",
      "authors": [
        "Vasilis Siomos and Jonathan Passerat-Palmbach and Giacomo Tarroni"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T18:52:41+00:00",
          "link": "https://arxiv.org/abs/2506.22580v1",
          "size": "576kb",
          "version": "v1"
        }
      ],
      "title": "FedCLAM: Client Adaptive Momentum with Foreground Intensity Matching for Federated Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22580",
        "HTML": "https://arxiv.org/html/2506.22580v1",
        "PDF": "https://arxiv.org/pdf/2506.22580"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22607",
      "abstract": "While age-specific fertility rates (ASFRs) provide the most extensive record of reproductive change, their aggregate nature masks the underlying behavioral mechanisms that ultimately drive fertility trends. To recover these mechanisms, we develop a likelihood-free Bayesian framework that couples an individual-level model of the reproductive process with Sequential Neural Posterior Estimation (SNPE). This allows us to infer eight behavioral and biological parameters from just two aggregate series: ASFRs and the age-profile of planned versus unplanned births. Applied to U.S. National Survey of Family Growth cohorts and to Demographic and Health Survey cohorts from Colombia, the Dominican Republic, and Peru, the method reproduces observed fertility schedules and, critically, predicts out-of-sample micro-level distributions of age at first sex, inter-birth intervals, and family-size ideals, none of which inform the estimation step. Because the fitted model yields complete synthetic life histories, it enables behaviorally explicit population forecasts and supports the construction of demographic digital twins.",
      "authors": [
        "Daniel Ciganda",
        "Ignacio Camp\\'on",
        "I\\~naki Permanyer",
        "Jakob H Macke"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Applications (stat.AP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T20:09:50+00:00",
          "link": "https://arxiv.org/abs/2506.22607v1",
          "size": "3445kb",
          "version": "v1"
        }
      ],
      "title": "Learning Individual Reproductive Behavior from Aggregate Fertility Rates via Neural Posterior Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22607",
        "HTML": "https://arxiv.org/html/2506.22607v1",
        "PDF": "https://arxiv.org/pdf/2506.22607"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22611",
      "abstract": "Extending Buehler et al.'s 2019 Deep Hedging paradigm, we innovatively employ deep neural networks to parameterize convex-risk minimization (CVaR/ES) for the portfolio tail-risk hedging problem. Through comprehensive numerical experiments on crisis-era bootstrap market simulators -- customizable with transaction costs, risk budgets, liquidity constraints, and market impact -- our end-to-end framework not only achieves significant one-day 99% CVaR reduction but also yields practical insights into friction-aware strategy adaptation, demonstrating robustness and operational viability in realistic markets.",
      "authors": [
        "Yuming Ma"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Portfolio Management (q-fin.PM)",
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Computational Finance (q-fin.CP)",
        "Risk Management (q-fin.RM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T20:16:52+00:00",
          "link": "https://arxiv.org/abs/2506.22611v1",
          "size": "38253kb",
          "version": "v1"
        }
      ],
      "title": "Deep Hedging to Manage Tail Risk",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22611",
        "PDF": "https://arxiv.org/pdf/2506.22611"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22617",
      "abstract": "The Large Scale Polarization Explorer (LSPE) project, funded by the Italian Space Agency (ASI), includes the development of LSPE-Strip, a ground-based radio telescope for observing Cosmic Microwave Background (CMB) anisotropies. LSPE-Strip, nearing its construction phase, will operate from the Teide Observatory in Tenerife, employing 49 coherent polarimeters at 43 GHz to deliver critical data on CMB anisotropies and 6 channels at 95 GHz as atmospheric monitor. On-site characterization of such advanced instruments is crucial to detect possible systematic effects, such as gain fluctuations, beam distortions, and pointing errors, that can compromise performance by introducing spurious polarizations or radiation collection from unintended directions. To address these challenges, a drone-mounted Q-band test source for on-site characterization of LSPE-Strip's polarimeter array was developed. Modern Unmanned Aerial Vehicles (UAVs) offer a flexible approach for antenna pattern measurements, yet their use in high-frequency radio astronomy is not consolidated practice. In October 2022, a UAV-based measurement campaign was conducted with the TFGI instrument on the second QUIJOTE telescope in Tenerife, in collaboration with the Instituto de Astrofisica de Canarias. This pioneering effort aimed to validate UAV-based beam characterization methods and assess QUIJOTE's performance under operational conditions. Preliminary results demonstrated high measurement accuracy, leveraging QUIJOTE's dual-receiver configuration for beam validation. These findings provide valuable insights for optimizing UAV systems in preparation for LSPE-Strip's future characterization.",
      "authors": [
        "Fabio Paonessa",
        "Lorenzo Ciorba",
        "Giuseppe Addamo",
        "Paz Alonso-Arias",
        "Barbara Caccianiga",
        "Marco Bersanelli",
        "Francesco Cuttaia",
        "Cristian Franceschet",
        "Ricardo Tanausu Genova Santos",
        "Massimo Gervasi",
        "Roger Hoyland",
        "Mike Jones",
        "Carlos Hugo Lopez-Caraballo",
        "Mauro Lumia",
        "Michele Maris",
        "Aniello Mennella",
        "Gianluca Morgante",
        "Oscar Antonio Peverini",
        "Sabrina Realini",
        "Jose Alberto Rubino-Martin",
        "Stefano Sartor",
        "Angela Taylor",
        "Fabrizio Villa",
        "Mario Zannoni and Giuseppe Virone"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T20:28:02+00:00",
          "link": "https://arxiv.org/abs/2506.22617v1",
          "size": "6447kb",
          "version": "v1"
        }
      ],
      "title": "On beam characterization of ground-based CMB radio telescopes using UAV-mounted sources: application to the QUIJOTE TFGI and plans for LSPE-Strip",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22617",
        "PDF": "https://arxiv.org/pdf/2506.22617"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22634",
      "abstract": "We establish rigorous error bounds for prime counting using a truncated Gaussian (TG) kernel in the explicit formula framework. Our main theorem proves that the approximation error remains globally below 1/2 for all sufficiently large arguments, guaranteeing exact computation of {\\pi}(x) through simple rounding, without relying on unproven hypotheses.\n  The TG kernel construction employs Gaussian-like test functions with compact support, engineered with vanishing moments to eliminate main terms. For x with 10^8 decimal digits, we demonstrate that only ~1200 nontrivial zeta zeros suffice to achieve the error bound, enabling computation in seconds on modern hardware - a dramatic improvement over classical methods.\n  Key contributions include: (1) Explicit tail truncation bounds using Taylor remainder analysis, showing exponential decay; (2) Zero-sum truncation error bounds via unconditional density estimates; (3) Rigorous treatment of trivial zero contributions. All constants are made explicit, ensuring full verifiability.\n  The method bridges analytic number theory and practical computation, with potential applications to record-breaking prime counting computations. We discuss algorithmic implications including FFT-based arithmetic for ~330 million bit numbers. The framework's flexibility suggests connections to deeper structures in prime distribution, particularly regarding optimized kernel designs and the interplay between smoothing parameters {\\alpha} and truncation heights.\n  This work exemplifies how classical analytic techniques, when carefully implemented with modern computational perspectives, yield practical algorithms for problems previously considered purely theoretical. The rigorous error analysis ensures reliability even at astronomical scales, opening new avenues for computational number theory research.",
      "authors": [
        "Bugra Kilictas",
        "Faruk Alpay"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Number Theory (math.NT)",
        "Data Structures and Algorithms (cs.DS)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T20:54:06+00:00",
          "link": "https://arxiv.org/abs/2506.22634v1",
          "size": "22kb",
          "version": "v1"
        }
      ],
      "title": "A Rigorous Error Bound for the TG Kernel in Prime Counting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22634",
        "HTML": "https://arxiv.org/html/2506.22634v1",
        "PDF": "https://arxiv.org/pdf/2506.22634"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22641",
      "abstract": "Recent benchmarks reveal that models for single-cell perturbation response are often outperformed by simply predicting the dataset mean. We trace this anomaly to a metric artifact: control-referenced deltas and unweighted error metrics reward mode collapse whenever the control is biased or the biological signal is sparse. Large-scale \\textit{in silico} simulations and analysis of two real-world perturbation datasets confirm that shared reference shifts, not genuine biological change, drives high performance in these evaluations. We introduce differentially expressed gene (DEG)-aware metrics, weighted mean-squared error (WMSE) and weighted delta $R^{2}$ ($R^{2}_{w}(\\Delta)$) with respect to all perturbations, that measure error in niche signals with high sensitivity. We further introduce negative and positive performance baselines to calibrate these metrics. With these improvements, the mean baseline sinks to null performance while genuine predictors are correctly rewarded. Finally, we show that using WMSE as a loss function reduces mode collapse and improves model performance.",
      "authors": [
        "Gabriel M. Mejia",
        "Henry E. Miller",
        "Francis J. A. Leblanc",
        "Bo Wang",
        "Brendan Swain",
        "Lucas Paulo de Lima Camillo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Genomics (q-bio.GN)",
        "Machine Learning (cs.LG)",
        "Molecular Networks (q-bio.MN)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T21:12:46+00:00",
          "link": "https://arxiv.org/abs/2506.22641v1",
          "size": "8748kb",
          "version": "v1"
        }
      ],
      "title": "Diversity by Design: Addressing Mode Collapse Improves scRNA-seq Perturbation Modeling on Well-Calibrated Metrics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22641",
        "HTML": "https://arxiv.org/html/2506.22641v1",
        "PDF": "https://arxiv.org/pdf/2506.22641"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22646",
      "abstract": "We propose a self-speaker adaptation method for streaming multi-talker automatic speech recognition (ASR) that eliminates the need for explicit speaker queries. Unlike conventional approaches requiring target speaker embeddings or enrollment audio, our technique dynamically adapts individual ASR instances through speaker-wise speech activity prediction. The key innovation involves injecting speaker-specific kernels generated via speaker supervision activations into selected ASR encoder layers. This enables instantaneous speaker adaptation to target speakers while handling fully overlapped speech even in a streaming scenario. Experiments show state-of-the-art performance in both offline and streaming scenarios, demonstrating that our self-adaptive method effectively addresses severe speech overlap through streamlined speaker-focused recognition. The results validate the proposed self-speaker adaptation approach as a robust solution for multi-talker ASR under severe overlapping speech conditions.",
      "authors": [
        "Weiqing Wang",
        "Taejin Park",
        "Ivan Medennikov",
        "Jinhan Wang",
        "Kunal Dhawan",
        "He Huang",
        "Nithin Rao Koluguri",
        "Jagadeesh Balam",
        "Boris Ginsburg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T21:25:22+00:00",
          "link": "https://arxiv.org/abs/2506.22646v1",
          "size": "541kb",
          "version": "v1"
        }
      ],
      "title": "Speaker Targeting via Self-Speaker Adaptation for Multi-talker ASR",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22646",
        "HTML": "https://arxiv.org/html/2506.22646v1",
        "PDF": "https://arxiv.org/pdf/2506.22646"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22675",
      "abstract": "Invariant prediction [Peters et al., 2016] analyzes feature/outcome data from multiple environments to identify invariant features - those with a stable predictive relationship to the outcome. Such features support generalization to new environments and help reveal causal mechanisms. Previous methods have primarily tackled this problem through hypothesis testing or regularized optimization. Here we develop Bayesian Invariant Prediction (BIP), a probabilistic model for invariant prediction. BIP encodes the indices of invariant features as a latent variable and recover them by posterior inference. Under the assumptions of Peters et al. [2016], the BIP posterior targets the true invariant features. We prove that the posterior is consistent and that greater environment heterogeneity leads to faster posterior contraction. To handle many features, we design an efficient variational approximation called VI-BIP. In simulations and real data, we find that BIP and VI-BIP are more accurate and scalable than existing methods for invariant prediction.",
      "authors": [
        "Luhuan Wu",
        "Mingzhang Yin",
        "Yixin Wang",
        "John P. Cunningham",
        "David M. Blei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T22:58:37+00:00",
          "link": "https://arxiv.org/abs/2506.22675v1",
          "size": "170kb",
          "version": "v1"
        }
      ],
      "title": "Bayesian Invariance Modeling of Multi-Environment Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22675",
        "HTML": "https://arxiv.org/html/2506.22675v1",
        "PDF": "https://arxiv.org/pdf/2506.22675"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22693",
      "abstract": "We introduce a new categorical and constructive foundation for analytic approximation based on a Contextual Choice Principle (CCP), which enforces locality and compatibility in the construction of mathematical objects. Central to our approach is the Universal Embedding and Linear Approximation Theorem (UELAT), which establishes that functions in broad spaces -- including C(K), Sobolev spaces W^{k,p}(Omega), and distributions D'(Omega) -- can be explicitly approximated by finite-rank linear projections, each with a constructive, algorithmically verifiable certificate of accuracy.\n  These constructions are governed categorically by a functorial adjunction between local logical probes and analytic models, making analytic existence both formally certifiable and programmatically extractable. As a key result, we prove a uniform certificate stability theorem, ensuring that approximation certificates persist under uniform convergence.\n  The CCP avoids classical pathologies (e.g., non-measurable sets, Banach--Tarski paradoxes) by eliminating non-constructive choice and replacing it with a coherent, local-to-global semantic logic. Our framework strengthens the foundations of constructive analysis while contributing tools relevant to formal verification, type-theoretic proof systems, and computational mathematics.",
      "authors": [
        "Andreu Ballus Santacana"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Functional Analysis (math.FA)",
        "Logic in Computer Science (cs.LO)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T00:26:31+00:00",
          "link": "https://arxiv.org/abs/2506.22693v1",
          "size": "27kb",
          "version": "v1"
        }
      ],
      "title": "Universal Gluing and Contextual Choice: Categorical Logic and the Foundations of Analytic Approximation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22693",
        "HTML": "https://arxiv.org/html/2506.22693v1",
        "PDF": "https://arxiv.org/pdf/2506.22693"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22701",
      "abstract": "This paper studies theoretical lower bounds for estimating the trace of a matrix function, $\\text{tr}(f(A))$, focusing on methods that use Hutchinson's method along with Block Krylov techniques. These methods work by approximating matrix-vector products like $f(A)V$ using a Block Krylov subspace. This is closely related to approximating functions with polynomials. We derive theoretical upper bounds on how many Krylov steps are needed for functions such as $A^{-1/2}$ and $A^{-1}$ by analyzing the upper bounds from the polynomial approximation of their scalar equivalent. In addition, we also develop lower limits on the number of queries needed for trace estimation, specifically for $\\text{tr}(W^{-p})$ where $W$ is a Wishart matrix. Our study clarifies the connection between the number of steps in Block Krylov methods and the degree of the polynomial used for approximation. This links the total cost of trace estimation to basic limits in polynomial approximation and how much information is needed for the computation.",
      "authors": [
        "Shi Jie Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistics Theory (math.ST)",
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T00:41:39+00:00",
          "link": "https://arxiv.org/abs/2506.22701v1",
          "size": "23kb",
          "version": "v1"
        }
      ],
      "title": "Lower bounds for trace estimation via Block Krylov and other methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22701",
        "HTML": "https://arxiv.org/html/2506.22701v1",
        "PDF": "https://arxiv.org/pdf/2506.22701"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22704",
      "abstract": "Large language models (LLMs) are poised to significantly impact software development, especially in the Open-Source Software (OSS) sector. To understand this impact, we first outline the mechanisms through which LLMs may influence OSS through code development, collaborative knowledge transfer, and skill development. We then empirically examine how LLMs affect OSS developers' work in these three key areas. Leveraging a natural experiment from a temporary ChatGPT ban in Italy, we employ a Difference-in-Differences framework with two-way fixed effects to analyze data from all OSS developers on GitHub in three similar countries, Italy, France, and Portugal, totaling 88,022 users. We find that access to ChatGPT increases developer productivity by 6.4%, knowledge sharing by 9.6%, and skill acquisition by 8.4%. These benefits vary significantly by user experience level: novice developers primarily experience productivity gains, whereas more experienced developers benefit more from improved knowledge sharing and accelerated skill acquisition. In addition, we find that LLM-assisted learning is highly context-dependent, with the greatest benefits observed in technically complex, fragmented, or rapidly evolving contexts. We show that the productivity effects of LLMs extend beyond direct code generation to include enhanced collaborative learning and knowledge exchange among developers; dynamics that are essential for gaining a holistic understanding of LLMs' impact in OSS. Our findings offer critical managerial implications: strategically deploying LLMs can accelerate novice developers' onboarding and productivity, empower intermediate developers to foster knowledge sharing and collaboration, and support rapid skill acquisition, together enhancing long-term organizational productivity and agility.",
      "authors": [
        "Sardar Fatooreh Bonabi",
        "Sarah Bana",
        "Tingting Nian",
        "Vijay Gurbaxani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "General Economics (econ.GN)",
        "Artificial Intelligence (cs.AI)",
        "Economics (q-fin.EC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T01:10:24+00:00",
          "link": "https://arxiv.org/abs/2506.22704v1",
          "size": "1512kb",
          "version": "v1"
        }
      ],
      "title": "Beyond Code: The Multidimensional Impacts of Large Language Models in Software Development",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22704",
        "PDF": "https://arxiv.org/pdf/2506.22704"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22705",
      "abstract": "The rapid surge in data generated by Internet of Things (IoT), artificial intelligence (AI), and machine learning (ML) applications demands ultra-fast, scalable, and energy-efficient hardware, as traditional von Neumann architectures face significant latency and power challenges due to data transfer bottlenecks between memory and processing units. Furthermore, conventional electrical memory technologies are increasingly constrained by rising bitline and wordline capacitance, as well as the resistance of compact and long interconnects, as technology scales. In contrast, photonics-based in-memory computing systems offer substantial speed and energy improvements over traditional transistor-based systems, owing to their ultra-fast operating frequencies, low crosstalk, and high data bandwidth. Hence, we present a novel differential photonic SRAM (pSRAM) bitcell-augmented scalable mixed-signal multi-bit photonic tensor core, enabling high-speed, energy-efficient matrix multiplication operations using fabrication-friendly integrated photonic components. Additionally, we propose a novel 1-hot encoding electro-optic analog-to-digital converter (eoADC) architecture to convert the multiplication outputs into digital bitstreams, supporting processing in the electrical domain. Our designed photonic tensor core, utilizing GlobalFoundries' monolithic 45SPCLO technology node, achieves computation speeds of 4.10 tera-operations per second (TOPS) and a power efficiency of 3.02 TOPS/W.",
      "authors": [
        "Md Abdullah-Al Kaiser",
        "Sugeet Sunder",
        "Ajey P. Jacob",
        "and Akhilesh R. Jaiswal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optics (physics.optics)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T01:11:10+00:00",
          "link": "https://arxiv.org/abs/2506.22705v1",
          "size": "2010kb",
          "version": "v1"
        }
      ],
      "title": "A Mixed-Signal Photonic SRAM-based High-Speed Energy-Efficient Photonic Tensor Core with Novel Electro-Optic ADC",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22705",
        "HTML": "https://arxiv.org/html/2506.22705v1",
        "PDF": "https://arxiv.org/pdf/2506.22705"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22763",
      "abstract": "Forecasting central bank policy decisions remains a persistent challenge for investors, financial institutions, and policymakers due to the wide-reaching impact of monetary actions. In particular, anticipating shifts in the U.S. federal funds rate is vital for risk management and trading strategies. Traditional methods relying only on structured macroeconomic indicators often fall short in capturing the forward-looking cues embedded in central bank communications.\n  This study examines whether predictive accuracy can be enhanced by integrating structured data with unstructured textual signals from Federal Reserve communications. We adopt a multi-modal framework, comparing traditional machine learning models, transformer-based language models, and deep learning architectures in both unimodal and hybrid settings.\n  Our results show that hybrid models consistently outperform unimodal baselines. The best performance is achieved by combining TF-IDF features of FOMC texts with economic indicators in an XGBoost classifier, reaching a test AUC of 0.83. FinBERT-based sentiment features marginally improve ranking but perform worse in classification, especially under class imbalance. SHAP analysis reveals that sparse, interpretable features align more closely with policy-relevant signals.\n  These findings underscore the importance of integrating textual and structured signals transparently. For monetary policy forecasting, simpler hybrid models can offer both accuracy and interpretability, delivering actionable insights for researchers and decision-makers.",
      "authors": [
        "Fiona Xiao Jingyi",
        "Lili Liu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Portfolio Management (q-fin.PM)",
        "Machine Learning (cs.LG)",
        "Computational Finance (q-fin.CP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T05:54:58+00:00",
          "link": "https://arxiv.org/abs/2506.22763v1",
          "size": "10081kb",
          "version": "v1"
        }
      ],
      "title": "Can We Reliably Predict the Fed's Next Move? A Multi-Modal Approach to U.S. Monetary Policy Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22763",
        "HTML": "https://arxiv.org/html/2506.22763v1",
        "PDF": "https://arxiv.org/pdf/2506.22763"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22790",
      "abstract": "This paper reports IEEE International Conference on Multimedia \\& Expo (ICME) 2025 Grand Challenge on Generalizable HDR and SDR Video Quality Measurement. With the rapid development of video technology, especially High Dynamic Range (HDR) and Standard Dynamic Range (SDR) contents, the need for robust and generalizable Video Quality Assessment (VQA) methods has become increasingly demanded. Existing VQA models often struggle to deliver consistent performance across varying dynamic ranges, distortion types, and diverse content. This challenge was established to benchmark and promote VQA approaches capable of jointly handling HDR and SDR content. In the final evaluation phase, five teams submitted seven models along with technical reports to the Full Reference (FR) and No Reference (NR) tracks. Among them, four methods outperformed VMAF baseline, while the top-performing model achieved state-of-the-art performance, setting a new benchmark for generalizable video quality assessment.",
      "authors": [
        "Yixu Chen",
        "Bowen Chen",
        "Hai Wei",
        "Alan C. Bovik",
        "Baojun Li",
        "Wei Sun",
        "Linhan Cao",
        "Kang Fu",
        "Dandan Zhu",
        "Jun Jia",
        "Menghan Hu",
        "Xiongkuo Min",
        "Guangtao Zhai",
        "Dounia Hammou",
        "Fei Yin",
        "Rafal Mantiuk",
        "Amritha Premkumar",
        "Prajit T Rajendran",
        "Vignesh V Menon"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T07:14:23+00:00",
          "link": "https://arxiv.org/abs/2506.22790v1",
          "size": "3004kb",
          "version": "v1"
        }
      ],
      "title": "ICME 2025 Generalizable HDR and SDR Video Quality Measurement Grand Challenge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22790",
        "HTML": "https://arxiv.org/html/2506.22790v1",
        "PDF": "https://arxiv.org/pdf/2506.22790"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22811",
      "abstract": "Coherent, continuous-wave, and electrically tunable chip-scale terahertz (THz) sources are critical for emerging applications in sensing, imaging, spectroscopy, communication, space and quantum technologies. Here, we demonstrate a robust source-on-a-chip THz emitter based on a layered high-temperature superconductor, engineered with an elliptical microcavity and capable of sustained coherent emission over an unprecedented operational lifetime exceeding 11 years. This compact THz source operates up to 60 K, with Tc= 90 K, delivering stable radiation in the 0.7-0.8 THz range, with on-chip electrical tunability from 100 GHz to 1 THz. Coherence arises from the phase-locked oscillation of intrinsic Josephson junction arrays, resonantly coupled to transverse electromagnetic modes within the cavity, analogous to a laser cavity, yielding collective macroscopic oscillations. THz emission remains detectable across a 0.5 m free-space open-air link at room temperature. We analyse the cavity-mode structure and extract THz photon generation rates up to 503 photons fs-1 in cryogenic conditions and 50-260 photons ps-1 over-the-air. These results establish long-term coherent THz emission from superconductors and chart a viable path toward scalable, tunable, solid-state coherent THz laser-on-a-chip platforms, especially for future classical and quantum systems.",
      "authors": [
        "Mingqi Zhang",
        "Shungo Nakagawa",
        "Yuki Enomoto",
        "Yoshihiko Kuzumi",
        "Ryuta Kikuchi",
        "Yuki Yamauchi",
        "Toshiaki Hattori",
        "Richard A. Klemm",
        "Kazuo Kadowaki",
        "Takanari Kashiwagi",
        "and Kaveh Delfanazari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Superconductivity (cond-mat.supr-con)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Applied Physics (physics.app-ph)",
        "Optics (physics.optics)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T08:26:13+00:00",
          "link": "https://arxiv.org/abs/2506.22811v1",
          "size": "2993kb",
          "version": "v1"
        }
      ],
      "title": "Terahertz source-on-a-chip with decade-long stability using layered superconductor elliptical microcavities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22811",
        "PDF": "https://arxiv.org/pdf/2506.22811"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22826",
      "abstract": "The handling of manifold-valued data, for instance, plays a central role in color restoration tasks relying on circle- or sphere-valued color models, in the study of rotational or directional information related to the special orthogonal group, and in Gaussian image processing, where the pixel statistics are interpreted as values on the hyperbolic sheet. Especially, to denoise these kind of data, there have been proposed several generalizations of total variation (TV) and Tikhonov-type denoising models incorporating the underlying manifolds. Recently, a novel, numerically efficient denoising approach has been introduced, where the data are embedded in an Euclidean ambient space, the non-convex manifolds are encoded by a series of positive semi-definite, fixed-rank matrices, and the rank constraint is relaxed to obtain a convexification that can be solved using standard algorithms from convex analysis. The aim of the present paper is to extent this approach to new kinds of data like multi-binary and Stiefel-valued data. Multi-binary data can, for instance, be used to model multi-color QR codes whereas Stiefel-valued data occur in image and video-based recognition. For both new data types, we propose TV- and Tikhonov-based denoising modelstogether with easy-to-solve convexification. All derived methods are evaluated on proof-of-concept, synthetic experiments.",
      "authors": [
        "Robert Beinert and Jonas Bresch"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T09:33:29+00:00",
          "link": "https://arxiv.org/abs/2506.22826v1",
          "size": "412kb",
          "version": "v1"
        }
      ],
      "title": "Denoising Multi-Color QR Codes and Stiefel-Valued Data by Relaxed Regularizations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22826",
        "HTML": "https://arxiv.org/html/2506.22826v1",
        "PDF": "https://arxiv.org/pdf/2506.22826"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22844",
      "abstract": "The ever-increasing demand for broadband and IoT wireless connectivity has recently urged the regulators around the world to start opening the 6 GHz spectrum for unlicensed use. These bands will, for example, permit the use of additional 1.2 GHz in the US and 500 MHz in Europe for unlicensed radio access technologies (RATs) such as Wi-Fi and 5G New Radio Unlicensed (5G NR-U). To support QoS-sensitive applications with both technologies, fair and efficient coexistence approaches between the two RATs, as well as with incumbents already operating in the 6 GHz band, are crucial. In this paper, we study through extensive simulations the achievable mean downlink throughput of both Wi-Fi 6E APs and 5G NR-U gNBs when they are co-deployed in a dense residential scenario under high-interference conditions. We also explore how different parameter settings e.g., MAC frame aggregation, energy detection threshold and maximum channel occupancy time (MCOT) affect the coexistence. Our findings give important insights into how to tune the key parameters to design fair coexistence policies.",
      "authors": [
        "Navid Keshtiarast and Marina Petrova"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T10:48:16+00:00",
          "link": "https://arxiv.org/abs/2506.22844v1",
          "size": "849kb",
          "version": "v1"
        }
      ],
      "title": "Coexistence analysis of Wi-Fi 6E and 5G NR-U in the 6 GHz band",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22844",
        "HTML": "https://arxiv.org/html/2506.22844v1",
        "PDF": "https://arxiv.org/pdf/2506.22844"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22851",
      "abstract": "Discrete time stochastic optimal control problems and Markov decision processes (MDPs) are fundamental models for sequential decision-making under uncertainty and as such provide the mathematical framework underlying reinforcement learning theory. A central tool for solving MDPs is the Bellman equation and its solution, the so-called $Q$-function. In this article, we construct deep neural network (DNN) approximations for $Q$-functions associated to MDPs with infinite time horizon and finite control set $A$. More specifically, we show that if the the payoff function and the random transition dynamics of the MDP can be suitably approximated by DNNs with leaky rectified linear unit (ReLU) activation, then the solutions $Q_d\\colon \\mathbb R^d\\to \\mathbb R^{|A|}$, $d\\in \\mathbb{N}$, of the associated Bellman equations can also be approximated in the $L^2$-sense by DNNs with leaky ReLU activation whose numbers of parameters grow at most polynomially in both the dimension $d\\in \\mathbb{N}$ of the state space and the reciprocal $1/\\varepsilon$ of the prescribed error $\\varepsilon\\in (0,1)$. Our proof relies on the recently introduced full-history recursive multilevel fixed-point (MLFP) approximation scheme.",
      "authors": [
        "Arnulf Jentzen",
        "Konrad Kleinberg",
        "Thomas Kruse"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Probability (math.PR)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T11:25:44+00:00",
          "link": "https://arxiv.org/abs/2506.22851v1",
          "size": "48kb",
          "version": "v1"
        }
      ],
      "title": "Deep neural networks can provably solve Bellman equations for Markov decision processes without the curse of dimensionality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22851",
        "PDF": "https://arxiv.org/pdf/2506.22851"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22857",
      "abstract": "We show that every $H$-minor-free graph that also excludes a $(k \\times k)$-grid as a minor has treewidth/branchwidth bounded from above by a function $f(t,k)$ that is linear in $k$ and polynomial in $t := |V(H)|$. Such a result was proven originally by [Demaine & Hajiaghayi, Combinatorica, 2008], where $f$ was indeed linear in $k$. However the dependency in $t$ in this result was non-explicit (and huge). Later, [Kawarabayashi & Kobayashi, JCTB, 2020] showed that this bound can be estimated to be $f(t,k)\\in 2^{\\mathcal{O}(t\\log t)} \\cdot k$. Wood recently asked whether $f$ can be pushed further to be polynomial, while maintaining the linearity on $k$. We answer this in a particularly strong sense, by showing that the treewidth/branchwidth of $G$ is in $\\mathcal{O}(gk + t^{2304}),$ where $g$ is the Euler genus of $H$. This directly yields $f(t,k)= \\mathcal{O}(t^2k + t^{2304})$.\n  Our methods build on techniques for branchwidth and on new bounds and insights for the Graph Minor Structure Theorem (GMST) due to [Gorsky, Seweryn & Wiederrecht, 2025, arXiv:2504.02532]. In particular, we prove a variant of the GMST that ensures some helpful properties for the minor relation. We further employ our methods to provide approximation algorithms for the treewidth/branchwidth of $H$-minor-free graphs. In particular, for every $\\varepsilon > 0$ and every $t$-vertex graph $H$ with Euler genus $g$, we give a $(g + \\varepsilon)$-approximation algorithm for the branchwidth of $H$-minor-free graphs running in $2^{\\mathsf{poly}(t) / \\varepsilon} \\cdot \\mathsf{poly}(n)$-time. Our algorithms explicitly return either an appropriate branch-decomposition or a grid-minor certifying a negative answer.",
      "authors": [
        "Maximilian Gorsky",
        "Giannos Stamoulis",
        "Dimitrios M. Thilikos",
        "and Sebastian Wiederrecht"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T11:41:09+00:00",
          "link": "https://arxiv.org/abs/2506.22857v1",
          "size": "152kb",
          "version": "v1"
        }
      ],
      "title": "Catching Rats in $H$-minor-free Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22857",
        "HTML": "https://arxiv.org/html/2506.22857v1",
        "PDF": "https://arxiv.org/pdf/2506.22857"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22882",
      "abstract": "Segmentation of brain structures from MRI is crucial for evaluating brain morphology, yet existing CNN and transformer-based methods struggle to delineate complex structures accurately. While current diffusion models have shown promise in image segmentation, they are inadequate when applied directly to brain MRI due to neglecting anatomical information. To address this, we propose Collaborative Anatomy Diffusion (CA-Diff), a framework integrating spatial anatomical features to enhance segmentation accuracy of the diffusion model. Specifically, we introduce distance field as an auxiliary anatomical condition to provide global spatial context, alongside a collaborative diffusion process to model its joint distribution with anatomical structures, enabling effective utilization of anatomical features for segmentation. Furthermore, we introduce a consistency loss to refine relationships between the distance field and anatomical structures and design a time adapted channel attention module to enhance the U-Net feature fusion procedure. Extensive experiments show that CA-Diff outperforms state-of-the-art (SOTA) methods.",
      "authors": [
        "Qilong Xing",
        "Zikai Song",
        "Yuteng Ye",
        "Yuke Chen",
        "Youjia Zhang",
        "Na Feng",
        "Junqing Yu",
        "Wei Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T13:39:09+00:00",
          "link": "https://arxiv.org/abs/2506.22882v1",
          "size": "1438kb",
          "version": "v1"
        }
      ],
      "title": "CA-Diff: Collaborative Anatomy Diffusion for Brain Tissue Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22882",
        "HTML": "https://arxiv.org/html/2506.22882v1",
        "PDF": "https://arxiv.org/pdf/2506.22882"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22903",
      "abstract": "Channel state information (CSI) is essential to unlock the potential of reconfigurable intelligent surfaces (RISs) in wireless communication systems. Since massive RIS elements are typically implemented without baseband signal processing capabilities, limited CSI feedback is necessary when designing the reflection/refraction coefficients of the RIS. In this article, the unique RIS-assisted channel features, such as the RIS position-dependent channel fluctuation, the ultra-high dimensional sub-channel matrix, and the structured sparsity, are distilled from recent advances in limited feedback and used as guidelines for designing feedback schemes. We begin by illustrating the use cases and the corresponding challenges associated with RIS feedback. We then discuss how to leverage techniques such as channel customization, structured-sparsity, autoencoders, and others to reduce feedback overhead and complexity when devising feedback schemes. Finally, we identify potential research directions by considering the unresolved challenges, the new RIS architecture, and the integration with multi-modal information and artificial intelligence.",
      "authors": [
        "Weicong Chen",
        "Jiajia Guo",
        "Yiming Cui",
        "Xiao Li",
        "Shi Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T14:38:21+00:00",
          "link": "https://arxiv.org/abs/2506.22903v1",
          "size": "1278kb",
          "version": "v1"
        }
      ],
      "title": "Limited Feedback in RIS-Assisted Wireless Communications: Use Cases, Challenges, and Future Directions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22903",
        "HTML": "https://arxiv.org/html/2506.22903v1",
        "PDF": "https://arxiv.org/pdf/2506.22903"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22923",
      "abstract": "Manufacturing industries are among the highest energy-consuming sectors, facing increasing pressure to reduce energy costs. This paper presents an energy-aware Model Predictive Control (MPC) framework to dynamically schedule manufacturing processes in response to time-varying electricity prices without compromising production goals or violating production constraints. A network-based manufacturing system model is developed to capture complex material flows, batch processing, and capacities of buffers and machines. The scheduling problem is formulated as a Mixed-Integer Quadratic Program (MIQP) that balances energy costs, buffer levels, and production requirements. A case study evaluates the proposed MPC framework under four industrial electricity pricing schemes. Numerical results demonstrate that the approach reduces energy usage expenses while satisfying production goals and adhering to production constraints. The findings highlight the importance of considering the detailed electricity cost structure in manufacturing scheduling decisions and provide practical insights for manufacturers when selecting among different electricity pricing strategies.",
      "authors": [
        "Hongliang Li",
        "Herschel C. Pangborn",
        "Ilya Kovalenko"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T15:18:00+00:00",
          "link": "https://arxiv.org/abs/2506.22923v1",
          "size": "522kb",
          "version": "v1"
        }
      ],
      "title": "Energy-Aware Model Predictive Control for Batch Manufacturing System Scheduling Under Different Electricity Pricing Strategies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22923",
        "HTML": "https://arxiv.org/html/2506.22923v1",
        "PDF": "https://arxiv.org/pdf/2506.22923"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22935",
      "abstract": "The ambiguity function is fundamental to radar waveform design, characterizing range and Doppler resolution capabilities. However, its traditional formulation involves non-differentiable operations, preventing integration with gradient-based optimization methods and modern machine learning frameworks. This paper presents the first complete mathematical framework and computational implementation for differentiable radar ambiguity functions. Our approach addresses the fundamental technical challenges that have prevented the radar community from leveraging automatic differentiation: proper handling of complex-valued gradients using Wirtinger calculus, efficient computation through parallelized FFT operations, numerical stability throughout cascaded operations, and composability with arbitrary differentiable operations. We term this approach GRAF (Gradient-based Radar Ambiguity Functions), which reformulates the ambiguity function computation to maintain mathematical equivalence while enabling gradient flow through the entire pipeline. The resulting implementation provides a general-purpose differentiable ambiguity function compatible with modern automatic differentiation frameworks, enabling new research directions including neural network-based waveform generation with ambiguity constraints, end-to-end optimization of radar systems, and integration of classical radar theory with modern deep learning. We provide complete implementation details and demonstrate computational efficiency suitable for practical applications. This work establishes the mathematical and computational foundation for applying modern machine learning techniques to radar waveform design, bridging classical radar signal processing with automatic differentiation frameworks.",
      "authors": [
        "Marc Bara Iniesta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T16:06:34+00:00",
          "link": "https://arxiv.org/abs/2506.22935v1",
          "size": "570kb",
          "version": "v1"
        }
      ],
      "title": "Differentiable Radar Ambiguity Functions: Mathematical Formulation and Computational Implementation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22935",
        "HTML": "https://arxiv.org/html/2506.22935v1",
        "PDF": "https://arxiv.org/pdf/2506.22935"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22952",
      "abstract": "Understanding brain dynamics through functional Magnetic Resonance Imaging (fMRI) remains a fundamental challenge in neuroscience, particularly in capturing how the brain transitions between various functional states. Recently, metastability, which refers to temporarily stable brain states, has offered a promising paradigm to quantify complex brain signals into interpretable, discretized representations. In particular, compared to cluster-based machine learning approaches, tokenization approaches leveraging vector quantization have shown promise in representation learning with powerful reconstruction and predictive capabilities. However, most existing methods ignore brain transition dependencies and lack a quantification of brain dynamics into representative and stable embeddings. In this study, we propose a Hierarchical State space-based Tokenization network, termed HST, which quantizes brain states and transitions in a hierarchical structure based on a state space-based model. We introduce a refined clustered Vector-Quantization Variational AutoEncoder (VQ-VAE) that incorporates quantization error feedback and clustering to improve quantization performance while facilitating metastability with representative and stable token representations. We validate our HST on two public fMRI datasets, demonstrating its effectiveness in quantifying the hierarchical dynamics of the brain and its potential in disease diagnosis and reconstruction performance. Our method offers a promising framework for the characterization of brain dynamics, facilitating the analysis of metastability.",
      "authors": [
        "Yanwu Yang",
        "Thomas Wolfers"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T17:12:18+00:00",
          "link": "https://arxiv.org/abs/2506.22952v1",
          "size": "1094kb",
          "version": "v1"
        }
      ],
      "title": "Hierarchical Characterization of Brain Dynamics via State Space-based Vector Quantization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22952",
        "HTML": "https://arxiv.org/html/2506.22952v1",
        "PDF": "https://arxiv.org/pdf/2506.22952"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22961",
      "abstract": "The MPC-in-the-head technique (Ishai et al., STOC 2007) is a celebrated method to build zero-knowledge protocols with desirable theoretical properties and high practical efficiency. This technique has generated a large body of research and has influenced the design of real-world post-quantum cryptographic signatures. In this work, we present a generalization of the MPC-in-the-head paradigm to the quantum setting, where the MPC is running a quantum computation. As an application of our framework, we propose a new approach to build zero-knowledge protocols where security holds even against a verifier that can obtain a superposition of transcripts. This notion was pioneered by Damgard et al., who built a zero-knowledge protocol for NP (in the common reference string model) secure against superposition attacks, by relying on perfectly hiding and unconditionally binding dual-mode commitments. Unfortunately, no such commitments are known from standard cryptographic assumptions. In this work we revisit this problem, and present two new three-round protocols in the common reference string model: (i) A zero-knowledge argument for NP, whose security reduces to the standard learning with errors (LWE) problem. (ii) A zero-knowledge argument for QMA from the same assumption.",
      "authors": [
        "Andrea Coladangelo",
        "Ruta Jawale",
        "Dakshita Khurana",
        "Giulio Malavolta",
        "Hendrik Waldner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T17:43:32+00:00",
          "link": "https://arxiv.org/abs/2506.22961v1",
          "size": "40kb",
          "version": "v1"
        }
      ],
      "title": "MPC in the Quantum Head (or: Superposition-Secure (Quantum) Zero-Knowledge)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22961",
        "HTML": "https://arxiv.org/html/2506.22961v1",
        "PDF": "https://arxiv.org/pdf/2506.22961"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22963",
      "abstract": "Cancer is a genetic disorder whose clonal evolution can be monitored by tracking noisy genome-wide copy number variants. We introduce the Copy Number Stochastic Block Model (CN-SBM), a probabilistic framework that jointly clusters samples and genomic regions based on discrete copy number states using a bipartite categorical block model. Unlike models relying on Gaussian or Poisson assumptions, CN-SBM respects the discrete nature of CNV calls and captures subpopulation-specific patterns through block-wise structure. Using a two-stage approach, CN-SBM decomposes CNV data into primary and residual components, enabling detection of both large-scale chromosomal alterations and finer aberrations. We derive a scalable variational inference algorithm for application to large cohorts and high-resolution data. Benchmarks on simulated and real datasets show improved model fit over existing methods. Applied to TCGA low-grade glioma data, CN-SBM reveals clinically relevant subtypes and structured residual variation, aiding patient stratification in survival analysis. These results establish CN-SBM as an interpretable, scalable framework for CNV analysis with direct relevance for tumor heterogeneity and prognosis.",
      "authors": [
        "Kevin Lam",
        "William Daniels",
        "J Maxwell Douglas",
        "Daniel Lai",
        "Samuel Aparicio",
        "Benjamin Bloem-Reddy",
        "Yongjin Park"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Genomics (q-bio.GN)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T17:45:45+00:00",
          "link": "https://arxiv.org/abs/2506.22963v1",
          "size": "2056kb",
          "version": "v1"
        }
      ],
      "title": "CN-SBM: Categorical Block Modelling For Primary and Residual Copy Number Variation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22963",
        "HTML": "https://arxiv.org/html/2506.22963v1",
        "PDF": "https://arxiv.org/pdf/2506.22963"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22966",
      "abstract": "Detection of collectively routing fleets of vehicles in future urban systems may become important for the management of traffic, as such routing may destabilize urban networks leading to deterioration of driving conditions. Accordingly, in this paper we discuss the question whether it is possible to determine the flow of fleet vehicles on all routes given the fleet size and behaviour as well as the combined total flow of fleet and non-fleet vehicles on every route. We prove that the answer to this Inverse Fleet Assignment Problem is 'yes' for myopic fleet strategies which are more 'selfish' than 'altruistic', and 'no' otherwise, under mild assumptions on route/link performance functions. To reach these conclusions we introduce the forward fleet assignment operator and study its properties, proving that it is invertible for 'bad' objectives of fleet controllers. We also discuss the challenges of implementing myopic fleet routing in the real world and compare it to Stackelberg and Nash routing. Finally, we show that optimal Stackelberg fleet routing could involve highly variable mixed strategies in some scenarios, which would likely cause chaos in the traffic network.",
      "authors": [
        "Grzegorz Jamr\\'oz",
        "Rafa{\\l} Kucharski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Multiagent Systems (cs.MA)",
        "Theoretical Economics (econ.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T17:56:38+00:00",
          "link": "https://arxiv.org/abs/2506.22966v1",
          "size": "3019kb",
          "version": "v1"
        }
      ],
      "title": "Detection of coordinated fleet vehicles in route choice urban games. Part I. Inverse fleet assignment theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22966",
        "HTML": "https://arxiv.org/html/2506.22966v1",
        "PDF": "https://arxiv.org/pdf/2506.22966"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22985",
      "abstract": "We propose a novel continuous-variable quantum key distribution (CVQKD) protocol that employs orthogonal frequency-division multiplexing (OFDM) in the terahertz (THz) band to enable high-throughput and secure quantum communication. By encoding quantum information across multiple subcarriers, the protocol enhances spectral efficiency and mitigates channel dispersion and atmospheric attenuation. We present a comprehensive security analysis under collective Gaussian attacks, considering both terrestrial free-space channels, accounting for humidity-induced absorption, and inter-satellite links, incorporating realistic intermodulation noise. Simulations show secret key rates (SKR) reaching ~72 bits per channel use in open-air conditions. While intermodulation noise imposes trade-offs, optimised modulation variance enables resilience and secure communication range. The maximum terrestrial quantum link extends up to 4.5 m due to atmospheric THz absorption, whereas inter-satellite links can support secure communication over distances exceeding 100 km, owing to minimal propagation channel losses in space. We evaluate the practical implementation of our protocol using recently developed on-chip coherent THz sources based on superconducting Josephson junctions. These compact, voltage-tunable emitters produce wideband coherent radiation, making them ideal candidates for integration in scalable quantum networks. By incorporating their characteristics into our simulations, we assess secure key generation under various environmental conditions. Our results show secure communication over distances up to 3 m in open air, and up to 26 km in cryogenic or vacuum environments. This work advances the prospect of compact, high-capacity CVQKD systems for both terrestrial and space-based THz quantum communication.",
      "authors": [
        "Mingqi Zhang and Kaveh Delfanazari"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Applied Physics (physics.app-ph)",
        "Instrumentation and Detectors (physics.ins-det)",
        "Optics (physics.optics)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T19:16:29+00:00",
          "link": "https://arxiv.org/abs/2506.22985v1",
          "size": "1623kb",
          "version": "v1"
        }
      ],
      "title": "Orthogonal Frequency Division Multiplexing Continuous Variable Terahertz Quantum Key Distribution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22985",
        "PDF": "https://arxiv.org/pdf/2506.22985"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23010",
      "abstract": "Mean-field characterizations of first-order iterative algorithms -- including Approximate Message Passing (AMP), stochastic and proximal gradient descent, and Langevin diffusions -- have enabled a precise understanding of learning dynamics in many statistical applications. For algorithms whose non-linearities have a coordinate-separable form, it is known that such characterizations enjoy a degree of universality with respect to the underlying data distribution. However, mean-field characterizations of non-separable algorithm dynamics have largely remained restricted to i.i.d. Gaussian or rotationally-invariant data.\n  In this work, we initiate a study of universality for non-separable AMP algorithms. We identify a general condition for AMP with polynomial non-linearities, in terms of a Bounded Composition Property (BCP) for their representing tensors, to admit a state evolution that holds universally for matrices with non-Gaussian entries. We then formalize a condition of BCP-approximability for Lipschitz AMP algorithms to enjoy a similar universal guarantee. We demonstrate that many common classes of non-separable non-linearities are BCP-approximable, including local denoisers, spectral denoisers for generic signals, and compositions of separable functions with generic linear maps, implying the universality of state evolution for AMP algorithms employing these non-linearities.",
      "authors": [
        "Max Lovig",
        "Tianhao Wang",
        "Zhou Fan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistics Theory (math.ST)",
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)",
        "Probability (math.PR)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-28T20:48:56+00:00",
          "link": "https://arxiv.org/abs/2506.23010v1",
          "size": "978kb",
          "version": "v1"
        }
      ],
      "title": "On Universality of Non-Separable Approximate Message Passing Algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23010",
        "PDF": "https://arxiv.org/pdf/2506.23010"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23040",
      "abstract": "Large language models are thought to have potential to aid in medical decision making. We investigate this here. We start with the treatment problem, the patient's core medical decision-making task, which is solved in collaboration with a healthcare provider. We discuss approaches to solving the treatment problem, including -- within evidence-based medicine -- trials and observational data. We then discuss the chat problem, and how this differs from the treatment problem -- in particular as it relates to imitation. We then discuss how a large language model might be used to solve the treatment problem and highlight some of the challenges that emerge. We finally discuss how these challenges relate to evidence-based medicine, and how this might inform next steps.",
      "authors": [
        "Samuel J. Weisenthal"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Other Statistics (stat.OT)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T00:23:06+00:00",
          "link": "https://arxiv.org/abs/2506.23040v1",
          "size": "65kb",
          "version": "v1"
        }
      ],
      "title": "Treatment, evidence, imitation, and chat",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23040",
        "HTML": "https://arxiv.org/html/2506.23040v1",
        "PDF": "https://arxiv.org/pdf/2506.23040"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23045",
      "abstract": "We communicate over wireless channels by first estimating and then equalizing the effective channel. In Zak-OTFS (orthogonal time frequency space) modulation the carrier waveform is a pulse in the delay-Doppler (DD) domain, formally a quasi-periodic localized function with specific periods along delay and Doppler. When the channel delay spread is less than the delay period, and the channel Doppler spread is less than the Doppler period, the response to a single Zak-OTFS carrier provides an image of the scattering environment and can be used to predict the effective channel at all other carriers. This makes channel estimation straightforward, and there is no loss in spectral efficiency since it is possible to design data and pilot signals that are mutually unbiased. However, the naive approach to equalization has complexity ${\\mathcal O}(M^3N^3)$ where $M$ and $N$ are respectively the number of delay and Doppler bins in an OTFS frame. We simplify equalization by transforming Zak-OTFS information symbols to CP-OFDM (cyclic prefix orthogonal frequency division multiplexing) modulation.\n  Why not simply communicate with CP-OFDM? Inter-carrier interference (ICI) in CP-OFDM makes it is very challenging to acquire the complete frequency domain (FD) channel response between subcarriers in the presence of mobility and delay spread. We avoid this difficulty by estimating the effective channel in the DD domain from which we are able to reconstruct the complete FD channel response. We take advantage of CP-OFDM to design an ${\\mathcal O}(M^2N^2)$ low-complexity method of jointly equalizing all subcarriers, where $MN$ is the number of subcarriers. Our approach removes the need for traditional pilots in CP-OFDM and reduces the need to vary carrier spacing with mobility.",
      "authors": [
        "Saif Khan Mohammed",
        "Sandesh Rao Mattu",
        "Nishant Mehrotra",
        "Venkatesh Khammammetti and Robert Calderbank"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T00:51:43+00:00",
          "link": "https://arxiv.org/abs/2506.23045v1",
          "size": "550kb",
          "version": "v1"
        }
      ],
      "title": "Zak-OFDM: Low Complexity Joint Equalization of OFDM Carriers in Doubly-Spread Channels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23045",
        "HTML": "https://arxiv.org/html/2506.23045v1",
        "PDF": "https://arxiv.org/pdf/2506.23045"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23062",
      "abstract": "Quantifying the convergence rate of the underdamped Langevin dynamics (ULD) is a classical topic, in large part due to the possibility for diffusive-to-ballistic speedups -- as was recently established for the continuous-time dynamics via space-time Poincare inequalities. A central challenge for analyzing ULD is that its degeneracy necessitates the development of new analysis approaches, e.g., the theory of hypocoercivity. In this paper, we give a new coupling-based framework for analyzing ULD and its numerical discretizations. First, in the continuous-time setting, we use this framework to establish new parabolic Harnack inequalities for ULD. These are the first Harnack inequalities that decay to zero in contractive settings, thereby reflecting the convergence properties of ULD in addition to just its regularity properties.\n  Second, we build upon these Harnack inequalities to develop a local error framework for analyzing discretizations of ULD in KL divergence. This extends our framework in part III from uniformly elliptic diffusions to degenerate diffusions, and shares its virtues: the framework is user-friendly, applies to sophisticated discretization schemes, and does not require contractivity. Applying this framework to the randomized midpoint discretization of ULD establishes (i) the first ballistic acceleration result for log-concave sampling (i.e., sublinear dependence on the condition number), and (ii) the first $d^{1/3}$ iteration complexity guarantee for sampling to constant total variation error in dimension $d$.",
      "authors": [
        "Jason M. Altschuler and Sinho Chewi and Matthew S. Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Probability (math.PR)",
        "Data Structures and Algorithms (cs.DS)",
        "Numerical Analysis (cs.NA)",
        "Analysis of PDEs (math.AP)",
        "Numerical Analysis (math.NA)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T02:22:04+00:00",
          "link": "https://arxiv.org/abs/2506.23062v1",
          "size": "226kb",
          "version": "v1"
        }
      ],
      "title": "Shifted Composition IV: Underdamped Langevin and Numerical Discretizations with Partial Acceleration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23062",
        "HTML": "https://arxiv.org/html/2506.23062v1",
        "PDF": "https://arxiv.org/pdf/2506.23062"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23102",
      "abstract": "The recent release of RadGenome-Chest CT has significantly advanced CT-based report generation. However, existing methods primarily focus on global features, making it challenging to capture region-specific details, which may cause certain abnormalities to go unnoticed. To address this, we propose MedRegion-CT, a region-focused Multi-Modal Large Language Model (MLLM) framework, featuring three key innovations. First, we introduce Region Representative ($R^2$) Token Pooling, which utilizes a 2D-wise pretrained vision model to efficiently extract 3D CT features. This approach generates global tokens representing overall slice features and region tokens highlighting target areas, enabling the MLLM to process comprehensive information effectively. Second, a universal segmentation model generates pseudo-masks, which are then processed by a mask encoder to extract region-centric features. This allows the MLLM to focus on clinically relevant regions, using six predefined region masks. Third, we leverage segmentation results to extract patient-specific attributions, including organ size, diameter, and locations. These are converted into text prompts, enriching the MLLM's understanding of patient-specific contexts. To ensure rigorous evaluation, we conducted benchmark experiments on report generation using the RadGenome-Chest CT. MedRegion-CT achieved state-of-the-art performance, outperforming existing methods in natural language generation quality and clinical relevance while maintaining interpretability. The code for our framework is publicly available.",
      "authors": [
        "Sunggu Kyung",
        "Jinyoung Seo",
        "Hyunseok Lim",
        "Dongyeong Kim",
        "Hyungbin Park",
        "Jimin Sung",
        "Jihyun Kim",
        "Wooyoung Jo",
        "Yoojin Nam",
        "Namkug Kim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T06:08:55+00:00",
          "link": "https://arxiv.org/abs/2506.23102v1",
          "size": "6745kb",
          "version": "v1"
        }
      ],
      "title": "MedRegion-CT: Region-Focused Multimodal LLM for Comprehensive 3D CT Report Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23102",
        "HTML": "https://arxiv.org/html/2506.23102v1",
        "PDF": "https://arxiv.org/pdf/2506.23102"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23121",
      "abstract": "Multi-organ medical segmentation is a crucial component of medical image processing, essential for doctors to make accurate diagnoses and develop effective treatment plans. Despite significant progress in this field, current multi-organ segmentation models often suffer from inaccurate details, dependence on geometric prompts and loss of spatial information. Addressing these challenges, we introduce a novel model named CRISP-SAM2 with CRoss-modal Interaction and Semantic Prompting based on SAM2. This model represents a promising approach to multi-organ medical segmentation guided by textual descriptions of organs. Our method begins by converting visual and textual inputs into cross-modal contextualized semantics using a progressive cross-attention interaction mechanism. These semantics are then injected into the image encoder to enhance the detailed understanding of visual information. To eliminate reliance on geometric prompts, we use a semantic prompting strategy, replacing the original prompt encoder to sharpen the perception of challenging targets. In addition, a similarity-sorting self-updating strategy for memory and a mask-refining process is applied to further adapt to medical imaging and enhance localized details. Comparative experiments conducted on seven public datasets indicate that CRISP-SAM2 outperforms existing models. Extensive analysis also demonstrates the effectiveness of our method, thereby confirming its superior performance, especially in addressing the limitations mentioned earlier. Our code is available at: https://github.com/YU-deep/CRISP\\_SAM2.git.",
      "authors": [
        "Xinlei Yu",
        "Chanmiao Wang",
        "Hui Jin",
        "Ahmed Elazab",
        "Gangyong Jia",
        "Xiang Wan",
        "Changqing Zou",
        "Ruiquan Ge"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T07:05:27+00:00",
          "link": "https://arxiv.org/abs/2506.23121v1",
          "size": "3210kb",
          "version": "v1"
        }
      ],
      "title": "CRISP-SAM2: SAM2 with Cross-Modal Interaction and Semantic Prompting for Multi-Organ Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23121",
        "HTML": "https://arxiv.org/html/2506.23121v1",
        "PDF": "https://arxiv.org/pdf/2506.23121"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23173",
      "abstract": "In the rapidly evolving field of optical engineering, precise alignment of multi-lens imaging systems is critical yet challenging, as even minor misalignments can significantly degrade performance. Traditional alignment methods rely on specialized equipment and are time-consuming processes, highlighting the need for automated and scalable solutions. We present two complementary deep learning-based inverse-design methods for diagnosing misalignments in multi-element lens systems using only optical measurements. First, we use ray-traced spot diagrams to predict five-degree-of-freedom (5-DOF) errors in a 6-lens photographic prime, achieving a mean absolute error of 0.031mm in lateral translation and 0.011$^\\circ$ in tilt. We also introduce a physics-based simulation pipeline that utilizes grayscale synthetic camera images, enabling a deep learning model to estimate 4-DOF, decenter and tilt errors in both two- and six-lens multi-lens systems. These results show the potential to reshape manufacturing and quality control in precision imaging.",
      "authors": [
        "Tomer Slor",
        "Dean Oren",
        "Shira Baneth",
        "Tom Coen",
        "Haim Suchowski"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optics (physics.optics)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T10:13:40+00:00",
          "link": "https://arxiv.org/abs/2506.23173v1",
          "size": "2763kb",
          "version": "v1"
        }
      ],
      "title": "Deep Learning for Optical Misalignment Diagnostics in Multi-Lens Imaging Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23173",
        "HTML": "https://arxiv.org/html/2506.23173v1",
        "PDF": "https://arxiv.org/pdf/2506.23173"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23184",
      "abstract": "Hematoxylin and eosin (H&E) staining visualizes histology but lacks specificity for diagnostic markers. Immunohistochemistry (IHC) staining provides protein-targeted staining but is restricted by tissue availability and antibody specificity. Virtual staining, i.e., computationally translating the H&E image to its IHC counterpart while preserving the tissue structure, is promising for efficient IHC generation. Existing virtual staining methods still face key challenges: 1) effective decomposition of staining style and tissue structure, 2) controllable staining process adaptable to diverse tissue and proteins, and 3) rigorous structural consistency modelling to handle the non-pixel-aligned nature of paired H&E and IHC images. This study proposes a mutual-information (MI)-guided score-based diffusion model for unpaired virtual staining. Specifically, we design 1) a global MI-guided energy function that disentangles the tissue structure and staining characteristics across modalities, 2) a novel timestep-customized reverse diffusion process for precise control of the staining intensity and structural reconstruction, and 3) a local MI-driven contrastive learning strategy to ensure the cellular level structural consistency between H&E-IHC images. Extensive experiments demonstrate the our superiority over state-of-the-art approaches, highlighting its biomedical potential. Codes will be open-sourced upon acceptance.",
      "authors": [
        "Anran Liu",
        "Xiaofei Wang",
        "Jing Cai",
        "Chao Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T11:02:45+00:00",
          "link": "https://arxiv.org/abs/2506.23184v1",
          "size": "1454kb",
          "version": "v1"
        }
      ],
      "title": "Score-based Diffusion Model for Unpaired Virtual Histology Staining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23184",
        "HTML": "https://arxiv.org/html/2506.23184v1",
        "PDF": "https://arxiv.org/pdf/2506.23184"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23203",
      "abstract": "As a green MIMO structure, massive H$^2$AD is viewed as a potential technology for the future 6G wireless network. For such a structure, it is a challenging task to design a low-complexity and high-performance fusion of target direction values sensed by different sub-array groups with fewer use of prior knowledge. To address this issue, a lightweight Cramer-Rao lower bound (CRLB)-ratio-weight fusion (WF) method is proposed, which approximates inverse CRLB of each subarray using antenna number reciprocals to eliminate real-time CRLB computation. This reduces complexity and prior knowledge dependence while preserving fusion performance. Moreover, a multi-branch deep neural network (MBDNN) is constructed to further enhance direction-of-arrival (DOA) sensing by leveraging candidate angles from multiple subarrays. The subarray-specific branch networks are integrated with a shared regression module to effectively eliminate pseudo-solutions and fuse true angles. Simulation results show that the proposed CRLB-ratio-WF method achieves DOA sensing performance comparable to CRLB-based methods, while significantly reducing the reliance on prior knowledge. More notably, the proposed MBDNN has superior performance in low-SNR ranges. At SNR $= -15$ dB, it achieves an order-of-magnitude improvement in estimation accuracy compared to CRLB-ratio-WF method.",
      "authors": [
        "Feng Shu",
        "Jiatong Bai",
        "Di Wu",
        "Wei Zhu",
        "Bin Deng",
        "Fuhui Zhou",
        "and Jiangzhou Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T12:14:59+00:00",
          "link": "https://arxiv.org/abs/2506.23203v1",
          "size": "767kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Branch DNN and CRLB-Ratio-Weight Fusion for Enhanced DOA Sensing via a Massive H$^2$AD MIMO Receiver",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23203",
        "HTML": "https://arxiv.org/html/2506.23203v1",
        "PDF": "https://arxiv.org/pdf/2506.23203"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23208",
      "abstract": "We present our solution for the Multi-Source COVID-19 Detection Challenge, which aims to classify chest CT scans into COVID and Non-COVID categories across data collected from four distinct hospitals and medical centers. A major challenge in this task lies in the domain shift caused by variations in imaging protocols, scanners, and patient populations across institutions. To enhance the cross-domain generalization of our model, we incorporate Variance Risk Extrapolation (VREx) into the training process. VREx encourages the model to maintain consistent performance across multiple source domains by explicitly minimizing the variance of empirical risks across environments. This regularization strategy reduces overfitting to center-specific features and promotes learning of domain-invariant representations. We further apply Mixup data augmentation to improve generalization and robustness. Mixup interpolates both the inputs and labels of randomly selected pairs of training samples, encouraging the model to behave linearly between examples and enhancing its resilience to noise and limited data. Our method achieves an average macro F1 score of 0.96 across the four sources on the validation set, demonstrating strong generalization.",
      "authors": [
        "Runtian Yuan",
        "Qingqiu Li",
        "Junlin Hou",
        "Jilan Xu",
        "Yuejie Zhang",
        "Rui Feng",
        "Hao Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T12:34:57+00:00",
          "link": "https://arxiv.org/abs/2506.23208v1",
          "size": "319kb",
          "version": "v1"
        }
      ],
      "title": "Multi-Source COVID-19 Detection via Variance Risk Extrapolation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23208",
        "HTML": "https://arxiv.org/html/2506.23208v1",
        "PDF": "https://arxiv.org/pdf/2506.23208"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23259",
      "abstract": "Myocardial infarction is a major cause of death globally, and accurate early diagnosis from electrocardiograms (ECGs) remains a clinical priority. Deep learning models have shown promise for automated ECG interpretation, but require large amounts of labeled data, which are often scarce in practice. We propose a physiology-aware pipeline that (i) synthesizes 12-lead ECGs with tunable MI morphology and realistic noise, and (ii) pre-trains recurrent and transformer classifiers with self-supervised masked-autoencoding plus a joint reconstruction-classification objective. We validate the realism of synthetic ECGs via statistical and visual analysis, confirming that key morphological features are preserved. Pretraining on synthetic data consistently improved classification performance, particularly in low-data settings, with AUC gains of up to 4 percentage points. These results show that controlled synthetic ECGs can help improve MI detection when real clinical data is limited.",
      "authors": [
        "Lachin Naghashyar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T14:29:55+00:00",
          "link": "https://arxiv.org/abs/2506.23259v1",
          "size": "713kb",
          "version": "v1"
        }
      ],
      "title": "Improving Myocardial Infarction Detection via Synthetic ECG Pretraining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23259",
        "HTML": "https://arxiv.org/html/2506.23259v1",
        "PDF": "https://arxiv.org/pdf/2506.23259"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23305",
      "abstract": "Bronchopulmonary dysplasia (BPD) is a common complication among preterm neonates, with portable X-ray imaging serving as the standard diagnostic modality in neonatal intensive care units (NICUs). However, lung magnetic resonance imaging (MRI) offers a non-invasive alternative that avoids sedation and radiation while providing detailed insights into the underlying mechanisms of BPD. Leveraging high-resolution 3D MRI data, advanced image processing and semantic segmentation algorithms can be developed to assist clinicians in identifying the etiology of BPD. In this dataset, we present MRI scans paired with corresponding semantic segmentations of the lungs and trachea for 40 neonates, the majority of whom are diagnosed with BPD. The imaging data consist of free-breathing 3D stack-of-stars radial gradient echo acquisitions, known as the StarVIBE series. Additionally, we provide comprehensive clinical data and baseline segmentation models, validated against clinical assessments, to support further research and development in neonatal lung imaging.",
      "authors": [
        "Rachit Saluja",
        "Arzu Kovanlikaya",
        "Candace Chien",
        "Lauren Kathryn Blatt",
        "Jeffrey M. Perlman",
        "Stefan Worgall",
        "Mert R. Sabuncu",
        "Jonathan P. Dyke"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:51:31+00:00",
          "link": "https://arxiv.org/abs/2506.23305v1",
          "size": "11291kb",
          "version": "v1"
        }
      ],
      "title": "BPD-Neo: An MRI Dataset for Lung-Trachea Segmentation with Clinical Data for Neonatal Bronchopulmonary Dysplasia",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23305",
        "HTML": "https://arxiv.org/html/2506.23305v1",
        "PDF": "https://arxiv.org/pdf/2506.23305"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23309",
      "abstract": "In contemporary surgical research and practice, accurately comprehending 3D surgical scenes with text-promptable capabilities is particularly crucial for surgical planning and real-time intra-operative guidance, where precisely identifying and interacting with surgical tools and anatomical structures is paramount. However, existing works focus on surgical vision-language model (VLM), 3D reconstruction, and segmentation separately, lacking support for real-time text-promptable 3D queries. In this paper, we present SurgTPGS, a novel text-promptable Gaussian Splatting method to fill this gap. We introduce a 3D semantics feature learning strategy incorporating the Segment Anything model and state-of-the-art vision-language models. We extract the segmented language features for 3D surgical scene reconstruction, enabling a more in-depth understanding of the complex surgical environment. We also propose semantic-aware deformation tracking to capture the seamless deformation of semantic features, providing a more precise reconstruction for both texture and semantic features. Furthermore, we present semantic region-aware optimization, which utilizes regional-based semantic information to supervise the training, particularly promoting the reconstruction quality and semantic smoothness. We conduct comprehensive experiments on two real-world surgical datasets to demonstrate the superiority of SurgTPGS over state-of-the-art methods, highlighting its potential to revolutionize surgical practices. SurgTPGS paves the way for developing next-generation intelligent surgical systems by enhancing surgical precision and safety. Our code is available at: https://github.com/lastbasket/SurgTPGS.",
      "authors": [
        "Yiming Huang",
        "Long Bai",
        "Beilei Cui",
        "Kun Yuan",
        "Guankun Wang",
        "Mobarakol Islam",
        "Nicolas Padoy",
        "Nassir Navab",
        "Hongliang Ren"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T15:55:01+00:00",
          "link": "https://arxiv.org/abs/2506.23309v1",
          "size": "911kb",
          "version": "v1"
        }
      ],
      "title": "SurgTPGS: Semantic 3D Surgical Scene Understanding with Text Promptable Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23309",
        "HTML": "https://arxiv.org/html/2506.23309v1",
        "PDF": "https://arxiv.org/pdf/2506.23309"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23311",
      "abstract": "We introduce MRF-DiPh, a novel physics informed denoising diffusion approach for multiparametric tissue mapping from highly accelerated, transient-state quantitative MRI acquisitions like Magnetic Resonance Fingerprinting (MRF). Our method is derived from a proximal splitting formulation, incorporating a pretrained denoising diffusion model as an effective image prior to regularize the MRF inverse problem. Further, during reconstruction it simultaneously enforces two key physical constraints: (1) k-space measurement consistency and (2) adherence to the Bloch response model. Numerical experiments on in-vivo brain scans data show that MRF-DiPh outperforms deep learning and compressed sensing MRF baselines, providing more accurate parameter maps while better preserving measurement fidelity and physical model consistency-critical for solving reliably inverse problems in medical imaging.",
      "authors": [
        "Perla Mayo",
        "Carolin M. Pirkl",
        "Alin Achim",
        "Bjoern Menze",
        "and Mohammad Golbabaee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Machine Learning (cs.LG)",
        "Medical Physics (physics.med-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T16:00:32+00:00",
          "link": "https://arxiv.org/abs/2506.23311v1",
          "size": "1857kb",
          "version": "v1"
        }
      ],
      "title": "Physics informed guided diffusion for accelerated multi-parametric MRI reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23311",
        "HTML": "https://arxiv.org/html/2506.23311v1",
        "PDF": "https://arxiv.org/pdf/2506.23311"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23334",
      "abstract": "Federated learning (FL) has emerged as a promising paradigm for collaboratively training deep learning models across institutions without exchanging sensitive medical data. However, its effectiveness is often hindered by limited data availability and non-independent, identically distributed data across participating clients, which can degrade model performance and generalization. To address these challenges, we propose a generative AI based data augmentation framework that integrates synthetic image sharing into the federated training process for breast cancer diagnosis via ultrasound images. Specifically, we train two simple class-specific Deep Convolutional Generative Adversarial Networks: one for benign and one for malignant lesions. We then simulate a realistic FL setting using three publicly available breast ultrasound image datasets: BUSI, BUS-BRA, and UDIAT. FedAvg and FedProx are adopted as baseline FL algorithms. Experimental results show that incorporating a suitable number of synthetic images improved the average AUC from 0.9206 to 0.9237 for FedAvg and from 0.9429 to 0.9538 for FedProx. We also note that excessive use of synthetic data reduced performance, underscoring the importance of maintaining a balanced ratio of real and synthetic samples. Our findings highlight the potential of generative AI based data augmentation to enhance FL results in the breast ultrasound image classification task.",
      "authors": [
        "Hongyi Pan",
        "Ziliang Hong",
        "Gorkem Durak",
        "Ziyue Xu",
        "Ulas Bagci"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T17:05:50+00:00",
          "link": "https://arxiv.org/abs/2506.23334v1",
          "size": "1048kb",
          "version": "v1"
        }
      ],
      "title": "Federated Breast Cancer Detection Enhanced by Synthetic Ultrasound Image Augmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23334",
        "HTML": "https://arxiv.org/html/2506.23334v1",
        "PDF": "https://arxiv.org/pdf/2506.23334"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23371",
      "abstract": "Multi-Pitch Estimation (MPE) continues to be a sought after capability of Music Information Retrieval (MIR) systems, and is critical for many applications and downstream tasks involving pitch, including music transcription. However, existing methods are largely based on supervised learning, and there are significant challenges in collecting annotated data for the task. Recently, self-supervised techniques exploiting intrinsic properties of pitch and harmonic signals have shown promise for both monophonic and polyphonic pitch estimation, but these still remain inferior to supervised methods. In this work, we extend the classic supervised MPE paradigm by incorporating several self-supervised objectives based on pitch-invariant and pitch-equivariant properties. This joint training results in a substantial improvement under closed training conditions, which naturally suggests that applying the same objectives to a broader collection of data will yield further improvements. However, in doing so we uncover a phenomenon whereby our model simultaneously overfits to the supervised data while degenerating on data used for self-supervision only. We demonstrate and investigate this and offer our insights on the underlying problem.",
      "authors": [
        "Frank Cwitkowitz and Zhiyao Duan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T19:10:51+00:00",
          "link": "https://arxiv.org/abs/2506.23371v1",
          "size": "165kb",
          "version": "v1"
        }
      ],
      "title": "Investigating an Overfitting and Degeneration Phenomenon in Self-Supervised Multi-Pitch Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23371",
        "HTML": "https://arxiv.org/html/2506.23371v1",
        "PDF": "https://arxiv.org/pdf/2506.23371"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23396",
      "abstract": "The opacity of many supervised learning algorithms remains a key challenge, hindering scientific discovery and limiting broader deployment -- particularly in high-stakes domains. This paper develops model- and distribution-agnostic significance tests to assess the influence of input features in any regression or classification algorithm. Our method evaluates a feature's incremental contribution to model performance by masking its values across samples. Under the null hypothesis, the distribution of performance differences across a test set has a non-positive median. We construct a uniformly most powerful, randomized sign test for this median, yielding exact p-values for assessing feature significance and confidence intervals with exact coverage for estimating population-level feature importance. The approach requires minimal assumptions, avoids model retraining or auxiliary models, and remains computationally efficient even for large-scale, high-dimensional settings. Experiments on synthetic tasks validate its statistical and computational advantages, and applications to real-world data illustrate its practical utility.",
      "authors": [
        "Kay Giesecke",
        "Enguerrand Horel",
        "Chartsiri Jirachotkulthorn"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T21:15:40+00:00",
          "link": "https://arxiv.org/abs/2506.23396v1",
          "size": "1493kb",
          "version": "v1"
        }
      ],
      "title": "AICO: Feature Significance Tests for Supervised Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23396",
        "HTML": "https://arxiv.org/html/2506.23396v1",
        "PDF": "https://arxiv.org/pdf/2506.23396"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23416",
      "abstract": "Pearson's chi-squared test is widely used to assess the uniformity of discrete histograms, typically relying on a continuous chi-squared distribution to approximate the test statistic, since computing the exact distribution is computationally too costly. While effective in many cases, this approximation allegedly fails when expected bin counts are low or tail probabilities are needed. Here, Zero-disparity Distribution Synthesis is presented, a fast dynamic programming approach for computing the exact distribution, enabling detailed analysis of approximation errors. The results dispel some existing misunderstandings and also reveal subtle, but significant pitfalls in approximation that are only apparent with exact values. The Python source code is available at https://github.com/DiscreteTotalVariation/ChiSquared.",
      "authors": [
        "Nikola Bani\\'c and Neven Elezovi\\'c"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Mathematical Software (cs.MS)",
        "Computation (stat.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T22:22:40+00:00",
          "link": "https://arxiv.org/abs/2506.23416v1",
          "size": "5697kb",
          "version": "v1"
        }
      ],
      "title": "Zero-disparity Distribution Synthesis: Fast Exact Calculation of Chi-Squared Statistic Distribution for Discrete Uniform Histograms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23416",
        "HTML": "https://arxiv.org/html/2506.23416v1",
        "PDF": "https://arxiv.org/pdf/2506.23416"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23429",
      "abstract": "In this work, we propose a novel machine learning approach to compute the optimal transport map between two continuous distributions from their unpaired samples, based on the DeepParticle methods. The proposed method leads to a min-min optimization during training and does not impose any restriction on the network structure. Theoretically we establish a weak convergence guarantee and a quantitative error bound between the learned map and the optimal transport map. Our numerical experiments validate the theoretical results and the effectiveness of the new approach, particularly on real-world tasks.",
      "authors": [
        "Yingyuan Li",
        "Aokun Wang",
        "Zhongjian Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-29T23:32:39+00:00",
          "link": "https://arxiv.org/abs/2506.23429v1",
          "size": "9927kb",
          "version": "v1"
        }
      ],
      "title": "DPOT: A DeepParticle method for Computation of Optimal Transport with convergence guarantee",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23429",
        "HTML": "https://arxiv.org/html/2506.23429v1",
        "PDF": "https://arxiv.org/pdf/2506.23429"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23453",
      "abstract": "Covariate shift occurs when the distribution of input features differs between the training and testing phases. In covariate shift, estimating an unknown function's moment is a classical problem that remains under-explored, despite its common occurrence in real-world scenarios. In this paper, we investigate the minimax lower bound of the problem when the source and target distributions are known. To achieve the minimax optimal bound (up to a logarithmic factor), we propose a two-stage algorithm. Specifically, it first trains an optimal estimator for the function under the source distribution, and then uses a likelihood ratio reweighting procedure to calibrate the moment estimator. In practice, the source and target distributions are typically unknown, and estimating the likelihood ratio may be unstable. To solve this problem, we propose a truncated version of the estimator that ensures double robustness and provide the corresponding upper bound. Extensive numerical studies on synthetic examples confirm our theoretical findings and further illustrate the effectiveness of our proposed method.",
      "authors": [
        "Zhen Zhang",
        "Xin Liu",
        "Shaoli Wang",
        "Jiaye Teng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T01:32:36+00:00",
          "link": "https://arxiv.org/abs/2506.23453v1",
          "size": "625kb",
          "version": "v1"
        }
      ],
      "title": "Minimax Optimal Two-Stage Algorithm For Moment Estimation Under Covariate Shift",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23453",
        "HTML": "https://arxiv.org/html/2506.23453v1",
        "PDF": "https://arxiv.org/pdf/2506.23453"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23456",
      "abstract": "Certain tasks in high-dimensional statistics become easier when the underlying distribution satisfies a local-to-global property called approximate tensorization of entropy (ATE). For example, the Glauber dynamics Markov chain of an ATE distribution mixes fast and can produce approximate samples in a small amount of time, since such a distribution satisfies a modified log-Sobolev inequality. Moreover, identity-testing for an ATE distribution requires few samples if the tester is given coordinate conditional access to the unknown distribution, as shown by Blanca, Chen, \\v{S}tefankovi\\v{c}, and Vigoda (COLT 2023).\n  A natural class of distributions that do not satisfy ATE consists of mixtures of (few) distributions that do satisfy ATE. We study the complexity of identity-testing and sampling for these distributions. Our main results are the following:\n  1. We show fast mixing of Glauber dynamics from a data-based initialization, with optimal sample complexity, for mixtures of distributions satisfying modified log-Sobolev inequalities. This extends work of Huang, Koehler, Lee, Mohanty, Rajaraman, Vuong, and Wu (STOC 2025, COLT 2025) for mixtures of distributions satisfying Poincar\\'e inequalities.\n  2. Answering an open question posed by Blanca et al., we give efficient identity-testers for mixtures of ATE distributions in the coordinate-conditional sampling access model. We also give some simplifications and improvements to the original algorithm of Blanca et al.",
      "authors": [
        "William Gay",
        "William He",
        "Nicholas Kocurek",
        "Ryan O'Donnell"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistics Theory (math.ST)",
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T01:36:32+00:00",
          "link": "https://arxiv.org/abs/2506.23456v1",
          "size": "28kb",
          "version": "v1"
        }
      ],
      "title": "Sampling and Identity-Testing Without Approximate Tensorization of Entropy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23456",
        "HTML": "https://arxiv.org/html/2506.23456v1",
        "PDF": "https://arxiv.org/pdf/2506.23456"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23466",
      "abstract": "Low-dose computed tomography (LDCT) reduces radiation exposure but suffers from image artifacts and loss of detail due to quantum and electronic noise, potentially impacting diagnostic accuracy. Transformer combined with diffusion models has been a promising approach for image generation. Nevertheless, existing methods exhibit limitations in preserving finegrained image details. To address this issue, frequency domain-directed diffusion transformer (FD-DiT) is proposed for LDCT reconstruction. FD-DiT centers on a diffusion strategy that progressively introduces noise until the distribution statistically aligns with that of LDCT data, followed by denoising processing. Furthermore, we employ a frequency decoupling technique to concentrate noise primarily in high-frequency domain, thereby facilitating effective capture of essential anatomical structures and fine details. A hybrid denoising network is then utilized to optimize the overall data reconstruction process. To enhance the capability in recognizing high-frequency noise, we incorporate sliding sparse local attention to leverage the sparsity and locality of shallow-layer information, propagating them via skip connections for improving feature representation. Finally, we propose a learnable dynamic fusion strategy for optimal component integration. Experimental results demonstrate that at identical dose levels, LDCT images reconstructed by FD-DiT exhibit superior noise and artifact suppression compared to state-of-the-art methods.",
      "authors": [
        "Qiqing Liu",
        "Guoquan Wei",
        "Zekun Zhou",
        "Yiyang Wen",
        "Liu Shi and Qiegen Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Medical Physics (physics.med-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T02:16:38+00:00",
          "link": "https://arxiv.org/abs/2506.23466v1",
          "size": "2054kb",
          "version": "v1"
        }
      ],
      "title": "FD-DiT: Frequency Domain-Directed Diffusion Transformer for Low-Dose CT Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23466",
        "PDF": "https://arxiv.org/pdf/2506.23466"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23487",
      "abstract": "We propose a novel test for assessing partial effects in Frechet regression on Bures Wasserstein manifolds. Our approach employs a sample splitting strategy: the first subsample is used to fit the Frechet regression model, yielding estimates of the covariance matrices and their associated optimal transport maps, while the second subsample is used to construct the test statistic. We prove that this statistic converges in distribution to a weighted mixture of chi squared components, where the weights correspond to the eigenvalues of an integral operator defined by an appropriate RKHS kernel. We establish that our procedure achieves the nominal asymptotic size and demonstrate that its worst-case power converges uniformly to one. Through extensive simulations and a real data application, we illustrate the test's finite-sample accuracy and practical utility.",
      "authors": [
        "Haoshu Xu",
        "Hongzhe Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T03:20:05+00:00",
          "link": "https://arxiv.org/abs/2506.23487v1",
          "size": "179kb",
          "version": "v1"
        }
      ],
      "title": "Test of partial effects for Frechet regression on Bures-Wasserstein manifolds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23487",
        "HTML": "https://arxiv.org/html/2506.23487v1",
        "PDF": "https://arxiv.org/pdf/2506.23487"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23490",
      "abstract": "Echocardiography is routine for cardiac examination. However, 2D ultrasound (US) struggles with accurate metric calculation and direct observation of 3D cardiac structures. Moreover, 3D US is limited by low resolution, small field of view and scarce availability in practice. Constructing the cardiac anatomical twin from 2D images is promising to provide precise treatment planning and clinical quantification. However, it remains challenging due to the rare paired data, complex structures, and US noises. In this study, we introduce a novel generative framework UltraTwin, to obtain cardiac anatomical twin from sparse multi-view 2D US. Our contribution is three-fold. First, pioneered the construction of a real-world and high-quality dataset containing strictly paired multi-view 2D US and CT, and pseudo-paired data. Second, we propose a coarse-to-fine scheme to achieve hierarchical reconstruction optimization. Last, we introduce an implicit autoencoder for topology-aware constraints. Extensive experiments show that UltraTwin reconstructs high-quality anatomical twins versus strong competitors. We believe it advances anatomical twin modeling for potential applications in personalized cardiac care.",
      "authors": [
        "Junxuan Yu",
        "Yaofei Duan",
        "Yuhao Huang",
        "Yu Wang",
        "Rongbo Ling",
        "Weihao Luo",
        "Ang Zhang",
        "Jingxian Xu",
        "Qiongying Ni",
        "Yongsong Zhou",
        "Binghan Li",
        "Haoran Dou",
        "Liping Liu",
        "Yanfen Chu",
        "Feng Geng",
        "Zhe Sheng",
        "Zhifeng Ding",
        "Dingxin Zhang",
        "Rui Huang",
        "Yuhang Zhang",
        "Xiaowei Xu",
        "Tao Tan",
        "Dong Ni",
        "Zhongshan Gou",
        "Xin Yang"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T03:27:42+00:00",
          "link": "https://arxiv.org/abs/2506.23490v1",
          "size": "5507kb",
          "version": "v1"
        }
      ],
      "title": "UltraTwin: Towards Cardiac Anatomical Twin Generation from Multi-view 2D Ultrasound",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23490",
        "HTML": "https://arxiv.org/html/2506.23490v1",
        "PDF": "https://arxiv.org/pdf/2506.23490"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23499",
      "abstract": "The unbounded knapsack problem can be considered as a particular case of the double partition problem that asks for a number of nonnegative integer solutions to a system of two linear Diophantine equations with integer coefficients. In the middle of 19th century Sylvester and Cayley suggested an approach based on the variable elimination allowing a reduction of a double partition to a sum of scalar partitions. This manuscript discusses a geometric interpretation of this method and its application to the knapsack problem.",
      "authors": [
        "Boris Y. Rubinstein"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Number Theory (math.NT)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T03:44:25+00:00",
          "link": "https://arxiv.org/abs/2506.23499v1",
          "size": "43kb",
          "version": "v1"
        }
      ],
      "title": "Unbounded knapsack problem and double partitions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23499",
        "HTML": "https://arxiv.org/html/2506.23499v1",
        "PDF": "https://arxiv.org/pdf/2506.23499"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23506",
      "abstract": "Lung magnetic resonance imaging (MRI) with ultrashort echo-time (UTE) represents a recent breakthrough in lung structure imaging, providing image resolution and quality comparable to computed tomography (CT). Due to the absence of ionising radiation, MRI is often preferred over CT in paediatric diseases such as cystic fibrosis (CF), one of the most common genetic disorders in Caucasians. To assess structural lung damage in CF imaging, CT scoring systems provide valuable quantitative insights for disease diagnosis and progression. However, few quantitative scoring systems are available in structural lung MRI (e.g., UTE-MRI). To provide fast and accurate quantification in lung MRI, we investigated the feasibility of novel Artificial intelligence-assisted Pixel-level Lung (APL) scoring for CF. APL scoring consists of 5 stages, including 1) image loading, 2) AI lung segmentation, 3) lung-bounded slice sampling, 4) pixel-level annotation, and 5) quantification and reporting. The results shows that our APL scoring took 8.2 minutes per subject, which was more than twice as fast as the previous grid-level scoring. Additionally, our pixel-level scoring was statistically more accurate (p=0.021), while strongly correlating with grid-level scoring (R=0.973, p=5.85e-9). This tool has great potential to streamline the workflow of UTE lung MRI in clinical settings, and be extended to other structural lung MRI sequences (e.g., BLADE MRI), and for other lung diseases (e.g., bronchopulmonary dysplasia).",
      "authors": [
        "Bowen Xin",
        "Rohan Hickey",
        "Tamara Blake",
        "Jin Jin",
        "Claire E Wainwright",
        "Thomas Benkert",
        "Alto Stemmer",
        "Peter Sly",
        "David Coman",
        "Jason Dowling"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Medical Physics (physics.med-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T04:08:42+00:00",
          "link": "https://arxiv.org/abs/2506.23506v1",
          "size": "2247kb",
          "version": "v1"
        }
      ],
      "title": "Artificial Intelligence-assisted Pixel-level Lung (APL) Scoring for Fast and Accurate Quantification in Ultra-short Echo-time MRI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23506",
        "PDF": "https://arxiv.org/pdf/2506.23506"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23510",
      "abstract": "Course-prerequisite networks (CPNs) are directed acyclic graphs that model complex academic curricula by representing courses as nodes and dependencies between them as directed links. These networks are indispensable tools for visualizing, studying, and understanding curricula. For example, CPNs can be used to detect important courses, improve advising, guide curriculum design, analyze graduation time distributions, and quantify the strength of knowledge flow between different university departments. However, most CPN analyses to date have focused only on micro- and meso-scale properties. To fill this gap, we define and study three new global CPN measures: breadth, depth, and flux. All three measures are invariant under transitive reduction and are based on the concept of topological stratification, which generalizes topological ordering in directed acyclic graphs. These measures can be used for macro-scale comparison of different CPNs. We illustrate the new measures numerically by applying them to three real and synthetic CPNs from three universities: the Cyprus University of Technology, the California Institute of Technology, and Johns Hopkins University. The CPN data analyzed in this paper are publicly available in a GitHub repository.",
      "authors": [
        "Konstantin Zuev",
        "Pavlos Stavrinides"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Social and Information Networks (cs.SI)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T04:21:56+00:00",
          "link": "https://arxiv.org/abs/2506.23510v1",
          "size": "200kb",
          "version": "v1"
        }
      ],
      "title": "Breadth, Depth, and Flux of Course-Prerequisite Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23510",
        "HTML": "https://arxiv.org/html/2506.23510v1",
        "PDF": "https://arxiv.org/pdf/2506.23510"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23511",
      "abstract": "In this paper, we design a deep learning-based convolutional autoencoder for channel coding and modulation. The objective is to develop an adaptive scheme capable of operating at various signal-to-noise ratios (SNR)s without the need for re-training. Additionally, the proposed framework allows validation by testing all possible codes in the codebook, as opposed to previous AI-based encoder/decoder frameworks which relied on testing only a small subset of the available codes. This limitation in earlier methods often led to unreliable conclusions when generalized to larger codebooks. In contrast to previous methods, our multi-level encoding and decoding approach splits the message into blocks, where each encoder block processes a distinct group of $B$ bits. By doing so, the proposed scheme can exhaustively test $2^{B}$ possible codewords for each encoder/decoder level, constituting a layer of the overall scheme. The proposed model was compared to classical polar codes and TurboAE-MOD schemes, showing improved reliability with achieving comparable, or even superior results in some settings. Notably, the architecture can adapt to different SNRs by selectively removing one of the encoder/decoder layers without re-training, thus demonstrating flexibility and efficiency in practical wireless communication scenarios.",
      "authors": [
        "Ahmad Abdel-Qader",
        "Anas Chaaban",
        "Mohamed S. Shehata"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Emerging Technologies (cs.ET)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T04:24:56+00:00",
          "link": "https://arxiv.org/abs/2506.23511v1",
          "size": "65kb",
          "version": "v1"
        }
      ],
      "title": "Mutli-Level Autoencoder: Deep Learning Based Channel Coding and Modulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23511",
        "HTML": "https://arxiv.org/html/2506.23511v1",
        "PDF": "https://arxiv.org/pdf/2506.23511"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23537",
      "abstract": "Existing learning-based methods effectively reconstruct HDR images from multi-exposure LDR inputs with extended dynamic range and improved detail, but they rely more on empirical design rather than theoretical foundation, which can impact their reliability. To address these limitations, we propose the cross-iterative Alignment and Fusion deep Unfolding Network (AFUNet), where HDR reconstruction is systematically decoupled into two interleaved subtasks -- alignment and fusion -- optimized through alternating refinement, achieving synergy between the two subtasks to enhance the overall performance. Our method formulates multi-exposure HDR reconstruction from a Maximum A Posteriori (MAP) estimation perspective, explicitly incorporating spatial correspondence priors across LDR images and naturally bridging the alignment and fusion subproblems through joint constraints. Building on the mathematical foundation, we reimagine traditional iterative optimization through unfolding -- transforming the conventional solution process into an end-to-end trainable AFUNet with carefully designed modules that work progressively. Specifically, each iteration of AFUNet incorporates an Alignment-Fusion Module (AFM) that alternates between a Spatial Alignment Module (SAM) for alignment and a Channel Fusion Module (CFM) for adaptive feature fusion, progressively bridging misaligned content and exposure discrepancies. Extensive qualitative and quantitative evaluations demonstrate AFUNet's superior performance, consistently surpassing state-of-the-art methods. Our code is available at: https://github.com/eezkni/AFUNet",
      "authors": [
        "Xinyue Li",
        "Zhangkai Ni",
        "Wenhan Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T06:03:34+00:00",
          "link": "https://arxiv.org/abs/2506.23537v1",
          "size": "5253kb",
          "version": "v1"
        }
      ],
      "title": "AFUNet: Cross-Iterative Alignment-Fusion Synergy for HDR Reconstruction via Deep Unfolding Paradigm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23537",
        "HTML": "https://arxiv.org/html/2506.23537v1",
        "PDF": "https://arxiv.org/pdf/2506.23537"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23546",
      "abstract": "Fixed points of recurrent neural networks can be leveraged to store and generate information. These fixed points can be captured by the Boltzmann-Gibbs measure, which leads to neural Langevin dynamics that can be used for sampling and learning a real dataset. We call this type of generative model neural Langevin machine, which is interpretable due to its analytic form of distribution and is simple to train. Moreover, the learning process is derived as a local asymmetric plasticity rule, bearing biological relevance. Therefore, one can realize a continuous sampling of creative dynamics in a neural network, mimicking an imagination process in brain circuits. This neural Langevin machine may be another promising generative model, at least in its strength in circuit-based sampling and biologically plausible learning rule.",
      "authors": [
        "Zhendong Yu and Weizhong Huang and Haiping Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T06:35:43+00:00",
          "link": "https://arxiv.org/abs/2506.23546v1",
          "size": "1257kb",
          "version": "v1"
        }
      ],
      "title": "Neural Langevin Machine: a local asymmetric learning rule can be creative",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23546",
        "HTML": "https://arxiv.org/html/2506.23546v1",
        "PDF": "https://arxiv.org/pdf/2506.23546"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23550",
      "abstract": "We find an efficient approach to approximately convert matrix product states (MPSs) into restricted Boltzmann machine wave functions consisting of a multinomial hidden unit through a canonical polyadic (CP) decomposition of the MPSs. This method allows us to generate well-behaved initial neural network quantum states for quantum many-body ground-state calculations in polynomial time of the number of variational parameters and systematically shorten the distance between the initial states and the ground states with increasing the rank of the CP decomposition. We demonstrate the efficiency of our method by taking the transverse-field Ising model as an example and discuss possible applications of our method to more general quantum many-body systems in which the ground-state wave functions possess complex nodal structures.",
      "authors": [
        "Ryui Kaneko",
        "Shimpei Goto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Strongly Correlated Electrons (cond-mat.str-el)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T06:49:31+00:00",
          "link": "https://arxiv.org/abs/2506.23550v1",
          "size": "1821kb",
          "version": "v1"
        }
      ],
      "title": "Seeding neural network quantum states with tensor network states",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23550",
        "HTML": "https://arxiv.org/html/2506.23550v1",
        "PDF": "https://arxiv.org/pdf/2506.23550"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23553",
      "abstract": "Contrastive language-audio pretraining (CLAP) is widely used for audio generation and recognition tasks. For example, CLAPScore, which utilizes the similarity of CLAP embeddings, has been a major metric for the evaluation of the relevance between audio and text in text-to-audio. However, the relationship between CLAPScore and human subjective evaluation scores is still unclarified. We show that CLAPScore has a low correlation with human subjective evaluation scores. Additionally, we propose a human-perception-based CLAP called Human-CLAP by training a contrastive language-audio model using the subjective evaluation score. In our experiments, the results indicate that our Human-CLAP improved the Spearman's rank correlation coefficient (SRCC) between the CLAPScore and the subjective evaluation scores by more than 0.25 compared with the conventional CLAP.",
      "authors": [
        "Taisei Takano",
        "Yuki Okamoto",
        "Yusuke Kanamori",
        "Yuki Saito",
        "Ryotaro Nagase",
        "Hiroshi Saruwatari"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T06:57:57+00:00",
          "link": "https://arxiv.org/abs/2506.23553v1",
          "size": "3587kb",
          "version": "v1"
        }
      ],
      "title": "Human-CLAP: Human-perception-based contrastive language-audio pretraining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23553",
        "HTML": "https://arxiv.org/html/2506.23553v1",
        "PDF": "https://arxiv.org/pdf/2506.23553"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23560",
      "abstract": "Quantum state tomography (QST) is a fundamental technique for estimating the state of a quantum system from measured data and plays a crucial role in evaluating the performance of quantum devices. However, standard estimation methods become impractical due to the exponential growth of parameters in the state representation. In this work, we address this challenge by parameterizing the state using a low-rank block tensor train decomposition and demonstrate that our approach is both memory- and computationally efficient. This framework applies to a broad class of quantum states that can be well approximated by low-rank decompositions, including pure states, nearly pure states, and ground states of Hamiltonians.",
      "authors": [
        "Shakir Showkat Sofi",
        "Charlotte Vermeylen",
        "and Lieven De Lathauwer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)",
        "Signal Processing (eess.SP)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T07:06:50+00:00",
          "link": "https://arxiv.org/abs/2506.23560v1",
          "size": "115kb",
          "version": "v1"
        }
      ],
      "title": "Tensor Train Quantum State Tomography using Compressed Sensing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23560",
        "PDF": "https://arxiv.org/pdf/2506.23560"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23569",
      "abstract": "The traditional clustering problem of renewable energy profiles is typically formulated as a combinatorial optimization that suffers from the Curse of Dimensionality (CoD) on classical computers. To address this issue, this paper first proposed a kernel-based quantum clustering method. More specifically, the kernel-based similarity between profiles with minimal intra-group distance is encoded into the ground-state of the Hamiltonian in the form of an Ising model. Then, this NP-hard problem can be reformulated into a Quadratic Unconstrained Binary Optimization (QUBO), which a Coherent Ising Machine (CIM) can naturally solve with significant improvement over classical computers. The test results from a real optical quantum computer verify the validity of the proposed method. It also demonstrates its ability to address CoD in an NP-hard clustering problem.",
      "authors": [
        "Chengjun Liu",
        "Yijun Xu",
        "Wei Gu",
        "Bo Sun",
        "Kai Wen",
        "Shuai Lu",
        "and Lamine Mili"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T07:22:34+00:00",
          "link": "https://arxiv.org/abs/2506.23569v1",
          "size": "3026kb",
          "version": "v1"
        }
      ],
      "title": "Alleviating CoD in Renewable Energy Profile Clustering Using an Optical Quantum Computer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23569",
        "HTML": "https://arxiv.org/html/2506.23569v1",
        "PDF": "https://arxiv.org/pdf/2506.23569"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23584",
      "abstract": "Generating radiology reports from CT scans remains a complex task due to the nuanced nature of medical imaging and the variability in clinical documentation. In this study, we propose a two-stage framework for generating renal radiology reports from 2D CT slices. First, we extract structured abnormality features using a multi-task learning model trained to identify lesion attributes such as location, size, enhancement, and attenuation. These extracted features are subsequently combined with the corresponding CT image and fed into a fine-tuned vision-language model to generate natural language report sentences aligned with clinical findings. We conduct experiments on a curated dataset of renal CT studies with manually annotated sentence-slice-feature triplets and evaluate performance using both classification metrics and natural language generation metrics. Our results demonstrate that the proposed model outperforms random baselines across all abnormality types, and the generated reports capture key clinical content with reasonable textual accuracy. This exploratory work highlights the feasibility of modular, feature-informed report generation for renal imaging. Future efforts will focus on extending this pipeline to 3D CT volumes and further improving clinical fidelity in multimodal medical AI systems.",
      "authors": [
        "Renjie Liang",
        "Zhengkang Fan",
        "Jinqian Pan",
        "Chenkun Sun",
        "Russell Terry",
        "Jie Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T07:45:02+00:00",
          "link": "https://arxiv.org/abs/2506.23584v1",
          "size": "555kb",
          "version": "v1"
        }
      ],
      "title": "A Clinically-Grounded Two-Stage Framework for Renal CT Report Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23584",
        "HTML": "https://arxiv.org/html/2506.23584v1",
        "PDF": "https://arxiv.org/pdf/2506.23584"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23619",
      "abstract": "This paper investigates the impact of posterior drift on out-of-sample forecasting accuracy in overparametrized machine learning models. We document the loss in performance when the loadings of the data generating process change between the training and testing samples. This matters crucially in settings in which regime changes are likely to occur, for instance, in financial markets. Applied to equity premium forecasting, our results underline the sensitivity of a market timing strategy to sub-periods and to the bandwidth parameters that control the complexity of the model. For the average investor, we find that focusing on holding periods of 15 years can generate very heterogeneous returns, especially for small bandwidths. Large bandwidths yield much more consistent outcomes, but are far less appealing from a risk-adjusted return standpoint. All in all, our findings tend to recommend cautiousness when resorting to large linear models for stock market predictions.",
      "authors": [
        "Guillaume Coqueret",
        "Martial Laguerre"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Statistical Finance (q-fin.ST)",
        "Machine Learning (cs.LG)",
        "Econometrics (econ.EM)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T08:31:15+00:00",
          "link": "https://arxiv.org/abs/2506.23619v1",
          "size": "233kb",
          "version": "v1"
        }
      ],
      "title": "Overparametrized models with posterior drift",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23619",
        "HTML": "https://arxiv.org/html/2506.23619v1",
        "PDF": "https://arxiv.org/pdf/2506.23619"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23650",
      "abstract": "We present an optimal quantum algorithm for fidelity estimation between two quantum states when one of them is pure. In particular, the (square root) fidelity of a mixed state to a pure state can be estimated to within additive error $\\varepsilon$ by using $\\Theta(1/\\varepsilon)$ queries to their state-preparation circuits, achieving a quadratic speedup over the folklore $O(1/\\varepsilon^2)$. Our approach is technically simple, and can moreover estimate the quantity $\\sqrt{\\operatorname{tr}(\\rho\\sigma^2)}$ that is not common in the literature. To the best of our knowledge, this is the first query-optimal approach to fidelity estimation involving mixed states.",
      "authors": [
        "Wang Fang and Qisheng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:24:03+00:00",
          "link": "https://arxiv.org/abs/2506.23650v1",
          "size": "13kb",
          "version": "v1"
        }
      ],
      "title": "Optimal Quantum Algorithm for Estimating Fidelity to a Pure State",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23650",
        "HTML": "https://arxiv.org/html/2506.23650v1",
        "PDF": "https://arxiv.org/pdf/2506.23650"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23664",
      "abstract": "Medical image data is less accessible than in other domains due to privacy and regulatory constraints. In addition, labeling requires costly, time-intensive manual image annotation by clinical experts. To overcome these challenges, synthetic medical data generation offers a promising solution. Generative AI (GenAI), employing generative deep learning models, has proven effective at producing realistic synthetic images. This study proposes a novel mask-guided GenAI approach using diffusion models to generate synthetic fetal head ultrasound images paired with segmentation masks. These synthetic pairs augment real datasets for supervised fine-tuning of the Segment Anything Model (SAM). Our results show that the synthetic data captures real image features effectively, and this approach reaches state-of-the-art fetal head segmentation, especially when trained with a limited number of real image-mask pairs. In particular, the segmentation reaches Dice Scores of 94.66\\% and 94.38\\% using a handful of ultrasound images from the Spanish and African cohorts, respectively. Our code, models, and data are available on GitHub.",
      "authors": [
        "Fangyijie Wang",
        "Kevin Whelan",
        "F\\'elix Balado",
        "Gu\\'enol\\'e Silvestre",
        "Kathleen M. Curran"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T09:40:12+00:00",
          "link": "https://arxiv.org/abs/2506.23664v1",
          "size": "2810kb",
          "version": "v1"
        }
      ],
      "title": "Diffusion Model-based Data Augmentation Method for Fetal Head Ultrasound Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23664",
        "HTML": "https://arxiv.org/html/2506.23664v1",
        "PDF": "https://arxiv.org/pdf/2506.23664"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23700",
      "abstract": "Medical image segmentation plays a crucial role in clinical diagnosis and treatment planning, where accurate boundary delineation is essential for precise lesion localization, organ identification, and quantitative assessment. In recent years, deep learning-based methods have significantly advanced segmentation accuracy. However, two major challenges remain. First, the performance of these methods heavily relies on large-scale annotated datasets, which are often difficult to obtain in medical scenarios due to privacy concerns and high annotation costs. Second, clinically challenging scenarios, such as low contrast in certain imaging modalities and blurry lesion boundaries caused by malignancy, still pose obstacles to precise segmentation. To address these challenges, we propose MedSAM-CA, an architecture-level fine-tuning approach that mitigates reliance on extensive manual annotations by adapting the pretrained foundation model, Medical Segment Anything (MedSAM). MedSAM-CA introduces two key components: the Convolutional Attention-Enhanced Boundary Refinement Network (CBR-Net) and the Attention-Enhanced Feature Fusion Block (Atte-FFB). CBR-Net operates in parallel with the MedSAM encoder to recover boundary information potentially overlooked by long-range attention mechanisms, leveraging hierarchical convolutional processing. Atte-FFB, embedded in the MedSAM decoder, fuses multi-level fine-grained features from skip connections in CBR-Net with global representations upsampled within the decoder to enhance boundary delineation accuracy. Experiments on publicly available datasets covering dermoscopy, CT, and MRI imaging modalities validate the effectiveness of MedSAM-CA. On dermoscopy dataset, MedSAM-CA achieves 94.43% Dice with only 2% of full training data, reaching 97.25% of full-data training performance, demonstrating strong effectiveness in low-resource clinical settings.",
      "authors": [
        "Peiting Tian",
        "Xi Chen",
        "Haixia Bi",
        "Fan Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:24:29+00:00",
          "link": "https://arxiv.org/abs/2506.23700v1",
          "size": "16521kb",
          "version": "v1"
        }
      ],
      "title": "MedSAM-CA: A CNN-Augmented ViT with Attention-Enhanced Multi-Scale Fusion for Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23700",
        "HTML": "https://arxiv.org/html/2506.23700v1",
        "PDF": "https://arxiv.org/pdf/2506.23700"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23701",
      "abstract": "Magnetic Resonance Imaging (MRI) reconstruction is essential in medical diagnostics. As the latest generative models, diffusion models (DMs) have struggled to produce high-fidelity images due to their stochastic nature in image domains. Latent diffusion models (LDMs) yield both compact and detailed prior knowledge in latent domains, which could effectively guide the model towards more effective learning of the original data distribution. Inspired by this, we propose Multi-domain Diffusion Prior Guidance (MDPG) provided by pre-trained LDMs to enhance data consistency in MRI reconstruction tasks. Specifically, we first construct a Visual-Mamba-based backbone, which enables efficient encoding and reconstruction of under-sampled images. Then pre-trained LDMs are integrated to provide conditional priors in both latent and image domains. A novel Latent Guided Attention (LGA) is proposed for efficient fusion in multi-level latent domains. Simultaneously, to effectively utilize a prior in both the k-space and image domain, under-sampled images are fused with generated full-sampled images by the Dual-domain Fusion Branch (DFB) for self-adaption guidance. Lastly, to further enhance the data consistency, we propose a k-space regularization strategy based on the non-auto-calibration signal (NACS) set. Extensive experiments on two public MRI datasets fully demonstrate the effectiveness of the proposed methodology. The code is available at https://github.com/Zolento/MDPG.",
      "authors": [
        "Lingtong Zhang",
        "Mengdie Song",
        "Xiaohan Hao",
        "Huayu Mai",
        "Bensheng Qiu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:25:08+00:00",
          "link": "https://arxiv.org/abs/2506.23701v1",
          "size": "739kb",
          "version": "v1"
        }
      ],
      "title": "MDPG: Multi-domain Diffusion Prior Guidance for MRI Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23701",
        "HTML": "https://arxiv.org/html/2506.23701v1",
        "PDF": "https://arxiv.org/pdf/2506.23701"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23721",
      "abstract": "Ultrasound (US) is widely accessible and radiation-free but has a steep learning curve due to its dynamic nature and non-standard imaging planes. Additionally, the constant need to shift focus between the US screen and the patient poses a challenge. To address these issues, we integrate deep learning (DL)-based semantic segmentation for real-time (RT) automated kidney volumetric measurements, which are essential for clinical assessment but are traditionally time-consuming and prone to fatigue. This automation allows clinicians to concentrate on image interpretation rather than manual measurements. Complementing DL, augmented reality (AR) enhances the usability of US by projecting the display directly into the clinician's field of view, improving ergonomics and reducing the cognitive load associated with screen-to-patient transitions. Two AR-DL-assisted US pipelines on HoloLens-2 are proposed: one streams directly via the application programming interface for a wireless setup, while the other supports any US device with video output for broader accessibility. We evaluate RT feasibility and accuracy using the Open Kidney Dataset and open-source segmentation models (nnU-Net, Segmenter, YOLO with MedSAM and LiteMedSAM). Our open-source GitHub pipeline includes model implementations, measurement algorithms, and a Wi-Fi-based streaming solution, enhancing US training and diagnostics, especially in point-of-care settings.",
      "authors": [
        "Gijs Luijten",
        "Roberto Maria Scardigno",
        "Lisle Faray de Paiva",
        "Peter Hoyer",
        "Jens Kleesiek",
        "Domenico Buongiorno",
        "Vitoantonio Bevilacqua",
        "Jan Egger"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T10:49:54+00:00",
          "link": "https://arxiv.org/abs/2506.23721v1",
          "size": "1835kb",
          "version": "v1"
        }
      ],
      "title": "Deep Learning-Based Semantic Segmentation for Real-Time Kidney Imaging and Measurements with Augmented Reality-Assisted Ultrasound",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23721",
        "HTML": "https://arxiv.org/html/2506.23721v1",
        "PDF": "https://arxiv.org/pdf/2506.23721"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23756",
      "abstract": "Recent advances in convex optimization have leveraged computer-assisted proofs to develop optimized first-order methods that improve over classical algorithms. However, each optimized method is specially tailored for a particular problem setting, and it is a well-documented challenge to extend optimized methods to other settings due to their highly bespoke design and analysis. We provide a general framework that derives optimized methods for composite optimization directly from those for unconstrained smooth optimization. The derived methods naturally extend the original methods, generalizing how proximal gradient descent extends gradient descent. The key to our result is certain algebraic identities that provide a unified and straightforward way of extending convergence analyses from unconstrained to composite settings. As concrete examples, we apply our framework to establish (1) the phenomenon of stepsize acceleration for proximal gradient descent; (2) a convergence rate for the proximal optimized gradient method which is faster than FISTA; (3) a new method that improves the state-of-the-art rate for minimizing gradient norm in the composite setting.",
      "authors": [
        "Jinho Bok",
        "Jason M. Altschuler"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T11:56:51+00:00",
          "link": "https://arxiv.org/abs/2506.23756v1",
          "size": "45kb",
          "version": "v1"
        }
      ],
      "title": "Optimized methods for composite optimization: a reduction perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23756",
        "HTML": "https://arxiv.org/html/2506.23756v1",
        "PDF": "https://arxiv.org/pdf/2506.23756"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23759",
      "abstract": "Surgical instrument segmentation under Federated Learning (FL) is a promising direction, which enables multiple surgical sites to collaboratively train the model without centralizing datasets. However, there exist very limited FL works in surgical data science, and FL methods for other modalities do not consider inherent characteristics in surgical domain: i) different scenarios show diverse anatomical backgrounds while highly similar instrument representation; ii) there exist surgical simulators which promote large-scale synthetic data generation with minimal efforts. In this paper, we propose a novel Personalized FL scheme, Spatio-Temporal Representation Decoupling and Enhancement (FedST), which wisely leverages surgical domain knowledge during both local-site and global-server training to boost segmentation. Concretely, our model embraces a Representation Separation and Cooperation (RSC) mechanism in local-site training, which decouples the query embedding layer to be trained privately, to encode respective backgrounds. Meanwhile, other parameters are optimized globally to capture the consistent representations of instruments, including the temporal layer to capture similar motion patterns. A textual-guided channel selection is further designed to highlight site-specific features, facilitating model adapta tion to each site. Moreover, in global-server training, we propose Synthesis-based Explicit Representation Quantification (SERQ), which defines an explicit representation target based on synthetic data to synchronize the model convergence during fusion for improving model generalization.",
      "authors": [
        "Zheng Fang",
        "Xiaoming Qi",
        "Chun-Mei Feng",
        "Jialun Pei",
        "Weixin Si",
        "Yueming Jin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:08:02+00:00",
          "link": "https://arxiv.org/abs/2506.23759v1",
          "size": "3088kb",
          "version": "v1"
        }
      ],
      "title": "Spatio-Temporal Representation Decoupling and Enhancement for Federated Instrument Segmentation in Surgical Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23759",
        "HTML": "https://arxiv.org/html/2506.23759v1",
        "PDF": "https://arxiv.org/pdf/2506.23759"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23767",
      "abstract": "Every publicly traded U.S. company files an annual 10-K report containing critical insights into financial health and risk. We propose Tiny eXplainable Risk Assessor (TinyXRA), a lightweight and explainable transformer-based model that automatically assesses company risk from these reports. Unlike prior work that relies solely on the standard deviation of excess returns (adjusted for the Fama-French model), which indiscriminately penalizes both upside and downside risk, TinyXRA incorporates skewness, kurtosis, and the Sortino ratio for more comprehensive risk assessment. We leverage TinyBERT as our encoder to efficiently process lengthy financial documents, coupled with a novel dynamic, attention-based word cloud mechanism that provides intuitive risk visualization while filtering irrelevant terms. This lightweight design ensures scalable deployment across diverse computing environments with real-time processing capabilities for thousands of financial documents which is essential for production systems with constrained computational resources. We employ triplet loss for risk quartile classification, improving over pairwise loss approaches in existing literature by capturing both the direction and magnitude of risk differences. Our TinyXRA achieves state-of-the-art predictive accuracy across seven test years on a dataset spanning 2013-2024, while providing transparent and interpretable risk assessments. We conduct comprehensive ablation studies to evaluate our contributions and assess model explanations both quantitatively by systematically removing highly attended words and sentences, and qualitatively by examining explanation coherence. The paper concludes with findings, practical implications, limitations, and future research directions.",
      "authors": [
        "Xue Wen Tan",
        "Stanley Kok"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Risk Management (q-fin.RM)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:13:35+00:00",
          "link": "https://arxiv.org/abs/2506.23767v1",
          "size": "29340kb",
          "version": "v1"
        }
      ],
      "title": "Explainable AI for Comprehensive Risk Assessment for Financial Reports: A Lightweight Hierarchical Transformer Network Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23767",
        "PDF": "https://arxiv.org/pdf/2506.23767"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23788",
      "abstract": "The ever-increasing number of distributed embedded systems in the context of the Internet of Things (IoT), Wireless Sensor Networks (WSN), and Cyber-Physical Systems (CPS) rely on wireless communication to collect and exchange data. Nodes can employ single-hop communication which, despite its ease, may necessitate energy-intensive long-range communication to cover long distances. Conversely, multi-hop communication allows for more energy-efficient short-range communication since nodes can rely on other nodes to forward their data. Yet, this approach requires relay nodes to be available and continuous maintenance of a dynamically changing distributed state. At the same time, energy harvesting has the potential to outperform traditional battery-based systems by improving their lifetime, scalability with lower maintenance costs, and environmental impact. However, the limited and temporally and spatially variable harvested energy poses significant challenges for networking in energy harvesting networks, particularly considering the energy demands and characteristics of both multi-hop and single-hop communication. We propose E-WAN, a protocol for energy harvesting wide-area low-power networks that builds on the concept of \\emph{virtual sub-networks} to enable resource-efficient multi-hop communication when possible and reliable however energy-intensive point-to-point communication otherwise. Nodes autonomously and dynamically move between the two and adjust to changing network states and resources based only on easily obtainable network state information. We illustrate E-WAN's advantages both in terms of efficiency and adaptability in various communication and harvesting scenarios. Furthermore, we demonstrate E-WAN operating in a realistic setting by deploying an energy harvesting network in a real-world indoor environment.",
      "authors": [
        "Naomi Stricker",
        "David Blaser",
        "Andres Gomez and Lothar Thiele"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T12:29:28+00:00",
          "link": "https://arxiv.org/abs/2506.23788v1",
          "size": "10563kb",
          "version": "v1"
        }
      ],
      "title": "E-WAN: Efficient Communication in Energy Harvesting Low-Power Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23788",
        "PDF": "https://arxiv.org/pdf/2506.23788"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23836",
      "abstract": "We consider centralized distributed optimization in the classical federated learning setup, where $n$ workers jointly find an $\\varepsilon$-stationary point of an $L$-smooth, $d$-dimensional nonconvex function $f$, having access only to unbiased stochastic gradients with variance $\\sigma^2$. Each worker requires at most $h$ seconds to compute a stochastic gradient, and the communication times from the server to the workers and from the workers to the server are $\\tau_{s}$ and $\\tau_{w}$ seconds per coordinate, respectively. One of the main motivations for distributed optimization is to achieve scalability with respect to $n$. For instance, it is well known that the distributed version of SGD has a variance-dependent runtime term $\\frac{h \\sigma^2 L \\Delta}{n \\varepsilon^2},$ which improves with the number of workers $n,$ where $\\Delta = f(x^0) - f^*,$ and $x^0 \\in R^d$ is the starting point. Similarly, using unbiased sparsification compressors, it is possible to reduce both the variance-dependent runtime term and the communication runtime term. However, once we account for the communication from the server to the workers $\\tau_{s}$, we prove that it becomes infeasible to design a method using unbiased random sparsification compressors that scales both the server-side communication runtime term $\\tau_{s} d \\frac{L \\Delta}{\\varepsilon}$ and the variance-dependent runtime term $\\frac{h \\sigma^2 L \\Delta}{\\varepsilon^2},$ better than poly-logarithmically in $n$, even in the homogeneous (i.i.d.) case, where all workers access the same distribution. To establish this result, we construct a new \"worst-case\" function and develop a new lower bound framework that reduces the analysis to the concentration of a random sum, for which we prove a concentration bound. These results reveal fundamental limitations in scaling distributed optimization, even under the homogeneous assumption.",
      "authors": [
        "Alexander Tyurin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:27:39+00:00",
          "link": "https://arxiv.org/abs/2506.23836v1",
          "size": "232kb",
          "version": "v1"
        }
      ],
      "title": "Proving the Limited Scalability of Centralized Distributed Optimization via a New Lower Bound Construction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23836",
        "HTML": "https://arxiv.org/html/2506.23836v1",
        "PDF": "https://arxiv.org/pdf/2506.23836"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23859",
      "abstract": "The vast majority of modern speech enhancement systems rely on data-driven neural network models. Conventionally, larger datasets are presumed to yield superior model performance, an observation empirically validated across numerous tasks in other domains. However, recent studies reveal diminishing returns when scaling speech enhancement data. We focus on a critical factor: prevalent quality issues in ``clean'' training labels within large-scale datasets. This work re-examines this phenomenon and demonstrates that, within large-scale training sets, prioritizing high-quality training data is more important than merely expanding the data volume. Experimental findings suggest that models trained on a carefully curated subset of 700 hours can outperform models trained on the 2,500-hour full dataset. This outcome highlights the crucial role of data curation in scaling speech enhancement systems effectively.",
      "authors": [
        "Chenda Li",
        "Wangyou Zhang",
        "Wei Wang",
        "Robin Scheibler",
        "Kohei Saijo",
        "Samuele Cornell",
        "Yihui Fu",
        "Marvin Sach",
        "Zhaoheng Ni",
        "Anurag Kumar",
        "Tim Fingscheidt",
        "Shinji Watanabe and Yanmin Qian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T13:55:10+00:00",
          "link": "https://arxiv.org/abs/2506.23859v1",
          "size": "632kb",
          "version": "v1"
        }
      ],
      "title": "Less is More: Data Curation Matters in Scaling Speech Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23859",
        "HTML": "https://arxiv.org/html/2506.23859v1",
        "PDF": "https://arxiv.org/pdf/2506.23859"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23874",
      "abstract": "The Mean Opinion Score (MOS) is fundamental to speech quality assessment. However, its acquisition requires significant human annotation. Although deep neural network approaches, such as DNSMOS and UTMOS, have been developed to predict MOS to avoid this issue, they often suffer from insufficient training data. Recognizing that the comparison of speech enhancement (SE) systems prioritizes a reliable system comparison over absolute scores, we propose URGENT-PK, a novel ranking approach leveraging pairwise comparisons. URGENT-PK takes homologous enhanced speech pairs as input to predict relative quality rankings. This pairwise paradigm efficiently utilizes limited training data, as all pairwise permutations of multiple systems constitute a training instance. Experiments across multiple open test sets demonstrate URGENT-PK's superior system-level ranking performance over state-of-the-art baselines, despite its simple network architecture and limited training data.",
      "authors": [
        "Jiahe Wang",
        "Chenda Li",
        "Wei Wang",
        "Wangyou Zhang",
        "Samuele Cornell",
        "Marvin Sach",
        "Robin Scheibler",
        "Kohei Saijo",
        "Yihui Fu",
        "Zhaoheng Ni",
        "Anurag Kumar",
        "Tim Fingscheidt",
        "Shinji Watanabe",
        "Yanmin Qian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:05:17+00:00",
          "link": "https://arxiv.org/abs/2506.23874v1",
          "size": "736kb",
          "version": "v1"
        }
      ],
      "title": "URGENT-PK: Perceptually-Aligned Ranking Model Designed for Speech Enhancement Competition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23874",
        "HTML": "https://arxiv.org/html/2506.23874v1",
        "PDF": "https://arxiv.org/pdf/2506.23874"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23914",
      "abstract": "Estimating physical parameters or material properties from experimental observations is a common objective in many areas of physics and material science. In many experiments, especially in shock physics, radiography is the primary means of observing the system of interest. However, radiography does not provide direct access to key state variables, such as density, which prevents the application of traditional parameter estimation approaches. Here we focus on flyer plate impact experiments on porous materials, and resolving the underlying parameterized equation of state (EoS) and crush porosity model parameters given radiographic observation(s). We use machine learning as a tool to demonstrate with high confidence that using only high impact velocity data does not provide sufficient information to accurately infer both EoS and crush model parameters, even with fully resolved density fields or a dynamic sequence of images. We thus propose an observable data set consisting of low and high impact velocity experiments/simulations that capture different regimes of compaction and shock propagation, and proceed to introduce a generative machine learning approach which produces a posterior distribution of physical parameters directly from radiographs. We demonstrate the effectiveness of the approach in estimating parameters from simulated flyer plate impact experiments, and show that the obtained estimates of EoS and crush model parameters can then be used in hydrodynamic simulations to obtain accurate and physically admissible density reconstructions. Finally, we examine the robustness of the approach to model mismatches, and find that the learned approach can provide useful parameter estimates in the presence of out-of-distribution radiographic noise and previously unseen physics, thereby promoting a potential breakthrough in estimating material properties from experimental radiographic images.",
      "authors": [
        "Evan Bell",
        "Daniel A. Serino",
        "Ben S. Southworth",
        "Trevor Wilcox",
        "Marc L. Klasky"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computational Physics (physics.comp-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T14:43:33+00:00",
          "link": "https://arxiv.org/abs/2506.23914v1",
          "size": "1899kb",
          "version": "v1"
        }
      ],
      "title": "Learning robust parameter inference and density reconstruction in flyer plate impact experiments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23914",
        "HTML": "https://arxiv.org/html/2506.23914v1",
        "PDF": "https://arxiv.org/pdf/2506.23914"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23942",
      "abstract": "The Zarankiewicz problem, a cornerstone problem in extremal graph theory, asks for the maximum number of edges in an $n$-vertex graph that does not contain the complete bipartite graph $K_{s,s}$. While the problem remains widely open in the case of general graphs, the past two decades have seen significant progress on this problem for various restricted graph classes -- particularly those arising from geometric settings -- leading to a deeper understanding of their structure.\n  In this paper, we develop a new structural tool for addressing Zarankiewicz-type problems. More specifically, we show that for any positive integer $k$, every graph with average degree $d$ either contains an induced $C_4$-free subgraph with average degree at least $k$, or it contains a $d$-vertex subgraph with $\\Omega_k(d^2)$ edges. As an application of this dichotomy, we propose a unified approach to a large number of Zarankiewicz-type problems in geometry, obtaining optimal bounds in each case.",
      "authors": [
        "Zach Hunter",
        "Aleksa Milojevi\\'c",
        "Istvan Tomon",
        "Benny Sudakov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:09:00+00:00",
          "link": "https://arxiv.org/abs/2506.23942v1",
          "size": "51kb",
          "version": "v1"
        }
      ],
      "title": "$C_4$-free subgraphs of high degree with geometric applications",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23942",
        "HTML": "https://arxiv.org/html/2506.23942v1",
        "PDF": "https://arxiv.org/pdf/2506.23942"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23966",
      "abstract": "Pinching-antenna systems have emerged as a promising flexible-antenna architecture for next-generation wireless networks, enabling enhanced adaptability and user-centric connectivity through antenna repositioning along waveguides. However, existing studies often overlook in-waveguide signal attenuation and in the literature, there is no comprehensive analysis on whether and under what conditions such an assumption is justified. This paper addresses this gap by explicitly incorporating in-waveguide attenuation into both the system model and algorithm design, and studying its impact on the downlink user data rates. We begin with a single-user scenario and derive a closed-form expression for the globally optimal antenna placement, which reveals how the attenuation coefficient and the user-to-waveguide distance jointly affect the optimal antenna position. Based on this analytical solution, we further provide a theoretical analysis identifying the system conditions under which the in-waveguide attenuation has an insignificant impact on the user achievable rate. The study is then extended to the multi-user multiple-input multiple-output setting, where two efficient algorithms are developed, based on the weighted minimum mean square error method and the maximum ratio combining method, to jointly optimize beamforming and antenna placement. Simulation results validate the efficacy of the proposed algorithms and demonstrate that pinching-antenna systems substantially outperform conventional fixed-antenna baselines, underscoring their potential for future flexible wireless communications.",
      "authors": [
        "Yanqing Xu",
        "Zhiguo Ding",
        "Robert Schober",
        "and Tsung-Hui Chang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:36:40+00:00",
          "link": "https://arxiv.org/abs/2506.23966v1",
          "size": "821kb",
          "version": "v1"
        }
      ],
      "title": "Pinching-Antenna Systems with In-Waveguide Attenuation: Performance Analysis and Algorithm Design",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23966",
        "HTML": "https://arxiv.org/html/2506.23966v1",
        "PDF": "https://arxiv.org/pdf/2506.23966"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.23989",
      "abstract": "We prove that Boolean matrices with bounded $\\gamma_2$-norm or bounded normalized trace norm must contain a linear-sized all-ones or all-zeros submatrix, verifying a conjecture of Hambardzumyan, Hatami, and Hatami. We also present further structural results about Boolean matrices of bounded $\\gamma_2$-norm and discuss applications in communication complexity, operator theory, spectral graph theory, and extremal combinatorics.\n  As a key application, we establish an inverse theorem for MaxCut. A celebrated result of Edwards states that every graph $G$ with $m$ edges has a cut of size at least $\\frac{m}{2}+\\frac{\\sqrt{8m+1}-1}{8}$, with equality achieved by complete graphs with an odd number of vertices. To contrast this, we prove that if the MaxCut of $G$ is at most $\\frac{m}{2}+O(\\sqrt{m})$, then $G$ must contain a clique of size $\\Omega(\\sqrt{m})$.",
      "authors": [
        "Igor Balla",
        "Lianna Hambardzumyan",
        "Istv\\'an Tomon"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Computational Complexity (cs.CC)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T15:54:45+00:00",
          "link": "https://arxiv.org/abs/2506.23989v1",
          "size": "32kb",
          "version": "v1"
        }
      ],
      "title": "Factorization norms and an inverse theorem for MaxCut",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.23989",
        "HTML": "https://arxiv.org/html/2506.23989v1",
        "PDF": "https://arxiv.org/pdf/2506.23989"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24003",
      "abstract": "In this paper, we present a practical approach to improve anatomical shape accuracy in whole-body medical segmentation. Our analysis shows that a shape-focused toolkit can enhance segmentation performance by over 8%, without the need for model re-training or fine-tuning. In comparison, modifications to model architecture typically lead to marginal gains of less than 3%. Motivated by this observation, we introduce ShapeKit, a flexible and easy-to-integrate toolkit designed to refine anatomical shapes. This work highlights the underappreciated value of shape-based tools and calls attention to their potential impact within the medical segmentation community.",
      "authors": [
        "Junqi Liu",
        "Dongli He",
        "Wenxuan Li",
        "Ningyu Wang",
        "Alan L. Yuille",
        "Zongwei Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:07:33+00:00",
          "link": "https://arxiv.org/abs/2506.24003v1",
          "size": "8535kb",
          "version": "v1"
        }
      ],
      "title": "ShapeKit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24003",
        "HTML": "https://arxiv.org/html/2506.24003v1",
        "PDF": "https://arxiv.org/pdf/2506.24003"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24007",
      "abstract": "This study investigates adaptive experimental design for treatment choice, also known as fixed-budget best-arm identification. We consider an adaptive procedure consisting of a treatment-allocation phase followed by a treatment-choice phase, and we design an adaptive experiment for this setup to efficiently identify the best treatment arm, defined as the one with the highest expected outcome. In our designed experiment, the treatment-allocation phase consists of two stages. The first stage is a pilot phase, where we allocate each treatment arm uniformly with equal proportions to eliminate clearly suboptimal arms and estimate outcome variances. In the second stage, we allocate treatment arms in proportion to the variances estimated in the first stage. After the treatment-allocation phase, the procedure enters the treatment-choice phase, where we choose the treatment arm with the highest sample mean as our estimate of the best treatment arm. We prove that this single design is simultaneously asymptotically minimax and Bayes optimal for the simple regret, with upper bounds that match our lower bounds up to exact constants. Therefore, our designed experiment achieves the sharp efficiency limits without requiring separate tuning for minimax and Bayesian objectives.",
      "authors": [
        "Masahiro Kato"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Econometrics (econ.EM)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Methodology (stat.ME)",
        "Machine Learning (stat.ML)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:11:44+00:00",
          "link": "https://arxiv.org/abs/2506.24007v1",
          "size": "50kb",
          "version": "v1"
        }
      ],
      "title": "Minimax and Bayes Optimal Best-arm Identification: Adaptive Experimental Design for Treatment Choice",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24007",
        "HTML": "https://arxiv.org/html/2506.24007v1",
        "PDF": "https://arxiv.org/pdf/2506.24007"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24008",
      "abstract": "The spatial photonic Ising machine (SPIM) is a promising optical hardware solver for large-scale combinatorial optimization problems with dense interactions. As the SPIM can represent Ising problems with rank-one coupling matrices, multiplexed versions have been proposed to enhance the applicability to higher-rank interactions. However, the multiplexing cost reduces the implementation efficiency, and even without multiplexing, the SPIM is known to represent coupling matrices beyond rank-one. In this paper, to clarify the intrinsic representation power of the original SPIM, we propose spatial QUBO (spQUBO), a formulation of Ising problems with spatially convolutional structures. We prove that any spQUBO reduces to a two-dimensional spQUBO, with the convolutional structure preserved, and that any two-dimensional spQUBO can be efficiently implemented on the SPIM without multiplexing. We further demonstrate its practical applicability to distance-based combinatorial optimization, such as placement problems and clustering problems. These results advance our understanding of the class of optimization problems where SPIMs exhibit superior efficiency and scalability. Furthermore, spQUBO's efficiency is not limited to the SPIM architecture; we show that its convolutional structure allows efficient computation using Fast Fourier Transforms (FFT).",
      "authors": [
        "Hiroshi Yamashita and Hideyuki Suzuki"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Emerging Technologies (cs.ET)",
        "Applied Physics (physics.app-ph)",
        "Optics (physics.optics)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:13:27+00:00",
          "link": "https://arxiv.org/abs/2506.24008v1",
          "size": "839kb",
          "version": "v1"
        }
      ],
      "title": "Spatial QUBO: Convolutional Formulation of Large-Scale Binary Optimization with Dense Interactions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24008",
        "HTML": "https://arxiv.org/html/2506.24008v1",
        "PDF": "https://arxiv.org/pdf/2506.24008"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24024",
      "abstract": "Auditory attention decoding (AAD) algorithms exploit brain signals, such as electroencephalography (EEG), to identify which speaker a listener is focusing on in a multi-speaker environment. While state-of-the-art AAD algorithms can identify the attended speaker on short time windows, their predictions are often too inaccurate for practical use. In this work, we propose augmenting AAD with a hidden Markov model (HMM) that models the temporal structure of attention. More specifically, the HMM relies on the fact that a subject is much less likely to switch attention than to keep attending the same speaker at any moment in time. We show how a HMM can significantly improve existing AAD algorithms in both causal (real-time) and non-causal (offline) settings. We further demonstrate that HMMs outperform existing postprocessing approaches in both accuracy and responsiveness, and explore how various factors such as window length, switching frequency, and AAD accuracy influence overall performance. The proposed method is computationally efficient, intuitive to use and applicable in both real-time and offline settings.",
      "authors": [
        "Nicolas Heintz",
        "Tom Francart and Alexander Bertrand"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:31:26+00:00",
          "link": "https://arxiv.org/abs/2506.24024v1",
          "size": "609kb",
          "version": "v1"
        }
      ],
      "title": "Post-processing of EEG-based Auditory Attention Decoding Decisions via Hidden Markov Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24024",
        "HTML": "https://arxiv.org/html/2506.24024v1",
        "PDF": "https://arxiv.org/pdf/2506.24024"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24034",
      "abstract": "Diffusion models (DMs) have recently been introduced as a regularizing prior for PET image reconstruction, integrating DMs trained on high-quality PET images with unsupervised schemes that condition on measured data. While these approaches have potential generalization advantages due to their independence from the scanner geometry and the injected activity level, they forgo the opportunity to explicitly model the interaction between the DM prior and noisy measurement data, potentially limiting reconstruction accuracy. To address this, we propose a supervised DM-based algorithm for PET reconstruction. Our method enforces the non-negativity of PET's Poisson likelihood model and accommodates the wide intensity range of PET images. Through experiments on realistic brain PET phantoms, we demonstrate that our approach outperforms or matches state-of-the-art deep learning-based methods quantitatively across a range of dose levels. We further conduct ablation studies to demonstrate the benefits of the proposed components in our model, as well as its dependence on training data, parameter count, and number of diffusion steps. Additionally, we show that our approach enables more accurate posterior sampling than unsupervised DM-based methods, suggesting improved uncertainty estimation. Finally, we extend our methodology to a practical approach for fully 3D PET and present example results from real [$^{18}$F]FDG brain PET data.",
      "authors": [
        "George Webber",
        "Alexander Hammers",
        "Andrew P King",
        "Andrew J Reader"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Medical Physics (physics.med-ph)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:39:50+00:00",
          "link": "https://arxiv.org/abs/2506.24034v1",
          "size": "6150kb",
          "version": "v1"
        }
      ],
      "title": "Supervised Diffusion-Model-Based PET Image Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24034",
        "HTML": "https://arxiv.org/html/2506.24034v1",
        "PDF": "https://arxiv.org/pdf/2506.24034"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24048",
      "abstract": "Consensus-based optimization (CBO) has established itself as an efficient gradient-free optimization scheme, with attractive mathematical properties, such as mean-field convergence results for non-convex loss functions. In this work, we study CBO in the context of closed-box adversarial attacks, which are imperceptible input perturbations that aim to fool a classifier, without accessing its gradient. Our contribution is to establish a connection between the so-called consensus hopping as introduced by Riedl et al. and natural evolution strategies (NES) commonly applied in the context of adversarial attacks and to rigorously relate both methods to gradient-based optimization schemes. Beyond that, we provide a comprehensive experimental study that shows that despite the conceptual similarities, CBO can outperform NES and other evolutionary strategies in certain scenarios.",
      "authors": [
        "Tim Roith",
        "Leon Bungert",
        "Philipp Wacker"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T16:54:44+00:00",
          "link": "https://arxiv.org/abs/2506.24048v1",
          "size": "3327kb",
          "version": "v1"
        }
      ],
      "title": "Consensus-based optimization for closed-box adversarial attacks and a connection to evolution strategies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24048",
        "PDF": "https://arxiv.org/pdf/2506.24048"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24074",
      "abstract": "Computer vision techniques have the potential to improve the diagnostic performance of colonoscopy, but the lack of 3D colonoscopy datasets for training and validation hinders their development. This paper introduces C3VDv2, the second version (v2) of the high-definition Colonoscopy 3D Video Dataset, featuring enhanced realism designed to facilitate the quantitative evaluation of 3D colon reconstruction algorithms. 192 video sequences were captured by imaging 60 unique, high-fidelity silicone colon phantom segments. Ground truth depth, surface normals, optical flow, occlusion, six-degree-of-freedom pose, coverage maps, and 3D models are provided for 169 colonoscopy videos. Eight simulated screening colonoscopy videos acquired by a gastroenterologist are provided with ground truth poses. The dataset includes 15 videos featuring colon deformations for qualitative assessment. C3VDv2 emulates diverse and challenging scenarios for 3D reconstruction algorithms, including fecal debris, mucous pools, blood, debris obscuring the colonoscope lens, en-face views, and fast camera motion. The enhanced realism of C3VDv2 will allow for more robust and representative development and evaluation of 3D reconstruction algorithms.",
      "authors": [
        "Mayank V. Golhar",
        "Lucas Sebastian Galeano Fretes",
        "Loren Ayers",
        "Venkata S. Akshintala",
        "Taylor L. Bobrow",
        "Nicholas J. Durr"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:29:06+00:00",
          "link": "https://arxiv.org/abs/2506.24074v1",
          "size": "10969kb",
          "version": "v1"
        }
      ],
      "title": "C3VDv2 -- Colonoscopy 3D video dataset with enhanced realism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24074",
        "HTML": "https://arxiv.org/html/2506.24074v1",
        "PDF": "https://arxiv.org/pdf/2506.24074"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.24081",
      "abstract": "We propose a circuit-level attack, SQUASH, a SWAP-Based Quantum Attack to sabotage Hybrid Quantum Neural Networks (HQNNs) for classification tasks. SQUASH is executed by inserting SWAP gate(s) into the variational quantum circuit of the victim HQNN. Unlike conventional noise-based or adversarial input attacks, SQUASH directly manipulates the circuit structure, leading to qubit misalignment and disrupting quantum state evolution. This attack is highly stealthy, as it does not require access to training data or introduce detectable perturbations in input states. Our results demonstrate that SQUASH significantly degrades classification performance, with untargeted SWAP attacks reducing accuracy by up to 74.08\\% and targeted SWAP attacks reducing target class accuracy by up to 79.78\\%. These findings reveal a critical vulnerability in HQNN implementations, underscoring the need for more resilient architectures against circuit-level adversarial interventions.",
      "authors": [
        "Rahul Kumar",
        "Wenqi Wei",
        "Ying Mao",
        "Junaid Farooq",
        "Ying Wang",
        "Juntao Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-30T17:36:31+00:00",
          "link": "https://arxiv.org/abs/2506.24081v1",
          "size": "712kb",
          "version": "v1"
        }
      ],
      "title": "SQUASH: A SWAP-Based Quantum Attack to Sabotage Hybrid Quantum Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.24081",
        "HTML": "https://arxiv.org/html/2506.24081v1",
        "PDF": "https://arxiv.org/pdf/2506.24081"
      },
      "source": "arXiv"
    },
    {
      "id": "1112.1768",
      "abstract": "The multi-armed bandit (MAB) problem is a widely studied model in the field of operations research for sequential decision making and reinforcement learning. This paper mainly considers the classical MAB model with the heavy-tailed reward distributions. We introduce the extended robust UCB policy, which is an extension of the pioneering UCB policies proposed by Bubeck et al. [5] and Lattimore [22]. The previous UCB policies require some strict conditions on the reward distributions, which can be hard to guarantee in practical scenarios. Our extended robust UCB generalizes Lattimore's seminary work (for moments of orders $p=4$ and $q=2$) to arbitrarily chosen $p>q>1$ as long as the two moments have a known controlled relationship, while still achieving the optimal regret growth order $O(log T)$, thus providing a broadened application area of the UCB policies for the heavy-tailed reward distributions. Furthermore, we achieve a near-optimal regret order without any knowledge of the reward distributions as long as their $p$-th moments exist for some $p>1$.",
      "authors": [
        "Keqin Liu",
        "Tianshuo Zheng",
        "Zhi-Hua Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Probability (math.PR)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2011-12-08T05:53:35+00:00",
          "link": "https://arxiv.org/abs/1112.1768v1",
          "size": "60kb",
          "version": "v1"
        },
        {
          "date": "2022-08-06T06:43:24+00:00",
          "link": "https://arxiv.org/abs/1112.1768v2",
          "size": "350kb",
          "version": "v2"
        },
        {
          "date": "2024-10-01T04:57:45+00:00",
          "link": "https://arxiv.org/abs/1112.1768v3",
          "size": "411kb",
          "version": "v3"
        },
        {
          "date": "2025-06-30T04:15:58+00:00",
          "link": "https://arxiv.org/abs/1112.1768v4",
          "size": "128kb",
          "version": "v4"
        }
      ],
      "title": "Extended UCB Policies for Frequentist Multi-armed Bandit Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/1112.1768",
        "HTML": "https://arxiv.org/html/1112.1768v4",
        "PDF": "https://arxiv.org/pdf/1112.1768"
      },
      "tasks": [
        "Decision Making",
        "Sequential Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "1306.1870",
      "abstract": "This is the manual of Cyan, a prototype-based object-oriented language. Cyan supports gradual typing (both static and dynamic typing), single inheritance, anonymous functions, generic prototypes with concepts, non-nullable types, partially safe object initialization, an object-oriented exception handling system, and a powerful Metaobject Protocol for metaprogramming at compile-time (this is described elsewhere).",
      "authors": [
        "Jos\\'e de Oliveira Guimar\\~aes"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2013-06-08T02:22:42+00:00",
          "link": "https://arxiv.org/abs/1306.1870v1",
          "size": "181kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T17:56:16+00:00",
          "link": "https://arxiv.org/abs/1306.1870v2",
          "size": "168kb",
          "version": "v2"
        }
      ],
      "title": "The Cyan Language",
      "links": {
        "Abstract": "https://arxiv.org/abs/1306.1870",
        "HTML": "https://arxiv.org/html/1306.1870v2",
        "PDF": "https://arxiv.org/pdf/1306.1870"
      },
      "source": "arXiv"
    },
    {
      "id": "2004.14547",
      "abstract": "We present Distributional Soft Actor-Critic (DSAC), a distributional reinforcement learning (RL) algorithm that combines the strengths of distributional information of accumulated rewards and entropy-driven exploration from Soft Actor-Critic (SAC) algorithm. DSAC models the randomness in both action and rewards, surpassing baseline performances on various continuous control tasks. Unlike standard approaches that solely maximize expected rewards, we propose a unified framework for risk-sensitive learning, one that optimizes the risk-related objective while balancing entropy to encourage exploration. Extensive experiments demonstrate DSAC's effectiveness in enhancing agent performances for both risk-neutral and risk-sensitive control tasks.",
      "authors": [
        "Xiaoteng Ma",
        "Junyao Chen",
        "Li Xia",
        "Jun Yang",
        "Qianchuan Zhao",
        "Zhengyuan Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2020-04-30T02:23:15+00:00",
          "link": "https://arxiv.org/abs/2004.14547v1",
          "size": "608kb",
          "version": "v1"
        },
        {
          "date": "2020-06-11T02:08:35+00:00",
          "link": "https://arxiv.org/abs/2004.14547v2",
          "size": "2631kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T01:33:14+00:00",
          "link": "https://arxiv.org/abs/2004.14547v3",
          "size": "3551kb",
          "version": "v3"
        }
      ],
      "title": "DSAC: Distributional Soft Actor-Critic for Risk-Sensitive Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2004.14547",
        "HTML": "https://arxiv.org/html/2004.14547v3",
        "PDF": "https://arxiv.org/pdf/2004.14547"
      },
      "tasks": [
        "continuous-control",
        "Continuous Control",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2011.04782",
      "abstract": "Goals for planning problems are typically conceived of as subsets of the state space. However, for many practical planning problems in robotics, we expect the robot to predict goals, e.g. from noisy sensors or by generalizing learned models to novel contexts. In these cases, sets with uncertainty naturally extend to probability distributions. While a few works have used probability distributions as goals for planning, surprisingly no systematic treatment of planning to goal distributions exists in the literature. This article serves to fill that gap. We argue that goal distributions are a more appropriate goal representation than deterministic sets for many robotics applications. We present a novel approach to planning under uncertainty to goal distributions, which we use to highlight several advantages of the goal distribution formulation. We build on previous results in the literature by formally framing our approach as an instance of planning as inference. We additionally derive reductions of several common planning objectives as special cases of our probabilistic planning framework. Our experiments demonstrate the flexibility of probability distributions as a goal representation on a variety of problems including planar navigation among obstacles, intercepting a moving target, rolling a ball to a target location, and a 7-DOF robot arm reaching to grasp an object.",
      "authors": [
        "Adam Conkey and Tucker Hermans"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2020-11-09T21:29:46+00:00",
          "link": "https://arxiv.org/abs/2011.04782v1",
          "size": "1268kb",
          "version": "v1"
        },
        {
          "date": "2022-04-29T15:42:40+00:00",
          "link": "https://arxiv.org/abs/2011.04782v2",
          "size": "3091kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T20:59:58+00:00",
          "link": "https://arxiv.org/abs/2011.04782v3",
          "size": "5613kb",
          "version": "v3"
        }
      ],
      "title": "Planning under Uncertainty to Goal Distributions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2011.04782",
        "HTML": "https://arxiv.org/html/2011.04782v3",
        "PDF": "https://arxiv.org/pdf/2011.04782"
      },
      "repo_urls": [
        "https://bitbucket.org/robot-learning/distribution_planning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2109.00970",
      "abstract": "In this paper, we propose a new and optimal construction of two-dimensional (2-D) Z-complementary array code set (ZCACS) using multivariable extended Boolean functions (EBFs). The proposed 2-D arrays can be used in multi-carrier code division multiple access (MC-CDMA) systems. The proposed construction produces a better PMEPR upper bound than the existing constructions for such use cases. We also propose a tighter upper bound for the set size and showed that the proposed code set is optimal in special cases. Finally, We derive 2-D Golay complementary array set (GCAS) and Golay complementary set (GCS) from the proposed construction, which has application in uniform rectangular array (URA)-based massive multiple-input multiple-output (mMIMO) system to achieve omnidirectional transmission. The simulation result shows the performance benefits of the derived codes. In essence, we show that the flexibility of the parameters of the proposed 2-D ZCACS makes it a good candidate for a wide range of use cases in wireless communication.",
      "authors": [
        "Abhishek Roy and Sudhan Majhi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2021-09-02T14:13:23+00:00",
          "link": "https://arxiv.org/abs/2109.00970v1",
          "size": "308kb",
          "version": "v1"
        },
        {
          "date": "2024-03-26T19:37:24+00:00",
          "link": "https://arxiv.org/abs/2109.00970v2",
          "size": "314kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T14:31:39+00:00",
          "link": "https://arxiv.org/abs/2109.00970v3",
          "size": "344kb",
          "version": "v3"
        }
      ],
      "title": "Construction of 2-D Z-Complementary Array Code Sets with Flexible Lengths for Different System Requirements",
      "links": {
        "Abstract": "https://arxiv.org/abs/2109.00970",
        "HTML": "https://arxiv.org/html/2109.00970v3",
        "PDF": "https://arxiv.org/pdf/2109.00970"
      },
      "source": "arXiv"
    },
    {
      "id": "2111.03639",
      "abstract": "We initiate the focused study of constant-cost randomized communication, with emphasis on its connection to graph representations. We observe that constant-cost randomized communication problems are equivalent to hereditary (i.e. closed under taking induced subgraphs) graph classes which admit constant-size adjacency sketches and probabilistic universal graphs (PUGs), which are randomized versions of the well-studied adjacency labeling schemes and induced-universal graphs. This gives a new perspective on long-standing questions about the existence of these objects, including new methods of constructing adjacency labeling schemes.\n  We ask three main questions about constant-cost communication, or equivalently, constant-size PUGs: (1) Are there any natural, non-trivial problems aside from Equality and k-Hamming Distance which have constant-cost communication? We provide a number of new examples, including deciding whether two vertices have path-distance at most k in a planar graph, and showing that constant-size PUGs are preserved by the Cartesian product operation. (2) What structures of a problem explain the existence or non-existence of a constant-cost protocol? We show that in many cases a Greater-Than subproblem is such a structure. (3) Is the Equality problem complete for constant-cost randomized communication? We show that it is not: there are constant-cost problems which do not reduce to Equality.",
      "authors": [
        "Nathaniel Harms",
        "Sebastian Wild",
        "Viktor Zamaraev"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2021-11-05T17:43:44+00:00",
          "link": "https://arxiv.org/abs/2111.03639v1",
          "size": "93kb",
          "version": "v1"
        },
        {
          "date": "2022-06-22T22:23:49+00:00",
          "link": "https://arxiv.org/abs/2111.03639v2",
          "size": "95kb",
          "version": "v2"
        },
        {
          "date": "2023-07-18T15:06:31+00:00",
          "link": "https://arxiv.org/abs/2111.03639v3",
          "size": "91kb",
          "version": "v3"
        },
        {
          "date": "2024-12-11T07:04:57+00:00",
          "link": "https://arxiv.org/abs/2111.03639v4",
          "size": "91kb",
          "version": "v4"
        },
        {
          "date": "2025-06-30T12:39:49+00:00",
          "link": "https://arxiv.org/abs/2111.03639v5",
          "size": "92kb",
          "version": "v5"
        }
      ],
      "title": "Randomized Communication and Implicit Graph Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2111.03639",
        "PDF": "https://arxiv.org/pdf/2111.03639"
      },
      "source": "arXiv"
    },
    {
      "id": "2112.06193",
      "abstract": "Recent years have witnessed great advances in object segmentation research. In addition to generic objects, aquatic animals have attracted research attention. Deep learning-based methods are widely used for aquatic animal segmentation and have achieved promising performance. However, there is a lack of challenging datasets for benchmarking. In this work, we build a new dataset dubbed \"Aquatic Animal Species.\" We also devise a novel GUided mixup augmeNtatioN and multi-modEl fusion for aquatic animaL segmentation (GUNNEL) that leverages the advantages of multiple segmentation models to segment aquatic animals effectively and improves the training performance by synthesizing hard samples. Extensive experiments demonstrated the superiority of our proposed framework over existing state-of-the-art instance segmentation methods. The code is available at https://github.com/lmquan2000/mask-mixup. The dataset is available at https://doi.org/10.5281/zenodo.8208877.",
      "authors": [
        "Minh-Quan Le and Trung-Nghia Le and Tam V. Nguyen and Isao Echizen and Minh-Triet Tran"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2021-12-12T09:57:59+00:00",
          "link": "https://arxiv.org/abs/2112.06193v1",
          "size": "24217kb",
          "version": "v1"
        },
        {
          "date": "2022-04-29T11:05:46+00:00",
          "link": "https://arxiv.org/abs/2112.06193v2",
          "size": "10239kb",
          "version": "v2"
        },
        {
          "date": "2023-08-10T16:03:31+00:00",
          "link": "https://arxiv.org/abs/2112.06193v3",
          "size": "10641kb",
          "version": "v3"
        },
        {
          "date": "2025-06-30T07:54:42+00:00",
          "link": "https://arxiv.org/abs/2112.06193v4",
          "size": "6800kb",
          "version": "v4"
        }
      ],
      "title": "GUNNEL: Guided Mixup Augmentation and Multi-Model Fusion for Aquatic Animal Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2112.06193",
        "HTML": "https://arxiv.org/html/2112.06193v4",
        "PDF": "https://arxiv.org/pdf/2112.06193"
      },
      "tasks": [
        "Benchmarking",
        "Instance Segmentation",
        "Segmentation",
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/lmquan2000/mask-mixup"
      ],
      "source": "arXiv"
    },
    {
      "id": "2201.03169",
      "abstract": "While existing federated learning approaches primarily focus on aggregating local models to construct a global model, in realistic settings, some clients may be reluctant to share their private models due to the inclusion of privacy-sensitive information. Knowledge distillation, which can extract model knowledge without accessing model parameters, is well-suited for this federated scenario. However, most distillation methods in federated learning (federated distillation) require a proxy dataset, which is difficult to obtain in the real world. Therefore, in this paper, we introduce a distributed three-player Generative Adversarial Network (GAN) to implement data-free mutual distillation and propose an effective method called FedDTG. We confirmed that the fake samples generated by GAN can make federated distillation more efficient and robust. Additionally, the distillation process between clients can deliver good individual client performance while simultaneously acquiring global knowledge and protecting data privacy. Our extensive experiments on benchmark vision datasets demonstrate that our method outperforms other federated distillation algorithms in terms of generalization.",
      "authors": [
        "Lingzhi Gao",
        "Zhenyuan Zhang",
        "Chao Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2022-01-10T05:26:33+00:00",
          "link": "https://arxiv.org/abs/2201.03169v1",
          "size": "1259kb",
          "version": "v1"
        },
        {
          "date": "2022-10-13T01:28:36+00:00",
          "link": "https://arxiv.org/abs/2201.03169v2",
          "size": "710kb",
          "version": "v2"
        },
        {
          "date": "2022-10-14T08:51:37+00:00",
          "link": "https://arxiv.org/abs/2201.03169v3",
          "size": "710kb",
          "version": "v3"
        },
        {
          "date": "2024-10-01T04:34:34+00:00",
          "link": "https://arxiv.org/abs/2201.03169v4",
          "size": "551kb",
          "version": "v4"
        },
        {
          "date": "2025-06-28T15:44:26+00:00",
          "link": "https://arxiv.org/abs/2201.03169v5",
          "size": "551kb",
          "version": "v5"
        }
      ],
      "title": "FedDTG:Federated Data-Free Knowledge Distillation via Three-Player Generative Adversarial Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2201.03169",
        "HTML": "https://arxiv.org/html/2201.03169v5",
        "PDF": "https://arxiv.org/pdf/2201.03169"
      },
      "tasks": [
        "Data-free Knowledge Distillation",
        "Federated Learning",
        "Generative Adversarial Network",
        "Knowledge Distillation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2206.00535",
      "abstract": "Deepfakes can fuel online misinformation. As deepfakes get harder to recognize with the naked eye, human users become more reliant on deepfake detection models to help them decide whether a video is real or fake. Currently, models yield a prediction for a video's authenticity, but do not integrate a method for alerting a human user. We introduce a framework for amplifying artifacts in deepfake videos to make them more detectable by people. We propose a novel, semi-supervised Artifact Attention module, which is trained on human responses to create attention maps that highlight video artifacts, and magnify them to create a novel visual indicator we call \"Deepfake Caricatures\". In a user study, we demonstrate that Caricatures greatly increase human detection, across video presentation times and user engagement levels. We also introduce a deepfake detection model that incorporates the Artifact Attention module to increase its accuracy and robustness. Overall, we demonstrate the success of a human-centered approach to designing deepfake mitigation methods.",
      "authors": [
        "Camilo Fosco",
        "Emilie Josephs",
        "Alex Andonian and Aude Oliva"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Human-Computer Interaction (cs.HC)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2022-06-01T14:43:49+00:00",
          "link": "https://arxiv.org/abs/2206.00535v1",
          "size": "6137kb",
          "version": "v1"
        },
        {
          "date": "2022-06-02T14:43:19+00:00",
          "link": "https://arxiv.org/abs/2206.00535v2",
          "size": "7330kb",
          "version": "v2"
        },
        {
          "date": "2023-04-10T17:14:43+00:00",
          "link": "https://arxiv.org/abs/2206.00535v3",
          "size": "11478kb",
          "version": "v3"
        },
        {
          "date": "2025-06-29T04:43:18+00:00",
          "link": "https://arxiv.org/abs/2206.00535v4",
          "size": "5589kb",
          "version": "v4"
        }
      ],
      "title": "Deepfake Caricatures: Amplifying attention to artifacts increases deepfake detection by humans and machines",
      "links": {
        "Abstract": "https://arxiv.org/abs/2206.00535",
        "HTML": "https://arxiv.org/html/2206.00535v4",
        "PDF": "https://arxiv.org/pdf/2206.00535"
      },
      "tasks": [
        "DeepFake Detection",
        "Face Swapping",
        "Human Detection",
        "Misinformation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2301.07876",
      "abstract": "This work analyzes how the trade-off between the modeling error, the terminal value function error, and the prediction horizon affects the performance of a nominal receding-horizon linear quadratic (LQ) controller. By developing a novel perturbation result of the Riccati difference equation, a novel performance upper bound is obtained and suggests that for many cases, the prediction horizon can be either one or infinity to improve the control performance, depending on the relative difference between the modeling error and the terminal value function error. The result also shows that when an infinite horizon is desired, a finite prediction horizon that is larger than the controllability index can be sufficient for achieving a near-optimal performance, revealing a close relation between the prediction horizon and controllability. The obtained suboptimality performance upper bound is applied to provide novel sample complexity and regret guarantees for nominal receding-horizon LQ controllers in a learning-based setting. We show that an adaptive prediction horizon that increases as a logarithmic function of time is beneficial for regret minimization.",
      "authors": [
        "Shengling Shi",
        "Anastasios Tsiamis",
        "Bart De Schutter"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2023-01-19T04:33:19+00:00",
          "link": "https://arxiv.org/abs/2301.07876v1",
          "size": "228kb",
          "version": "v1"
        },
        {
          "date": "2024-04-09T03:11:26+00:00",
          "link": "https://arxiv.org/abs/2301.07876v2",
          "size": "326kb",
          "version": "v2"
        },
        {
          "date": "2024-12-16T19:24:22+00:00",
          "link": "https://arxiv.org/abs/2301.07876v3",
          "size": "464kb",
          "version": "v3"
        },
        {
          "date": "2025-06-28T00:39:35+00:00",
          "link": "https://arxiv.org/abs/2301.07876v4",
          "size": "437kb",
          "version": "v4"
        }
      ],
      "title": "Suboptimality analysis of receding horizon quadratic control with unknown linear systems and its applications in learning-based control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2301.07876",
        "PDF": "https://arxiv.org/pdf/2301.07876"
      },
      "tasks": [
        "Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2304.05005",
      "abstract": "This paper investigates equilibrium computation and the price of anarchy for Bayesian games, which are the fundamental models of games with incomplete information. In normal-form games with complete information, it is known that efficiently computable no-regret dynamics converge to correlated equilibria, and the price of anarchy for correlated equilibria can be bounded for a broad class of games called smooth games. However, in Bayesian games, as surveyed by Forges (1993), several non-equivalent extensions of correlated equilibria exist, and it remains unclear whether they can be efficiently computed or whether their price of anarchy can be bounded.\n  In this paper, we identify a natural extension of correlated equilibria that can be computed efficiently and is guaranteed to have bounds on the price of anarchy in various games. First, we propose a variant of regret called untruthful swap regret. If each player minimizes it in repeated play of Bayesian games, the empirical distribution of these dynamics is guaranteed to converge to communication equilibria, which is one of the extensions of correlated equilibria proposed by Myerson (1982). We present an efficient algorithm for minimizing untruthful swap regret with a sublinear upper bound, which we prove to be tight in terms of the number of types. As a result, by simulating the dynamics with our algorithm, we can approximately compute a communication equilibrium in polynomial time. Furthermore, we extend existing lower bounds on the price of anarchy based on the smoothness arguments from Bayes--Nash equilibria to equilibria obtained by the proposed dynamics.",
      "authors": [
        "Kaito Fujii"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-04-11T06:22:51+00:00",
          "link": "https://arxiv.org/abs/2304.05005v1",
          "size": "70kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T13:53:00+00:00",
          "link": "https://arxiv.org/abs/2304.05005v2",
          "size": "67kb",
          "version": "v2"
        }
      ],
      "title": "Bayes correlated equilibria, no-regret dynamics in Bayesian games, and the price of anarchy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2304.05005",
        "PDF": "https://arxiv.org/pdf/2304.05005"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2305.02240",
      "abstract": "The 2-Vertex-Connected Spanning Subgraph problem (2VCSS) is among the most basic NP-hard (Survivable) Network Design problems: we are given an (unweighted) undirected graph $G$. Our goal is to find a spanning subgraph $S$ of $G$ with the minimum number of edges which is $2$-vertex-connected, namely $S$ remains connected after the deletion of an arbitrary node. 2VCSS is well-studied in terms of approximation algorithms, and the current best (polynomial-time) approximation factor is $10/7$ by Heeger and Vygen [SIDMA'17] (improving on earlier results by Khuller and Vishkin [STOC'92] and Garg, Vempala and Singla [SODA'93]).\n  Here we present an improved $4/3$ approximation. Our main technical ingredient is an approximation preserving reduction to a conveniently structured subset of instances which are ``almost'' 3-vertex-connected. The latter reduction might be helpful in future work.",
      "authors": [
        "Miguel Bosch-Calvo",
        "Fabrizio Grandoni",
        "and Afrouz Jabal Ameli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-03T16:19:51+00:00",
          "link": "https://arxiv.org/abs/2305.02240v1",
          "size": "678kb",
          "version": "v1"
        },
        {
          "date": "2023-12-19T16:49:48+00:00",
          "link": "https://arxiv.org/abs/2305.02240v2",
          "size": "847kb",
          "version": "v2"
        },
        {
          "date": "2025-06-13T07:35:08+00:00",
          "link": "https://arxiv.org/abs/2305.02240v3",
          "size": "1090kb",
          "version": "v3"
        },
        {
          "date": "2025-06-30T16:04:17+00:00",
          "link": "https://arxiv.org/abs/2305.02240v4",
          "size": "1091kb",
          "version": "v4"
        }
      ],
      "title": "A $4/3$ Approximation for $2$-Vertex-Connectivity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.02240",
        "HTML": "https://arxiv.org/html/2305.02240v4",
        "PDF": "https://arxiv.org/pdf/2305.02240"
      },
      "source": "arXiv"
    },
    {
      "id": "2305.10442",
      "abstract": "Sampling-based path planning algorithms play an important role in autonomous robotics. However, a common problem among the RRT-based algorithms is that the initial path generated is not optimal, and the convergence is too slow for real-world applications. In this paper, we propose a novel image-based learning algorithm using a Convolutional Block Attention Generative Adversarial Network (CBAGAN-RRT) with a combination of spatial and channel attention and a novel loss function to design the heuristics, find a better optimal path, and improve the convergence of the algorithm, both concerning time and speed. The probability distribution of the paths generated from our GAN model is used to guide the sampling process for the RRT algorithm. We demonstrate that our algorithm outperforms the previous state-of-the-art algorithms using both the image quality generation metrics, like IOU Score, Dice Score, FID score, and path planning metrics like time cost and the number of nodes. Ablation studies show the effectiveness of various components in our network architecture. The advantage of our approach is that we can avoid the complicated preprocessing in the state space, our model can be generalized to complex environments like those containing turns and narrow passages without loss of accuracy, and our model can be easily integrated with other sampling-based path planning algorithms.",
      "authors": [
        "Abhinav Sagar",
        "Sai Teja Gilukara"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-13T20:06:53+00:00",
          "link": "https://arxiv.org/abs/2305.10442v1",
          "size": "397kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T14:15:46+00:00",
          "link": "https://arxiv.org/abs/2305.10442v2",
          "size": "236kb",
          "version": "v2"
        }
      ],
      "title": "CBAGAN-RRT: Convolutional Block Attention Generative Adversarial Network for Sampling-Based Path Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.10442",
        "HTML": "https://arxiv.org/html/2305.10442v2",
        "PDF": "https://arxiv.org/pdf/2305.10442"
      },
      "tasks": [
        "Generative Adversarial Network"
      ],
      "source": "arXiv"
    },
    {
      "id": "2305.16121",
      "abstract": "Deep learning is experiencing a rise in large-scale models. Training large-scale models is costly, prompting researchers to train large-scale models on commodity servers that more researchers can access. The massive number of parameters necessitates the use of model parallelism training methods. Existing studies focus on training with pipeline model parallelism. However, the tensor model parallelism (TMP) is inevitable when the model size keeps increasing, where frequent data-dependent communication and computation operations significantly reduce the training efficiency.\n  In this paper, we present Oases, an automated TMP method with overlapped communication to accelerate large-scale model training on commodity servers. Oases proposes a fine-grained training operation schedule to maximize overlapping communication and computation that have data dependence. Additionally, we design the Oases planner that searches for the best model parameter partition strategy of TMP to achieve further accelerations. Unlike existing methods, Oases planner is tailored to model the cost of overlapped communication-computation operations.\n  We evaluate Oases on various model settings and two commodity clusters, and compare Oases to four state-of-the-art implementations. Experimental results show that Oases achieves speedups of 1.01--1.48\\(\\times\\) over the fastest baseline, and speedups of up to 1.95\\(\\times\\) over Megatron.",
      "authors": [
        "Shengwei Li",
        "Zhiquan Lai",
        "Dongsheng Li",
        "Yanqi Hao",
        "Weijie Liu",
        "Keshi Ge",
        "Xiaoge Deng",
        "Kai Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-25T14:53:35+00:00",
          "link": "https://arxiv.org/abs/2305.16121v1",
          "size": "1606kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T05:29:27+00:00",
          "link": "https://arxiv.org/abs/2305.16121v2",
          "size": "4375kb",
          "version": "v2"
        }
      ],
      "title": "Oases: Efficient Large-Scale Model Training on Commodity Servers via Overlapped and Automated Tensor Model Parallelism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.16121",
        "HTML": "https://arxiv.org/html/2305.16121v2",
        "PDF": "https://arxiv.org/pdf/2305.16121"
      },
      "source": "arXiv"
    },
    {
      "id": "2305.16264",
      "abstract": "The current trend of scaling language models involves increasing both parameter count and training dataset size. Extrapolating this trend suggests that training dataset size may soon be limited by the amount of text data available on the internet. Motivated by this limit, we investigate scaling language models in data-constrained regimes. Specifically, we run a large set of experiments varying the extent of data repetition and compute budget, ranging up to 900 billion training tokens and 9 billion parameter models. We find that with constrained data for a fixed compute budget, training with up to 4 epochs of repeated data yields negligible changes to loss compared to having unique data. However, with more repetition, the value of adding compute eventually decays to zero. We propose and empirically validate a scaling law for compute optimality that accounts for the decreasing value of repeated tokens and excess parameters. Finally, we experiment with approaches mitigating data scarcity, including augmenting the training dataset with code data or removing commonly used filters. Models and datasets from our 400 training runs are freely available at https://github.com/huggingface/datablations.",
      "authors": [
        "Niklas Muennighoff",
        "Alexander M. Rush",
        "Boaz Barak",
        "Teven Le Scao",
        "Aleksandra Piktus",
        "Nouamane Tazi",
        "Sampo Pyysalo",
        "Thomas Wolf",
        "Colin Raffel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-25T17:18:55+00:00",
          "link": "https://arxiv.org/abs/2305.16264v1",
          "size": "1454kb",
          "version": "v1"
        },
        {
          "date": "2023-05-30T17:51:41+00:00",
          "link": "https://arxiv.org/abs/2305.16264v2",
          "size": "1521kb",
          "version": "v2"
        },
        {
          "date": "2023-06-15T13:20:45+00:00",
          "link": "https://arxiv.org/abs/2305.16264v3",
          "size": "1623kb",
          "version": "v3"
        },
        {
          "date": "2023-10-26T02:24:24+00:00",
          "link": "https://arxiv.org/abs/2305.16264v4",
          "size": "1623kb",
          "version": "v4"
        },
        {
          "date": "2025-06-28T00:00:06+00:00",
          "link": "https://arxiv.org/abs/2305.16264v5",
          "size": "1619kb",
          "version": "v5"
        }
      ],
      "title": "Scaling Data-Constrained Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.16264",
        "HTML": "https://arxiv.org/html/2305.16264v5",
        "PDF": "https://arxiv.org/pdf/2305.16264"
      },
      "models": [
        {
          "model_path": "Finnish-NLP/llama-7b-finnish",
          "downloads": "90",
          "likes": "4",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Finnish-NLP/llama-7b-finnish"
        },
        {
          "model_path": "Finnish-NLP/llama-3b-finnish",
          "downloads": "430",
          "likes": "5",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Finnish-NLP/llama-3b-finnish"
        },
        {
          "model_path": "Finnish-NLP/Ahma-3B",
          "downloads": "1561",
          "likes": "12",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Finnish-NLP/Ahma-3B"
        },
        {
          "model_path": "Finnish-NLP/Ahma-7B",
          "downloads": "105",
          "likes": "8",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Finnish-NLP/Ahma-7B"
        },
        {
          "model_path": "RichardErkhov/Finnish-NLP_-_llama-7b-finnish-gguf",
          "downloads": "165",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/RichardErkhov/Finnish-NLP_-_llama-7b-finnish-gguf"
        },
        {
          "model_path": "QuantFactory/Ahma-3B-GGUF",
          "downloads": "170",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/QuantFactory/Ahma-3B-GGUF"
        },
        {
          "model_path": "RichardErkhov/Finnish-NLP_-_llama-3b-finnish-gguf",
          "downloads": "251",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/RichardErkhov/Finnish-NLP_-_llama-3b-finnish-gguf"
        },
        {
          "model_path": "RichardErkhov/Finnish-NLP_-_Ahma-3B-gguf",
          "downloads": "243",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/RichardErkhov/Finnish-NLP_-_Ahma-3B-gguf"
        },
        {
          "model_path": "RichardErkhov/Finnish-NLP_-_Ahma-7B-4bits",
          "downloads": "4",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/RichardErkhov/Finnish-NLP_-_Ahma-7B-4bits"
        }
      ],
      "datasets": [
        {
          "dataset_name": "Muennighoff/babi",
          "downloads": "344",
          "likes": "3",
          "link": "https://huggingface.co/datasets/Muennighoff/babi"
        },
        {
          "dataset_name": "datablations/c4-subsets",
          "downloads": "924",
          "likes": "3",
          "link": "https://huggingface.co/datasets/datablations/c4-subsets"
        },
        {
          "dataset_name": "datablations/oscar-subsets",
          "downloads": "429",
          "likes": "0",
          "link": "https://huggingface.co/datasets/datablations/oscar-subsets"
        }
      ],
      "conference": "scaling-data-constrained-language-models",
      "conference_url_abs": "https://openreview.net/forum?id=j5BuTrEj35",
      "tasks": [],
      "repo_urls": [
        "https://github.com/huggingface/datablations",
        "https://github.com/hornhehhf/llm-ell"
      ],
      "source": "arXiv"
    },
    {
      "id": "2307.02897",
      "abstract": "Smartphones with multi-camera systems, featuring cameras with varying field-of-views (FoVs), are increasingly common. This variation in FoVs results in content differences across videos, paving the way for an innovative approach to video super-resolution (VSR). This method enhances the VSR performance of lower resolution (LR) videos by leveraging higher resolution reference (Ref) videos. Previous works, which operate on this principle, generally expand on traditional VSR models by combining LR and Ref inputs over time into a unified stream. However, we can expect that better results are obtained by independently aggregating these Ref image sequences temporally. Therefore, we introduce an improved method, RefVSR++, which performs the parallel aggregation of LR and Ref images in the temporal direction, aiming to optimize the use of the available data. RefVSR++ also incorporates improved mechanisms for aligning image features over time, crucial for effective VSR. Our experiments demonstrate that RefVSR++ outperforms previous works by over 1dB in PSNR, setting a new benchmark in the field.",
      "authors": [
        "Han Zou",
        "Masanori Suganuma",
        "Takayuki Okatani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-06T10:09:52+00:00",
          "link": "https://arxiv.org/abs/2307.02897v1",
          "size": "34613kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T02:12:57+00:00",
          "link": "https://arxiv.org/abs/2307.02897v2",
          "size": "5707kb",
          "version": "v2"
        }
      ],
      "title": "RefVSR++: Exploiting Reference Inputs for Reference-based Video Super-resolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.02897",
        "HTML": "https://arxiv.org/html/2307.02897v2",
        "PDF": "https://arxiv.org/pdf/2307.02897"
      },
      "tasks": [
        "Reference-based Video Super-Resolution",
        "Super-Resolution",
        "Video Super-Resolution"
      ],
      "source": "arXiv"
    },
    {
      "id": "2307.09253",
      "abstract": "We introduce $\\omega$-catoids as generalisations of\n  (strict) $\\omega$-categories and in particular the higher path\n  categories generated by computads or polygraphs in\n  higher-dimensional rewriting. We also introduce $\\omega$-quantales\n  that generalise the $\\omega$-Kleene algebras recently proposed for\n  algebraic coherence proofs in higher-dimensional rewriting. We then\n  establish correspondences between $\\omega$-catoids and convolution\n  $\\omega$-quantales. These are related to J\\'onsson-Tarski-style\n  dualities between relational structures and lattices with operators.\n  We extend these correspondences to $(\\omega,p)$-catoids, catoids\n  with a groupoid structure above some dimension, and convolution\n  $(\\omega,p)$-quantales, using Dedekind quantales above some\n  dimension to capture homotopic constructions and proofs in\n  higher-dimensional rewriting. We also specialise them to finitely\n  decomposable $(\\omega, p)$-catoids, an appropriate setting for\n  defining $(\\omega, p)$-semirings and $(\\omega, p)$-Kleene\n  algebras. These constructions support the systematic development and\n  justification of $\\omega$-Kleene algebra and $\\omega$-quantale\n  axioms, improving on the recent approach mentioned, where axioms for\n  $\\omega$-Kleene algebras have been introduced in an ad hoc fashion.",
      "authors": [
        "Cameron Calk",
        "Philippe Malbos",
        "Damien Pous",
        "Georg Struth"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-18T13:35:31+00:00",
          "link": "https://arxiv.org/abs/2307.09253v1",
          "size": "52kb",
          "version": "v1"
        },
        {
          "date": "2024-02-11T09:57:32+00:00",
          "link": "https://arxiv.org/abs/2307.09253v2",
          "size": "52kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T19:00:21+00:00",
          "link": "https://arxiv.org/abs/2307.09253v3",
          "size": "59kb",
          "version": "v3"
        }
      ],
      "title": "Higher Catoids, Higher Quantales and their Correspondences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.09253",
        "HTML": "https://arxiv.org/html/2307.09253v3",
        "PDF": "https://arxiv.org/pdf/2307.09253"
      },
      "source": "arXiv"
    },
    {
      "id": "2307.13153",
      "abstract": "We investigate a combinatorial optimization problem that involves patrolling the edges of an acute triangle using a unit-speed agent. The goal is to minimize the maximum (1-gap) idle time of any edge, which is defined as the time gap between consecutive visits to that edge. This problem has roots in a centuries-old optimization problem posed by Fagnano in 1775, who sought to determine the inscribed triangle of an acute triangle with the minimum perimeter. It is well-known that the orthic triangle, giving rise to a periodic and cyclic trajectory obeying the laws of geometric optics, is the optimal solution to Fagnano's problem. Such trajectories are known as Fagnano orbits, or more generally as billiard trajectories. We demonstrate that the orthic triangle is also an optimal solution to the patrolling problem.\n  Our main contributions pertain to new connections between billiard trajectories and optimal patrolling schedules in combinatorial optimization. In particular, as an artifact of our arguments, we introduce a novel 2-gap patrolling problem that seeks to minimize the visitation time of objects every three visits. We prove that there exist infinitely many well-structured billiard-type optimal trajectories for this problem, including the orthic trajectory, which has the special property of minimizing the visitation time gap between any two consecutively visited edges. Complementary to that, we also examine the cost of dynamic, sub-optimal trajectories to the 1-gap patrolling optimization problem. These trajectories result from a greedy algorithm and can be implemented by a computationally primitive mobile agent.",
      "authors": [
        "Konstantinos Georgiou",
        "Somnath Kundu",
        "Pawel Pralat"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2023-07-24T22:39:39+00:00",
          "link": "https://arxiv.org/abs/2307.13153v1",
          "size": "97kb",
          "version": "v1"
        },
        {
          "date": "2024-04-14T15:14:29+00:00",
          "link": "https://arxiv.org/abs/2307.13153v2",
          "size": "93kb",
          "version": "v2"
        },
        {
          "date": "2025-02-06T22:59:54+00:00",
          "link": "https://arxiv.org/abs/2307.13153v3",
          "size": "87kb",
          "version": "v3"
        },
        {
          "date": "2025-06-28T15:44:01+00:00",
          "link": "https://arxiv.org/abs/2307.13153v4",
          "size": "88kb",
          "version": "v4"
        }
      ],
      "title": "The Fagnano Triangle Patrolling Problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2307.13153",
        "HTML": "https://arxiv.org/html/2307.13153v4",
        "PDF": "https://arxiv.org/pdf/2307.13153"
      },
      "source": "arXiv"
    },
    {
      "id": "2309.04355",
      "abstract": "Compressed Sparse Column (CSC) and Coordinate (COO) are popular compression formats for sparse matrices. However, both CSC and COO are general purpose and cannot take advantage of any of the properties of the data other than sparsity, such as data redundancy. Highly redundant sparse data is common in many machine learning applications, such as genomics, and is often too large for in-core computation using conventional sparse storage formats. In this paper, we present two extensions to CSC: (1) Value-Compressed Sparse Column (VCSC) and (2) Index- and Value-Compressed Sparse Column (IVCSC). VCSC takes advantage of high redundancy within a column to further compress data up to 3-fold over COO and 2.25-fold over CSC, without significant negative impact to performance characteristics. IVCSC extends VCSC by compressing index arrays through delta encoding and byte-packing, achieving a 10-fold decrease in memory usage over COO and 7.5-fold decrease over CSC. Our benchmarks on simulated and real data show that VCSC and IVCSC can be read in compressed form with little added computational cost. These two novel compression formats offer a broadly useful solution to encoding and reading redundant sparse data.",
      "authors": [
        "Skyler Ruiter",
        "Seth Wolfgang",
        "Marc Tunnell",
        "Timothy Triche Jr.",
        "Erin Carrier",
        "Zachary DeBruine"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-08T14:24:40+00:00",
          "link": "https://arxiv.org/abs/2309.04355v1",
          "size": "254kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T17:01:35+00:00",
          "link": "https://arxiv.org/abs/2309.04355v2",
          "size": "1446kb",
          "version": "v2"
        }
      ],
      "title": "Value-Compressed Sparse Column (VCSC): Sparse Matrix Storage for Redundant Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.04355",
        "HTML": "https://arxiv.org/html/2309.04355v2",
        "PDF": "https://arxiv.org/pdf/2309.04355"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2309.16494",
      "abstract": "Recently, deep learning-based methods have dominated image dehazing domain. Although very competitive dehazing performance has been achieved with sophisticated models, effective solutions for extracting useful features are still under-explored. In addition, non-local network, which has made a breakthrough in many vision tasks, has not been appropriately applied to image dehazing. Thus, a multi-receptive-field non-local network (MRFNLN) consisting of the multi-stream feature attention block (MSFAB) and cross non-local block (CNLB) is presented in this paper. We start with extracting richer features for dehazing. Specifically, we design a multi-stream feature extraction (MSFE) sub-block, which contains three parallel convolutions with different receptive fields (i.e., $1\\times 1$, $3\\times 3$, $5\\times 5$) for extracting multi-scale features. Following MSFE, we employ an attention sub-block to make the model adaptively focus on important channels/regions. The MSFE and attention sub-blocks constitute our MSFAB. Then, we design a cross non-local block (CNLB), which can capture long-range dependencies beyond the query. Instead of the same input source of query branch, the key and value branches are enhanced by fusing more preceding features. CNLB is computation-friendly by leveraging a spatial pyramid down-sampling (SPDS) strategy to reduce the computation and memory consumption without sacrificing the performance. Last but not least, a novel detail-focused contrastive regularization (DFCR) is presented by emphasizing the low-level details and ignoring the high-level semantic information in the representation space. Comprehensive experimental results demonstrate that the proposed MRFNLN model outperforms recent state-of-the-art dehazing methods with less than 1.5 Million parameters.",
      "authors": [
        "Zewei He",
        "Zixuan Chen",
        "Jinlei Li",
        "Ziqian Lu",
        "Xuecheng Sun",
        "Hao Luo",
        "Zhe-Ming Lu",
        "Evangelos K. Markakis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-28T14:59:16+00:00",
          "link": "https://arxiv.org/abs/2309.16494v1",
          "size": "21005kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T17:51:31+00:00",
          "link": "https://arxiv.org/abs/2309.16494v2",
          "size": "7603kb",
          "version": "v2"
        }
      ],
      "title": "Accurate and lightweight dehazing via multi-receptive-field non-local network and novel contrastive regularization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.16494",
        "HTML": "https://arxiv.org/html/2309.16494v2",
        "PDF": "https://arxiv.org/pdf/2309.16494"
      },
      "tasks": [
        "Image Dehazing"
      ],
      "source": "arXiv"
    },
    {
      "id": "2310.00085",
      "abstract": "Safe landing is essential in robotics applications, from industrial settings to space exploration. As artificial intelligence advances, we have developed PEACE (Prompt Engineering Automation for CLIPSeg Enhancement), a system that automatically generates and refines prompts for identifying landing zones in changing environments. Traditional approaches using fixed prompts for open-vocabulary models struggle with environmental changes and can lead to dangerous outcomes when conditions are not represented in the predefined prompts. PEACE addresses this limitation by dynamically adapting to shifting data distributions. Our key innovation is the dual segmentation of safe and unsafe landing zones, allowing the system to refine the results by removing unsafe areas from potential landing sites. Using only monocular cameras and image segmentation, PEACE can safely guide descent operations from 100 meters to altitudes as low as 20 meters. The testing shows that PEACE significantly outperforms the standard CLIP and CLIPSeg prompting methods, improving the successful identification of safe landing zones from 57% to 92%. We have also demonstrated enhanced performance when replacing CLIPSeg with FastSAM. The complete source code is available as an open-source software.",
      "authors": [
        "Haechan Mark Bong",
        "Rongge Zhang",
        "Antoine Robillard",
        "Giovanni Beltrame"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-29T18:44:27+00:00",
          "link": "https://arxiv.org/abs/2310.00085v1",
          "size": "4948kb",
          "version": "v1"
        },
        {
          "date": "2023-12-08T17:22:40+00:00",
          "link": "https://arxiv.org/abs/2310.00085v2",
          "size": "4948kb",
          "version": "v2"
        },
        {
          "date": "2024-09-02T20:53:33+00:00",
          "link": "https://arxiv.org/abs/2310.00085v3",
          "size": "7525kb",
          "version": "v3"
        },
        {
          "date": "2024-09-06T20:08:40+00:00",
          "link": "https://arxiv.org/abs/2310.00085v4",
          "size": "7535kb",
          "version": "v4"
        },
        {
          "date": "2025-06-26T18:21:41+00:00",
          "link": "https://arxiv.org/abs/2310.00085v5",
          "size": "54790kb",
          "version": "v5"
        }
      ],
      "title": "PEACE: Prompt Engineering Automation for CLIPSeg Enhancement for Safe-Landing Zone Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.00085",
        "HTML": "https://arxiv.org/html/2310.00085v5",
        "PDF": "https://arxiv.org/pdf/2310.00085"
      },
      "repo_urls": [
        "https://github.com/MISTLab/PEACE"
      ],
      "source": "arXiv"
    },
    {
      "id": "2310.03647",
      "abstract": "Existing approaches to algorithmic fairness aim to ensure equitable outcomes if human decision-makers comply perfectly with algorithmic decisions. However, perfect compliance with the algorithm is rarely a reality or even a desirable outcome in human-AI collaboration. Yet, recent studies have shown that selective compliance with fair algorithms can amplify discrimination relative to the prior human policy. As a consequence, ensuring equitable outcomes requires fundamentally different algorithmic design principles that ensure robustness to the decision-maker's (a priori unknown) compliance pattern. We define the notion of compliance-robustly fair algorithmic recommendations that are guaranteed to (weakly) improve fairness in decisions, regardless of the human's compliance pattern. We propose a simple optimization strategy to identify the best performance-improving compliance-robustly fair policy. However, we show that it may be infeasible to design algorithmic recommendations that are simultaneously fair in isolation, compliance-robustly fair, and more accurate than the human policy; thus, if our goal is to improve the equity and accuracy of human-AI collaboration, it may not be desirable to enforce traditional algorithmic fairness constraints. We illustrate the value of our approach on criminal sentencing data before and after the introduction of an algorithmic risk assessment tool in Virginia.",
      "authors": [
        "Haosen Ge",
        "Hamsa Bastani",
        "Osbert Bastani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-05T16:21:42+00:00",
          "link": "https://arxiv.org/abs/2310.03647v1",
          "size": "70kb",
          "version": "v1"
        },
        {
          "date": "2025-02-12T01:59:32+00:00",
          "link": "https://arxiv.org/abs/2310.03647v2",
          "size": "402kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T18:13:15+00:00",
          "link": "https://arxiv.org/abs/2310.03647v3",
          "size": "365kb",
          "version": "v3"
        }
      ],
      "title": "Rethinking Algorithmic Fairness for Human-AI Collaboration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.03647",
        "HTML": "https://arxiv.org/html/2310.03647v3",
        "PDF": "https://arxiv.org/pdf/2310.03647"
      },
      "tasks": [
        "Fairness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2310.11594",
      "abstract": "The delicate equilibrium between user privacy and the ability to unleash the potential of distributed data is an important concern. Federated learning, which enables the training of collaborative models without sharing of data, has emerged as a privacy-centric solution. This approach brings forth security challenges, notably poisoning and backdoor attacks where malicious entities inject corrupted data into the training process, as well as evasion attacks that aim to induce misclassifications at test time. Our research investigates the intersection of adversarial training, a common defense method against evasion attacks, and backdoor attacks within federated learning. We introduce Adversarial Robustness Unhardening (ARU), which is employed by a subset of adversarial clients to intentionally undermine model robustness during federated training, rendering models susceptible to a broader range of evasion attacks. We present extensive experiments evaluating ARU's impact on adversarial training and existing robust aggregation defenses against poisoning and backdoor attacks. Our results show that ARU can substantially undermine adversarial training's ability to harden models against test-time evasion attacks, and that adversaries employing ARU can even evade robust aggregation defenses that often neutralize poisoning or backdoor attacks.",
      "authors": [
        "Taejin Kim",
        "Jiarui Li",
        "Shubhranshu Singh",
        "Nikhil Madaan",
        "Carlee Joe-Wong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-17T21:38:41+00:00",
          "link": "https://arxiv.org/abs/2310.11594v1",
          "size": "663kb",
          "version": "v1"
        },
        {
          "date": "2023-10-21T03:18:35+00:00",
          "link": "https://arxiv.org/abs/2310.11594v2",
          "size": "663kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T19:25:01+00:00",
          "link": "https://arxiv.org/abs/2310.11594v3",
          "size": "2189kb",
          "version": "v3"
        }
      ],
      "title": "Adversarial Robustness Unhardening via Backdoor Attacks in Federated Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.11594",
        "HTML": "https://arxiv.org/html/2310.11594v3",
        "PDF": "https://arxiv.org/pdf/2310.11594"
      },
      "tasks": [
        "Adversarial Robustness",
        "Federated Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2310.15952",
      "abstract": "Once deployed, medical image analysis methods are often faced with unexpected image corruptions and noise perturbations. These unknown covariate shifts present significant challenges to deep learning based methods trained on \"clean\" images. This often results in unreliable predictions and poorly calibrated confidence, hence hindering clinical applicability. While recent methods have been developed to address specific issues such as confidence calibration or adversarial robustness, no single framework effectively tackles all these challenges simultaneously. To bridge this gap, we propose LaDiNE, a novel ensemble learning method combining the robustness of Vision Transformers with diffusion-based generative models for improved reliability in medical image classification. Specifically, transformer encoder blocks are used as hierarchical feature extractors that learn invariant features from images for each ensemble member, resulting in features that are robust to input perturbations. In addition, diffusion models are used as flexible density estimators to estimate member densities conditioned on the invariant features, leading to improved modeling of complex data distributions while retaining properly calibrated confidence. Extensive experiments on tuberculosis chest X-rays and melanoma skin cancer datasets demonstrate that LaDiNE achieves superior performance compared to a wide range of state-of-the-art methods by simultaneously improving prediction accuracy and confidence calibration under unseen noise, adversarial perturbations, and resolution degradation.",
      "authors": [
        "Xing Shen",
        "Hengguan Huang",
        "Brennan Nichyporuk",
        "Tal Arbel"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-24T15:53:07+00:00",
          "link": "https://arxiv.org/abs/2310.15952v1",
          "size": "1032kb",
          "version": "v1"
        },
        {
          "date": "2023-10-25T15:11:57+00:00",
          "link": "https://arxiv.org/abs/2310.15952v2",
          "size": "1032kb",
          "version": "v2"
        },
        {
          "date": "2023-11-10T09:52:03+00:00",
          "link": "https://arxiv.org/abs/2310.15952v3",
          "size": "1032kb",
          "version": "v3"
        },
        {
          "date": "2024-09-24T19:33:34+00:00",
          "link": "https://arxiv.org/abs/2310.15952v4",
          "size": "2276kb",
          "version": "v4"
        },
        {
          "date": "2025-06-29T17:46:13+00:00",
          "link": "https://arxiv.org/abs/2310.15952v5",
          "size": "2363kb",
          "version": "v5"
        }
      ],
      "title": "Improving Robustness and Reliability in Medical Image Classification with Latent-Guided Diffusion and Nested-Ensembles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.15952",
        "HTML": "https://arxiv.org/html/2310.15952v5",
        "PDF": "https://arxiv.org/pdf/2310.15952"
      },
      "tasks": [
        "Data Augmentation",
        "image-classification",
        "Image Classification",
        "Medical Image Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2311.01715",
      "abstract": "Acousto-optic sensing provides an alternative approach to traditional microphone arrays by shedding light on the interaction of light with an acoustic field. Sound field reconstruction is a fascinating and advanced technique used in acousto-optics sensing. Current challenges in sound-field reconstruction methods pertain to scenarios in which the sound source is located within the reconstruction area, known as the exterior problem. Existing reconstruction algorithms, primarily designed for interior scenarios, often exhibit suboptimal performance when applied to exterior cases. This paper introduces a novel technique for exterior sound-field reconstruction. The proposed method leverages concentric circle sampling and a two-dimensional exterior sound-field reconstruction approach based on circular harmonic extensions. To evaluate the efficacy of this approach, both numerical simulations and practical experiments are conducted. The results highlight the superior accuracy of the proposed method when compared to conventional reconstruction methods, all while utilizing a minimal amount of measured projection data.",
      "authors": [
        "Phuc Duc Nguyen",
        "Kenji Ishikawa",
        "Noboru Harada",
        "Takehiro Moriya"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-03T05:19:26+00:00",
          "link": "https://arxiv.org/abs/2311.01715v1",
          "size": "2669kb",
          "version": "v1"
        },
        {
          "date": "2024-11-02T13:58:53+00:00",
          "link": "https://arxiv.org/abs/2311.01715v2",
          "size": "3009kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T05:52:19+00:00",
          "link": "https://arxiv.org/abs/2311.01715v3",
          "size": "3570kb",
          "version": "v3"
        }
      ],
      "title": "Acousto-optic reconstruction of exterior sound field based on concentric circle sampling with circular harmonic expansion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.01715",
        "HTML": "https://arxiv.org/html/2311.01715v3",
        "PDF": "https://arxiv.org/pdf/2311.01715"
      },
      "source": "arXiv"
    },
    {
      "id": "2311.03542",
      "abstract": "We survey graph reachability indexing techniques for efficient processing of graph reachability queries in two types of popular graph models: plain graphs and edge-labeled graphs. Reachability queries are Boolean in nature, determining whether a directed path exists between a given source and target vertex. They form a core class of navigational queries in graph processing. Reachability indexes are specialized data structures designed to accelerate reachability query processing. Work on this topic goes back four decades -- we include 33 of the proposed techniques. Plain graphs contain only vertices and edges, with reachability queries checking path existence between a source and target vertex. Edge-labeled graphs, in contrast, augment plain graphs by adding edge labels. Reachability queries in edge-labeled graphs incorporate path constraints based on edge labels, assessing both path existence and compliance with path constraints.\n  We categorize techniques in both plain and edge-labeled graphs and discuss the approaches according to this classification, using existing techniques as exemplars. We discuss the main challenges within each class and how these might be addressed in other approaches. We conclude with a discussion of the open research challenges and future research directions, along the lines of integrating reachability indexes into modern graph database management systems. This survey serves as a comprehensive resource for researchers and practitioners interested in the advancements, techniques, and challenges on reachability indexing in graph analytics.",
      "authors": [
        "Chao Zhang",
        "Angela Bonifati",
        "M. Tamer \\\"Ozsu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-06T21:27:32+00:00",
          "link": "https://arxiv.org/abs/2311.03542v1",
          "size": "2529kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T14:47:12+00:00",
          "link": "https://arxiv.org/abs/2311.03542v2",
          "size": "1918kb",
          "version": "v2"
        }
      ],
      "title": "Indexing Techniques for Graph Reachability Queries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.03542",
        "HTML": "https://arxiv.org/html/2311.03542v2",
        "PDF": "https://arxiv.org/pdf/2311.03542"
      },
      "source": "arXiv"
    },
    {
      "id": "2311.07460",
      "abstract": "Significant progress has been made in anomaly detection and run-time monitoring to improve the safety and security of cyber-physical systems (CPS). However, less attention has been paid to hazard mitigation. This paper proposes a combined knowledge and data driven approach, KnowSafe, for the design of safety engines that can predict and mitigate safety hazards resulting from safety-critical malicious attacks or accidental faults targeting a CPS controller. We integrate domain-specific knowledge of safety constraints and context-specific mitigation actions with machine learning (ML) techniques to estimate system trajectories in the far and near future, infer potential hazards, and generate optimal corrective actions to keep the system safe. Experimental evaluation on two realistic closed-loop testbeds for artificial pancreas systems (APS) and a real-world clinical trial dataset for diabetes treatment demonstrates that KnowSafe outperforms the state-of-the-art by achieving higher accuracy in predicting system state trajectories and potential hazards, a low false positive rate, and no false negatives. It also maintains the safe operation of the simulated APS despite faults or attacks without introducing any new hazards, with a hazard mitigation success rate of 92.8%, which is at least 76% higher than solely rule-based (50.9%) and data-driven (52.7%) methods.",
      "authors": [
        "Xugui Zhou",
        "Maxfield Kouzel",
        "Chloe Smith",
        "Homa Alemzadeh"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-13T16:43:34+00:00",
          "link": "https://arxiv.org/abs/2311.07460v1",
          "size": "5596kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T05:22:47+00:00",
          "link": "https://arxiv.org/abs/2311.07460v2",
          "size": "5607kb",
          "version": "v2"
        }
      ],
      "title": "KnowSafe: Combined Knowledge and Data Driven Hazard Mitigation in Artificial Pancreas Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.07460",
        "HTML": "https://arxiv.org/html/2311.07460v2",
        "PDF": "https://arxiv.org/pdf/2311.07460"
      },
      "tasks": [
        "Anomaly Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2312.01431",
      "abstract": "Adapting pre-trained image models to video modality has proven to be an effective strategy for robust few-shot action recognition. In this work, we explore the potential of adapter tuning in image-to-video model adaptation and propose a novel video adapter tuning framework, called Disentangled-and-Deformable Spatio-Temporal Adapter (D$^2$ST-Adapter). It features a lightweight design, low adaptation overhead and powerful spatio-temporal feature adaptation capabilities. D$^2$ST-Adapter is structured with an internal dual-pathway architecture that enables built-in disentangled encoding of spatial and temporal features within the adapter, seamlessly integrating into the single-stream feature learning framework of pre-trained image models. In particular, we develop an efficient yet effective implementation of the D$^2$ST-Adapter, incorporating the specially devised anisotropic Deformable Spatio-Temporal Attention as its pivotal operation. This mechanism can be individually tailored for two pathways with anisotropic sampling densities along the spatial and temporal domains in 3D spatio-temporal space, enabling disentangled encoding of spatial and temporal features while maintaining a lightweight design. Extensive experiments by instantiating our method on both pre-trained ResNet and ViT demonstrate the superiority of our method over state-of-the-art methods. Our method is particularly well-suited to challenging scenarios where temporal dynamics are critical for action recognition. Code is available at https://github.com/qizhongtan/D2ST-Adapter.",
      "authors": [
        "Wenjie Pei",
        "Qizhong Tan",
        "Guangming Lu",
        "Jiandong Tian",
        "Jun Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-03T15:40:10+00:00",
          "link": "https://arxiv.org/abs/2312.01431v1",
          "size": "4308kb",
          "version": "v1"
        },
        {
          "date": "2024-04-17T12:36:06+00:00",
          "link": "https://arxiv.org/abs/2312.01431v2",
          "size": "7706kb",
          "version": "v2"
        },
        {
          "date": "2024-04-20T14:15:36+00:00",
          "link": "https://arxiv.org/abs/2312.01431v3",
          "size": "7702kb",
          "version": "v3"
        },
        {
          "date": "2025-06-30T07:19:35+00:00",
          "link": "https://arxiv.org/abs/2312.01431v4",
          "size": "9091kb",
          "version": "v4"
        }
      ],
      "title": "D$^2$ST-Adapter: Disentangled-and-Deformable Spatio-Temporal Adapter for Few-shot Action Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.01431",
        "HTML": "https://arxiv.org/html/2312.01431v4",
        "PDF": "https://arxiv.org/pdf/2312.01431"
      },
      "tasks": [
        "Action Recognition",
        "Few-Shot action recognition",
        "Few Shot Action Recognition",
        "Few-Shot Learning"
      ],
      "repo_urls": [
        "https://github.com/qizhongtan/d2st-adapter"
      ],
      "source": "arXiv"
    },
    {
      "id": "2312.02312",
      "abstract": "Video games have served as useful benchmarks for the decision-making community, but going beyond Atari games towards modern games has been prohibitively expensive for the vast majority of the research community. Prior work in modern video games typically relied on game-specific integration to obtain game features and enable online training, or on existing large datasets. An alternative approach is to train agents using imitation learning to play video games purely from images. However, this setting poses a fundamental question: which visual encoders obtain representations that retain information critical for decision making? To answer this question, we conduct a systematic study of imitation learning with publicly available pre-trained visual encoders compared to the typical task-specific end-to-end training approach in Minecraft, Counter-Strike: Global Offensive, and Minecraft Dungeons. Our results show that end-to-end training can be effective with comparably low-resolution images and only minutes of demonstrations, but significant improvements can be gained by utilising pre-trained encoders such as DINOv2 depending on the game. In addition to enabling effective decision making, we show that pre-trained encoders can make decision-making research in video games more accessible by significantly reducing the cost of training.",
      "authors": [
        "Lukas Sch\\\"afer",
        "Logan Jones",
        "Anssi Kanervisto",
        "Yuhan Cao",
        "Tabish Rashid",
        "Raluca Georgescu",
        "Dave Bignell",
        "Siddhartha Sen",
        "Andrea Trevi\\~no Gavito",
        "Sam Devlin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-04T19:52:12+00:00",
          "link": "https://arxiv.org/abs/2312.02312v1",
          "size": "6167kb",
          "version": "v1"
        },
        {
          "date": "2025-04-30T17:44:55+00:00",
          "link": "https://arxiv.org/abs/2312.02312v2",
          "size": "6079kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T11:59:07+00:00",
          "link": "https://arxiv.org/abs/2312.02312v3",
          "size": "6080kb",
          "version": "v3"
        }
      ],
      "title": "Visual Encoders for Data-Efficient Imitation Learning in Modern Video Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.02312",
        "PDF": "https://arxiv.org/pdf/2312.02312"
      },
      "tasks": [
        "Atari Games",
        "Decision Making",
        "Imitation Learning",
        "Minecraft",
        "Sequential Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2312.03121",
      "abstract": "We argue that many general evaluation problems can be viewed through the lens of voting theory. Each task is interpreted as a separate voter, which requires only ordinal rankings or pairwise comparisons of agents to produce an overall evaluation. By viewing the aggregator as a social welfare function, we are able to leverage centuries of research in social choice theory to derive principled evaluation frameworks with axiomatic foundations. These evaluations are interpretable and flexible, while avoiding many of the problems currently facing cross-task evaluation. We apply this Voting-as-Evaluation (VasE) framework across multiple settings, including reinforcement learning, large language models, and humans. In practice, we observe that VasE can be more robust than popular evaluation frameworks (Elo and Nash averaging), discovers properties in the evaluation data not evident from scores alone, and can predict outcomes better than Elo in a complex seven-player game. We identify one particular approach, maximal lotteries, that satisfies important consistency properties relevant to evaluation, is computationally efficient (polynomial in the size of the evaluation data), and identifies game-theoretic cycles.",
      "authors": [
        "Marc Lanctot",
        "Kate Larson",
        "Yoram Bachrach",
        "Luke Marris",
        "Zun Li",
        "Avishkar Bhoopchand",
        "Thomas Anthony",
        "Brian Tanner",
        "Anna Koop"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computer Science and Game Theory (cs.GT)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2023-12-05T20:40:37+00:00",
          "link": "https://arxiv.org/abs/2312.03121v1",
          "size": "743kb",
          "version": "v1"
        },
        {
          "date": "2023-12-07T02:16:24+00:00",
          "link": "https://arxiv.org/abs/2312.03121v2",
          "size": "743kb",
          "version": "v2"
        },
        {
          "date": "2025-01-20T19:52:00+00:00",
          "link": "https://arxiv.org/abs/2312.03121v3",
          "size": "742kb",
          "version": "v3"
        },
        {
          "date": "2025-06-28T20:24:20+00:00",
          "link": "https://arxiv.org/abs/2312.03121v4",
          "size": "740kb",
          "version": "v4"
        }
      ],
      "title": "Evaluating Agents using Social Choice Theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2312.03121",
        "HTML": "https://arxiv.org/html/2312.03121v4",
        "PDF": "https://arxiv.org/pdf/2312.03121"
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/google-deepmind/open_spiel/tree/master/open_spiel/python/voting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2401.01042",
      "abstract": "Event-based cameras provide accurate and high temporal resolution measurements for performing computer vision tasks in challenging scenarios, such as high-dynamic range environments and fast-motion maneuvers. Despite their advantages, utilizing deep learning for event-based vision encounters a significant obstacle due to the scarcity of annotated data caused by the relatively recent emergence of event-based cameras. To overcome this limitation, leveraging the knowledge available from annotated data obtained with conventional frame-based cameras presents an effective solution based on unsupervised domain adaptation. We propose a new algorithm tailored for adapting a deep neural network trained on annotated frame-based data to generalize well on event-based unannotated data. Our approach incorporates uncorrelated conditioning and self-supervised learning in an adversarial learning scheme to close the gap between the two source and target domains. By applying self-supervised learning, the algorithm learns to align the representations of event-based data with those from frame-based camera data, thereby facilitating knowledge transfer.Furthermore, the inclusion of uncorrelated conditioning ensures that the adapted model effectively distinguishes between event-based and conventional data, enhancing its ability to classify event-based images accurately.Through empirical experimentation and evaluation, we demonstrate that our algorithm surpasses existing approaches designed for the same purpose using two benchmarks. The superior performance of our solution is attributed to its ability to effectively utilize annotated data from frame-based cameras and transfer the acquired knowledge to the event-based vision domain.",
      "authors": [
        "Mohammad Rostami and Dayuan Jian and Ruitong Sun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-02T05:10:08+00:00",
          "link": "https://arxiv.org/abs/2401.01042v1",
          "size": "5300kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T06:51:22+00:00",
          "link": "https://arxiv.org/abs/2401.01042v2",
          "size": "1302kb",
          "version": "v2"
        }
      ],
      "title": "Relating Events and Frames Based on Self-Supervised Learning and Uncorrelated Conditioning for Unsupervised Domain Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.01042",
        "HTML": "https://arxiv.org/html/2401.01042v2",
        "PDF": "https://arxiv.org/pdf/2401.01042"
      },
      "tasks": [
        "Domain Adaptation",
        "Event-based vision",
        "Self-Supervised Learning",
        "Unsupervised Domain Adaptation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2401.01497",
      "abstract": "Sequential recommenders are crucial to the success of online applications, \\eg e-commerce, video streaming, and social media. While model architectures continue to improve, for every new application domain, we still have to train a new model from scratch for high quality recommendations. On the other hand, pre-trained language and vision models have shown great success in zero-shot or few-shot adaptation to new application domains. Inspired by the success of pre-trained models in peer AI fields, we propose a novel pre-trained sequential recommendation framework: PrepRec. We learn universal item representations by modeling item popularity dynamics. Through extensive experiments on five real-world datasets, we show that PrepRec, without any auxiliary information, can not only zero-shot transfer to a new domain, but achieve competitive performance compared to state-of-the-art sequential recommender models with only a fraction of the model size. In addition, with a simple post-hoc interpolation, PrepRec can improve the performance of existing sequential recommenders on average by 13.8\\% in Recall@10 and 29.5% in NDCG@10. We provide an anonymized implementation of PrepRec at https://anonymous.4open.science/r/PrepRec--2F60/",
      "authors": [
        "Junting Wang",
        "Praneet Rathi",
        "and Hari Sundaram"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-03T02:02:58+00:00",
          "link": "https://arxiv.org/abs/2401.01497v1",
          "size": "4449kb",
          "version": "v1"
        },
        {
          "date": "2024-04-10T05:27:12+00:00",
          "link": "https://arxiv.org/abs/2401.01497v2",
          "size": "4825kb",
          "version": "v2"
        },
        {
          "date": "2024-10-05T22:55:51+00:00",
          "link": "https://arxiv.org/abs/2401.01497v3",
          "size": "6091kb",
          "version": "v3"
        },
        {
          "date": "2024-10-25T01:43:57+00:00",
          "link": "https://arxiv.org/abs/2401.01497v4",
          "size": "6092kb",
          "version": "v4"
        },
        {
          "date": "2025-06-28T08:55:48+00:00",
          "link": "https://arxiv.org/abs/2401.01497v5",
          "size": "1881kb",
          "version": "v5"
        }
      ],
      "title": "A Pre-trained Sequential Recommendation Framework: Popularity Dynamics for Zero-shot Transfer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.01497",
        "HTML": "https://arxiv.org/html/2401.01497v5",
        "PDF": "https://arxiv.org/pdf/2401.01497"
      },
      "tasks": [
        "Sequential Recommendation"
      ],
      "repo_urls": [
        "https://github.com/crowddynamicslab/preprec"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.00450",
      "abstract": "Graph Neural Networks (GNNs) have made significant advancements in node classification, but their success relies on sufficient labeled nodes per class in the training data. Real-world graph data often exhibits a long-tail distribution with sparse labels, emphasizing the importance of GNNs' ability in few-shot node classification, which entails categorizing nodes with limited data. Traditional episodic meta-learning approaches have shown promise in this domain, but they face an inherent limitation: it might lead the model to converge to suboptimal solutions because of random and uniform task assignment, ignoring task difficulty levels. This could lead the meta-learner to face complex tasks too soon, hindering proper learning. Ideally, the meta-learner should start with simple concepts and advance to more complex ones, like human learning. So, we introduce CPT, a novel two-stage curriculum learning method that aligns task difficulty with the meta-learner's progressive competence, enhancing overall performance. Specifically, in CPT's initial stage, the focus is on simpler tasks, fostering foundational skills for engaging with complex tasks later. Importantly, the second stage dynamically adjusts task difficulty based on the meta-learner's growing competence, aiming for optimal knowledge acquisition. Extensive experiments on popular node classification datasets demonstrate significant improvements of our strategy over existing methods.",
      "authors": [
        "Qilong Yan",
        "Yufeng Zhang",
        "Jinghao Zhang",
        "Jingpu Duan",
        "Jian Yin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-01T09:36:56+00:00",
          "link": "https://arxiv.org/abs/2402.00450v1",
          "size": "996kb",
          "version": "v1"
        },
        {
          "date": "2024-02-23T08:52:09+00:00",
          "link": "https://arxiv.org/abs/2402.00450v2",
          "size": "996kb",
          "version": "v2"
        },
        {
          "date": "2024-10-18T02:45:18+00:00",
          "link": "https://arxiv.org/abs/2402.00450v3",
          "size": "997kb",
          "version": "v3"
        },
        {
          "date": "2024-12-31T04:45:50+00:00",
          "link": "https://arxiv.org/abs/2402.00450v4",
          "size": "1183kb",
          "version": "v4"
        },
        {
          "date": "2025-06-30T08:31:11+00:00",
          "link": "https://arxiv.org/abs/2402.00450v5",
          "size": "974kb",
          "version": "v5"
        }
      ],
      "title": "CPT: Competence-progressive Training Strategy for Few-shot Node Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.00450",
        "HTML": "https://arxiv.org/html/2402.00450v5",
        "PDF": "https://arxiv.org/pdf/2402.00450"
      },
      "tasks": [
        "Meta-Learning",
        "Node Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.01782",
      "abstract": "Spiking Neural Networks (SNNs), providing more realistic neuronal dynamics, have been shown to achieve performance comparable to Artificial Neural Networks (ANNs) in several machine learning tasks. Information is processed as spikes within SNNs in an event-based mechanism that significantly reduces energy consumption. However, training SNNs is challenging due to the non-differentiable nature of the spiking mechanism. Traditional approaches, such as Backpropagation Through Time (BPTT), have shown effectiveness but come with additional computational and memory costs and are biologically implausible. In contrast, recent works propose alternative learning methods with varying degrees of locality, demonstrating success in classification tasks. In this work, we show that these methods share similarities during the training process, while they present a trade-off between biological plausibility and performance. Further, given the implicitly recurrent nature of SNNs, this research investigates the influence of the addition of explicit recurrence to SNNs. We experimentally prove that the addition of explicit recurrent weights enhances the robustness of SNNs. We also investigate the performance of local learning methods under gradient and non-gradient-based adversarial attacks.",
      "authors": [
        "Jiaqi Lin",
        "Sen Lu",
        "Malyaban Bal",
        "Abhronil Sengupta"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-01T19:57:08+00:00",
          "link": "https://arxiv.org/abs/2402.01782v1",
          "size": "367kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T14:07:25+00:00",
          "link": "https://arxiv.org/abs/2402.01782v2",
          "size": "383kb",
          "version": "v2"
        }
      ],
      "title": "Benchmarking Spiking Neural Network Learning Methods with Varying Locality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.01782",
        "HTML": "https://arxiv.org/html/2402.01782v2",
        "PDF": "https://arxiv.org/pdf/2402.01782"
      },
      "tasks": [
        "Benchmarking"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.02242",
      "abstract": "Pre-trained vision models (PVMs) have demonstrated remarkable adaptability across a wide range of downstream vision tasks, showcasing exceptional performance. However, as these models scale to billions or even trillions of parameters, conventional full fine-tuning has become increasingly impractical due to its high computational and storage demands. To address these challenges, parameter-efficient fine-tuning (PEFT) has emerged as a promising alternative, aiming to achieve performance comparable to full fine-tuning while making minimal adjustments to the model parameters. This paper presents a comprehensive survey of the latest advancements in the visual PEFT field, systematically reviewing current methodologies and categorizing them into four primary categories: addition-based, partial-based, unified-based, and multi-task tuning. In addition, this paper offers an in-depth analysis of widely used visual datasets and real-world applications where PEFT methods have been successfully applied. Furthermore, this paper introduces the V-PEFT Bench, a unified benchmark designed to standardize the evaluation of PEFT methods across a diverse set of vision tasks, ensuring consistency and fairness in comparison. Finally, the paper outlines potential directions for future research to propel advances in the PEFT field. A comprehensive collection of resources is available at https://github.com/synbol/Awesome-Parameter-Efficient-Transfer-Learning.",
      "authors": [
        "Yi Xin",
        "Jianjiang Yang",
        "Siqi Luo",
        "Yuntao Du",
        "Qi Qin",
        "Kangrui Cen",
        "Yangfan He",
        "Bin Fu",
        "Xiaokang Yang",
        "Guangtao Zhai",
        "Ming-Hsuan Yang",
        "Xiaohong Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-03T19:12:20+00:00",
          "link": "https://arxiv.org/abs/2402.02242v1",
          "size": "99kb",
          "version": "v1"
        },
        {
          "date": "2024-02-08T08:17:57+00:00",
          "link": "https://arxiv.org/abs/2402.02242v2",
          "size": "99kb",
          "version": "v2"
        },
        {
          "date": "2025-03-25T04:37:33+00:00",
          "link": "https://arxiv.org/abs/2402.02242v3",
          "size": "99kb",
          "version": "v3"
        },
        {
          "date": "2025-03-26T05:36:30+00:00",
          "link": "https://arxiv.org/abs/2402.02242v4",
          "size": "99kb",
          "version": "v4"
        },
        {
          "date": "2025-06-29T17:09:26+00:00",
          "link": "https://arxiv.org/abs/2402.02242v5",
          "size": "9900kb",
          "version": "v5"
        }
      ],
      "title": "Parameter-Efficient Fine-Tuning for Pre-Trained Vision Models: A Survey and Benchmark",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.02242",
        "HTML": "https://arxiv.org/html/2402.02242v5",
        "PDF": "https://arxiv.org/pdf/2402.02242"
      },
      "tasks": [
        "parameter-efficient fine-tuning",
        "Transfer Learning"
      ],
      "repo_urls": [
        "https://github.com/synbol/awesome-parameter-efficient-transfer-learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.04665",
      "abstract": "In this paper, we propose a novel Gaussian process-based moving horizon estimation (MHE) framework for unknown nonlinear systems. On the one hand, we approximate the system dynamics by the posterior means of the learned Gaussian processes (GPs). On the other hand, we exploit the posterior variances of the Gaussian processes to design the weighting matrices in the MHE cost function and account for the uncertainty in the learned system dynamics. The data collection and the tuning of the hyperparameters are done offline. We prove robust stability of the GP-based MHE scheme using a Lyapunov-based proof technique. Furthermore, as additional contribution, we derive a sufficient condition under which incremental input/output-to-state stability (a nonlinear detectability notion) is preserved when approximating the system dynamics using, e.g., machine learning techniques. Finally, we illustrate the performance of the GP-based MHE scheme in two simulation case studies and show how the chosen weighting matrices can lead to an improved performance compared to standard cost functions.",
      "authors": [
        "Tobias M. Wolff",
        "Victor G. Lopez",
        "and Matthias A. M\\\"uller"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-07T08:52:59+00:00",
          "link": "https://arxiv.org/abs/2402.04665v1",
          "size": "932kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T12:41:37+00:00",
          "link": "https://arxiv.org/abs/2402.04665v2",
          "size": "934kb",
          "version": "v2"
        }
      ],
      "title": "Gaussian Process-Based Nonlinear Moving Horizon Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.04665",
        "HTML": "https://arxiv.org/html/2402.04665v2",
        "PDF": "https://arxiv.org/pdf/2402.04665"
      },
      "tasks": [
        "Gaussian Processes"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.08765",
      "abstract": "With the rise of social media, political conversations now take place in more diffuse environments. In this context, it is not always clear why some actors, more than others, have greater influence on how discussions are shaped. To investigate the factors behind such influence, we build on nodality, a concept in political science which describes the capacity of an actor to exchange information within discourse networks. This concept goes beyond traditional network metrics that describe the position of an actor in the network to include exogenous drivers of influence (e.g. factors relating to organisational hierarchies). We study online discourse on Twitter (now X) in the UK to measure the relative nodality of two sets of policy actors - Members of Parliament (MPs) and accredited journalists - on four policy topics. We find that influence on the platform is driven by two key factors: (i) active nodality, derived from the actor's level of topic-related engagement, and (ii) inherent nodality, which is independent of the platform discourse and reflects the actor's institutional position. These findings significantly further our understanding of the origins of influence on social media platforms and suggest in which contexts influence is transferable across topics.",
      "authors": [
        "Sukankana Chakraborty and Leonardo Castro-Gonzalez and Helen Margetts and Hardik Rajpal and Daniele Guariso and Jonathan Bright"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-13T19:59:49+00:00",
          "link": "https://arxiv.org/abs/2402.08765v1",
          "size": "4528kb",
          "version": "v1"
        },
        {
          "date": "2024-06-12T09:01:50+00:00",
          "link": "https://arxiv.org/abs/2402.08765v2",
          "size": "4550kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T20:56:39+00:00",
          "link": "https://arxiv.org/abs/2402.08765v3",
          "size": "11126kb",
          "version": "v3"
        }
      ],
      "title": "Who is driving the conversation? Analysing the nodality of British MPs and journalists on social media",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.08765",
        "HTML": "https://arxiv.org/html/2402.08765v3",
        "PDF": "https://arxiv.org/pdf/2402.08765"
      },
      "source": "arXiv"
    },
    {
      "id": "2402.09600",
      "abstract": "Graph Neural Networks (GNNs) have achieved remarkable success in learning node representations and have shown strong performance in tasks such as node classification. However, recent findings indicate that the presence of noise in real-world graph data can substantially impair the effectiveness of GNNs. To address this challenge, we introduce a robust and innovative node representation learning method named Graph Contrastive Learning with Low-Rank Regularization, or GCL-LRR, which follows a two-stage transductive learning framework for node classification. In the first stage, the GCL-LRR encoder is optimized through prototypical contrastive learning while incorporating a low-rank regularization objective. In the second stage, the representations generated by GCL-LRR are employed by a linear transductive classifier to predict the labels of unlabeled nodes within the graph. Our GCL-LRR is inspired by the Low Frequency Property (LFP) of the graph data and its labels, and it is also theoretically motivated by our sharp generalization bound for transductive learning. To the best of our knowledge, our theoretical result is among the first to theoretically demonstrate the advantage of low-rank regularization in transductive learning, which is also supported by strong empirical results. To further enhance the performance of GCL-LRR, we present an improved model named GCL-LR-Attention, which incorporates a novel LR-Attention layer into GCL-LRR. GCL-LR-Attention reduces the kernel complexity of GCL-LRR and contributes to a tighter generalization bound, leading to improved performance. Extensive evaluations on standard benchmark datasets evidence the effectiveness and robustness of both GCL-LRR and GCL-LR-Attention in learning meaningful node representations. The code is available at https://github.com/Statistical-Deep-Learning/GCL-LR-Attention.",
      "authors": [
        "Yancheng Wang",
        "Yingzhen Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Social and Information Networks (cs.SI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-14T22:15:37+00:00",
          "link": "https://arxiv.org/abs/2402.09600v1",
          "size": "3636kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T05:31:17+00:00",
          "link": "https://arxiv.org/abs/2402.09600v2",
          "size": "1414kb",
          "version": "v2"
        }
      ],
      "title": "Graph Contrastive Learning with Low-Rank Regularization and Low-Rank Attention for Noisy Node Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.09600",
        "HTML": "https://arxiv.org/html/2402.09600v2",
        "PDF": "https://arxiv.org/pdf/2402.09600"
      },
      "tasks": [
        "Classification",
        "Contrastive Learning",
        "Node Classification",
        "Transductive Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.09833",
      "abstract": "A key component of any robot is the interface between robotics middleware software and physical motors. New robots often use arbitrary, messy mixtures of closed and open motor drivers and error-prone physical mountings, wiring, and connectors to interface them. There is a need for a standardizing OSH component to abstract this complexity, as Arduino did for interfacing to smaller components. We present a OSH printed circuit board to solve this problem once and for all. On the high-level side, it interfaces to Arduino Giga - acting as an unusually large and robust shield - and thus to existing open source software stacks. A ROS2 interface is provided. On the lower-level side, it interfaces to existing emerging standard open hardware including OSH motor drivers and relays, which can already be used to drive fully open hardware wheeled and arm robots. This enables the creation of a family of standardized, fully open hardware, fully reproducible, research platforms.",
      "authors": [
        "Chris Waltham",
        "Andy Perrett",
        "Rakshit Soni",
        "Charles Fox"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-15T09:52:03+00:00",
          "link": "https://arxiv.org/abs/2402.09833v1",
          "size": "5280kb",
          "version": "v1"
        },
        {
          "date": "2024-05-13T15:30:57+00:00",
          "link": "https://arxiv.org/abs/2402.09833v2",
          "size": "5276kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T17:51:46+00:00",
          "link": "https://arxiv.org/abs/2402.09833v3",
          "size": "6152kb",
          "version": "v3"
        }
      ],
      "title": "R4: rapid reproducible robotics research open hardware control system",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.09833",
        "PDF": "https://arxiv.org/pdf/2402.09833"
      },
      "source": "arXiv"
    },
    {
      "id": "2402.12993",
      "abstract": "The development of AI-assisted chemical synthesis tools requires comprehensive datasets covering diverse reaction types, yet current high-throughput experimental (HTE) approaches are expensive and limited in scope. Chemical literature represents a vast, underexplored data source containing thousands of reactions published annually. However, extracting reaction information from literature faces significant challenges including varied writing styles, complex coreference relationships, and multimodal information presentation. This paper proposes ChemMiner, a novel end-to-end framework leveraging multiple agents powered by large language models (LLMs) to extract high-fidelity chemical data from literature. ChemMiner incorporates three specialized agents: a text analysis agent for coreference mapping, a multimodal agent for non-textual information extraction, and a synthesis analysis agent for data generation. Furthermore, we developed a comprehensive benchmark with expert-annotated chemical literature to evaluate both extraction efficiency and precision. Experimental results demonstrate reaction identification rates comparable to human chemists while significantly reducing processing time, with high accuracy, recall, and F1 scores. Our open-sourced benchmark facilitates future research in chemical literature data mining.",
      "authors": [
        "Kexin Chen",
        "Yuyang Du",
        "Junyou Li",
        "Hanqun Cao",
        "Menghao Guo",
        "Xilin Dang",
        "Lanqing Li",
        "Jiezhong Qiu",
        "Pheng Ann Heng",
        "Guangyong Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-20T13:21:46+00:00",
          "link": "https://arxiv.org/abs/2402.12993v1",
          "size": "322kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T08:19:19+00:00",
          "link": "https://arxiv.org/abs/2402.12993v2",
          "size": "3751kb",
          "version": "v2"
        }
      ],
      "title": "ChemMiner: A Large Language Model Agent System for Chemical Literature Data Mining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.12993",
        "HTML": "https://arxiv.org/html/2402.12993v2",
        "PDF": "https://arxiv.org/pdf/2402.12993"
      },
      "tasks": [
        "AI Agent",
        "Drug Discovery",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.15677",
      "abstract": "This paper studies a consensus problem in multidimensional networks having the same agent-to-agent interaction pattern under both intra- and cross-layer time delays. Several conditions for the agents to asymptotically reach a consensus are derived, which involve the overall network's structure, the local interacting pattern, and the assumptions specified on the time delays. The validity of these conditions is proved by direct eigenvalue evaluation and supported by numerical simulations.",
      "authors": [
        "Hoang Huy Vu",
        "Quyen Ngoc Nguyen",
        "Tuynh Van Pham",
        "Chuong Van Nguyen",
        "Minh Hoang Trinh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Multiagent Systems (cs.MA)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-24T01:33:57+00:00",
          "link": "https://arxiv.org/abs/2402.15677v1",
          "size": "2066kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T02:37:05+00:00",
          "link": "https://arxiv.org/abs/2402.15677v2",
          "size": "16144kb",
          "version": "v2"
        }
      ],
      "title": "Consensus seeking in diffusive multidimensional networks with a repeated interaction pattern and time-delays",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.15677",
        "HTML": "https://arxiv.org/html/2402.15677v2",
        "PDF": "https://arxiv.org/pdf/2402.15677"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2402.18784",
      "abstract": "The question \"Can machines think?\" and the Turing Test to assess whether machines could achieve human-level intelligence is one of the roots of AI. With the philosophical argument \"I think, therefore I am\", this paper challenge the idea of a \"thinking machine\" supported by current AIs since there is no sense of self in them. Current artificial intelligence is only seemingly intelligent information processing and does not truly understand or be subjectively aware of oneself and perceive the world with the self as human intelligence does. In this paper, we introduce a Brain-inspired and Self-based Artificial Intelligence (BriSe AI) paradigm. This BriSe AI paradigm is dedicated to coordinating various cognitive functions and learning strategies in a self-organized manner to build human-level AI models and robotic applications. Specifically, BriSe AI emphasizes the crucial role of the Self in shaping the future AI, rooted with a practical hierarchical Self framework, including Perception and Learning, Bodily Self, Autonomous Self, Social Self, and Conceptual Self. The hierarchical framework of the Self highlights self-based environment perception, self-bodily modeling, autonomous interaction with the environment, social interaction and collaboration with others, and even more abstract understanding of the Self. Furthermore, the positive mutual promotion and support among multiple levels of Self, as well as between Self and learning, enhance the BriSe AI's conscious understanding of information and flexible adaptation to complex environments, serving as a driving force propelling BriSe AI towards real Artificial General Intelligence.",
      "authors": [
        "Yi Zeng",
        "Feifei Zhao",
        "Yuxuan Zhao",
        "Dongcheng Zhao",
        "Enmeng Lu",
        "Qian Zhang",
        "Yuwei Wang",
        "Hui Feng",
        "Zhuoya Zhao",
        "Jihang Wang",
        "Qingqun Kong",
        "Yinqian Sun",
        "Yang Li",
        "Guobin Shen",
        "Bing Han",
        "Yiting Dong",
        "Wenxuan Pan",
        "Xiang He",
        "Aorigele Bao",
        "Jin Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Neurons and Cognition (q-bio.NC)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-29T01:15:17+00:00",
          "link": "https://arxiv.org/abs/2402.18784v1",
          "size": "4238kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T01:37:22+00:00",
          "link": "https://arxiv.org/abs/2402.18784v2",
          "size": "4216kb",
          "version": "v2"
        }
      ],
      "title": "Brain-inspired and Self-based Artificial Intelligence",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.18784",
        "HTML": "https://arxiv.org/html/2402.18784v2",
        "PDF": "https://arxiv.org/pdf/2402.18784"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2403.03508",
      "abstract": "When deploying time series forecasting models based on machine learning to real world settings, one often encounter situations where the data distribution drifts. Such drifts expose the forecasting models to out-of-distribution (OOD) data, and machine learning models lack robustness in these settings. Robustness can be improved by using deep generative models or genetic algorithms to augment time series datasets, but these approaches lack interpretability and are computationally expensive. In this work, we develop an interpretable and simple framework for generating time series. Our method combines time-series decompositions with analytic functions, and is able to generate time series with characteristics matching both in- and out-of-distribution data. This approach allows users to generate new time series in an interpretable fashion, which can be used to augment the dataset and improve forecasting robustness. We demonstrate our framework through EXPRTS, a visual analytics tool designed for univariate time series forecasting models and datasets. Different visualizations of the data distribution, forecasting errors and single time series instances enable users to explore time series datasets, apply transformations, and evaluate forecasting model robustness across diverse scenarios. We show how our framework can generate meaningful OOD time series that improve model robustness, and we validate EXPRTS effectiveness and usability through three use-cases and a user study.",
      "authors": [
        "H{\\aa}kon Hanisch Kj{\\ae}rnli",
        "Lluis Mas-Ribas",
        "Hans Jakob H{\\aa}land",
        "Vegard Sj{\\aa}vik",
        "Aida Ashrafi",
        "Helge Langseth and Odd Erik Gundersen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-06T07:34:47+00:00",
          "link": "https://arxiv.org/abs/2403.03508v1",
          "size": "1774kb",
          "version": "v1"
        },
        {
          "date": "2025-06-23T17:29:58+00:00",
          "link": "https://arxiv.org/abs/2403.03508v2",
          "size": "1822kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T20:55:29+00:00",
          "link": "https://arxiv.org/abs/2403.03508v3",
          "size": "1822kb",
          "version": "v3"
        }
      ],
      "title": "EXPRTS: Exploring and Probing the Robustness of Time Series Forecasting Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.03508",
        "HTML": "https://arxiv.org/html/2403.03508v3",
        "PDF": "https://arxiv.org/pdf/2403.03508"
      },
      "tasks": [
        "Time Series",
        "Time Series Forecasting"
      ],
      "repo_urls": [
        "https://github.com/lluism/counterfacts"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.04444",
      "abstract": "Recently, diffusion-based methods for monocular 3D human pose estimation have achieved state-of-the-art (SOTA) performance by directly regressing the 3D joint coordinates from the 2D pose sequence. Although some methods decompose the task into bone length and bone direction prediction based on the human anatomical skeleton to explicitly incorporate more human body prior constraints, the performance of these methods is significantly lower than that of the SOTA diffusion-based methods. This can be attributed to the tree structure of the human skeleton. Direct application of the disentangled method could amplify the accumulation of hierarchical errors, propagating through each hierarchy. Meanwhile, the hierarchical information has not been fully explored by the previous methods. To address these problems, a Disentangled Diffusion-based 3D Human Pose Estimation method with Hierarchical Spatial and Temporal Denoiser is proposed, termed DDHPose. In our approach: (1) We disentangle the 3D pose and diffuse the bone length and bone direction during the forward process of the diffusion model to effectively model the human pose prior. A disentanglement loss is proposed to supervise diffusion model learning. (2) For the reverse process, we propose Hierarchical Spatial and Temporal Denoiser (HSTDenoiser) to improve the hierarchical modeling of each joint. Our HSTDenoiser comprises two components: the Hierarchical-Related Spatial Transformer (HRST) and the Hierarchical-Related Temporal Transformer (HRTT). HRST exploits joint spatial information and the influence of the parent joint on each joint for spatial modeling, while HRTT utilizes information from both the joint and its hierarchical adjacent joints to explore the hierarchical temporal correlations among joints. Code and models are available at https://github.com/Andyen512/DDHPose",
      "authors": [
        "Qingyuan Cai",
        "Xuecai Hu",
        "Saihui Hou",
        "Li Yao",
        "Yongzhen Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-07T12:20:13+00:00",
          "link": "https://arxiv.org/abs/2403.04444v1",
          "size": "6012kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T06:40:41+00:00",
          "link": "https://arxiv.org/abs/2403.04444v2",
          "size": "5644kb",
          "version": "v2"
        }
      ],
      "title": "Disentangled Diffusion-Based 3D Human Pose Estimation with Hierarchical Spatial and Temporal Denoiser",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.04444",
        "HTML": "https://arxiv.org/html/2403.04444v2",
        "PDF": "https://arxiv.org/pdf/2403.04444"
      },
      "tasks": [
        "3D Human Pose Estimation",
        "Disentanglement",
        "Monocular 3D Human Pose Estimation",
        "Multi-Hypotheses 3D Human Pose Estimation",
        "Pose Estimation"
      ],
      "repo_urls": [
        "https://github.com/Andyen512/DDHPose"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.10798",
      "abstract": "Retrieval-augmented generation (RAG) with large language models (LLMs) plays a crucial role in question answering, as LLMs possess limited knowledge and are not updated with continuously growing information. Most recent work on RAG has focused primarily on text-based or large-image retrieval, which constrains the broader application of RAG models. We recognize that object-level retrieval is essential for addressing questions that extend beyond image content. To tackle this issue, we propose a task of object retrieval for visual question answering with outside knowledge (OR-OK-VQA), aimed to extend image-based content understanding in conjunction with LLMs. A key challenge in this task is retrieving diverse objects-related images that contribute to answering the questions. To enable accurate and robust general object retrieval, it is necessary to learn embeddings for local objects. This paper introduces a novel unsupervised deep feature embedding technique called multi-scale group collaborative embedding learning (MS-GCEL), developed to learn embeddings for long-tailed objects at different scales. Additionally, we establish an OK-VQA evaluation benchmark using images from the BelgaLogos, Visual Genome, and LVIS datasets. Prior to the OK-VQA evaluation, we construct a benchmark of challenges utilizing objects extracted from the COCO 2017 and VOC 2007 datasets to support the training and evaluation of general object retrieval models. Our evaluations on both general object retrieval and OK-VQA demonstrate the effectiveness of the proposed approach. The code and dataset will be publicly released for future research.",
      "authors": [
        "Shichao Kan",
        "Yuhai Deng",
        "Jiale Fu",
        "Lihui Cen",
        "Zhe Qu",
        "Linna Zhang",
        "Yixiong Liang and Yigang Cen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-16T04:01:50+00:00",
          "link": "https://arxiv.org/abs/2403.10798v1",
          "size": "5403kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T05:35:42+00:00",
          "link": "https://arxiv.org/abs/2403.10798v2",
          "size": "26040kb",
          "version": "v2"
        }
      ],
      "title": "Object Retrieval for Visual Question Answering with Outside Knowledge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.10798",
        "HTML": "https://arxiv.org/html/2403.10798v2",
        "PDF": "https://arxiv.org/pdf/2403.10798"
      },
      "tasks": [
        "Metric Learning",
        "Object",
        "Retrieval"
      ],
      "repo_urls": [
        "https://github.com/dengyuhai/ms-ugcml"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.11052",
      "abstract": "Recent advancements in text-to-image diffusion models have demonstrated their remarkable capability to generate high-quality images from textual prompts. However, increasing research indicates that these models memorize and replicate images from their training data, raising tremendous concerns about potential copyright infringement and privacy risks. In our study, we provide a novel perspective to understand this memorization phenomenon by examining its relationship with cross-attention mechanisms. We reveal that during memorization, the cross-attention tends to focus disproportionately on the embeddings of specific tokens. The diffusion model is overfitted to these token embeddings, memorizing corresponding training images. To elucidate this phenomenon, we further identify and discuss various intrinsic findings of cross-attention that contribute to memorization. Building on these insights, we introduce an innovative approach to detect and mitigate memorization in diffusion models. The advantage of our proposed method is that it will not compromise the speed of either the training or the inference processes in these models while preserving the quality of generated images. Our code is available at https://github.com/renjie3/MemAttn .",
      "authors": [
        "Jie Ren",
        "Yaxin Li",
        "Shenglai Zeng",
        "Han Xu",
        "Lingjuan Lyu",
        "Yue Xing",
        "Jiliang Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-17T01:27:00+00:00",
          "link": "https://arxiv.org/abs/2403.11052v1",
          "size": "29546kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T22:08:04+00:00",
          "link": "https://arxiv.org/abs/2403.11052v2",
          "size": "5328kb",
          "version": "v2"
        }
      ],
      "title": "Unveiling and Mitigating Memorization in Text-to-image Diffusion Models through Cross Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.11052",
        "HTML": "https://arxiv.org/html/2403.11052v2",
        "PDF": "https://arxiv.org/pdf/2403.11052"
      },
      "tasks": [
        "Memorization"
      ],
      "repo_urls": [
        "https://github.com/renjie3/memattn"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.17329",
      "abstract": "Deep learning has achieved tremendous success. However, unlike SVMs, which provide direct decision criteria and can be trained with a small dataset, it still has significant weaknesses due to its requirement for massive datasets during training and the black-box characteristics on decision criteria. This paper addresses these issues by identifying support vectors in deep learning models. To this end, we propose the DeepKKT condition, an adaptation of the traditional Karush-Kuhn-Tucker (KKT) condition for deep learning models, and confirm that generated Deep Support Vectors (DSVs) using this condition exhibit properties similar to traditional support vectors. This allows us to apply our method to few-shot dataset distillation problems and alleviate the black-box characteristics of deep learning models. Additionally, we demonstrate that the DeepKKT condition can transform conventional classification models into generative models with high fidelity, particularly as latent generative models using class labels as latent variables. We validate the effectiveness of DSVs using common datasets (ImageNet, CIFAR10 and CIFAR100) on the general architectures (ResNet and ConvNet), proving their practical applicability.",
      "authors": [
        "Junhoo Lee",
        "Hyunho Lee",
        "Kyomin Hwang",
        "Nojun Kwak"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-26T02:24:32+00:00",
          "link": "https://arxiv.org/abs/2403.17329v1",
          "size": "7652kb",
          "version": "v1"
        },
        {
          "date": "2024-06-27T06:19:01+00:00",
          "link": "https://arxiv.org/abs/2403.17329v2",
          "size": "42578kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T06:56:14+00:00",
          "link": "https://arxiv.org/abs/2403.17329v3",
          "size": "17701kb",
          "version": "v3"
        }
      ],
      "title": "Deep Support Vectors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.17329",
        "HTML": "https://arxiv.org/html/2403.17329v3",
        "PDF": "https://arxiv.org/pdf/2403.17329"
      },
      "tasks": [
        "Dataset Distillation",
        "Decision Making",
        "Deep Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.03446",
      "abstract": "Deep clustering, which learns representation and semantic clustering without labels information, poses a great challenge for deep learning-based approaches. Despite significant progress in recent years, most existing methods focus on uniformly distributed datasets, significantly limiting the practical applicability of their methods. In this paper, we propose a more practical problem setting named deep imbalanced clustering, where the underlying classes exhibit an imbalance distribution. To address this challenge, we introduce a novel optimal transport-based pseudo-label learning framework. Our framework formulates pseudo-label generation as a Semantic-regularized Progressive Partial Optimal Transport (SP$^2$OT) problem, which progressively transports each sample to imbalanced clusters under prior and semantic relation constraints, thus generating high-quality and imbalance-aware pseudo-labels. To solve the SP$^2$OT problem, we propose a projected mirror descent algorithm, which alternates between: (1) computing the gradient of the SP$^2$OT objective, and (2) performing gradient descent with projection via an entropy-regularized progressive partial optimal transport formulation. Furthermore, we formulate the second step as an unbalanced optimal transport problem with augmented constraints and develop an efficient solution based on fast matrix scaling algorithms. Experiments on various datasets, including a human-curated long-tailed CIFAR100, challenging ImageNet-R, and large-scale subsets of fine-grained iNaturalist2018 datasets, demonstrate the superiority of our method. Code is available: https://github.com/rhfeiyang/SPPOT",
      "authors": [
        "Chuyu Zhang",
        "Hui Ren",
        "Xuming He"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-04T13:46:52+00:00",
          "link": "https://arxiv.org/abs/2404.03446v1",
          "size": "6817kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T15:38:20+00:00",
          "link": "https://arxiv.org/abs/2404.03446v2",
          "size": "6095kb",
          "version": "v2"
        }
      ],
      "title": "SP$^2$OT: Semantic-Regularized Progressive Partial Optimal Transport for Imbalanced Clustering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.03446",
        "HTML": "https://arxiv.org/html/2404.03446v2",
        "PDF": "https://arxiv.org/pdf/2404.03446"
      },
      "tasks": [
        "Clustering",
        "Deep Clustering",
        "Pseudo Label"
      ],
      "repo_urls": [
        "https://github.com/rhfeiyang/SPPOT"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.08221",
      "abstract": "Generative AI is becoming increasingly prevalent in creative fields, sparking urgent debates over how current copyright laws can keep pace with technological innovation. Recent controversies of AI models generating near-replicas of copyrighted material highlight the need to adapt current legal frameworks and develop technical methods to mitigate copyright infringement risks. This task requires understanding the intersection between computational concepts such as large-scale data scraping and probabilistic content generation, legal definitions of originality and fair use, and economic impacts on IP rights holders. However, most existing research on copyright in AI takes a purely computer science or law-based approach, leaving a gap in coordinating these approaches that only multidisciplinary efforts can effectively address. To bridge this gap, our survey adopts a comprehensive approach synthesizing insights from law, policy, economics, and computer science. It begins by discussing the foundational goals and considerations that should be applied to copyright in generative AI, followed by methods for detecting and assessing potential violations in AI system outputs. Next, it explores various regulatory options influenced by legal, policy, and economic frameworks to manage and mitigate copyright concerns associated with generative AI and reconcile the interests of IP rights holders with that of generative AI producers. The discussion then introduces techniques to safeguard individual creative works from unauthorized replication, such as watermarking and cryptographic protections. Finally, it describes advanced training strategies designed to prevent AI models from reproducing protected content. In doing so, we highlight key opportunities for action and offer actionable strategies that creators, developers, and policymakers can use in navigating the evolving copyright landscape.",
      "authors": [
        "Archer Amon",
        "Zhipeng Yin",
        "Zichong Wang",
        "Avash Palikhe",
        "Wenbin Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-31T22:10:01+00:00",
          "link": "https://arxiv.org/abs/2404.08221v1",
          "size": "2355kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T19:41:33+00:00",
          "link": "https://arxiv.org/abs/2404.08221v2",
          "size": "1095kb",
          "version": "v2"
        }
      ],
      "title": "Uncertain Boundaries: Multidisciplinary Approaches to Copyright Issues in Generative AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.08221",
        "HTML": "https://arxiv.org/html/2404.08221v2",
        "PDF": "https://arxiv.org/pdf/2404.08221"
      },
      "tasks": [
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.09848",
      "abstract": "In a hyper-relational knowledge graph (HKG), each fact is composed of a main triple associated with attribute-value qualifiers, which express additional factual knowledge. The hyper-relational knowledge graph completion (HKGC) task aims at inferring plausible missing links in a HKG. Most existing approaches to HKGC focus on enhancing the communication between qualifier pairs and main triples, while overlooking two important properties that emerge from the monotonicity of the hyper-relational graphs representation regime. Stage Reasoning allows for a two-step reasoning process, facilitating the integration of coarse-grained inference results derived solely from main triples and fine-grained inference results obtained from hyper-relational facts with qualifiers. In the initial stage, coarse-grained results provide an upper bound for correct predictions, which are subsequently refined in the fine-grained step. More generally, Qualifier Monotonicity implies that by attaching more qualifier pairs to a main triple, we may only narrow down the answer set, but never enlarge it. This paper proposes the HyperMono model for hyper-relational knowledge graph completion, which realizes stage reasoning and qualifier monotonicity. To implement qualifier monotonicity HyperMono resorts to cone embeddings. Experiments on three real-world datasets with three different scenario conditions demonstrate the strong performance of HyperMono when compared to the SoTA.",
      "authors": [
        "Zhiwei Hu",
        "V\\'ictor Guti\\'errez-Basulto",
        "Zhiliang Xiang",
        "Ru Li",
        "Jeff Z. Pan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-15T15:00:17+00:00",
          "link": "https://arxiv.org/abs/2404.09848v1",
          "size": "2312kb",
          "version": "v1"
        },
        {
          "date": "2024-08-13T09:51:39+00:00",
          "link": "https://arxiv.org/abs/2404.09848v2",
          "size": "1506kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T12:50:35+00:00",
          "link": "https://arxiv.org/abs/2404.09848v3",
          "size": "607kb",
          "version": "v3"
        }
      ],
      "title": "HyperMono: A Monotonicity-aware Approach to Hyper-Relational Knowledge Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.09848",
        "HTML": "https://arxiv.org/html/2404.09848v3",
        "PDF": "https://arxiv.org/pdf/2404.09848"
      },
      "tasks": [
        "Attribute",
        "Knowledge Graph Completion"
      ],
      "repo_urls": [
        "https://github.com/jiyaowei/lp_nkgs"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.09992",
      "abstract": "Autonomous embodied agents live on an Internet of multimedia websites. Can they hop around multimodal websites to complete complex user tasks? Existing benchmarks fail to assess them in a realistic, evolving environment for their embodiment across websites. To answer this question, we present MMInA, a multihop and multimodal benchmark to evaluate the embodied agents for compositional Internet tasks, with several appealing properties: 1) Evolving real-world multimodal websites. Our benchmark uniquely operates on evolving real-world websites, ensuring a high degree of realism and applicability to natural user tasks. Our data includes 1,050 human-written tasks covering various domains such as shopping and travel, with each task requiring the agent to extract multimodal information from web pages as observations autonomously; 2) Multihop web browsing. Our dataset features naturally compositional tasks that require information from or actions on multiple websites to solve, to assess long-range reasoning capabilities on web tasks; 3) Holistic evaluation. We propose a novel protocol for evaluating an agent's progress in completing multihop tasks. We experiment with both standalone (multimodal) language models and heuristic-based web agents. Extensive experiments demonstrate that while long-chain multihop web tasks are easy for humans, they remain challenging for state-of-the-art web agents. We identify that agents are more likely to fail on the early hops when solving tasks with more hops, which results in lower task success rates. To address this issue, we propose a simple memory augmentation approach that replays past action trajectories to reflect. Our method significantly improves the performance of both the single-hop and multihop web browsing abilities. Our code and data are available at github.com/shulin16/MMInA.",
      "authors": [
        "Shulin Tian",
        "Ziniu Zhang",
        "Liangyu Chen",
        "Ziwei Liu"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-15T17:59:50+00:00",
          "link": "https://arxiv.org/abs/2404.09992v1",
          "size": "40360kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T05:24:54+00:00",
          "link": "https://arxiv.org/abs/2404.09992v2",
          "size": "40256kb",
          "version": "v2"
        }
      ],
      "title": "MMInA: Benchmarking Multihop Multimodal Internet Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.09992",
        "HTML": "https://arxiv.org/html/2404.09992v2",
        "PDF": "https://arxiv.org/pdf/2404.09992"
      },
      "datasets": [
        {
          "dataset_name": "shulin16/mmina",
          "downloads": "64",
          "likes": "2",
          "link": "https://huggingface.co/datasets/shulin16/mmina"
        }
      ],
      "tasks": [
        "Benchmarking"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.15421",
      "abstract": "A famous result due to Lov\\'{a}sz states that two finite relational structures $M$ and $N$ are isomorphic if, and only if, for all finite relational structures $T$, the number of homomorphisms from $T$ to $M$ is equal to the number of homomorphisms from $T$ to $N$. Since first-order logic (FOL) can describe finite structures up to isomorphism, this can be interpreted as a characterization of FOL-equivalence via homomorphism-count indistinguishability with respect to the class of finite structures. We identify classes of labeled transition systems (LTSs) such that homomorphism-count indistinguishability with respect to these classes, where \"counting\" is done within an appropriate semiring structure, captures equivalence with respect to positive-existential modal logic, graded modal logic, and hybrid logic, as well as the extensions of these logics with either backward or global modalities. Our positive results apply not only to finite structures, but also to certain well-behaved infinite structures. We also show that equivalence with respect to positive modal logic and equivalence with respect to the basic modal language are not captured by homomorphism-count indistinguishability with respect to any class of LTSs, regardless of which semiring is used for counting.",
      "authors": [
        "Jesse Comer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-23T18:11:38+00:00",
          "link": "https://arxiv.org/abs/2404.15421v1",
          "size": "52kb",
          "version": "v1"
        },
        {
          "date": "2024-06-23T00:14:02+00:00",
          "link": "https://arxiv.org/abs/2404.15421v2",
          "size": "545kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T15:15:58+00:00",
          "link": "https://arxiv.org/abs/2404.15421v3",
          "size": "50kb",
          "version": "v3"
        }
      ],
      "title": "Lov\\'asz Theorems for Modal Languages",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.15421",
        "PDF": "https://arxiv.org/pdf/2404.15421"
      },
      "source": "arXiv"
    },
    {
      "id": "2404.16078",
      "abstract": "Machines that can replicate human intelligence with type 2 reasoning capabilities should be able to reason at multiple levels of spatio-temporal abstractions and scales using internal world models. Devising formalisms to develop such internal world models, which accurately reflect the causal hierarchies inherent in the dynamics of the real world, is a critical research challenge in the domains of artificial intelligence and machine learning. This thesis identifies several limitations with the prevalent use of state space models (SSMs) as internal world models and propose two new probabilistic formalisms namely Hidden-Parameter SSMs and Multi-Time Scale SSMs to address these drawbacks. The structure of graphical models in both formalisms facilitates scalable exact probabilistic inference using belief propagation, as well as end-to-end learning via backpropagation through time. This approach permits the development of scalable, adaptive hierarchical world models capable of representing nonstationary dynamics across multiple temporal abstractions and scales. Moreover, these probabilistic formalisms integrate the concept of uncertainty in world states, thus improving the system's capacity to emulate the stochastic nature of the real world and quantify the confidence in its predictions. The thesis also discuss how these formalisms are in line with related neuroscience literature on Bayesian brain hypothesis and predicitive processing. Our experiments on various real and simulated robots demonstrate that our formalisms can match and in many cases exceed the performance of contemporary transformer variants in making long-range future predictions. We conclude the thesis by reflecting on the limitations of our current models and suggesting directions for future research.",
      "authors": [
        "Vaisakh Shaj"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-24T12:41:04+00:00",
          "link": "https://arxiv.org/abs/2404.16078v1",
          "size": "20074kb",
          "version": "v1"
        },
        {
          "date": "2024-04-26T09:54:28+00:00",
          "link": "https://arxiv.org/abs/2404.16078v2",
          "size": "20074kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T13:01:16+00:00",
          "link": "https://arxiv.org/abs/2404.16078v3",
          "size": "19993kb",
          "version": "v3"
        }
      ],
      "title": "Learning World Models With Hierarchical Temporal Abstractions: A Probabilistic Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.16078",
        "PDF": "https://arxiv.org/pdf/2404.16078"
      },
      "tasks": [
        "State Space Models"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.17750",
      "abstract": "This paper studies the shallow Ritz method for solving the one-dimensional diffusion problem. It is shown that the shallow Ritz method improves the order of approximation dramatically for non-smooth problems. To realize this optimal or nearly optimal order of the shallow Ritz approximation, we develop a damped block Newton (dBN) method that alternates between updates of the linear and non-linear parameters. Per each iteration, the linear and the non-linear parameters are updated by exact inversion and one step of a modified, damped Newton method applied to a reduced non-linear system, respectively. The computational cost of each dBN iteration is $O(n)$.\n  Starting with the non-linear parameters as a uniform partition of the interval, numerical experiments show that the dBN is capable of efficiently moving mesh points to nearly optimal locations. To improve efficiency of the dBN further, we propose an adaptive damped block Newton (AdBN) method by combining the dBN with the adaptive neuron enhancement (ANE) method [26].",
      "authors": [
        "Zhiqiang Cai",
        "Anastassia Doktorova",
        "Robert D. Falgout",
        "C\\'esar Herrera"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-27T01:39:50+00:00",
          "link": "https://arxiv.org/abs/2404.17750v1",
          "size": "625kb",
          "version": "v1"
        },
        {
          "date": "2025-01-23T17:08:53+00:00",
          "link": "https://arxiv.org/abs/2404.17750v2",
          "size": "1144kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T23:06:12+00:00",
          "link": "https://arxiv.org/abs/2404.17750v3",
          "size": "352kb",
          "version": "v3"
        }
      ],
      "title": "Efficient Shallow Ritz Method For 1D Diffusion Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.17750",
        "HTML": "https://arxiv.org/html/2404.17750v3",
        "PDF": "https://arxiv.org/pdf/2404.17750"
      },
      "source": "arXiv"
    },
    {
      "id": "2404.19015",
      "abstract": "Neural Radiance Fields (NeRF) show impressive performance in photo-realistic free-view rendering of scenes. Recent improvements on the NeRF such as TensoRF and ZipNeRF employ explicit models for faster optimization and rendering, as compared to the NeRF that employs an implicit representation. However, both implicit and explicit radiance fields require dense sampling of images in the given scene. Their performance degrades significantly when only a sparse set of views is available. Researchers find that supervising the depth estimated by a radiance field helps train it effectively with fewer views. The depth supervision is obtained either using classical approaches or neural networks pre-trained on a large dataset. While the former may provide only sparse supervision, the latter may suffer from generalization issues. As opposed to the earlier approaches, we seek to learn the depth supervision by designing augmented models and training them along with the main radiance field. Further, we aim to design a framework of regularizations that can work across different implicit and explicit radiance fields. We observe that certain features of these radiance field models overfit to the observed images in the sparse-input scenario. Our key finding is that reducing the capability of the radiance fields with respect to positional encoding, the number of decomposed tensor components or the size of the hash table, constrains the model to learn simpler solutions, which estimate better depth in certain regions. By designing augmented models based on such reduced capabilities, we obtain better depth supervision for the main radiance field. We achieve state-of-the-art view-synthesis performance with sparse input views on popular datasets containing forward-facing and 360$^\\circ$ scenes by employing the above regularizations.",
      "authors": [
        "Nagabhushan Somraj",
        "Sai Harsha Mupparaju",
        "Adithyan Karanayil",
        "Rajiv Soundararajan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-29T18:00:25+00:00",
          "link": "https://arxiv.org/abs/2404.19015v1",
          "size": "16065kb",
          "version": "v1"
        },
        {
          "date": "2024-05-23T08:04:54+00:00",
          "link": "https://arxiv.org/abs/2404.19015v2",
          "size": "16065kb",
          "version": "v2"
        },
        {
          "date": "2024-05-27T10:02:05+00:00",
          "link": "https://arxiv.org/abs/2404.19015v3",
          "size": "16065kb",
          "version": "v3"
        },
        {
          "date": "2025-06-28T03:13:33+00:00",
          "link": "https://arxiv.org/abs/2404.19015v4",
          "size": "21077kb",
          "version": "v4"
        }
      ],
      "title": "Simple-RF: Regularizing Sparse Input Radiance Fields with Simpler Solutions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.19015",
        "HTML": "https://arxiv.org/html/2404.19015v4",
        "PDF": "https://arxiv.org/pdf/2404.19015"
      },
      "tasks": [
        "NeRF"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.19543",
      "abstract": "Large Language Models (LLMs) have catalyzed significant advancements in Natural Language Processing (NLP), yet they encounter challenges such as hallucination and the need for domain-specific knowledge. To mitigate these, recent methodologies have integrated information retrieved from external resources with LLMs, substantially enhancing their performance across NLP tasks. This survey paper addresses the absence of a comprehensive overview on Retrieval-Augmented Language Models (RALMs), both Retrieval-Augmented Generation (RAG) and Retrieval-Augmented Understanding (RAU), providing an in-depth examination of their paradigm, evolution, taxonomy, and applications. The paper discusses the essential components of RALMs, including Retrievers, Language Models, and Augmentations, and how their interactions lead to diverse model structures and applications. RALMs demonstrate utility in a spectrum of tasks, from translation and dialogue systems to knowledge-intensive applications. The survey includes several evaluation methods of RALMs, emphasizing the importance of robustness, accuracy, and relevance in their assessment. It also acknowledges the limitations of RALMs, particularly in retrieval quality and computational efficiency, offering directions for future research. In conclusion, this survey aims to offer a structured insight into RALMs, their potential, and the avenues for their future development in NLP. The paper is supplemented with a Github Repository containing the surveyed works and resources for further study: https://github.com/2471023025/RALM_Survey.",
      "authors": [
        "Yucheng Hu",
        "Yuxing Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-30T13:14:51+00:00",
          "link": "https://arxiv.org/abs/2404.19543v1",
          "size": "7015kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T14:57:19+00:00",
          "link": "https://arxiv.org/abs/2404.19543v2",
          "size": "7019kb",
          "version": "v2"
        }
      ],
      "title": "RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.19543",
        "HTML": "https://arxiv.org/html/2404.19543v2",
        "PDF": "https://arxiv.org/pdf/2404.19543"
      },
      "tasks": [
        "Computational Efficiency",
        "Hallucination",
        "Language Modeling",
        "Language Modelling",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation",
        "Survey"
      ],
      "repo_urls": [
        "https://github.com/2471023025/ralm_survey",
        "https://github.com/MS-P3/code6/tree/main/rag"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.01299",
      "abstract": "Large Language Models (LLMs) have emerged as powerful support tools across various natural language tasks and a range of application domains. Recent studies focus on exploring their capabilities for data annotation. This paper provides a comparative overview of twelve studies investigating the potential of LLMs in labelling data. While the models demonstrate promising cost and time-saving benefits, there exist considerable limitations, such as representativeness, bias, sensitivity to prompt variations and English language preference. Leveraging insights from these studies, our empirical analysis further examines the alignment between human and GPT-generated opinion distributions across four subjective datasets. In contrast to the studies examining representation, our methodology directly obtains the opinion distribution from GPT. Our analysis thereby supports the minority of studies that are considering diverse perspectives when evaluating data annotation tasks and highlights the need for further research in this direction.",
      "authors": [
        "Maja Pavlovic",
        "Massimo Poesio"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-02T14:00:22+00:00",
          "link": "https://arxiv.org/abs/2405.01299v1",
          "size": "665kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T09:07:37+00:00",
          "link": "https://arxiv.org/abs/2405.01299v2",
          "size": "425kb",
          "version": "v2"
        }
      ],
      "title": "The Effectiveness of LLMs as Annotators: A Comparative Overview and Empirical Analysis of Direct Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.01299",
        "HTML": "https://arxiv.org/html/2405.01299v2",
        "PDF": "https://arxiv.org/pdf/2405.01299"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2405.02377",
      "abstract": "In the vibrant landscape of AI research, decentralised learning is gaining momentum. Decentralised learning allows individual nodes to keep data locally where they are generated and to share knowledge extracted from local data among themselves through an interactive process of collaborative refinement. This paradigm supports scenarios where data cannot leave local nodes due to privacy or sovereignty reasons or real-time constraints imposing proximity of models to locations where inference has to be carried out. The distributed nature of decentralised learning implies significant new research challenges with respect to centralised learning. Among them, in this paper, we focus on robustness issues. Specifically, we study the effect of nodes' disruption on the collective learning process. Assuming a given percentage of \"central\" nodes disappear from the network, we focus on different cases, characterised by (i) different distributions of data across nodes and (ii) different times when disruption occurs with respect to the start of the collaborative learning task. Through these configurations, we are able to show the non-trivial interplay between the properties of the network connecting nodes, the persistence of knowledge acquired collectively before disruption or lack thereof, and the effect of data availability pre- and post-disruption. Our results show that decentralised learning processes are remarkably robust to network disruption. As long as even minimum amounts of data remain available somewhere in the network, the learning process is able to recover from disruptions and achieve significant classification accuracy. This clearly varies depending on the remaining connectivity after disruption, but we show that even nodes that remain completely isolated can retain significant knowledge acquired before the disruption.",
      "authors": [
        "Luigi Palmieri",
        "Chiara Boldrini",
        "Lorenzo Valerio",
        "Andrea Passarella",
        "Marco Conti",
        "J\\'anos Kert\\'esz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-03T12:14:48+00:00",
          "link": "https://arxiv.org/abs/2405.02377v1",
          "size": "11171kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T13:27:03+00:00",
          "link": "https://arxiv.org/abs/2405.02377v2",
          "size": "5781kb",
          "version": "v2"
        }
      ],
      "title": "Robustness of Decentralised Learning to Nodes and Data Disruption",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.02377",
        "HTML": "https://arxiv.org/html/2405.02377v2",
        "PDF": "https://arxiv.org/pdf/2405.02377"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2405.05118",
      "abstract": "We formally introduce a systematic (de/re)-composition approach, based on the algebraic formalism of \"Multi-Dimensional Homomorphisms (MDHs)\". Our approach is designed as general enough to be applicable to a wide range of data-parallel computations and for various kinds of target parallel architectures. To efficiently target the deep and complex memory and core hierarchies of contemporary architectures, we exploit our introduced (de/re)-composition approach for a correct-by-construction, parametrized cache blocking and parallelization strategy. We show that our approach is powerful enough to express, in the same formalism, the (de/re)-composition strategies of different classes of state-of-the-art approaches (scheduling-based, polyhedral, etc), and we demonstrate that the parameters of our strategies enable systematically generating code that can be fully automatically optimized (auto-tuned) for the particular target architecture and characteristics of the input and output data (e.g., their sizes and memory layouts). Particularly, our experiments confirm that via auto-tuning, we achieve higher performance than state-of-the-art approaches, including hand-optimized solutions provided by vendors (such as NVIDIA cuBLAS/cuDNN and Intel oneMKL/oneDNN), on real-world data sets and for a variety of data-parallel computations, including: linear algebra routines, stencil and quantum chemistry computations, data mining algorithms, and computations that recently gained high attention due to their relevance for deep learning.",
      "authors": [
        "Ari Rasch"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-08T15:16:02+00:00",
          "link": "https://arxiv.org/abs/2405.05118v1",
          "size": "25305kb",
          "version": "v1"
        },
        {
          "date": "2024-05-24T12:56:30+00:00",
          "link": "https://arxiv.org/abs/2405.05118v2",
          "size": "25306kb",
          "version": "v2"
        },
        {
          "date": "2024-10-23T10:39:15+00:00",
          "link": "https://arxiv.org/abs/2405.05118v3",
          "size": "25306kb",
          "version": "v3"
        },
        {
          "date": "2025-06-30T16:23:35+00:00",
          "link": "https://arxiv.org/abs/2405.05118v4",
          "size": "25243kb",
          "version": "v4"
        }
      ],
      "title": "Full Version: (De/Re)-Composition of Data-Parallel Computations via Multi-Dimensional Homomorphisms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.05118",
        "HTML": "https://arxiv.org/html/2405.05118v4",
        "PDF": "https://arxiv.org/pdf/2405.05118"
      },
      "source": "arXiv"
    },
    {
      "id": "2405.12293",
      "abstract": "This work studies fundamental limits for recovering the underlying correspondence among multiple correlated graphs. In the setting of inhomogeneous random graphs, we present and analyze a matching algorithm: first partially match the graphs pairwise and then combine the partial matchings by transitivity. Our analysis yields a sufficient condition on the problem parameters to exactly match all nodes across all the graphs. In the setting of homogeneous (Erd\\H{o}s-R\\'enyi) graphs, we show that this condition is also necessary, i.e. the algorithm works down to the information theoretic threshold. This reveals a scenario where exact matching between two graphs alone is impossible, but leveraging more than two graphs allows exact matching among all the graphs. Converse results are also given in the inhomogeneous setting and transitivity again plays a role. Along the way, we derive independent results about the k-core of inhomogeneous random graphs.",
      "authors": [
        "Taha Ameen",
        "Bruce Hajek"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Discrete Mathematics (cs.DM)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-20T18:01:11+00:00",
          "link": "https://arxiv.org/abs/2405.12293v1",
          "size": "17029kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T21:18:24+00:00",
          "link": "https://arxiv.org/abs/2405.12293v2",
          "size": "1410kb",
          "version": "v2"
        }
      ],
      "title": "Aligning Multiple Inhomogeneous Random Graphs: Fundamental Limits of Exact Recovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.12293",
        "HTML": "https://arxiv.org/html/2405.12293v2",
        "PDF": "https://arxiv.org/pdf/2405.12293"
      },
      "source": "arXiv"
    },
    {
      "id": "2405.13152",
      "abstract": "A thorough understanding of the interaction between the target agent and surrounding agents is a prerequisite for accurate trajectory prediction. Although many methods have been explored, they assign correlation coefficients to surrounding agents in a purely learning-based manner. In this study, we present ASPILin, which manually selects interacting agents and replaces the attention scores in Transformer with a newly computed physical correlation coefficient, enhancing the interpretability of interaction modeling. Surprisingly, these simple modifications can significantly improve prediction performance and substantially reduce computational costs. We intentionally simplified our model in other aspects, such as map encoding. Remarkably, experiments conducted on the INTERACTION, highD, and CitySim datasets demonstrate that our method is efficient and straightforward, outperforming other state-of-the-art methods.",
      "authors": [
        "Shiji Huang",
        "Lei Ye",
        "Min Chen",
        "Wenhai Luo",
        "Dihong Wang",
        "Chenqi Xu",
        "Deyuan Liang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-21T18:45:18+00:00",
          "link": "https://arxiv.org/abs/2405.13152v1",
          "size": "646kb",
          "version": "v1"
        },
        {
          "date": "2024-10-11T19:40:39+00:00",
          "link": "https://arxiv.org/abs/2405.13152v2",
          "size": "1193kb",
          "version": "v2"
        },
        {
          "date": "2024-10-23T12:56:05+00:00",
          "link": "https://arxiv.org/abs/2405.13152v3",
          "size": "1190kb",
          "version": "v3"
        },
        {
          "date": "2025-03-04T13:07:09+00:00",
          "link": "https://arxiv.org/abs/2405.13152v4",
          "size": "1480kb",
          "version": "v4"
        },
        {
          "date": "2025-06-28T15:40:13+00:00",
          "link": "https://arxiv.org/abs/2405.13152v5",
          "size": "3566kb",
          "version": "v5"
        }
      ],
      "title": "Interpretable Interaction Modeling for Trajectory Prediction via Agent Selection and Physical Coefficient",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.13152",
        "HTML": "https://arxiv.org/html/2405.13152v5",
        "PDF": "https://arxiv.org/pdf/2405.13152"
      },
      "tasks": [
        "Autonomous Driving",
        "Trajectory Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.13535",
      "abstract": "In recent years, inconsistency in Bayesian deep learning has attracted significant attention. Tempered or generalized posterior distributions are frequently employed as direct and effective solutions. Nonetheless, the underlying mechanisms and the effectiveness of generalized posteriors remain active research topics. In this work, we interpret posterior tempering as a correction for model misspecification via adjustments to the joint probability, and as a recalibration of priors by reducing aleatoric uncertainty. We also identify a unique property of the Laplace approximation: the generalized normalizing constant remains invariant, in contrast to general Bayesian learning, where this constant typically depends on model parameters after generalization. Leveraging this property, we introduce the generalized Laplace approximation, which requires only a simple modification to the Hessian calculation of the regularized loss. This approach provides a flexible and scalable framework for high-quality posterior inference. We evaluate the proposed method on state-of-the-art neural networks and real-world datasets, demonstrating that the generalized Laplace approximation enhances predictive performance.",
      "authors": [
        "Yinsong Chen",
        "Samson S. Yu",
        "Zhong Li",
        "Chee Peng Lim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-22T11:11:42+00:00",
          "link": "https://arxiv.org/abs/2405.13535v1",
          "size": "1737kb",
          "version": "v1"
        },
        {
          "date": "2024-05-24T06:31:55+00:00",
          "link": "https://arxiv.org/abs/2405.13535v2",
          "size": "1738kb",
          "version": "v2"
        },
        {
          "date": "2024-10-10T04:41:33+00:00",
          "link": "https://arxiv.org/abs/2405.13535v3",
          "size": "0kb",
          "version": "v3"
        },
        {
          "date": "2025-06-30T12:20:59+00:00",
          "link": "https://arxiv.org/abs/2405.13535v4",
          "size": "1650kb",
          "version": "v4"
        }
      ],
      "title": "Addressing the Inconsistency in Bayesian Deep Learning via Generalized Laplace Approximation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.13535",
        "HTML": "https://arxiv.org/html/2405.13535v4",
        "PDF": "https://arxiv.org/pdf/2405.13535"
      },
      "tasks": [
        "Attribute"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.13692",
      "abstract": "Transformer-based neural networks, empowered by Self-Supervised Learning (SSL), have demonstrated unprecedented performance across various domains. However, related literature suggests that tabular Transformers may struggle to outperform classical Machine Learning algorithms, such as Gradient Boosted Decision Trees (GBDT). In this paper, we aim to challenge GBDTs with tabular Transformers on a typical task faced in e-commerce, namely fraud detection. Our study is additionally motivated by the problem of selection bias, often occurring in real-life fraud detection systems. It is caused by the production system affecting which subset of traffic becomes labeled. This issue is typically addressed by sampling randomly a small part of the whole production data, referred to as a Control Group. This subset follows a target distribution of production data and therefore is usually preferred for training classification models with standard ML algorithms. Our methodology leverages the capabilities of Transformers to learn transferable representations using all available data by means of SSL, giving it an advantage over classical methods. Furthermore, we conduct large-scale experiments, pre-training tabular Transformers on vast amounts of data instances and fine-tuning them on smaller target datasets. The proposed approach outperforms heavily tuned GBDTs by a considerable margin of the Average Precision (AP) score in offline evaluations. Finally, we report the results of an online A/B experiment. Experimental results confirm the superiority of tabular Transformers compared to GBDTs in production, demonstrated by a statistically significant improvement in our business metric.",
      "authors": [
        "Sergei Krutikov (1)",
        "Bulat Khaertdinov (2)",
        "Rodion Kiriukhin (1)",
        "Shubham Agrawal (1)",
        "Mozhdeh Ariannezhad (1)",
        "Kees Jan De Vries (1) ((1) Booking.com",
        "(2) Maastricht University)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-22T14:38:48+00:00",
          "link": "https://arxiv.org/abs/2405.13692v1",
          "size": "1934kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T08:01:46+00:00",
          "link": "https://arxiv.org/abs/2405.13692v2",
          "size": "134kb",
          "version": "v2"
        }
      ],
      "title": "Challenging Gradient Boosted Decision Trees with Tabular Transformers for Fraud Detection at Booking.com",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.13692",
        "HTML": "https://arxiv.org/html/2405.13692v2",
        "PDF": "https://arxiv.org/pdf/2405.13692"
      },
      "tasks": [
        "Fraud Detection",
        "Selection bias",
        "Self-Supervised Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.14715",
      "abstract": "Modern retrieval systems often struggle with upgrading to new and more powerful models due to the incompatibility of embeddings between the old and new models. This necessitates a costly process known as backfilling, which involves re-computing the embeddings for a large number of data samples. In vision, Backward-compatible Training (BT) has been proposed to ensure that the new model aligns with the old model's embeddings. This paper extends the concept of vision-only BT to the field of cross-modal retrieval, marking the first attempt to address Cross-modal BT (XBT). Our goal is to achieve backward-compatibility between Vision-Language Pretraining (VLP) models, such as CLIP, for the cross-modal retrieval task. To address XBT challenges, we propose an efficient solution: a projection module that maps the new model's embeddings to those of the old model. This module, pretrained solely with text data, significantly reduces the number of image-text pairs required for XBT learning, and, once it is pretrained, it avoids using the old model during training. Furthermore, we utilize parameter-efficient training strategies that improve efficiency and preserve the off-the-shelf new model's knowledge by avoiding any modifications. Experimental results on cross-modal retrieval datasets demonstrate the effectiveness of XBT and its potential to enable backfill-free upgrades when a new VLP model emerges.",
      "authors": [
        "Young Kyun Jang",
        "Ser-nam Lim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-23T15:46:35+00:00",
          "link": "https://arxiv.org/abs/2405.14715v1",
          "size": "2960kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T23:48:38+00:00",
          "link": "https://arxiv.org/abs/2405.14715v2",
          "size": "2913kb",
          "version": "v2"
        }
      ],
      "title": "Towards Cross-modal Backward-compatible Representation Learning for Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.14715",
        "HTML": "https://arxiv.org/html/2405.14715v2",
        "PDF": "https://arxiv.org/pdf/2405.14715"
      },
      "tasks": [
        "Cross-Modal Retrieval",
        "Representation Learning",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.15328",
      "abstract": "User data spread across multiple modalities has popularized multi-modal recommender systems (MMRS). They recommend diverse content such as products, social media posts, TikTok reels, etc., based on a user-item interaction graph. With rising data privacy demands, recent methods propose unlearning private user data from uni-modal recommender systems (RS). However, methods for unlearning item data related to outdated user preferences, revoked licenses, and legally requested removals are still largely unexplored.\n  Previous RS unlearning methods are unsuitable for MMRS due to the incompatibility of their matrix-based representation with the multi-modal user-item interaction graph. Moreover, their data partitioning step degrades performance on each shard due to poor data heterogeneity and requires costly performance aggregation across shards.\n  This paper introduces MMRecUn, the first approach known to us for unlearning in MMRS and unlearning item data. Given a trained RS model, MMRecUn employs a novel Reverse Bayesian Personalized Ranking (BPR) objective to enable the model to forget marked data. The reverse BPR attenuates the impact of user-item interactions within the forget set, while the forward BPR reinforces the significance of user-item interactions within the retain set. Our experiments demonstrate that MMRecUn outperforms baseline methods across various unlearning requests when evaluated on benchmark MMRS datasets. MMRecUn achieves recall performance improvements of up to 49.85% compared to baseline methods and is up to 1.3x faster than the Gold model, which is trained on retain set from scratch. MMRecUn offers significant advantages, including superiority in removing target interactions, preserving retained interactions, and zero overhead costs compared to previous methods.\n  Code: https://github.com/MachineUnlearn/MMRecUN\n  Extended version: arXiv:2405.15328",
      "authors": [
        "Yash Sinha",
        "Murari Mandal",
        "Mohan Kankanhalli"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-24T08:11:59+00:00",
          "link": "https://arxiv.org/abs/2405.15328v1",
          "size": "1436kb",
          "version": "v1"
        },
        {
          "date": "2024-12-17T05:35:15+00:00",
          "link": "https://arxiv.org/abs/2405.15328v2",
          "size": "1483kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T04:33:18+00:00",
          "link": "https://arxiv.org/abs/2405.15328v3",
          "size": "1557kb",
          "version": "v3"
        }
      ],
      "title": "Multi-Modal Recommendation Unlearning for Legal, Licensing, and Modality Constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.15328",
        "HTML": "https://arxiv.org/html/2405.15328v3",
        "PDF": "https://arxiv.org/pdf/2405.15328"
      },
      "tasks": [
        "Multi-modal Recommendation",
        "Recommendation Systems"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.16258",
      "abstract": "Unsupervised fault detection in multivariate time series plays a vital role in ensuring the stable operation of complex systems. Traditional methods often assume that normal data follow a single Gaussian distribution and identify anomalies as deviations from this distribution. {\\color{black} However, this simplified assumption fails to capture the diversity and structural complexity of real-world time series, which can lead to misjudgments and reduced detection performance in practical applications. To address this issue, we propose a new method that combines a neighborhood-driven data augmentation strategy with a multi-manifold representation learning framework.} By incorporating information from local neighborhoods, the augmentation module can simulate contextual variations of normal data, enhancing the model's adaptability to distributional changes. In addition, we design a structure-aware feature learning approach that encourages natural clustering of similar patterns in the feature space while maintaining sufficient distinction between different operational states. Extensive experiments on several public benchmark datasets demonstrate that our method achieves superior performance in terms of both accuracy and robustness, showing strong potential for generalization and real-world deployment.",
      "authors": [
        "Hong Liu",
        "Xiuxiu Qiu",
        "Yiming Shi",
        "Miao Xu",
        "Zelin Zang",
        "Zhen Lei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-25T14:48:04+00:00",
          "link": "https://arxiv.org/abs/2405.16258v1",
          "size": "2429kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T14:17:13+00:00",
          "link": "https://arxiv.org/abs/2405.16258v2",
          "size": "8872kb",
          "version": "v2"
        }
      ],
      "title": "Deep Multi-Manifold Transformation Based Multivariate Time Series Fault Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.16258",
        "HTML": "https://arxiv.org/html/2405.16258v2",
        "PDF": "https://arxiv.org/pdf/2405.16258"
      },
      "tasks": [
        "Contrastive Learning",
        "Data Augmentation",
        "Diversity",
        "Fault Detection",
        "Time Series"
      ],
      "repo_urls": [
        "https://github.com/zangzelin/code_usd"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.17451",
      "abstract": "Integrating Artificial Intelligence (AI) into software systems has significantly enhanced their capabilities while escalating energy demands. Ensemble learning, combining predictions from multiple models to form a single prediction, intensifies this problem due to cumulative energy consumption. This paper presents a novel approach to model selection that addresses the challenge of balancing the accuracy of AI models with their energy consumption in a live AI ensemble system. We explore how reducing the number of models or improving the efficiency of model usage within an ensemble during inference can reduce energy demands without substantially sacrificing accuracy. This study introduces and evaluates two model selection strategies, Static and Dynamic, for optimizing ensemble learning systems performance while minimizing energy usage. Our results demonstrate that the Static strategy improves the F1 score beyond the baseline, reducing average energy usage from 100% from the full ensemble to 62%. The Dynamic strategy further enhances F1 scores, using on average 76% compared to 100% of the full ensemble. Moreover, we propose an approach that balances accuracy with resource consumption, significantly reducing energy usage without substantially impacting accuracy. This method decreased the average energy usage of the Static strategy from approximately 62% to 14%, and for the Dynamic strategy, from around 76% to 57%. Our field study of Green AI using an operational AI system developed by a large professional services provider shows the practical applicability of adopting energy-conscious model selection strategies in live production environments.",
      "authors": [
        "Nienke Nijkamp and June Sallou and Niels van der Heijden and Lu\\'is Cruz"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-21T18:57:43+00:00",
          "link": "https://arxiv.org/abs/2405.17451v1",
          "size": "13191kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T14:17:09+00:00",
          "link": "https://arxiv.org/abs/2405.17451v2",
          "size": "2170kb",
          "version": "v2"
        }
      ],
      "title": "Green AI in Action: Strategic Model Selection for Ensembles in Production",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.17451",
        "HTML": "https://arxiv.org/html/2405.17451v2",
        "PDF": "https://arxiv.org/pdf/2405.17451"
      },
      "tasks": [
        "Ensemble Learning",
        "Model Selection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.19202",
      "abstract": "Traffic incidents involving vulnerable road users (VRUs) constitute a significant proportion of global road accidents. Advances in traffic communication ecosystems, coupled with sophisticated signal processing and machine learning techniques, have facilitated the utilization of data from diverse sensors. Despite these advancements and the availability of extensive datasets, substantial progress is required to mitigate traffic casualties. This paper provides a comprehensive survey of state-of-the-art technologies and methodologies to enhance the safety of VRUs. The study investigates the communication networks between vehicles and VRUs, emphasizing the integration of advanced sensors and the availability of relevant datasets. It explores preprocessing techniques and data fusion methods to enhance sensor data quality. Furthermore, our study assesses critical simulation environments essential for developing and testing VRU safety systems. Our research also highlights recent advances in VRU detection and classification algorithms, addressing challenges such as variable environmental conditions. Additionally, we cover cutting-edge research in predicting VRU intentions and behaviors, which is mandatory for proactive collision avoidance strategies. Through this survey, we aim to provide a comprehensive understanding of the current landscape of VRU safety technologies, identifying areas of progress and areas needing further research and development.",
      "authors": [
        "Renato M. Silva",
        "Gregorio F. Azevedo",
        "Matheus V. V. Berto",
        "Jean R. Rocha",
        "Eduardo C. Fidelis",
        "Matheus V. Nogueira",
        "Pedro H. Lisboa",
        "Tiago A. Almeida"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-29T15:42:10+00:00",
          "link": "https://arxiv.org/abs/2405.19202v1",
          "size": "3523kb",
          "version": "v1"
        },
        {
          "date": "2024-06-07T14:26:41+00:00",
          "link": "https://arxiv.org/abs/2405.19202v2",
          "size": "3509kb",
          "version": "v2"
        },
        {
          "date": "2024-06-14T13:28:43+00:00",
          "link": "https://arxiv.org/abs/2405.19202v3",
          "size": "3918kb",
          "version": "v3"
        },
        {
          "date": "2024-11-05T19:24:50+00:00",
          "link": "https://arxiv.org/abs/2405.19202v4",
          "size": "3034kb",
          "version": "v4"
        },
        {
          "date": "2025-06-27T21:39:35+00:00",
          "link": "https://arxiv.org/abs/2405.19202v5",
          "size": "3138kb",
          "version": "v5"
        }
      ],
      "title": "Vulnerable Road User Detection and Safety Enhancement: A Comprehensive Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.19202",
        "PDF": "https://arxiv.org/pdf/2405.19202"
      },
      "tasks": [
        "Collision Avoidance",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.04875",
      "abstract": "3D cars are commonly used in self-driving systems, virtual/augmented reality, and games. However, existing 3D car datasets are either synthetic or low-quality, limiting their applications in practical scenarios and presenting a significant gap toward high-quality real-world 3D car datasets. In this paper, we propose the first large-scale 3D real car dataset, termed 3DRealCar, offering three distinctive features. (1) \\textbf{High-Volume}: 2,500 cars are meticulously scanned by smartphones, obtaining car images and point clouds with real-world dimensions; (2) \\textbf{High-Quality}: Each car is captured in an average of 200 dense, high-resolution 360-degree RGB-D views, enabling high-fidelity 3D reconstruction; (3) \\textbf{High-Diversity}: The dataset contains various cars from over 100 brands, collected under three distinct lighting conditions, including reflective, standard, and dark. Additionally, we offer detailed car parsing maps for each instance to promote research in car parsing tasks. Moreover, we remove background point clouds and standardize the car orientation to a unified axis for the reconstruction only on cars and controllable rendering without background. We benchmark 3D reconstruction results with state-of-the-art methods across different lighting conditions in 3DRealCar. Extensive experiments demonstrate that the standard lighting condition part of 3DRealCar can be used to produce a large number of high-quality 3D cars, improving various 2D and 3D tasks related to cars. Notably, our dataset brings insight into the fact that recent 3D reconstruction methods face challenges in reconstructing high-quality 3D cars under reflective and dark lighting conditions. \\textcolor{red}{\\href{https://xiaobiaodu.github.io/3drealcar/}{Our dataset is here.}}",
      "authors": [
        "Xiaobiao Du",
        "Yida Wang",
        "Haiyang Sun",
        "Zhuojie Wu",
        "Hongwei Sheng",
        "Shuyun Wang",
        "Jiaying Ying",
        "Ming Lu",
        "Tianqing Zhu",
        "Kun Zhan",
        "Xin Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-07T12:14:27+00:00",
          "link": "https://arxiv.org/abs/2406.04875v1",
          "size": "9413kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T04:33:43+00:00",
          "link": "https://arxiv.org/abs/2406.04875v2",
          "size": "8915kb",
          "version": "v2"
        }
      ],
      "title": "3DRealCar: An In-the-wild RGB-D Car Dataset with 360-degree Views",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.04875",
        "HTML": "https://arxiv.org/html/2406.04875v2",
        "PDF": "https://arxiv.org/pdf/2406.04875"
      },
      "tasks": [
        "3D Reconstruction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.09843",
      "abstract": "Large Language Models (LLMs) have recently been used to generate mutants in both research work and in industrial practice. However, there has been no comprehensive empirical study of their performance for this increasingly important LLM-based Software Engineering application. To address this, we report the results of a comprehensive empirical study over six different LLMs, including both state-of-the-art open- and closed-source models, on 851 real bugs drawn from two different Java real-world bug benchmarks. Our results reveal that, compared to existing rule-based approaches, LLMs generate more diverse mutants, that are behaviorally closer to real bugs and, most importantly, with 90.1% higher fault detection. That is, 79.1% (for LLMs) vs. 41.6% (for rule-based); an increase of 37.5 percentage points. Nevertheless, our results also reveal that these impressive results for improved effectiveness come at a cost: the LLM-generated mutants have worse non-compilability, duplication, and equivalent mutant rates by 36.1, 13.1, and 4.2 percentage points, respectively. These findings are immediately actionable for both research and practice. They allow practitioners to have greater confidence in deploying LLM-based mutation, while researchers now have a baseline for the state-of-the-art, with which they can research techniques to further improve effectiveness and reduce cost.",
      "authors": [
        "Bo Wang",
        "Mingda Chen",
        "Youfang Lin",
        "Mark Harman",
        "Mike Papadakis and Jie M. Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-14T08:49:41+00:00",
          "link": "https://arxiv.org/abs/2406.09843v1",
          "size": "1651kb",
          "version": "v1"
        },
        {
          "date": "2024-09-14T12:56:09+00:00",
          "link": "https://arxiv.org/abs/2406.09843v2",
          "size": "2553kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T07:07:17+00:00",
          "link": "https://arxiv.org/abs/2406.09843v3",
          "size": "1752kb",
          "version": "v3"
        }
      ],
      "title": "A Comprehensive Study on Large Language Models for Mutation Testing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.09843",
        "HTML": "https://arxiv.org/html/2406.09843v3",
        "PDF": "https://arxiv.org/pdf/2406.09843"
      },
      "source": "arXiv"
    },
    {
      "id": "2406.10197",
      "abstract": "Image composition and generation are processes where the artists need control over various parts of the generated images. However, the current state-of-the-art generation models, like Stable Diffusion, cannot handle fine-grained part-level attributes in the text prompts. Specifically, when additional attribute details are added to the base text prompt, these text-to-image models either generate an image vastly different from the image generated from the base prompt or ignore the attribute details. To mitigate these issues, we introduce PartComposer, a training-free method that enables image generation based on fine-grained part-level attributes specified for objects in the base text prompt. This allows more control for artists and enables novel object compositions by combining distinctive object parts. PartComposer first localizes object parts by denoising the object region from a specific diffusion process. This enables each part token to be localized to the right region. After obtaining part masks, we run a localized diffusion process in each part region based on fine-grained part attributes and combine them to produce the final image. All stages of PartComposer are based on repurposing a pre-trained diffusion model, which enables it to generalize across domains. We demonstrate the effectiveness of part-level control provided by PartComposer through qualitative visual examples and quantitative comparisons with contemporary baselines.",
      "authors": [
        "Harsh Rangwani",
        "Aishwarya Agarwal",
        "Kuldeep Kulkarni",
        "R. Venkatesh Babu",
        "and Srikrishna Karanam"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-14T17:31:29+00:00",
          "link": "https://arxiv.org/abs/2406.10197v1",
          "size": "4053kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T17:42:12+00:00",
          "link": "https://arxiv.org/abs/2406.10197v2",
          "size": "7070kb",
          "version": "v2"
        }
      ],
      "title": "Composing Parts for Expressive Object Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.10197",
        "HTML": "https://arxiv.org/html/2406.10197v2",
        "PDF": "https://arxiv.org/pdf/2406.10197"
      },
      "tasks": [
        "Denoising",
        "Image Generation",
        "Object",
        "Text to Image Generation",
        "Text-to-Image Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.12574",
      "abstract": "Distributed systems can be subject to various kinds of partial failures, therefore building fault-tolerance or failure mitigation mechanisms for distributed systems remains an important domain of research. In this paper, we present a calculus to formally model distributed systems subject to crash failures with recovery. The recovery model considered in the paper is weak, in the sense that it makes no assumption on the exact state in which a failed node resumes its execution, only its identity has to be distinguishable from past incarnations of itself. Our calculus is inspired in part by the Erlang programming language and in part by the distributed $\\pi$-calculus with nodes and link failures (D$\\pi$F) introduced by Francalanza and Hennessy. In order to reason about distributed systems with failures and recovery we develop a behavioral theory for our calculus, in the form of a contextual equivalence, and of a fully abstract coinductive characterization of this equivalence by means of a labelled transition system semantics and its associated weak bisimilarity. This result is valuable for it provides a compositional proof technique for proving or disproving contextual equivalence between systems.",
      "authors": [
        "Giovanni Fabbretti",
        "Ivan Lanese",
        "Jean-Bernard Stefani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-18T13:02:39+00:00",
          "link": "https://arxiv.org/abs/2406.12574v1",
          "size": "90kb",
          "version": "v1"
        },
        {
          "date": "2024-06-19T12:28:55+00:00",
          "link": "https://arxiv.org/abs/2406.12574v2",
          "size": "90kb",
          "version": "v2"
        },
        {
          "date": "2024-12-24T09:52:33+00:00",
          "link": "https://arxiv.org/abs/2406.12574v3",
          "size": "88kb",
          "version": "v3"
        },
        {
          "date": "2025-05-26T18:06:30+00:00",
          "link": "https://arxiv.org/abs/2406.12574v4",
          "size": "89kb",
          "version": "v4"
        },
        {
          "date": "2025-06-28T08:49:41+00:00",
          "link": "https://arxiv.org/abs/2406.12574v5",
          "size": "90kb",
          "version": "v5"
        }
      ],
      "title": "A Behavioral Theory for Distributed Systems with Weak Recovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.12574",
        "PDF": "https://arxiv.org/pdf/2406.12574"
      },
      "source": "arXiv"
    },
    {
      "id": "2406.12593",
      "abstract": "Differentiable Search Index (DSI) utilizes pre-trained language models to perform indexing and document retrieval via end-to-end learning without relying on external indexes. However, DSI requires full re-training to index new documents, causing significant computational inefficiencies. Continual learning (CL) offers a solution by enabling the model to incrementally update without full re-training. Existing CL solutions in document retrieval rely on memory buffers or generative models for rehearsal, which is infeasible when accessing previous training data is restricted due to privacy concerns. To this end, we introduce PromptDSI, a prompt-based, rehearsal-free continual learning approach for document retrieval. PromptDSI follows the Prompt-based Continual Learning (PCL) framework, using learnable prompts to efficiently index new documents without accessing previous documents or queries. To improve retrieval latency, we remove the initial forward pass of PCL, which otherwise greatly increases training and inference time, with a negligible trade-off in performance. Additionally, we introduce a novel topic-aware prompt pool that employs neural topic embeddings as fixed keys, eliminating the instability of prompt key optimization while maintaining competitive performance with existing PCL prompt pools. In a challenging rehearsal-free continual learning setup, we demonstrate that PromptDSI variants outperform rehearsal-based baselines, match the strong cache-based baseline in mitigating forgetting, and significantly improving retrieval performance on new corpora.",
      "authors": [
        "Tuan-Luc Huynh",
        "Thuy-Trang Vu",
        "Weiqing Wang",
        "Yinwei Wei",
        "Trung Le",
        "Dragan Gasevic",
        "Yuan-Fang Li",
        "Thanh-Toan Do"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-18T13:25:18+00:00",
          "link": "https://arxiv.org/abs/2406.12593v1",
          "size": "748kb",
          "version": "v1"
        },
        {
          "date": "2024-10-16T13:45:54+00:00",
          "link": "https://arxiv.org/abs/2406.12593v2",
          "size": "664kb",
          "version": "v2"
        },
        {
          "date": "2025-06-20T12:59:40+00:00",
          "link": "https://arxiv.org/abs/2406.12593v3",
          "size": "457kb",
          "version": "v3"
        },
        {
          "date": "2025-06-28T06:24:44+00:00",
          "link": "https://arxiv.org/abs/2406.12593v4",
          "size": "457kb",
          "version": "v4"
        }
      ],
      "title": "PromptDSI: Prompt-based Rehearsal-free Continual Learning for Document Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.12593",
        "HTML": "https://arxiv.org/html/2406.12593v4",
        "PDF": "https://arxiv.org/pdf/2406.12593"
      },
      "tasks": [
        "Continual Learning",
        "Incremental Learning",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.15303",
      "abstract": "Multiple Instance Learning (MIL) effectively analyzes whole slide images but faces overfitting due to attention over-concentration. While existing solutions rely on complex architectural modifications or additional processing steps, we introduce Attention Entropy Maximization (AEM), a simple yet effective regularization technique. Our investigation reveals the positive correlation between attention entropy and model performance. Building on this insight, we integrate AEM regularization into the MIL framework to penalize excessive attention concentration. To address sensitivity to the AEM weight parameter, we implement Cosine Weight Annealing, reducing parameter dependency. Extensive evaluations demonstrate AEM's superior performance across diverse feature extractors, MIL frameworks, attention mechanisms, and augmentation techniques. Here is our anonymous code: https://github.com/dazhangyu123/AEM.",
      "authors": [
        "Yunlong Zhang and Honglin Li and Yunxuan Sun and Zhongyi Shui and Jingxiong Li and Chenglu Zhu and Lin Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-18T02:01:17+00:00",
          "link": "https://arxiv.org/abs/2406.15303v1",
          "size": "74607kb",
          "version": "v1"
        },
        {
          "date": "2024-08-18T02:48:32+00:00",
          "link": "https://arxiv.org/abs/2406.15303v2",
          "size": "23485kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T07:58:08+00:00",
          "link": "https://arxiv.org/abs/2406.15303v3",
          "size": "174kb",
          "version": "v3"
        }
      ],
      "title": "AEM: Attention Entropy Maximization for Multiple Instance Learning based Whole Slide Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.15303",
        "HTML": "https://arxiv.org/html/2406.15303v3",
        "PDF": "https://arxiv.org/pdf/2406.15303"
      },
      "datasets": [
        {
          "dataset_name": "dazhangyu123/AEM-dataset",
          "downloads": "30",
          "likes": "0",
          "link": "https://huggingface.co/datasets/dazhangyu123/AEM-dataset"
        }
      ],
      "tasks": [
        "Diversity",
        "image-classification",
        "Image Classification",
        "Multiple Instance Learning",
        "whole slide images"
      ],
      "repo_urls": [
        "https://github.com/dazhangyu123/acmil",
        "https://github.com/dazhangyu123/adr",
        "https://github.com/dazhangyu123/aem"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.15627",
      "abstract": "The rapid proliferation of large language models (LLMs) has stimulated researchers to seek effective and efficient approaches to deal with LLM hallucinations and low-quality outputs. Uncertainty quantification (UQ) is a key element of machine learning applications in dealing with such challenges. However, research to date on UQ for LLMs has been fragmented in terms of techniques and evaluation methodologies. In this work, we address this issue by introducing a novel benchmark that implements a collection of state-of-the-art UQ baselines and offers an environment for controllable and consistent evaluation of novel UQ techniques over various text generation tasks. Our benchmark also supports the assessment of confidence normalization methods in terms of their ability to provide interpretable scores. Using our benchmark, we conduct a large-scale empirical investigation of UQ and normalization techniques across eleven tasks, identifying the most effective approaches. Code: https://github.com/IINemo/lm-polygraph Benchmark: https://huggingface.co/LM-Polygraph",
      "authors": [
        "Roman Vashurin",
        "Ekaterina Fadeeva",
        "Artem Vazhentsev",
        "Lyudmila Rvanova",
        "Akim Tsvigun",
        "Daniil Vasilev",
        "Rui Xing",
        "Abdelrahman Boda Sadallah",
        "Kirill Grishchenkov",
        "Sergey Petrakov",
        "Alexander Panchenko",
        "Timothy Baldwin",
        "Preslav Nakov",
        "Maxim Panov",
        "Artem Shelmanov"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-21T20:06:31+00:00",
          "link": "https://arxiv.org/abs/2406.15627v1",
          "size": "3352kb",
          "version": "v1"
        },
        {
          "date": "2024-10-29T20:45:58+00:00",
          "link": "https://arxiv.org/abs/2406.15627v2",
          "size": "3858kb",
          "version": "v2"
        },
        {
          "date": "2025-01-10T10:24:19+00:00",
          "link": "https://arxiv.org/abs/2406.15627v3",
          "size": "3876kb",
          "version": "v3"
        },
        {
          "date": "2025-06-30T12:15:07+00:00",
          "link": "https://arxiv.org/abs/2406.15627v4",
          "size": "195kb",
          "version": "v4"
        }
      ],
      "title": "Benchmarking Uncertainty Quantification Methods for Large Language Models with LM-Polygraph",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.15627",
        "PDF": "https://arxiv.org/pdf/2406.15627"
      },
      "tasks": [
        "Benchmarking",
        "Text Generation",
        "Uncertainty Quantification"
      ],
      "repo_urls": [
        "https://github.com/iinemo/lm-polygraph",
        "https://github.com/jinhaoduan/sar",
        "https://github.com/jinhaoduan/shifting-attention-to-relevance"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.01461",
      "abstract": "The capacity of large language models (LLMs) to generate honest, harmless, and helpful responses heavily relies on the quality of user prompts. However, these prompts often tend to be brief and vague, thereby significantly limiting the full potential of LLMs. Moreover, harmful prompts can be meticulously crafted and manipulated by adversaries to jailbreak LLMs, inducing them to produce potentially toxic content. To enhance the capabilities of LLMs while maintaining strong robustness against harmful jailbreak inputs, this study proposes a transferable and pluggable framework that refines user prompts before they are input into LLMs. This strategy improves the quality of the queries, empowering LLMs to generate more truthful, benign and useful responses. Specifically, a lightweight query refinement model is introduced and trained using a specially designed reinforcement learning approach that incorporates multiple objectives to enhance particular capabilities of LLMs. Extensive experiments demonstrate that the refinement model not only improves the quality of responses but also strengthens their robustness against jailbreak attacks. Code is available at: https://github.com/Huangzisu/query-refinement .",
      "authors": [
        "Xiaohua Wang",
        "Zisu Huang",
        "Feiran Zhang",
        "Zhibo Xu",
        "Cenyuan Zhang",
        "Qi Qian",
        "Xiaoqing Zheng",
        "Xuanjing Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-01T16:55:28+00:00",
          "link": "https://arxiv.org/abs/2407.01461v1",
          "size": "668kb",
          "version": "v1"
        },
        {
          "date": "2025-02-18T06:06:14+00:00",
          "link": "https://arxiv.org/abs/2407.01461v2",
          "size": "634kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T07:39:54+00:00",
          "link": "https://arxiv.org/abs/2407.01461v3",
          "size": "634kb",
          "version": "v3"
        }
      ],
      "title": "Enhancing the Capability and Robustness of Large Language Models through Reinforcement Learning-Driven Query Refinement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.01461",
        "HTML": "https://arxiv.org/html/2407.01461v3",
        "PDF": "https://arxiv.org/pdf/2407.01461"
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/huangzisu/query-refinement"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.01496",
      "abstract": "This paper studies the shallow Ritz method for solving one-dimensional diffusion-reaction problems. The method is capable of improving the order of approximation for non-smooth problems. By following a similar approach to the one presented in [9], we present a damped block Newton (dBN) method to achieve nearly optimal order of approximation. The dBN method optimizes the Ritz functional by alternating between the linear and non-linear parameters of the shallow ReLU neural network (NN). For diffusion-reaction problems, new difficulties arise: (1) for the linear parameters, the mass matrix is dense and even more ill-conditioned than the stiffness matrix, and (2) for the non-linear parameters, the Hessian matrix is dense and may be singular. This paper addresses these challenges, resulting in a dBN method with computational cost of ${\\cal O}(n)$.\n  The ideas presented for diffusion-reaction problems can also be applied to least-squares approximation problems. For both applications, starting with the non-linear parameters as a uniform partition, numerical experiments show that the dBN method moves the mesh points to nearly optimal locations.",
      "authors": [
        "Zhiqiang Cai",
        "Anastassia Doktorova",
        "Robert D. Falgout",
        "C\\'esar Herrera"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Machine Learning (cs.LG)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-01T17:42:29+00:00",
          "link": "https://arxiv.org/abs/2407.01496v1",
          "size": "8047kb",
          "version": "v1"
        },
        {
          "date": "2025-05-16T19:08:48+00:00",
          "link": "https://arxiv.org/abs/2407.01496v2",
          "size": "8496kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T16:22:47+00:00",
          "link": "https://arxiv.org/abs/2407.01496v3",
          "size": "637kb",
          "version": "v3"
        }
      ],
      "title": "Efficient Shallow Ritz Method For 1D Diffusion-Reaction Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.01496",
        "HTML": "https://arxiv.org/html/2407.01496v3",
        "PDF": "https://arxiv.org/pdf/2407.01496"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2407.01570",
      "abstract": "Despite the significant advancements in Deep Reinforcement Learning (RL) observed in the last decade, the amount of training experience necessary to learn effective policies remains one of the primary concerns both in simulated and real environments. Looking to solve this issue, previous work has shown that improved training efficiency can be achieved by separately modeling agent and environment, but usually requiring a supervisory agent mask.\n  In contrast to RL, humans can perfect a new skill from a small number of trials and in most cases do so without a supervisory signal, making neuroscientific studies of human development a valuable source of inspiration for RL. In particular, we explore the idea of motor prediction, which states that humans develop an internal model of themselves and of the consequences that their motor commands have on the immediate sensory inputs. Our insight is that the movement of the agent provides a cue that allows the duality between agent and environment to be learned.\n  To instantiate this idea, we present Ego-Foresight, a self-supervised method for disentangling agent and environment based on motion and prediction. Our main finding is self-supervised agent-awareness by visuomotor prediction of the agent improves sample-efficiency and performance of the underlying RL algorithm.\n  To test our approach, we first study its ability to visually predict agent movement irrespective of the environment, in simulated and real-world robotic data. Then, we integrate Ego-Foresight with a model-free RL algorithm to solve simulated robotic tasks, showing that self-supervised agent-awareness can improve sample-efficiency and performance in RL.",
      "authors": [
        "Manuel Serra Nunes and Atabak Dehban and Yiannis Demiris and Jos\\'e Santos-Victor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-27T13:32:43+00:00",
          "link": "https://arxiv.org/abs/2407.01570v1",
          "size": "19624kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T15:16:44+00:00",
          "link": "https://arxiv.org/abs/2407.01570v2",
          "size": "42930kb",
          "version": "v2"
        }
      ],
      "title": "Ego-Foresight: Self-supervised Learning of Agent-Aware Representations for Improved RL",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.01570",
        "HTML": "https://arxiv.org/html/2407.01570v2",
        "PDF": "https://arxiv.org/pdf/2407.01570"
      },
      "source": "arXiv"
    },
    {
      "id": "2407.02856",
      "abstract": "This study investigates the efficacy of machine learning models in network security threat detection through the critical lens of partial versus complete flow information, addressing a common gap between research settings and real-time operational needs. We systematically evaluate how a standard benchmark model, Random Forest, performs under varying training and testing conditions (complete/complete, partial/partial, complete/partial), quantifying the performance impact when dealing with the incomplete data typical in real-time environments. Our findings demonstrate a significant performance difference, with precision and recall dropping by up to 30% under certain conditions when models trained on complete flows are tested against partial flows. The study also reveals that, for the evaluated dataset and model, a minimum threshold around 7 packets in the test set appears necessary for maintaining reliable detection rates, providing valuable, quantified insights for developing more realistic real-time detection strategies.",
      "authors": [
        "Adrian Pekar and Richard Jozsa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-03T07:14:25+00:00",
          "link": "https://arxiv.org/abs/2407.02856v1",
          "size": "525kb",
          "version": "v1"
        },
        {
          "date": "2025-02-19T15:25:31+00:00",
          "link": "https://arxiv.org/abs/2407.02856v2",
          "size": "586kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T13:16:32+00:00",
          "link": "https://arxiv.org/abs/2407.02856v3",
          "size": "580kb",
          "version": "v3"
        }
      ],
      "title": "Early-Stage Anomaly Detection: A Study of Model Performance on Complete vs. Partial Flows",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.02856",
        "HTML": "https://arxiv.org/html/2407.02856v3",
        "PDF": "https://arxiv.org/pdf/2407.02856"
      },
      "tasks": [
        "Anomaly Detection"
      ],
      "repo_urls": [
        "https://github.com/flowfrontiers/cyberml-completevsfirstn"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.03146",
      "abstract": "Data augmentation is widely applied and has shown its benefits in different machine learning tasks. However, as recently observed, it may have an unfair effect in multi-class classification. While data augmentation generally improves the overall performance (and therefore is beneficial for many classes), it can actually be detrimental for other classes, which can be problematic in some application domains. In this paper, to counteract this phenomenon, we propose CLAM, a CLAss-dependent Multiplicative-weights method. To derive it, we first formulate the training of a classifier as a non-linear optimization problem that aims at simultaneously maximizing the individual class performances and balancing them. By rewriting this optimization problem as an adversarial two-player game, we propose a novel multiplicative weight algorithm, for which we prove the convergence. Interestingly, our formulation also reveals that the class-dependent effects of data augmentation is not due to data augmentation only, but is in fact a general phenomenon. Our empirical results over six datasets demonstrate that the performance of learned classifiers is indeed more fairly distributed over classes, with only limited impact on the average accuracy.",
      "authors": [
        "Yunpeng Jiang and Yutong Ban and Paul Weng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computer Science and Game Theory (cs.GT)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-31T02:56:43+00:00",
          "link": "https://arxiv.org/abs/2407.03146v1",
          "size": "2617kb",
          "version": "v1"
        },
        {
          "date": "2024-07-08T05:21:59+00:00",
          "link": "https://arxiv.org/abs/2407.03146v2",
          "size": "2617kb",
          "version": "v2"
        },
        {
          "date": "2025-03-25T09:05:02+00:00",
          "link": "https://arxiv.org/abs/2407.03146v3",
          "size": "2648kb",
          "version": "v3"
        },
        {
          "date": "2025-06-20T02:36:15+00:00",
          "link": "https://arxiv.org/abs/2407.03146v4",
          "size": "3859kb",
          "version": "v4"
        },
        {
          "date": "2025-06-30T03:47:49+00:00",
          "link": "https://arxiv.org/abs/2407.03146v5",
          "size": "3859kb",
          "version": "v5"
        }
      ],
      "title": "Understanding and Reducing the Class-Dependent Effects of Data Augmentation with A Two-Player Game Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.03146",
        "HTML": "https://arxiv.org/html/2407.03146v5",
        "PDF": "https://arxiv.org/pdf/2407.03146"
      },
      "tasks": [
        "Data Augmentation",
        "Fairness",
        "Multi-class Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.06109",
      "abstract": "Controllable generation is considered a potentially vital approach to address the challenge of annotating 3D data, and the precision of such controllable generation becomes particularly imperative in the context of data production for autonomous driving. Existing methods focus on the integration of diverse generative information into controlling inputs, utilizing frameworks such as GLIGEN or ControlNet, to produce commendable outcomes in controllable generation. However, such approaches intrinsically restrict generation performance to the learning capacities of predefined network architectures. In this paper, we explore the innovative integration of controlling information and introduce PerLDiff (\\textbf{Per}spective-\\textbf{L}ayout \\textbf{Diff}usion Models), a novel method for effective street view image generation that fully leverages perspective 3D geometric information. Our PerLDiff employs 3D geometric priors to guide the generation of street view images with precise object-level control within the network learning process, resulting in a more robust and controllable output. Moreover, it demonstrates superior controllability compared to alternative layout control methods. Empirical results justify that our PerLDiff markedly enhances the precision of controllable generation on the NuScenes and KITTI datasets.",
      "authors": [
        "Jinhua Zhang",
        "Hualian Sheng",
        "Sijia Cai",
        "Bing Deng",
        "Qiao Liang",
        "Wen Li",
        "Ying Fu",
        "Jieping Ye",
        "Shuhang Gu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-08T16:46:47+00:00",
          "link": "https://arxiv.org/abs/2407.06109v1",
          "size": "47354kb",
          "version": "v1"
        },
        {
          "date": "2024-07-16T14:05:17+00:00",
          "link": "https://arxiv.org/abs/2407.06109v2",
          "size": "47463kb",
          "version": "v2"
        },
        {
          "date": "2024-12-03T03:11:21+00:00",
          "link": "https://arxiv.org/abs/2407.06109v3",
          "size": "45359kb",
          "version": "v3"
        },
        {
          "date": "2025-06-30T12:12:38+00:00",
          "link": "https://arxiv.org/abs/2407.06109v4",
          "size": "30298kb",
          "version": "v4"
        }
      ],
      "title": "PerLDiff: Controllable Street View Synthesis Using Perspective-Layout Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.06109",
        "HTML": "https://arxiv.org/html/2407.06109v4",
        "PDF": "https://arxiv.org/pdf/2407.06109"
      },
      "tasks": [
        "Autonomous Driving",
        "Image Generation"
      ],
      "repo_urls": [
        "https://github.com/labshuhanggu/perldiff"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.06639",
      "abstract": "Non-invasive estimation of Li-ion battery state-of-health from operational data is valuable for battery applications, but remains challenging. Pure model-based methods may suffer from inaccuracy and long-term instability of parameter estimates, whereas pure data-driven methods rely heavily on training data quality and quantity, causing lack of generality when extrapolating to unseen cases. We apply an aging-aware equivalent circuit model for health estimation, combining the flexibility of data-driven techniques within a model-based approach. A simplified electrical model with voltage source and resistor incorporates Gaussian process regression to learn capacity fade over time and also the dependence of resistance on operating conditions and time. The approach was validated against two datasets and shown to give accurate performance with less than 1% relative root mean square error (RMSE) in capacity and less than 2% mean absolute percentage error (MAPE). Critically, we show that the open circuit voltage versus state-of-charge function must be accurately known, and any inaccuracies or changes in this over time strongly influence the inferred resistance. However, this feature (or bug) may also be used to estimate in operando differential voltage curves from operational data.",
      "authors": [
        "Zihao Zhou",
        "Antti Aitio",
        "David Howey"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-09T08:07:39+00:00",
          "link": "https://arxiv.org/abs/2407.06639v1",
          "size": "927kb",
          "version": "v1"
        },
        {
          "date": "2024-07-10T01:45:08+00:00",
          "link": "https://arxiv.org/abs/2407.06639v2",
          "size": "927kb",
          "version": "v2"
        },
        {
          "date": "2024-07-14T03:24:18+00:00",
          "link": "https://arxiv.org/abs/2407.06639v3",
          "size": "894kb",
          "version": "v3"
        },
        {
          "date": "2025-03-06T14:54:01+00:00",
          "link": "https://arxiv.org/abs/2407.06639v4",
          "size": "877kb",
          "version": "v4"
        },
        {
          "date": "2025-06-30T15:35:03+00:00",
          "link": "https://arxiv.org/abs/2407.06639v5",
          "size": "1027kb",
          "version": "v5"
        }
      ],
      "title": "Learning Li-ion battery health and degradation modes from data with aging-aware circuit models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.06639",
        "HTML": "https://arxiv.org/html/2407.06639v5",
        "PDF": "https://arxiv.org/pdf/2407.06639"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2407.06674",
      "abstract": "This manuscript addresses the problem of approximating an unknown function from point evaluations. When obtaining these point evaluations is costly, minimising the required sample size becomes crucial, and it is unreasonable to reserve a sufficiently large test sample for estimating the approximation accuracy. Therefore, an approximation with a certified quasi-optimality factor is required. This article shows that such an approximation can be obtained when the sought function lies in a reproducing kernel Hilbert space (RKHS) and is to be approximated in a finite-dimensional linear subspace. However, selecting the sample points to minimise the quasi-optimality factor requires optimising over an infinite set of points and computing exact inner products in RKHS, which is often infeasible in practice. Extending results from optimal sampling for $L^2$ approximation, the present manuscript proves that random points, drawn independently from the Christoffel sampling distribution associated with $\\mathcal{V}_d$, can yield a controllable quasi-optimality factor with high probability. Inspired by this result, a novel sampling scheme, coined subspace-informed volume sampling, is introduced and evaluated in numerical experiments, where it outperforms classical i.i.d. Christoffel sampling and continuous volume sampling. To reduce the size of such a random sample, an additional greedy subsampling scheme with provable suboptimality bounds is introduced. Our presentation is of independent interest to the community researching the parametrised background data weak (PBDW) method, as it offers a simpler interpretation of the method.",
      "authors": [
        "Philipp Trunschke",
        "Anthony Nouy"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-09T08:48:34+00:00",
          "link": "https://arxiv.org/abs/2407.06674v1",
          "size": "1664kb",
          "version": "v1"
        },
        {
          "date": "2024-10-07T18:40:55+00:00",
          "link": "https://arxiv.org/abs/2407.06674v2",
          "size": "1663kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T12:32:34+00:00",
          "link": "https://arxiv.org/abs/2407.06674v3",
          "size": "964kb",
          "version": "v3"
        }
      ],
      "title": "Sample-based almost-sure quasi-optimal approximation in reproducing kernel Hilbert spaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.06674",
        "PDF": "https://arxiv.org/pdf/2407.06674"
      },
      "source": "arXiv"
    },
    {
      "id": "2407.08906",
      "abstract": "Illustration is a fundamental mode of human expression and communication. Certain types of motion that accompany speech can provide this illustrative mode of communication. While Augmented and Virtual Reality technologies (AR/VR) have introduced tools for producing drawings with hand motions (air drawing), they typically require costly hardware and additional digital markers, thereby limiting their accessibility and portability. Furthermore, air drawing demands considerable skill to achieve aesthetic results. To address these challenges, we introduce the concept of AirSketch, aimed at generating faithful and visually coherent sketches directly from hand motions, eliminating the need for complicated headsets or markers. We devise a simple augmentation-based self-supervised training procedure, enabling a controllable image diffusion model to learn to translate from highly noisy hand tracking images to clean, aesthetically pleasing sketches, while preserving the essential visual cues from the original tracking data. We present two air drawing datasets to study this problem. Our findings demonstrate that beyond producing photo-realistic images from precise spatial inputs, controllable image diffusion can effectively produce a refined, clear sketch from a noisy input. Our work serves as an initial step towards marker-less air drawing and reveals distinct applications of controllable diffusion models to AirSketch and AR/VR in general.",
      "authors": [
        "Hui Xian Grace Lim",
        "Xuanming Cui",
        "Yogesh S Rawat",
        "Ser-Nam Lim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Graphics (cs.GR)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-12T00:52:04+00:00",
          "link": "https://arxiv.org/abs/2407.08906v1",
          "size": "40268kb",
          "version": "v1"
        },
        {
          "date": "2024-11-10T21:07:59+00:00",
          "link": "https://arxiv.org/abs/2407.08906v2",
          "size": "48239kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T17:16:06+00:00",
          "link": "https://arxiv.org/abs/2407.08906v3",
          "size": "43802kb",
          "version": "v3"
        }
      ],
      "title": "AirSketch: Generative Motion to Sketch",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.08906",
        "HTML": "https://arxiv.org/html/2407.08906v3",
        "PDF": "https://arxiv.org/pdf/2407.08906"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2407.09972",
      "abstract": "Federated learning (FL) allows participants to collaboratively train machine learning models while keeping their data local, making it ideal for collaborations among healthcare institutions on sensitive data. However, in this paper, we propose a novel privacy attack called MedLeak, which allows a malicious FL server to recover high-quality site-specific private medical data from the client model updates. MedLeak works by introducing an adversarially crafted model during the FL training process. Honest clients, unaware of the insidious changes in the published models, continue to send back their updates as per the standard FL protocol. Leveraging a novel analytical method, MedLeak can efficiently recover private client data from the aggregated parameter updates, eliminating costly optimization. In addition, the scheme relies solely on the aggregated updates, thus rendering secure aggregation protocols ineffective, as they depend on the randomization of intermediate results for security while leaving the final aggregated results unaltered.\n  We implement MedLeak on medical image datasets (MedMNIST, COVIDx CXR-4, and Kaggle Brain Tumor MRI), as well as a medical text dataset (MedAbstract). The results demonstrate that our attack achieves high recovery rates and strong quantitative scores on both image and text datasets. We also thoroughly evaluate MedLeak across different attack parameters, providing insights into key factors that influence attack performance and potential defenses. Furthermore, we demonstrate that the recovered data can support downstream tasks such as disease classification with minimal performance loss. Our findings validate the need for enhanced privacy measures in FL systems, particularly for safeguarding sensitive medical data against powerful model inversion attacks.",
      "authors": [
        "Shanghao Shi",
        "Md Shahedul Haque",
        "Abhijeet Parida",
        "Chaoyu Zhang",
        "Marius George Linguraru",
        "Y.Thomas Hou",
        "Syed Muhammad Anwar",
        "and Wenjing Lou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Cryptography and Security (cs.CR)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-13T18:31:35+00:00",
          "link": "https://arxiv.org/abs/2407.09972v1",
          "size": "3043kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T15:48:58+00:00",
          "link": "https://arxiv.org/abs/2407.09972v2",
          "size": "3894kb",
          "version": "v2"
        }
      ],
      "title": "MedLeak: Multimodal Medical Data Leakage in Secure Federated Learning with Crafted Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.09972",
        "HTML": "https://arxiv.org/html/2407.09972v2",
        "PDF": "https://arxiv.org/pdf/2407.09972"
      },
      "tasks": [
        "Federated Learning",
        "Privacy Preserving"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.10490",
      "abstract": "Learning dynamics, which describes how the learning of specific training examples influences the model's predictions on other examples, gives us a powerful tool for understanding the behavior of deep learning systems. We study the learning dynamics of large language models during different types of finetuning, by analyzing the step-wise decomposition of how influence accumulates among different potential responses. Our framework allows a uniform interpretation of many interesting observations about the training of popular algorithms for both instruction tuning and preference tuning. In particular, we propose a hypothetical explanation of why specific types of hallucination are strengthened after finetuning, e.g., the model might use phrases or facts in the response for question B to answer question A, or the model might keep repeating similar simple phrases when generating responses. We also extend our framework and highlight a unique \"squeezing effect\" to explain a previously observed phenomenon in off-policy direct preference optimization (DPO), where running DPO for too long makes even the desired outputs less likely. This framework also provides insights into where the benefits of on-policy DPO and other variants come from. The analysis not only provides a novel perspective of understanding LLM's finetuning but also inspires a simple, effective method to improve alignment performance.",
      "authors": [
        "Yi Ren",
        "Danica J. Sutherland"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-15T07:30:28+00:00",
          "link": "https://arxiv.org/abs/2407.10490v1",
          "size": "4295kb",
          "version": "v1"
        },
        {
          "date": "2024-10-02T16:47:30+00:00",
          "link": "https://arxiv.org/abs/2407.10490v2",
          "size": "3999kb",
          "version": "v2"
        },
        {
          "date": "2025-02-20T01:09:57+00:00",
          "link": "https://arxiv.org/abs/2407.10490v3",
          "size": "5727kb",
          "version": "v3"
        },
        {
          "date": "2025-06-29T05:43:22+00:00",
          "link": "https://arxiv.org/abs/2407.10490v4",
          "size": "5883kb",
          "version": "v4"
        }
      ],
      "title": "Learning Dynamics of LLM Finetuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.10490",
        "PDF": "https://arxiv.org/pdf/2407.10490"
      },
      "tasks": [
        "Hallucination"
      ],
      "repo_urls": [
        "https://github.com/joshua-ren/learning_dynamics_llm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.12749",
      "abstract": "Hardware design workflows rely on Process Design Kits (PDKs) from different fabrication nodes, each containing standard cell libraries optimized for speed, power, or density. Engineers typically navigate between the design and target PDK to make informed decisions, such as selecting gates for area optimization or enhancing the speed of the critical path. However, this process is often manual, time-consuming, and prone to errors. To address this, we present ChipXplore, a multi-agent collaborative framework powered by large language models that enables engineers to query hardware designs and PDKs using natural language. By exploiting the structured nature of PDK and hardware design data, ChipXplore retrieves relevant information through text-to-SQL and text-to-Cypher customized workflows. The framework achieves an execution accuracy of 97.39\\% in complex natural language queries and improves productivity by making retrieval 5.63x faster while reducing errors by 5.25x in user studies. Compared to generic workflows, ChipXplore's customized workflow is capable of orchestrating reasoning and planning over multiple databases, improving accuracy by 29.78\\%. ChipXplore lays the foundation for building autonomous agents capable of tackling diverse physical design tasks that require PDK and hardware design awareness.",
      "authors": [
        "Manar Abdelatty",
        "Jacob Rosenstein",
        "and Sherief Reda"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-17T17:11:13+00:00",
          "link": "https://arxiv.org/abs/2407.12749v1",
          "size": "6011kb",
          "version": "v1"
        },
        {
          "date": "2024-11-01T17:31:11+00:00",
          "link": "https://arxiv.org/abs/2407.12749v2",
          "size": "11834kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T18:37:14+00:00",
          "link": "https://arxiv.org/abs/2407.12749v3",
          "size": "2731kb",
          "version": "v3"
        }
      ],
      "title": "ChipXplore: Natural Language Exploration of Hardware Designs and Libraries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.12749",
        "HTML": "https://arxiv.org/html/2407.12749v3",
        "PDF": "https://arxiv.org/pdf/2407.12749"
      },
      "tasks": [
        "Information Retrieval",
        "Natural Language Queries",
        "Navigate",
        "Retrieval"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.21536",
      "abstract": "Multimodal emotion recognition in conversation (MERC) has garnered substantial research attention recently. Existing MERC methods face several challenges: (1) they fail to fully harness direct inter-modal cues, possibly leading to less-than-thorough cross-modal modeling; (2) they concurrently extract information from the same and different modalities at each network layer, potentially triggering conflicts from the fusion of multi-source data; (3) they lack the agility required to detect dynamic sentimental changes, perhaps resulting in inaccurate classification of utterances with abrupt sentiment shifts. To address these issues, a novel approach named GraphSmile is proposed for tracking intricate emotional cues in multimodal dialogues. GraphSmile comprises two key components, i.e., GSF and SDP modules. GSF ingeniously leverages graph structures to alternately assimilate inter-modal and intra-modal emotional dependencies layer by layer, adequately capturing cross-modal cues while effectively circumventing fusion conflicts. SDP is an auxiliary task to explicitly delineate the sentiment dynamics between utterances, promoting the model's ability to distinguish sentimental discrepancies. GraphSmile is effortlessly applied to multimodal sentiment analysis in conversation (MSAC), thus enabling simultaneous execution of MERC and MSAC tasks. Empirical results on multiple benchmarks demonstrate that GraphSmile can handle complex emotional and sentimental patterns, significantly outperforming baseline models.",
      "authors": [
        "Jiang Li",
        "Xiaoping Wang",
        "Zhigang Zeng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-31T11:47:36+00:00",
          "link": "https://arxiv.org/abs/2407.21536v1",
          "size": "1732kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T16:49:43+00:00",
          "link": "https://arxiv.org/abs/2407.21536v2",
          "size": "1734kb",
          "version": "v2"
        }
      ],
      "title": "Tracing Intricate Cues in Dialogue: Joint Graph Structure and Sentiment Dynamics for Multimodal Emotion Recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.21536",
        "HTML": "https://arxiv.org/html/2407.21536v2",
        "PDF": "https://arxiv.org/pdf/2407.21536"
      },
      "tasks": [
        "Emotion Recognition",
        "Emotion Recognition in Conversation",
        "Multimodal Emotion Recognition",
        "Multimodal Sentiment Analysis",
        "Sentiment Analysis"
      ],
      "repo_urls": [
        "https://github.com/lijfrank-open/GraphSmile"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.02191",
      "abstract": "Image inpainting, the process of filling in missing areas in an image, is a common image editing technique. Inpainting can be used to conceal or alter image contents in malicious manipulation of images, driving the need for research in image inpainting detection. Most existing methods use a basic encoder-decoder structure, which often results in a high number of false positives or misses the inpainted regions, especially when dealing with targets of varying semantics and scales. Additionally, the lack of an effective approach to capture boundary artifacts leads to less accurate edge localization. In this paper, we describe a new method for inpainting detection based on a Dense Feature Interaction Network (DeFI-Net). DeFI-Net uses a novel feature pyramid architecture to capture and amplify multi-scale representations across various stages, thereby improving the detection of image inpainting by better strengthening feature-level interactions. Additionally, the network can adaptively direct the lower-level features, which carry edge and shape information, to refine the localization of manipulated regions while integrating the higher-level semantic features. Using DeFI-Net, we develop a method combining complementary representations to accurately identify inpainted areas. Evaluation on seven image inpainting datasets demonstrates the effectiveness of our approach, which achieves state-of-the-art performance in detecting inpainting across diverse models. Code and models are available at https://github.com/Boombb/DeFI-Net_Inpainting.",
      "authors": [
        "Ye Yao",
        "Tingfeng Han",
        "Shan Jia",
        "Siwei Lyu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-05T02:35:13+00:00",
          "link": "https://arxiv.org/abs/2408.02191v1",
          "size": "12959kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T05:36:56+00:00",
          "link": "https://arxiv.org/abs/2408.02191v2",
          "size": "12894kb",
          "version": "v2"
        }
      ],
      "title": "Dense Feature Interaction Network for Image Inpainting Localization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.02191",
        "HTML": "https://arxiv.org/html/2408.02191v2",
        "PDF": "https://arxiv.org/pdf/2408.02191"
      },
      "tasks": [
        "Image Inpainting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.04209",
      "abstract": "This work proposes a novel numerical scheme for solving the high-dimensional Hamilton-Jacobi-Bellman equation with a functional hierarchical tensor ansatz. We consider the setting of stochastic control, whereby one applies control to a particle under Brownian motion. In particular, the existence of diffusion presents a new challenge to conventional tensor network methods for deterministic optimal control. To overcome the difficulty, we use a general regression-based formulation where the loss term is the Bellman consistency error combined with a Sobolev-type penalization term. We propose two novel sketching-based subroutines for obtaining the tensor-network approximation to the action-value functions and the value functions, which greatly accelerate the convergence for the subsequent regression phase. We apply the proposed approach successfully to two challenging control problems with Ginzburg-Landau potential in 1D and 2D with 64 variables.",
      "authors": [
        "Xun Tang",
        "Nan Sheng and Lexing Ying"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-08T04:26:56+00:00",
          "link": "https://arxiv.org/abs/2408.04209v1",
          "size": "4656kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T04:57:36+00:00",
          "link": "https://arxiv.org/abs/2408.04209v2",
          "size": "4096kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T07:00:41+00:00",
          "link": "https://arxiv.org/abs/2408.04209v3",
          "size": "3987kb",
          "version": "v3"
        }
      ],
      "title": "Solving high-dimensional Hamilton-Jacobi-Bellman equation with functional hierarchical tensor",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.04209",
        "HTML": "https://arxiv.org/html/2408.04209v3",
        "PDF": "https://arxiv.org/pdf/2408.04209"
      },
      "source": "arXiv"
    },
    {
      "id": "2408.06576",
      "abstract": "Cyber Threat Intelligence (CTI) summarization involves generating concise and accurate highlights from web intelligence data, which is critical for providing decision-makers with actionable insights to swiftly detect and respond to cyber threats in the cybersecurity domain. Despite that, the development of efficient techniques for summarizing CTI reports, comprising facts, analytical insights, attack processes, and more, has been hindered by the lack of suitable datasets. To address this gap, we introduce CTISum, a new benchmark dataset designed for the CTI summarization task. Recognizing the significance of understanding attack processes, we also propose a novel fine-grained subtask: attack process summarization, which aims to help defenders assess risks, identify security gaps, and uncover vulnerabilities. Specifically, a multi-stage annotation pipeline is designed to collect and annotate CTI data from diverse web sources, alongside a comprehensive benchmarking of CTISum using both extractive, abstractive and LLMs-based summarization methods. Experimental results reveal that current state-of-the-art models face significant challenges when applied to CTISum, highlighting that automatic summarization of CTI reports remains an open research problem. The code and example dataset can be made publicly available at https://github.com/pengwei-iie/CTISum.",
      "authors": [
        "Wei Peng",
        "Junmei Ding",
        "Wei Wang",
        "Lei Cui",
        "Wei Cai",
        "Zhiyu Hao",
        "Xiaochun Yun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-13T02:25:16+00:00",
          "link": "https://arxiv.org/abs/2408.06576v1",
          "size": "1253kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T02:56:37+00:00",
          "link": "https://arxiv.org/abs/2408.06576v2",
          "size": "1603kb",
          "version": "v2"
        }
      ],
      "title": "CTISum: A New Benchmark Dataset For Cyber Threat Intelligence Summarization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.06576",
        "HTML": "https://arxiv.org/html/2408.06576v2",
        "PDF": "https://arxiv.org/pdf/2408.06576"
      },
      "tasks": [
        "Abstractive Text Summarization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.06832",
      "abstract": "The integration of data from diverse sensor modalities (e.g., camera and LiDAR) constitutes a prevalent methodology within the ambit of autonomous driving scenarios. Recent advancements in efficient point cloud transformers have underscored the efficacy of integrating information in sparse formats. When it comes to fusion, since image patches are dense in pixel space with ambiguous depth, it necessitates additional design considerations for effective fusion. In this paper, we conduct a comprehensive exploration of design choices for Transformer-based sparse cameraLiDAR fusion. This investigation encompasses strategies for image-to-3D and LiDAR-to-2D mapping, attention neighbor grouping, single modal tokenizer, and micro-structure of Transformer. By amalgamating the most effective principles uncovered through our investigation, we introduce FlatFusion, a carefully designed framework for sparse camera-LiDAR fusion. Notably, FlatFusion significantly outperforms state-of-the-art sparse Transformer-based methods, including UniTR, CMT, and SparseFusion, achieving 73.7 NDS on the nuScenes validation set with 10.1 FPS with PyTorch.",
      "authors": [
        "Yutao Zhu",
        "Xiaosong Jia",
        "Xinyu Yang",
        "Junchi Yan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-13T11:46:32+00:00",
          "link": "https://arxiv.org/abs/2408.06832v1",
          "size": "17096kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T13:55:41+00:00",
          "link": "https://arxiv.org/abs/2408.06832v2",
          "size": "3908kb",
          "version": "v2"
        }
      ],
      "title": "FlatFusion: Delving into Details of Sparse Transformer-based Camera-LiDAR Fusion for Autonomous Driving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.06832",
        "HTML": "https://arxiv.org/html/2408.06832v2",
        "PDF": "https://arxiv.org/pdf/2408.06832"
      },
      "tasks": [
        "Autonomous Driving",
        "Image to 3D"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.07575",
      "abstract": "Most constraint-based causal learning algorithms provably return the correct causal graph under certain correctness conditions, such as faithfulness. By representing any constraint-based causal learning algorithm using the notion of a property, we provide a general framework to obtain and study correctness conditions for these algorithms. From the framework, we provide exact correctness conditions for the PC algorithm, which are then related to the correctness conditions of some other existing causal discovery algorithms. The framework also suggests a paradigm for designing causal learning algorithms which allows for the correctness conditions of algorithms to be controlled for before designing the actual algorithm, and has the following implications. We show that the sparsest Markov representation condition is the weakest correctness condition for algorithms that output ancestral graphs or directed acyclic graphs satisfying any existing notions of minimality. We also reason that Pearl-minimality is necessary for meaningful causal learning but not sufficient to relax the faithfulness condition and, as such, has to be strengthened, such as by including background knowledge, for causal learning beyond faithfulness.",
      "authors": [
        "Kai Z. Teh",
        "Kayvan Sadeghi",
        "Terry Soo"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Statistics Theory (math.ST)",
        "Methodology (stat.ME)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-14T14:16:02+00:00",
          "link": "https://arxiv.org/abs/2408.07575v1",
          "size": "7885kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T13:16:49+00:00",
          "link": "https://arxiv.org/abs/2408.07575v2",
          "size": "417kb",
          "version": "v2"
        }
      ],
      "title": "A General Framework on Conditions for Constraint-based Causal Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.07575",
        "HTML": "https://arxiv.org/html/2408.07575v2",
        "PDF": "https://arxiv.org/pdf/2408.07575"
      },
      "tasks": [
        "Causal Discovery"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.10789",
      "abstract": "Low-level 3D representations, such as point clouds, meshes, NeRFs and 3D Gaussians, are commonly used for modeling 3D objects and scenes. However, cognitive studies indicate that human perception operates at higher levels and interprets 3D environments by decomposing them into meaningful structural parts, rather than low-level elements like points or voxels. Structured geometric decomposition enhances scene interpretability and facilitates downstream tasks requiring component-level manipulation. In this work, we introduce PartGS, a self-supervised part-aware reconstruction framework that integrates 2D Gaussians and superquadrics to parse objects and scenes into an interpretable decomposition, leveraging multi-view image inputs to uncover 3D structural information. Our method jointly optimizes superquadric meshes and Gaussians by coupling their parameters within a hybrid representation. On one hand, superquadrics enable the representation of a wide range of shape primitives, facilitating flexible and meaningful decompositions. On the other hand, 2D Gaussians capture detailed texture and geometric details, ensuring high-fidelity appearance and geometry reconstruction. Operating in a self-supervised manner, our approach demonstrates superior performance compared to state-of-the-art methods across extensive experiments on the DTU, ShapeNet, and real-world datasets.",
      "authors": [
        "Zhirui Gao",
        "Renjiao Yi",
        "Yuhang Huang",
        "Wei Chen",
        "Chenyang Zhu",
        "Kai Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-20T12:30:37+00:00",
          "link": "https://arxiv.org/abs/2408.10789v1",
          "size": "5028kb",
          "version": "v1"
        },
        {
          "date": "2024-12-02T17:04:07+00:00",
          "link": "https://arxiv.org/abs/2408.10789v2",
          "size": "13672kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T07:40:39+00:00",
          "link": "https://arxiv.org/abs/2408.10789v3",
          "size": "7703kb",
          "version": "v3"
        }
      ],
      "title": "Self-supervised Learning of Hybrid Part-aware 3D Representation of 2D Gaussians and Superquadrics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.10789",
        "HTML": "https://arxiv.org/html/2408.10789v3",
        "PDF": "https://arxiv.org/pdf/2408.10789"
      },
      "tasks": [
        "3D Reconstruction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.11189",
      "abstract": "Queries to large language models (LLMs) can be divided into two parts: the instruction/question and the accompanying context. The context for retrieval-augmented generation (RAG) systems in most benchmarks comes from Wikipedia-like texts written in a neutral and factual tone. However, real-world RAG applications often retrieve internet-based text with diverse tones and linguistic styles, posing challenges for downstream tasks. This paper introduces (a) a dataset that transforms RAG-retrieved passages into emotionally inflected and sarcastic text, (b) an emotion translation model for adapting text to different tones, and (c) a prompt-based method to improve LLMs' pragmatic interpretation of retrieved text.",
      "authors": [
        "Benjamin Reichman",
        "Adar Avsian",
        "Kartik Talamadupula",
        "Toshish Jawale",
        "Larry Heck"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-20T20:47:27+00:00",
          "link": "https://arxiv.org/abs/2408.11189v1",
          "size": "574kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T19:13:23+00:00",
          "link": "https://arxiv.org/abs/2408.11189v2",
          "size": "4098kb",
          "version": "v2"
        }
      ],
      "title": "Emotional RAG LLMs: Reading Comprehension for the Open Internet",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.11189",
        "HTML": "https://arxiv.org/html/2408.11189v2",
        "PDF": "https://arxiv.org/pdf/2408.11189"
      },
      "datasets": [
        {
          "dataset_name": "Symblai/reading-with-intent",
          "downloads": "57",
          "likes": "0",
          "link": "https://huggingface.co/datasets/Symblai/reading-with-intent"
        }
      ],
      "tasks": [
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.13697",
      "abstract": "The rise of generative models has raised concerns about image authenticity online, highlighting the urgent need for a detector that is (1) highly generalizable, capable of handling unseen forgery techniques, and (2) data-efficient, achieving optimal performance with minimal training data, enabling it to counter newly emerging forgery techniques effectively. To achieve this, we propose ForgeLens, a data-efficient, feature-guided framework that incorporates two lightweight designs to enable a frozen network to focus on forgery-specific features. First, we introduce the Weight-Shared Guidance Module (WSGM), which guides the extraction of forgery-specific features during training. Second, a forgery-aware feature integrator, FAFormer, is used to effectively integrate forgery information across multi-stage features. ForgeLens addresses a key limitation of previous frozen network-based methods, where general-purpose features extracted from large datasets often contain excessive forgery-irrelevant information. As a result, it achieves strong generalization and reaches optimal performance with minimal training data. Experimental results on 19 generative models, including both GANs and diffusion models, demonstrate improvements of 13.61% in Avg.Acc and 8.69% in Avg.AP over the base model. Notably, ForgeLens outperforms existing forgery detection methods, achieving state-of-the-art performance with just 1% of the training data. Our code is available at https://github.com/Yingjian-Chen/ForgeLens.",
      "authors": [
        "Yingjian Chen",
        "Lei Zhang",
        "Yakun Niu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-25T01:15:52+00:00",
          "link": "https://arxiv.org/abs/2408.13697v1",
          "size": "2902kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T00:08:20+00:00",
          "link": "https://arxiv.org/abs/2408.13697v2",
          "size": "3491kb",
          "version": "v2"
        }
      ],
      "title": "ForgeLens: Data-Efficient Forgery Focus for Generalizable Forgery Image Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.13697",
        "HTML": "https://arxiv.org/html/2408.13697v2",
        "PDF": "https://arxiv.org/pdf/2408.13697"
      },
      "tasks": [
        "DeepFake Detection",
        "Face Swapping"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.14419",
      "abstract": "We introduce CHARTOM, a visual theory-of-mind benchmark designed to evaluate multimodal large language models' capability to understand and reason about misleading data visualizations though charts. CHARTOM consists of carefully designed charts and associated questions that require a language model to not only correctly comprehend the factual content in the chart (the FACT question) but also judge whether the chart will be misleading to a human readers (the MIND question), a dual capability with significant societal benefits. We detail the construction of our benchmark including its calibration on human performance and estimation of MIND ground truth called the Human Misleadingness Index. We evaluated several leading LLMs -- including GPT, Claude, Gemini, Qwen, Llama, and Llava series models -- on the CHARTOM dataset and found that it was challenging to all models both on FACT and MIND questions. This highlights the limitations of current LLMs and presents significant opportunity for future LLMs to improve on understanding misleading charts.",
      "authors": [
        "Shubham Bharti",
        "Shiyun Cheng",
        "Jihyun Rho",
        "Jianrui Zhang",
        "Mu Cai",
        "Yong Jae Lee",
        "Martina Rau",
        "Xiaojin Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-26T17:04:23+00:00",
          "link": "https://arxiv.org/abs/2408.14419v1",
          "size": "1773kb",
          "version": "v1"
        },
        {
          "date": "2025-05-09T19:55:14+00:00",
          "link": "https://arxiv.org/abs/2408.14419v2",
          "size": "1900kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T00:08:15+00:00",
          "link": "https://arxiv.org/abs/2408.14419v3",
          "size": "2840kb",
          "version": "v3"
        }
      ],
      "title": "CHARTOM: A Visual Theory-of-Mind Benchmark for LLMs on Misleading Charts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.14419",
        "HTML": "https://arxiv.org/html/2408.14419v3",
        "PDF": "https://arxiv.org/pdf/2408.14419"
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "repo_urls": [
        "https://github.com/ukplab/arxiv2025-misleading-visualizations"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.15495",
      "abstract": "When symmetry is present in the loss function, the model is likely to be trapped in a low-capacity state that is sometimes known as a \"collapse\". Being trapped in these low-capacity states can be a major obstacle to training across many scenarios where deep learning technology is applied. We first prove two concrete mechanisms through which symmetries lead to reduced capacities and ignored features during training and inference. We then propose a simple and theoretically justified algorithm, syre, to remove almost all symmetry-induced low-capacity states in neural networks. When this type of entrapment is especially a concern, removing symmetries with the proposed method is shown to correlate well with improved optimization or performance. A remarkable merit of the proposed method is that it is model-agnostic and does not require any knowledge of the symmetry.",
      "authors": [
        "Liu Ziyin",
        "Yizhou Xu",
        "Isaac Chuang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-28T02:45:41+00:00",
          "link": "https://arxiv.org/abs/2408.15495v1",
          "size": "2508kb",
          "version": "v1"
        },
        {
          "date": "2025-02-25T21:27:31+00:00",
          "link": "https://arxiv.org/abs/2408.15495v2",
          "size": "3261kb",
          "version": "v2"
        },
        {
          "date": "2025-02-27T15:30:47+00:00",
          "link": "https://arxiv.org/abs/2408.15495v3",
          "size": "3261kb",
          "version": "v3"
        },
        {
          "date": "2025-06-29T22:14:46+00:00",
          "link": "https://arxiv.org/abs/2408.15495v4",
          "size": "2251kb",
          "version": "v4"
        }
      ],
      "title": "Remove Symmetries to Control Model Expressivity and Improve Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.15495",
        "HTML": "https://arxiv.org/html/2408.15495v4",
        "PDF": "https://arxiv.org/pdf/2408.15495"
      },
      "tasks": [
        "model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.15867",
      "abstract": "Reconfigurable intelligent surfaces (RISs) have been introduced as arrays of nearly passive elements with software-tunable electromagnetic properties to dynamically manipulate the reflection/transmission of radio signals. Research works in this area are focused on two applications, namely {\\it user-assist} RIS aiming at tuning the RIS to enhance the quality-of-service (QoS) of target users, and the {\\it malicious} RIS aiming for an attacker to degrade the QoS at victim receivers through generating {\\it intended} destructive interference. While both user-assist and malicious RIS applications have been explored extensively, the impact of RIS deployments on imposing {\\it unintended} interference on various wireless user-equipments (EUs) remains underexplored. This paper investigates the challenges of integrating RISs into multi-carrier, multi-user, and multi-operator networks. We discuss how RIS deployments intended to benefit specific users can negatively impact other users served at various carrier frequencies through different network operators. While not an ideal solution, we discuss how ultra-narrowband metasurfaces can be incorporated into the manufacturing of RISs to mitigate some challenges of RIS deployment in wireless networks. We also present a simulation scenario to illuminate some practical challenges associated with the deployment of RISs in shared public environments.",
      "authors": [
        "Mehdi Monemi",
        "Mehdi Rasti",
        "Arthur S. de Sena",
        "Mohammad Amir Fallah",
        "Matti Latva-Aho",
        "Marco Di Renzo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-28T15:35:05+00:00",
          "link": "https://arxiv.org/abs/2408.15867v1",
          "size": "847kb",
          "version": "v1"
        },
        {
          "date": "2024-12-11T06:21:28+00:00",
          "link": "https://arxiv.org/abs/2408.15867v2",
          "size": "1200kb",
          "version": "v2"
        },
        {
          "date": "2025-01-27T10:34:28+00:00",
          "link": "https://arxiv.org/abs/2408.15867v3",
          "size": "1292kb",
          "version": "v3"
        },
        {
          "date": "2025-02-19T17:35:02+00:00",
          "link": "https://arxiv.org/abs/2408.15867v4",
          "size": "2385kb",
          "version": "v4"
        },
        {
          "date": "2025-06-29T10:33:31+00:00",
          "link": "https://arxiv.org/abs/2408.15867v5",
          "size": "1331kb",
          "version": "v5"
        }
      ],
      "title": "Practical Challenges for Reliable RIS Deployment in Heterogeneous Multi-Operator Multi-Band Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.15867",
        "HTML": "https://arxiv.org/html/2408.15867v5",
        "PDF": "https://arxiv.org/pdf/2408.15867"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2408.17245",
      "abstract": "Spike trains serve as the primary medium for information transmission in Spiking Neural Networks, playing a crucial role in determining system efficiency. Existing encoding schemes based on spike counts or timing often face severe limitations under low-timestep constraints, while more expressive alternatives typically involve complex neuronal dynamics or system designs, which hinder scalability and practical deployment. To address these challenges, we propose the Ternary Momentum Neuron (TMN), a novel neuron model featuring two key innovations: (1) a lightweight momentum mechanism that realizes exponential input weighting by doubling the membrane potential before integration, and (2) a ternary predictive spiking scheme which employs symmetric sub-thresholds $\\pm\\frac{1}{2}v_{th}$ to enable early spiking and correct over-firing. Extensive experiments across diverse tasks and network architectures demonstrate that the proposed approach achieves high-precision encoding with significantly fewer timesteps, providing a scalable and hardware-aware solution for next-generation SNN computing.",
      "authors": [
        "Yiwen Gu",
        "Junchuan Gu",
        "Haibin Shen",
        "Kejie Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-30T12:39:25+00:00",
          "link": "https://arxiv.org/abs/2408.17245v1",
          "size": "473kb",
          "version": "v1"
        },
        {
          "date": "2024-12-04T03:11:59+00:00",
          "link": "https://arxiv.org/abs/2408.17245v2",
          "size": "203kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T07:20:41+00:00",
          "link": "https://arxiv.org/abs/2408.17245v3",
          "size": "531kb",
          "version": "v3"
        }
      ],
      "title": "TMN: A Lightweight Neuron Model for Efficient Nonlinear Spike Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.17245",
        "HTML": "https://arxiv.org/html/2408.17245v3",
        "PDF": "https://arxiv.org/pdf/2408.17245"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2409.01524",
      "abstract": "Self-correction is a novel method that can stimulate the potential reasoning abilities of large language models (LLMs). It involves detecting and correcting errors during the inference process when LLMs solve reasoning problems. However, recent works do not regard self-correction as a spontaneous and intrinsic capability of LLMs. Instead, such correction is achieved through post-hoc generation, external knowledge introduction, multi-model collaboration, and similar techniques. In this paper, we propose a series of mathematical LLMs called S$^3$c-Math, which are able to perform Spontaneous Step-level Self-correction for Mathematical reasoning. This capability helps LLMs to recognize whether their ongoing inference tends to contain errors and simultaneously correct these errors to produce a more reliable response. We proposed a method, which employs a step-level sampling approach to construct step-wise self-correction data for achieving such ability. Additionally, we implement a training strategy that uses above constructed data to equip LLMs with spontaneous step-level self-correction capacities. Our data and methods have been demonstrated to be effective across various foundation LLMs, consistently showing significant progress in evaluations on GSM8K, MATH, and other mathematical benchmarks. To the best of our knowledge, we are the first to introduce the spontaneous step-level self-correction ability of LLMs in mathematical reasoning.",
      "authors": [
        "Yuchen Yan",
        "Jin Jiang",
        "Yang Liu",
        "Yixin Cao",
        "Xin Xu",
        "Mengdi Zhang",
        "Xunliang Cai",
        "Jian Shao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-03T01:40:21+00:00",
          "link": "https://arxiv.org/abs/2409.01524v1",
          "size": "862kb",
          "version": "v1"
        },
        {
          "date": "2025-02-20T02:20:58+00:00",
          "link": "https://arxiv.org/abs/2409.01524v2",
          "size": "862kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T04:34:18+00:00",
          "link": "https://arxiv.org/abs/2409.01524v3",
          "size": "857kb",
          "version": "v3"
        }
      ],
      "title": "S^3cMath: Spontaneous Step-level Self-correction Makes Large Language Models Better Mathematical Reasoners",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.01524",
        "HTML": "https://arxiv.org/html/2409.01524v3",
        "PDF": "https://arxiv.org/pdf/2409.01524"
      },
      "tasks": [
        "GSM8K",
        "Math",
        "Mathematical Reasoning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.01754",
      "abstract": "From the invention of writing and the printing press, to television and social media, human history is punctuated by major innovations in communication technology, which fundamentally altered how ideas spread and reshaped our culture. Recent chatbots powered by generative artificial intelligence constitute a novel medium that encodes cultural patterns in their neural representations and disseminates them in conversations with hundreds of millions of people. Understanding whether these patterns transmit into human language, and ultimately shape human culture, is a fundamental question. While fully quantifying the causal impact of a chatbot like ChatGPT on human culture is very challenging, lexicographic shift in human spoken communication may offer an early indicator of such broad phenomenon. Here, we apply econometric causal inference techniques to 740,249 hours of human discourse from 360,445 YouTube academic talks and 771,591 conversational podcast episodes across multiple disciplines. We detect a measurable and abrupt increase in the use of words preferentially generated by ChatGPT, such as delve, comprehend, boast, swift, and meticulous, after its release. These findings suggest a scenario where machines, originally trained on human data and subsequently exhibiting their own cultural traits, can, in turn, measurably reshape human culture. This marks the beginning of a closed cultural feedback loop in which cultural traits circulate bidirectionally between humans and machines. Our results motivate further research into the evolution of human-machine culture, and raise concerns over the erosion of linguistic and cultural diversity, and the risks of scalable manipulation.",
      "authors": [
        "Hiromu Yakura",
        "Ezequiel Lopez-Lopez",
        "Levin Brinkmann",
        "Ignacio Serna",
        "Prateek Gupta",
        "Ivan Soraperra",
        "Iyad Rahwan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-03T10:01:51+00:00",
          "link": "https://arxiv.org/abs/2409.01754v1",
          "size": "2346kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T14:43:32+00:00",
          "link": "https://arxiv.org/abs/2409.01754v2",
          "size": "8008kb",
          "version": "v2"
        }
      ],
      "title": "Empirical evidence of Large Language Model's influence on human spoken communication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.01754",
        "HTML": "https://arxiv.org/html/2409.01754v2",
        "PDF": "https://arxiv.org/pdf/2409.01754"
      },
      "tasks": [
        "Diversity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.03872",
      "abstract": "Motivated by the challenge of moment recovery in hydrodynamic approximation in kinetic theory, we propose a data-driven approach for the hydrodynamic models. Inspired by continuous data assimilation, our method introduces a relaxation-based nudging system coupled with a novel discretization technique. This approach facilitates the simultaneous recovery of both the force term and a high-resolution solution from sparsely observed data. To address potential numerical artifacts, we use kernel regression to fit the observed data. We also analyze the convergence of the proposed nudging system under both full and partial data scenarios. When applied to moment systems, the source term involves the derivative of higher-order moments, our approach serves as a crucial step for data preparation in machine-learning based moment closure models. Multiple numerical experiments demonstrate the effectiveness of our algorithm, and we discuss its potential extension to high-dimensional systems.",
      "authors": [
        "Jincheng Lu",
        "Kunlun Qi",
        "Li Wang",
        "Jeff Calder"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-05T19:21:19+00:00",
          "link": "https://arxiv.org/abs/2409.03872v1",
          "size": "1131kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T02:46:05+00:00",
          "link": "https://arxiv.org/abs/2409.03872v2",
          "size": "924kb",
          "version": "v2"
        }
      ],
      "title": "Continuous data assimilation for hydrodynamics: consistent discretization and application to moment recovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.03872",
        "HTML": "https://arxiv.org/html/2409.03872v2",
        "PDF": "https://arxiv.org/pdf/2409.03872"
      },
      "source": "arXiv"
    },
    {
      "id": "2409.07567",
      "abstract": "Many organizations were forced to quickly transition to the work-from-anywhere (WFA) model as a necessity to continue with their operations and remain in business despite the restrictions imposed during the COVID-19 pandemic. Many decisions were made in a rush, and cybersecurity decency tools were not in place to support this transition. In this paper, we first attempt to uncover some challenges and implications related to the cybersecurity of the WFA model. Secondly, we conducted an online user study to investigate the readiness and cybersecurity awareness of employers and their employees who shifted to work remotely from anywhere. The user study questionnaire addressed different resilience perspectives of individuals and organizations. The collected data includes 45 responses from remotely working employees of different organizational types: universities, government, private, and non-profit organizations. Despite the importance of security training and guidelines, it was surprising that many participants had not received them. A robust communication strategy is necessary to ensure that employees are informed and updated on security incidents that the organization encounters. Additionally, there is an increased need to pay attention to the security-related attributes of employees, such as their behavior, awareness, and compliance. Finally, we outlined best practice recommendations and mitigation tips guided by the study results to help individuals and organizations resist cybercrime and fraud and mitigate WFA-related cybersecurity risks.",
      "authors": [
        "Mohammed Mahyoub",
        "Ashraf Matrawy",
        "Kamal Isleem",
        "Olakunle Ibitoye"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-11T18:47:04+00:00",
          "link": "https://arxiv.org/abs/2409.07567v1",
          "size": "735kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T15:10:16+00:00",
          "link": "https://arxiv.org/abs/2409.07567v2",
          "size": "695kb",
          "version": "v2"
        }
      ],
      "title": "Cybersecurity Challenge Analysis of Work-from-Anywhere (WFA) and Recommendations guided by a User Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.07567",
        "HTML": "https://arxiv.org/html/2409.07567v2",
        "PDF": "https://arxiv.org/pdf/2409.07567"
      },
      "source": "arXiv"
    },
    {
      "id": "2409.08516",
      "abstract": "Class Incremental Semantic Segmentation (CISS) aims to mitigate catastrophic forgetting by maintaining a balance between previously learned and newly introduced knowledge. Existing methods, primarily based on regularization techniques like knowledge distillation, help preserve old knowledge but often face challenges in effectively integrating new knowledge, resulting in limited overall improvement. Endpoints Weight Fusion (EWF) method, while simple, effectively addresses some of these limitations by dynamically fusing the model weights from previous steps with those from the current step, using a fusion parameter alpha determined by the relative number of previously known classes and newly introduced classes. However, the simplicity of the alpha calculation may limit its ability to fully capture the complexities of different task scenarios, potentially leading to suboptimal fusion outcomes. In this paper, we propose an enhanced approach called Adaptive Weight Fusion (AWF), which introduces an alternating training strategy for the fusion parameter, allowing for more flexible and adaptive weight integration. AWF achieves superior performance by better balancing the retention of old knowledge with the learning of new classes, significantly improving results on benchmark CISS tasks compared to the original EWF. And our experiment code will be released on Github.",
      "authors": [
        "Zechao Sun",
        "Shuying Piao",
        "Haolin Jin",
        "Chang Dong",
        "Lin Yue",
        "Weitong Chen",
        "Luping Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-13T03:29:16+00:00",
          "link": "https://arxiv.org/abs/2409.08516v1",
          "size": "3466kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T11:15:38+00:00",
          "link": "https://arxiv.org/abs/2409.08516v2",
          "size": "3468kb",
          "version": "v2"
        }
      ],
      "title": "AWF: Adaptive Weight Fusion for Enhanced Class Incremental Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.08516",
        "HTML": "https://arxiv.org/html/2409.08516v2",
        "PDF": "https://arxiv.org/pdf/2409.08516"
      },
      "tasks": [
        "Class-Incremental Semantic Segmentation",
        "Knowledge Distillation",
        "Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.09111",
      "abstract": "Learning representations for structured data with certain geometries (e.g., observed or unobserved) is a fundamental challenge, wherein message passing neural networks (MPNNs) have become a de facto class of model solutions. In this paper, inspired by physical systems, we propose an energy-constrained diffusion model, which combines the inductive bias of diffusion on manifolds with layer-wise constraints of energy minimization. We identify that the diffusion operators have a one-to-one correspondence with the energy functions implicitly descended by the diffusion process, and the finite-difference iteration for solving the energy-constrained diffusion system induces the propagation layers of various types of MPNNs operating on observed or latent structures. This leads to a unified mathematical framework for common neural architectures whose computational flows can be cast as message passing (or its special case), including MLPs, GNNs, and Transformers. Building on these insights, we devise a new class of neural message passing models, dubbed diffusion-inspired Transformers, whose global attention layers are derived from the principled energy-constrained diffusion framework. Across diverse datasets ranging from real-world networks to images, texts, and physical particles, we demonstrate that the new model achieves promising performance in scenarios where the data structures are observed (as a graph), partially observed, or entirely unobserved.",
      "authors": [
        "Qitian Wu",
        "David Wipf",
        "Junchi Yan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-13T17:54:41+00:00",
          "link": "https://arxiv.org/abs/2409.09111v1",
          "size": "7116kb",
          "version": "v1"
        },
        {
          "date": "2025-06-22T18:46:40+00:00",
          "link": "https://arxiv.org/abs/2409.09111v2",
          "size": "2985kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T04:58:47+00:00",
          "link": "https://arxiv.org/abs/2409.09111v3",
          "size": "2983kb",
          "version": "v3"
        }
      ],
      "title": "From Diffusion to Transformers: A Unified Framework for Neural Message Passing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.09111",
        "PDF": "https://arxiv.org/pdf/2409.09111"
      },
      "tasks": [
        "Inductive Bias"
      ],
      "repo_urls": [
        "https://github.com/qitianwu/difformer"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.11753",
      "abstract": "Re-orchestration is the process of adapting a music piece for a different set of instruments. By altering the original instrumentation, the orchestrator often modifies the musical texture while preserving a recognizable melodic line and ensures that each part is playable within the technical and expressive capabilities of the chosen instruments. In this work, we propose METEOR, a model for generating Melody-aware Texture-controllable re-Orchestration with a Transformer-based variational auto-encoder (VAE). This model performs symbolic instrumental and textural music style transfers with a focus on melodic fidelity and controllability. We allow bar- and track-level controllability of the accompaniment with various textural attributes while keeping a homophonic texture. With both subjective and objective evaluations, we show that our model outperforms style transfer models on a re-orchestration task in terms of generation quality and controllability. Moreover, it can be adapted for a lead sheet orchestration task as a zero-shot learning model, achieving performance comparable to a model specifically trained for this task.",
      "authors": [
        "Dinh-Viet-Toan Le",
        "Yi-Hsuan Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-18T07:15:11+00:00",
          "link": "https://arxiv.org/abs/2409.11753v1",
          "size": "91kb",
          "version": "v1"
        },
        {
          "date": "2025-05-28T09:01:12+00:00",
          "link": "https://arxiv.org/abs/2409.11753v2",
          "size": "91kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T06:47:19+00:00",
          "link": "https://arxiv.org/abs/2409.11753v3",
          "size": "95kb",
          "version": "v3"
        }
      ],
      "title": "METEOR: Melody-aware Texture-controllable Symbolic Orchestral Music Generation via Transformer VAE",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.11753",
        "HTML": "https://arxiv.org/html/2409.11753v3",
        "PDF": "https://arxiv.org/pdf/2409.11753"
      },
      "repo_urls": [
        "https://github.com/dinhviettoanle/meteor"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.15010",
      "abstract": "Monocular depth estimation has seen significant advances through discriminative approaches, yet their performance remains constrained by the limitations of training datasets. While generative approaches have addressed this challenge by leveraging priors from internet-scale datasets, with recent studies showing state-of-the-art results using fine-tuned text-to-image diffusion models, there is still room for improvement. Notably, autoregressive generative approaches, particularly Visual AutoRegressive modeling, have demonstrated superior results compared to diffusion models in conditioned image synthesis, while offering faster inference times. In this work, we apply Visual Autoregressive Transformer (VAR) to the monocular depth estimation problem. However, the conventional GPT-2-style training procedure (teacher forcing) inherited by VAR yields suboptimal results for depth estimation. To address this limitation, we introduce DepthART - a novel training method formulated as a Depth Autoregressive Refinement Task. Unlike traditional VAR training with static inputs and targets, our method implements a dynamic target formulation based on model outputs, enabling self-refinement. By utilizing the model's own predictions as inputs instead of ground truth token maps during training, we frame the objective as residual minimization, effectively reducing the discrepancy between training and inference procedures. Our experimental results demonstrate that the proposed training approach significantly enhances the performance of VAR in depth estimation tasks. When trained on Hypersim dataset using our approach, the model achieves superior results across multiple unseen benchmarks compared to existing generative and discriminative baselines.",
      "authors": [
        "Bulat Gabdullin",
        "Nina Konovalova",
        "Nikolay Patakin",
        "Dmitry Senushkin",
        "Anton Konushin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-23T13:36:34+00:00",
          "link": "https://arxiv.org/abs/2409.15010v1",
          "size": "23349kb",
          "version": "v1"
        },
        {
          "date": "2024-10-25T12:15:32+00:00",
          "link": "https://arxiv.org/abs/2409.15010v2",
          "size": "23349kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T10:25:40+00:00",
          "link": "https://arxiv.org/abs/2409.15010v3",
          "size": "4422kb",
          "version": "v3"
        }
      ],
      "title": "DepthART: Monocular Depth Estimation as Autoregressive Refinement Task",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.15010",
        "HTML": "https://arxiv.org/html/2409.15010v3",
        "PDF": "https://arxiv.org/pdf/2409.15010"
      },
      "tasks": [
        "Depth Estimation",
        "Image Generation",
        "Monocular Depth Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.15380",
      "abstract": "Multilingual large language models (LLMs) today may not necessarily provide culturally appropriate and relevant responses to its Filipino users. We introduce Kalahi, a cultural LLM evaluation suite collaboratively created by native Filipino speakers. It is composed of 150 high-quality, handcrafted and nuanced prompts that test LLMs for generations that are relevant to shared Filipino cultural knowledge and values. Strong LLM performance in Kalahi indicates a model's ability to generate responses similar to what an average Filipino would say or do in a given situation. We conducted experiments on LLMs with multilingual and Filipino language support. Results show that Kalahi, while trivial for Filipinos, is challenging for LLMs, with the best model answering only 46.0% of the questions correctly compared to native Filipino performance of 89.10%. Thus, Kalahi can be used to accurately and reliably evaluate Filipino cultural representation in LLMs.",
      "authors": [
        "Jann Railey Montalan",
        "Jian Gang Ngui",
        "Wei Qi Leong",
        "Yosephine Susanto",
        "Hamsawardhini Rengarajan",
        "Alham Fikri Aji",
        "William Chandra Tjhi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-20T15:01:21+00:00",
          "link": "https://arxiv.org/abs/2409.15380v1",
          "size": "368kb",
          "version": "v1"
        },
        {
          "date": "2024-11-30T09:57:09+00:00",
          "link": "https://arxiv.org/abs/2409.15380v2",
          "size": "1200kb",
          "version": "v2"
        },
        {
          "date": "2024-12-18T14:39:02+00:00",
          "link": "https://arxiv.org/abs/2409.15380v3",
          "size": "1107kb",
          "version": "v3"
        },
        {
          "date": "2025-06-28T07:25:45+00:00",
          "link": "https://arxiv.org/abs/2409.15380v4",
          "size": "1001kb",
          "version": "v4"
        }
      ],
      "title": "Kalahi: A handcrafted, grassroots cultural LLM evaluation suite for Filipino",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.15380",
        "HTML": "https://arxiv.org/html/2409.15380v4",
        "PDF": "https://arxiv.org/pdf/2409.15380"
      },
      "datasets": [
        {
          "dataset_name": "aisingapore/kalahi",
          "downloads": "21",
          "likes": "0",
          "link": "https://huggingface.co/datasets/aisingapore/kalahi"
        },
        {
          "dataset_name": "aisingapore/Cultural-Evaluation-Kalahi",
          "downloads": "35",
          "likes": "0",
          "link": "https://huggingface.co/datasets/aisingapore/Cultural-Evaluation-Kalahi"
        }
      ],
      "tasks": [],
      "repo_urls": [
        "https://github.com/aisingapore/kalahi"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.15564",
      "abstract": "Traditional machine learning methods for movement recognition often struggle with limited model interpretability and a lack of insight into human movement dynamics. This study introduces a novel representation learning framework based on causal inference to address these challenges. Our two-stage approach combines the Peter-Clark (PC) algorithm and Kullback-Leibler (KL) divergence to identify and quantify causal relationships between human joints. By capturing joint interactions, the proposed causal Graph Convolutional Network (GCN) produces interpretable and robust representations. Experimental results on the EmoPain dataset demonstrate that the causal GCN outperforms traditional GCNs in accuracy, F1 score, and recall, particularly in detecting protective behaviors. This work contributes to advancing human motion analysis and lays a foundation for adaptive and intelligent healthcare solutions.",
      "authors": [
        "Xingrui Gu",
        "Chuyi Jiang",
        "Erte Wang",
        "Qiang Cui",
        "Leimin Tian",
        "Lianlong Wu",
        "Siyang Song",
        "Chuang Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-23T21:38:49+00:00",
          "link": "https://arxiv.org/abs/2409.15564v1",
          "size": "5030kb",
          "version": "v1"
        },
        {
          "date": "2024-09-27T08:40:26+00:00",
          "link": "https://arxiv.org/abs/2409.15564v2",
          "size": "5030kb",
          "version": "v2"
        },
        {
          "date": "2025-05-26T08:43:16+00:00",
          "link": "https://arxiv.org/abs/2409.15564v3",
          "size": "6845kb",
          "version": "v3"
        },
        {
          "date": "2025-06-30T00:05:33+00:00",
          "link": "https://arxiv.org/abs/2409.15564v4",
          "size": "4452kb",
          "version": "v4"
        }
      ],
      "title": "CauSkelNet: Causal Representation Learning for Human Behaviour Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.15564",
        "HTML": "https://arxiv.org/html/2409.15564v4",
        "PDF": "https://arxiv.org/pdf/2409.15564"
      },
      "tasks": [
        "Causal Inference",
        "Representation Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.17564",
      "abstract": "Previous works have attempted to improve tracking efficiency through lightweight architecture design or knowledge distillation from teacher models to compact student trackers. However, these solutions often sacrifice accuracy for speed to a great extent, and also have the problems of complex training process and structural limitations. Thus, we propose a general model compression framework for efficient transformer object tracking, named CompressTracker, to reduce model size while preserving tracking accuracy. Our approach features a novel stage division strategy that segments the transformer layers of the teacher model into distinct stages to break the limitation of model structure. Additionally, we also design a unique replacement training technique that randomly substitutes specific stages in the student model with those from the teacher model, as opposed to training the student model in isolation. Replacement training enhances the student model's ability to replicate the teacher model's behavior and simplifies the training process. To further forcing student model to emulate teacher model, we incorporate prediction guidance and stage-wise feature mimicking to provide additional supervision during the teacher model's compression process. CompressTracker is structurally agnostic, making it compatible with any transformer architecture. We conduct a series of experiment to verify the effectiveness and generalizability of our CompressTracker. Our CompressTracker-SUTrack, compressed from SUTrack, retains about 99 performance on LaSOT (72.2 AUC) while achieves 2.42x speed up. Code is available at https://github.com/LingyiHongfd/CompressTracker.",
      "authors": [
        "Lingyi Hong",
        "Jinglun Li",
        "Xinyu Zhou",
        "Shilin Yan",
        "Pinxue Guo",
        "Kaixun Jiang",
        "Zhaoyu Chen",
        "Shuyong Gao",
        "Runze Li",
        "Xingdong Sheng",
        "Wei Zhang",
        "Hong Lu",
        "Wenqiang Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-26T06:27:15+00:00",
          "link": "https://arxiv.org/abs/2409.17564v1",
          "size": "606kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T08:38:59+00:00",
          "link": "https://arxiv.org/abs/2409.17564v2",
          "size": "435kb",
          "version": "v2"
        }
      ],
      "title": "General Compression Framework for Efficient Transformer Object Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.17564",
        "HTML": "https://arxiv.org/html/2409.17564v2",
        "PDF": "https://arxiv.org/pdf/2409.17564"
      },
      "tasks": [
        "Model Compression",
        "Object",
        "Object Tracking",
        "Visual Object Tracking"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.17777",
      "abstract": "Deep multimodal learning has shown remarkable success by leveraging contrastive learning to capture explicit one-to-one relations across modalities. However, real-world data often exhibits shared relations beyond simple pairwise associations. We propose M3CoL, a Multimodal Mixup Contrastive Learning approach to capture nuanced shared relations inherent in multimodal data. Our key contribution is a Mixup-based contrastive loss that learns robust representations by aligning mixed samples from one modality with their corresponding samples from other modalities thereby capturing shared relations between them. For multimodal classification tasks, we introduce a framework that integrates a fusion module with unimodal prediction modules for auxiliary supervision during training, complemented by our proposed Mixup-based contrastive loss. Through extensive experiments on diverse datasets (N24News, ROSMAP, BRCA, and Food-101), we demonstrate that M3CoL effectively captures shared multimodal relations and generalizes across domains. It outperforms state-of-the-art methods on N24News, ROSMAP, and BRCA, while achieving comparable performance on Food-101. Our work highlights the significance of learning shared relations for robust multimodal learning, opening up promising avenues for future research. Our code is publicly available at https://github.com/RaghavSinghal10/M3CoL.",
      "authors": [
        "Raja Kumar",
        "Raghav Singhal",
        "Pranamya Kulkarni",
        "Deval Mehta",
        "Kshitij Jadhav"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-26T12:15:13+00:00",
          "link": "https://arxiv.org/abs/2409.17777v1",
          "size": "16456kb",
          "version": "v1"
        },
        {
          "date": "2024-10-18T16:31:49+00:00",
          "link": "https://arxiv.org/abs/2409.17777v2",
          "size": "16455kb",
          "version": "v2"
        },
        {
          "date": "2024-12-06T06:58:30+00:00",
          "link": "https://arxiv.org/abs/2409.17777v3",
          "size": "16455kb",
          "version": "v3"
        },
        {
          "date": "2025-06-30T07:55:13+00:00",
          "link": "https://arxiv.org/abs/2409.17777v4",
          "size": "10426kb",
          "version": "v4"
        }
      ],
      "title": "Harnessing Shared Relations via Multimodal Mixup Contrastive Learning for Multimodal Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.17777",
        "HTML": "https://arxiv.org/html/2409.17777v4",
        "PDF": "https://arxiv.org/pdf/2409.17777"
      },
      "tasks": [
        "Contrastive Learning"
      ],
      "repo_urls": [
        "https://github.com/RaghavSinghal10/M3CoL"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.18860",
      "abstract": "Recent Prompt-based Continual learning (PCL) has achieved remarkable performance with pre-trained models. These approaches expand a prompt pool by adding a new set of prompts while learning and select the correct set during inference. Previous studies have revealed that learning task-wised prompt sets individually and low selection accuracy pose challenges to the performance of PCL. In this paper, we propose a plug-in method, $\\textbf{L}$earning $\\textbf{W}$hether $\\textbf{t}$o $\\textbf{G}$row $\\textbf{(LW2G)}$, which leverages the disparities between tasks to form an effective and efficient prompt sets pool, thereby achieving intra-task knowledge sharing and cooperation and avoiding the unbounded increase in the cost of the prompt pool. Specifically, a shared set is utilized when several tasks share certain commonalities, and a new set is added when there are significant differences between the new and previous tasks. To achieve this, we develop a metric called Hinder Forward Capability (HFC) to measure the hindrance imposed on learning new tasks by surgically modifying the original gradient onto the orthogonal complement of the old feature space. With HFC, an automated scheme, Dynamic Growing Approach, adaptively learns whether to grow with a dynamic threshold. Furthermore, we design a gradient-based constraint to ensure consistency between the updating prompts and pre-trained knowledge. Extensive experiments show the effectiveness of our method. Code is available at https://github.com/RAIAN08/LW2G.",
      "authors": [
        "Qian Feng",
        "Da-wei Zhou",
        "Hanbin Zhao",
        "Chao Zhang",
        "Jiahua Dong",
        "Dengxin Dai",
        "Hui Qian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-27T15:55:13+00:00",
          "link": "https://arxiv.org/abs/2409.18860v1",
          "size": "2640kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T07:10:12+00:00",
          "link": "https://arxiv.org/abs/2409.18860v2",
          "size": "1171kb",
          "version": "v2"
        }
      ],
      "title": "LW2G: Learning Whether to Grow for Prompt-based Continual Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.18860",
        "HTML": "https://arxiv.org/html/2409.18860v2",
        "PDF": "https://arxiv.org/pdf/2409.18860"
      },
      "tasks": [
        "Continual Learning",
        "Prompt Learning",
        "Retrieval"
      ],
      "repo_urls": [
        "https://github.com/raian08/lw2g"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.20003",
      "abstract": "Multibiometrics, which uses multiple biometric traits to improve recognition performance instead of using only one biometric trait to authenticate individuals, has been investigated. Previous studies have combined individually acquired biometric traits or have not fully considered the convenience of the system. Focusing on a single face image, we propose a novel multibiometric method that combines five biometric traits, i.e., face, iris, periocular, nose, eyebrow, that can be extracted from a single face image. The proposed method does not sacrifice the convenience of biometrics since only a single face image is used as input. Through a variety of experiments using the CASIA Iris Distance database, we demonstrate the effectiveness of the proposed multibiometrics method.",
      "authors": [
        "Koichi Ito",
        "Taito Tonosaki",
        "Takafumi Aoki",
        "Tetsushi Ohki",
        "and Masakatsu Nishigaki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-30T06:55:01+00:00",
          "link": "https://arxiv.org/abs/2409.20003v1",
          "size": "7356kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T03:29:58+00:00",
          "link": "https://arxiv.org/abs/2409.20003v2",
          "size": "7342kb",
          "version": "v2"
        }
      ],
      "title": "Multibiometrics Using a Single Face Image",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.20003",
        "HTML": "https://arxiv.org/html/2409.20003v2",
        "PDF": "https://arxiv.org/pdf/2409.20003"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2410.01017",
      "abstract": "The Polynomial Learning With Errors problem (PLWE) serves as the background of two of the three cryptosystems standardized in August 2024 by the National Institute of Standards and Technology to replace non-quantum resistant current primitives like those based on RSA, Diffie-Hellman or its elliptic curve analogue. Although PLWE is highly believed to be quantum resistant, this fact has not yet been established, contrariwise to other post-quantum proposals like multivariate and some code based ones. Moreover, several vulnerabilities have been encountered for a number of specific instances. In a search for more flexibility, it becomes fully relevant to study the robustness of PLWE based on other polynomials, not necessarily cyclotomic. In 2015, Elias et al found a good number of attacks based on different features of the roots of the polynomial. In the present work we present an overview of the approximations made against PLWE derived from this and subsequent works, along with several new attacks which refine those by Elias et al. exploiting the order of the trace of roots over finite extensions of the finite field under the three scenarios laid out by Elias et al., allowing to generalize the setting in which the attacks can be carried out.",
      "authors": [
        "Iv\\'an Blanco Chac\\'on",
        "Ra\\'ul Dur\\'an D\\'iaz and Rodrigo Mart\\'in S\\'anchez-Ledesma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-01T19:25:04+00:00",
          "link": "https://arxiv.org/abs/2410.01017v1",
          "size": "56kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T10:56:27+00:00",
          "link": "https://arxiv.org/abs/2410.01017v2",
          "size": "59kb",
          "version": "v2"
        }
      ],
      "title": "A Generalized Approach to Root-based Attacks against PLWE",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.01017",
        "HTML": "https://arxiv.org/html/2410.01017v2",
        "PDF": "https://arxiv.org/pdf/2410.01017"
      },
      "source": "arXiv"
    },
    {
      "id": "2410.01276",
      "abstract": "Machine unlearning (MU) aims to remove the influence of particular data points from the learnable parameters of a trained machine learning model. This is a crucial capability in light of data privacy requirements, trustworthiness, and safety in deployed models. MU is particularly challenging for deep neural networks (DNNs), such as convolutional nets or vision transformers, as such DNNs tend to memorize a notable portion of their training dataset. Nevertheless, the community lacks a rigorous and multifaceted study that looks into the success of MU methods for DNNs. In this paper, we investigate 18 state-of-the-art MU methods across various benchmark datasets and models, with each evaluation conducted over 10 different initializations, a comprehensive evaluation involving MU over 100K models. We show that, with the proper hyperparameters, Masked Small Gradients (MSG) and Convolution Transpose (CT), consistently perform better in terms of model accuracy and run-time efficiency across different models, datasets, and initializations, assessed by population-based membership inference attacks (MIA) and per-sample unlearning likelihood ratio attacks (U-LiRA). Furthermore, our benchmark highlights the fact that comparing a MU method only with commonly used baselines, such as Gradient Ascent (GA) or Successive Random Relabeling (SRL), is inadequate, and we need better baselines like Negative Gradient Plus (NG+) with proper hyperparameter selection.",
      "authors": [
        "Xavier F. Cadet",
        "Anastasia Borovykh",
        "Mohammad Malekzadeh",
        "Sara Ahmadi-Abhari",
        "Hamed Haddadi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-02T06:41:58+00:00",
          "link": "https://arxiv.org/abs/2410.01276v1",
          "size": "87kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T03:46:59+00:00",
          "link": "https://arxiv.org/abs/2410.01276v2",
          "size": "276kb",
          "version": "v2"
        }
      ],
      "title": "Deep Unlearn: Benchmarking Machine Unlearning for Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.01276",
        "HTML": "https://arxiv.org/html/2410.01276v2",
        "PDF": "https://arxiv.org/pdf/2410.01276"
      },
      "tasks": [
        "Benchmarking",
        "Machine Unlearning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.01697",
      "abstract": "Deep neural networks (DNNs) are vulnerable to small adversarial perturbations, which are tiny changes to the input data that appear insignificant but cause the model to produce drastically different outputs. Many defense methods require modifying model architectures during evaluation or performing test-time data purification. This not only introduces additional complexity but is often architecture-dependent. We show, however, that robust feature learning during training can significantly enhance DNN robustness. We propose MOREL, a multi-objective approach that aligns natural and adversarial features using cosine similarity and multi-positive contrastive losses to encourage similar features for same-class inputs. Extensive experiments demonstrate that MOREL significantly improves robustness against both white-box and black-box attacks. Our code is available at https://github.com/salomonhotegni/MOREL",
      "authors": [
        "Sedjro Salomon Hotegni",
        "Sebastian Peitz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-02T16:05:03+00:00",
          "link": "https://arxiv.org/abs/2410.01697v1",
          "size": "409kb",
          "version": "v1"
        },
        {
          "date": "2024-10-03T09:28:48+00:00",
          "link": "https://arxiv.org/abs/2410.01697v2",
          "size": "409kb",
          "version": "v2"
        },
        {
          "date": "2024-12-13T16:55:33+00:00",
          "link": "https://arxiv.org/abs/2410.01697v3",
          "size": "1606kb",
          "version": "v3"
        },
        {
          "date": "2025-06-29T20:23:44+00:00",
          "link": "https://arxiv.org/abs/2410.01697v4",
          "size": "1744kb",
          "version": "v4"
        }
      ],
      "title": "Enhancing Adversarial Robustness through Multi-Objective Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.01697",
        "HTML": "https://arxiv.org/html/2410.01697v4",
        "PDF": "https://arxiv.org/pdf/2410.01697"
      },
      "tasks": [
        "Adversarial Robustness",
        "Representation Learning"
      ],
      "repo_urls": [
        "https://github.com/salomonhotegni/MOREL"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.03145",
      "abstract": "Large language models (LLMs) fine-tuned with alignment techniques, such as reinforcement learning from human feedback, have been instrumental in developing some of the most capable AI systems to date. Despite their success, existing methods typically rely on simple binary labels, such as those indicating preferred outputs in pairwise preferences, which fail to capture the subtle differences in relative quality between pairs. To address this limitation, we introduce an approach called Margin Matching Preference Optimization (MMPO), which incorporates relative quality margins into optimization, leading to improved LLM policies and reward models. Specifically, given quality margins in pairwise preferences, we design soft target probabilities based on the Bradley-Terry model, which are then used to train models with the standard cross-entropy objective. Experiments with both human and AI feedback data demonstrate that MMPO consistently outperforms baseline methods, often by a substantial margin, on popular benchmarks including MT-bench and RewardBench. Notably, the 7B model trained with MMPO achieves state-of-the-art performance on RewardBench as of June 2024, outperforming other models of the same scale. Our analysis also shows that MMPO is more robust to overfitting, leading to better-calibrated models.",
      "authors": [
        "Kyuyoung Kim",
        "Ah Jeong Seo",
        "Hao Liu",
        "Jinwoo Shin",
        "Kimin Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-04T04:56:11+00:00",
          "link": "https://arxiv.org/abs/2410.03145v1",
          "size": "263kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T08:52:35+00:00",
          "link": "https://arxiv.org/abs/2410.03145v2",
          "size": "257kb",
          "version": "v2"
        }
      ],
      "title": "Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.03145",
        "HTML": "https://arxiv.org/html/2410.03145v2",
        "PDF": "https://arxiv.org/pdf/2410.03145"
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/kykim0/margin-matching-pref-opt"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.06735",
      "abstract": "Recent large language models (LLMs) have demonstrated remarkable generalization abilities in mathematics and logical reasoning tasks. Prior research indicates that LLMs pre-trained with programming language data exhibit high mathematical and reasoning abilities; however, this causal relationship has not been rigorously tested. Our research aims to verify which programming languages and features during pre-training affect logical inference performance. Specifically, we pre-trained decoder-based language models from scratch using datasets from ten programming languages (e.g., Python, C, Java) and three natural language datasets (Wikipedia, Fineweb, C4) under identical conditions. Thereafter, we evaluated the trained models in a few-shot in-context learning setting on logical reasoning tasks: FLD and bAbi, which do not require commonsense or world knowledge. The results demonstrate that nearly all models trained with programming languages consistently outperform those trained with natural languages, indicating that programming languages contain factors that elicit logic inference performance. In addition, we found that models trained with programming languages exhibit a better ability to follow instructions compared to those trained with natural languages. Further analysis reveals that the depth of Abstract Syntax Trees representing parsed results of programs also affects logical reasoning performance. These findings will offer insights into the essential elements of pre-training for acquiring the foundational abilities of LLMs.",
      "authors": [
        "Fumiya Uchiyama",
        "Takeshi Kojima",
        "Andrew Gambardella",
        "Qi Cao",
        "Yusuke Iwasawa",
        "Yutaka Matsuo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-09T10:13:13+00:00",
          "link": "https://arxiv.org/abs/2410.06735v1",
          "size": "661kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T13:44:16+00:00",
          "link": "https://arxiv.org/abs/2410.06735v2",
          "size": "281kb",
          "version": "v2"
        }
      ],
      "title": "Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.06735",
        "HTML": "https://arxiv.org/html/2410.06735v2",
        "PDF": "https://arxiv.org/pdf/2410.06735"
      },
      "tasks": [
        "In-Context Learning",
        "Logical Reasoning",
        "World Knowledge"
      ],
      "repo_urls": [
        "https://github.com/fumiyauchiyama/code_pretraining"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.08174",
      "abstract": "Multimodal Large Language Models (MLLMs) exhibit promising advancements across various tasks, yet they still encounter significant trustworthiness issues. Prior studies apply Split Conformal Prediction (SCP) in language modeling to construct prediction sets with statistical guarantees. However, these methods typically rely on internal model logits or are restricted to multiple-choice settings, which hampers their generalizability and adaptability in dynamic, open-ended environments. In this paper, we introduce TRON, a two-step framework for risk control and assessment, applicable to any MLLM that supports sampling in both open-ended and closed-ended scenarios. TRON comprises two main components: (1) a novel conformal score to sample response sets of minimum size, and (2) a nonconformity score to identify high-quality responses based on self-consistency theory, controlling the error rates by two specific risk levels. Furthermore, we investigate semantic redundancy in prediction sets within open-ended contexts for the first time, leading to a promising evaluation metric for MLLMs based on average set size. Our comprehensive experiments across four Video Question-Answering (VideoQA) datasets utilizing eight MLLMs show that TRON achieves desired error rates bounded by two user-specified risk levels. Additionally, deduplicated prediction sets maintain adaptiveness while being more efficient and stable for risk assessment under different risk levels.",
      "authors": [
        "Qingni Wang",
        "Tiantian Geng",
        "Zhiyuan Wang",
        "Teng Wang",
        "Bo Fu",
        "Feng Zheng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-10T17:50:42+00:00",
          "link": "https://arxiv.org/abs/2410.08174v1",
          "size": "4008kb",
          "version": "v1"
        },
        {
          "date": "2024-12-14T10:34:35+00:00",
          "link": "https://arxiv.org/abs/2410.08174v2",
          "size": "6548kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T15:19:19+00:00",
          "link": "https://arxiv.org/abs/2410.08174v3",
          "size": "5784kb",
          "version": "v3"
        }
      ],
      "title": "Sample then Identify: A General Framework for Risk Control and Assessment in Multimodal Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08174",
        "HTML": "https://arxiv.org/html/2410.08174v3",
        "PDF": "https://arxiv.org/pdf/2410.08174"
      },
      "tasks": [
        "Conformal Prediction",
        "Language Modeling",
        "Language Modelling",
        "Multiple-choice",
        "Prediction",
        "Question Answering",
        "Video Question Answering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.09432",
      "abstract": "Low-Rank Adaptation (LoRA) is a popular technique for efficient fine-tuning of foundation models. However, applying LoRA in federated learning environments, where data is distributed across multiple clients, presents unique challenges. Existing methods rely on traditional federated averaging of LoRA adapters, resulting in inexact updates. To address this, we propose Federated Exact LoRA, or FedEx-LoRA, which adds a residual error term to the pretrained frozen weight matrix. Our approach achieves exact updates with minimal computational and communication overhead, preserving LoRA's efficiency. We evaluate the method on various models across arithmetic reasoning, commonsense reasoning, natural language understanding and natural language generation tasks, showing consistent performance gains over state-of-the-art methods across multiple settings. Through extensive analysis, we quantify that the deviations in updates from the ideal solution are significant, highlighting the need for exact aggregation. Our method's simplicity, efficiency, and broad applicability position it as a promising solution for accurate and effective federated fine-tuning of foundation models. Our code is publicly available at https://github.com/RaghavSinghal10/fedex-lora.",
      "authors": [
        "Raghav Singhal",
        "Kaustubh Ponkshe",
        "Praneeth Vepakomma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Computation and Language (cs.CL)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-12T08:22:44+00:00",
          "link": "https://arxiv.org/abs/2410.09432v1",
          "size": "1170kb",
          "version": "v1"
        },
        {
          "date": "2024-11-29T15:47:03+00:00",
          "link": "https://arxiv.org/abs/2410.09432v2",
          "size": "1176kb",
          "version": "v2"
        },
        {
          "date": "2025-02-07T19:41:49+00:00",
          "link": "https://arxiv.org/abs/2410.09432v3",
          "size": "1176kb",
          "version": "v3"
        },
        {
          "date": "2025-06-30T07:53:38+00:00",
          "link": "https://arxiv.org/abs/2410.09432v4",
          "size": "1170kb",
          "version": "v4"
        }
      ],
      "title": "FedEx-LoRA: Exact Aggregation for Federated and Efficient Fine-Tuning of Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.09432",
        "HTML": "https://arxiv.org/html/2410.09432v4",
        "PDF": "https://arxiv.org/pdf/2410.09432"
      },
      "tasks": [
        "Arithmetic Reasoning",
        "Federated Learning",
        "Natural Language Understanding",
        "Text Generation"
      ],
      "repo_urls": [
        "https://github.com/CERT-Lab/fed-sb",
        "https://github.com/RaghavSinghal10/fedex-lora"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.10105",
      "abstract": "In the realm of high-resolution (HR), fine-grained image segmentation, the primary challenge is balancing broad contextual awareness with the precision required for detailed object delineation, capturing intricate details and the finest edges of objects. Diffusion models, trained on vast datasets comprising billions of image-text pairs, such as SD V2.1, have revolutionized text-to-image synthesis by delivering exceptional quality, fine detail resolution, and strong contextual awareness, making them an attractive solution for high-resolution image segmentation. To this end, we propose DiffDIS, a diffusion-driven segmentation model that taps into the potential of the pre-trained U-Net within diffusion models, specifically designed for high-resolution, fine-grained object segmentation. By leveraging the robust generalization capabilities and rich, versatile image representation prior of the SD models, coupled with a task-specific stable one-step denoising approach, we significantly reduce the inference time while preserving high-fidelity, detailed generation. Additionally, we introduce an auxiliary edge generation task to not only enhance the preservation of fine details of the object boundaries, but reconcile the probabilistic nature of diffusion with the deterministic demands of segmentation. With these refined strategies in place, DiffDIS serves as a rapid object mask generation model, specifically optimized for generating detailed binary maps at high resolutions, while demonstrating impressive accuracy and swift processing. Experiments on the DIS5K dataset demonstrate the superiority of DiffDIS, achieving state-of-the-art results through a streamlined inference process. The source code will be publicly available at https://github.com/qianyu-dlut/DiffDIS.",
      "authors": [
        "Qian Yu",
        "Peng-Tao Jiang",
        "Hao Zhang",
        "Jinwei Chen",
        "Bo Li",
        "Lihe Zhang",
        "Huchuan Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-14T02:49:23+00:00",
          "link": "https://arxiv.org/abs/2410.10105v1",
          "size": "5673kb",
          "version": "v1"
        },
        {
          "date": "2025-02-28T09:44:00+00:00",
          "link": "https://arxiv.org/abs/2410.10105v2",
          "size": "12974kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T02:27:51+00:00",
          "link": "https://arxiv.org/abs/2410.10105v3",
          "size": "3926kb",
          "version": "v3"
        }
      ],
      "title": "High-Precision Dichotomous Image Segmentation via Probing Diffusion Capacity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.10105",
        "HTML": "https://arxiv.org/html/2410.10105v3",
        "PDF": "https://arxiv.org/pdf/2410.10105"
      },
      "conference": "high-precision-dichotomous-image-segmentation-1",
      "conference_url_abs": "https://openreview.net/forum?id=vh1e2WJfZp&noteId=vh1e2WJfZp",
      "tasks": [
        "Denoising",
        "Dichotomous Image Segmentation",
        "Image Generation",
        "Image Segmentation",
        "Object",
        "Segmentation",
        "Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/qianyu-dlut/DiffDIS"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.10360",
      "abstract": "Retrieval-Augmented Generation (RAG) offers an effective solution to the issues faced by Large Language Models (LLMs) in hallucination generation and knowledge obsolescence by incorporating externally retrieved knowledge. However, existing methods lack effective control mechanisms for integrating internal and external knowledge. Inspired by human cognitive processes, we propose Parenting, a novel framework that decouples, identifies, and purposefully optimizes parameter subspaces related to adherence and robustness. Specifically, Parenting utilizes a key parameter mining method that combines forward and backward propagation signals to localize subspaces representing different capabilities. Then, Parenting employs a type-tailored tuning strategy, applying specific and appropriate optimizations to different subspaces, aiming to achieve a balanced enhancement of both adherence and robustness. Extensive experiments on various datasets and models validate the effectiveness and generalizability of our method.",
      "authors": [
        "Yongxin Xu",
        "Ruizhe Zhang",
        "Xinke Jiang",
        "Yujie Feng",
        "Yuzhen Xiao",
        "Xinyu Ma",
        "Runchuan Zhu",
        "Xu Chu",
        "Junfeng Zhao",
        "Yasha Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-14T10:26:57+00:00",
          "link": "https://arxiv.org/abs/2410.10360v1",
          "size": "1311kb",
          "version": "v1"
        },
        {
          "date": "2024-10-20T07:53:50+00:00",
          "link": "https://arxiv.org/abs/2410.10360v2",
          "size": "2388kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T02:12:43+00:00",
          "link": "https://arxiv.org/abs/2410.10360v3",
          "size": "2400kb",
          "version": "v3"
        }
      ],
      "title": "Parenting: Optimizing Knowledge Selection of Retrieval-Augmented Language Models with Parameter Decoupling and Tailored Tuning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.10360",
        "HTML": "https://arxiv.org/html/2410.10360v3",
        "PDF": "https://arxiv.org/pdf/2410.10360"
      },
      "tasks": [
        "Hallucination",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.11301",
      "abstract": "Exploring new knowledge is a fundamental human ability that can be mirrored in the development of deep neural networks, especially in the field of object detection. Open world object detection (OWOD) is an emerging area of research that adapts this principle to explore new knowledge. It focuses on recognizing and learning from objects absent from initial training sets, thereby incrementally expanding its knowledge base when new class labels are introduced. This survey paper offers a thorough review of the OWOD domain, covering essential aspects, including problem definitions, benchmark datasets, source codes, evaluation metrics, and a comparative study of existing methods. Additionally, we investigate related areas like open set recognition (OSR) and incremental learning (IL), underlining their relevance to OWOD. Finally, the paper concludes by addressing the limitations and challenges faced by current OWOD algorithms and proposes directions for future research. To our knowledge, this is the first comprehensive survey of the emerging OWOD field with over one hundred references, marking a significant step forward for object detection technology. A comprehensive source code and benchmarks are archived and concluded at https://github.com/ArminLee/OWOD Review.",
      "authors": [
        "Yiming Li",
        "Yi Wang",
        "Wenqian Wang",
        "Dan Lin",
        "Bingbing Li",
        "Kim-Hui Yap"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-15T05:46:00+00:00",
          "link": "https://arxiv.org/abs/2410.11301v1",
          "size": "10272kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T12:17:40+00:00",
          "link": "https://arxiv.org/abs/2410.11301v2",
          "size": "10095kb",
          "version": "v2"
        }
      ],
      "title": "Open World Object Detection: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.11301",
        "HTML": "https://arxiv.org/html/2410.11301v2",
        "PDF": "https://arxiv.org/pdf/2410.11301"
      },
      "tasks": [
        "Incremental Learning",
        "Object",
        "object-detection",
        "Object Detection",
        "Open Set Learning",
        "Open World Object Detection",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.15441",
      "abstract": "In this work, we provide a global condition for contraction with respect to an invariant Riemannian metric on reductive homogeneous spaces. Using left-invariant frames, vector fields on the manifold are horizontally lifted to the ambient Lie group, where the Levi-Civita connection is globally characterized as a real matrix multiplication. By linearizing in these left-invariant frames, we characterize contraction using matrix measures on real square matrices, avoiding the use of local charts. Applying this global condition, we provide a necessary condition for a prescribed subset of the manifold to possibly admit a contracting system, which accounts for the underlying geometry of the invariant metric. Applied to the sphere, this condition implies that no great circle can be contained in a contraction region. Finally, we apply our results to compute reachable sets for an attitude control problem.",
      "authors": [
        "Akash Harapanahalli and Samuel Coogan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-20T16:22:59+00:00",
          "link": "https://arxiv.org/abs/2410.15441v1",
          "size": "2173kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T16:21:56+00:00",
          "link": "https://arxiv.org/abs/2410.15441v2",
          "size": "2173kb",
          "version": "v2"
        }
      ],
      "title": "A Global Coordinate-Free Approach to Invariant Contraction on Homogeneous Manifolds",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.15441",
        "HTML": "https://arxiv.org/html/2410.15441v2",
        "PDF": "https://arxiv.org/pdf/2410.15441"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2410.17218",
      "abstract": "Creativity is the ability to produce novel, useful, and surprising ideas, and has been widely studied as a crucial aspect of human cognition. Machine creativity on the other hand has been a long-standing challenge. With the rise of advanced generative AI, there has been renewed interest and debate regarding AI's creative capabilities. Therefore, it is imperative to revisit the state of creativity in AI and identify key progresses and remaining challenges. In this work, we survey leading works studying the creative capabilities of AI systems, focusing on creative problem-solving, linguistic, artistic, and scientific creativity. Our review suggests that while the latest AI models are largely capable of producing linguistically and artistically creative outputs such as poems, images, and musical pieces, they struggle with tasks that require creative problem-solving, abstract thinking and compositionality and their generations suffer from a lack of diversity, originality, long-range incoherence and hallucinations. We also discuss key questions concerning copyright and authorship issues with generative models. Furthermore, we highlight the need for a comprehensive evaluation of creativity that is process-driven and considers several dimensions of creativity. Finally, we propose future research directions to improve the creativity of AI outputs, drawing inspiration from cognitive science and psychology.",
      "authors": [
        "Mete Ismayilzada",
        "Debjit Paul",
        "Antoine Bosselut",
        "Lonneke van der Plas"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-22T17:43:39+00:00",
          "link": "https://arxiv.org/abs/2410.17218v1",
          "size": "2873kb",
          "version": "v1"
        },
        {
          "date": "2024-10-24T18:25:15+00:00",
          "link": "https://arxiv.org/abs/2410.17218v2",
          "size": "2876kb",
          "version": "v2"
        },
        {
          "date": "2024-11-27T15:22:29+00:00",
          "link": "https://arxiv.org/abs/2410.17218v3",
          "size": "2892kb",
          "version": "v3"
        },
        {
          "date": "2024-12-09T12:45:53+00:00",
          "link": "https://arxiv.org/abs/2410.17218v4",
          "size": "2890kb",
          "version": "v4"
        },
        {
          "date": "2025-06-29T16:35:17+00:00",
          "link": "https://arxiv.org/abs/2410.17218v5",
          "size": "2454kb",
          "version": "v5"
        }
      ],
      "title": "Creativity in AI: Progresses and Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.17218",
        "HTML": "https://arxiv.org/html/2410.17218v5",
        "PDF": "https://arxiv.org/pdf/2410.17218"
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/mismayil/creativity-in-AI"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.17711",
      "abstract": "As large language models (LLMs) are widely applied across various fields, model compression has become increasingly crucial for reducing costs and improving inference efficiency. Post-training pruning is a promising method that does not require resource-intensive iterative training and only needs a small amount of calibration data to assess the importance of parameters. Recent research has enhanced post-training pruning from different aspects but few of them systematically explore the effects of calibration data, and it is unclear if there exist better calibration data construction strategies. We fill this blank and surprisingly observe that calibration data is also crucial to post-training pruning, especially for high sparsity. Through controlled experiments on important influence factors of calibration data, including the pruning settings, the amount of data, and its similarity with pre-training data, we observe that a small size of data is adequate, and more similar data to its pre-training stage can yield better performance. As pre-training data is usually inaccessible for advanced LLMs, we further provide a self-generating calibration data synthesis strategy to construct feasible calibration data. Experimental results on recent strong open-source LLMs (e.g., DCLM, and LLaMA-3) show that the proposed strategy can enhance the performance of strong pruning methods (e.g., Wanda, DSnoT, OWL) by a large margin (up to $2.68\\%$). Code is available at https://github.com/Dereck0602/calibration_data.",
      "authors": [
        "Yixin Ji",
        "Yang Xiang",
        "Juntao Li",
        "Qingrong Xia",
        "Ping Li",
        "Xinyu Duan",
        "Zhefeng Wang",
        "Min Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-23T09:36:21+00:00",
          "link": "https://arxiv.org/abs/2410.17711v1",
          "size": "730kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T07:21:34+00:00",
          "link": "https://arxiv.org/abs/2410.17711v2",
          "size": "218kb",
          "version": "v2"
        }
      ],
      "title": "Beware of Calibration Data for Pruning Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.17711",
        "HTML": "https://arxiv.org/html/2410.17711v2",
        "PDF": "https://arxiv.org/pdf/2410.17711"
      },
      "tasks": [
        "Model Compression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.19504",
      "abstract": "Dimensionality reduction (DR) plays a crucial role in various fields, including data engineering and visualization, by simplifying complex datasets while retaining essential information. However, achieving both high DR accuracy and strong explainability remains a fundamental challenge, especially for users dealing with high-dimensional data. Traditional DR methods often face a trade-off between precision and transparency, where optimizing for performance can lead to reduced explainability, and vice versa. This limitation is especially prominent in real-world applications such as image, tabular, and text data analysis, where both accuracy and explainability are critical. To address these challenges, this work introduces the MOE-based Explainable Deep Manifold Transformation (DMT-ME). The proposed approach combines hyperbolic embeddings, which effectively capture complex hierarchical structures, with Mixture of Experts (MOE) models, which dynamically allocate tasks based on input features. DMT-ME enhances DR accuracy by leveraging hyperbolic embeddings to represent the hierarchical nature of data, while also improving explainability by explicitly linking input data, embedding outcomes, and key features through the MOE structure. Extensive experiments demonstrate that DMT-ME consistently achieves superior performance in both DR accuracy and model explainability, making it a robust solution for complex data analysis. The code is available at https://github.com/zangzelin/code_dmtme",
      "authors": [
        "Zelin Zang",
        "Yuhao Wang",
        "Jinlin Wu",
        "Hong Liu",
        "Yue Shen",
        "Zhen Lei",
        "Stan.Z Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-25T12:11:32+00:00",
          "link": "https://arxiv.org/abs/2410.19504v1",
          "size": "43748kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T13:59:31+00:00",
          "link": "https://arxiv.org/abs/2410.19504v2",
          "size": "39443kb",
          "version": "v2"
        }
      ],
      "title": "MOE-Enhanced Explanable Deep Manifold Transformation for Complex Data Embedding and Visualization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.19504",
        "HTML": "https://arxiv.org/html/2410.19504v2",
        "PDF": "https://arxiv.org/pdf/2410.19504"
      },
      "tasks": [
        "Dimensionality Reduction",
        "Mixture-of-Experts"
      ],
      "repo_urls": [
        "https://github.com/zangzelin/code_dmthi"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.21896",
      "abstract": "Symbolic Regression remains an NP-Hard problem, with extensive research focusing on AI models for this task. Transformer models have shown promise in Symbolic Regression, but performance suffers with smaller datasets. We propose applying k-fold cross-validation to a transformer-based symbolic regression model trained on a significantly reduced dataset (15,000 data points, down from 500,000). This technique partitions the training data into multiple subsets (folds), iteratively training on some while validating on others. Our aim is to provide an estimate of model generalization and mitigate overfitting issues associated with smaller datasets. Results show that this process improves the model's output consistency and generalization by a relative improvement in validation loss of 53.31%. Potentially enabling more efficient and accessible symbolic regression in resource-constrained environments.",
      "authors": [
        "Kaustubh Kislay",
        "Shlok Singh",
        "Soham Joshi",
        "Rohan Dutta",
        "Jay Shim",
        "George Flint",
        "Kevin Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-29T09:39:54+00:00",
          "link": "https://arxiv.org/abs/2410.21896v1",
          "size": "1648kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T08:45:26+00:00",
          "link": "https://arxiv.org/abs/2410.21896v2",
          "size": "246kb",
          "version": "v2"
        }
      ],
      "title": "Evaluating K-Fold Cross Validation for Transformer Based Symbolic Regression Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.21896",
        "HTML": "https://arxiv.org/html/2410.21896v2",
        "PDF": "https://arxiv.org/pdf/2410.21896"
      },
      "tasks": [
        "regression",
        "Symbolic Regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.22686",
      "abstract": "In this work, we propose a novel diagonalization-based preconditioner for the all-at-once linear system arising from the optimal control problem of parabolic equations. The proposed preconditioner is constructed based on an $\\epsilon$-circulant modification to the rotated block diagonal (RBD) preconditioning technique and can be efficiently diagonalized by fast Fourier transforms in a parallel-in-time fashion. To our knowledge, this marks the first application of the $\\epsilon$-circulant modification to RBD preconditioning. Before our work, the studies of parallel-in-time preconditioning techniques for the optimal control problem are mainly focused on $\\epsilon$-circulant modification to Schur complement based preconditioners, which involves multiplication of forward and backward evolutionary processes and thus square the condition number. Compared with those Schur complement based preconditioning techniques in the literature, the advantage of the proposed $\\epsilon$-circulant modified RBD preconditioning is that it does not involve the multiplication of forward and backward evolutionary processes. When the generalized minimal residual method is deployed on the preconditioned system, we prove that when choosing $\\epsilon=\\mathcal{O}(\\sqrt{\\tau})$ with $\\tau$ being the temporal step-size, the convergence rate of the preconditioned GMRES solver is independent of the matrix size and the regularization parameter. Numerical results are provided to demonstrate the effectiveness of our proposed solvers.",
      "authors": [
        "Sean Y. Hon",
        "Po Yin Fung",
        "Xue-lei Lin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-30T04:45:30+00:00",
          "link": "https://arxiv.org/abs/2410.22686v1",
          "size": "42kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T08:44:25+00:00",
          "link": "https://arxiv.org/abs/2410.22686v2",
          "size": "65kb",
          "version": "v2"
        }
      ],
      "title": "An optimal diagonalization-based preconditioner for parabolic optimal control problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.22686",
        "HTML": "https://arxiv.org/html/2410.22686v2",
        "PDF": "https://arxiv.org/pdf/2410.22686"
      },
      "source": "arXiv"
    },
    {
      "id": "2411.01600",
      "abstract": "Accurately predicting long-horizon molecular dynamics (MD) trajectories remains a significant challenge, as existing deep learning methods often struggle to retain fidelity over extended simulations. We hypothesize that one key factor limiting accuracy is the difficulty of capturing interactions that span distinct spatial and temporal scales, ranging from high-frequency local vibrations to low-frequency global conformational changes. To address these limitations, we propose Graph Fourier Neural ODEs (GF-NODE), integrating a graph Fourier transform for spatial frequency decomposition with a Neural ODE framework for continuous-time evolution. Specifically, GF-NODE first decomposes molecular configurations into multiple spatial frequency modes using the graph Laplacian, then evolves the frequency components in time via a learnable Neural ODE module that captures both local and global dynamics, and finally reconstructs the updated molecular geometry through an inverse graph Fourier transform. By explicitly modeling high- and low-frequency phenomena in this unified pipeline, GF-NODE captures long-range correlations and local fluctuations more effectively. We provide theoretical insight through heat equation analysis on a simplified diffusion model, demonstrating how graph Laplacian eigenvalues can determine temporal dynamics scales, and crucially validate this correspondence through comprehensive empirical analysis on real molecular dynamics trajectories showing quantitative spatial-temporal correlations across diverse molecular systems. Experimental results on challenging MD benchmarks demonstrate that GF-NODE achieves state-of-the-art accuracy while preserving essential geometrical features over extended simulations. These findings highlight the promise of bridging spectral decomposition with continuous-time modeling to improve the robustness and predictive power of MD simulations.",
      "authors": [
        "Fang Sun",
        "Zijie Huang",
        "Haixin Wang",
        "Huacong Tang",
        "Xiao Luo",
        "Wei Wang",
        "Yizhou Sun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Chemical Physics (physics.chem-ph)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-03T15:10:48+00:00",
          "link": "https://arxiv.org/abs/2411.01600v1",
          "size": "306kb",
          "version": "v1"
        },
        {
          "date": "2025-03-13T21:08:29+00:00",
          "link": "https://arxiv.org/abs/2411.01600v2",
          "size": "831kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T00:11:13+00:00",
          "link": "https://arxiv.org/abs/2411.01600v3",
          "size": "6359kb",
          "version": "v3"
        }
      ],
      "title": "Graph Fourier Neural ODEs: Modeling Spatial-temporal Multi-scales in Molecular Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.01600",
        "HTML": "https://arxiv.org/html/2411.01600v3",
        "PDF": "https://arxiv.org/pdf/2411.01600"
      },
      "tasks": [
        "Computational chemistry",
        "Drug Discovery"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.02058",
      "abstract": "A data-driven approach based on unsupervised machine learning is proposed to infer the intrinsic dimension $m^{\\ast}$ of the high-dimensional trajectories of the Fermi-Pasta-Ulam-Tsingou (FPUT) model. Principal component analysis (PCA) is applied to trajectory data consisting of $n_s = 4,000,000$ datapoints, of the FPUT $\\beta$ model with $N = 32$ coupled oscillators, revealing a critical relationship between $m^{\\ast}$ and the model's nonlinear strength. By estimating the intrinsic dimension $m^{\\ast}$ using multiple methods (participation ratio, Kaiser rule, and the Kneedle algorithm), it is found that $m^{\\ast}$ increases with the model nonlinearity. Interestingly, in the weakly nonlinear regime, for trajectories initialized by exciting the first mode, the participation ratio estimates $m^{\\ast} = 2, 3$, strongly suggesting that quasi-periodic motion on a low-dimensional Riemannian manifold underlies the characteristic energy recurrences observed in the FPUT model.",
      "authors": [
        "Gionni Marchetti"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Statistical Mechanics (cond-mat.stat-mech)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-04T13:01:13+00:00",
          "link": "https://arxiv.org/abs/2411.02058v1",
          "size": "3484kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T14:49:26+00:00",
          "link": "https://arxiv.org/abs/2411.02058v2",
          "size": "2448kb",
          "version": "v2"
        }
      ],
      "title": "Intrinsic Dimensionality of Fermi-Pasta-Ulam-Tsingou High-Dimensional Trajectories Through Manifold Learning: A Linear Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.02058",
        "HTML": "https://arxiv.org/html/2411.02058v2",
        "PDF": "https://arxiv.org/pdf/2411.02058"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2411.02335",
      "abstract": "Activation sparsity denotes the existence of substantial weakly-contributed elements within activation outputs that can be eliminated, benefiting many important applications concerned with large language models (LLMs). Although promoting greater activation sparsity within LLMs deserves deep studies, existing works lack comprehensive and quantitative research on the correlation between activation sparsity and potentially influential factors. In this paper, we present a comprehensive study on the quantitative scaling properties and influential factors of the activation sparsity within decoder-only Transformer-based LLMs. Specifically, we propose PPL-$p\\%$ sparsity, a precise and performance-aware activation sparsity metric that is applicable to any activation function. Through extensive experiments, we find several important phenomena. Firstly, different activation functions exhibit comparable performance but opposite training-time sparsity trends. The activation ratio (i.e., $1-\\mathrm{sparsity\\ ratio}$) evolves as a convergent increasing power-law and decreasing logspace power-law with the amount of training data for SiLU-activated and ReLU-activated LLMs, respectively. These demonstrate that ReLU is more efficient as the activation function than SiLU and can leverage more training data to improve activation sparsity. Secondly, the activation ratio linearly increases with the width-depth ratio below a certain bottleneck point, indicating the potential advantage of a deeper architecture at a fixed parameter scale. Finally, at similar width-depth ratios, we surprisingly find that the limit value of activation sparsity varies weakly with the parameter scale, i.e., the activation patterns within LLMs are insensitive to the parameter scale. These empirical laws towards LLMs with greater activation sparsity have important implications for making LLMs more efficient and interpretable.",
      "authors": [
        "Yuqi Luo",
        "Chenyang Song",
        "Xu Han",
        "Yingfa Chen",
        "Chaojun Xiao",
        "Xiaojun Meng",
        "Liqun Deng",
        "Jiansheng Wei",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-04T17:59:04+00:00",
          "link": "https://arxiv.org/abs/2411.02335v1",
          "size": "1168kb",
          "version": "v1"
        },
        {
          "date": "2025-02-26T07:39:03+00:00",
          "link": "https://arxiv.org/abs/2411.02335v2",
          "size": "1204kb",
          "version": "v2"
        },
        {
          "date": "2025-05-16T07:29:10+00:00",
          "link": "https://arxiv.org/abs/2411.02335v3",
          "size": "1188kb",
          "version": "v3"
        },
        {
          "date": "2025-06-30T09:50:52+00:00",
          "link": "https://arxiv.org/abs/2411.02335v4",
          "size": "1168kb",
          "version": "v4"
        }
      ],
      "title": "Sparsing Law: Towards Large Language Models with Greater Activation Sparsity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.02335",
        "HTML": "https://arxiv.org/html/2411.02335v4",
        "PDF": "https://arxiv.org/pdf/2411.02335"
      },
      "models": [
        {
          "model_path": "SparseLLM/sparsing-law-0.1b-relu",
          "downloads": "78",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/SparseLLM/sparsing-law-0.1b-relu"
        },
        {
          "model_path": "SparseLLM/sparsing-law-0.1b-silu",
          "downloads": "96",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/SparseLLM/sparsing-law-0.1b-silu"
        },
        {
          "model_path": "SparseLLM/sparsing-law-0.2b-relu",
          "downloads": "17",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/SparseLLM/sparsing-law-0.2b-relu"
        },
        {
          "model_path": "SparseLLM/sparsing-law-0.8b-relu",
          "downloads": "15",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/SparseLLM/sparsing-law-0.8b-relu"
        },
        {
          "model_path": "SparseLLM/sparsing-law-0.4b-relu",
          "downloads": "34",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/SparseLLM/sparsing-law-0.4b-relu"
        },
        {
          "model_path": "SparseLLM/sparsing-law-1.2b-relu",
          "downloads": "14",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/SparseLLM/sparsing-law-1.2b-relu"
        },
        {
          "model_path": "SparseLLM/sparsing-law-0.2b-silu",
          "downloads": "16",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/SparseLLM/sparsing-law-0.2b-silu"
        },
        {
          "model_path": "SparseLLM/sparsing-law-0.4b-silu",
          "downloads": "17",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/SparseLLM/sparsing-law-0.4b-silu"
        },
        {
          "model_path": "SparseLLM/sparsing-law-0.8b-silu",
          "downloads": "16",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/SparseLLM/sparsing-law-0.8b-silu"
        },
        {
          "model_path": "SparseLLM/sparsing-law-1.2b-silu",
          "downloads": "34",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/SparseLLM/sparsing-law-1.2b-silu"
        },
        {
          "model_path": "SparseLLM/sparsing-law-2.4b-relu",
          "downloads": "21",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/SparseLLM/sparsing-law-2.4b-relu"
        }
      ],
      "tasks": [],
      "repo_urls": [
        "https://github.com/thunlp/SparsingLaw"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.02608",
      "abstract": "Robotic cloth manipulation faces challenges due to the fabric's complex dynamics and the high dimensionality of configuration spaces. Previous methods have largely focused on isolated smoothing or folding tasks and overly reliant on simulations, often failing to bridge the significant sim-to-real gap in deformable object manipulation. To overcome these challenges, we propose a two-stream architecture with sequential and spatial pathways, unifying smoothing and folding tasks into a single adaptable policy model that accommodates various cloth types and states. The sequential stream determines the pick and place positions for the cloth, while the spatial stream, using a connectivity dynamics model, constructs a visibility graph from partial point cloud data of the self-occluded cloth, allowing the robot to infer the cloth's full configuration from incomplete observations. To bridge the sim-to-real gap, we utilize a hand tracking detection algorithm to gather and integrate human demonstration data into our novel end-to-end neural network, improving real-world adaptability. Our method, validated on a UR5 robot across four distinct cloth folding tasks with different goal shapes, consistently achieves folded states from arbitrary crumpled initial configurations, with success rates of 99\\%, 99\\%, 83\\%, and 67\\%. It outperforms existing state-of-the-art cloth manipulation techniques and demonstrates strong generalization to unseen cloth with diverse colors, shapes, and stiffness in real-world experiments.Videos and source code are available at: https://zcswdt.github.io/SSFold/",
      "authors": [
        "Changshi Zhou",
        "Haichuan Xu",
        "Jiarui Hu",
        "Feng Luan",
        "Zhipeng Wang",
        "Yanchao Dong",
        "Yanmin Zhou",
        "Bin He"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-24T11:40:40+00:00",
          "link": "https://arxiv.org/abs/2411.02608v1",
          "size": "58356kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T07:14:28+00:00",
          "link": "https://arxiv.org/abs/2411.02608v2",
          "size": "14492kb",
          "version": "v2"
        }
      ],
      "title": "SSFold: Learning to Fold Arbitrary Crumpled Cloth Using Graph Dynamics from Human Demonstration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.02608",
        "HTML": "https://arxiv.org/html/2411.02608v2",
        "PDF": "https://arxiv.org/pdf/2411.02608"
      },
      "source": "arXiv"
    },
    {
      "id": "2411.05087",
      "abstract": "Existing innovation metrics inadequately capture software innovation, creating blind spots for researchers and policymakers seeking to understand and foster technological innovation in an increasingly software-defined economy. This paper introduces a novel measure of software innovation based on open source software (OSS) development activity on GitHub. We examine the dependency growth and release complexity among 350,000 unique releases from 33,000 unique packages across the JavaScript, Python, and Ruby ecosystems over two years post-release. We find that the semantic versioning types of OSS releases exhibit ecosystem-specific and maturity-dependent patterns in predicting one-year dependency growth, with minor releases showing relatively consistent adoption across contexts while major and patch releases vary significantly by ecosystem and package size. In addition, while semantic versioning correlates with the technical complexity of the change-set, complexity itself shows minimal correlation with downstream adoption, suggesting that versioning signals rather than technical change drive dependency growth. Overall, while semantic versioning release information can be used as a unit of innovation in OSS development complementary to common sources for innovation metrics (e.g. scientific publications, patents, and standards), this measure should be weighted by ecosystem culture, package maturity, and release type to accurately capture innovation dynamics. We conclude with a discussion of the theoretical and practical implications of this novel measure of software innovation as well as future research directions.",
      "authors": [
        "Eva Maxfield Brown",
        "Cailean Osborne",
        "Peter Cihon",
        "Moritz B\\\"ohmecke-Schwafert",
        "Kevin Xu",
        "Mirko Boehm",
        "and Knut Blind"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-07T19:11:32+00:00",
          "link": "https://arxiv.org/abs/2411.05087v1",
          "size": "342kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T14:52:27+00:00",
          "link": "https://arxiv.org/abs/2411.05087v2",
          "size": "751kb",
          "version": "v2"
        }
      ],
      "title": "Measuring Software Innovation with Open Source Software Development Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.05087",
        "HTML": "https://arxiv.org/html/2411.05087v2",
        "PDF": "https://arxiv.org/pdf/2411.05087"
      },
      "repo_urls": [
        "https://github.com/evamaxfield/dg-uoi-analysis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.06197",
      "abstract": "Multi-object tracking (MOT) is dominated by two paradigms: tracking-by-detection (TBD) and tracking-by-query (TBQ). While TBD is decoupled and efficient, its fragmented association steps and heuristic matching pipelines often compromise robustness in complex scenarios. TBQ provides stronger semantic modeling through end-to-end learning, but suffers from high training cost and slow inference due to tight coupling between detection and association. To address these challenges, we propose TBDQ-Net, a unified tracking-by-detection-and-query (TBDQ) framework that effectively combines the strengths of both paradigms. Our method efficiently integrates pretrained, high-performance detectors with an MOT-tailored associator. The associator is lightweight and directly fetches information from the inference of detectors, enhancing the overall efficiency of the framework. The associator is also learnable, making it essential for fully end-to-end optimization, ensuring robust tracking capabilities. Specifically, the associator comprises two key modules: basic information interaction (BII) for comprehensive semantic interaction, and content-position alignment (CPA) for semantic and positional consistency. TBDQ-Net's effectiveness is extensively demonstrated on DanceTrack, SportsMOT and MOT20 benchmarks. As a structurally efficient and semantically robust tracking framework, it outperforms the leading TBD method by 6.0 IDF1 points on DanceTrack and achieves at least 37.5% faster inference than prominent TBQ methods.",
      "authors": [
        "Shukun Jia",
        "Shiyu Hu",
        "Yichao Cao",
        "Feng Yang",
        "Xin Lu",
        "Xiaobo Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-09T14:38:08+00:00",
          "link": "https://arxiv.org/abs/2411.06197v1",
          "size": "1149kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T02:52:56+00:00",
          "link": "https://arxiv.org/abs/2411.06197v2",
          "size": "3751kb",
          "version": "v2"
        }
      ],
      "title": "Tracking by Detection and Query: An Efficient End-to-End Framework for Multi-Object Tracking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.06197",
        "HTML": "https://arxiv.org/html/2411.06197v2",
        "PDF": "https://arxiv.org/pdf/2411.06197"
      },
      "tasks": [
        "Multi-Object Tracking",
        "Object Tracking"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.06660",
      "abstract": "Knowledge graph completion (KGC) is a task of inferring missing triples based on existing Knowledge Graphs (KGs). Both structural and semantic information are vital for successful KGC. However, existing methods only use either the structural knowledge from the KG embeddings or the semantic information from pre-trained language models (PLMs), leading to suboptimal model performance. Moreover, since PLMs are not trained on KGs, directly using PLMs to encode triples may be inappropriate. To overcome these limitations, we propose a novel framework called Bridge, which jointly encodes structural and semantic information of KGs. Specifically, we strategically encode entities and relations separately by PLMs to better utilize the semantic knowledge of PLMs and enable structured representation learning via a structural learning principle. Furthermore, to bridge the gap between KGs and PLMs, we employ a self-supervised representation learning method called BYOL to fine-tune PLMs with two different views of a triple. Unlike BYOL, which uses augmentation methods to create two semantically similar views of the same image, potentially altering the semantic information. We strategically separate the triple into two parts to create different views, thus avoiding semantic alteration. Experiments demonstrate that Bridge outperforms the SOTA models on three benchmark datasets.",
      "authors": [
        "Qiao Qiao",
        "Yuepei Li",
        "Qing Wang",
        "Kang Zhou",
        "Qi Li"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-11T01:59:04+00:00",
          "link": "https://arxiv.org/abs/2411.06660v1",
          "size": "1460kb",
          "version": "v1"
        },
        {
          "date": "2025-02-27T00:29:15+00:00",
          "link": "https://arxiv.org/abs/2411.06660v2",
          "size": "470kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T01:26:26+00:00",
          "link": "https://arxiv.org/abs/2411.06660v3",
          "size": "313kb",
          "version": "v3"
        }
      ],
      "title": "Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.06660",
        "HTML": "https://arxiv.org/html/2411.06660v3",
        "PDF": "https://arxiv.org/pdf/2411.06660"
      },
      "tasks": [
        "Knowledge Graph Completion",
        "Knowledge Graphs",
        "Representation Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.07186",
      "abstract": "Large language models (LLMs) prompted with text and audio have achieved state-of-the-art performance across various auditory tasks, including speech, music, and general audio, showing emergent abilities on unseen tasks. However, their potential has yet to be fully demonstrated in bioacoustics tasks, such as detecting animal vocalizations in large recordings, classifying rare and endangered species, and labeling context and behavior -- tasks that are crucial for conservation, biodiversity monitoring, and animal behavior studies. In this work, we present NatureLM-audio, the first audio-language foundation model specifically designed for bioacoustics. Our training dataset consists of carefully curated text-audio pairs spanning bioacoustics, speech, and music, designed to address the field's limited availability of annotated data. We demonstrate successful transfer of learned representations from music and speech to bioacoustics, and our model shows promising generalization to unseen taxa and tasks. We evaluate NatureLM-audio on a novel benchmark (BEANS-Zero) and it sets a new state of the art on several bioacoustics tasks, including zero-shot classification of unseen species. To advance bioacoustics research, we release our model weights, benchmark data, and open-source the code for training and benchmark data generation and model training.",
      "authors": [
        "David Robinson",
        "Marius Miron",
        "Masato Hagiwara",
        "Benno Weck",
        "Sara Keen",
        "Milad Alizadeh",
        "Gagan Narula",
        "Matthieu Geist",
        "Olivier Pietquin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-11T18:01:45+00:00",
          "link": "https://arxiv.org/abs/2411.07186v1",
          "size": "2384kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T00:58:43+00:00",
          "link": "https://arxiv.org/abs/2411.07186v2",
          "size": "5564kb",
          "version": "v2"
        }
      ],
      "title": "NatureLM-audio: an Audio-Language Foundation Model for Bioacoustics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.07186",
        "HTML": "https://arxiv.org/html/2411.07186v2",
        "PDF": "https://arxiv.org/pdf/2411.07186"
      },
      "models": [
        {
          "model_path": "EarthSpeciesProject/NatureLM-audio",
          "downloads": "413",
          "likes": "8",
          "trending_score": "1.0",
          "link": "https://huggingface.co/EarthSpeciesProject/NatureLM-audio"
        }
      ],
      "datasets": [
        {
          "dataset_name": "EarthSpeciesProject/NatureLM-audio-training",
          "downloads": "3829",
          "likes": "5",
          "link": "https://huggingface.co/datasets/EarthSpeciesProject/NatureLM-audio-training"
        }
      ],
      "tasks": [
        "Zero-Shot Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.07347",
      "abstract": "We study the problem of determining the minimal genus of a simple finite connected graph. We present an algorithm which, for an arbitrary graph $G$ with $n$ vertices and $m$ edges, determines the orientable genus of $G$ in $O(n(4^m/n)^{n/t})$ steps where $t$ is the girth of $G$. This algorithm avoids difficulties that many other genus algorithms have with handling bridge placements which is a well-known issue. The algorithm has a number of useful properties for practical use: it is simple to implement, it outputs the faces of an optimal embedding, and it iteratively narrows both upper and lower bounds. We illustrate the algorithm by determining the genus of the $(3,12)$ cage (which is 17); other graphs are also considered.",
      "authors": [
        "Alexander Metzger",
        "Austin Ulrigg"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-11T20:11:30+00:00",
          "link": "https://arxiv.org/abs/2411.07347v1",
          "size": "12976kb",
          "version": "v1"
        },
        {
          "date": "2024-11-15T09:32:01+00:00",
          "link": "https://arxiv.org/abs/2411.07347v2",
          "size": "12977kb",
          "version": "v2"
        },
        {
          "date": "2025-01-09T20:51:47+00:00",
          "link": "https://arxiv.org/abs/2411.07347v3",
          "size": "12977kb",
          "version": "v3"
        },
        {
          "date": "2025-06-29T05:50:36+00:00",
          "link": "https://arxiv.org/abs/2411.07347v4",
          "size": "4160kb",
          "version": "v4"
        }
      ],
      "title": "An Efficient Genus Algorithm Based on Graph Rotations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.07347",
        "HTML": "https://arxiv.org/html/2411.07347v4",
        "PDF": "https://arxiv.org/pdf/2411.07347"
      },
      "repo_urls": [
        "https://github.com/SanderGi/Genus"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.08482",
      "abstract": "In automated driving, object detection is crucial for perceiving the environment. Although deep learning-based detectors offer high performance, their black-box nature complicates safety assurance. We propose a novel methodology to analyze how object- and environment-related factors affect LiDAR- and camera-based 3D object detectors. A statistical univariate analysis relates each factor to pedestrian detection errors. Additionally, a Random Forest (RF) model predicts errors from meta-information, with Shapley Values interpreting feature importance. By capturing feature dependencies, the RF enables a nuanced analysis of detection errors. Understanding these factors reveals detector performance gaps and supports safer object detection system development.",
      "authors": [
        "Anton Kuznietsov",
        "Dirk Schweickard",
        "Steven Peters"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-13T10:01:33+00:00",
          "link": "https://arxiv.org/abs/2411.08482v1",
          "size": "868kb",
          "version": "v1"
        },
        {
          "date": "2025-02-01T02:05:35+00:00",
          "link": "https://arxiv.org/abs/2411.08482v2",
          "size": "4396kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T10:19:35+00:00",
          "link": "https://arxiv.org/abs/2411.08482v3",
          "size": "1905kb",
          "version": "v3"
        }
      ],
      "title": "Methodology for an Analysis of Influencing Factors on 3D Object Detection Performance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.08482",
        "HTML": "https://arxiv.org/html/2411.08482v3",
        "PDF": "https://arxiv.org/pdf/2411.08482"
      },
      "tasks": [
        "3D Object Detection",
        "Autonomous Driving",
        "Object",
        "object-detection",
        "Object Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.08870",
      "abstract": "Several recent works seek to adapt general-purpose large language models (LLMs) and vision-language models (VLMs) for medical applications through continued pretraining on publicly available biomedical corpora. These works typically claim that such domain-adaptive pretraining improves performance on various downstream medical tasks, such as answering medical exam questions. In this paper, we compare ten \"medical\" LLMs and two VLMs against their corresponding base models, arriving at a different conclusion: all medical VLMs and nearly all medical LLMs fail to consistently improve over their base models in the zero-/few-shot prompting and supervised fine-tuning regimes for medical question answering (QA). For instance, on clinical-note-based QA tasks in the 3-shot setting, medical LLMs outperform their base models in only 26.7% of cases, reach a (statistical) tie in 16.7% of cases, and perform significantly worse in the remaining 56.7% of cases. Our conclusions are based on (i) comparing each medical model directly against its base model; (ii) optimizing the prompts for each model separately in zero-/few-shot prompting; and (iii) accounting for statistical uncertainty in comparisons. Our findings suggest that state-of-the-art general-domain models may already exhibit strong medical knowledge and reasoning capabilities, and offer recommendations to strengthen the conclusions of future studies.",
      "authors": [
        "Daniel P. Jeong",
        "Pranav Mani",
        "Saurabh Garg",
        "Zachary C. Lipton",
        "Michael Oberst"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-13T18:50:13+00:00",
          "link": "https://arxiv.org/abs/2411.08870v1",
          "size": "1424kb",
          "version": "v1"
        },
        {
          "date": "2025-02-28T07:34:44+00:00",
          "link": "https://arxiv.org/abs/2411.08870v2",
          "size": "2154kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T21:17:10+00:00",
          "link": "https://arxiv.org/abs/2411.08870v3",
          "size": "2122kb",
          "version": "v3"
        }
      ],
      "title": "The Limited Impact of Medical Adaptation of Large Language and Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.08870",
        "HTML": "https://arxiv.org/html/2411.08870v3",
        "PDF": "https://arxiv.org/pdf/2411.08870"
      },
      "tasks": [
        "Question Answering"
      ],
      "repo_urls": [
        "https://github.com/taekb/eval-medical-dapt"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.09062",
      "abstract": "Manufacturing requires reliable object detection methods for precise picking and handling of diverse types of manufacturing parts and components. Traditional object detection methods utilize either only 2D images from cameras or 3D data from lidars or similar 3D sensors. However, each of these sensors have weaknesses and limitations. Cameras do not have depth perception and 3D sensors typically do not carry color information. These weaknesses can undermine the reliability and robustness of industrial manufacturing systems. To address these challenges, this work proposes a multi-sensor system combining an red-green-blue (RGB) camera and a 3D point cloud sensor. The two sensors are calibrated for precise alignment of the multimodal data captured from the two hardware devices. A novel multimodal object detection method is developed to process both RGB and depth data. This object detector is based on the Faster R-CNN baseline that was originally designed to process only camera images. The results show that the multimodal model significantly outperforms the depth-only and RGB-only baselines on established object detection metrics. More specifically, the multimodal model improves mAP by 13% and raises Mean Precision by 11.8% in comparison to the RGB-only baseline. Compared to the depth-only baseline, it improves mAP by 78% and raises Mean Precision by 57%. Hence, this method facilitates more reliable and robust object detection in service to smart manufacturing applications.",
      "authors": [
        "Nazanin Mahjourian",
        "Vinh Nguyen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-13T22:43:15+00:00",
          "link": "https://arxiv.org/abs/2411.09062v1",
          "size": "4295kb",
          "version": "v1"
        },
        {
          "date": "2025-03-27T19:10:34+00:00",
          "link": "https://arxiv.org/abs/2411.09062v2",
          "size": "6105kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T02:44:53+00:00",
          "link": "https://arxiv.org/abs/2411.09062v3",
          "size": "3251kb",
          "version": "v3"
        }
      ],
      "title": "Multimodal Object Detection using Depth and Image Data for Manufacturing Parts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.09062",
        "HTML": "https://arxiv.org/html/2411.09062v3",
        "PDF": "https://arxiv.org/pdf/2411.09062"
      },
      "tasks": [
        "Object",
        "object-detection",
        "Object Detection",
        "Robust Object Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.09850",
      "abstract": "Diffusion models have emerged as a powerful foundation model for visual generations. With an appropriate sampling process, it can effectively serve as a generative prior for solving general inverse problems. Current posterior sampling-based methods take the measurement (i.e., degraded image sample) into the posterior sampling to infer the distribution of the target data (i.e., clean image sample). However, in this manner, we show that high-frequency information can be prematurely introduced during the early stages, which could induce larger posterior estimate errors during restoration sampling. To address this observation, we first reveal that forming the log-posterior gradient with the noisy measurement ( i.e., noisy measurement from a diffusion forward process) instead of the clean one can benefit the early posterior sampling. Consequently, we propose a novel diffusion posterior sampling method DPS-CM, which incorporates a Crafted Measurement (i.e., noisy measurement crafted by a reverse denoising process, rather than constructed from the diffusion forward process) to form the posterior estimate. This integration aims to mitigate the misalignment with the diffusion prior caused by cumulative posterior estimate errors. Experimental results demonstrate that our approach significantly improves the overall capacity to solve general and noisy inverse problems, such as Gaussian deblurring, super-resolution, inpainting, nonlinear deblurring, and tasks with Poisson noise, relative to existing approaches. Code is available at: https://github.com/sjz5202/DPS-CM.",
      "authors": [
        "Shijie Zhou",
        "Huaisheng Zhu",
        "Rohan Sharma",
        "Jiayi Chen",
        "Ruiyi Zhang",
        "Kaiyi Ji and Changyou Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-15T00:06:57+00:00",
          "link": "https://arxiv.org/abs/2411.09850v1",
          "size": "47807kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T18:50:55+00:00",
          "link": "https://arxiv.org/abs/2411.09850v2",
          "size": "43910kb",
          "version": "v2"
        }
      ],
      "title": "Enhancing Diffusion Posterior Sampling for Inverse Problems by Integrating Crafted Measurements",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.09850",
        "PDF": "https://arxiv.org/pdf/2411.09850"
      },
      "tasks": [
        "Deblurring",
        "Denoising",
        "Super-Resolution"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.10557",
      "abstract": "We present a novel visual instruction tuning strategy to improve the zero-shot task generalization of multimodal large language models by building a firm text-only knowledge base. Existing work lacks sufficient experimentation on the importance of each modality in the instruction tuning stage, often using a majority of vision-language data while keeping text-only data limited and fixing mixtures of modalities. By incorporating diverse text-only data in the visual instruction tuning stage, we vary vision-language data in various controlled experiments to investigate the importance of modality in visual instruction tuning. Our comprehensive evaluation shows that the text-heavy instruction tuning approach is able to perform on-par with traditional vision-heavy mixtures on both modalities across 12 general datasets while using as low as half the total training tokens. We find that simply increasing sufficiently diverse text-only data enables transfer of instruction following ability and domain knowledge across modalities while being more efficient than the vision-language approach.",
      "authors": [
        "Jianhong Tu",
        "Zhuohao Ni",
        "Nicholas Crispino",
        "Zihao Yu",
        "Michael Bendersky",
        "Beliz Gunel",
        "Ruoxi Jia",
        "Xin Liu",
        "Lingjuan Lyu",
        "Dawn Song",
        "Chenguang Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-15T20:09:59+00:00",
          "link": "https://arxiv.org/abs/2411.10557v1",
          "size": "2667kb",
          "version": "v1"
        },
        {
          "date": "2024-11-19T05:16:28+00:00",
          "link": "https://arxiv.org/abs/2411.10557v2",
          "size": "2667kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T18:24:35+00:00",
          "link": "https://arxiv.org/abs/2411.10557v3",
          "size": "311kb",
          "version": "v3"
        }
      ],
      "title": "MLAN: Language-Based Instruction Tuning Preserves and Transfers Knowledge in Multimodal Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.10557",
        "HTML": "https://arxiv.org/html/2411.10557v3",
        "PDF": "https://arxiv.org/pdf/2411.10557"
      },
      "tasks": [
        "Instruction Following",
        "Zero-shot Generalization"
      ],
      "repo_urls": [
        "https://github.com/wang-research-lab/mlan"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.13020",
      "abstract": "We present Asymmetric Dexterity (AsymDex), a novel and simple reinforcement learning (RL) framework that can efficiently learn a large class of bimanual skills in multi-fingered hands without relying on demonstrations. Two crucial insights enable AsymDex to reduce the observation and action space dimensions and improve sample efficiency. First, true ambidexterity is rare in humans and most of us exhibit strong \"handedness\". Inspired by this observation, we assign complementary roles to each hand: the facilitating hand repositions and reorients one object, while the dominant hand performs complex manipulations to achieve the desired result (e.g., opening a bottle cap, or pouring liquids). Second, controlling the relative motion between the hands is crucial for coordination and synchronization of the two hands. As such, we design relative observation and action spaces and leverage a relative-pose tracking controller. Further, we propose a two-phase decomposition in which AsymDex can be readily integrated with recent advances in grasp learning to facilitate both the acquisition and manipulation of objects using two hands. Unlike existing RL-based methods for bimanual dexterity with multi-fingered hands, which are either sample inefficient or tailored to a specific task, AsymDex can efficiently learn a wide variety of bimanual skills that exhibit asymmetry. Detailed experiments on seven asymmetric bimanual dexterous manipulation tasks (four simulated and three real-world) reveal that AsymDex consistently outperforms strong baselines that challenge our design choices. The project website is at https://sites.google.com/view/asymdex-2025/.",
      "authors": [
        "Zhaodong Yang",
        "Yunhai Han",
        "Ai-Ping Hu",
        "Harish Ravichandar"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-20T03:47:11+00:00",
          "link": "https://arxiv.org/abs/2411.13020v1",
          "size": "3348kb",
          "version": "v1"
        },
        {
          "date": "2025-05-09T22:25:40+00:00",
          "link": "https://arxiv.org/abs/2411.13020v2",
          "size": "25830kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T02:20:39+00:00",
          "link": "https://arxiv.org/abs/2411.13020v3",
          "size": "6256kb",
          "version": "v3"
        }
      ],
      "title": "AsymDex: Asymmetry and Relative Coordinates for RL-based Bimanual Dexterity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.13020",
        "HTML": "https://arxiv.org/html/2411.13020v3",
        "PDF": "https://arxiv.org/pdf/2411.13020"
      },
      "source": "arXiv"
    },
    {
      "id": "2411.13757",
      "abstract": "Large Language Models (LLMs) have revolutionized natural language processing (NLP), excelling in tasks like text generation and summarization. However, their increasing adoption in mission-critical applications raises concerns about hardware-based threats, particularly bit-flip attacks (BFAs). BFAs, enabled by fault injection methods such as Rowhammer, target model parameters in memory, compromising both integrity and performance. Identifying critical parameters for BFAs in the vast parameter space of LLMs poses significant challenges. While prior research suggests transformer-based architectures are inherently more robust to BFAs compared to traditional deep neural networks, we challenge this assumption. For the first time, we demonstrate that as few as three bit-flips can cause catastrophic performance degradation in an LLM with billions of parameters. Current BFA techniques are inadequate for exploiting this vulnerability due to the difficulty of efficiently identifying critical parameters within the immense parameter space. To address this, we propose AttentionBreaker, a novel framework tailored for LLMs that enables efficient traversal of the parameter space to identify critical parameters. Additionally, we introduce GenBFA, an evolutionary optimization strategy designed to refine the search further, isolating the most critical bits for an efficient and effective attack. Empirical results reveal the profound vulnerability of LLMs to AttentionBreaker. For example, merely three bit-flips (4.129 x 10^-9% of total parameters) in the LLaMA3-8B-Instruct 8-bit quantized (W8) model result in a complete performance collapse: accuracy on MMLU tasks drops from 67.3% to 0%, and Wikitext perplexity skyrockets from 12.6 to 4.72 x 10^5. These findings underscore the effectiveness of AttentionBreaker in uncovering and exploiting critical vulnerabilities within LLM architectures.",
      "authors": [
        "Sanjay Das",
        "Swastik Bhattacharya",
        "Souvik Kundu",
        "Shamik Kundu",
        "Anand Menon",
        "Arnab Raha and Kanad Basu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-21T00:01:51+00:00",
          "link": "https://arxiv.org/abs/2411.13757v1",
          "size": "3707kb",
          "version": "v1"
        },
        {
          "date": "2025-02-07T16:24:17+00:00",
          "link": "https://arxiv.org/abs/2411.13757v2",
          "size": "2486kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T21:44:50+00:00",
          "link": "https://arxiv.org/abs/2411.13757v3",
          "size": "3784kb",
          "version": "v3"
        }
      ],
      "title": "GenBFA: An Evolutionary Optimization Approach to Bit-Flip Attacks on LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.13757",
        "HTML": "https://arxiv.org/html/2411.13757v3",
        "PDF": "https://arxiv.org/pdf/2411.13757"
      },
      "tasks": [
        "MMLU",
        "Text Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.14565",
      "abstract": "Video Anomaly Detection (VAD) aims to automatically analyze spatiotemporal patterns in surveillance videos collected from open spaces to detect anomalous events that may cause harm, such as fighting, stealing, and car accidents. However, vision-based surveillance systems such as closed-circuit television often capture personally identifiable information. The lack of transparency and interpretability in video transmission and usage raises public concerns about privacy and ethics, limiting the real-world application of VAD. Recently, researchers have focused on privacy concerns in VAD by conducting systematic studies from various perspectives including data, features, and systems, making Privacy-Preserving Video Anomaly Detection (P2VAD) a hotspot in the AI community. However, current research in P2VAD is fragmented, and prior reviews have mostly focused on methods using RGB sequences, overlooking privacy leakage and appearance bias considerations. To address this gap, this article is the first to systematically reviews the progress of P2VAD, defining its scope and providing an intuitive taxonomy. We outline the basic assumptions, learning frameworks, and optimization objectives of various approaches, analyzing their strengths, weaknesses, and potential correlations. Additionally, we provide open access to research resources such as benchmark datasets and available code. Finally, we discuss key challenges and future opportunities from the perspectives of AI development and P2VAD deployment, aiming to guide future work in the field.",
      "authors": [
        "Yang Liu",
        "Siao Liu",
        "Xiaoguang Zhu",
        "Jielin Li",
        "Hao Yang",
        "Liangyu Teng",
        "Juncen Guo",
        "Yan Wang",
        "Dingkang Yang",
        "Jing Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-21T20:29:59+00:00",
          "link": "https://arxiv.org/abs/2411.14565v1",
          "size": "642kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T09:36:36+00:00",
          "link": "https://arxiv.org/abs/2411.14565v2",
          "size": "800kb",
          "version": "v2"
        }
      ],
      "title": "Privacy-Preserving Video Anomaly Detection: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.14565",
        "HTML": "https://arxiv.org/html/2411.14565v2",
        "PDF": "https://arxiv.org/pdf/2411.14565"
      },
      "tasks": [
        "Anomaly Detection",
        "Ethics",
        "Privacy Preserving",
        "Survey",
        "Video Anomaly Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.15103",
      "abstract": "We contribute to the theory of (homotopy) colimits inside homotopy type theory. The heart of our work characterizes the connection between colimits in coslices of a universe, called coslice colimits, and colimits in the universe (i.e., ordinary colimits). To derive this characterization, we find an explicit construction of colimits in coslices that is tailored to reveal the connection. We use the construction to derive properties of colimits. Notably, we prove that the forgetful functor from a coslice creates colimits over trees. We also use the construction to examine how colimits interact with orthogonal factorization systems and with cohomology theories. As a consequence of their interaction with orthogonal factorization systems, all pointed colimits (special kinds of coslice colimits) preserve $n$-connectedness, which implies that higher groups are closed under colimits on directed graphs. We have formalized our main construction of the coslice colimit functor in Agda. The code for this paper is available at https://github.com/PHart3/colimits-agda .",
      "authors": [
        "Perry Hart and Kuen-Bang Hou (Favonia)"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Category Theory (math.CT)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-22T18:06:15+00:00",
          "link": "https://arxiv.org/abs/2411.15103v1",
          "size": "49kb",
          "version": "v1"
        },
        {
          "date": "2025-02-07T19:50:12+00:00",
          "link": "https://arxiv.org/abs/2411.15103v2",
          "size": "58kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T13:36:17+00:00",
          "link": "https://arxiv.org/abs/2411.15103v3",
          "size": "59kb",
          "version": "v3"
        }
      ],
      "title": "Coslice Colimits in Homotopy Type Theory",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.15103",
        "PDF": "https://arxiv.org/pdf/2411.15103"
      },
      "repo_urls": [
        "https://github.com/phart3/colimits-agda"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.15240",
      "abstract": "Pretrained foundation models and transformer architectures have driven the success of large language models (LLMs) and other modern AI breakthroughs. However, similar advancements in health data modeling remain limited due to the need for innovative adaptations. Wearable movement data offers a valuable avenue for exploration, as it's a core feature in nearly all commercial smartwatches, well established in clinical and mental health research, and the sequential nature of the data shares similarities to language. We introduce the Pretrained Actigraphy Transformer (PAT), the first open source foundation model designed for time-series wearable movement data. Leveraging transformer-based architectures and novel techniques, such as patch embeddings, and pretraining on data from 29,307 participants in a national U.S. sample, PAT achieves state-of-the-art performance in several mental health prediction tasks. PAT is also lightweight and easily interpretable, making it a robust tool for mental health research.\n  GitHub: https://github.com/njacobsonlab/Pretrained-Actigraphy-Transformer/",
      "authors": [
        "Franklin Y. Ruan",
        "Aiwei Zhang",
        "Jenny Y. Oh",
        "SouYoung Jin",
        "Nicholas C. Jacobson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-22T01:58:35+00:00",
          "link": "https://arxiv.org/abs/2411.15240v1",
          "size": "2614kb",
          "version": "v1"
        },
        {
          "date": "2024-11-26T06:11:42+00:00",
          "link": "https://arxiv.org/abs/2411.15240v2",
          "size": "2067kb",
          "version": "v2"
        },
        {
          "date": "2025-01-14T04:10:46+00:00",
          "link": "https://arxiv.org/abs/2411.15240v3",
          "size": "2126kb",
          "version": "v3"
        },
        {
          "date": "2025-06-28T20:08:42+00:00",
          "link": "https://arxiv.org/abs/2411.15240v4",
          "size": "2265kb",
          "version": "v4"
        }
      ],
      "title": "Foundation Models for Wearable Movement Data in Mental Health Research",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.15240",
        "PDF": "https://arxiv.org/pdf/2411.15240"
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/njacobsonlab/pretrained-actigraphy-transformer"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.15397",
      "abstract": "The cost of deploying vision transformers increasingly represents a barrier to wider industrial adoption. Existing compression techniques require additional end-to-end fine-tuning or incur a significant drawback to runtime, making them ill-suited for online (real-time) inference, where a prediction is made on any new input as it comes in. We introduce the $\\textbf{Visual Word Tokenizer}$ (VWT), a training-free method for reducing power costs while retaining performance and runtime. The VWT groups visual subwords (image patches) that are frequently used into visual words while infrequent ones remain intact. To do so, $\\textit{intra}$-image or $\\textit{inter}$-image statistics are leveraged to identify similar visual concepts for sequence compression. Experimentally, we demonstrate a reduction in wattage of up to 25% with only a 20% increase in runtime at most. Comparative approaches of 8-bit quantization and token merging achieve a lower or similar power efficiency but exact a higher toll on runtime (up to 100% or more). Our results indicate that VWTs are well-suited for efficient online inference with a marginal compromise on performance.",
      "authors": [
        "Leonidas Gee",
        "Wing Yan Li",
        "Viktoriia Sharmanska",
        "Novi Quadrianto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-23T00:47:13+00:00",
          "link": "https://arxiv.org/abs/2411.15397v1",
          "size": "25040kb",
          "version": "v1"
        },
        {
          "date": "2025-06-20T13:50:00+00:00",
          "link": "https://arxiv.org/abs/2411.15397v2",
          "size": "23498kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T10:22:45+00:00",
          "link": "https://arxiv.org/abs/2411.15397v3",
          "size": "23498kb",
          "version": "v3"
        }
      ],
      "title": "Efficient Online Inference of Vision Transformers by Training-Free Tokenization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.15397",
        "HTML": "https://arxiv.org/html/2411.15397v3",
        "PDF": "https://arxiv.org/pdf/2411.15397"
      },
      "models": [
        {
          "model_path": "LeonidasY/inter-image-imgnet-100",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/LeonidasY/inter-image-imgnet-100"
        },
        {
          "model_path": "LeonidasY/inter-image-imgnet-1000",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/LeonidasY/inter-image-imgnet-1000"
        },
        {
          "model_path": "LeonidasY/inter-image-imgnet-10000",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/LeonidasY/inter-image-imgnet-10000"
        }
      ],
      "tasks": [
        "Quantization"
      ],
      "repo_urls": [
        "https://github.com/wearepal/visual-word-tokenizer"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.16645",
      "abstract": "In the area of recommender systems, the vast majority of research efforts is spent on developing increasingly sophisticated recommendation models, also using increasingly more computational resources. Unfortunately, most of these research efforts target a very small set of application domains, mostly e-commerce and media recommendation. Furthermore, many of these models are never evaluated with users, let alone put into practice. The scientific, economic and societal value of much of these efforts by scholars therefore remains largely unclear. To achieve a stronger positive impact resulting from these efforts, we posit that we as a research community should more often address use cases where recommender systems contribute to societal good (RS4Good). In this opinion piece, we first discuss a number of examples where the use of recommender systems for problems of societal concern has been successfully explored in the literature. We then proceed by outlining a paradigmatic shift that is needed to conduct successful RS4Good research, where the key ingredients are interdisciplinary collaborations and longitudinal evaluation approaches with humans in the loop.",
      "authors": [
        "Dietmar Jannach and Alan Said and Marko Tkal\\v{c}i\\v{c} and Markus Zanker"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-25T18:27:50+00:00",
          "link": "https://arxiv.org/abs/2411.16645v1",
          "size": "67kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T19:54:34+00:00",
          "link": "https://arxiv.org/abs/2411.16645v2",
          "size": "101kb",
          "version": "v2"
        }
      ],
      "title": "Recommender Systems for Good (RS4Good): Survey of Use Cases and a Call to Action for Research that Matters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.16645",
        "HTML": "https://arxiv.org/html/2411.16645v2",
        "PDF": "https://arxiv.org/pdf/2411.16645"
      },
      "tasks": [
        "Recommendation Systems"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.16750",
      "abstract": "Traditional monocular depth estimation suffers from inherent ambiguity and visual nuisance. We argue that language prior can enhance monocular depth estimation by leveraging the inductive bias learned during the text-to-image pre-training of diffusion models. The ability of these models to generate images that align with text indicates that they have learned the spatial relationships, size, and shape of specified objects, which can be applied to improve depth estimation. Thus, we propose PriorDiffusion, using a pre-trained text-to-image diffusion model that takes both images and corresponding text descriptions to infer affine-invariant depth through a denoising process. We also show that language prior enhances the model's perception of specific regions of images that users care about and describe. Simultaneously, language prior acts as a constraint to accelerate the convergence of both training and the inference diffusion trajectory. By training on HyperSim and Virtual KITTI, we achieve faster training convergence, fewer inference diffusion steps, and state-of-the-art zero-shot performance across NYUv2, KITTI, ETH3D, and ScanNet. Code will be released upon acceptance.",
      "authors": [
        "Ziyao Zeng",
        "Jingcheng Ni",
        "Daniel Wang",
        "Patrick Rim",
        "Younjoon Chung",
        "Fengyu Yang",
        "Byung-Woo Hong",
        "Alex Wong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-24T05:07:10+00:00",
          "link": "https://arxiv.org/abs/2411.16750v1",
          "size": "5642kb",
          "version": "v1"
        },
        {
          "date": "2025-04-17T18:32:36+00:00",
          "link": "https://arxiv.org/abs/2411.16750v2",
          "size": "6655kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T23:07:48+00:00",
          "link": "https://arxiv.org/abs/2411.16750v3",
          "size": "6641kb",
          "version": "v3"
        }
      ],
      "title": "PriorDiffusion: Leverage Language Prior in Diffusion Models for Monocular Depth Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.16750",
        "HTML": "https://arxiv.org/html/2411.16750v3",
        "PDF": "https://arxiv.org/pdf/2411.16750"
      },
      "tasks": [
        "Denoising",
        "Depth Estimation",
        "Inductive Bias",
        "Monocular Depth Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.16782",
      "abstract": "Adversarial examples usually exhibit good cross-model transferability, enabling attacks on black-box models with limited information about their architectures and parameters, which are highly threatening in commercial black-box scenarios. Model ensembling is an effective strategy to improve the transferability of adversarial examples by attacking multiple surrogate models. However, since prior studies usually adopt few models in the ensemble, there remains an open question of whether scaling the number of models can further improve black-box attacks. Inspired by the scaling law of large foundation models, we investigate the scaling laws of black-box adversarial attacks in this work. Through theoretical analysis and empirical evaluations, we conclude with clear scaling laws that using more surrogate models enhances adversarial transferability. Comprehensive experiments verify the claims on standard image classifiers, diverse defended models and multimodal large language models using various adversarial attack methods. Specifically, by scaling law, we achieve 90%+ transfer attack success rate on even proprietary models like GPT-4o. Further visualization indicates that there is also a scaling law on the interpretability and semantics of adversarial perturbations.",
      "authors": [
        "Chuan Liu",
        "Huanran Chen",
        "Yichi Zhang",
        "Yinpeng Dong",
        "Jun Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-25T08:14:37+00:00",
          "link": "https://arxiv.org/abs/2411.16782v1",
          "size": "30405kb",
          "version": "v1"
        },
        {
          "date": "2025-05-15T08:18:43+00:00",
          "link": "https://arxiv.org/abs/2411.16782v2",
          "size": "25719kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T16:32:50+00:00",
          "link": "https://arxiv.org/abs/2411.16782v3",
          "size": "7181kb",
          "version": "v3"
        }
      ],
      "title": "Scaling Laws for Black box Adversarial Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.16782",
        "HTML": "https://arxiv.org/html/2411.16782v3",
        "PDF": "https://arxiv.org/pdf/2411.16782"
      },
      "tasks": [
        "Adversarial Attack"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.17960",
      "abstract": "Main memory's rising energy consumption has emerged as a critical challenge in modern computing architectures, particularly in large-scale systems, driven by frequent access patterns, growing data volumes, and insufficient power management strategies. Accurate modeling of DRAM power consumption is essential to address this challenge and optimize energy efficiency. However, existing modeling tools often rely on vendor-provided datasheet values that are obtained under worst-case or idealized conditions. As a result, they fail to capture important system-level factors, such as temperature variations, chip aging, and workload-induced variability, which leads to significant discrepancies between estimated and actual power consumption observed in real deployments. In this work, we propose a runtime calibration methodology for the DRAMPower model using energy measurements collected from real-system experiments. By applying custom memory benchmarks on an HPC cluster and leveraging fine-grained power monitoring infrastructure, we refine key current parameters (IDD values) in the model. Our calibration reduces the average energy estimation error to less than 5%, substantially improving modeling accuracy and making DRAMPower a more reliable tool for power-aware system design and optimization on the target server platform.",
      "authors": [
        "Xinyu Shi",
        "Dina Ali Abdelhamid",
        "Thomas Ilsche",
        "Saeideh Alinezhad Chamazcoti",
        "Timon Evenblij",
        "Mohit Gupta",
        "Francky Catthoor"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-27T00:36:27+00:00",
          "link": "https://arxiv.org/abs/2411.17960v1",
          "size": "505kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T05:35:14+00:00",
          "link": "https://arxiv.org/abs/2411.17960v2",
          "size": "676kb",
          "version": "v2"
        }
      ],
      "title": "Calibrating DRAMPower Model for HPC: A Runtime Perspective from Real-Time Measurements",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.17960",
        "HTML": "https://arxiv.org/html/2411.17960v2",
        "PDF": "https://arxiv.org/pdf/2411.17960"
      },
      "source": "arXiv"
    },
    {
      "id": "2411.18066",
      "abstract": "Recently, 3D Gaussian Splatting (3DGS) has achieved impressive performance on indoor surface reconstruction and 3D open-vocabulary segmentation. This paper presents GLS, a unified framework of 3D surface reconstruction and open-vocabulary segmentation based on 3DGS. GLS extends two fields by improving their sharpness and smoothness. For indoor surface reconstruction, we introduce surface normal prior as a geometric cue to guide the rendered normal, and use the normal error to optimize the rendered depth. For 3D open-vocabulary segmentation, we employ 2D CLIP features to guide instance features and enhance the surface smoothness, then utilize DEVA masks to maintain their view consistency. Extensive experiments demonstrate the effectiveness of jointly optimizing surface reconstruction and 3D open-vocabulary segmentation, where GLS surpasses state-of-the-art approaches of each task on MuSHRoom, ScanNet++ and LERF-OVS datasets. Project webpage: https://jiaxiongq.github.io/GLS_ProjectPage.",
      "authors": [
        "Jiaxiong Qiu",
        "Liu Liu",
        "Xinjie Wang",
        "Tianwei Lin",
        "Wei Sui",
        "Zhizhong Su"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-27T05:21:34+00:00",
          "link": "https://arxiv.org/abs/2411.18066v1",
          "size": "5132kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T03:48:34+00:00",
          "link": "https://arxiv.org/abs/2411.18066v2",
          "size": "4524kb",
          "version": "v2"
        }
      ],
      "title": "GLS: Geometry-aware 3D Language Gaussian Splatting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.18066",
        "HTML": "https://arxiv.org/html/2411.18066v2",
        "PDF": "https://arxiv.org/pdf/2411.18066"
      },
      "tasks": [
        "3DGS",
        "Segmentation",
        "Surface Reconstruction"
      ],
      "repo_urls": [
        "https://github.com/jiaxiongq/gls"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.18797",
      "abstract": "Recent advancements in LLMs unlearning have shown remarkable success in removing unwanted data-model influences while preserving the model's utility for legitimate knowledge. Despite these strides, sparse Mixture-of-Experts (MoE) LLMs--a key subset of the LLM family--have remained unexplored in the context of unlearning. As MoE LLMs are celebrated for their exceptional performance, we ask:How can unlearning be performed effectively and efficiently on MoE LLMs? Our pilot study shows that the dynamic routing nature of MoE LLMs introduces unique challenges, leading to excessive forgetting, uncontrolled knowledge erasure and substantial utility drops when existing unlearning methods are applied. To address this, we propose a novel Selected-Expert Unlearning Framework (SEUF). Through expert attribution, unlearning is concentrated on the most actively engaged experts for the specified knowledge. Concurrently, an anchor loss is applied to the router to stabilize the active state of this targeted expert, ensuring focused and controlled unlearning. SEUF is compatible with various standard unlearning algorithms. Extensive experiments demonstrate that SEUF enhances both forget quality up to 5% and model utility by 35% on MoE LLMs across various benchmarks and LLM architectures (compared to standard unlearning algorithms), while only unlearning 0.06% of the model parameters.",
      "authors": [
        "Haomin Zhuang",
        "Yihua Zhang",
        "Kehan Guo",
        "Jinghan Jia",
        "Gaowen Liu",
        "Sijia Liu",
        "and Xiangliang Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-27T22:46:08+00:00",
          "link": "https://arxiv.org/abs/2411.18797v1",
          "size": "1910kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T17:45:54+00:00",
          "link": "https://arxiv.org/abs/2411.18797v2",
          "size": "275kb",
          "version": "v2"
        }
      ],
      "title": "SEUF: Is Unlearning One Expert Enough for Mixture-of-Experts LLMs?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.18797",
        "HTML": "https://arxiv.org/html/2411.18797v2",
        "PDF": "https://arxiv.org/pdf/2411.18797"
      },
      "tasks": [
        "Large Language Model",
        "Mixture-of-Experts"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.00348",
      "abstract": "Traffic Surveillance Systems (TSS) have become increasingly crucial in modern intelligent transportation systems, with vision technologies playing a central role for scene perception and understanding. While existing surveys typically focus on isolated aspects of TSS, a comprehensive analytical framework bridging low-level and high-level perception tasks, particularly considering emerging technologies, remains lacking. This paper presents a systematic review of vision technologies in TSS, examining both low-level perception tasks (object detection, classification, and tracking) and high-level perception tasks (parameter estimation, anomaly detection, and behavior understanding). Specifically, we first provide a detailed methodological categorization and comprehensive performance evaluation for each task. Our investigation reveals five fundamental limitations in current TSS: perceptual data degradation in complex scenarios, data-driven learning constraints, semantic understanding gaps, sensing coverage limitations and computational resource demands. To address these challenges, we systematically analyze five categories of current approaches and potential trends: advanced perception enhancement, efficient learning paradigms, knowledge-enhanced understanding, cooperative sensing frameworks and efficient computing frameworks, critically assessing their real-world applicability. Furthermore, we evaluate the transformative potential of foundation models in TSS, which exhibit remarkable zero-shot learning abilities, strong generalization, and sophisticated reasoning capabilities across diverse tasks. This review provides a unified analytical framework bridging low-level and high-level perception tasks, systematically analyzes current limitations and solutions, and presents a structured roadmap for integrating emerging technologies, particularly foundation models, to enhance TSS capabilities.",
      "authors": [
        "Wei Zhou",
        "Li Yang",
        "Lei Zhao",
        "Runyu Zhang",
        "Yifan Cui",
        "Hongpu Huang",
        "Kun Qie",
        "Chen Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-30T04:17:56+00:00",
          "link": "https://arxiv.org/abs/2412.00348v1",
          "size": "8703kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T06:36:13+00:00",
          "link": "https://arxiv.org/abs/2412.00348v2",
          "size": "6531kb",
          "version": "v2"
        }
      ],
      "title": "Vision Technologies with Applications in Traffic Surveillance Systems: A Holistic Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.00348",
        "HTML": "https://arxiv.org/html/2412.00348v2",
        "PDF": "https://arxiv.org/pdf/2412.00348"
      },
      "tasks": [
        "Anomaly Detection",
        "object-detection",
        "Object Detection",
        "parameter estimation",
        "Scene Generation",
        "Zero-Shot Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.01053",
      "abstract": "Neural speech codecs have gained great attention for their outstanding reconstruction with discrete token representations.\n  It is a crucial component in generative tasks such as speech coding and large language models (LLM).\n  However, most works based on residual vector quantization perform worse with fewer tokens due to low coding efficiency for modeling complex coupled information.\n  In this paper, we propose a neural speech codec named FreeCodec which employs a more effective encoding framework by decomposing intrinsic properties of speech into different components:\n  1) a global vector is extracted as the timbre information,\n  2) a prosody encoder with a long stride level is used to model the prosody information,\n  3) the content information is from a content encoder.\n  Using different training strategies, FreeCodec achieves state-of-the-art performance in reconstruction and disentanglement scenarios.\n  Results from subjective and objective experiments demonstrate that our framework outperforms existing methods.",
      "authors": [
        "Youqiang Zheng and Weiping Tu and Yueteng Kang and Jie Chen and Yike Zhang and Li Xiao and Yuhong Yang and Long Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-02T02:29:22+00:00",
          "link": "https://arxiv.org/abs/2412.01053v1",
          "size": "3755kb",
          "version": "v1"
        },
        {
          "date": "2024-12-07T15:02:11+00:00",
          "link": "https://arxiv.org/abs/2412.01053v2",
          "size": "3755kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T09:45:02+00:00",
          "link": "https://arxiv.org/abs/2412.01053v3",
          "size": "1055kb",
          "version": "v3"
        }
      ],
      "title": "FreeCodec: A disentangled neural speech codec with fewer tokens",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.01053",
        "HTML": "https://arxiv.org/html/2412.01053v3",
        "PDF": "https://arxiv.org/pdf/2412.01053"
      },
      "repo_urls": [
        "https://github.com/exercise-book-yq/FreeCodec"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.01064",
      "abstract": "With the rapid advancement of diffusion-based generative models, portrait image animation has achieved remarkable results. However, it still faces challenges in temporally consistent video generation and fast sampling due to its iterative sampling nature. This paper presents FLOAT, an audio-driven talking portrait video generation method based on flow matching generative model. Instead of a pixel-based latent space, we take advantage of a learned orthogonal motion latent space, enabling efficient generation and editing of temporally consistent motion. To achieve this, we introduce a transformer-based vector field predictor with an effective frame-wise conditioning mechanism. Additionally, our method supports speech-driven emotion enhancement, enabling a natural incorporation of expressive motions. Extensive experiments demonstrate that our method outperforms state-of-the-art audio-driven talking portrait methods in terms of visual quality, motion fidelity, and efficiency.",
      "authors": [
        "Taekyung Ki",
        "Dongchan Min",
        "Gyeongsu Chae"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Multimedia (cs.MM)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-02T02:50:07+00:00",
          "link": "https://arxiv.org/abs/2412.01064v1",
          "size": "13317kb",
          "version": "v1"
        },
        {
          "date": "2024-12-04T09:43:18+00:00",
          "link": "https://arxiv.org/abs/2412.01064v2",
          "size": "13317kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T15:11:31+00:00",
          "link": "https://arxiv.org/abs/2412.01064v3",
          "size": "15231kb",
          "version": "v3"
        }
      ],
      "title": "FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.01064",
        "PDF": "https://arxiv.org/pdf/2412.01064"
      },
      "tasks": [
        "Image Animation",
        "Video Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.01131",
      "abstract": "Recently, much work has concerned itself with the enigma of what exactly PLMs (pretrained language models) learn about different aspects of language, and how they learn it. One stream of this type of research investigates the knowledge that PLMs have about semantic relations. However, many aspects of semantic relations were left unexplored. Only one relation was considered, namely hypernymy. Furthermore, previous work did not measure humans' performance on the same task as that solved by the PLMs. This means that at this point in time, there is only an incomplete view of models' semantic relation knowledge. To address this gap, we introduce a comprehensive evaluation framework covering five relations beyond hypernymy, namely hyponymy, holonymy, meronymy, antonymy, and synonymy. We use six metrics (two newly introduced here) for recently untreated aspects of semantic relation knowledge, namely soundness, completeness, symmetry, asymmetry, prototypicality, and distinguishability and fairly compare humans and models on the same task. Our extensive experiments involve 16 PLMs, eight masked and eight causal language models. Up to now only masked language models had been tested although causal and masked language models treat context differently. Our results reveal a significant knowledge gap between humans and models for almost all semantic relations. Antonymy is the outlier relation where all models perform reasonably well. In general, masked language models perform significantly better than causal language models. Nonetheless, both masked and causal language models are likely to confuse non-antonymy relations with antonymy.",
      "authors": [
        "Zhihan Cao",
        "Hiroaki Yamada",
        "Simone Teufel",
        "Takenobu Tokunaga"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-02T05:11:34+00:00",
          "link": "https://arxiv.org/abs/2412.01131v1",
          "size": "302kb",
          "version": "v1"
        },
        {
          "date": "2025-06-25T03:12:51+00:00",
          "link": "https://arxiv.org/abs/2412.01131v2",
          "size": "218kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T05:07:49+00:00",
          "link": "https://arxiv.org/abs/2412.01131v3",
          "size": "218kb",
          "version": "v3"
        }
      ],
      "title": "A Comprehensive Evaluation of Semantic Relation Knowledge of Pretrained Language Models and Humans",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.01131",
        "HTML": "https://arxiv.org/html/2412.01131v3",
        "PDF": "https://arxiv.org/pdf/2412.01131"
      },
      "tasks": [
        "Relation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.01787",
      "abstract": "Recent generative models based on score matching and flow matching have significantly advanced generation tasks, but their potential in discriminative tasks remains underexplored. Previous approaches, such as generative classifiers, have not fully leveraged the capabilities of these models for discriminative tasks due to their intricate designs. We propose Pretrained Reversible Generation (PRG), which extracts unsupervised representations by reversing the generative process of a pretrained continuous generation model. PRG effectively reuses unsupervised generative models, leveraging their high capacity to serve as robust and generalizable feature extractors for downstream tasks. This framework enables the flexible selection of feature hierarchies tailored to specific downstream tasks. Our method consistently outperforms prior approaches across multiple benchmarks, achieving state-of-the-art performance among generative model based methods, including 78% top-1 accuracy on ImageNet at a resolution of 64*64. Extensive ablation studies, including out-of-distribution evaluations, further validate the effectiveness of our approach.PRG is available at https://github.com/opendilab/PRG.",
      "authors": [
        "Rongkun Xue",
        "Jinouwen Zhang",
        "Yazhe Niu",
        "Dazhong Shen",
        "Bingqi Ma",
        "Yu Liu",
        "Jing Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-29T08:24:49+00:00",
          "link": "https://arxiv.org/abs/2412.01787v1",
          "size": "34281kb",
          "version": "v1"
        },
        {
          "date": "2025-03-08T14:13:46+00:00",
          "link": "https://arxiv.org/abs/2412.01787v2",
          "size": "39964kb",
          "version": "v2"
        },
        {
          "date": "2025-06-26T04:26:18+00:00",
          "link": "https://arxiv.org/abs/2412.01787v3",
          "size": "23445kb",
          "version": "v3"
        },
        {
          "date": "2025-06-29T11:52:27+00:00",
          "link": "https://arxiv.org/abs/2412.01787v4",
          "size": "23446kb",
          "version": "v4"
        }
      ],
      "title": "Pretrained Reversible Generation as Unsupervised Visual Representation Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.01787",
        "HTML": "https://arxiv.org/html/2412.01787v4",
        "PDF": "https://arxiv.org/pdf/2412.01787"
      },
      "tasks": [
        "Representation Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.02113",
      "abstract": "In recent years, Large Language Models (LLMs) have garnered considerable attention for their remarkable abilities in natural language processing tasks. However, their widespread adoption has raised concerns pertaining to trust and safety. This systematic review investigates the current research landscape on trust and safety in LLMs, with a particular focus on the novel application of LLMs within the field of Trust and Safety itself. We delve into the complexities of utilizing LLMs in domains where maintaining trust and safety is paramount, offering a consolidated perspective on this emerging trend.\\\n  By synthesizing findings from various studies, we identify key challenges and potential solutions, aiming to benefit researchers and practitioners seeking to understand the nuanced interplay between LLMs and Trust and Safety.\n  This review provides insights on best practices for using LLMs in Trust and Safety, and explores emerging risks such as prompt injection and jailbreak attacks. Ultimately, this study contributes to a deeper understanding of how LLMs can be effectively and responsibly utilized to enhance trust and safety in the digital realm.",
      "authors": [
        "Doohee You",
        "Dan Chon"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-03T03:10:12+00:00",
          "link": "https://arxiv.org/abs/2412.02113v1",
          "size": "20kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T17:50:31+00:00",
          "link": "https://arxiv.org/abs/2412.02113v2",
          "size": "21kb",
          "version": "v2"
        }
      ],
      "title": "Trust & Safety of LLMs and LLMs in Trust & Safety",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.02113",
        "HTML": "https://arxiv.org/html/2412.02113v2",
        "PDF": "https://arxiv.org/pdf/2412.02113"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.02547",
      "abstract": "This paper attacks time-domain identification for interaction parameters of a heterogeneous networked dynamic system (NDS), with each of its subsystems being described by a continuous-time descriptor quadratic-bilinear time-invariant (QBTI) model. The obtained results can also be applied to parameter estimations for a lumped QBTI system. No restrictions are put on the sampling rate. Explicit formulas are derived respectively for the transient and steady-state responses of the NDS, provided that the probing signal is generated by a linear time invariant (LTI) system. Some relations have been derived between the NDS steady-state response and its frequency domain input-output mappings. These relations reveal that the value of some NDS associated generalized TFMs can in principle be estimated at almost any interested point of the imaginary axis from time-domain input-output experimental data, as well as its derivatives and a right tangential interpolation along an arbitrary direction. Based on these relations, an estimation algorithm is suggested respectively for the parameters of the NDS and the values of these generalized TFMs. A numerical example is included to illustrate characteristics of the suggested estimation algorithms.",
      "authors": [
        "Tong Zhou and Yubing Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Dynamical Systems (math.DS)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-03T16:40:43+00:00",
          "link": "https://arxiv.org/abs/2412.02547v1",
          "size": "19kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T08:19:26+00:00",
          "link": "https://arxiv.org/abs/2412.02547v2",
          "size": "2718kb",
          "version": "v2"
        }
      ],
      "title": "Interaction Identification of a Heterogeneous NDS with Quadratic-Bilinear Subsystems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.02547",
        "HTML": "https://arxiv.org/html/2412.02547v2",
        "PDF": "https://arxiv.org/pdf/2412.02547"
      },
      "source": "arXiv"
    },
    {
      "id": "2412.04062",
      "abstract": "In this paper, we propose ZipAR, a training-free, plug-and-play parallel decoding framework for accelerating auto-regressive (AR) visual generation. The motivation stems from the observation that images exhibit local structures, and spatially distant regions tend to have minimal interdependence. Given a partially decoded set of visual tokens, in addition to the original next-token prediction scheme in the row dimension, the tokens corresponding to spatially adjacent regions in the column dimension can be decoded in parallel, enabling the ``next-set prediction'' paradigm. By decoding multiple tokens simultaneously in a single forward pass, the number of forward passes required to generate an image is significantly reduced, resulting in a substantial improvement in generation efficiency. Experiments demonstrate that ZipAR can reduce the number of model forward passes by up to 91% on the Emu3-Gen model without requiring any additional retraining. Code is available here: https://github.com/ThisisBillhe/ZipAR.",
      "authors": [
        "Yefei He",
        "Feng Chen",
        "Yuanyu He",
        "Shaoxuan He",
        "Hong Zhou",
        "Kaipeng Zhang",
        "Bohan Zhuang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-05T10:57:08+00:00",
          "link": "https://arxiv.org/abs/2412.04062v1",
          "size": "8035kb",
          "version": "v1"
        },
        {
          "date": "2024-12-18T07:28:52+00:00",
          "link": "https://arxiv.org/abs/2412.04062v2",
          "size": "8035kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T07:13:36+00:00",
          "link": "https://arxiv.org/abs/2412.04062v3",
          "size": "4400kb",
          "version": "v3"
        }
      ],
      "title": "ZipAR: Parallel Auto-regressive Image Generation through Spatial Locality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.04062",
        "HTML": "https://arxiv.org/html/2412.04062v3",
        "PDF": "https://arxiv.org/pdf/2412.04062"
      },
      "tasks": [
        "Image Generation"
      ],
      "repo_urls": [
        "https://github.com/ThisisBillhe/ZipAR"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.04205",
      "abstract": "Automatic translation systems offer a powerful solution to bridge language barriers in scenarios where participants do not share a common language. However, these systems can introduce errors leading to misunderstandings and conversation breakdown. A key issue is that current systems fail to incorporate the rich contextual information necessary to resolve ambiguities and omitted details, resulting in literal, inappropriate, or misaligned translations. In this work, we present a framework to improve large language model-based translation systems by incorporating contextual information in bilingual conversational settings during training and inference. We validate our proposed framework on two task-oriented domains: customer chat and user-assistant interaction. Across both settings, the system produced by our framework-TowerChat-consistently results in better translations than state-of-the-art systems like GPT-4o and TowerInstruct, as measured by multiple automatic translation quality metrics on several language pairs. We also show that the resulting model leverages context in an intended and interpretable way, improving consistency between the conveyed message and the generated translations.",
      "authors": [
        "Jos\\'e Pombal",
        "Sweta Agrawal",
        "Patrick Fernandes",
        "Emmanouil Zaranis",
        "Andr\\'e F. T. Martins"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-05T14:41:05+00:00",
          "link": "https://arxiv.org/abs/2412.04205v1",
          "size": "10952kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T15:38:34+00:00",
          "link": "https://arxiv.org/abs/2412.04205v2",
          "size": "9826kb",
          "version": "v2"
        }
      ],
      "title": "A Context-aware Framework for Translation-mediated Conversations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.04205",
        "HTML": "https://arxiv.org/html/2412.04205v2",
        "PDF": "https://arxiv.org/pdf/2412.04205"
      },
      "tasks": [
        "Large Language Model",
        "Translation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.06954",
      "abstract": "Given the dominance of dense retrievers that do not generalize well beyond their training dataset distributions, domain-specific test sets are essential in evaluating retrieval. There are few test datasets for retrieval systems intended for use by healthcare providers in a point-of-care setting. To fill this gap we have collaborated with medical professionals to create CURE, an ad-hoc retrieval test dataset for passage ranking with 2000 queries spanning 10 medical domains with a monolingual (English) and two cross-lingual (French/Spanish -> English) conditions. In this paper, we describe how CURE was constructed and provide baseline results to showcase its effectiveness as an evaluation tool. CURE is published with a Creative Commons Attribution Non Commercial 4.0 license and can be accessed on Hugging Face and as a retrieval task on MTEB.",
      "authors": [
        "Nadia Athar Sheikh",
        "Daniel Buades Marcos",
        "Anne-Laure Jousse",
        "Akintunde Oladipo",
        "Olivier Rousseau",
        "Jimmy Lin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-09T20:01:59+00:00",
          "link": "https://arxiv.org/abs/2412.06954v1",
          "size": "136kb",
          "version": "v1"
        },
        {
          "date": "2024-12-11T16:46:25+00:00",
          "link": "https://arxiv.org/abs/2412.06954v2",
          "size": "136kb",
          "version": "v2"
        },
        {
          "date": "2024-12-16T16:18:28+00:00",
          "link": "https://arxiv.org/abs/2412.06954v3",
          "size": "136kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T19:09:49+00:00",
          "link": "https://arxiv.org/abs/2412.06954v4",
          "size": "228kb",
          "version": "v4"
        }
      ],
      "title": "CURE: A Dataset for Clinical Understanding & Retrieval Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.06954",
        "HTML": "https://arxiv.org/html/2412.06954v4",
        "PDF": "https://arxiv.org/pdf/2412.06954"
      },
      "datasets": [
        {
          "dataset_name": "clinia/CUREv1",
          "downloads": "773",
          "likes": "4",
          "link": "https://huggingface.co/datasets/clinia/CUREv1"
        }
      ],
      "tasks": [
        "Passage Ranking",
        "Retrieval"
      ],
      "repo_urls": [
        "https://github.com/embeddings-benchmark/mteb/blob/main/mteb/tasks/Retrieval/multilingual/CUREv1Retrieval.py"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.06990",
      "abstract": "We study the problem of solving matrix games of the form $\\max_{\\mathbf{w}\\in\\mathcal{W}}\\min_{\\mathbf{p}\\in\\Delta}\\mathbf{p}^{\\top}A\\mathbf{w}$, where $A$ is some matrix and $\\Delta$ is the probability simplex. This problem encapsulates canonical tasks such as finding a linear separator and computing Nash equilibria in zero-sum games. However, perhaps surprisingly, its inherent complexity (as formalized in the standard framework of oracle complexity [Nemirovski and Yudin, 1983]) is not well-understood. In this work, we first identify different oracle models which are implicitly used by prior algorithms, amounting to multiplying the matrix $A$ by a vector from either one or both sides. We then prove complexity lower bounds for algorithms under both access models, which in particular imply a separation between them. Specifically, we start by showing that algorithms for linear separability based on one-sided multiplications must require $\\Omega(\\gamma_A^{-2})$ iterations, where $\\gamma_A$ is the margin, as matched by the Perceptron algorithm. We then prove that accelerated algorithms for this task, which utilize multiplications from both sides, must require $\\tilde{\\Omega}(\\gamma_{A}^{-2/3})$ iterations, establishing the first oracle complexity barrier for such algorithms. Finally, by adapting our lower bound to $\\ell_1$ geometry, we prove that computing an $\\epsilon$-approximate Nash equilibrium requires $\\tilde{\\Omega}(\\epsilon^{-2/5})$ iterations, which is an exponential improvement over the previously best-known lower bound due to Hadiji et al. [2024].",
      "authors": [
        "Guy Kornowski",
        "Ohad Shamir"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-09T20:58:26+00:00",
          "link": "https://arxiv.org/abs/2412.06990v1",
          "size": "26kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T00:10:41+00:00",
          "link": "https://arxiv.org/abs/2412.06990v2",
          "size": "24kb",
          "version": "v2"
        }
      ],
      "title": "The Oracle Complexity of Simplex-based Matrix Games: Linear Separability and Nash Equilibria",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.06990",
        "HTML": "https://arxiv.org/html/2412.06990v2",
        "PDF": "https://arxiv.org/pdf/2412.06990"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.09442",
      "abstract": "Textual-based prompt learning methods primarily employ multiple learnable soft prompts and hard class tokens in a cascading manner as text inputs, aiming to align image and text (category) spaces for downstream tasks. However, current training is restricted to aligning images with predefined known categories and cannot be associated with unknown categories. In this work, we propose utilizing universal attributes as a bridge to enhance the alignment between images and unknown categories. Specifically, we introduce an Attribute-anchored Textual Prompt learning method for vision-language models, named ATPrompt. This approach expands the learning space of soft prompts from the original one-dimensional category level into the multi-dimensional attribute level by incorporating multiple attribute tokens into the learnable soft prompts. Through this modification, we transform the text prompt from a category-centric form to an attribute-category hybrid form. Additionally, we introduce a straightforward differentiable attribute search method to identify representative and suitable attributes for downstream tasks. As an easy-to-use plug-in technique, ATPrompt can seamlessly replace the existing basic prompt format in textual-based methods, providing general improvements at a negligible computational cost. Extensive experiments across 11 datasets validate the effectiveness of our method.",
      "authors": [
        "Zheng Li",
        "Yibing Song",
        "Ming-Ming Cheng",
        "Xiang Li",
        "Jian Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-12T16:57:20+00:00",
          "link": "https://arxiv.org/abs/2412.09442v1",
          "size": "2168kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T13:54:19+00:00",
          "link": "https://arxiv.org/abs/2412.09442v2",
          "size": "2037kb",
          "version": "v2"
        }
      ],
      "title": "Advancing Textual Prompt Learning with Anchored Attributes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.09442",
        "HTML": "https://arxiv.org/html/2412.09442v2",
        "PDF": "https://arxiv.org/pdf/2412.09442"
      },
      "tasks": [
        "Attribute",
        "Large Language Model",
        "Prompt Learning"
      ],
      "repo_urls": [
        "https://github.com/zhengli97/promptkd"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.10266",
      "abstract": "Stance detection is crucial for fostering a human-centric Web by analyzing user-generated content to identify biases and harmful narratives that undermine trust. With the development of Large Language Models (LLMs), existing approaches treat stance detection as a classification problem, providing robust methodologies for modeling complex group interactions and advancing capabilities in natural language tasks. However, these methods often lack interpretability, limiting their ability to offer transparent and understandable justifications for predictions. This study adopts a generative approach, where stance predictions include explicit, interpretable rationales, and integrates them into smaller language models through single-task and multitask learning. We find that incorporating reasoning into stance detection enables the smaller model (FlanT5) to outperform GPT-3.5's zero-shot performance, achieving an improvement of up to 9.57%. Moreover, our results show that reasoning capabilities enhance multitask learning performance but may reduce effectiveness in single-task settings. Crucially, we demonstrate that faithful rationales improve rationale distillation into SLMs, advancing efforts to build interpretable, trustworthy systems for addressing discrimination, fostering trust, and promoting equitable engagement on social media.",
      "authors": [
        "Jiaqing Yuan",
        "Ruijie Xi",
        "Munindar P. Singh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-13T16:34:39+00:00",
          "link": "https://arxiv.org/abs/2412.10266v1",
          "size": "1197kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T00:26:57+00:00",
          "link": "https://arxiv.org/abs/2412.10266v2",
          "size": "798kb",
          "version": "v2"
        }
      ],
      "title": "Reasoner Outperforms: Generative Stance Detection with Rationalization for Social Media",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.10266",
        "HTML": "https://arxiv.org/html/2412.10266v2",
        "PDF": "https://arxiv.org/pdf/2412.10266"
      },
      "tasks": [
        "Stance Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.10354",
      "abstract": "We present NeuralOperator, an open-source Python library for operator learning. Neural operators generalize neural networks to maps between function spaces instead of finite-dimensional Euclidean spaces. They can be trained and inferenced on input and output functions given at various discretizations, satisfying a discretization convergence properties. Built on top of PyTorch, NeuralOperator provides all the tools for training and deploying neural operator models, as well as developing new ones, in a high-quality, tested, open-source package. It combines cutting-edge models and customizability with a gentle learning curve and simple user interface for newcomers.",
      "authors": [
        "Jean Kossaifi",
        "Nikola Kovachki",
        "Zongyi Li",
        "David Pitt",
        "Miguel Liu-Schiaffini",
        "Valentin Duruisseaux",
        "Robert Joseph George",
        "Boris Bonev",
        "Kamyar Azizzadenesheli",
        "Julius Berner",
        "Anima Anandkumar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-13T18:49:37+00:00",
          "link": "https://arxiv.org/abs/2412.10354v1",
          "size": "111kb",
          "version": "v1"
        },
        {
          "date": "2024-12-17T21:15:33+00:00",
          "link": "https://arxiv.org/abs/2412.10354v2",
          "size": "111kb",
          "version": "v2"
        },
        {
          "date": "2025-04-30T17:23:25+00:00",
          "link": "https://arxiv.org/abs/2412.10354v3",
          "size": "111kb",
          "version": "v3"
        },
        {
          "date": "2025-06-29T17:09:59+00:00",
          "link": "https://arxiv.org/abs/2412.10354v4",
          "size": "50kb",
          "version": "v4"
        }
      ],
      "title": "A Library for Learning Neural Operators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.10354",
        "HTML": "https://arxiv.org/html/2412.10354v4",
        "PDF": "https://arxiv.org/pdf/2412.10354"
      },
      "tasks": [
        "Operator learning"
      ],
      "repo_urls": [
        "https://github.com/neuraloperator/neuraloperator"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.10493",
      "abstract": "Text-to-image (T2I) models are widespread, but their limited safety guardrails expose end users to harmful content and potentially allow for model misuse. Current safety measures are typically limited to text-based filtering or concept removal strategies, able to remove just a few concepts from the model's generative capabilities. In this work, we introduce AlignGuard, a method for safety alignment of T2I models. We enable the application of Direct Preference Optimization (DPO) for safety purposes in T2I models by synthetically generating a dataset of harmful and safe image-text pairs, which we call CoProV2. Using a custom DPO strategy and this dataset, we train safety experts, in the form of low-rank adaptation (LoRA) matrices, able to guide the generation process away from specific safety-related concepts. Then, we merge the experts into a single LoRA using a novel merging strategy for optimal scaling performance. This expert-based approach enables scalability, allowing us to remove 7x more harmful concepts from T2I models compared to baselines. AlignGuard consistently outperforms the state-of-the-art on many benchmarks and establishes new practices for safety alignment in T2I networks. Code and data will be shared at https://safetydpo.github.io/.",
      "authors": [
        "Runtao Liu",
        "I Chieh Chen",
        "Jindong Gu",
        "Jipeng Zhang",
        "Renjie Pi",
        "Qifeng Chen",
        "Philip Torr",
        "Ashkan Khakzar",
        "Fabio Pizzati"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-13T18:59:52+00:00",
          "link": "https://arxiv.org/abs/2412.10493v1",
          "size": "10517kb",
          "version": "v1"
        },
        {
          "date": "2025-06-24T20:53:27+00:00",
          "link": "https://arxiv.org/abs/2412.10493v2",
          "size": "52462kb",
          "version": "v2"
        }
      ],
      "title": "AlignGuard: Scalable Safety Alignment for Text-to-Image Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.10493",
        "PDF": "https://arxiv.org/pdf/2412.10493"
      },
      "tasks": [
        "Image Generation",
        "Safety Alignment",
        "Text to Image Generation",
        "Text-to-Image Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.10718",
      "abstract": "Visual generation has witnessed remarkable progress in single-image tasks, yet extending these capabilities to temporal sequences remains challenging. Current approaches either build specialized video models from scratch with enormous computational costs or add separate motion modules to image generators, both requiring learning temporal dynamics anew. We observe that modern image generation models possess underutilized potential in handling structured layouts with implicit temporal understanding. Building on this insight, we introduce GRID, which reformulates temporal sequences as grid layouts, enabling holistic processing of visual sequences while leveraging existing model capabilities. Through a parallel flow-matching training strategy with coarse-to-fine scheduling, our approach achieves up to 67 faster inference speeds while using <1/1000 of the computational resources compared to specialized models. Extensive experiments demonstrate that GRID not only excels in temporal tasks from Text-to-Video to 3D Editing but also preserves strong performance in image generation, establishing itself as an efficient and versatile omni-solution for visual generation.",
      "authors": [
        "Cong Wan",
        "Xiangyang Luo",
        "Hao Luo",
        "Zijian Cai",
        "Yiren Song",
        "Yunlong Zhao",
        "Yifan Bai",
        "Fan Wang",
        "Yuhang He",
        "Yihong Gong"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-14T07:22:03+00:00",
          "link": "https://arxiv.org/abs/2412.10718v1",
          "size": "26772kb",
          "version": "v1"
        },
        {
          "date": "2024-12-17T05:24:57+00:00",
          "link": "https://arxiv.org/abs/2412.10718v2",
          "size": "26772kb",
          "version": "v2"
        },
        {
          "date": "2025-01-10T07:20:26+00:00",
          "link": "https://arxiv.org/abs/2412.10718v3",
          "size": "26774kb",
          "version": "v3"
        },
        {
          "date": "2025-01-21T04:00:36+00:00",
          "link": "https://arxiv.org/abs/2412.10718v4",
          "size": "29394kb",
          "version": "v4"
        },
        {
          "date": "2025-06-30T10:03:43+00:00",
          "link": "https://arxiv.org/abs/2412.10718v5",
          "size": "11147kb",
          "version": "v5"
        }
      ],
      "title": "Grid: Omni Visual Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.10718",
        "HTML": "https://arxiv.org/html/2412.10718v5",
        "PDF": "https://arxiv.org/pdf/2412.10718"
      },
      "tasks": [
        "Image Generation",
        "Scheduling",
        "Temporal Sequences"
      ],
      "repo_urls": [
        "https://github.com/should-ai-lab/grid"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.12386",
      "abstract": "Interpretability in Table Question Answering (Table QA) is critical, especially in high-stakes domains like finance and healthcare. While recent Table QA approaches based on Large Language Models (LLMs) achieve high accuracy, they often produce ambiguous explanations of how answers are derived.\n  We propose Plan-of-SQLs (POS), a new Table QA method that makes the model's decision-making process interpretable. POS decomposes a question into a sequence of atomic steps, each directly translated into an executable SQL command on the table, thereby ensuring that every intermediate result is transparent. Through extensive experiments, we show that: First, POS generates the highest-quality explanations among compared methods, which markedly improves the users' ability to simulate and verify the model's decisions. Second, when evaluated on standard Table QA benchmarks (TabFact, WikiTQ, and FeTaQA), POS achieves QA accuracy that is competitive to existing methods, while also offering greater efficiency-requiring significantly fewer LLM calls and table database queries (up to 25x fewer)-and more robust performance on large-sized tables. Finally, we observe high agreement (up to 90.59% in forward simulation) between LLMs and human users when making decisions based on the same explanations, suggesting that LLMs could serve as an effective proxy for humans in evaluating Table QA explanations.",
      "authors": [
        "Giang Nguyen",
        "Ivan Brugere",
        "Shubham Sharma",
        "Sanjay Kariyappa",
        "Anh Totti Nguyen",
        "Freddy Lecue"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-16T22:44:31+00:00",
          "link": "https://arxiv.org/abs/2412.12386v1",
          "size": "3005kb",
          "version": "v1"
        },
        {
          "date": "2025-04-02T22:07:14+00:00",
          "link": "https://arxiv.org/abs/2412.12386v2",
          "size": "3346kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T18:26:11+00:00",
          "link": "https://arxiv.org/abs/2412.12386v3",
          "size": "2254kb",
          "version": "v3"
        }
      ],
      "title": "Interpretable LLM-based Table Question Answering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.12386",
        "HTML": "https://arxiv.org/html/2412.12386v3",
        "PDF": "https://arxiv.org/pdf/2412.12386"
      },
      "tasks": [
        "POS",
        "Question Answering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.12873",
      "abstract": "Finding heavy hitters in databases and data streams is a fundamental problem with applications ranging from network monitoring to database query optimization, machine learning, and more. Approximation algorithms offer practical solutions, but they present trade-offs involving throughput, memory usage, and accuracy. Moreover, modern applications further complicate these trade-offs by demanding capabilities beyond sequential processing that require both parallel scaling and support for concurrent queries and updates.\n  Analysis of these trade-offs led us to the key idea behind our proposed streaming algorithm, Cuckoo Heavy Keeper (CHK). The approach introduces an inverted process for distinguishing frequent from infrequent items, which unlocks new algorithmic synergies that were previously inaccessible with conventional approaches. By further analyzing the competing metrics with a focus on parallelism, we propose an algorithmic framework that balances scalability aspects and provides options to optimize query and insertion efficiency based on their relative frequencies. The framework is capable of parallelizing any heavy-hitter detection algorithm.\n  Besides the algorithms' analysis, we present an extensive evaluation on both real-world and synthetic data across diverse distributions and query selectivity, representing the broad spectrum of application needs. Compared to state-of-the-art methods, CHK improves throughput by 1.7-5.7$\\times$ and accuracy by up to four orders of magnitude even under low-skew data and tight memory constraints. These properties allow its parallel instances to achieve near-linear scale-up and low latency for heavy-hitter queries, even under a high query rate. We expect the versatility of CHK and its parallel instances to impact a broad spectrum of tools and applications in large-scale data analytics and stream processing systems",
      "authors": [
        "Vinh Quang Ngo",
        "Marina Papatriantafilou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-17T12:52:52+00:00",
          "link": "https://arxiv.org/abs/2412.12873v1",
          "size": "1402kb",
          "version": "v1"
        },
        {
          "date": "2025-04-03T15:02:23+00:00",
          "link": "https://arxiv.org/abs/2412.12873v2",
          "size": "1760kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T14:46:17+00:00",
          "link": "https://arxiv.org/abs/2412.12873v3",
          "size": "365kb",
          "version": "v3"
        }
      ],
      "title": "Cuckoo Heavy Keeper and the balancing act of maintaining heavy hitters in stream processing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.12873",
        "PDF": "https://arxiv.org/pdf/2412.12873"
      },
      "repo_urls": [
        "https://github.com/vinhqngo5/cuckoo_heavy_keeper"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.13964",
      "abstract": "When considering risky events or actions, we must not downplay the role of involved objects: a charged battery in our phone averts the risk of being stranded in the desert after a flat tyre, and a functional firewall mitigates the risk of a hacker intruding the network. The Common Ontology of Value and Risk (COVER) highlights how the role of objects and their relationships remains pivotal to performing transparent, complete and accountable risk assessment. In this paper, we operationalize some of the notions proposed by COVER -- such as parthood between objects and participation of objects in events/actions -- by presenting a new framework for risk assessment: WATCHDOG. WATCHDOG enriches the expressivity of vetted formal models for risk -- i.e., fault trees and attack trees -- by bridging the disciplines of ontology and formal methods into an ontology-aware formal framework composed by a more expressive modelling formalism, Object-Oriented Disruption Graphs (DOGs), logic (DOGLog) and an intermediate query language (DOGLang). With these, WATCHDOG allows risk assessors to pose questions about disruption propagation, disruption likelihood and risk levels, keeping the fundamental role of objects at risk always in sight.",
      "authors": [
        "Stefano M. Nicoletti and E. Moritz Hahn and Mattia Fumagalli and Giancarlo Guizzardi and Mari\\\"elle Stoelinga"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-18T15:44:04+00:00",
          "link": "https://arxiv.org/abs/2412.13964v1",
          "size": "1064kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T13:52:42+00:00",
          "link": "https://arxiv.org/abs/2412.13964v2",
          "size": "836kb",
          "version": "v2"
        }
      ],
      "title": "WATCHDOG: an ontology-aWare risk AssessmenT approaCH via object-oriented DisruptiOn Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.13964",
        "HTML": "https://arxiv.org/html/2412.13964v2",
        "PDF": "https://arxiv.org/pdf/2412.13964"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.14030",
      "abstract": "Wastewater treatment plants are increasingly recognized as promising candidates for machine learning applications, due to their societal importance and high availability of data. However, their varied designs, operational conditions, and influent characteristics hinder straightforward automation. In this study, we use data from a pilot reactor at the Veas treatment facility in Norway to explore how machine learning can be used to optimize biological nitrate ($\\mathrm{NO_3^-}$) reduction to molecular nitrogen ($\\mathrm{N_2}$) in the biogeochemical process known as \\textit{denitrification}. Rather than focusing solely on predictive accuracy, our approach prioritizes understanding the foundational requirements for effective data-driven modelling of wastewater treatment. Specifically, we aim to identify which process parameters are most critical, the necessary data quantity and quality, how to structure data effectively, and what properties are required by the models. We find that nonlinear models perform best on the training and validation data sets, indicating nonlinear relationships to be learned, but linear models transfer better to the unseen test data, which comes later in time. The variable measuring the water temperature has a particularly detrimental effect on the models, owing to a significant change in distributions between training and test data. We therefore conclude that multiple years of data is necessary to learn robust machine learning models. By addressing foundational elements, particularly in the context of the climatic variability faced by northern regions, this work lays the groundwork for a more structured and tailored approach to machine learning for wastewater treatment. We share publicly both the data and code used to produce the results in the paper.",
      "authors": [
        "Eivind B{\\o}hn",
        "S{\\o}lve Eidnes and Kjell Rune Jonassen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-18T16:49:23+00:00",
          "link": "https://arxiv.org/abs/2412.14030v1",
          "size": "1024kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T11:41:43+00:00",
          "link": "https://arxiv.org/abs/2412.14030v2",
          "size": "593kb",
          "version": "v2"
        }
      ],
      "title": "Machine learning in wastewater treatment: insights from modelling a pilot denitrification reactor",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.14030",
        "PDF": "https://arxiv.org/pdf/2412.14030"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.15171",
      "abstract": "Gaussian-based human avatars have achieved an unprecedented level of visual fidelity. However, existing approaches based on high-capacity neural networks typically require a desktop GPU to achieve real-time performance for a single avatar, and it remains non-trivial to animate and render such avatars on mobile devices including a standalone VR headset due to substantially limited memory and computational bandwidth. In this paper, we present SqueezeMe, a simple and highly effective framework to convert high-fidelity 3D Gaussian full-body avatars into a lightweight representation that supports both animation and rendering with mobile-grade compute. Our key observation is that the decoding of pose-dependent Gaussian attributes from a neural network creates non-negligible memory and computational overhead. Inspired by blendshapes and linear pose correctives widely used in Computer Graphics, we address this by distilling the pose correctives learned with neural networks into linear layers. Moreover, we further reduce the parameters by sharing the correctives among nearby Gaussians. Combining them with a custom splatting pipeline based on Vulkan, we achieve, for the first time, simultaneous animation and rendering of 3 Gaussian avatars in real-time (72 FPS) on a Meta Quest 3 VR headset. Demo videos are available at https://forresti.github.io/squeezeme.",
      "authors": [
        "Forrest Iandola",
        "Stanislav Pidhorskyi",
        "Igor Santesteban",
        "Divam Gupta",
        "Anuj Pahuja",
        "Nemanja Bartolovic",
        "Frank Yu",
        "Emanuel Garbin",
        "Tomas Simon",
        "Shunsuke Saito"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-19T18:46:55+00:00",
          "link": "https://arxiv.org/abs/2412.15171v1",
          "size": "4865kb",
          "version": "v1"
        },
        {
          "date": "2024-12-21T00:13:54+00:00",
          "link": "https://arxiv.org/abs/2412.15171v2",
          "size": "4865kb",
          "version": "v2"
        },
        {
          "date": "2025-02-17T23:29:25+00:00",
          "link": "https://arxiv.org/abs/2412.15171v3",
          "size": "6873kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T18:35:11+00:00",
          "link": "https://arxiv.org/abs/2412.15171v4",
          "size": "9008kb",
          "version": "v4"
        }
      ],
      "title": "SqueezeMe: Mobile-Ready Distillation of Gaussian Full-Body Avatars",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.15171",
        "HTML": "https://arxiv.org/html/2412.15171v4",
        "PDF": "https://arxiv.org/pdf/2412.15171"
      },
      "tasks": [
        "Decoder"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.16105",
      "abstract": "Load uncertainty must be accounted for during design to ensure building energy systems can meet energy demands during operation. Reducing building load uncertainty allows for improved designs with less compromise to be identified, reducing the cost of decarbonizing energy usage. However, the building monitoring required to reduce load uncertainty is costly.\n  This study uses Value of Information analysis (VoI) to quantify the economic benefit of practical building monitoring for supporting energy system design decisions, and determine if its benefits outweigh its cost. An extension of the VoI framework, termed 'On-Policy' VoI, is proposed, which admits complex decision making tasks where decision policies are required. This is applied to a case study district energy system design problem, where a Linear Program model is used to size solar-battery systems and grid connection capacity under uncertain building loads, modelled using historic electricity metering data.\n  Load uncertainty is found to significantly impact both system operating costs ($\\pm$30%) and the optimal system design ($\\pm$20%). However, using building monitoring data to improve the design of the district reduces overall costs by less than 1.5% on average. As this is less than the cost of measurement, using monitoring is not economically worthwhile in this case. This provides the first numerical evidence to support the sufficiency of using standard building load profiles for energy system design. Further, reducing only uncertainty in mean load is found to provide most of the available decision support benefit, meaning using hourly measurement data provides little benefit for energy retrofit design.",
      "authors": [
        "Max Langtry",
        "Ruchi Choudhary"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-20T17:45:56+00:00",
          "link": "https://arxiv.org/abs/2412.16105v1",
          "size": "6188kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T16:23:40+00:00",
          "link": "https://arxiv.org/abs/2412.16105v2",
          "size": "6173kb",
          "version": "v2"
        }
      ],
      "title": "Quantifying the benefit of load uncertainty reduction for the design of district energy systems under grid constraints using the Value of Information",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.16105",
        "HTML": "https://arxiv.org/html/2412.16105v2",
        "PDF": "https://arxiv.org/pdf/2412.16105"
      },
      "tasks": [
        "Decision Making"
      ],
      "repo_urls": [
        "https://github.com/mal84emma/Building-Design-VoI"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.17063",
      "abstract": "This work presents a computational approach to analyze character development along the narrative timeline. The analysis characterizes the inner and outer changes the protagonist undergoes within a narrative, and the interplay between them. We consider transcripts of Holocaust survivor testimonies as a test case, each telling the story of an individual in first-person terms. We focus on the survivor's religious trajectory, examining the evolution of their disposition toward religious belief and practice along the testimony. Clustering the resulting trajectories in the dataset, we identify common sequences in the data. Our findings highlight multiple common structures of religiosity across the narratives: in terms of belief, most present a constant disposition, while for practice, most present an oscillating structure, serving as valuable material for historical and sociological research. This work demonstrates the potential of natural language processing techniques for analyzing character evolution through thematic trajectories in narratives.",
      "authors": [
        "Esther Shizgal",
        "Eitan Wagner",
        "Renana Keydar",
        "Omri Abend"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-22T15:20:53+00:00",
          "link": "https://arxiv.org/abs/2412.17063v1",
          "size": "5064kb",
          "version": "v1"
        },
        {
          "date": "2025-06-03T12:53:28+00:00",
          "link": "https://arxiv.org/abs/2412.17063v2",
          "size": "11209kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T11:39:21+00:00",
          "link": "https://arxiv.org/abs/2412.17063v3",
          "size": "4157kb",
          "version": "v3"
        }
      ],
      "title": "Computational Analysis of Character Development in Holocaust Testimonies",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.17063",
        "HTML": "https://arxiv.org/html/2412.17063v3",
        "PDF": "https://arxiv.org/pdf/2412.17063"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.18543",
      "abstract": "In this paper, we present a data-driven representation for linear parameter-varying (LPV) systems, which can be used for direct data-driven analysis and control of such systems. Specifically, we use the behavioral approach to develop a data-driven representation of the finite-horizon behavior of LPV systems for which there exists a kernel representation with shifted-affine scheduling dependence. Moreover, we provide a necessary and sufficient rank-based test on the available data that concludes whether the data fully represents the finite-horizon LPV behavior. Using the proposed data-driven representation, we also solve the data-driven simulation problem for LPV systems. Through multiple examples, we demonstrate that the results in this paper allow us to formulate a novel set of direct data-driven analysis and control methods for LPV systems, which are also applicable for LPV embeddings of nonlinear systems.",
      "authors": [
        "Chris Verhoek",
        "Ivan Markovsky",
        "Sofie Haesaert",
        "Roland T\\'oth"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-24T16:48:41+00:00",
          "link": "https://arxiv.org/abs/2412.18543v1",
          "size": "576kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T14:51:16+00:00",
          "link": "https://arxiv.org/abs/2412.18543v2",
          "size": "3815kb",
          "version": "v2"
        }
      ],
      "title": "A behavioral approach for LPV data-driven representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.18543",
        "HTML": "https://arxiv.org/html/2412.18543v2",
        "PDF": "https://arxiv.org/pdf/2412.18543"
      },
      "tasks": [
        "Scheduling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.19326",
      "abstract": "Current multimodal large language models (MLLMs) struggle with fine-grained or precise understanding of visuals although they give comprehensive perception and reasoning in a spectrum of vision applications. Recent studies either develop tool-using or unify specific visual tasks into the autoregressive framework, often at the expense of overall multimodal performance. To address this issue and enhance MLLMs with visual tasks in a scalable fashion, we propose Task Preference Optimization (TPO), a novel method that utilizes differentiable task preferences derived from typical fine-grained visual tasks. TPO introduces learnable task tokens that establish connections between multiple task-specific heads and the MLLM. By leveraging rich visual labels during training, TPO significantly enhances the MLLM's multimodal capabilities and task-specific performance. Through multi-task co-training within TPO, we observe synergistic benefits that elevate individual task performance beyond what is achievable through single-task training methodologies. Our instantiation of this approach with VideoChat and LLaVA demonstrates an overall 14.6% improvement in multimodal performance compared to baseline models. Additionally, MLLM-TPO demonstrates robust zero-shot capabilities across various tasks, performing comparably to state-of-the-art supervised models. The code will be released at https://github.com/OpenGVLab/TPO",
      "authors": [
        "Ziang Yan",
        "Zhilin Li",
        "Yinan He",
        "Chenting Wang",
        "Kunchang Li",
        "Xinhao Li",
        "Xiangyu Zeng",
        "Zilei Wang",
        "Yali Wang",
        "Yu Qiao",
        "Limin Wang",
        "Yi Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-26T18:56:05+00:00",
          "link": "https://arxiv.org/abs/2412.19326v1",
          "size": "6124kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T13:15:13+00:00",
          "link": "https://arxiv.org/abs/2412.19326v2",
          "size": "6123kb",
          "version": "v2"
        }
      ],
      "title": "Task Preference Optimization: Improving Multimodal Large Language Models with Vision Task Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.19326",
        "HTML": "https://arxiv.org/html/2412.19326v2",
        "PDF": "https://arxiv.org/pdf/2412.19326"
      },
      "models": [
        {
          "model_path": "OpenGVLab/VideoChat-TPO",
          "downloads": "25",
          "likes": "5",
          "trending_score": "0.0",
          "link": "https://huggingface.co/OpenGVLab/VideoChat-TPO"
        }
      ],
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Yan_Task_Preference_Optimization_Improving_Multimodal_Large_Language_Models_with_Vision_CVPR_2025_paper.html",
      "tasks": [],
      "repo_urls": [
        "https://github.com/opengvlab/tpo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.19628",
      "abstract": "Recent advances in vision transformers (ViTs) have demonstrated the advantage of global modeling capabilities, prompting widespread integration of large-kernel convolutions for enlarging the effective receptive field (ERF). However, the quadratic scaling of parameter count and computational complexity (FLOPs) with respect to kernel size poses significant efficiency and optimization challenges. This paper introduces RecConv, a recursive decomposition strategy that efficiently constructs multi-frequency representations using small-kernel convolutions. RecConv establishes a linear relationship between parameter growth and decomposing levels which determines the effective receptive field $k\\times 2^\\ell$ for a base kernel $k$ and $\\ell$ levels of decomposition, while maintaining constant FLOPs regardless of the ERF expansion. Specifically, RecConv achieves a parameter expansion of only $\\ell+2$ times and a maximum FLOPs increase of $5/3$ times, compared to the exponential growth ($4^\\ell$) of standard and depthwise convolutions. RecNeXt-M3 outperforms RepViT-M1.1 by 1.9 $AP^{box}$ on COCO with similar FLOPs. This innovation provides a promising avenue towards designing efficient and compact networks across various modalities. Codes and models can be found at https://github.com/suous/RecNeXt.",
      "authors": [
        "Mingshu Zhao",
        "Yi Luo",
        "Yong Ouyang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-27T13:13:52+00:00",
          "link": "https://arxiv.org/abs/2412.19628v1",
          "size": "1954kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T17:22:15+00:00",
          "link": "https://arxiv.org/abs/2412.19628v2",
          "size": "8717kb",
          "version": "v2"
        }
      ],
      "title": "RecConv: Efficient Recursive Convolutions for Multi-Frequency Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.19628",
        "HTML": "https://arxiv.org/html/2412.19628v2",
        "PDF": "https://arxiv.org/pdf/2412.19628"
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/suous/recnext"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.20471",
      "abstract": "We study zero-sum games in the space of probability distributions over the Euclidean space $\\mathbb{R}^d$ with entropy regularization, in the setting when the interaction function between the players is smooth and strongly convex-strongly concave. We prove an exponential convergence guarantee for the mean-field min-max Langevin dynamics to compute the equilibrium distribution of the zero-sum game. We also study the finite-particle approximation of the mean-field min-max Langevin dynamics, both in continuous and discrete times. We prove biased convergence guarantees for the continuous-time finite-particle min-max Langevin dynamics to the stationary mean-field equilibrium distribution with an explicit bias term which does not scale with the number of particles. We also prove biased convergence guarantees for the discrete-time finite-particle min-max Langevin algorithm to the stationary mean-field equilibrium distribution with an additional bias term which scales with the step size and the number of particles. This provides an explicit iteration complexity for the average particle along the finite-particle algorithm to approximately compute the equilibrium distribution of the zero-sum game.",
      "authors": [
        "Yang Cai",
        "Siddharth Mitra",
        "Xiuyuan Wang",
        "Andre Wibisono"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-29T14:20:23+00:00",
          "link": "https://arxiv.org/abs/2412.20471v1",
          "size": "58kb",
          "version": "v1"
        },
        {
          "date": "2025-02-07T14:12:47+00:00",
          "link": "https://arxiv.org/abs/2412.20471v2",
          "size": "63kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T00:02:09+00:00",
          "link": "https://arxiv.org/abs/2412.20471v3",
          "size": "63kb",
          "version": "v3"
        }
      ],
      "title": "On the Convergence of Min-Max Langevin Dynamics and Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.20471",
        "PDF": "https://arxiv.org/pdf/2412.20471"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.20521",
      "abstract": "In table grape cultivation, harvesting depends on accurately assessing fruit quality. While some characteristics, like color, are visible, others, such as Soluble Solid Content (SSC), or sugar content measured in degrees Brix ({\\deg}Brix), require specific tools. SSC is a key quality factor that correlates with ripeness, but lacks a direct causal relationship with color. Hyperspectral cameras can estimate SSC with high accuracy under controlled laboratory conditions, but their practicality in field environments is limited. This study investigates the potential of simple RGB sensors under uncontrolled lighting to estimate SSC and color, enabling cost-effective, robot-assisted harvesting. Over the 2021 and 2022 summer seasons, we collected grape images with corresponding SSC and color labels to evaluate algorithmic solutions for SSC estimation, specifically testing for cross-seasonal and cross-device robustness. We propose two approaches: a computationally efficient histogram-based method for resource-constrained robots and a Deep Neural Network (DNN) model for more complex applications. Our results demonstrate high performance, with the DNN model achieving a Mean Absolute Error (MAE) as low as $1.05$ {\\deg}Brix on a challenging cross-device test set. The lightweight histogram-based method also proved effective, reaching an MAE of $1.46$ {\\deg}Brix. These results are highly competitive with those from hyperspectral systems, which report errors in the $1.27$--$2.20$ {\\deg}Brix range in similar field applications.",
      "authors": [
        "Thomas Alessandro Ciarfuglia",
        "Ionut Marian Motoi",
        "Leonardo Saraceni",
        "Daniele Nardi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-29T17:10:35+00:00",
          "link": "https://arxiv.org/abs/2412.20521v1",
          "size": "9945kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T10:44:14+00:00",
          "link": "https://arxiv.org/abs/2412.20521v2",
          "size": "8309kb",
          "version": "v2"
        }
      ],
      "title": "Can Robots \"Taste\" Grapes? Estimating SSC with Simple RGB Sensors",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.20521",
        "HTML": "https://arxiv.org/html/2412.20521v2",
        "PDF": "https://arxiv.org/pdf/2412.20521"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.20892",
      "abstract": "The ideas of aleatoric and epistemic uncertainty are widely used to reason about the probabilistic predictions of machine-learning models. We identify incoherence in existing discussions of these ideas and suggest this stems from the aleatoric-epistemic view being insufficiently expressive to capture all the distinct quantities that researchers are interested in. To address this we present a decision-theoretic perspective that relates rigorous notions of uncertainty, predictive performance and statistical dispersion in data. This serves to support clearer thinking as the field moves forward. Additionally we provide insights into popular information-theoretic quantities, showing they can be poor estimators of what they are often purported to measure, while also explaining how they can still be useful in guiding data acquisition.",
      "authors": [
        "Freddie Bickford Smith",
        "Jannik Kossen",
        "Eleanor Trollope",
        "Mark van der Wilk",
        "Adam Foster",
        "Tom Rainforth"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-30T12:04:36+00:00",
          "link": "https://arxiv.org/abs/2412.20892v1",
          "size": "46kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T10:42:51+00:00",
          "link": "https://arxiv.org/abs/2412.20892v2",
          "size": "622kb",
          "version": "v2"
        }
      ],
      "title": "Rethinking Aleatoric and Epistemic Uncertainty",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.20892",
        "HTML": "https://arxiv.org/html/2412.20892v2",
        "PDF": "https://arxiv.org/pdf/2412.20892"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2501.01644",
      "abstract": "Biomedical Knowledge Graphs (BKGs) integrate diverse datasets to elucidate complex relationships within the biomedical field. Effective link prediction on these graphs can uncover valuable connections, such as potential novel drug-disease relations. We introduce a novel multimodal approach that unifies embeddings from specialized Language Models (LMs) with Graph Contrastive Learning (GCL) to enhance intra-entity relationships while employing a Knowledge Graph Embedding (KGE) model to capture inter-entity relationships for effective link prediction. To address limitations in existing BKGs, we present PrimeKG++, an enriched knowledge graph incorporating multimodal data, including biological sequences and textual descriptions for each entity type. By combining semantic and relational information in a unified representation, our approach demonstrates strong generalizability, enabling accurate link predictions even for unseen nodes. Experimental results on PrimeKG++ and the DrugBank drug-target interaction dataset demonstrate the effectiveness and robustness of our method across diverse biomedical datasets. Our source code, pre-trained models, and data are publicly available at https://github.com/HySonLab/BioMedKG",
      "authors": [
        "Tien Dang",
        "Viet Thanh Duy Nguyen",
        "Minh Tuan Le",
        "Truong-Son Hy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-03T05:29:12+00:00",
          "link": "https://arxiv.org/abs/2501.01644v1",
          "size": "804kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T22:15:00+00:00",
          "link": "https://arxiv.org/abs/2501.01644v2",
          "size": "734kb",
          "version": "v2"
        }
      ],
      "title": "Multimodal Contrastive Representation Learning in Augmented Biomedical Knowledge Graphs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.01644",
        "HTML": "https://arxiv.org/html/2501.01644v2",
        "PDF": "https://arxiv.org/pdf/2501.01644"
      },
      "tasks": [
        "Contrastive Learning",
        "Graph Embedding",
        "Knowledge Graph Embedding",
        "Knowledge Graphs",
        "Link Prediction",
        "Representation Learning"
      ],
      "repo_urls": [
        "https://github.com/hysonlab/biomedkg"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.02497",
      "abstract": "The remarkable performance of the o1 model in complex reasoning demonstrates that test-time compute scaling can further unlock the model's potential, enabling powerful System-2 thinking. However, there is still a lack of comprehensive surveys for test-time compute scaling. We trace the concept of test-time compute back to System-1 models. In System-1 models, test-time compute addresses distribution shifts and improves robustness and generalization through parameter updating, input modification, representation editing, and output calibration. In System-2 models, it enhances the model's reasoning ability to solve complex problems through repeated sampling, self-correction, and tree search. We organize this survey according to the trend of System-1 to System-2 thinking, highlighting the key role of test-time compute in the transition from System-1 models to weak System-2 models, and then to strong System-2 models. We also point out advanced topics and future directions.",
      "authors": [
        "Yixin Ji",
        "Juntao Li",
        "Yang Xiang",
        "Hai Ye",
        "Kaixin Wu",
        "Kai Yao",
        "Jia Xu",
        "Linjian Mo",
        "Min Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-05T10:24:20+00:00",
          "link": "https://arxiv.org/abs/2501.02497v1",
          "size": "1735kb",
          "version": "v1"
        },
        {
          "date": "2025-03-03T07:16:16+00:00",
          "link": "https://arxiv.org/abs/2501.02497v2",
          "size": "1775kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T06:49:52+00:00",
          "link": "https://arxiv.org/abs/2501.02497v3",
          "size": "983kb",
          "version": "v3"
        }
      ],
      "title": "A Survey of Test-Time Compute: From Intuitive Inference to Deliberate Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.02497",
        "HTML": "https://arxiv.org/html/2501.02497v3",
        "PDF": "https://arxiv.org/pdf/2501.02497"
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/dereck0602/awesome_test_time_llms"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.02725",
      "abstract": "The rapid advancements in artificial intelligence (AI), particularly in generative AI and large language models (LLMs), have profoundly impacted the creative industries, enabling more innovative content creation, enhancing workflows, and democratizing access to creative tools. This paper explores these technological shifts, with particular focus on how those that have emerged since our previous review in 2022 have expanded creative opportunities and improved efficiency. These technological advancements have enhanced the capabilities of text-to-image, text-to-video, and multimodal generation technologies. In particular, key breakthroughs in LLMs have established new benchmarks in conversational AI, while advancements in image generators have revolutionized content creation. We also discuss the integration of AI into post-production workflows, which has significantly accelerated and improved traditional processes. Once content has been created, it must be delivered to its audiences; the media industry is now facing the demands of increased communication traffic due to creative content. We therefore include a discussion of how AI is beginning to transform the way we represent and compress media content. We highlight the trend toward unified AI frameworks capable of addressing and integrating multiple creative tasks, and we underscore the importance of human insight to drive the creative process and oversight to mitigate AI-generated inaccuracies. Finally, we explore AI's future potential in the creative sector, stressing the need to navigate emerging challenges and to maximize its benefits while addressing the associated risks.",
      "authors": [
        "Nantheera Anantrasirichai and Fan Zhang and David Bull"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-06T02:46:33+00:00",
          "link": "https://arxiv.org/abs/2501.02725v1",
          "size": "9980kb",
          "version": "v1"
        },
        {
          "date": "2025-02-16T10:20:10+00:00",
          "link": "https://arxiv.org/abs/2501.02725v2",
          "size": "9981kb",
          "version": "v2"
        },
        {
          "date": "2025-06-05T21:18:13+00:00",
          "link": "https://arxiv.org/abs/2501.02725v3",
          "size": "8710kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T18:52:13+00:00",
          "link": "https://arxiv.org/abs/2501.02725v4",
          "size": "8710kb",
          "version": "v4"
        }
      ],
      "title": "Artificial Intelligence in Creative Industries: Advances Prior to 2025",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.02725",
        "HTML": "https://arxiv.org/html/2501.02725v4",
        "PDF": "https://arxiv.org/pdf/2501.02725"
      },
      "tasks": [
        "Data Compression",
        "multimodal generation",
        "Navigate"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.03124",
      "abstract": "Process-level Reward Models (PRMs) are crucial for complex reasoning and decision-making tasks, where each intermediate step plays an important role in the reasoning process. Since language models are prone to various types of errors during the reasoning process, PRMs are required to possess nuanced capabilities for detecting various implicit error types in real-world scenarios. However, current benchmarks primarily focus on step correctness, failing to evaluate PRMs' performance systematically. To address this gap, we introduce PRMBench, a process-level benchmark specifically designed to assess the fine-grained error detection capabilities of PRMs. PRMBench comprises 6,216 carefully designed problems and 83,456 step-level labels, evaluating models across multiple dimensions, including simplicity, soundness, and sensitivity. In our experiments on 15 models, spanning both open-source PRMs and closed-source large language models prompted as critic models, we uncover significant weaknesses in current PRMs. These findings underscore the challenges inherent in process-level evaluation and highlight key directions for future research. We hope PRMBench can be a robust bench for advancing research on PRM evaluation and development.",
      "authors": [
        "Mingyang Song",
        "Zhaochen Su",
        "Xiaoye Qu",
        "Jiawei Zhou",
        "Yu Cheng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-06T16:31:45+00:00",
          "link": "https://arxiv.org/abs/2501.03124v1",
          "size": "849kb",
          "version": "v1"
        },
        {
          "date": "2025-01-07T12:33:44+00:00",
          "link": "https://arxiv.org/abs/2501.03124v2",
          "size": "851kb",
          "version": "v2"
        },
        {
          "date": "2025-04-09T05:29:30+00:00",
          "link": "https://arxiv.org/abs/2501.03124v3",
          "size": "2464kb",
          "version": "v3"
        },
        {
          "date": "2025-05-28T07:55:32+00:00",
          "link": "https://arxiv.org/abs/2501.03124v4",
          "size": "2468kb",
          "version": "v4"
        },
        {
          "date": "2025-06-28T12:31:45+00:00",
          "link": "https://arxiv.org/abs/2501.03124v5",
          "size": "2217kb",
          "version": "v5"
        }
      ],
      "title": "PRMBench: A Fine-grained and Challenging Benchmark for Process-Level Reward Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.03124",
        "PDF": "https://arxiv.org/pdf/2501.03124"
      },
      "models": [
        {
          "model_path": "ibm-granite/granite-3.3-8b-lora-math-prm",
          "downloads": "0",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/ibm-granite/granite-3.3-8b-lora-math-prm"
        }
      ],
      "datasets": [
        {
          "dataset_name": "hitsmy/PRMBench_Preview",
          "downloads": "114",
          "likes": "4",
          "link": "https://huggingface.co/datasets/hitsmy/PRMBench_Preview"
        }
      ],
      "tasks": [
        "Decision Making"
      ],
      "repo_urls": [
        "https://github.com/ssmisya/PRMBench"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.05460",
      "abstract": "Large Multimodal Models (LMMs) extend Large Language Models (LLMs) by handling diverse inputs such as images, audio, and video, but at the cost of adding a multimodal encoding stage that increases both computational and memory overhead. This step negatively affects key Service Level Objectives (SLOs), such as time to first token (TTFT) and time per output token (TPOT). We introduce Encode-Prefill-Decode (EPD) Disaggregation, a novel framework that separates the encoding, prefill, and decode stages onto dedicated resources. Unlike current systems, which bundle encoding and prefill together, our approach decouples these steps, unlocking new opportunities and optimizations. These include a mechanism to cache multimedia tokens for efficient transfer, a novel way to parallelize the encoding load within a request, a module for optimal resource allocation for disaggregated serving, and a novel role-switching method to handle changing workload characteristics. Experimental evaluations with popular LMMs show substantial gains in memory efficiency (up to 15x lower peak memory utilization), batch sizes (up to 22x larger), 10x more images per request, and 2.2x larger KV caches. Furthermore, it leads to significant improvements in SLO attainment (up to 90-100% improvement) and TTFT (up to 71% reduction), compared to systems that do not disaggregate. The code is available at https://github.com/vbdi/epdserve.",
      "authors": [
        "Gursimran Singh",
        "Xinglu Wang",
        "Yifan Hu",
        "Timothy Yu",
        "Linzi Xing",
        "Wei Jiang",
        "Zhefeng Wang",
        "Xiaolong Bai",
        "Yi Li",
        "Ying Xiong",
        "Yong Zhang",
        "Zhenan Fan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-25T10:11:31+00:00",
          "link": "https://arxiv.org/abs/2501.05460v1",
          "size": "2345kb",
          "version": "v1"
        },
        {
          "date": "2025-02-05T22:55:47+00:00",
          "link": "https://arxiv.org/abs/2501.05460v2",
          "size": "1346kb",
          "version": "v2"
        },
        {
          "date": "2025-06-05T04:21:30+00:00",
          "link": "https://arxiv.org/abs/2501.05460v3",
          "size": "1861kb",
          "version": "v3"
        },
        {
          "date": "2025-06-28T03:53:17+00:00",
          "link": "https://arxiv.org/abs/2501.05460v4",
          "size": "1861kb",
          "version": "v4"
        }
      ],
      "title": "Efficiently Serving Large Multimodal Models Using EPD Disaggregation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.05460",
        "HTML": "https://arxiv.org/html/2501.05460v4",
        "PDF": "https://arxiv.org/pdf/2501.05460"
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/vbdi/epdserve"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.06729",
      "abstract": "Federated Learning (FL) enables multiple users to collaboratively train a global model in a distributed manner without revealing their personal data. However, FL remains vulnerable to model poisoning attacks, where malicious actors inject crafted updates to compromise the global model's accuracy. We propose a novel defense mechanism, Kernel-based Trust Segmentation (KeTS), to counter model poisoning attacks. Unlike existing approaches, KeTS analyzes the evolution of each client's updates and effectively segments malicious clients using Kernel Density Estimation (KDE), even in the presence of benign outliers. We thoroughly evaluate KeTS's performance against the six most effective model poisoning attacks (i.e., Trim-Attack, Krum-Attack, Min-Max attack, Min-Sum attack, and their variants) on four different datasets (i.e., MNIST, Fashion-MNIST, CIFAR-10, and KDD-CUP-1999) and compare its performance with three classical robust schemes (i.e., Krum, Trim-Mean, and Median) and a state-of-the-art defense (i.e., FLTrust). Our results show that KeTS outperforms the existing defenses in every attack setting; beating the best-performing defense by an overall average of >24% (on MNIST), >14% (on Fashion-MNIST), >9% (on CIFAR-10), >11% (on KDD-CUP-1999). A series of further experiments (varying poisoning approaches, attacker population, etc.) reveal the consistent and superior performance of KeTS under diverse conditions. KeTS is a practical solution as it satisfies all three defense objectives (i.e., fidelity, robustness, and efficiency) without imposing additional overhead on the clients. Finally, we also discuss a simple, yet effective extension to KeTS to handle consistent-untargeted (e.g., sign-flipping) attacks as well as targeted attacks (e.g., label-flipping).",
      "authors": [
        "Ankit Gangwal",
        "Mauro Conti",
        "Tommaso Pauselli"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-12T06:51:43+00:00",
          "link": "https://arxiv.org/abs/2501.06729v1",
          "size": "2784kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T07:32:53+00:00",
          "link": "https://arxiv.org/abs/2501.06729v2",
          "size": "3145kb",
          "version": "v2"
        }
      ],
      "title": "KeTS: Kernel-based Trust Segmentation against Model Poisoning Attacks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06729",
        "HTML": "https://arxiv.org/html/2501.06729v2",
        "PDF": "https://arxiv.org/pdf/2501.06729"
      },
      "source": "arXiv"
    },
    {
      "id": "2501.07423",
      "abstract": "This research provides an in-depth evaluation of various machine learning models for energy forecasting, focusing on the unique challenges of seasonal variations in student residential settings. The study assesses the performance of baseline models, such as LSTM and GRU, alongside state-of-the-art forecasting methods, including Autoregressive Feedforward Neural Networks, Transformers, and hybrid approaches. Special attention is given to predicting energy consumption amidst challenges like seasonal patterns, vacations, meteorological changes, and irregular human activities that cause sudden fluctuations in usage. The findings reveal that no single model consistently outperforms others across all seasons, emphasizing the need for season-specific model selection or tailored designs. Notably, the proposed Hyper Network based LSTM and MiniAutoEncXGBoost models exhibit strong adaptability to seasonal variations, effectively capturing abrupt changes in energy consumption during summer months. This study advances the energy forecasting field by emphasizing the critical role of seasonal dynamics and model-specific behavior in achieving accurate predictions.",
      "authors": [
        "Muhammad Umair Danish",
        "Mathumitha Sureshkumar",
        "Tehara Fonseka",
        "Umeshika Uthayakumar",
        "Vinura Galwaduge"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-13T15:43:22+00:00",
          "link": "https://arxiv.org/abs/2501.07423v1",
          "size": "1389kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T17:12:47+00:00",
          "link": "https://arxiv.org/abs/2501.07423v2",
          "size": "1389kb",
          "version": "v2"
        }
      ],
      "title": "An Investigation into Seasonal Variations in Energy Forecasting for Student Residences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.07423",
        "HTML": "https://arxiv.org/html/2501.07423v2",
        "PDF": "https://arxiv.org/pdf/2501.07423"
      },
      "tasks": [
        "Model Selection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.07561",
      "abstract": "We propose a two-stage concatenated coding scheme for reliable and information-theoretically secure communication over intersymbol interference wiretap channels. Motivated by the theoretical coding strategies that achieve the secrecy capacity, our scheme integrates low-density parity-check (LDPC) codes in the outer stage, forming a nested structure of wiretap codes, with trellis codes in the inner stage to improve achievable secure rates. The trellis code is specifically designed to transform the uniformly distributed codewords produced by the LDPC code stage into a Markov process, achieving tight lower bounds on the secrecy capacity. We further estimate the information leakage rate of the proposed coding scheme using an upper bound. To meet the weak secrecy criterion, we optimize degree distributions of the irregular LDPC codes at the outer stage, essentially driving the estimated upper bound on the information leakage rate to zero.",
      "authors": [
        "Aria Nouri",
        "Reza Asvadi",
        "Jun Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-13T18:51:46+00:00",
          "link": "https://arxiv.org/abs/2501.07561v1",
          "size": "1757kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T13:36:06+00:00",
          "link": "https://arxiv.org/abs/2501.07561v2",
          "size": "1688kb",
          "version": "v2"
        }
      ],
      "title": "Design and Analysis of a Concatenated Code for Intersymbol Interference Wiretap Channels",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.07561",
        "HTML": "https://arxiv.org/html/2501.07561v2",
        "PDF": "https://arxiv.org/pdf/2501.07561"
      },
      "source": "arXiv"
    },
    {
      "id": "2501.08005",
      "abstract": "Out-of-distribution (OOD) detection holds significant importance across many applications. While semantic and domain-shift OOD problems are well-studied, this work focuses on covariate shifts - subtle variations in the data distribution that can degrade machine learning performance. We hypothesize that detecting these subtle shifts can improve our understanding of in-distribution boundaries, ultimately improving OOD detection. In adversarial discriminators trained with Batch Normalization (BN), real and adversarial samples form distinct domains with unique batch statistics - a property we exploit for OOD detection. We introduce DisCoPatch, an unsupervised Adversarial Variational Autoencoder (VAE) framework that harnesses this mechanism. During inference, batches consist of patches from the same image, ensuring a consistent data distribution that allows the model to rely on batch statistics. DisCoPatch uses the VAE's suboptimal outputs (generated and reconstructed) as negative samples to train the discriminator, thereby improving its ability to delineate the boundary between in-distribution samples and covariate shifts. By tightening this boundary, DisCoPatch achieves state-of-the-art results in public OOD detection benchmarks. The proposed model not only excels in detecting covariate shifts, achieving 95.5% AUROC on ImageNet-1K(-C) but also outperforms all prior methods on public Near-OOD (95.0%) benchmarks. With a compact model size of 25MB, it achieves high OOD detection performance at notably lower latency than existing methods, making it an efficient and practical solution for real-world OOD detection applications. The code is publicly available.",
      "authors": [
        "Francisco Caetano",
        "Christiaan Viviers",
        "Luis A. Zavala-Mondrag\\'on",
        "Peter H. N. de With",
        "Fons van der Sommen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-14T10:49:26+00:00",
          "link": "https://arxiv.org/abs/2501.08005v1",
          "size": "4329kb",
          "version": "v1"
        },
        {
          "date": "2025-05-21T11:06:04+00:00",
          "link": "https://arxiv.org/abs/2501.08005v2",
          "size": "4323kb",
          "version": "v2"
        },
        {
          "date": "2025-06-26T16:11:14+00:00",
          "link": "https://arxiv.org/abs/2501.08005v3",
          "size": "3185kb",
          "version": "v3"
        },
        {
          "date": "2025-06-30T07:31:40+00:00",
          "link": "https://arxiv.org/abs/2501.08005v4",
          "size": "3185kb",
          "version": "v4"
        }
      ],
      "title": "DisCoPatch: Taming Adversarially-driven Batch Statistics for Improved Out-of-Distribution Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.08005",
        "HTML": "https://arxiv.org/html/2501.08005v4",
        "PDF": "https://arxiv.org/pdf/2501.08005"
      },
      "tasks": [
        "All",
        "Out-of-Distribution Detection",
        "Out of Distribution (OOD) Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.08983",
      "abstract": "3D scene generation has garnered growing attention in recent years and has made significant progress. Generating 4D cities is more challenging than 3D scenes due to the presence of structurally complex, visually diverse objects like buildings and vehicles, and heightened human sensitivity to distortions in urban environments. To tackle these issues, we propose CityDreamer4D, a compositional generative model specifically tailored for generating unbounded 4D cities. Our main insights are 1) 4D city generation should separate dynamic objects (e.g., vehicles) from static scenes (e.g., buildings and roads), and 2) all objects in the 4D scene should be composed of different types of neural fields for buildings, vehicles, and background stuff. Specifically, we propose Traffic Scenario Generator and Unbounded Layout Generator to produce dynamic traffic scenarios and static city layouts using a highly compact BEV representation. Objects in 4D cities are generated by combining stuff-oriented and instance-oriented neural fields for background stuff, buildings, and vehicles. To suit the distinct characteristics of background stuff and instances, the neural fields employ customized generative hash grids and periodic positional embeddings as scene parameterizations. Furthermore, we offer a comprehensive suite of datasets for city generation, including OSM, GoogleEarth, and CityTopia. The OSM dataset provides a variety of real-world city layouts, while the Google Earth and CityTopia datasets deliver large-scale, high-quality city imagery complete with 3D instance annotations. Leveraging its compositional design, CityDreamer4D supports a range of downstream applications, such as instance editing, city stylization, and urban simulation, while delivering state-of-the-art performance in generating realistic 4D cities.",
      "authors": [
        "Haozhe Xie",
        "Zhaoxi Chen",
        "Fangzhou Hong",
        "Ziwei Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-15T17:59:56+00:00",
          "link": "https://arxiv.org/abs/2501.08983v1",
          "size": "16015kb",
          "version": "v1"
        },
        {
          "date": "2025-03-14T12:54:19+00:00",
          "link": "https://arxiv.org/abs/2501.08983v2",
          "size": "16015kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T03:02:48+00:00",
          "link": "https://arxiv.org/abs/2501.08983v3",
          "size": "16213kb",
          "version": "v3"
        }
      ],
      "title": "Compositional Generative Model of Unbounded 4D Cities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.08983",
        "HTML": "https://arxiv.org/html/2501.08983v3",
        "PDF": "https://arxiv.org/pdf/2501.08983"
      },
      "tasks": [
        "Scene Generation"
      ],
      "repo_urls": [
        "https://github.com/hzxie/CityDreamer4D"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.10316",
      "abstract": "Recent LLMs have enabled significant advancements for conversational agents. However, they are also well known to hallucinate, producing responses that seem plausible but are factually incorrect. On the other hand, users tend to over-rely on LLM-based AI agents, accepting AI's suggestion even when it is wrong. Adding positive friction, such as explanations or getting user confirmations, has been proposed as a mitigation in AI-supported decision-making systems. In this paper, we propose an accountability model for LLM-based task-oriented dialogue agents to address user overreliance via friction turns in cases of model uncertainty and errors associated with dialogue state tracking (DST). The accountability model is an augmented LLM with an additional accountability head that functions as a binary classifier to predict the relevant slots of the dialogue state mentioned in the conversation. We perform our experiments with multiple backbone LLMs on two established benchmarks (MultiWOZ and Snips). Our empirical findings demonstrate that the proposed approach not only enables reliable estimation of AI agent errors but also guides the decoder in generating more accurate actions. We observe around 3% absolute improvement in joint goal accuracy (JGA) of DST output by incorporating accountability heads into modern LLMs. Self-correcting the detected errors further increases the JGA from 67.13 to 70.51, achieving state-of-the-art DST performance. Finally, we show that error correction through user confirmations (friction turn) achieves a similar performance gain, highlighting its potential to reduce user overreliance.",
      "authors": [
        "Suvodip Dey",
        "Yi-Jyun Sun",
        "Gokhan Tur",
        "Dilek Hakkani-Tur"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-17T17:40:12+00:00",
          "link": "https://arxiv.org/abs/2501.10316v1",
          "size": "201kb",
          "version": "v1"
        },
        {
          "date": "2025-02-19T00:39:39+00:00",
          "link": "https://arxiv.org/abs/2501.10316v2",
          "size": "232kb",
          "version": "v2"
        },
        {
          "date": "2025-05-16T02:33:23+00:00",
          "link": "https://arxiv.org/abs/2501.10316v3",
          "size": "232kb",
          "version": "v3"
        },
        {
          "date": "2025-06-28T03:44:49+00:00",
          "link": "https://arxiv.org/abs/2501.10316v4",
          "size": "228kb",
          "version": "v4"
        }
      ],
      "title": "Know Your Mistakes: Towards Preventing Overreliance on Task-Oriented Conversational AI Through Accountability Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.10316",
        "HTML": "https://arxiv.org/html/2501.10316v4",
        "PDF": "https://arxiv.org/pdf/2501.10316"
      },
      "tasks": [
        "AI Agent",
        "Dialogue State Tracking",
        "Friction"
      ],
      "repo_urls": [
        "https://github.com/uiuc-conversational-ai-lab/accountable-dst"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.11487",
      "abstract": "Identifying the unknown convolutional code corresponding to the given intercepted data is an important problem in military surveillance and in wireless communication. While a variety of code identification algorithms are available in the literature, the key contribution of our work lies in the novel solution and the corresponding analysis. In this paper, we focus on the situation when the given data corresponds to either of the two potential convolutional codes and the goal is to detect the correct code. We first provide a new interpretation of the convolutional code as a Markov chain, which is more suitable for analyzing the code detection problem. Our problem then gets reduced to identifying between the two Markov chains. We provide the closed-form expressions for the corresponding state transition matrices and estimate the error exponent for the underlying likelihood ratio test (LRT). We also provide a computationally efficient BCJR-based method for computing the likelihoods required for the LRT. We observe that BCJR-based likelihoods suffer from numerical issues for a longer data sequence, and hence, in this case, we design neural networks that have been found to achieve the optimal performance of the LRT.",
      "authors": [
        "Harshvardhan Pandey",
        "Pragya Khanna",
        "Arti Yardi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-20T13:38:36+00:00",
          "link": "https://arxiv.org/abs/2501.11487v1",
          "size": "162kb",
          "version": "v1"
        },
        {
          "date": "2025-01-22T13:33:22+00:00",
          "link": "https://arxiv.org/abs/2501.11487v2",
          "size": "167kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T15:39:27+00:00",
          "link": "https://arxiv.org/abs/2501.11487v3",
          "size": "0kb",
          "version": "v3"
        }
      ],
      "title": "Detecting Convolutional Codes: A Markovian Approach with LRT and DNN",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.11487",
        "PDF": "https://arxiv.org/pdf/2501.11487"
      },
      "source": "arXiv"
    },
    {
      "id": "2501.12756",
      "abstract": "The increasing availability of full-field displacement data from imaging techniques in experimental mechanics is determining a gradual shift in the paradigm of material model calibration and discovery, from using several simple-geometry tests towards a few, or even one single test with complicated geometry. The feasibility of such a \"one-shot\" calibration or discovery heavily relies upon the richness of the measured displacement data, i.e., their ability to probe the space of the state variables and the stress space (whereby the stresses depend on the constitutive law being sought) to an extent sufficient for an accurate and robust calibration or discovery process. The richness of the displacement data is in turn directly governed by the specimen geometry. In this paper, we propose a density-based topology optimisation framework to optimally design the geometry of the target specimen for calibration of an anisotropic elastic material model. To this end, we perform automatic, high-resolution specimen design by maximising the robustness of the solution of the inverse problem, i.e., the identified material parameters, given noisy displacement measurements from digital image correlation. We discuss the choice of the cost function and the design of the topology optimisation framework, and we analyse a range of optimised topologies generated for the identification of isotropic and anisotropic elastic responses.",
      "authors": [
        "Saeid Ghouli",
        "Moritz Flaschel",
        "Siddhant Kumar",
        "Laura De Lorenzis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Materials Science (cond-mat.mtrl-sci)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-22T09:42:57+00:00",
          "link": "https://arxiv.org/abs/2501.12756v1",
          "size": "14370kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T12:38:31+00:00",
          "link": "https://arxiv.org/abs/2501.12756v2",
          "size": "14550kb",
          "version": "v2"
        }
      ],
      "title": "A topology optimisation framework to design test specimens for one-shot identification or discovery of material models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.12756",
        "HTML": "https://arxiv.org/html/2501.12756v2",
        "PDF": "https://arxiv.org/pdf/2501.12756"
      },
      "source": "arXiv"
    },
    {
      "id": "2501.13215",
      "abstract": "Models of opinion dynamics describe how opinions are shaped in various environments. While these models are able to replicate general opinion distributions observed in real-world scenarios, their capacity to align with data at the user level remains mostly untested. We evaluate the capacity of the multi-state voter model with zealots to capture individual opinions in a fine-grained Twitter dataset collected during the 2017 French Presidential elections. Our findings reveal a strong correspondence between individual opinion distributions in the equilibrium state of the model and ground-truth political leanings of the users. Additionally, we demonstrate that discord probabilities accurately identify pairs of like-minded users. These results emphasize the validity of the voter model in complex settings, and advocate for further empirical evaluations of opinion dynamics models at the user level.",
      "authors": [
        "Antoine Vendeville"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-22T20:56:31+00:00",
          "link": "https://arxiv.org/abs/2501.13215v1",
          "size": "8192kb",
          "version": "v1"
        },
        {
          "date": "2025-06-18T11:43:39+00:00",
          "link": "https://arxiv.org/abs/2501.13215v2",
          "size": "7817kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T10:36:43+00:00",
          "link": "https://arxiv.org/abs/2501.13215v3",
          "size": "7836kb",
          "version": "v3"
        }
      ],
      "title": "Voter model can accurately predict individual opinions in online populations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.13215",
        "HTML": "https://arxiv.org/html/2501.13215v3",
        "PDF": "https://arxiv.org/pdf/2501.13215"
      },
      "source": "arXiv"
    },
    {
      "id": "2501.13349",
      "abstract": "While diffusion-based generative models have made significant strides in visual content creation, conventional approaches face computational challenges, especially for high-resolution images, as they denoise the entire image from noisy inputs. This contrasts with signal processing techniques, such as Fourier and wavelet analyses, which often employ hierarchical decompositions. Inspired by such principles, particularly the idea of signal separation, we introduce a diffusion framework leveraging multi-scale latent factorization. Our framework uniquely decomposes the denoising target, typically latent features from a pretrained Variational Autoencoder, into a low-frequency base signal capturing core structural information and a high-frequency residual signal that contributes finer, high-frequency details like textures. This decomposition into base and residual components directly informs our two-stage image generation process, which first produces the low-resolution base, followed by the generation of the high-resolution residual. Our proposed architecture facilitates reduced sampling steps during the residual learning stage, owing to the inherent ease of modeling residual information, which confers advantages over conventional full-resolution generation techniques. This specific approach of decomposing the signal into a base and a residual, conceptually akin to how wavelet analysis can separate different frequency bands, yields a more streamlined and intuitive design distinct from generic hierarchical models. Our method, \\name\\ (Multi-Scale Factorization), demonstrates its effectiveness by achieving FID scores of 2.08 ($256\\times256$) and 2.47 ($512\\times512$) on class-conditional ImageNet benchmarks, outperforming the DiT baseline (2.27 and 3.04 respectively) while also delivering a $4\\times$ speed-up with the same number of sampling steps.",
      "authors": [
        "Haohang Xu",
        "Longyu Chen",
        "Yichen Zhang",
        "Shuangrui Ding",
        "Zhipeng Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-23T03:18:23+00:00",
          "link": "https://arxiv.org/abs/2501.13349v1",
          "size": "7566kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T09:57:33+00:00",
          "link": "https://arxiv.org/abs/2501.13349v2",
          "size": "8732kb",
          "version": "v2"
        }
      ],
      "title": "MSF: Efficient Diffusion Model Via Multi-Scale Latent Factorize",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.13349",
        "HTML": "https://arxiv.org/html/2501.13349v2",
        "PDF": "https://arxiv.org/pdf/2501.13349"
      },
      "tasks": [
        "Image Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.14406",
      "abstract": "Pre-trained Language Models (PLMs) have demonstrated their superiority and versatility in modern Natural Language Processing (NLP), effectively adapting to various downstream tasks through further fine-tuning. Federated Parameter-Efficient Fine-Tuning (FedPEFT) has emerged as a promising solution to address privacy and efficiency challenges in distributed training for PLMs on resource-constrained local devices. However, our measurements reveal two key limitations of FedPEFT: heterogeneous data across devices exacerbates performance degradation of low-rank adaptation, and a fixed parameter configuration results in communication inefficiency. To overcome these limitations, we propose FedARA, a novel Adaptive Rank Allocation framework for federated parameter-efficient fine-tuning of language models. Specifically, FedARA employs truncated Singular Value Decomposition (SVD) adaptation to enhance similar feature representation across clients, significantly mitigating the adverse effects of data heterogeneity. Subsequently, it utilizes dynamic rank allocation to progressively identify critical ranks, effectively improving communication efficiency. Lastly, it leverages rank-based module pruning to automatically remove inactive modules, steadily reducing local computational cost and memory usage in each federated learning round. Extensive experiments show that FedARA consistently outperforms baselines by an average of 6.95% to 8.49% across various datasets and models under heterogeneous data while significantly improving communication efficiency by 2.40$ \\times$. Moreover, experiments on various edge devices demonstrate substantial decreases in total training time and energy consumption by up to 48.90% and 46.95%, respectively.",
      "authors": [
        "Fei Wu",
        "Jia Hu",
        "Geyong Min",
        "Shiqiang Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-24T11:19:07+00:00",
          "link": "https://arxiv.org/abs/2501.14406v1",
          "size": "2856kb",
          "version": "v1"
        },
        {
          "date": "2025-03-01T17:30:25+00:00",
          "link": "https://arxiv.org/abs/2501.14406v2",
          "size": "1673kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T10:20:31+00:00",
          "link": "https://arxiv.org/abs/2501.14406v3",
          "size": "1751kb",
          "version": "v3"
        }
      ],
      "title": "Adaptive Rank Allocation for Federated Parameter-Efficient Fine-Tuning of Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.14406",
        "HTML": "https://arxiv.org/html/2501.14406v3",
        "PDF": "https://arxiv.org/pdf/2501.14406"
      },
      "tasks": [
        "Federated Learning",
        "parameter-efficient fine-tuning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.14607",
      "abstract": "Referring video object segmentation (RVOS) aims to segment target objects throughout a video based on a text description. This is challenging as it involves deep vision-language understanding, pixel-level dense prediction and spatiotemporal reasoning. Despite notable progress in recent years, existing methods still exhibit a noticeable gap when considering all these aspects. In this work, we propose \\textbf{ReferDINO}, a strong RVOS model that inherits region-level vision-language alignment from foundational visual grounding models, and is further endowed with pixel-level dense perception and cross-modal spatiotemporal reasoning. In detail, ReferDINO integrates two key components: 1) a grounding-guided deformable mask decoder that utilizes location prediction to progressively guide mask prediction through differentiable deformation mechanisms; 2) an object-consistent temporal enhancer that injects pretrained time-varying text features into inter-frame interaction to capture object-aware dynamic changes. Moreover, a confidence-aware query pruning strategy is designed to accelerate object decoding without compromising model performance. Extensive experimental results on five benchmarks demonstrate that our ReferDINO significantly outperforms previous methods (e.g., +3.9% (\\mathcal{J}&\\mathcal{F}) on Ref-YouTube-VOS) with real-time inference speed (51 FPS).",
      "authors": [
        "Tianming Liang",
        "Kun-Yu Lin",
        "Chaolei Tan",
        "Jianguo Zhang",
        "Wei-Shi Zheng",
        "Jian-Fang Hu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-24T16:24:15+00:00",
          "link": "https://arxiv.org/abs/2501.14607v1",
          "size": "3876kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T16:09:19+00:00",
          "link": "https://arxiv.org/abs/2501.14607v2",
          "size": "3528kb",
          "version": "v2"
        }
      ],
      "title": "ReferDINO: Referring Video Object Segmentation with Visual Grounding Foundations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.14607",
        "HTML": "https://arxiv.org/html/2501.14607v2",
        "PDF": "https://arxiv.org/pdf/2501.14607"
      },
      "models": [
        {
          "model_path": "liangtm/referdino",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/liangtm/referdino"
        }
      ],
      "tasks": [
        "Decoder",
        "Object",
        "Referring Expression Segmentation",
        "Referring Video Object Segmentation",
        "Semantic Segmentation",
        "Video Object Segmentation",
        "Video Semantic Segmentation",
        "Visual Grounding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.14694",
      "abstract": "Self-supervised learning (SSL) is an emerging paradigm that exploits supervisory signals generated from the data itself, and many recent studies have leveraged SSL to conduct graph anomaly detection. However, we empirically found that three important factors can substantially impact detection performance across datasets: 1) the specific SSL strategy employed; 2) the tuning of the strategy's hyperparameters; and 3) the allocation of combination weights when using multiple strategies. Most SSL-based graph anomaly detection methods circumvent these issues by arbitrarily or selectively (i.e., guided by label information) choosing SSL strategies, hyperparameter settings, and combination weights. While an arbitrary choice may lead to subpar performance, using label information in an unsupervised setting is label information leakage and leads to severe overestimation of a method's performance. Leakage has been criticized as \"one of the top ten data mining mistakes\", yet many recent studies on SSL-based graph anomaly detection have been using label information to select hyperparameters. To mitigate this issue, we propose to use an internal evaluation strategy (with theoretical analysis) to select hyperparameters in SSL for unsupervised anomaly detection. We perform extensive experiments using 10 recent SSL-based graph anomaly detection algorithms on various benchmark datasets, demonstrating both the prior issues with hyperparameter selection and the effectiveness of our proposed strategy.",
      "authors": [
        "Zhong Li",
        "Yuhang Wang",
        "Matthijs van Leeuwen"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-24T18:13:44+00:00",
          "link": "https://arxiv.org/abs/2501.14694v1",
          "size": "1200kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T12:21:00+00:00",
          "link": "https://arxiv.org/abs/2501.14694v2",
          "size": "934kb",
          "version": "v2"
        }
      ],
      "title": "Towards Automated Self-Supervised Learning for Truly Unsupervised Graph Anomaly Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.14694",
        "HTML": "https://arxiv.org/html/2501.14694v2",
        "PDF": "https://arxiv.org/pdf/2501.14694"
      },
      "tasks": [
        "Anomaly Detection",
        "Graph Anomaly Detection",
        "Self-Supervised Learning",
        "Unsupervised Anomaly Detection"
      ],
      "repo_urls": [
        "https://github.com/zhonglifr/autogad2024"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.16297",
      "abstract": "The incorporation of high-resolution visual input equips multimodal large language models (MLLMs) with enhanced visual perception capabilities for real-world tasks. However, most existing high-resolution MLLMs rely on a cropping-based approach to process images, which leads to fragmented visual encoding and a sharp increase in redundant tokens. To tackle these issues, we propose the FALCON model. FALCON introduces a novel visual register technique to simultaneously: 1) Eliminate redundant tokens at the stage of visual encoding. To directly address the visual redundancy present in the output of vision encoder, we propose a Register-based Representation Compacting (ReCompact) mechanism. This mechanism introduces a set of learnable visual registers designed to adaptively aggregate essential information while discarding redundancy. It enables the encoder to produce a more compact visual representation with a minimal number of output tokens, thus eliminating the need for an additional compression module. 2) Ensure continuity in visual encoding. To address the potential encoding errors caused by fragmented visual inputs, we develop a Register Interactive Attention (ReAtten) module. This module facilitates effective and efficient information exchange across sub-images by enabling interactions between visual registers. It ensures the continuity of visual semantics throughout the encoding. We conduct comprehensive experiments with FALCON on high-resolution benchmarks across a wide range of scenarios. FALCON demonstrates superior performance with a remarkable 9-fold reduction in visual tokens.",
      "authors": [
        "Renshan Zhang",
        "Rui Shao",
        "Gongwei Chen",
        "Miao Zhang",
        "Kaiwen Zhou",
        "Weili Guan",
        "Liqiang Nie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-27T18:36:10+00:00",
          "link": "https://arxiv.org/abs/2501.16297v1",
          "size": "25272kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T12:24:33+00:00",
          "link": "https://arxiv.org/abs/2501.16297v2",
          "size": "20590kb",
          "version": "v2"
        }
      ],
      "title": "FALCON: Resolving Visual Redundancy and Fragmentation in High-resolution Multimodal Large Language Models via Visual Registers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.16297",
        "HTML": "https://arxiv.org/html/2501.16297v2",
        "PDF": "https://arxiv.org/pdf/2501.16297"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2501.17599",
      "abstract": "Modeling spatial heterogeneity in the data generation process is essential for understanding and predicting geographical phenomena. Despite their prevalence in geospatial tasks, neural network models usually assume spatial stationarity, which could limit their performance in the presence of spatial process heterogeneity. By allowing model parameters to vary over space, several approaches have been proposed to incorporate spatial heterogeneity into neural networks. However, current geographically weighting approaches are ineffective on graph neural networks, yielding no significant improvement in prediction accuracy. We assume the crux lies in the over-fitting risk brought by a large number of local parameters. Accordingly, we propose to model spatial process heterogeneity at the regional level rather than at the individual level, which largely reduces the number of spatially varying parameters. We further develop a heuristic optimization procedure to learn the region partition adaptively in the process of model training. Our proposed spatial-heterogeneity-aware graph convolutional network, named RegionGCN, is applied to the spatial prediction of county-level vote share in the 2016 US presidential election based on socioeconomic attributes. Results show that RegionGCN achieves significant improvement over the basic and geographically weighted GCNs. We also offer an exploratory analysis tool for the spatial variation of non-linear relationships through ensemble learning of regional partitions from RegionGCN. Our work contributes to the practice of Geospatial Artificial Intelligence (GeoAI) in tackling spatial heterogeneity.",
      "authors": [
        "Hao Guo",
        "Han Wang",
        "Di Zhu",
        "Lun Wu",
        "A. Stewart Fotheringham",
        "Yu Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-29T12:09:01+00:00",
          "link": "https://arxiv.org/abs/2501.17599v1",
          "size": "1431kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T06:48:45+00:00",
          "link": "https://arxiv.org/abs/2501.17599v2",
          "size": "1930kb",
          "version": "v2"
        }
      ],
      "title": "RegionGCN: Spatial-Heterogeneity-Aware Graph Convolutional Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.17599",
        "PDF": "https://arxiv.org/pdf/2501.17599"
      },
      "tasks": [
        "Ensemble Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.17653",
      "abstract": "This work proposes variational autoencoders (VAEs) to predict a vehicle's jerk signals from torque demand in the context of limited real-world drivetrain datasets. We implement both unconditional and conditional VAEs, trained on experimental data from two variants of a fully electric SUV with differing torque and drivetrain configurations. The VAEs synthesize jerk signals that capture characteristics from multiple drivetrain scenarios by leveraging the learned latent space. A performance comparison with baseline physics-based and hybrid models confirms the effectiveness of the VAEs, without requiring detailed system parametrization. Unconditional VAEs generate realistic jerk signals without prior system knowledge, while conditional VAEs enable the generation of signals tailored to specific torque inputs. This approach reduces the dependence on costly and time-intensive real-world experiments and extensive manual modeling. The results support the integration of generative models such as VAEs into drivetrain simulation pipelines, both for data augmentation and for efficient exploration of complex operational scenarios, with the potential to streamline validation and accelerate vehicle development.",
      "authors": [
        "Pallavi Sharma and Jorge-Humberto Urrea-Quintero and Bogdan Bogdan and Adrian-Dumitru Ciotec and Laura Vasilie and Henning Wessels and Matteo Skull"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-29T13:37:32+00:00",
          "link": "https://arxiv.org/abs/2501.17653v1",
          "size": "6655kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T14:26:51+00:00",
          "link": "https://arxiv.org/abs/2501.17653v2",
          "size": "5139kb",
          "version": "v2"
        }
      ],
      "title": "Drivetrain simulation using variational autoencoders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.17653",
        "HTML": "https://arxiv.org/html/2501.17653v2",
        "PDF": "https://arxiv.org/pdf/2501.17653"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2501.17905",
      "abstract": "Large language models (LLMs) have achieved significant progress across various domains, but their increasing scale results in high computational and memory costs. Recent studies have revealed that LLMs exhibit sparsity, providing the potential to reduce model size through pruning techniques. However, existing pruning methods typically follow a prune-then-finetune paradigm. Since the pruned components still contain valuable information, their direct removal often leads to irreversible performance degradation, imposing a substantial computational burden to recover performance during finetuning. In this paper, we propose a novel paradigm that first applies regularization, then prunes, and finally finetunes. Based on this paradigm, we introduce DReSS, a simple and effective Data-driven Regularized Structured Streamlining method for LLMs. By leveraging a small amount of data to regularize the components to be pruned, DReSS explicitly transfers the important information to the remaining parts of the model in advance. Compared to direct pruning, this can reduce the information loss caused by parameter removal, thereby enhancing its language modeling capabilities. Experimental results demonstrate that DReSS significantly outperforms existing pruning methods even under extreme pruning ratios, significantly reducing latency and increasing throughput.",
      "authors": [
        "Mingkuan Feng",
        "Jinyang Wu",
        "Shuai Zhang",
        "Pengpeng Shao",
        "Ruihan Jin",
        "Zhengqi Wen",
        "Jianhua Tao",
        "Feihu Che"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-29T14:28:11+00:00",
          "link": "https://arxiv.org/abs/2501.17905v1",
          "size": "193kb",
          "version": "v1"
        },
        {
          "date": "2025-02-10T04:07:04+00:00",
          "link": "https://arxiv.org/abs/2501.17905v2",
          "size": "193kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T03:25:00+00:00",
          "link": "https://arxiv.org/abs/2501.17905v3",
          "size": "322kb",
          "version": "v3"
        }
      ],
      "title": "DReSS: Data-driven Regularized Structured Streamlining for Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.17905",
        "HTML": "https://arxiv.org/html/2501.17905v3",
        "PDF": "https://arxiv.org/pdf/2501.17905"
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.18164",
      "abstract": "We have theoretically analyzed the use of Riemannian stochastic gradient descent (RSGD) and found that using an increasing batch size leads to faster RSGD convergence rate than using a constant batch size not only with a constant learning rate but also with a decaying learning rate, such as cosine annealing decay and polynomial decay. The convergence rate of RSGD improves from $O(\\sqrt{T^{-1}+\\text{const.}})$ with a constant batch size to $O(T^{-\\frac{1}{2}})$ with an increasing batch size, where $T$ denotes the number of iterations. Using principal component analysis and low-rank matrix completion tasks, we investigated, both theoretically and numerically, how increasing batch size affects computational time as measured by stochastic first-order oracle (SFO) complexity. Increasing batch size reduces the SFO complexity of RSGD. Furthermore, our numerical results demonstrated that increasing batch size offers the advantages of both small and large constant batch sizes.",
      "authors": [
        "Kanata Oowada and Hideaki Iiduka"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-30T06:23:28+00:00",
          "link": "https://arxiv.org/abs/2501.18164v1",
          "size": "1909kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T18:25:29+00:00",
          "link": "https://arxiv.org/abs/2501.18164v2",
          "size": "713kb",
          "version": "v2"
        }
      ],
      "title": "Faster Convergence of Riemannian Stochastic Gradient Descent with Increasing Batch Size",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.18164",
        "HTML": "https://arxiv.org/html/2501.18164v2",
        "PDF": "https://arxiv.org/pdf/2501.18164"
      },
      "tasks": [
        "Low-Rank Matrix Completion",
        "Matrix Completion"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.18377",
      "abstract": "We propose a theory that can determine the lowest isolation level that can be allocated to each transaction program in an application in a mixed-isolation-level setting, to guarantee that all executions will be serializable and thus preserve all integrity constraints, even those that are not explicitly declared. This extends prior work applied to completely known transactions, to deal with the realistic situation where transactions are generated by running programs with parameters that are not known in advance. Using our theory, we propose an optimization method that allows for high throughput while ensuring that all executions are serializable. Our method is based on searching for application code modifications that are semantics-preserving while improving the isolation level allocation. We illustrate our approach to the SmallBank benchmark.",
      "authors": [
        "Brecht Vandevoort",
        "Alan Fekete",
        "Bas Ketsman",
        "Frank Neven",
        "Stijn Vansummeren"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-30T14:29:45+00:00",
          "link": "https://arxiv.org/abs/2501.18377v1",
          "size": "1066kb",
          "version": "v1"
        },
        {
          "date": "2025-04-30T09:56:43+00:00",
          "link": "https://arxiv.org/abs/2501.18377v2",
          "size": "1403kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T15:16:20+00:00",
          "link": "https://arxiv.org/abs/2501.18377v3",
          "size": "1402kb",
          "version": "v3"
        }
      ],
      "title": "Using Read Promotion and Mixed Isolation Levels for Performant Yet Serializable Execution of Transaction Programs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.18377",
        "HTML": "https://arxiv.org/html/2501.18377v3",
        "PDF": "https://arxiv.org/pdf/2501.18377"
      },
      "source": "arXiv"
    },
    {
      "id": "2502.00306",
      "abstract": "Retrieval-Augmented Generation (RAG) enables Large Language Models (LLMs) to generate grounded responses by leveraging external knowledge databases without altering model parameters. Although the absence of weight tuning prevents leakage via model parameters, it introduces the risk of inference adversaries exploiting retrieved documents in the model's context. Existing methods for membership inference and data extraction often rely on jailbreaking or carefully crafted unnatural queries, which can be easily detected or thwarted with query rewriting techniques common in RAG systems. In this work, we present Interrogation Attack (IA), a membership inference technique targeting documents in the RAG datastore. By crafting natural-text queries that are answerable only with the target document's presence, our approach demonstrates successful inference with just 30 queries while remaining stealthy; straightforward detectors identify adversarial prompts from existing methods up to ~76x more frequently than those generated by our attack. We observe a 2x improvement in TPR@1%FPR over prior inference attacks across diverse RAG configurations, all while costing less than $0.02 per document inference.",
      "authors": [
        "Ali Naseh",
        "Yuefeng Peng",
        "Anshuman Suri",
        "Harsh Chaudhari",
        "Alina Oprea",
        "Amir Houmansadr"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-01T04:01:18+00:00",
          "link": "https://arxiv.org/abs/2502.00306v1",
          "size": "646kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T16:37:59+00:00",
          "link": "https://arxiv.org/abs/2502.00306v2",
          "size": "650kb",
          "version": "v2"
        }
      ],
      "title": "Riddle Me This! Stealthy Membership Inference for Retrieval-Augmented Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.00306",
        "HTML": "https://arxiv.org/html/2502.00306v2",
        "PDF": "https://arxiv.org/pdf/2502.00306"
      },
      "tasks": [
        "Membership Inference Attack",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.00361",
      "abstract": "Diffusion policies have achieved superior performance in imitation learning and offline reinforcement learning (RL) due to their rich expressiveness. However, the conventional diffusion training procedure requires samples from target distribution, which is impossible in online RL since we cannot sample from the optimal policy. Backpropagating policy gradient through the diffusion process incurs huge computational costs and instability, thus being expensive and not scalable. To enable efficient training of diffusion policies in online RL, we generalize the conventional denoising score matching by reweighting the loss function. The resulting Reweighted Score Matching (RSM) preserves the optimal solution and low computational cost of denoising score matching, while eliminating the need to sample from the target distribution and allowing learning to optimize value functions. We introduce two tractable reweighted loss functions to solve two commonly used policy optimization problems, policy mirror descent and max-entropy policy, resulting in two practical algorithms named Diffusion Policy Mirror Descent (DPMD) and Soft Diffusion Actor-Critic (SDAC). We conducted comprehensive comparisons on MuJoCo benchmarks. The empirical results show that the proposed algorithms outperform recent diffusion-policy online RLs on most tasks, and the DPMD improves more than 120% over soft actor-critic on Humanoid and Ant.",
      "authors": [
        "Haitong Ma",
        "Tianyi Chen",
        "Kai Wang",
        "Na Li",
        "Bo Dai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-01T07:55:06+00:00",
          "link": "https://arxiv.org/abs/2502.00361v1",
          "size": "1547kb",
          "version": "v1"
        },
        {
          "date": "2025-02-12T06:10:33+00:00",
          "link": "https://arxiv.org/abs/2502.00361v2",
          "size": "1621kb",
          "version": "v2"
        },
        {
          "date": "2025-05-28T06:35:04+00:00",
          "link": "https://arxiv.org/abs/2502.00361v3",
          "size": "5599kb",
          "version": "v3"
        },
        {
          "date": "2025-06-30T03:48:44+00:00",
          "link": "https://arxiv.org/abs/2502.00361v4",
          "size": "4138kb",
          "version": "v4"
        }
      ],
      "title": "Efficient Online Reinforcement Learning for Diffusion Policy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.00361",
        "HTML": "https://arxiv.org/html/2502.00361v4",
        "PDF": "https://arxiv.org/pdf/2502.00361"
      },
      "source": "arXiv"
    },
    {
      "id": "2502.00801",
      "abstract": "LiDAR-camera extrinsic calibration (LCEC) is crucial for multi-modal data fusion in mechatronics. Existing methods, whether target-based or target-free, typically rely on customized calibration targets or fixed scene types, limiting their practicality in real-world applications. To address these challenges, we introduce EdO-LCEC, the first environment-driven online calibration approach. Unlike traditional target-free methods, EdO-LCEC observes the feature density of the application environment through a generalizable scene discriminator. Based on this feature density, EdO-LCEC extracts LiDAR intensity and depth features from varying perspectives to achieve higher calibration accuracy. To overcome the challenges of cross-modal feature matching between LiDAR and camera, we propose dual-path correspondence matching (DPCM), which leverages both structural and textural consistency for reliable 3D-2D correspondences. Additionally, our approach models the calibration process as a joint optimization problem utilizing global constraints from multiple views and scenes to enhance accuracy. Extensive experiments on real-world datasets demonstrate that EdO-LCEC outperforms state-of-the-art methods, particularly in sparse or partially overlapping sensor views.",
      "authors": [
        "Zhiwei Huang",
        "Jiaqi Li",
        "Ping Zhong",
        "Rui Fan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-02T13:52:35+00:00",
          "link": "https://arxiv.org/abs/2502.00801v1",
          "size": "6741kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T07:47:33+00:00",
          "link": "https://arxiv.org/abs/2502.00801v2",
          "size": "6521kb",
          "version": "v2"
        }
      ],
      "title": "Environment-Driven Online LiDAR-Camera Extrinsic Calibration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.00801",
        "HTML": "https://arxiv.org/html/2502.00801v2",
        "PDF": "https://arxiv.org/pdf/2502.00801"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.01061",
      "abstract": "End-to-end human animation, such as audio-driven talking human generation, has undergone notable advancements in the recent few years. However, existing methods still struggle to scale up as large general video generation models, limiting their potential in real applications. In this paper, we propose OmniHuman, a Diffusion Transformer-based framework that scales up data by mixing motion-related conditions into the training phase. To this end, we introduce two training principles for these mixed conditions, along with the corresponding model architecture and inference strategy. These designs enable OmniHuman to fully leverage data-driven motion generation, ultimately achieving highly realistic human video generation. More importantly, OmniHuman supports various portrait contents (face close-up, portrait, half-body, full-body), supports both talking and singing, handles human-object interactions and challenging body poses, and accommodates different image styles. Compared to existing end-to-end audio-driven methods, OmniHuman not only produces more realistic videos, but also offers greater flexibility in inputs. It also supports multiple driving modalities (audio-driven, video-driven and combined driving signals). Video samples are provided on the ttfamily project page (https://omnihuman-lab.github.io)",
      "authors": [
        "Gaojie Lin",
        "Jianwen Jiang",
        "Jiaqi Yang",
        "Zerong Zheng",
        "Chao Liang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-03T05:17:32+00:00",
          "link": "https://arxiv.org/abs/2502.01061v1",
          "size": "16828kb",
          "version": "v1"
        },
        {
          "date": "2025-02-13T06:56:29+00:00",
          "link": "https://arxiv.org/abs/2502.01061v2",
          "size": "16114kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T08:26:56+00:00",
          "link": "https://arxiv.org/abs/2502.01061v3",
          "size": "9516kb",
          "version": "v3"
        }
      ],
      "title": "OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.01061",
        "HTML": "https://arxiv.org/html/2502.01061v3",
        "PDF": "https://arxiv.org/pdf/2502.01061"
      },
      "tasks": [
        "Human Animation",
        "Human-Object Interaction Detection",
        "Motion Generation",
        "Video Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.01705",
      "abstract": "Large language models (LLMs) have achieved remarkable progress in natural language processing, but their high computational and memory costs hinder deployment on resource-constrained devices. Binarization, which reduces model weights to 1 bit, is a promising solution for efficient inference. However, binarized LLMs still exhibit redundancy that can be further compressed. Semi-structured pruning offers a favorable trade-off between model performance and hardware efficiency, but naively combining it with binarization often leads to severe performance degradation. To address this, we propose Progressive Binarization with Semi-Structured Pruning (PBS$^2$P), a novel post-training compression framework. We propose Stepwise semi-structured Pruning with Binarization Optimization (SPBO) to jointly reduce pruning and binarization error. Additionally, we develop a Coarse-to-Fine Search (CFS) strategy to more effectively select pruning elements. Extensive experiments across multiple LLM families show that PBS$^2$P consistently outperforms state-of-the-art binary post-training quantization methods in both perplexity and downstream accuracy. The code and models will be available at: https://github.com/XIANGLONGYAN/PBS2P.",
      "authors": [
        "Xianglong Yan and Tianao Zhang and Zhiteng Li and Yulun Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-03T13:30:29+00:00",
          "link": "https://arxiv.org/abs/2502.01705v1",
          "size": "479kb",
          "version": "v1"
        },
        {
          "date": "2025-02-08T02:23:05+00:00",
          "link": "https://arxiv.org/abs/2502.01705v2",
          "size": "479kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T05:16:02+00:00",
          "link": "https://arxiv.org/abs/2502.01705v3",
          "size": "317kb",
          "version": "v3"
        }
      ],
      "title": "Progressive Binarization with Semi-Structured Pruning for LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.01705",
        "HTML": "https://arxiv.org/html/2502.01705v3",
        "PDF": "https://arxiv.org/pdf/2502.01705"
      },
      "tasks": [
        "Binarization"
      ],
      "repo_urls": [
        "https://github.com/xianglongyan/pbs2p"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.02668",
      "abstract": "Projection Pursuit is a classic exploratory technique for finding interesting projections of a dataset. We propose a method for recovering projections containing either Imbalanced Clusters or a Bernoulli-Rademacher distribution using a gradient-based technique to optimize the projection index. As sample complexity is a major limiting factor in Projection Pursuit, we analyze our algorithm's sample complexity within a Planted Vector setting where we can observe that Imbalanced Clusters can be recovered more easily than balanced ones. Additionally, we give a generalized result that works for a variety of data distributions and projection indices. We compare these results to computational lower bounds in the Low-Degree-Polynomial Framework. Finally, we experimentally evaluate our method's applicability to real-world data using FashionMNIST and the Human Activity Recognition Dataset, where our algorithm outperforms others when only a few samples are available.",
      "authors": [
        "Martin Eppert",
        "Satyaki Mukherjee",
        "Debarghya Ghoshdastidar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-04T19:18:17+00:00",
          "link": "https://arxiv.org/abs/2502.02668v1",
          "size": "912kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T11:52:00+00:00",
          "link": "https://arxiv.org/abs/2502.02668v2",
          "size": "914kb",
          "version": "v2"
        }
      ],
      "title": "Recovering Imbalanced Clusters via Gradient-Based Projection Pursuit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.02668",
        "HTML": "https://arxiv.org/html/2502.02668v2",
        "PDF": "https://arxiv.org/pdf/2502.02668"
      },
      "source": "arXiv"
    },
    {
      "id": "2502.03607",
      "abstract": "Recent advances in diffusion models hold significant potential in robotics, enabling the generation of diverse and smooth trajectories directly from raw representations of the environment. Despite this promise, applying diffusion models to motion planning remains challenging due to their difficulty in enforcing critical constraints, such as collision avoidance and kinematic feasibility. These limitations become even more pronounced in Multi-Robot Motion Planning (MRMP), where multiple robots must coordinate in shared spaces. To address these challenges, this work proposes Simultaneous MRMP Diffusion (SMD), a novel approach integrating constrained optimization into the diffusion sampling process to produce collision-free, kinematically feasible trajectories. Additionally, the paper introduces a comprehensive MRMP benchmark to evaluate trajectory planning algorithms across scenarios with varying robot densities, obstacle complexities, and motion constraints. Experimental results show SMD consistently outperforms classical and other learning-based motion planners, achieving higher success rates and efficiency in complex multi-robot environments.",
      "authors": [
        "Jinhao Liang",
        "Jacob K Christopher",
        "Sven Koenig and Ferdinando Fioretto"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-05T20:51:28+00:00",
          "link": "https://arxiv.org/abs/2502.03607v1",
          "size": "6329kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T14:20:37+00:00",
          "link": "https://arxiv.org/abs/2502.03607v2",
          "size": "7118kb",
          "version": "v2"
        }
      ],
      "title": "Simultaneous Multi-Robot Motion Planning with Projected Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.03607",
        "HTML": "https://arxiv.org/html/2502.03607v2",
        "PDF": "https://arxiv.org/pdf/2502.03607"
      },
      "tasks": [
        "Collision Avoidance",
        "Motion Planning",
        "Trajectory Planning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.03669",
      "abstract": "This position paper argues that the machine learning community should fundamentally rethink how AI-inspired methods are developed and evaluated for combinatorial optimization (CO). We present comprehensive empirical benchmarks comparing various recent AI-inspired GPU-based methods with several classical CPU-based solvers on the Maximum Independent Set (MIS) problem. Strikingly, even on in-distribution random graphs, leading AI-inspired methods are consistently outperformed by the state-of-the-art classical solver KaMIS, and some AI-inspired methods frequently fail to surpass even the simplest degree-based greedy heuristic. To better understand the source of these failures, we introduce a novel analysis, serialization, which reveals that non-backtracking AI methods, such as LTFT (based on GFlowNets), end up reasoning similarly to the simplest degree-based greedy heuristic, and thus worse than KaMIS.\n  Our findings reveal three core issues: (1) Limited benchmarks and evaluation - AI-inspired methods are often tested only on small instances with very limited inference time, which covers up issues with scalability and resource usage; (2) Intrinsic hardness and learning limits - even under ideal, in-distribution conditions, learning-based approaches lag behind classical heuristics, highlighting inherent barriers that receive little attention; and (3) Insufficient use and understanding of classical heuristics - current learning frameworks often neglect to incorporate effective classical techniques.\n  Although we use MIS as a testbed, similar gaps and challenges have been reported in other combinatorial optimization problems, suggesting broader relevance for our recommendations. We propose that future research must address these issues by rigorous benchmarking, deepening understanding of learning limitations, and integrating classical heuristics into AI-inspired methods.",
      "authors": [
        "Yikai Wu",
        "Haoyu Zhao",
        "Sanjeev Arora"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Discrete Mathematics (cs.DM)",
        "Optimization and Control (math.OC)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-05T23:24:47+00:00",
          "link": "https://arxiv.org/abs/2502.03669v1",
          "size": "3042kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T02:02:59+00:00",
          "link": "https://arxiv.org/abs/2502.03669v2",
          "size": "2063kb",
          "version": "v2"
        }
      ],
      "title": "Time to Rethink AI for Combinatorial Optimization: Classical Algorithms Remain Tough to Match",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.03669",
        "HTML": "https://arxiv.org/html/2502.03669v2",
        "PDF": "https://arxiv.org/pdf/2502.03669"
      },
      "tasks": [
        "Combinatorial Optimization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.03892",
      "abstract": "In this paper, we introduce and analyze a class of numerical schemes that demonstrate remarkable superiority in terms of efficiency, the preservation of positivity, energy stability, and high-order precision to solve the time-dependent Poisson-Nernst-Planck (PNP) system, which is\n  as a highly versatile and sophisticated model and accommodates a plenitude of applications in the emulation of the translocation of charged particles across a multifarious expanse of physical and biological systems. The numerical schemes presented here are based on the energy variational formulation. It allows the PNP system to be reformulated as a non-constant mobility $H^{-1}$ gradient flow, incorporating singular logarithmic energy potentials. To achieve a fully discrete numerical scheme, we employ a combination of first/second-order semi-implicit time discretization methods, coupled with either the $k$-th order direct discontinuous Galerkin (DDG) method or the finite element (FE) method for spatial discretization. The schemes are verified to possess positivity preservation and energy stability. Optimal error estimates and particular superconvergence results for the fully-discrete numerical solution are established. Numerical experiments are provided to showcase the accuracy, efficiency, and robustness of the proposed schemes.",
      "authors": [
        "Waixiang Cao",
        "Yuzhe Qin",
        "and Minqiang Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-06T09:06:51+00:00",
          "link": "https://arxiv.org/abs/2502.03892v1",
          "size": "996kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T11:55:53+00:00",
          "link": "https://arxiv.org/abs/2502.03892v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "A class of positive-preserving,energy stable and high order numerical schemes for the Poission-Nernst-Planck system",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.03892",
        "PDF": "https://arxiv.org/pdf/2502.03892"
      },
      "source": "arXiv"
    },
    {
      "id": "2502.04397",
      "abstract": "Foundation models trained on patient electronic health records (EHRs) require tokenizing medical data into sequences of discrete vocabulary items. Existing tokenizers treat medical codes from EHRs as isolated textual tokens. However, each medical code is defined by its textual description, its position in ontological hierarchies, and its relationships to other codes, such as disease co-occurrences and drug-treatment associations. Medical vocabularies contain more than 600,000 codes with critical information for clinical reasoning. We introduce MedTok, a multimodal medical code tokenizer that uses the text descriptions and relational context of codes. MedTok processes text using a language model encoder and encodes the relational structure with a graph encoder. It then quantizes both modalities into a unified token space, preserving modality-specific and cross-modality information. We integrate MedTok into five EHR models and evaluate it on operational and clinical tasks across in-patient and out-patient datasets, including outcome prediction, diagnosis classification, drug recommendation, and risk stratification. Swapping standard EHR tokenizers with MedTok improves AUPRC across all EHR models, by 4.10% on MIMIC-III, 4.78% on MIMIC-IV, and 11.32% on EHRShot, with the largest gains in drug recommendation. Beyond EHR modeling, we demonstrate using MedTok tokenizer with medical QA systems. Our results demonstrate the potential of MedTok as a unified tokenizer for medical codes, improving tokenization for medical foundation models.",
      "authors": [
        "Xiaorui Su",
        "Shvat Messica",
        "Yepeng Huang",
        "Ruth Johnson",
        "Lukas Fesser",
        "Shanghua Gao",
        "Faryad Sahneh",
        "Marinka Zitnik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-06T06:58:09+00:00",
          "link": "https://arxiv.org/abs/2502.04397v1",
          "size": "1178kb",
          "version": "v1"
        },
        {
          "date": "2025-02-12T22:26:50+00:00",
          "link": "https://arxiv.org/abs/2502.04397v2",
          "size": "1293kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T03:09:34+00:00",
          "link": "https://arxiv.org/abs/2502.04397v3",
          "size": "1692kb",
          "version": "v3"
        }
      ],
      "title": "Multimodal Medical Code Tokenizer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.04397",
        "HTML": "https://arxiv.org/html/2502.04397v3",
        "PDF": "https://arxiv.org/pdf/2502.04397"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.04843",
      "abstract": "Novel View Synthesis (NVS) techniques, notably Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS), can augment camera pose estimation by extending and diversifying training data. However, images generated by these methods are often plagued by spatial artifacts such as blurring and ghosting, undermining their reliability as training data for camera pose estimation. This limitation is particularly critical for Scene Coordinate Regression (SCR) methods, which aim at pixel-level 3D coordinate estimation, because rendering artifacts directly lead to estimation inaccuracies. To address this challenge, we propose a dual-criteria filtering mechanism that dynamically identifies and discards suboptimal pixels during training. The dual-criteria filter evaluates two concurrent metrics: (1) real-time SCR reprojection error, and (2) gradient threshold, across the coordinate regression domain. In addition, for visual localization problems in sparse-input scenarios, it becomes even more necessary to use NVS-generated data to assist localization. We design a coarse-to-fine Points of Interest (PoI) variant using sparse-input NVS to solve this problem. Experiments across indoor and outdoor benchmarks confirm our method's efficacy, achieving state-of-the-art localization accuracy while maintaining computational efficiency.",
      "authors": [
        "Feifei Li and Qi Song and Chi Zhang and Hui Shuai and Rui Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-07T11:24:23+00:00",
          "link": "https://arxiv.org/abs/2502.04843v1",
          "size": "28917kb",
          "version": "v1"
        },
        {
          "date": "2025-02-11T10:48:23+00:00",
          "link": "https://arxiv.org/abs/2502.04843v2",
          "size": "28917kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T10:06:29+00:00",
          "link": "https://arxiv.org/abs/2502.04843v3",
          "size": "2300kb",
          "version": "v3"
        }
      ],
      "title": "PoI: A Filter to Extract Pixel of Interest from Novel View Synthesis for Scene Coordinate Regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.04843",
        "HTML": "https://arxiv.org/html/2502.04843v3",
        "PDF": "https://arxiv.org/pdf/2502.04843"
      },
      "tasks": [
        "Diversity",
        "NeRF",
        "Novel View Synthesis",
        "regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.05355",
      "abstract": "The Nonlinear GMRES (NGMRES) proposed by Washio and Oosterlee [Electron. Trans. Numer. Anal, 6(271-290), 1997] is an acceleration method for fixed point iterations. It has been demonstrated to be effective, but its convergence properties have not been extensively studied in the literature so far. In this work we aim to close some of this gap, by offering a convergence analysis for NGMRES applied to linear systems. A central part of our analysis focuses on identifying equivalences between NGMRES and the classical Krylov subspace GMRES method.",
      "authors": [
        "Chen Greif and Yunhui He"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-07T21:56:53+00:00",
          "link": "https://arxiv.org/abs/2502.05355v1",
          "size": "71kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T16:33:10+00:00",
          "link": "https://arxiv.org/abs/2502.05355v2",
          "size": "80kb",
          "version": "v2"
        }
      ],
      "title": "Convergence Properties of Nonlinear GMRES Applied to Linear Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05355",
        "HTML": "https://arxiv.org/html/2502.05355v2",
        "PDF": "https://arxiv.org/pdf/2502.05355"
      },
      "source": "arXiv"
    },
    {
      "id": "2502.05489",
      "abstract": "Large language models (LLMs) show promising capabilities in predicting human emotions from text. However, the mechanisms through which these models process emotional stimuli remain largely unexplored. Our study addresses this gap by investigating how autoregressive LLMs infer emotions, showing that emotion representations are functionally localized to specific regions in the model. Our evaluation includes diverse model families and sizes and is supported by robustness checks. We then show that the identified representations are psychologically plausible by drawing on cognitive appraisal theory, a well-established psychological framework positing that emotions emerge from evaluations (appraisals) of environmental stimuli. By causally intervening on construed appraisal concepts, we steer the generation and show that the outputs align with theoretical and intuitive expectations. This work highlights a novel way to causally intervene and precisely shape emotional text generation, potentially benefiting safety and alignment in sensitive affective domains.",
      "authors": [
        "Ala N. Tak",
        "Amin Banayeeanzade",
        "Anahita Bolourani",
        "Mina Kian",
        "Robin Jia",
        "Jonathan Gratch"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-08T08:11:37+00:00",
          "link": "https://arxiv.org/abs/2502.05489v1",
          "size": "1173kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T00:37:41+00:00",
          "link": "https://arxiv.org/abs/2502.05489v2",
          "size": "1099kb",
          "version": "v2"
        }
      ],
      "title": "Mechanistic Interpretability of Emotion Inference in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05489",
        "HTML": "https://arxiv.org/html/2502.05489v2",
        "PDF": "https://arxiv.org/pdf/2502.05489"
      },
      "source": "arXiv"
    },
    {
      "id": "2502.05623",
      "abstract": "We study the mixing time guarantee for sampling in relative Fisher information via the Proximal Sampler algorithm, which is an approximate proximal discretization of the Langevin dynamics. We show that when the target probability distribution is strongly log-concave, the relative Fisher information converges exponentially fast along the Proximal Sampler; this matches the exponential convergence rate of the relative Fisher information along the continuous-time Langevin dynamics for strongly log-concave target. When combined with a standard implementation of the Proximal Sampler via rejection sampling, this exponential convergence rate provides a high-accuracy iteration complexity guarantee for the Proximal Sampler in relative Fisher information when the target distribution is strongly log-concave and log-smooth. Our proof proceeds by establishing a strong data processing inequality for relative Fisher information along the Gaussian channel under strong log-concavity, and a data processing inequality along the reverse Gaussian channel for a special distribution. The forward and reverse Gaussian channels compose to form the Proximal Sampler, and these data processing inequalities imply the exponential convergence rate of the relative Fisher information along the Proximal Sampler.",
      "authors": [
        "Andre Wibisono"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)",
        "Optimization and Control (math.OC)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-08T16:07:12+00:00",
          "link": "https://arxiv.org/abs/2502.05623v1",
          "size": "167kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T00:24:10+00:00",
          "link": "https://arxiv.org/abs/2502.05623v2",
          "size": "168kb",
          "version": "v2"
        }
      ],
      "title": "Mixing Time of the Proximal Sampler in Relative Fisher Information via Strong Data Processing Inequality",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05623",
        "HTML": "https://arxiv.org/html/2502.05623v2",
        "PDF": "https://arxiv.org/pdf/2502.05623"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.05651",
      "abstract": "The increasing demand for mental health services has led to the rise of AI-driven mental health chatbots, though challenges related to privacy, data collection, and expertise persist. Motivational Interviewing (MI) is gaining attention as a theoretical basis for boosting expertise in the development of these chatbots. However, existing datasets are showing limitations for training chatbots, leading to a substantial demand for publicly available resources in the field of MI and psychotherapy. These challenges are even more pronounced in non-English languages, where they receive less attention. In this paper, we propose a novel framework that simulates MI sessions enriched with the expertise of professional therapists. We train an MI forecaster model that mimics the behavioral choices of professional therapists and employ Large Language Models (LLMs) to generate utterances through prompt engineering. Then, we present KMI, the first synthetic dataset theoretically grounded in MI, containing 1,000 high-quality Korean Motivational Interviewing dialogues. Through an extensive expert evaluation of the generated dataset and the dialogue model trained on it, we demonstrate the quality, expertise, and practicality of KMI. We also introduce novel metrics derived from MI theory in order to evaluate dialogues from the perspective of MI.",
      "authors": [
        "Hyunjong Kim",
        "Suyeon Lee",
        "Yeongjae Cho",
        "Eunseo Ryu",
        "Yohan Jo",
        "Suran Seong",
        "Sungzoon Cho"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-08T17:53:41+00:00",
          "link": "https://arxiv.org/abs/2502.05651v1",
          "size": "1313kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T16:54:48+00:00",
          "link": "https://arxiv.org/abs/2502.05651v2",
          "size": "1313kb",
          "version": "v2"
        }
      ],
      "title": "KMI: A Dataset of Korean Motivational Interviewing Dialogues for Psychotherapy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05651",
        "HTML": "https://arxiv.org/html/2502.05651v2",
        "PDF": "https://arxiv.org/pdf/2502.05651"
      },
      "source": "arXiv"
    },
    {
      "id": "2502.05695",
      "abstract": "This paper proposes a novel Semantic Communication (SemCom) framework for real-time adaptive-bitrate video streaming by integrating Latent Diffusion Models (LDMs) within the FFmpeg techniques. This solution addresses the challenges of high bandwidth usage, storage inefficiencies, and quality of experience (QoE) degradation associated with traditional Constant Bitrate Streaming (CBS) and Adaptive Bitrate Streaming (ABS). The proposed approach leverages LDMs to compress I-frames into a latent space, offering significant storage and semantic transmission savings without sacrificing high visual quality. While retaining B-frames and P-frames as adjustment metadata to support efficient refinement of video reconstruction at the user side, the proposed framework further incorporates state-of-the-art denoising and Video Frame Interpolation (VFI) techniques. These techniques mitigate semantic ambiguity and restore temporal coherence between frames, even in noisy wireless communication environments. Experimental results demonstrate the proposed method achieves high-quality video streaming with optimized bandwidth usage, outperforming state-of-the-art solutions in terms of QoE and resource efficiency. This work opens new possibilities for scalable real-time video streaming in 5G and future post-5G networks.",
      "authors": [
        "Zijiang Yan",
        "Jianhua Pei",
        "Hongda Wu",
        "Hina Tabassum",
        "Ping Wang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Multimedia (cs.MM)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-08T21:14:28+00:00",
          "link": "https://arxiv.org/abs/2502.05695v1",
          "size": "3484kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T17:37:30+00:00",
          "link": "https://arxiv.org/abs/2502.05695v2",
          "size": "4080kb",
          "version": "v2"
        }
      ],
      "title": "Semantic-Aware Adaptive Video Streaming Using Latent Diffusion Models for Wireless Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05695",
        "HTML": "https://arxiv.org/html/2502.05695v2",
        "PDF": "https://arxiv.org/pdf/2502.05695"
      },
      "tasks": [
        "Denoising",
        "Video Frame Interpolation",
        "Video Reconstruction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.07004",
      "abstract": "Large transformer models are known to produce high-norm tokens. In vision transformers (ViTs), such tokens have been mathematically modeled through the singular vectors of the linear approximations of layers. However, in large language models (LLMs), the underlying causes of high-norm tokens remain largely unexplored, and their different properties from those of ViTs require a new analysis framework. In this paper, we provide both theoretical insights and empirical validation across a range of recent models, leading to the following observations: i) The layer-wise singular direction predicts the abrupt explosion of token norms in LLMs. ii) The negative eigenvalues of a layer explain its sudden decay. iii) The computational pathways leading to high-norm tokens differ between initial and noninitial tokens. iv) High-norm tokens are triggered by the right leading singular vector of the matrix approximating the corresponding modules. We showcase two practical applications of these findings: the improvement of quantization schemes and the design of LLM signatures. Our findings not only advance the understanding of singular defects in LLMs but also open new avenues for their application. We expect that this work will stimulate further research into the internal mechanisms of LLMs. Code is released at https://github.com/haoqiwang/singular_defect.",
      "authors": [
        "Haoqi Wang",
        "Tong Zhang",
        "Mathieu Salzmann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T20:09:16+00:00",
          "link": "https://arxiv.org/abs/2502.07004v1",
          "size": "5061kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T22:12:48+00:00",
          "link": "https://arxiv.org/abs/2502.07004v2",
          "size": "10967kb",
          "version": "v2"
        }
      ],
      "title": "Demystifying Singular Defects in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.07004",
        "HTML": "https://arxiv.org/html/2502.07004v2",
        "PDF": "https://arxiv.org/pdf/2502.07004"
      },
      "tasks": [
        "Quantization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.07007",
      "abstract": "Recent advancements in AI-generated content have significantly improved the realism of 3D and 4D generation. However, most existing methods prioritize appearance consistency while neglecting underlying physical principles, leading to artifacts such as unrealistic deformations, unstable dynamics, and implausible objects interactions. Incorporating physics priors into generative models has become a crucial research direction to enhance structural integrity and motion realism. This survey provides a review of physics-aware generative methods, systematically analyzing how physical constraints are integrated into 3D and 4D generation. First, we examine recent works in incorporating physical priors into static and dynamic 3D generation, categorizing methods based on representation types, including vision-based, NeRF-based, and Gaussian Splatting-based approaches. Second, we explore emerging techniques in 4D generation, focusing on methods that model temporal dynamics with physical simulations. Finally, we conduct a comparative analysis of major methods, highlighting their strengths, limitations, and suitability for different materials and motion dynamics. By presenting an in-depth analysis of physics-grounded AIGC, this survey aims to bridge the gap between generative models and physical realism, providing insights that inspire future research in physically consistent content generation.",
      "authors": [
        "Siwei Meng",
        "Yawei Luo and Ping Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T20:13:16+00:00",
          "link": "https://arxiv.org/abs/2502.07007v1",
          "size": "40kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T03:41:19+00:00",
          "link": "https://arxiv.org/abs/2502.07007v2",
          "size": "70kb",
          "version": "v2"
        }
      ],
      "title": "Grounding Creativity in Physics: A Brief Survey of Physical Priors in AIGC",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.07007",
        "PDF": "https://arxiv.org/pdf/2502.07007"
      },
      "tasks": [
        "3D Generation",
        "NeRF",
        "Physical Simulations",
        "Survey"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.08769",
      "abstract": "Masked Image Modeling (MIM) offers a promising approach to self-supervised representation learning, however existing MIM models still lag behind the state-of-the-art. In this paper, we systematically analyze target representations, loss functions, and architectures, to introduce CAPI - a novel pure-MIM framework that relies on the prediction of latent clusterings. Our approach leverages a clustering-based loss, which is stable to train, and exhibits promising scaling properties. Our ViT-L backbone, CAPI, achieves 83.8% accuracy on ImageNet and 32.1% mIoU on ADE20K with simple linear probes, substantially outperforming previous MIM methods and approaching the performance of the current state-of-the-art, DINOv2. We release all our code and models.",
      "authors": [
        "Timoth\\'ee Darcet",
        "Federico Baldassarre",
        "Maxime Oquab",
        "Julien Mairal",
        "Piotr Bojanowski"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-12T20:17:10+00:00",
          "link": "https://arxiv.org/abs/2502.08769v1",
          "size": "10353kb",
          "version": "v1"
        },
        {
          "date": "2025-02-17T09:54:11+00:00",
          "link": "https://arxiv.org/abs/2502.08769v2",
          "size": "10353kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T10:48:00+00:00",
          "link": "https://arxiv.org/abs/2502.08769v3",
          "size": "9544kb",
          "version": "v3"
        }
      ],
      "title": "Cluster and Predict Latent Patches for Improved Masked Image Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.08769",
        "HTML": "https://arxiv.org/html/2502.08769v3",
        "PDF": "https://arxiv.org/pdf/2502.08769"
      },
      "models": [
        {
          "model_path": "birder-project/rope_vit_reg4_b14_capi",
          "downloads": "102",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/birder-project/rope_vit_reg4_b14_capi"
        },
        {
          "model_path": "birder-project/rope_vit_reg4_b14_capi-imagenet21k",
          "downloads": "153",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/birder-project/rope_vit_reg4_b14_capi-imagenet21k"
        },
        {
          "model_path": "birder-project/rope_vit_reg4_b14_capi-inat21",
          "downloads": "109",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/birder-project/rope_vit_reg4_b14_capi-inat21"
        },
        {
          "model_path": "birder-project/rope_vit_reg4_b14_capi-places365",
          "downloads": "53",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/birder-project/rope_vit_reg4_b14_capi-places365"
        }
      ],
      "tasks": [
        "Representation Learning"
      ],
      "repo_urls": [
        "https://github.com/facebookresearch/capi",
        "https://gitlab.com/birder/birder"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.10341",
      "abstract": "Modern language models are trained on large, unstructured datasets consisting of trillions of tokens and obtained by crawling the web. The unstructured nature makes it difficult to reason about their contents and develop systematic approaches to data curation. In this paper, we unpack monolithic web corpora by developing taxonomies of their contents and organizing them into domains. We introduce WebOrganizer, a framework for organizing web pages in terms of both their topic and format. Using these two complementary notions of domains, we automatically annotate pre-training data by distilling annotations from a large language model into efficient classifiers. This allows us to study how data from different domains should be mixed to improve models on downstream tasks, and we show that we can combine insights about effective topics and formats to further boost performance. We demonstrate that our domain mixing also improves existing methods that select data based on quality. Furthermore, we study and compare how quality-based methods will implicitly change the domain mixture. Overall, our work demonstrates that constructing and mixing domains provides a valuable complement to quality-based data curation methods, opening new avenues for effective and insightful pre-training data curation.",
      "authors": [
        "Alexander Wettig",
        "Kyle Lo",
        "Sewon Min",
        "Hannaneh Hajishirzi",
        "Danqi Chen",
        "Luca Soldaini"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-14T18:02:37+00:00",
          "link": "https://arxiv.org/abs/2502.10341v1",
          "size": "282kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T23:09:12+00:00",
          "link": "https://arxiv.org/abs/2502.10341v2",
          "size": "307kb",
          "version": "v2"
        }
      ],
      "title": "Organize the Web: Constructing Domains Enhances Pre-Training Data Curation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.10341",
        "HTML": "https://arxiv.org/html/2502.10341v2",
        "PDF": "https://arxiv.org/pdf/2502.10341"
      },
      "models": [
        {
          "model_path": "WebOrganizer/TopicClassifier-NoURL",
          "downloads": "2179",
          "likes": "9",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/TopicClassifier-NoURL"
        },
        {
          "model_path": "WebOrganizer/TopicClassifier",
          "downloads": "17221",
          "likes": "11",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/TopicClassifier"
        },
        {
          "model_path": "WebOrganizer/FormatClassifier-NoURL",
          "downloads": "3520",
          "likes": "5",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/FormatClassifier-NoURL"
        },
        {
          "model_path": "WebOrganizer/FormatClassifier",
          "downloads": "31083",
          "likes": "6",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/FormatClassifier"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Baseline",
          "downloads": "75",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Baseline"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_KMeans_for_MMLU",
          "downloads": "59",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_KMeans_for_MMLU"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_Topics_for_MMLU",
          "downloads": "35",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_Topics_for_MMLU"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_Formats_for_MMLU",
          "downloads": "64",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_Formats_for_MMLU"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_Topics_x_Formats_for_MMLU",
          "downloads": "12",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_Topics_x_Formats_for_MMLU"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_KMeans_for_HellaSwag",
          "downloads": "42",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_KMeans_for_HellaSwag"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_Topics_for_HellaSwag",
          "downloads": "26",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_Topics_for_HellaSwag"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_Formats_for_HellaSwag",
          "downloads": "28",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_Formats_for_HellaSwag"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_Topics_x_Formats_for_HellaSwag",
          "downloads": "27",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_Topics_x_Formats_for_HellaSwag"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_KMeans_for_MMLU_and_HellaSwag",
          "downloads": "16",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_KMeans_for_MMLU_and_HellaSwag"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_Topics_for_MMLU_and_Hellaswag",
          "downloads": "26",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_Topics_for_MMLU_and_Hellaswag"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_Formats_for_MMLU_and_Hellaswag",
          "downloads": "13",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_Formats_for_MMLU_and_Hellaswag"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-Sampling_over_Topics_x_Formats_for_MMLU_and_Hellaswag",
          "downloads": "17",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-Sampling_over_Topics_x_Formats_for_MMLU_and_Hellaswag"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-FineWebEdu",
          "downloads": "10",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-FineWebEdu"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-FineWebEdu_over_Topics_x_Formats_for_MMLU_and_Hellaswag",
          "downloads": "12",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-FineWebEdu_over_Topics_x_Formats_for_MMLU_and_Hellaswag"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-DCLMFasttext",
          "downloads": "9",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-DCLMFasttext"
        },
        {
          "model_path": "WebOrganizer/LM-1b_1x-DCLMFasttext_over_Topics_x_Formats_for_MMLU_and_Hellaswag",
          "downloads": "28",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/WebOrganizer/LM-1b_1x-DCLMFasttext_over_Topics_x_Formats_for_MMLU_and_Hellaswag"
        },
        {
          "model_path": "davanstrien/ModernBERT-web-topics-1m",
          "downloads": "18",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/davanstrien/ModernBERT-web-topics-1m"
        },
        {
          "model_path": "wissamantoun/WebOrganizer-FormatClassifier",
          "downloads": "24",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/wissamantoun/WebOrganizer-FormatClassifier"
        },
        {
          "model_path": "wissamantoun/WebOrganizer-FormatClassifier-ModernBERT",
          "downloads": "13",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/wissamantoun/WebOrganizer-FormatClassifier-ModernBERT"
        },
        {
          "model_path": "wissamantoun/WebOrganizer-TopicClassifier-ModernBERT",
          "downloads": "6",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/wissamantoun/WebOrganizer-TopicClassifier-ModernBERT"
        }
      ],
      "datasets": [
        {
          "dataset_name": "WebOrganizer/Corpus-200B",
          "downloads": "135539",
          "likes": "8",
          "link": "https://huggingface.co/datasets/WebOrganizer/Corpus-200B"
        },
        {
          "dataset_name": "WebOrganizer/TopicAnnotations-Llama-3.1-8B",
          "downloads": "65",
          "likes": "1",
          "link": "https://huggingface.co/datasets/WebOrganizer/TopicAnnotations-Llama-3.1-8B"
        },
        {
          "dataset_name": "WebOrganizer/TopicAnnotations-Llama-3.1-405B-FP8",
          "downloads": "89",
          "likes": "1",
          "link": "https://huggingface.co/datasets/WebOrganizer/TopicAnnotations-Llama-3.1-405B-FP8"
        },
        {
          "dataset_name": "WebOrganizer/FormatAnnotations-Llama-3.1-8B",
          "downloads": "113",
          "likes": "1",
          "link": "https://huggingface.co/datasets/WebOrganizer/FormatAnnotations-Llama-3.1-8B"
        },
        {
          "dataset_name": "WebOrganizer/FormatAnnotations-Llama-3.1-405B-FP8",
          "downloads": "31",
          "likes": "1",
          "link": "https://huggingface.co/datasets/WebOrganizer/FormatAnnotations-Llama-3.1-405B-FP8"
        }
      ],
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.11161",
      "abstract": "In real-world scenarios, multi-view cameras are typically employed for fine-grained manipulation tasks. Existing approaches (e.g., ACT) tend to treat multi-view features equally and directly concatenate them for policy learning. However, it will introduce redundant visual information and bring higher computational costs, leading to ineffective manipulation. For a fine-grained manipulation task, it tends to involve multiple stages while the most contributed view for different stages is varied over time. In this paper, we propose a plug-and-play best-feature-aware (BFA) fusion strategy for multi-view manipulation tasks, which is adaptable to various policies. Built upon the visual backbone of the policy network, we design a lightweight network to predict the importance score of each view. Based on the predicted importance scores, the reweighted multi-view features are subsequently fused and input into the end-to-end policy network, enabling seamless integration. Notably, our method demonstrates outstanding performance in fine-grained manipulations. Experimental results show that our approach outperforms multiple baselines by 22-46% success rate on different tasks. Our work provides new insights and inspiration for tackling key challenges in fine-grained manipulations.",
      "authors": [
        "Zihan Lan",
        "Weixin Mao",
        "Haosheng Li",
        "Le Wang",
        "Tiancai Wang",
        "Haoqiang Fan",
        "Osamu Yoshie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-16T15:26:21+00:00",
          "link": "https://arxiv.org/abs/2502.11161v1",
          "size": "16536kb",
          "version": "v1"
        },
        {
          "date": "2025-02-19T07:10:06+00:00",
          "link": "https://arxiv.org/abs/2502.11161v2",
          "size": "16536kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T17:23:09+00:00",
          "link": "https://arxiv.org/abs/2502.11161v3",
          "size": "24597kb",
          "version": "v3"
        }
      ],
      "title": "BFA: Best-Feature-Aware Fusion for Multi-View Fine-grained Manipulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.11161",
        "HTML": "https://arxiv.org/html/2502.11161v3",
        "PDF": "https://arxiv.org/pdf/2502.11161"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.11538",
      "abstract": "With the large-scale integration of Internet of Things (IoT) into enterprise information management systems, organizations are pursuing digital transformation that hinges on real-time data insights-and yet face escalating security and governance risks. Detecting and responding to threats at scale without impairing system efficiency has therefore become a critical information-management and decision-support challenge for today's executives. This paper develops a distributed, gain-based anomaly-detection framework tailored to IoT-enabled enterprise systems, underpinned by an optimized sensor-subset partitioning strategy. Starting from the perspective of set partitioning strategies, this study analyzes the key factor that contributes to the performance differences between distributed and centralized algorithms. By examining the gain mutual influence of sensor subsets, an optimal set partitioning strategy is designed to minimize inter-subset mutual influence while enhancing intra-subset correlation. To further reduce the computational cost of gain updates, a suboptimal partitioning strategy based on Grassmann distance is proposed, improving the efficiency of selecting suspicious sensors. Theoretical analysis demonstrates that this approach effectively reduces the computational cost of gain updates while maintaining detection performance. Finally, simulation results validate the effectiveness of the proposed method in enhancing attack detection performance.",
      "authors": [
        "Yuhan Suo",
        "Runqi Chai",
        "Kaiyuan Chen",
        "Senchun Chai",
        "Wannian Liang",
        "and Yuanqing Xia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-17T08:07:55+00:00",
          "link": "https://arxiv.org/abs/2502.11538v1",
          "size": "255kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T04:35:59+00:00",
          "link": "https://arxiv.org/abs/2502.11538v2",
          "size": "285kb",
          "version": "v2"
        }
      ],
      "title": "Efficient malicious information detection method based on set partitioning for large-scale Internet of Things",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.11538",
        "HTML": "https://arxiv.org/html/2502.11538v2",
        "PDF": "https://arxiv.org/pdf/2502.11538"
      },
      "source": "arXiv"
    },
    {
      "id": "2502.12080",
      "abstract": "Previous 3D human creation methods have made significant progress in synthesizing view-consistent and temporally aligned results from sparse-view images or monocular videos. However, it remains challenging to produce perpetually realistic, view-consistent, and temporally coherent human avatars from a single image, as limited information is available in the single-view input setting. Motivated by the success of 2D character animation, we propose HumanGif, a single-view human diffusion model with generative prior. Specifically, we formulate the single-view-based 3D human novel view and pose synthesis as a single-view-conditioned human diffusion process, utilizing generative priors from foundational diffusion models to complement the missing information. To ensure fine-grained and consistent novel view and pose synthesis, we introduce a Human NeRF module in HumanGif to learn spatially aligned features from the input image, implicitly capturing the relative camera and human pose transformation. Furthermore, we introduce an image-level loss during optimization to bridge the gap between latent and image spaces in diffusion models. Extensive experiments on RenderPeople, DNA-Rendering, THuman 2.1, and TikTok datasets demonstrate that HumanGif achieves the best perceptual performance, with better generalizability for novel view and pose synthesis.",
      "authors": [
        "Shoukang Hu",
        "Takuya Narihira",
        "Kazumi Fukuda",
        "Ryosuke Sawata",
        "Takashi Shibuya",
        "Yuki Mitsufuji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-17T17:55:27+00:00",
          "link": "https://arxiv.org/abs/2502.12080v1",
          "size": "16780kb",
          "version": "v1"
        },
        {
          "date": "2025-02-21T16:03:54+00:00",
          "link": "https://arxiv.org/abs/2502.12080v2",
          "size": "16771kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T10:53:42+00:00",
          "link": "https://arxiv.org/abs/2502.12080v3",
          "size": "19629kb",
          "version": "v3"
        }
      ],
      "title": "HumanGif: Single-View Human Diffusion with Generative Prior",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.12080",
        "HTML": "https://arxiv.org/html/2502.12080v3",
        "PDF": "https://arxiv.org/pdf/2502.12080"
      },
      "models": [
        {
          "model_path": "Sony/humangif",
          "downloads": "0",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Sony/humangif"
        }
      ],
      "tasks": [
        "3D Human Reconstruction",
        "NeRF",
        "Novel View Synthesis"
      ],
      "repo_urls": [
        "https://github.com/skhu101/humangif"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.13010",
      "abstract": "Large Language Models (LLMs) have significantly advanced medical question-answering by leveraging extensive clinical data and medical literature. However, the rapid evolution of medical knowledge and the labor-intensive process of manually updating domain-specific resources pose challenges to the reliability of these systems. To address this, we introduce Agentic Medical Graph-RAG (AMG-RAG), a comprehensive framework that automates the construction and continuous updating of medical knowledge graphs, integrates reasoning, and retrieves current external evidence, such as PubMed and WikiSearch. By dynamically linking new findings and complex medical concepts, AMG-RAG not only improves accuracy but also enhances interpretability in medical queries.\n  Evaluations on the MEDQA and MEDMCQA benchmarks demonstrate the effectiveness of AMG-RAG, achieving an F1 score of 74.1 percent on MEDQA and an accuracy of 66.34 percent on MEDMCQA, outperforming both comparable models and those 10 to 100 times larger. Notably, these improvements are achieved without increasing computational overhead, highlighting the critical role of automated knowledge graph generation and external evidence retrieval in delivering up-to-date, trustworthy medical insights.",
      "authors": [
        "Mohammad Reza Rezaei",
        "Reza Saadati Fard",
        "Jayson L. Parker",
        "Rahul G. Krishnan",
        "Milad Lankarany"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-18T16:29:45+00:00",
          "link": "https://arxiv.org/abs/2502.13010v1",
          "size": "2881kb",
          "version": "v1"
        },
        {
          "date": "2025-05-27T17:05:15+00:00",
          "link": "https://arxiv.org/abs/2502.13010v2",
          "size": "5263kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T14:58:00+00:00",
          "link": "https://arxiv.org/abs/2502.13010v3",
          "size": "1657kb",
          "version": "v3"
        }
      ],
      "title": "Agentic Medical Knowledge Graphs Enhance Medical Question Answering: Bridging the Gap Between LLMs and Evolving Medical Knowledge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.13010",
        "HTML": "https://arxiv.org/html/2502.13010v3",
        "PDF": "https://arxiv.org/pdf/2502.13010"
      },
      "tasks": [
        "Graph Generation",
        "Knowledge Graphs",
        "MedQA",
        "Question Answering",
        "RAG"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.13283",
      "abstract": "In overparameterized logistic regression, gradient descent (GD) iterates diverge in norm while converging in direction to the maximum $\\ell_2$-margin solution -- a phenomenon known as the implicit bias of GD. This work investigates additional regularization effects induced by early stopping in well-specified high-dimensional logistic regression. We first demonstrate that the excess logistic risk vanishes for early-stopped GD but diverges to infinity for GD iterates at convergence. This suggests that early-stopped GD is well-calibrated, whereas asymptotic GD is statistically inconsistent. Second, we show that to attain a small excess zero-one risk, polynomially many samples are sufficient for early-stopped GD, while exponentially many samples are necessary for any interpolating estimator, including asymptotic GD. This separation underscores the statistical benefits of early stopping in the overparameterized regime. Finally, we establish nonasymptotic bounds on the norm and angular differences between early-stopped GD and $\\ell_2$-regularized empirical risk minimizer, thereby connecting the implicit regularization of GD with explicit $\\ell_2$-regularization.",
      "authors": [
        "Jingfeng Wu",
        "Peter Bartlett",
        "Matus Telgarsky",
        "Bin Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-18T21:04:06+00:00",
          "link": "https://arxiv.org/abs/2502.13283v1",
          "size": "61kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T01:46:22+00:00",
          "link": "https://arxiv.org/abs/2502.13283v2",
          "size": "84kb",
          "version": "v2"
        }
      ],
      "title": "Benefits of Early Stopping in Gradient Descent for Overparameterized Logistic Regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.13283",
        "HTML": "https://arxiv.org/html/2502.13283v2",
        "PDF": "https://arxiv.org/pdf/2502.13283"
      },
      "tasks": [
        "regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.13451",
      "abstract": "Vision-and-language navigation (VLN) is a key task in Embodied AI, requiring agents to navigate diverse and unseen environments while following natural language instructions. Traditional approaches rely heavily on historical observations as spatio-temporal contexts for decision making, leading to significant storage and computational overhead. In this paper, we introduce MapNav, a novel end-to-end VLN model that leverages Annotated Semantic Map (ASM) to replace historical frames. Specifically, our approach constructs a top-down semantic map at the start of each episode and update it at each timestep, allowing for precise object mapping and structured navigation information. Then, we enhance this map with explicit textual labels for key regions, transforming abstract semantics into clear navigation cues and generate our ASM. MapNav agent using the constructed ASM as input, and use the powerful end-to-end capabilities of VLM to empower VLN. Extensive experiments demonstrate that MapNav achieves state-of-the-art (SOTA) performance in both simulated and real-world environments, validating the effectiveness of our method. Moreover, we will release our ASM generation source code and dataset to ensure reproducibility, contributing valuable resources to the field. We believe that our proposed MapNav can be used as a new memory representation method in VLN, paving the way for future research in this field.",
      "authors": [
        "Lingfeng Zhang",
        "Xiaoshuai Hao",
        "Qinwen Xu",
        "Qiang Zhang",
        "Xinyao Zhang",
        "Pengwei Wang",
        "Jing Zhang",
        "Zhongyuan Wang",
        "Shanghang Zhang",
        "Renjing Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-19T05:52:34+00:00",
          "link": "https://arxiv.org/abs/2502.13451v1",
          "size": "23324kb",
          "version": "v1"
        },
        {
          "date": "2025-02-21T09:01:50+00:00",
          "link": "https://arxiv.org/abs/2502.13451v2",
          "size": "23324kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T02:13:54+00:00",
          "link": "https://arxiv.org/abs/2502.13451v3",
          "size": "23318kb",
          "version": "v3"
        }
      ],
      "title": "MapNav: A Novel Memory Representation via Annotated Semantic Maps for VLM-based Vision-and-Language Navigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.13451",
        "HTML": "https://arxiv.org/html/2502.13451v3",
        "PDF": "https://arxiv.org/pdf/2502.13451"
      },
      "source": "arXiv"
    },
    {
      "id": "2502.15610",
      "abstract": "Accurate identification of bioactive peptides (BPs) and protein post-translational modifications (PTMs) is essential for understanding protein function and advancing therapeutic discovery. However, most computational methods remain limited in their generalizability across diverse peptide functions. Here, we present PDeepPP, a unified deep learning framework that integrates pretrained protein language models with a hybrid transformer-convolutional architecture, enabling robust identification across diverse peptide classes and PTM sites. We curated comprehensive benchmark datasets and implemented strategies to address data imbalance, allowing PDeepPP to systematically extract both global and local sequence features. Through extensive analyses-including dimensionality reduction and comparison studies-PDeepPP demonstrates strong, interpretable peptide representations and achieves state-of-the-art performance in 25 of the 33 biological identification tasks. Notably, PDeepPP attains high accuracy in antimicrobial (0.9726) and phosphorylation site (0.9984) identification, with 99.5% specificity in glycosylation site prediction and substantial reduction in false negatives in antimalarial tasks. By enabling large-scale, accurate peptide analysis, PDeepPP supports biomedical research and the discovery of novel therapeutic targets for disease treatment. All code, datasets, and pretrained models are publicly available via GitHub:https://github.com/fondress/PDeepPP and Hugging Face:https://huggingface.co/fondress/PDeppPP.",
      "authors": [
        "Jixiu Zhai",
        "Tianchi Lu",
        "Haitian Zhong",
        "Ziyang Xu",
        "Yuhuan Liu",
        "Shengrui Xu",
        "Jingwan Wang and Dan Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-21T17:31:22+00:00",
          "link": "https://arxiv.org/abs/2502.15610v1",
          "size": "36495kb",
          "version": "v1"
        },
        {
          "date": "2025-04-17T17:52:57+00:00",
          "link": "https://arxiv.org/abs/2502.15610v2",
          "size": "36392kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T05:46:24+00:00",
          "link": "https://arxiv.org/abs/2502.15610v3",
          "size": "36315kb",
          "version": "v3"
        }
      ],
      "title": "A general language model for peptide identification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15610",
        "HTML": "https://arxiv.org/html/2502.15610v3",
        "PDF": "https://arxiv.org/pdf/2502.15610"
      },
      "models": [
        {
          "model_path": "fondress/PDeepPP",
          "downloads": "0",
          "likes": "1",
          "trending_score": "0.0",
          "link": "https://huggingface.co/fondress/PDeepPP"
        }
      ],
      "tasks": [
        "Deep Learning",
        "Language Modeling",
        "Language Modelling",
        "model",
        "Specificity"
      ],
      "repo_urls": [
        "https://github.com/fondress/pdeeppp"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.15676",
      "abstract": "Theory of Mind (ToM), the ability to understand people's minds based on their behavior, is key to developing socially intelligent agents. Current approaches to ToM reasoning either rely on prompting Large Language Models (LLMs), which are prone to systematic errors, or use handcrafted, rigid agent models for model-based inference, which are more robust but fail to generalize across domains. In this work, we introduce AutoToM, an automated agent modeling method for scalable, robust, and interpretable mental inference. Given a ToM problem, AutoToM first proposes an initial agent model and then performs automated Bayesian inverse planning based on this model, leveraging an LLM backend. Guided by inference uncertainty, it iteratively refines the model by introducing additional mental variables and/or incorporating more timesteps in the context. Across five diverse benchmarks, AutoToM outperforms existing ToM methods and even large reasoning models. Additionally, we show that AutoToM can produce human-like confidence estimates and enable online mental inference for embodied decision-making.",
      "authors": [
        "Zhining Zhang",
        "Chuanyang Jin",
        "Mung Yao Jia",
        "Shunchi Zhang",
        "Tianmin Shu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-21T18:57:52+00:00",
          "link": "https://arxiv.org/abs/2502.15676v1",
          "size": "5834kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T16:18:27+00:00",
          "link": "https://arxiv.org/abs/2502.15676v2",
          "size": "5131kb",
          "version": "v2"
        }
      ],
      "title": "AutoToM: Scaling Model-based Mental Inference via Automated Agent Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15676",
        "PDF": "https://arxiv.org/pdf/2502.15676"
      },
      "tasks": [
        "Model Discovery"
      ],
      "repo_urls": [
        "https://github.com/chuanyangjin/MMToM-QA",
        "https://github.com/SCAI-JHU/AutoToM"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.15727",
      "abstract": "This paper presents a novel approach to evaluate the efficiency of a RAG-based agentic Large Language Model (LLM) architecture for network packet seed generation and enrichment. Enhanced by chain-of-thought (COT) prompting techniques, the proposed approach focuses on the improvement of the seeds' structural quality in order to guide protocol fuzzing frameworks through a wide exploration of the protocol state space. Our method leverages RAG and text embeddings to dynamically reference to the Request For Comments (RFC) documents knowledge base for answering queries regarding the protocol's Finite State Machine (FSM), then iteratively reasons through the retrieved knowledge, for output refinement and proper seed placement. We then evaluate the response structure quality of the agent's output, based on metrics as BLEU, ROUGE, and Word Error Rate (WER) by comparing the generated packets against the ground-truth packets. Our experiments demonstrate significant improvements of up to 18.19%, 14.81%, and 23.45% in BLEU, ROUGE, and WER, respectively, over baseline models. These results confirm the potential of such approach, improving LLM-based protocol fuzzing frameworks for the identification of hidden vulnerabilities.",
      "authors": [
        "Youssef Maklad",
        "Fares Wael",
        "Wael Elsersy",
        "Ali Hamdi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-30T01:03:49+00:00",
          "link": "https://arxiv.org/abs/2502.15727v1",
          "size": "832kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T18:24:21+00:00",
          "link": "https://arxiv.org/abs/2502.15727v2",
          "size": "832kb",
          "version": "v2"
        }
      ],
      "title": "Retrieval Augmented Generation Based LLM Evaluation For Protocol State Machine Inference With Chain-of-Thought Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15727",
        "HTML": "https://arxiv.org/html/2502.15727v2",
        "PDF": "https://arxiv.org/pdf/2502.15727"
      },
      "tasks": [
        "Large Language Model",
        "RAG",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.15799",
      "abstract": "Large Language Models (LLMs) are powerful tools for modern applications, but their computational demands limit accessibility. Quantization offers efficiency gains, yet its impact on safety and trustworthiness remains poorly understood. To address this, we introduce OpenMiniSafety, a human-curated safety dataset with 1.067 challenging questions to rigorously evaluate model behavior. We publicly release human safety evaluations for four LLMs (both quantized and full-precision), totaling 4.268 annotated question-answer pairs. By assessing 66 quantized variants of these models using four post-training quantization (PTQ) and two quantization-aware training (QAT) methods across four safety benchmarks including human-centric evaluations we uncover critical safety performance trade-offs. Our results show both PTQ and QAT can degrade safety alignment, with QAT techniques like QLORA or STE performing less safely. No single method consistently outperforms others across benchmarks, precision settings, or models, highlighting the need for safety-aware compression strategies. Furthermore, precision-specialized methods (e.g., QUIK and AWQ for 4-bit, AQLM and Q-PET for 2-bit) excel at their target precision, meaning that these methods are not better at compressing but rather different approaches.",
      "authors": [
        "Artyom Kharinaev",
        "Viktor Moskvoretskii",
        "Egor Shvetsov",
        "Kseniia Studenikina",
        "Bykov Mikhail",
        "Evgeny Burnaev"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-18T20:32:05+00:00",
          "link": "https://arxiv.org/abs/2502.15799v1",
          "size": "644kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T19:20:45+00:00",
          "link": "https://arxiv.org/abs/2502.15799v2",
          "size": "551kb",
          "version": "v2"
        }
      ],
      "title": "Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.15799",
        "PDF": "https://arxiv.org/pdf/2502.15799"
      },
      "tasks": [
        "Quantization"
      ],
      "repo_urls": [
        "https://github.com/On-Point-RND/OpenSafetyMini-Investigating-the-Impact-of-Quantization-Methods-on-the-Safety-and-Reliability-of-LLM"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.16096",
      "abstract": "In this work, we study the problem of computing a maximum common contraction of two vertex-labeled graphs, i.e. how to make them identical by contracting as little edges as possible in the two graphs. We study the problem from a parameterized complexity point of view, using parameters such as the maximum degree, the degeneracy, the clique-width or treewidth of the input graphs as well as the number of allowed contractions. We put this complexity in perspective with that of the labeled contractibility problem, i.e determining whether a labeled graph is a contraction of another. Surprisingly, our results indicate very little difference between these problems in terms of parameterized complexity status. We only prove their status to differ when parameterizing by both the degeneracy and the number of allowed contractions, showing W[1]-hardness of the maximum common contraction problem in this case, whereas the contractibility problem is FPT.",
      "authors": [
        "Manuel Lafond and Bertrand Marchand"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-22T05:39:36+00:00",
          "link": "https://arxiv.org/abs/2502.16096v1",
          "size": "361kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T23:04:44+00:00",
          "link": "https://arxiv.org/abs/2502.16096v2",
          "size": "346kb",
          "version": "v2"
        }
      ],
      "title": "The Parameterized Landscape of Labeled Graph Contractions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.16096",
        "HTML": "https://arxiv.org/html/2502.16096v2",
        "PDF": "https://arxiv.org/pdf/2502.16096"
      },
      "source": "arXiv"
    },
    {
      "id": "2502.16196",
      "abstract": "In this work, we present and analyze a novel stabilized virtual element formulation for the coupled Stokes-Temperature equation on polygonal meshes, employing equal-order element pairs where viscosity depends on temperature. The main objective of the proposed virtual elements is to develop a stabilized virtual element problem that avoids higher-order derivative terms and bilinear forms involving velocity, pressure and temperature, thereby avoiding the coupling between virtual element pairs. Moreover, it also reduces the violation of divergence-free constraints and offers reasonable control over the gradient of temperature. We derive the stability of the continuous solution using the Banach fixed-point theorem under sufficiently small data. The stabilized coupled virtual element problem is formulated using the local projection-based stabilization methods. We demonstrate the existence and uniqueness of the stabilized discrete solution using the Brouwer fixed-point theorem and the contraction theorem under the assumption of sufficient small data by showing the well-posedness of the stabilized decoupled virtual element problems. Furthermore, we derive the error estimates with optimal convergence rates in the energy norms. We present several numerical examples to confirm the theoretical findings. Additionally, the numerical behavior of the proposed stabilized method is shown to be robust with respect to linear and non-linear thermal conductivity.",
      "authors": [
        "Sudheer Mishra",
        "Natarajan E"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-22T11:53:11+00:00",
          "link": "https://arxiv.org/abs/2502.16196v1",
          "size": "2503kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T12:25:31+00:00",
          "link": "https://arxiv.org/abs/2502.16196v2",
          "size": "1554kb",
          "version": "v2"
        }
      ],
      "title": "An equal-order virtual element framework for the coupled Stokes-Temperature equation with nonlinear viscosity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.16196",
        "HTML": "https://arxiv.org/html/2502.16196v2",
        "PDF": "https://arxiv.org/pdf/2502.16196"
      },
      "source": "arXiv"
    },
    {
      "id": "2502.16825",
      "abstract": "Iterative data generation and model retraining are widely used to align large language models (LLMs). It typically involves a policy model to generate on-policy responses and a reward model to guide training data selection. Direct Preference Optimization (DPO) further enhances this process by constructing preference pairs of chosen and rejected responses. In this work, we aim to \\emph{scale up} the number of on-policy samples via repeated random sampling to improve alignment performance. Conventional practice selects the sample with the highest reward as chosen and the lowest as rejected for DPO. However, our experiments reveal that this strategy leads to a \\emph{decline} in performance as the sample size increases. To address this, we investigate preference data construction through the lens of underlying normal distribution of sample rewards. We categorize the reward space into seven representative points and systematically explore all 21 ($C_7^2$) pairwise combinations. Through evaluations on four models using AlpacaEval 2, we find that selecting the rejected response at reward position $\\mu - 2\\sigma$ rather than the minimum reward, is crucial for optimal performance. We finally introduce a scalable preference data construction strategy that consistently enhances model performance as the sample scale increases.",
      "authors": [
        "Yao Xiao",
        "Hai Ye",
        "Linyao Chen",
        "Hwee Tou Ng",
        "Lidong Bing",
        "Xiaoli Li",
        "Roy Ka-wei Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-24T04:22:57+00:00",
          "link": "https://arxiv.org/abs/2502.16825v1",
          "size": "937kb",
          "version": "v1"
        },
        {
          "date": "2025-05-21T12:53:32+00:00",
          "link": "https://arxiv.org/abs/2502.16825v2",
          "size": "8523kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T07:31:40+00:00",
          "link": "https://arxiv.org/abs/2502.16825v3",
          "size": "8524kb",
          "version": "v3"
        }
      ],
      "title": "Finding the Sweet Spot: Preference Data Construction for Scaling Preference Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.16825",
        "HTML": "https://arxiv.org/html/2502.16825v3",
        "PDF": "https://arxiv.org/pdf/2502.16825"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.18282",
      "abstract": "Recent works have shown that Large Language Models (LLMs) have a tendency to memorize patterns and biases present in their training data, raising important questions about how such memorized content influences model behavior. One such concern is the emergence of political bias in LLM outputs. In this paper, we investigate the extent to which LLMs' political leanings reflect memorized patterns from their pretraining corpora. We propose a method to quantitatively evaluate political leanings embedded in the large pretraining corpora. Subsequently we investigate to whom are the LLMs' political leanings more aligned with, their pretrainig corpora or the surveyed human opinions. As a case study, we focus on probing the political leanings of LLMs in 32 US Supreme Court cases, addressing contentious topics such as abortion and voting rights. Our findings reveal that LLMs strongly reflect the political leanings in their training data, and no strong correlation is observed with their alignment to human opinions as expressed in surveys. These results underscore the importance of responsible curation of training data, and the methodology for auditing the memorization in LLMs to ensure human-AI alignment.",
      "authors": [
        "Shanshan Xu",
        "T.Y.S.S Santosh",
        "Yanai Elazar",
        "Quirin Vogel",
        "Barbara Plank",
        "Matthias Grabmair"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-25T15:16:17+00:00",
          "link": "https://arxiv.org/abs/2502.18282v1",
          "size": "6498kb",
          "version": "v1"
        },
        {
          "date": "2025-03-04T19:06:06+00:00",
          "link": "https://arxiv.org/abs/2502.18282v2",
          "size": "6495kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T10:09:37+00:00",
          "link": "https://arxiv.org/abs/2502.18282v3",
          "size": "6476kb",
          "version": "v3"
        }
      ],
      "title": "Better Aligned with Survey Respondents or Training Data? Unveiling Political Leanings of LLMs on U.S. Supreme Court Cases",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.18282",
        "HTML": "https://arxiv.org/html/2502.18282v3",
        "PDF": "https://arxiv.org/pdf/2502.18282"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.18435",
      "abstract": "Language models usually use left-to-right (L2R) autoregressive factorization. However, L2R factorization may not always be the best inductive bias. Therefore, we investigate whether alternative factorizations of the text distribution could be beneficial in some tasks. We investigate right-to-left (R2L) training as a compelling alternative, focusing on multiple-choice questions (MCQs) as a test bed for knowledge extraction and reasoning. Through extensive experiments across various model sizes (2B-8B parameters) and training datasets, we find that R2L models can significantly outperform L2R models on several MCQ benchmarks, including logical reasoning, commonsense understanding, and truthfulness assessment tasks. Our analysis reveals that this performance difference may be fundamentally linked to multiple factors including calibration, computability, and directional conditional entropy. We analyze the impact of these factors through controlled simulation studies using arithmetic tasks, where the impacting factors can be better disentangled. Our work demonstrates that exploring alternative factorizations of the text distribution can lead to improvements in LLM capabilities and provides theoretical insights into optimal factorization towards approximating human language distribution, and when each reasoning order might be more advantageous. Our code and checkpoints are released at https://github.com/apple/ml-reversal-blessing.",
      "authors": [
        "Yizhe Zhang",
        "Richard Bai",
        "Zijin Gu",
        "Ruixiang Zhang",
        "Jiatao Gu",
        "Emmanuel Abbe",
        "Samy Bengio",
        "Navdeep Jaitly"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Theory (cs.IT)",
        "Machine Learning (cs.LG)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-25T18:30:25+00:00",
          "link": "https://arxiv.org/abs/2502.18435v1",
          "size": "2462kb",
          "version": "v1"
        },
        {
          "date": "2025-03-20T03:25:21+00:00",
          "link": "https://arxiv.org/abs/2502.18435v2",
          "size": "2462kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T19:00:20+00:00",
          "link": "https://arxiv.org/abs/2502.18435v3",
          "size": "2455kb",
          "version": "v3"
        }
      ],
      "title": "What Makes the Preferred Thinking Direction for LLMs in Multiple-choice Questions?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.18435",
        "HTML": "https://arxiv.org/html/2502.18435v3",
        "PDF": "https://arxiv.org/pdf/2502.18435"
      },
      "models": [
        {
          "model_path": "apple/ml-reversal-blessing",
          "downloads": "0",
          "likes": "4",
          "trending_score": "0.0",
          "link": "https://huggingface.co/apple/ml-reversal-blessing"
        }
      ],
      "tasks": [
        "Inductive Bias",
        "Logical Reasoning",
        "Multiple-choice"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.18968",
      "abstract": "User simulators are crucial for replicating human interactions with dialogue systems, supporting both collaborative training and automatic evaluation, especially for large language models (LLMs). However, current role-playing methods face challenges such as a lack of utterance-level authenticity and user-level diversity, often hindered by role confusion and dependence on predefined profiles of well-known figures. In contrast, direct simulation focuses solely on text, neglecting implicit user traits like personality and conversation-level consistency. To address these issues, we introduce the User Simulator with Implicit Profiles (USP), a framework that infers implicit user profiles from human-machine interactions to simulate personalized and realistic dialogues. We first develop an LLM-driven extractor with a comprehensive profile schema, then refine the simulation using conditional supervised fine-tuning and reinforcement learning with cycle consistency, optimizing at both the utterance and conversation levels. Finally, a diverse profile sampler captures the distribution of real-world user profiles. Experimental results show that USP outperforms strong baselines in terms of authenticity and diversity while maintaining comparable consistency. Additionally, using USP to evaluate LLM on dynamic multi-turn aligns well with mainstream benchmarks, demonstrating its effectiveness in real-world applications.",
      "authors": [
        "Kuang Wang",
        "Xianfei Li",
        "Shenghao Yang",
        "Li Zhou",
        "Feng Jiang and Haizhou Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-26T09:26:54+00:00",
          "link": "https://arxiv.org/abs/2502.18968v1",
          "size": "7750kb",
          "version": "v1"
        },
        {
          "date": "2025-02-28T03:41:20+00:00",
          "link": "https://arxiv.org/abs/2502.18968v2",
          "size": "7100kb",
          "version": "v2"
        },
        {
          "date": "2025-06-01T08:16:38+00:00",
          "link": "https://arxiv.org/abs/2502.18968v3",
          "size": "836kb",
          "version": "v3"
        },
        {
          "date": "2025-06-29T15:58:49+00:00",
          "link": "https://arxiv.org/abs/2502.18968v4",
          "size": "834kb",
          "version": "v4"
        }
      ],
      "title": "Know You First and Be You Better: Modeling Human-Like User Simulators via Implicit Profiles",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.18968",
        "HTML": "https://arxiv.org/html/2502.18968v4",
        "PDF": "https://arxiv.org/pdf/2502.18968"
      },
      "models": [
        {
          "model_path": "wangkevin02/USP",
          "downloads": "31",
          "likes": "1",
          "trending_score": "1.0",
          "link": "https://huggingface.co/wangkevin02/USP"
        },
        {
          "model_path": "wangkevin02/AI_Detect_Model",
          "downloads": "33",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/wangkevin02/AI_Detect_Model"
        }
      ],
      "datasets": [
        {
          "dataset_name": "wangkevin02/LMSYS-USP",
          "downloads": "5",
          "likes": "1",
          "link": "https://huggingface.co/datasets/wangkevin02/LMSYS-USP"
        }
      ],
      "tasks": [],
      "repo_urls": [
        "https://github.com/wangkevin02/USP"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.19537",
      "abstract": "Leading language model (LM) providers like OpenAI and Anthropic allow customers to fine-tune frontier LMs for specific use cases. To prevent abuse, these providers apply filters to block fine-tuning on overtly harmful data. In this setting, we make three contributions: First, while past work has shown that safety alignment is \"shallow\", we correspondingly demonstrate that existing fine-tuning attacks are shallow -- attacks target only the first several tokens of the model response, and consequently can be blocked by generating the first several response tokens with an aligned model. Second, we conceptually illustrate how to make attacks deeper by introducing a new fine-tuning attack that trains models to first refuse harmful requests before answering them; this \"refuse-then-comply\" strategy bypasses shallow defenses and produces harmful responses that evade output filters. Third, we demonstrate the potency of our new fine-tuning attack by jailbreaking both open-source models equipped with defenses and production models, achieving attack success rates of 57% and 72% against GPT-4o and Claude Haiku, respectively. Our attack received a $2000 bug bounty from OpenAI and was acknowledged as a vulnerability by Anthropic. Our work undermines the notion that models are safe because they initially refuse harmful requests and broadens awareness of the scope of attacks that face production fine-tuning APIs.",
      "authors": [
        "Joshua Kazdan",
        "Abhay Puri",
        "Rylan Schaeffer",
        "Lisa Yu",
        "Chris Cundy",
        "Jason Stanley",
        "Sanmi Koyejo",
        "Krishnamurthy Dvijotham"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-26T20:20:01+00:00",
          "link": "https://arxiv.org/abs/2502.19537v1",
          "size": "2456kb",
          "version": "v1"
        },
        {
          "date": "2025-03-19T17:50:21+00:00",
          "link": "https://arxiv.org/abs/2502.19537v2",
          "size": "2456kb",
          "version": "v2"
        },
        {
          "date": "2025-04-01T18:57:07+00:00",
          "link": "https://arxiv.org/abs/2502.19537v3",
          "size": "2463kb",
          "version": "v3"
        },
        {
          "date": "2025-06-29T22:09:54+00:00",
          "link": "https://arxiv.org/abs/2502.19537v4",
          "size": "3149kb",
          "version": "v4"
        }
      ],
      "title": "No, of course I can! Refusal Mechanisms Can Be Exploited Using Harmless Fine-Tuning Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.19537",
        "HTML": "https://arxiv.org/html/2502.19537v4",
        "PDF": "https://arxiv.org/pdf/2502.19537"
      },
      "tasks": [
        "Data Poisoning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.20532",
      "abstract": "Label-free chemical imaging holds significant promise for improving digital pathology workflows, but data acquisition speed remains a limiting factor. To address this gap, we propose an adaptive strategy-initially scan the low information (LI) content of the entire tissue quickly, identify regions with high aleatoric uncertainty (AU), and selectively re-image them at better quality to capture higher information (HI) details. The primary challenge lies in distinguishing between high-AU regions mitigable through HI imaging and those that are not. However, since existing uncertainty frameworks cannot separate such AU subcategories, we propose a fine-grained disentanglement method based on post-hoc latent space analysis to unmix resolvable from irresolvable high-AU regions. We apply our approach to streamline infrared spectroscopic imaging of breast tissues, achieving superior downstream segmentation performance. This marks the first study focused on fine-grained AU disentanglement within dynamic image spaces (LI-to-HI), with novel application to streamline histopathology.",
      "authors": [
        "Ji-Hun Oh",
        "Kianoush Falahkheirkhah",
        "Rohit Bhargava"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-27T21:36:27+00:00",
          "link": "https://arxiv.org/abs/2502.20532v1",
          "size": "9742kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T04:16:09+00:00",
          "link": "https://arxiv.org/abs/2502.20532v2",
          "size": "9284kb",
          "version": "v2"
        }
      ],
      "title": "Finer Disentanglement of Aleatoric Uncertainty Can Accelerate Chemical Histopathology Imaging",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20532",
        "HTML": "https://arxiv.org/html/2502.20532v2",
        "PDF": "https://arxiv.org/pdf/2502.20532"
      },
      "source": "arXiv"
    },
    {
      "id": "2502.20959",
      "abstract": "Serverless computing has emerged as a pivotal paradigm for deploying Deep Learning (DL) models, offering automatic scaling and cost efficiency. However, the inherent cold start problem in serverless ML inference systems, particularly the time-consuming model loading process, remains a significant bottleneck. Utilizing pipelined model loading improves efficiency but still suffer from pipeline stalls due to sequential layer construction and monolithic weight loading. In this paper, we propose \\textit{Cicada}, a novel pipeline optimization framework that coordinates computational, storage, and scheduling resources through three key mechanisms: (1) \\textit{MiniLoader}: which reduces layer construction overhead by opportunistically optimizing parameter initialization; (2) \\textit{WeightDecoupler}: decoupling weight file processing from layer construction, enabling asynchronous weight retrieval and out-of-order weight application; (3) \\textit{Priority-Aware Scheduler}: dynamically allocating resources to ensure high-priority inference tasks are executed promptly. Our experimental results demonstrate that Cicada achieves significant performance improvements over the state-of-the-art PISeL framework. Specifically, Cicada reduces end-to-end inference latency by an average of 61.59\\%, with the MiniLoader component contributing the majority of this optimization (53.41\\%), and the WeightDecoupler achieves up to 26.17\\% improvement. Additionally, Cicada achieves up to 2.52x speedup in the inference pipeline utlization compared to PISeL.",
      "authors": [
        "Z. Wu",
        "Y. Deng",
        "J. Hu",
        "L. Cui",
        "Z. Zhang",
        "L. Zeng",
        "G. Min"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-28T11:19:05+00:00",
          "link": "https://arxiv.org/abs/2502.20959v1",
          "size": "826kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T19:24:34+00:00",
          "link": "https://arxiv.org/abs/2502.20959v2",
          "size": "1535kb",
          "version": "v2"
        }
      ],
      "title": "Cicada: A Pipeline-Efficient Approach to Serverless Inference with Decoupled Management",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20959",
        "HTML": "https://arxiv.org/html/2502.20959v2",
        "PDF": "https://arxiv.org/pdf/2502.20959"
      },
      "source": "arXiv"
    },
    {
      "id": "2502.21085",
      "abstract": "Badminton, known for having the fastest ball speeds among all sports, presents significant challenges to the field of computer vision, including player identification, court line detection, shuttlecock trajectory tracking, and player stroke-type classification. In this paper, we introduce a novel video segmentation strategy to extract frames of each player's racket swing in a badminton broadcast match. These segmented frames are then processed by two existing models: one for Human Pose Estimation to obtain player skeletal joints, and the other for shuttlecock trajectory detection to extract shuttlecock trajectories. Leveraging these joints, trajectories, and player positions as inputs, we propose Badminton Stroke-type Transformer (BST) to classify player stroke-types in singles. To the best of our knowledge, experimental results demonstrate that our method outperforms the previous state-of-the-art on the largest publicly available badminton video dataset, ShuttleSet, which shows that effectively leveraging ball trajectory is likely to be a trend for racket sports action recognition.",
      "authors": [
        "Jing-Yuan Chang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-28T14:18:39+00:00",
          "link": "https://arxiv.org/abs/2502.21085v1",
          "size": "550kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T10:17:08+00:00",
          "link": "https://arxiv.org/abs/2502.21085v2",
          "size": "594kb",
          "version": "v2"
        }
      ],
      "title": "BST: Badminton Stroke-type Transformer for Skeleton-based Action Recognition in Racket Sports",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.21085",
        "HTML": "https://arxiv.org/html/2502.21085v2",
        "PDF": "https://arxiv.org/pdf/2502.21085"
      },
      "tasks": [
        "Action Recognition",
        "Line Detection",
        "Pose Estimation",
        "Skeleton Based Action Recognition",
        "Video Segmentation",
        "Video Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/Va6lue/BST-Badminton-Stroke-type-Transformer"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.00071",
      "abstract": "In face-to-face interaction, we use multiple modalities, including speech and gestures, to communicate information and resolve references to objects. However, how representational co-speech gestures refer to objects remains understudied from a computational perspective. In this work, we address this gap by introducing a multimodal reference resolution task centred on representational gestures, while simultaneously tackling the challenge of learning robust gesture embeddings. We propose a self-supervised pre-training approach to gesture representation learning that grounds body movements in spoken language. Our experiments show that the learned embeddings align with expert annotations and have significant predictive power. Moreover, reference resolution accuracy further improves when (1) using multimodal gesture representations, even when speech is unavailable at inference time, and (2) leveraging dialogue history. Overall, our findings highlight the complementary roles of gesture and speech in reference resolution, offering a step towards more naturalistic models of human-machine interaction.",
      "authors": [
        "Esam Ghaleb",
        "Bulat Khaertdinov",
        "Asl{\\i} \\\"Ozy\\\"urek",
        "Raquel Fern\\'andez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Computation and Language (cs.CL)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-27T17:28:12+00:00",
          "link": "https://arxiv.org/abs/2503.00071v1",
          "size": "6381kb",
          "version": "v1"
        },
        {
          "date": "2025-06-02T14:52:36+00:00",
          "link": "https://arxiv.org/abs/2503.00071v2",
          "size": "11250kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T18:02:32+00:00",
          "link": "https://arxiv.org/abs/2503.00071v3",
          "size": "11250kb",
          "version": "v3"
        }
      ],
      "title": "I see what you mean: Co-Speech Gestures for Reference Resolution in Multimodal Dialogue",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00071",
        "HTML": "https://arxiv.org/html/2503.00071v3",
        "PDF": "https://arxiv.org/pdf/2503.00071"
      },
      "tasks": [
        "Representation Learning"
      ],
      "repo_urls": [
        "https://github.com/EsamGhaleb/MultimodalReferenceResolution"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.00436",
      "abstract": "In the dynamic landscape of artificial intelligence, the exploration of hallucinations within vision-language (VL) models emerges as a critical frontier. This work delves into the intricacies of hallucinatory phenomena exhibited by widely used image captioners, unraveling interesting patterns. Specifically, we step upon previously introduced techniques of conceptual counterfactual explanations to address VL hallucinations. The deterministic and efficient nature of the employed conceptual counterfactuals backbone is able to suggest semantically minimal edits driven by hierarchical knowledge, so that the transition from a hallucinated caption to a non-hallucinated one is performed in a black-box manner. HalCECE, our proposed hallucination detection framework is highly interpretable, by providing semantically meaningful edits apart from standalone numbers, while the hierarchical decomposition of hallucinated concepts leads to a thorough hallucination analysis. Another novelty tied to the current work is the investigation of role hallucinations, being one of the first works to involve interconnections between visual concepts in hallucination detection. Overall, HalCECE recommends an explainable direction to the crucial field of VL hallucination detection, thus fostering trustworthy evaluation of current and future VL systems.",
      "authors": [
        "Maria Lymperaiou",
        "Giorgos Filandrianos",
        "Angeliki Dimitriou",
        "Athanasios Voulodimos",
        "Giorgos Stamou"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-01T10:28:19+00:00",
          "link": "https://arxiv.org/abs/2503.00436v1",
          "size": "1282kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T08:26:14+00:00",
          "link": "https://arxiv.org/abs/2503.00436v2",
          "size": "1080kb",
          "version": "v2"
        }
      ],
      "title": "HalCECE: A Framework for Explainable Hallucination Detection through Conceptual Counterfactuals in Image Captioning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00436",
        "HTML": "https://arxiv.org/html/2503.00436v2",
        "PDF": "https://arxiv.org/pdf/2503.00436"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.00583",
      "abstract": "We address the Multi-Robot Motion Planning (MRMP) problem of computing collision-free trajectories for multiple robots in shared continuous environments. While existing frameworks effectively decompose MRMP into single-robot subproblems, spatiotemporal motion planning with dynamic obstacles remains challenging, particularly in cluttered or narrow-corridor settings. We propose Space-Time Graphs of Convex Sets (ST-GCS), a novel planner that systematically covers the collision-free space-time domain with convex sets instead of relying on random sampling. By extending Graphs of Convex Sets (GCS) into the time dimension, ST-GCS formulates time-optimal trajectories in a unified convex optimization that naturally accommodates velocity bounds and flexible arrival times. We also propose Exact Convex Decomposition (ECD) to \"reserve\" trajectories as spatiotemporal obstacles, maintaining a collision-free space-time graph of convex sets for subsequent planning. Integrated into two prioritized-planning frameworks, ST-GCS consistently achieves higher success rates and better solution quality than state-of-the-art sampling-based planners -- often at orders-of-magnitude faster runtimes -- underscoring its benefits for MRMP in challenging settings.",
      "authors": [
        "Jingtao Tang",
        "Zining Mao",
        "Lufan Yang",
        "Hang Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-01T18:28:57+00:00",
          "link": "https://arxiv.org/abs/2503.00583v1",
          "size": "1528kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T23:53:38+00:00",
          "link": "https://arxiv.org/abs/2503.00583v2",
          "size": "1289kb",
          "version": "v2"
        }
      ],
      "title": "Space-Time Graphs of Convex Sets for Multi-Robot Motion Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00583",
        "HTML": "https://arxiv.org/html/2503.00583v2",
        "PDF": "https://arxiv.org/pdf/2503.00583"
      },
      "tasks": [
        "Motion Planning"
      ],
      "repo_urls": [
        "https://github.com/reso1/stgcs"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.01328",
      "abstract": "Pipeline parallelism (PP) is widely used for training large language models (LLMs), yet its scalability is often constrained by high activation memory consumption as the number of in-flight microbatches grows with the degree of PP. In this paper, we focus on addressing this challenge by leveraging the under-explored memory offload strategy in PP. With empirical study, we discover that in the majority of standard configurations, at least half, and potentially all, of the activations can be offloaded with negligible overhead. In the cases where full overload is not possible, we introduce a novel selective offload strategy that decreases peak activation memory in a better-than-linear manner. Furthermore, we integrate memory offload with other techniques to jointly consider overall throughput and memory limitation. Our experiments proves that the per-device activation memory effectively reduces with the total number of stages, making PP a stronger alternative than TP, offering up to a 19\\% acceleration with even lower memory consumption. The implementation is open-sourced at \\href{https://github.com/sail-sg/zero-bubble-pipeline-parallelism}{this url}.",
      "authors": [
        "Xinyi Wan",
        "Penghui Qi",
        "Guangxing Huang",
        "Min Lin",
        "Jialin Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-03T09:11:06+00:00",
          "link": "https://arxiv.org/abs/2503.01328v1",
          "size": "606kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T06:37:05+00:00",
          "link": "https://arxiv.org/abs/2503.01328v2",
          "size": "399kb",
          "version": "v2"
        }
      ],
      "title": "PipeOffload: Improving Scalability of Pipeline Parallelism with Memory Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01328",
        "HTML": "https://arxiv.org/html/2503.01328v2",
        "PDF": "https://arxiv.org/pdf/2503.01328"
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/sail-sg/zero-bubble-pipeline-parallelism"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.01875",
      "abstract": "Time series data are foundational in finance, healthcare, and energy domains. However, most existing methods and datasets remain focused on a narrow spectrum of tasks, such as forecasting or anomaly detection. To bridge this gap, we introduce Time Series Multi-Task Question Answering (Time-MQA), a unified framework that enables natural language queries across multiple time series tasks - numerical analytical tasks and open-ended question answering with reasoning. Central to Time-MQA is the TSQA dataset, a large-scale dataset containing $\\sim$200k question-answer pairs derived from diverse time series spanning environment, traffic, etc. This comprehensive resource covers various time series lengths and promotes robust model development. We further demonstrate how continually pre-training large language models (Mistral 7B, Llama-3 8B, and Qwen-2.5 7B) on the TSQA dataset enhanced time series reasoning capabilities, moving beyond mere numeric tasks and enabling more advanced and intuitive interactions with temporal data. The complete TSQA dataset, models, user study questionnaires for evaluation, and other related materials have been open-sourced.",
      "authors": [
        "Yaxuan Kong",
        "Yiyuan Yang",
        "Yoontae Hwang",
        "Wenjie Du",
        "Stefan Zohren",
        "Zhangyang Wang",
        "Ming Jin",
        "Qingsong Wen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-26T13:47:13+00:00",
          "link": "https://arxiv.org/abs/2503.01875v1",
          "size": "12026kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T18:42:47+00:00",
          "link": "https://arxiv.org/abs/2503.01875v2",
          "size": "6227kb",
          "version": "v2"
        }
      ],
      "title": "Time-MQA: Time Series Multi-Task Question Answering with Context Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.01875",
        "HTML": "https://arxiv.org/html/2503.01875v2",
        "PDF": "https://arxiv.org/pdf/2503.01875"
      },
      "datasets": [
        {
          "dataset_name": "Time-MQA/TSQA",
          "downloads": "193",
          "likes": "1",
          "link": "https://huggingface.co/datasets/Time-MQA/TSQA"
        }
      ],
      "tasks": [
        "Anomaly Detection",
        "Natural Language Queries",
        "Open-Ended Question Answering",
        "Question Answering",
        "Time Series"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.02236",
      "abstract": "In this work, we design and implement VQ-LLM, an efficient fused Vector Quantization (VQ) kernel generation framework. We first introduce a software abstraction called codebook cache to optimize codebook access efficiency and support the integration of VQ with various computations. The codebook cache adaptively stores different entries across the GPU's memory hierarchy, including off-chip global memory, on-chip shared memory, and registers. Centered around the codebook cache, we design an efficient computation engine that optimizes memory traffic during computations involving codebooks. This compute engine adopts the codebook-centric dataflow and fusion optimizations. Additionally, we provide adaptive heuristics to tailor parameter selection in our optimizations to diverse VQ configurations. Our optimizations achieve an average latency reduction of 46.13% compared to unoptimized versions. Compared to existing open-source implementations, our methods decrease latency by 64.36% to 99.1%. A final comparison with state-of-the-art element-wise quantization methods like AWQ and KVQuant shows that our VQ-LLM is practically viable, achieving latencies close or even better latencies to those at equivalent bit-widths, potentially offering greater accuracy.",
      "authors": [
        "Zihan Liu",
        "Xinhao Luo",
        "Junxian Guo",
        "Wentao Ni",
        "Yangjie Zhou",
        "Yue Guan",
        "Cong Guo",
        "Weihao Cui",
        "Yu Feng",
        "Minyi Guo",
        "Yuhao Zhu",
        "Minjia Zhang",
        "Jingwen Leng",
        "Chen Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-04T03:18:56+00:00",
          "link": "https://arxiv.org/abs/2503.02236v1",
          "size": "7875kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T05:54:40+00:00",
          "link": "https://arxiv.org/abs/2503.02236v2",
          "size": "1179kb",
          "version": "v2"
        }
      ],
      "title": "VQ-LLM: High-performance Code Generation for Vector Quantization Augmented LLM Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.02236",
        "HTML": "https://arxiv.org/html/2503.02236v2",
        "PDF": "https://arxiv.org/pdf/2503.02236"
      },
      "source": "arXiv"
    },
    {
      "id": "2503.03501",
      "abstract": "Gait recognition is a computer vision task that identifies individuals based on their walking patterns. Gait recognition performance is commonly evaluated by ranking a gallery of candidates and measuring the accuracy at the top Rank-$K$. Existing models are typically single-staged, i.e. searching for the probe's nearest neighbors in a gallery using a single global feature representation. Although these models typically excel at retrieving the correct identity within the top-$K$ predictions, they struggle when hard negatives appear in the top short-list, leading to relatively low performance at the highest ranks (e.g., Rank-1). In this paper, we introduce CarGait, a Cross-Attention Re-ranking method for gait recognition, that involves re-ordering the top-$K$ list leveraging the fine-grained correlations between pairs of gait sequences through cross-attention between gait strips. This re-ranking scheme can be adapted to existing single-stage models to enhance their final results. We demonstrate the capabilities of CarGait by extensive experiments on three common gait datasets, Gait3D, GREW, and OU-MVLP, and seven different gait models, showing consistent improvements in Rank-1,5 accuracy, superior results over existing re-ranking methods, and strong baselines.",
      "authors": [
        "Gavriel Habib",
        "Noa Barzilay",
        "Or Shimshi",
        "Rami Ben-Ari",
        "Nir Darshan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-05T13:47:02+00:00",
          "link": "https://arxiv.org/abs/2503.03501v1",
          "size": "2169kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T12:55:50+00:00",
          "link": "https://arxiv.org/abs/2503.03501v2",
          "size": "2170kb",
          "version": "v2"
        }
      ],
      "title": "CarGait: Cross-Attention based Re-ranking for Gait recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.03501",
        "HTML": "https://arxiv.org/html/2503.03501v2",
        "PDF": "https://arxiv.org/pdf/2503.03501"
      },
      "tasks": [
        "Gait Recognition",
        "Re-Ranking"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.03560",
      "abstract": "This paper studies a multi-target multi-user integrated sensing and communication (ISAC) system where a multi-antenna base station (BS) communicates with multiple single-antenna users in the downlink and senses the unknown and random angle information of multiple targets based on their reflected echo signals at the BS receiver as well as their prior probability information. We focus on a general beamforming structure with both communication beams and dedicated sensing beams, whose design is highly non-trivial as more sensing beams provide more flexibility in sensing, but introduce extra interference to communication. To resolve this trade-off, we first characterize the periodic posterior Cram\\'er-Rao bound (PCRB) as a lower bound of the mean-cyclic error (MCE) in multi-target sensing. Then, we optimize the beamforming to minimize the maximum periodic PCRB among all targets to ensure fairness, subject to individual communication rate constraints at multiple users. Despite the non-convexity of this problem, we propose a general construction method for the optimal solution by leveraging semi-definite relaxation (SDR), and derive a general bound on the number of sensing beams needed. Moreover, we unveil specific structures of the optimal solution in various cases, where tighter bounds on the number of sensing beams needed are derived (e.g., no or at most one sensing beam is needed under stringent rate constraints or with homogeneous targets). Next, we study the beamforming optimization to minimize the sum periodic PCRB under user rate constraints. By applying SDR, we propose a general construction method for the optimal solution and its specific structures which yield lower computational complexities. We derive a general bound and various tighter bounds on the number of sensing beams needed. Numerical results validate our analysis and effectiveness of our proposed beamforming designs.",
      "authors": [
        "Jiayi Yao and Shuowen Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-05T14:46:33+00:00",
          "link": "https://arxiv.org/abs/2503.03560v1",
          "size": "30885kb",
          "version": "v1"
        },
        {
          "date": "2025-05-03T14:01:39+00:00",
          "link": "https://arxiv.org/abs/2503.03560v2",
          "size": "30885kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T18:17:57+00:00",
          "link": "https://arxiv.org/abs/2503.03560v3",
          "size": "13350kb",
          "version": "v3"
        }
      ],
      "title": "Optimal Beamforming for Multi-Target Multi-User ISAC Exploiting Prior Information: How Many Sensing Beams Are Needed?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.03560",
        "HTML": "https://arxiv.org/html/2503.03560v3",
        "PDF": "https://arxiv.org/pdf/2503.03560"
      },
      "source": "arXiv"
    },
    {
      "id": "2503.03984",
      "abstract": "Autonomous visual navigation is an essential element in robot autonomy. Reinforcement learning (RL) offers a promising policy training paradigm. However existing RL methods suffer from high sample complexity, poor sim-to-real transfer, and limited runtime adaptability to navigation scenarios not seen during training. These problems are particularly challenging for drones, with complex nonlinear and unstable dynamics, and strong dynamic coupling between control and perception. In this paper, we propose a novel framework that integrates 3D Gaussian Splatting (3DGS) with differentiable deep reinforcement learning (DDRL) to train vision-based drone navigation policies. By leveraging high-fidelity 3D scene representations and differentiable simulation, our method improves sample efficiency and sim-to-real transfer. Additionally, we incorporate a Context-aided Estimator Network (CENet) to adapt to environmental variations at runtime. Moreover, by curriculum training in a mixture of different surrounding environments, we achieve in-task generalization, the ability to solve new instances of a task not seen during training. Drone hardware experiments demonstrate our method's high training efficiency compared to state-of-the-art RL methods, zero shot sim-to-real transfer for real robot deployment without fine tuning, and ability to adapt to new instances within the same task class (e.g. to fly through a gate at different locations with different distractors in the environment). Our simulator and training framework are open-sourced at: https://github.com/Qianzhong-Chen/grad_nav.",
      "authors": [
        "Qianzhong Chen",
        "Jiankai Sun",
        "Naixiang Gao",
        "JunEn Low",
        "Timothy Chen",
        "and Mac Schwager"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T00:13:01+00:00",
          "link": "https://arxiv.org/abs/2503.03984v1",
          "size": "5551kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T04:19:33+00:00",
          "link": "https://arxiv.org/abs/2503.03984v2",
          "size": "2670kb",
          "version": "v2"
        }
      ],
      "title": "GRaD-Nav: Efficiently Learning Visual Drone Navigation with Gaussian Radiance Fields and Differentiable Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.03984",
        "HTML": "https://arxiv.org/html/2503.03984v2",
        "PDF": "https://arxiv.org/pdf/2503.03984"
      },
      "source": "arXiv"
    },
    {
      "id": "2503.04257",
      "abstract": "Motion synthesis for diverse object categories holds great potential for 3D content creation but remains underexplored due to two key challenges: (1) the lack of comprehensive motion datasets that include a wide range of high-quality motions and annotations, and (2) the absence of methods capable of handling heterogeneous skeletal templates from diverse objects. To address these challenges, we contribute the following: First, we augment the Truebones Zoo dataset, a high-quality animal motion dataset covering over 70 species, by annotating it with detailed text descriptions, making it suitable for text-based motion synthesis. Second, we introduce rig augmentation techniques that generate diverse motion data while preserving consistent dynamics, enabling models to adapt to various skeletal configurations. Finally, we redesign existing motion diffusion models to dynamically adapt to arbitrary skeletal templates, enabling motion synthesis for a diverse range of objects with varying structures. Experiments show that our method learns to generate high-fidelity motions from textual descriptions for diverse and even unseen objects, setting a strong foundation for motion synthesis across diverse object categories and skeletal templates. Qualitative results are available at: $\\href{https://t2m4lvo.github.io}{https://t2m4lvo.github.io}$.",
      "authors": [
        "Wonkwang Lee",
        "Jongwon Jeong",
        "Taehong Moon",
        "Hyeon-Jong Kim",
        "Jaehyeon Kim",
        "Gunhee Kim",
        "Byeong-Uk Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T09:39:09+00:00",
          "link": "https://arxiv.org/abs/2503.04257v1",
          "size": "8422kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T08:56:10+00:00",
          "link": "https://arxiv.org/abs/2503.04257v2",
          "size": "10618kb",
          "version": "v2"
        }
      ],
      "title": "How to Move Your Dragon: Text-to-Motion Synthesis for Large-Vocabulary Objects",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04257",
        "HTML": "https://arxiv.org/html/2503.04257v2",
        "PDF": "https://arxiv.org/pdf/2503.04257"
      },
      "datasets": [
        {
          "dataset_name": "1Konny/t2m4lvo-truebones-zoo",
          "downloads": "0",
          "likes": "2",
          "link": "https://huggingface.co/datasets/1Konny/t2m4lvo-truebones-zoo"
        }
      ],
      "tasks": [
        "Motion Synthesis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.04722",
      "abstract": "Large language models (LLMs) exhibit the ability to generalize given few-shot examples in their input prompt, an emergent capability known as in-context learning (ICL). We investigate whether LLMs use ICL to perform structured reasoning in ways that are consistent with a Bayesian framework or rely on pattern matching. Using a controlled setting of biased coin flips, we find that: (1) LLMs often possess biased priors, causing initial divergence in zero-shot settings, (2) in-context evidence outweighs explicit bias instructions, (3) LLMs broadly follow Bayesian posterior updates, with deviations primarily due to miscalibrated priors rather than flawed updates, and (4) attention magnitude has negligible effect on Bayesian inference. With sufficient demonstrations of biased coin flips via ICL, LLMs update their priors in a Bayesian manner.",
      "authors": [
        "Ritwik Gupta",
        "Rodolfo Corona",
        "Jiaxin Ge",
        "Eric Wang",
        "Dan Klein",
        "Trevor Darrell",
        "David M. Chan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-06T18:59:23+00:00",
          "link": "https://arxiv.org/abs/2503.04722v1",
          "size": "5711kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T07:01:43+00:00",
          "link": "https://arxiv.org/abs/2503.04722v2",
          "size": "768kb",
          "version": "v2"
        }
      ],
      "title": "Enough Coin Flips Can Make LLMs Act Bayesian",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04722",
        "HTML": "https://arxiv.org/html/2503.04722v2",
        "PDF": "https://arxiv.org/pdf/2503.04722"
      },
      "source": "arXiv"
    },
    {
      "id": "2503.04734",
      "abstract": "Food systems are responsible for a third of human-caused greenhouse gas emissions. We investigate what Large Language Models (LLMs) can contribute to reducing the environmental impacts of food production. We define a typology of design and prediction tasks based on the sustainable food literature and collaboration with domain experts, and evaluate six LLMs on four tasks in our typology. For example, for a sustainable protein design task, food science experts estimated that collaboration with an LLM can reduce time spent by 45% on average, compared to 22% for collaboration with another expert human food scientist. However, for a sustainable menu design task, LLMs produce suboptimal solutions when instructed to consider both human satisfaction and climate impacts. We propose a general framework for integrating LLMs with combinatorial optimization to improve reasoning capabilities. Our approach decreases emissions of food choices by 79% in a hypothetical restaurant while maintaining participants' satisfaction with their set of choices. Our results demonstrate LLMs' potential, supported by optimization techniques, to accelerate sustainable food development and adoption.",
      "authors": [
        "Anna T. Thomas",
        "Adam Yee",
        "Andrew Mayne",
        "Maya B. Mathur",
        "Dan Jurafsky",
        "Kristina Gligori\\'c"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-02T18:12:16+00:00",
          "link": "https://arxiv.org/abs/2503.04734v1",
          "size": "616kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T18:05:20+00:00",
          "link": "https://arxiv.org/abs/2503.04734v2",
          "size": "171kb",
          "version": "v2"
        }
      ],
      "title": "What can large language models do for sustainable food?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04734",
        "HTML": "https://arxiv.org/html/2503.04734v2",
        "PDF": "https://arxiv.org/pdf/2503.04734"
      },
      "source": "arXiv"
    },
    {
      "id": "2503.04759",
      "abstract": "This paper investigates Nash equilibria (NEs) in multi-player turn-based games on graphs, where player preferences are modeled as $\\omega$-automatic relations via deterministic parity automata. Unlike much of the existing literature, which focuses on specific reward functions, our results apply to any preference relation definable by an $\\omega$-automatic relation. We analyze the computational complexity of determining the existence of an NE (possibly under some constraints), verifying whether a given strategy profile forms an NE, and checking whether a specific outcome can be realized by an NE. When a (constrained) NE exists, we show that there always exists one with finite-memory strategies. Finally, we explore fundamental properties of $\\omega$-automatic relations and their implications in the existence of equilibria.",
      "authors": [
        "V\\'eronique Bruy\\`ere",
        "Christophe Grandmont and Jean-Fran\\c{c}ois Raskin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-10T13:09:20+00:00",
          "link": "https://arxiv.org/abs/2503.04759v1",
          "size": "149kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T08:36:04+00:00",
          "link": "https://arxiv.org/abs/2503.04759v2",
          "size": "149kb",
          "version": "v2"
        }
      ],
      "title": "Games with $\\omega$-Automatic Preference Relations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.04759",
        "HTML": "https://arxiv.org/html/2503.04759v2",
        "PDF": "https://arxiv.org/pdf/2503.04759"
      },
      "source": "arXiv"
    },
    {
      "id": "2503.05197",
      "abstract": "Point clouds are increasingly important in intelligent applications, but frequent off-chip memory traffic in accelerators causes pipeline stalls and leads to high energy consumption. While conventional line buffer techniques can eliminate off-chip traffic, they cannot be directly applied to point clouds due to their inherent computation patterns. To address this, we introduce two techniques: compulsory splitting and deterministic termination, enabling fully-streaming processing. We further propose StreamGrid, a framework that integrates these techniques and automatically optimizes on-chip buffer sizes. Our evaluation shows StreamGrid reduces on-chip memory by 61.3\\% and energy consumption by 40.5\\% with marginal accuracy loss compared to the baselines without our techniques. Additionally, we achieve 10.0$\\times$ speedup and 3.9$\\times$ energy efficiency over state-of-the-art accelerators.",
      "authors": [
        "Yu Feng",
        "Zheng Liu",
        "Weikai Lin",
        "Zihan Liu",
        "Jingwen Leng",
        "Minyi Guo",
        "Zhezhi He",
        "Jieru Zhao",
        "Yuhao Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-07T07:39:17+00:00",
          "link": "https://arxiv.org/abs/2503.05197v1",
          "size": "3026kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T02:44:21+00:00",
          "link": "https://arxiv.org/abs/2503.05197v2",
          "size": "2855kb",
          "version": "v2"
        }
      ],
      "title": "StreamGrid: Streaming Point Cloud Analytics via Compulsory Splitting and Deterministic Termination",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05197",
        "HTML": "https://arxiv.org/html/2503.05197v2",
        "PDF": "https://arxiv.org/pdf/2503.05197"
      },
      "source": "arXiv"
    },
    {
      "id": "2503.05429",
      "abstract": "Cross-Technology Interference (CTI) poses challenges for the performance and robustness of wireless networks. There are opportunities for better cooperation if the spectral occupation and technology of the interference can be detected. Namely, this information can help the Orthogonal Frequency Division Multiple Access (OFDMA) scheduler in IEEE 802.11ax (Wi-Fi 6) to efficiently allocate resources to multiple users inthe frequency domain. This work shows that a single Channel State Information (CSI) snapshot, which is used for packet demodulation in the receiver, is enough to detect and classify the type of CTI on low-cost Wi-Fi 6 hardware. We show the classification accuracy of a small Convolutional Neural Network (CNN) for different Signal-to-Noise Ratio (SNR) and Signal-to-Interference Ratio (SIR) with simulated data, as well as using a wired and over-the-air test with a professional wireless connectivity tester, while running the inference on the low-cost device. Furthermore, we use openwifi, a full-stack Wi-Fi transceiver running on software-defined radio (SDR) available in the w-iLab.t testbed, as Access Point (AP) to implement a CTI-aware multi-user OFDMA scheduler when the clients send CTI detection feedback to the AP. We show experimentally that it can fully mitigate the 35% throughput loss caused by CTI when the AP applies the appropriate scheduling.",
      "authors": [
        "Thijs Havinga",
        "Xianjun Jiao",
        "Wei Liu",
        "Baiheng Chen",
        "Adnan Shahid and Ingrid Moerman"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Signal Processing (eess.SP)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-07T13:58:58+00:00",
          "link": "https://arxiv.org/abs/2503.05429v1",
          "size": "5662kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T08:04:38+00:00",
          "link": "https://arxiv.org/abs/2503.05429v2",
          "size": "5662kb",
          "version": "v2"
        }
      ],
      "title": "Wi-Fi 6 Cross-Technology Interference Detection and Mitigation by OFDMA: an Experimental Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05429",
        "HTML": "https://arxiv.org/html/2503.05429v2",
        "PDF": "https://arxiv.org/pdf/2503.05429"
      },
      "source": "arXiv"
    },
    {
      "id": "2503.06132",
      "abstract": "Recent studies have highlighted the interplay between diffusion models and representation learning. Intermediate representations from diffusion models can be leveraged for downstream visual tasks, while self-supervised vision models can enhance the convergence and generation quality of diffusion models. However, transferring pretrained weights from vision models to diffusion models is challenging due to input mismatches and the use of latent spaces. To address these challenges, we propose Unified Self-supervised Pretraining (USP), a framework that initializes diffusion models via masked latent modeling in a Variational Autoencoder (VAE) latent space. USP achieves comparable performance in understanding tasks while significantly improving the convergence speed and generation quality of diffusion models. Our code will be publicly available at https://github.com/AMAP-ML/USP.",
      "authors": [
        "Xiangxiang Chu and Renda Li and Yong Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-08T09:01:03+00:00",
          "link": "https://arxiv.org/abs/2503.06132v1",
          "size": "2635kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T10:41:53+00:00",
          "link": "https://arxiv.org/abs/2503.06132v2",
          "size": "12937kb",
          "version": "v2"
        }
      ],
      "title": "USP: Unified Self-Supervised Pretraining for Image Generation and Understanding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.06132",
        "HTML": "https://arxiv.org/html/2503.06132v2",
        "PDF": "https://arxiv.org/pdf/2503.06132"
      },
      "tasks": [
        "Image Generation",
        "Representation Learning"
      ],
      "repo_urls": [
        "https://github.com/cxxgtxy/usp"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.06520",
      "abstract": "Traditional methods for reasoning segmentation rely on supervised fine-tuning with categorical labels and simple descriptions, limiting its out-of-domain generalization and lacking explicit reasoning processes. To address these limitations, we propose Seg-Zero, a novel framework that demonstrates remarkable generalizability and derives explicit chain-of-thought reasoning through cognitive reinforcement. Seg-Zero introduces a decoupled architecture consisting of a reasoning model and a segmentation model. The reasoning model interprets user intentions, generates explicit reasoning chains, and produces positional prompts, which are subsequently used by the segmentation model to generate precious pixel-level masks. We design a sophisticated reward mechanism that integrates both format and accuracy rewards to effectively guide optimization directions. Trained exclusively via reinforcement learning with GRPO and without explicit reasoning data, Seg-Zero achieves robust zero-shot generalization and exhibits emergent test-time reasoning capabilities. Experiments show that Seg-Zero-7B achieves a zero-shot performance of 57.5 on the ReasonSeg benchmark, surpassing the prior LISA-7B by 18\\%. This significant improvement highlights Seg-Zero's ability to generalize across domains while presenting an explicit reasoning process. Code is available at https://github.com/dvlab-research/Seg-Zero.",
      "authors": [
        "Yuqi Liu",
        "Bohao Peng",
        "Zhisheng Zhong",
        "Zihao Yue",
        "Fanbin Lu",
        "Bei Yu",
        "Jiaya Jia"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-09T08:48:51+00:00",
          "link": "https://arxiv.org/abs/2503.06520v1",
          "size": "3538kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T11:01:08+00:00",
          "link": "https://arxiv.org/abs/2503.06520v2",
          "size": "3415kb",
          "version": "v2"
        }
      ],
      "title": "Seg-Zero: Reasoning-Chain Guided Segmentation via Cognitive Reinforcement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.06520",
        "HTML": "https://arxiv.org/html/2503.06520v2",
        "PDF": "https://arxiv.org/pdf/2503.06520"
      },
      "models": [
        {
          "model_path": "Ricky06662/Seg-Zero-7B",
          "downloads": "2642",
          "likes": "2",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Ricky06662/Seg-Zero-7B"
        },
        {
          "model_path": "Ricky06662/Seg-Zero-7B-Best-on-ReasonSegTest",
          "downloads": "2189",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Ricky06662/Seg-Zero-7B-Best-on-ReasonSegTest"
        }
      ],
      "datasets": [
        {
          "dataset_name": "Ricky06662/refCOCOg_2k_840",
          "downloads": "373",
          "likes": "2",
          "link": "https://huggingface.co/datasets/Ricky06662/refCOCOg_2k_840"
        },
        {
          "dataset_name": "Yuting6/ttrl",
          "downloads": "264",
          "likes": "0",
          "link": "https://huggingface.co/datasets/Yuting6/ttrl"
        }
      ],
      "tasks": [
        "Domain Generalization",
        "Object Detection",
        "Open Vocabulary Object Detection",
        "Open Vocabulary Semantic Segmentation",
        "Reasoning Segmentation",
        "Referring Expression Segmentation",
        "Segmentation",
        "Zero-shot Generalization",
        "Zero Shot Segmentation"
      ],
      "repo_urls": [
        "https://github.com/hiyouga/easyr1",
        "https://github.com/dvlab-research/Seg-Zero",
        "https://github.com/dvlab-research/VisionReasoner"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.06671",
      "abstract": "In this paper, we tackle the high computational overhead of Transformers for efficient image super-resolution~(SR). Motivated by the observations of self-attention's inter-layer repetition, we introduce a convolutionized self-attention module named Convolutional Attention~(ConvAttn) that emulates self-attention's long-range modeling capability and instance-dependent weighting with a single shared large kernel and dynamic kernels. By utilizing the ConvAttn module, we significantly reduce the reliance on self-attention and its involved memory-bound operations while maintaining the representational capability of Transformers. Furthermore, we overcome the challenge of integrating flash attention into the lightweight SR regime, effectively mitigating self-attention's inherent memory bottleneck. We scale up the window size to 32$\\times$32 with flash attention rather than proposing an intricate self-attention module, significantly improving PSNR by 0.31dB on Urban100$\\times$2 while reducing latency and memory usage by 16$\\times$ and 12.2$\\times$. Building on these approaches, our proposed network, termed Emulating Self-attention with Convolution~(ESC), notably improves PSNR by 0.27 dB on Urban100$\\times$4 compared to HiT-SRF, reducing the latency and memory usage by 3.7$\\times$ and 6.2$\\times$, respectively. Extensive experiments demonstrate that our ESC maintains the ability for long-range modeling, data scalability, and the representational power of Transformers despite most self-attention being replaced by the ConvAttn module.",
      "authors": [
        "Dongheon Lee and Seokju Yun and Youngmin Ro"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-09T15:45:53+00:00",
          "link": "https://arxiv.org/abs/2503.06671v1",
          "size": "19437kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T07:49:21+00:00",
          "link": "https://arxiv.org/abs/2503.06671v2",
          "size": "7225kb",
          "version": "v2"
        }
      ],
      "title": "Emulating Self-attention with Convolution for Efficient Image Super-Resolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.06671",
        "HTML": "https://arxiv.org/html/2503.06671v2",
        "PDF": "https://arxiv.org/pdf/2503.06671"
      },
      "tasks": [
        "Computational Efficiency",
        "Image Super-Resolution",
        "Long-range modeling",
        "Super-Resolution"
      ],
      "repo_urls": [
        "https://github.com/dslisleedh/ESC"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.07417",
      "abstract": "Low-light enhancement has wide applications in autonomous driving, 3D reconstruction, remote sensing, surveillance, and so on, which can significantly improve information utilization. However, most existing methods lack generalization and are limited to specific tasks such as image recovery. To address these issues, we propose Gated-Mechanism Mixture-of-Experts (GM-MoE), the first framework to introduce a mixture-of-experts network for low-light image enhancement. GM-MoE comprises a dynamic gated weight conditioning network and three sub-expert networks, each specializing in a distinct enhancement task. Combining a self-designed gated mechanism that dynamically adjusts the weights of the sub-expert networks for different data domains. Additionally, we integrate local and global feature fusion within sub-expert networks to enhance image quality by capturing multi-scale features. Experimental results demonstrate that the GM-MoE achieves superior generalization with respect to 25 compared approaches, reaching state-of-the-art performance on PSNR on 5 benchmarks and SSIM on 4 benchmarks, respectively.",
      "authors": [
        "Minwen Liao",
        "Hao Bo Dong",
        "Xinyi Wang",
        "Kurban Ubul",
        "Ziyang Yan",
        "Yihua Shao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-10T15:05:50+00:00",
          "link": "https://arxiv.org/abs/2503.07417v1",
          "size": "20030kb",
          "version": "v1"
        },
        {
          "date": "2025-03-26T05:34:56+00:00",
          "link": "https://arxiv.org/abs/2503.07417v2",
          "size": "20030kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T10:49:59+00:00",
          "link": "https://arxiv.org/abs/2503.07417v3",
          "size": "17984kb",
          "version": "v3"
        }
      ],
      "title": "GM-MoE: Low-Light Enhancement with Gated-Mechanism Mixture-of-Experts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.07417",
        "HTML": "https://arxiv.org/html/2503.07417v3",
        "PDF": "https://arxiv.org/pdf/2503.07417"
      },
      "tasks": [
        "3D Reconstruction",
        "Autonomous Driving",
        "Image Enhancement",
        "Low-Light Image Enhancement",
        "Mixture-of-Experts",
        "SSIM"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.07503",
      "abstract": "Reasoning segmentation is a challenging vision-language task that aims to output the segmentation mask with respect to a complex, implicit, and even non-visual query text. Previous works incorporated multimodal Large Language Models (MLLMs) with segmentation models to approach the difficult problem. However, their segmentation quality often falls short in complex cases, particularly when dealing with out-of-domain objects with intricate structures, blurry boundaries, occlusions, or high similarity with surroundings. In this paper, we introduce ThinkFirst, a training-free reasoning segmentation framework that leverages GPT's chain of thought to address these challenging cases. Our approach allows GPT-4o or other powerful MLLMs to generate a detailed, chain-of-thought description of an image. This summarized description is then passed to a language-instructed segmentation assistant to aid the segmentation process. Our framework allows users to easily interact with the segmentation agent using multimodal inputs, such as easy text and image scribbles, for successive refinement or communication. We evaluate the performance of ThinkFirst on diverse objects. Extensive experiments show that, this zero-shot-CoT approach significantly improves the vanilla reasoning segmentation agent, both qualitatively and quantitatively, while being less sensitive or critical to user-supplied prompts after Thinking First.",
      "authors": [
        "Shiu-hong Kao",
        "Yu-Wing Tai",
        "Chi-Keung Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-10T16:26:11+00:00",
          "link": "https://arxiv.org/abs/2503.07503v1",
          "size": "5757kb",
          "version": "v1"
        },
        {
          "date": "2025-03-13T20:45:02+00:00",
          "link": "https://arxiv.org/abs/2503.07503v2",
          "size": "5757kb",
          "version": "v2"
        },
        {
          "date": "2025-03-25T07:05:14+00:00",
          "link": "https://arxiv.org/abs/2503.07503v3",
          "size": "5846kb",
          "version": "v3"
        },
        {
          "date": "2025-06-28T21:31:26+00:00",
          "link": "https://arxiv.org/abs/2503.07503v4",
          "size": "4580kb",
          "version": "v4"
        }
      ],
      "title": "Think Before You Segment: High-Quality Reasoning Segmentation with GPT Chain of Thoughts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.07503",
        "HTML": "https://arxiv.org/html/2503.07503v4",
        "PDF": "https://arxiv.org/pdf/2503.07503"
      },
      "tasks": [
        "Reasoning Segmentation",
        "Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.07661",
      "abstract": "Model merging is a technique that combines multiple finetuned models into a single model without additional training, allowing a free-rider to cheaply inherit specialized capabilities. This study investigates methodologies to suppress unwanted model merging by free-riders. Existing methods such as model watermarking or fingerprinting can only detect merging in hindsight. In contrast, we propose a first proactive defense against model merging. Specifically, our defense method modifies the model parameters so that the model is disrupted if the model is merged with any other model, while its functionality is kept unchanged if not merged with others. Our approach consists of two modules, rearranging MLP parameters and scaling attention heads, which push the model out of the shared basin in parameter space, causing the merging performance with other models to degrade significantly. We conduct extensive experiments on image classification, image generation, and text classification to demonstrate that our defense severely disrupts merging while retaining the functionality of the post-protect model. Moreover, we analyze potential adaptive attacks and further propose a dropout-based pruning to improve our proposal's robustness.",
      "authors": [
        "Wei Junhao",
        "Yu Zhe",
        "Sakuma Jun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-08T06:08:47+00:00",
          "link": "https://arxiv.org/abs/2503.07661v1",
          "size": "7626kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T12:59:43+00:00",
          "link": "https://arxiv.org/abs/2503.07661v2",
          "size": "7561kb",
          "version": "v2"
        }
      ],
      "title": "Disrupting Model Merging: A Parameter-Level Defense Without Sacrificing Accuracy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.07661",
        "HTML": "https://arxiv.org/html/2503.07661v2",
        "PDF": "https://arxiv.org/pdf/2503.07661"
      },
      "tasks": [
        "image-classification",
        "Image Classification",
        "Image Generation",
        "text-classification",
        "Text Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.08101",
      "abstract": "Query-based methods with dense features have demonstrated remarkable success in 3D object detection tasks. However, the computational demands of these models, particularly with large image sizes and multiple transformer layers, pose significant challenges for efficient running on edge devices. Existing pruning and distillation methods either need retraining or are designed for ViT models, which are hard to migrate to 3D detectors. To address this issue, we propose a zero-shot runtime pruning method for transformer decoders in 3D object detection models. The method, termed tgGBC (trim keys gradually Guided By Classification scores), systematically trims keys in transformer modules based on their importance. We expand the classification score to multiply it with the attention map to get the importance score of each key and then prune certain keys after each transformer layer according to their importance scores. Our method achieves a 1.99x speedup in the transformer decoder of the latest ToC3D model, with only a minimal performance loss of less than 1%. Interestingly, for certain models, our method even enhances their performance. Moreover, we deploy 3D detectors with tgGBC on an edge device, further validating the effectiveness of our method. The code can be found at https://github.com/iseri27/tg_gbc.",
      "authors": [
        "Lizhen Xu",
        "Xiuxiu Bai",
        "Xiaojun Jia",
        "Jianwu Fang",
        "Shanmin Pang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T07:03:28+00:00",
          "link": "https://arxiv.org/abs/2503.08101v1",
          "size": "12561kb",
          "version": "v1"
        },
        {
          "date": "2025-03-12T04:03:24+00:00",
          "link": "https://arxiv.org/abs/2503.08101v2",
          "size": "6268kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T08:23:00+00:00",
          "link": "https://arxiv.org/abs/2503.08101v3",
          "size": "2123kb",
          "version": "v3"
        }
      ],
      "title": "Accelerate 3D Object Detection Models via Zero-Shot Attention Key Pruning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08101",
        "HTML": "https://arxiv.org/html/2503.08101v3",
        "PDF": "https://arxiv.org/pdf/2503.08101"
      },
      "tasks": [
        "3D Object Detection",
        "object-detection",
        "Object Detection"
      ],
      "repo_urls": [
        "https://github.com/iseri27/tg_gbc"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.08858",
      "abstract": "To navigate crowds without collisions, robots must interact with humans by forecasting their future motion and reacting accordingly. While learning-based prediction models have shown success in generating likely human trajectory predictions, integrating these stochastic models into a robot controller presents several challenges. The controller needs to account for interactive coupling between planned robot motion and human predictions while ensuring both predictions and robot actions are safe (i.e. collision-free). To address these challenges, we present a receding horizon crowd navigation method for single-robot multi-human environments. We first propose a diffusion model to generate joint trajectory predictions for all humans in the scene. We then incorporate these multi-modal predictions into a SICNav Bilevel MPC problem that simultaneously solves for a robot plan (upper-level) and acts as a safety filter to refine the predictions for non-collision (lower-level). Combining planning and prediction refinement into one bilevel problem ensures that the robot plan and human predictions are coupled. We validate the open-loop trajectory prediction performance of our diffusion model on the commonly used ETH/UCY benchmark and evaluate the closed-loop performance of our robot navigation method in simulation and extensive real-robot experiments demonstrating safe, efficient, and reactive robot motion.",
      "authors": [
        "Sepehr Samavi",
        "Anthony Lem",
        "Fumiaki Sato",
        "Sirui Chen",
        "Qiao Gu",
        "Keijiro Yano",
        "Angela P. Schoellig",
        "Florian Shkurti"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T19:54:50+00:00",
          "link": "https://arxiv.org/abs/2503.08858v1",
          "size": "7728kb",
          "version": "v1"
        },
        {
          "date": "2025-05-12T14:45:28+00:00",
          "link": "https://arxiv.org/abs/2503.08858v2",
          "size": "8413kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T16:22:14+00:00",
          "link": "https://arxiv.org/abs/2503.08858v3",
          "size": "1895kb",
          "version": "v3"
        }
      ],
      "title": "SICNav-Diffusion: Safe and Interactive Crowd Navigation with Diffusion Trajectory Predictions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08858",
        "HTML": "https://arxiv.org/html/2503.08858v3",
        "PDF": "https://arxiv.org/pdf/2503.08858"
      },
      "source": "arXiv"
    },
    {
      "id": "2503.08883",
      "abstract": "Stackelberg games, widely applied in domains like economics and security, involve asymmetric interactions where a leader's strategy drives follower responses. Accurately modeling these dynamics allows domain experts to optimize strategies in interactive scenarios, such as turn-based sports like badminton. In multi-agent systems, agent behaviors are interdependent, and traditional Multi-Agent Imitation Learning (MAIL) methods often fail to capture these complex interactions. Correlated policies, which account for opponents' strategies, are essential for accurately modeling such dynamics. However, even methods designed for learning correlated policies, like CoDAIL, struggle in Stackelberg games due to their asymmetric decision-making, where leaders and followers cannot simultaneously account for each other's actions, often leading to non-correlated policies. Furthermore, existing MAIL methods that match occupancy measures or use adversarial techniques like GAIL or Inverse RL face scalability challenges, particularly in high-dimensional environments, and suffer from unstable training. To address these challenges, we propose a correlated policy occupancy measure specifically designed for Stackelberg games and introduce the Latent Stackelberg Differential Network (LSDN) to match it. LSDN models two-agent interactions as shared latent state trajectories and uses multi-output Geometric Brownian Motion (MO-GBM) to effectively capture joint policies. By leveraging MO-GBM, LSDN disentangles environmental influences from agent-driven transitions in latent space, enabling the simultaneous learning of interdependent policies. This design eliminates the need for adversarial training and simplifies the learning process. Extensive experiments on Iterative Matrix Games and multi-agent particle environments demonstrate that LSDN can better reproduce complex interaction dynamics than existing MAIL methods.",
      "authors": [
        "Kuang-Da Wang",
        "Ping-Chun Hsieh",
        "Wen-Chih Peng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T20:52:56+00:00",
          "link": "https://arxiv.org/abs/2503.08883v1",
          "size": "1135kb",
          "version": "v1"
        },
        {
          "date": "2025-03-16T17:42:42+00:00",
          "link": "https://arxiv.org/abs/2503.08883v2",
          "size": "1135kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T07:26:06+00:00",
          "link": "https://arxiv.org/abs/2503.08883v3",
          "size": "0kb",
          "version": "v3"
        }
      ],
      "title": "Imitation Learning of Correlated Policies in Stackelberg Games",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.08883",
        "PDF": "https://arxiv.org/pdf/2503.08883"
      },
      "tasks": [
        "Imitation Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.09185",
      "abstract": "Incomplete multi-view clustering (IMVC) has garnered increasing attention in recent years due to the common issue of missing data in multi-view datasets. The primary approach to address this challenge involves recovering the missing views before applying conventional multi-view clustering methods. Although imputation-based IMVC methods have achieved significant improvements, they still encounter notable limitations: 1) heavy reliance on paired data for training the data recovery module, which is impractical in real scenarios with high missing data rates; 2) the generated data often lacks diversity and discriminability, resulting in suboptimal clustering results. To address these shortcomings, we propose a novel IMVC method called Diffusion Contrastive Generation (DCG). Motivated by the consistency between the diffusion and clustering processes, DCG learns the distribution characteristics to enhance clustering by applying forward diffusion and reverse denoising processes to intra-view data. By performing contrastive learning on a limited set of paired multi-view samples, DCG can align the generated views with the real views, facilitating accurate recovery of views across arbitrary missing view scenarios. Additionally, DCG integrates instance-level and category-level interactive learning to exploit the consistent and complementary information available in multi-view data, achieving robust and end-to-end clustering. Extensive experiments demonstrate that our method outperforms state-of-the-art approaches. The code is available at https://github.com/zhangyuanyang21/2025-AAAI-DCG.",
      "authors": [
        "Yuanyang Zhang",
        "Yijie Lin",
        "Weiqing Yan",
        "Li Yao",
        "Xinhang Wan",
        "Guangyuan Li",
        "Chao Zhang",
        "Guanzhou Ke",
        "Jie Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-12T09:27:25+00:00",
          "link": "https://arxiv.org/abs/2503.09185v1",
          "size": "846kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T05:58:32+00:00",
          "link": "https://arxiv.org/abs/2503.09185v2",
          "size": "846kb",
          "version": "v2"
        }
      ],
      "title": "Incomplete Multi-view Clustering via Diffusion Contrastive Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.09185",
        "HTML": "https://arxiv.org/html/2503.09185v2",
        "PDF": "https://arxiv.org/pdf/2503.09185"
      },
      "tasks": [
        "Clustering",
        "Contrastive Learning",
        "Denoising",
        "Imputation",
        "Incomplete multi-view clustering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.10135",
      "abstract": "Speculative decoding (SPD) aims to accelerate the auto-regressive token generation process of a target Large Language Model (LLM). Some approaches employ a draft model with multiple heads to predict a sequence of future tokens, where each head handles a token in the sequence. The target LLM verifies the predicted sequence and accepts aligned tokens, enabling efficient multi-token generation. However, existing methods assume that all tokens within a sequence are equally important, employing identical head structures and relying on a single-generation paradigm, either serial or parallel. To this end, we theoretically demonstrate that initial tokens in the draft sequence are more important than later ones. Building on this insight, we propose Gumiho, a hybrid model combining serial and parallel heads. Specifically, given the critical importance of early tokens, we employ a sophisticated Transformer architecture for the early draft heads in a serial configuration to improve accuracy. For later tokens, we utilize multiple lightweight MLP heads operating in parallel to enhance efficiency. By allocating more advanced model structures and longer running times to the early heads, Gumiho achieves improved overall performance. The experimental results demonstrate that our method outperforms existing approaches, fully validating its effectiveness.",
      "authors": [
        "Jinze Li",
        "Yixing Xu",
        "Haiduo Huang",
        "Xuanwu Yin",
        "Dong Li",
        "Edith C.H. Ngai",
        "Emad Barsoum"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-13T07:55:38+00:00",
          "link": "https://arxiv.org/abs/2503.10135v1",
          "size": "1971kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T04:51:00+00:00",
          "link": "https://arxiv.org/abs/2503.10135v2",
          "size": "1971kb",
          "version": "v2"
        }
      ],
      "title": "Gumiho: A Hybrid Architecture to Prioritize Early Tokens in Speculative Decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.10135",
        "HTML": "https://arxiv.org/html/2503.10135v2",
        "PDF": "https://arxiv.org/pdf/2503.10135"
      },
      "tasks": [
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.10995",
      "abstract": "The development of Large Language Models (LLMs) remains heavily skewed towards English and a few other high-resource languages. This linguistic disparity is particularly evident for Bangla - the 5th most spoken language. A few initiatives attempted to create open-source Bangla LLMs with performance still behind high-resource languages and limited reproducibility. To address this gap, we introduce TigerLLM - a family of Bangla LLMs. Our results demonstrate that these models surpass all open-source alternatives and also outperform larger proprietary models like GPT3.5 across standard benchmarks, establishing TigerLLM as the new baseline for future Bangla language modeling.",
      "authors": [
        "Nishat Raihan",
        "Marcos Zampieri"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-14T01:41:16+00:00",
          "link": "https://arxiv.org/abs/2503.10995v1",
          "size": "1085kb",
          "version": "v1"
        },
        {
          "date": "2025-05-16T06:08:08+00:00",
          "link": "https://arxiv.org/abs/2503.10995v2",
          "size": "1085kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T18:00:53+00:00",
          "link": "https://arxiv.org/abs/2503.10995v3",
          "size": "845kb",
          "version": "v3"
        }
      ],
      "title": "TigerLLM -- A Family of Bangla Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.10995",
        "HTML": "https://arxiv.org/html/2503.10995v3",
        "PDF": "https://arxiv.org/pdf/2503.10995"
      },
      "datasets": [
        {
          "dataset_name": "md-nishat-008/Bangla-Instruct",
          "downloads": "17",
          "likes": "0",
          "link": "https://huggingface.co/datasets/md-nishat-008/Bangla-Instruct"
        },
        {
          "dataset_name": "md-nishat-008/Bangla-TextBook",
          "downloads": "61",
          "likes": "0",
          "link": "https://huggingface.co/datasets/md-nishat-008/Bangla-TextBook"
        }
      ],
      "tasks": [
        "Language Modeling",
        "Language Modelling"
      ],
      "repo_urls": [
        "https://github.com/mraihan-gmu/TigerLLM"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.11167",
      "abstract": "Decoding visual stimuli from neural activity is essential for understanding the human brain. While fMRI methods have successfully reconstructed static images, fMRI-to-video reconstruction faces challenges due to the need for capturing spatiotemporal dynamics like motion and scene transitions. Recent approaches have improved semantic and perceptual alignment but struggle to integrate coarse fMRI data with detailed visual features. Inspired by the hierarchical organization of the visual system, we propose NEURONS, a novel framework that decouples learning into four correlated sub-tasks: key object segmentation, concept recognition, scene description, and blurry video reconstruction. This approach simulates the visual cortex's functional specialization, allowing the model to capture diverse video content. In the inference stage, NEURONS generates robust conditioning signals for a pre-trained text-to-video diffusion model to reconstruct the videos. Extensive experiments demonstrate that NEURONS outperforms state-of-the-art baselines, achieving solid improvements in video consistency (26.6%) and semantic-level accuracy (19.1%). Notably, NEURONS shows a strong functional correlation with the visual cortex, highlighting its potential for brain-computer interfaces and clinical applications. Code and model weights are available at: https://github.com/xmed-lab/NEURONS.",
      "authors": [
        "Haonan Wang",
        "Qixiang Zhang",
        "Lehan Wang",
        "Xuanqi Huang",
        "Xiaomeng Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-14T08:12:28+00:00",
          "link": "https://arxiv.org/abs/2503.11167v1",
          "size": "9318kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T14:53:40+00:00",
          "link": "https://arxiv.org/abs/2503.11167v2",
          "size": "9324kb",
          "version": "v2"
        }
      ],
      "title": "Neurons: Emulating the Human Visual Cortex Improves Fidelity and Interpretability in fMRI-to-Video Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11167",
        "HTML": "https://arxiv.org/html/2503.11167v2",
        "PDF": "https://arxiv.org/pdf/2503.11167"
      },
      "tasks": [
        "Semantic Segmentation",
        "Video Reconstruction"
      ],
      "repo_urls": [
        "https://github.com/xmed-lab/neurons"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.11655",
      "abstract": "Large language models (LLMs) have transformed sentiment analysis, yet balancing accuracy, efficiency, and explainability remains a critical challenge. This study presents the first comprehensive evaluation of DeepSeek-R1--an open-source reasoning model--against OpenAI's GPT-4o and GPT-4o-mini. We test the full 671B model and its distilled variants, systematically documenting few-shot learning curves. Our experiments show DeepSeek-R1 achieves a 91.39\\% F1 score on 5-class sentiment and 99.31\\% accuracy on binary tasks with just 5 shots, an eightfold improvement in few-shot efficiency over GPT-4o. Architecture-specific distillation effects emerge, where a 32B Qwen2.5-based model outperforms the 70B Llama-based variant by 6.69 percentage points. While its reasoning process reduces throughput, DeepSeek-R1 offers superior explainability via transparent, step-by-step traces, establishing it as a powerful, interpretable open-source alternative.",
      "authors": [
        "Donghao Huang and Zhaoxia Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-03T07:17:46+00:00",
          "link": "https://arxiv.org/abs/2503.11655v1",
          "size": "318kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T12:58:45+00:00",
          "link": "https://arxiv.org/abs/2503.11655v2",
          "size": "222kb",
          "version": "v2"
        }
      ],
      "title": "Explainable Sentiment Analysis with DeepSeek-R1: Performance, Efficiency, and Few-Shot Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11655",
        "PDF": "https://arxiv.org/pdf/2503.11655"
      },
      "source": "arXiv"
    },
    {
      "id": "2503.11901",
      "abstract": "This study characterizes GPU resilience in Delta HPC, a large-scale AI system that consists of 1,056 A100 and H100 GPUs, with over 1,300 petaflops of peak throughput. Delta HPC is operated by the National Center for Supercomputing Applications (NCSA) at the University of Illinois Urbana-Champaign. We used 2.5 years of operational data (11.7 million GPU hours) on GPU errors. Our major findings include: (i) H100 GPU memory resilience is worse than A100 GPU memory, with 3.2x lower per-GPU MTBE for memory errors, (ii) The GPU memory error-recovery mechanisms on H100 GPUs are insufficient to handle the increased memory capacity, (iii) H100 GPUs demonstrate significantly improved GPU hardware resilience over A100 GPUs with respect to critical hardware components, (iv) GPU errors on both A100 and H100 GPUs frequently result in job failures due to the lack of robust recovery mechanisms at the application level, and (v) We project the impact of GPU node availability on larger-scales and find that significant overprovisioning of 5% is necessary to handle GPU failures.",
      "authors": [
        "Shengkun Cui",
        "Archit Patke",
        "Hung Nguyen",
        "Aditya Ranjan",
        "Ziheng Chen",
        "Phuong Cao",
        "Brett Bode",
        "Gregory Bauer",
        "Catello Di Martino",
        "Saurabh Jha",
        "Chandra Narayanaswami",
        "Daby Sow",
        "Zbigniew T. Kalbarczyk and Ravishankar K. Iyer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-14T22:14:18+00:00",
          "link": "https://arxiv.org/abs/2503.11901v1",
          "size": "846kb",
          "version": "v1"
        },
        {
          "date": "2025-03-24T03:52:43+00:00",
          "link": "https://arxiv.org/abs/2503.11901v2",
          "size": "846kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T06:07:45+00:00",
          "link": "https://arxiv.org/abs/2503.11901v3",
          "size": "979kb",
          "version": "v3"
        }
      ],
      "title": "Characterizing GPU Resilience and Impact on AI/HPC Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11901",
        "HTML": "https://arxiv.org/html/2503.11901v3",
        "PDF": "https://arxiv.org/pdf/2503.11901"
      },
      "tasks": [
        "Attribute"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.11950",
      "abstract": "The increasing integration of Artificial Intelligence (AI) in digital ecosystems has reshaped privacy dynamics, particularly for young digital citizens navigating data-driven environments. This study explores evolving privacy concerns across three key stakeholder groups, digital citizens (ages 16-19), parents/educators, and AI professionals, and assesses differences in data ownership, trust, transparency, parental mediation, education, and risk-benefit perceptions. Employing a grounded theory methodology, this research synthesizes insights from 482 participants through structured surveys, qualitative interviews, and focus groups. The findings reveal distinct privacy expectations: Young users emphasize autonomy and digital freedom, while parents and educators advocate for regulatory oversight and AI literacy programs. AI professionals, in contrast, prioritize the balance between ethical system design and technological efficiency. The data further highlights gaps in AI literacy and transparency, emphasizing the need for comprehensive, stakeholder-driven privacy frameworks that accommodate diverse user needs. Using comparative thematic analysis, this study identifies key tensions in privacy governance and develops the novel Privacy-Ethics Alignment in AI (PEA-AI) model, which structures privacy decision-making as a dynamic negotiation between stakeholders. By systematically analyzing themes such as transparency, user control, risk perception, and parental mediation, this research provides a scalable, adaptive foundation for AI governance, ensuring that privacy protections evolve alongside emerging AI technologies and youth-centric digital interactions.",
      "authors": [
        "Ankur Barthwal",
        "Molly Campbell",
        "and Ajay Kumar Shrestha"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-15T01:42:45+00:00",
          "link": "https://arxiv.org/abs/2503.11950v1",
          "size": "645kb",
          "version": "v1"
        },
        {
          "date": "2025-03-21T00:54:33+00:00",
          "link": "https://arxiv.org/abs/2503.11950v2",
          "size": "633kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T18:32:48+00:00",
          "link": "https://arxiv.org/abs/2503.11950v3",
          "size": "736kb",
          "version": "v3"
        }
      ],
      "title": "Privacy Ethics Alignment in AI: A Stakeholder-Centric Framework for Ethical AI",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.11950",
        "PDF": "https://arxiv.org/pdf/2503.11950"
      },
      "tasks": [
        "Ethics"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.13377",
      "abstract": "Temporal Video Grounding (TVG), the task of locating specific video segments based on language queries, is a core challenge in long-form video understanding. While recent Large Vision-Language Models (LVLMs) have shown early promise in tackling TVG through supervised fine-tuning (SFT), their abilities to generalize remain limited. To address this, we propose a novel post-training framework that enhances the generalization capabilities of LVLMs via reinforcement learning (RL). Specifically, our contributions span three key directions: (1) Time-R1: we introduce a reasoning-guided post-training framework via RL with verifiable reward to enhance the capabilities of LVLMs on the TVG task. (2) TimeRFT: we explore data-efficient post-training strategies on our curated RL-friendly dataset, which trains the model to progressively comprehend difficult samples, leading to better generalization. (3) TVGBench: we carefully construct a small yet comprehensive benchmark for LVLM evaluation, assessing 11 types of queries and featuring balanced distributions across both videos and queries. Extensive experiments demonstrate that Time-R1 achieves state-of-the-art performance across multiple downstream datasets using only 2.5K training data, while improving its general video understanding capabilities.",
      "authors": [
        "Ye Wang",
        "Ziheng Wang",
        "Boshen Xu",
        "Yang Du",
        "Kejun Lin",
        "Zihan Xiao",
        "Zihao Yue",
        "Jianzhong Ju",
        "Liang Zhang",
        "Dingyi Yang",
        "Xiangnan Fang",
        "Zewen He",
        "Zhenbo Luo",
        "Wenxuan Wang",
        "Junqi Lin",
        "Jian Luan",
        "Qin Jin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-17T17:04:20+00:00",
          "link": "https://arxiv.org/abs/2503.13377v1",
          "size": "353kb",
          "version": "v1"
        },
        {
          "date": "2025-05-26T17:59:02+00:00",
          "link": "https://arxiv.org/abs/2503.13377v2",
          "size": "6077kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T08:11:35+00:00",
          "link": "https://arxiv.org/abs/2503.13377v3",
          "size": "3385kb",
          "version": "v3"
        }
      ],
      "title": "Time-R1: Post-Training Large Vision Language Model for Temporal Video Grounding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.13377",
        "HTML": "https://arxiv.org/html/2503.13377v3",
        "PDF": "https://arxiv.org/pdf/2503.13377"
      },
      "tasks": [
        "Video Grounding"
      ],
      "repo_urls": [
        "https://github.com/www-ye/timezero"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.13883",
      "abstract": "Traffic sign detection is essential for autonomous driving and Advanced Driver Assistance Systems (ADAS). However, existing methods struggle with low-light conditions due to issues like indistinct small-object features, limited feature interaction, and poor image quality, which degrade detection accuracy and speed. To address this issue, we propose YOLO-LLTS, an end-to-end real-time traffic sign detection algorithm specifically designed for low-light environments. YOLO-LLTS introduces three main contributions: the High-Resolution Feature Map for Small Object Detection (HRFM-SOD) module to enhance small-object detection by mitigating feature dilution; the Multi-branch Feature Interaction Attention (MFIA) module to improve information extraction through multi-scale features interaction; and the Prior-Guided Feature Enhancement Module (PGFE) to enhance image quality by addressing noise, low contrast, and blurriness. Additionally, we construct a novel dataset, the Chinese Nighttime Traffic Sign Sample Set (CNTSSS), covering diverse nighttime scenarios. Experiments show that YOLO-LLTS achieves state-of-the-art performance, outperforming previous best methods by 2.7% mAP50 and 1.6% mAP50:95 on TT100K-night, 1.3% mAP50 and 1.9% mAP50:95 on CNTSSS, 7.5% mAP50 and 9.8% mAP50:95 on GTSDB-night, and superior results on CCTSDB2021. Deployment on edge devices confirms its real-time applicability and effectiveness.",
      "authors": [
        "Ziyu Lin",
        "Yunfan Wu",
        "Yuhang Ma",
        "Junzhou Chen",
        "Ronghui Zhang",
        "Jiaming Wu",
        "Guodong Yin",
        "and Liang Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-18T04:28:05+00:00",
          "link": "https://arxiv.org/abs/2503.13883v1",
          "size": "2605kb",
          "version": "v1"
        },
        {
          "date": "2025-03-30T11:16:14+00:00",
          "link": "https://arxiv.org/abs/2503.13883v2",
          "size": "3200kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T16:45:14+00:00",
          "link": "https://arxiv.org/abs/2503.13883v3",
          "size": "4054kb",
          "version": "v3"
        }
      ],
      "title": "YOLO-LLTS: Real-Time Low-Light Traffic Sign Detection via Prior-Guided Enhancement and Multi-Branch Feature Interaction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.13883",
        "HTML": "https://arxiv.org/html/2503.13883v3",
        "PDF": "https://arxiv.org/pdf/2503.13883"
      },
      "tasks": [
        "Small Object Detection",
        "Traffic Sign Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.15170",
      "abstract": "Popularity dynamics in social media depend on a complex interplay of social influence between users and popularity-based recommendations that are provided by the platforms. In this work, we introduce a discrete-time dynamical system to model the evolution of popularity on social media. Our model generalizes the well-known Friedkin-Johnsen model to a set of influencers vying for popularity. We study the asymptotic behavior of this model and illustrate it with numerical examples. Our results highlight the interplay of social influence, past popularity, and content quality in determining the popularity of influencers.",
      "authors": [
        "Gaya Cocca",
        "Paolo Frasca",
        "Chiara Ravazzi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-19T12:54:49+00:00",
          "link": "https://arxiv.org/abs/2503.15170v1",
          "size": "59kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T10:54:08+00:00",
          "link": "https://arxiv.org/abs/2503.15170v2",
          "size": "54kb",
          "version": "v2"
        }
      ],
      "title": "A Coupled Friedkin-Johnsen Model of Popularity Dynamics in Social Media",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15170",
        "HTML": "https://arxiv.org/html/2503.15170v2",
        "PDF": "https://arxiv.org/pdf/2503.15170"
      },
      "source": "arXiv"
    },
    {
      "id": "2503.15426",
      "abstract": "Although Multimodal Large Language Models (MLLMs) excel at various image-related tasks, they encounter challenges in precisely aligning coordinates with spatial information within images, particularly in position-aware tasks such as visual grounding. This limitation arises from two key factors. First, MLLMs lack explicit spatial references, making it difficult to associate textual descriptions with precise image locations. Second, their feature extraction processes prioritize global context over fine-grained spatial details, leading to weak localization capability. To address these issues, we introduce VPP-LLaVA, an MLLM enhanced with Visual Position Prompt (VPP) to improve its grounding capability. VPP-LLaVA integrates two complementary mechanisms: the global VPP overlays a learnable, axis-like tensor onto the input image to provide structured spatial cues, while the local VPP incorporates position-aware queries to support fine-grained localization.To effectively train our model with spatial guidance, we further introduce VPP-SFT, a curated dataset of 0.6M high-quality visual grounding samples. Designed in a compact format, it enables efficient training and is significantly smaller than datasets used by other MLLMs (e.g., ~21M samples in MiniGPT-v2), yet still provides a strong performance boost. The resulting model, VPP-LLaVA, not only achieves state-of-the-art results on standard visual grounding benchmarks but also demonstrates strong zero-shot generalization to challenging unseen datasets. Code and dataset will be released upon acceptance at https://github.com/WayneTomas/VPP-LLaVA.",
      "authors": [
        "Wei Tang",
        "Yanpeng Sun",
        "Qinying Gu",
        "Zechao Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-19T17:08:13+00:00",
          "link": "https://arxiv.org/abs/2503.15426v1",
          "size": "7636kb",
          "version": "v1"
        },
        {
          "date": "2025-03-24T16:34:55+00:00",
          "link": "https://arxiv.org/abs/2503.15426v2",
          "size": "7637kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T08:04:49+00:00",
          "link": "https://arxiv.org/abs/2503.15426v3",
          "size": "14749kb",
          "version": "v3"
        }
      ],
      "title": "Visual Position Prompt for MLLM based Visual Grounding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15426",
        "HTML": "https://arxiv.org/html/2503.15426v3",
        "PDF": "https://arxiv.org/pdf/2503.15426"
      },
      "tasks": [
        "Position",
        "Visual Grounding"
      ],
      "repo_urls": [
        "https://github.com/waynetomas/vpp-llava"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.15758",
      "abstract": "Transformer-based models have emerged as a leading architecture for natural language processing, natural language generation, and image generation tasks. A fundamental element of the transformer architecture is self-attention, which allows the model to capture intricate dependencies within the data. However, the self-attention mechanism also incurs significant computational and memory costs, particularly for long sequences.\n  In this paper, we introduce ATTENTION2D, a novel approach that exploits parallelism along two dimensions - query and key/value - of the self-attention operation. This method enables efficient distribution and parallelization of computations across multiple devices. Our approach facilitates asymptotically faster training and inference phases compared to previous methods, without relying on approximations or incurring additional computational or memory overheads. Furthermore, unlike existing techniques that struggle to scale with an increasing number of processing units, our approach effectively scales with additional processing units.\n  Our experimental results confirm the effectiveness of our method in improving communication efficiency and scalability. Compared to Ring Attention, our approach demonstrated up to a 5x performance boost on a GPT-3-like model using 64 NVIDIA A100 GPUs across 16 nodes, and up to a 9.4x performance boost on 64 NVIDIA H100 GPUs across 64 nodes.",
      "authors": [
        "Venmugil Elango"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-20T00:25:44+00:00",
          "link": "https://arxiv.org/abs/2503.15758v1",
          "size": "302kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T22:35:32+00:00",
          "link": "https://arxiv.org/abs/2503.15758v2",
          "size": "302kb",
          "version": "v2"
        }
      ],
      "title": "ATTENTION2D: Communication Efficient Distributed Self-Attention Mechanism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15758",
        "HTML": "https://arxiv.org/html/2503.15758v2",
        "PDF": "https://arxiv.org/pdf/2503.15758"
      },
      "tasks": [
        "Image Generation",
        "Text Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.16334",
      "abstract": "Recent findings reveal that much of the knowledge in a Transformer-based Large Language Model (LLM) is encoded in its feed-forward (FFN) layers, where each FNN layer can be interpreted as the summation of sub-updates, each corresponding to a weighted column vector from the FFN's value parameter matrix that often encodes human-interpretable concepts. In light of this, we hypothesize that model performance and behaviors can be further enhanced and controlled by modulating the contributions of these sub-updates based on their relevance to the input or target output style, and propose LLMBRACES, a novel and efficient method that computes relevance scores associated with value vectors in FFN layers and leverages these scores to dynamically adjust the contribution of sub-updates. By optimizing sub-update contributions, LLMBRACES refines the prediction process, leading to more accurate and reliable outputs, much like a 'brace' providing support and stability. Moreover, LLMBRACES can be extended to support conditional control over generation characteristics, such as sentiment, thereby offering fine-grained steering of LLM outputs. Extensive experiments on various LLMs-including Qwen2.5-1.5B, Llama2-7B, and Llama3-8B-demonstrate that LLMBRACES outperforms baseline approaches in both fine-tuning and zero-shot settings while requiring significantly fewer tunable parameters, up to 75% fewer compared to LoRA. Furthermore, LLMBRACES excels in sentiment-controlled generation and toxicity reduction, highlighting its potential for flexible, controlled text generation across applications.",
      "authors": [
        "Ying Shen",
        "Lifu Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-20T16:55:26+00:00",
          "link": "https://arxiv.org/abs/2503.16334v1",
          "size": "9437kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T04:21:26+00:00",
          "link": "https://arxiv.org/abs/2503.16334v2",
          "size": "9431kb",
          "version": "v2"
        }
      ],
      "title": "LLM Braces: Straightening Out LLM Predictions with Relevant Sub-Updates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.16334",
        "HTML": "https://arxiv.org/html/2503.16334v2",
        "PDF": "https://arxiv.org/pdf/2503.16334"
      },
      "tasks": [
        "Large Language Model",
        "Text Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.17222",
      "abstract": "Cardiovascular events, such as heart attacks and strokes, remain a leading cause of mortality globally, necessitating meticulous monitoring and adjudication in clinical trials. This process, traditionally performed manually by clinical experts, is time-consuming, resource-intensive, and prone to inter-reviewer variability, potentially introducing bias and hindering trial progress. This study addresses these critical limitations by presenting a novel framework for automating the adjudication of cardiovascular events in clinical trials using Large Language Models (LLMs). We developed a two-stage approach: first, employing an LLM-based pipeline for event information extraction from unstructured clinical data and second, using an LLM-based adjudication process guided by a Tree of Thoughts approach and clinical endpoint committee (CEC) guidelines. Using cardiovascular event-specific clinical trial data, the framework achieved an F1-score of 0.82 for event extraction and an accuracy of 0.68 for adjudication. Furthermore, we introduce the CLEART score, a novel, automated metric specifically designed for evaluating the quality of AI-generated clinical reasoning in adjudicating cardiovascular events. This approach demonstrates significant potential for substantially reducing adjudication time and costs while maintaining high-quality, consistent, and auditable outcomes in clinical trials. The reduced variability and enhanced standardization also allow for faster identification and mitigation of risks associated with cardiovascular therapies.",
      "authors": [
        "Sonish Sivarajkumar",
        "Kimia Ameri",
        "Chuqin Li",
        "Yanshan Wang",
        "and Min Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-21T15:25:53+00:00",
          "link": "https://arxiv.org/abs/2503.17222v1",
          "size": "1091kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T20:51:41+00:00",
          "link": "https://arxiv.org/abs/2503.17222v2",
          "size": "961kb",
          "version": "v2"
        }
      ],
      "title": "Automating Adjudication of Cardiovascular Events Using Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17222",
        "HTML": "https://arxiv.org/html/2503.17222v2",
        "PDF": "https://arxiv.org/pdf/2503.17222"
      },
      "source": "arXiv"
    },
    {
      "id": "2503.17657",
      "abstract": "Diffusion denoising models have become a popular approach for image generation, but they often suffer from slow convergence during training. In this paper, we identify that this slow convergence is partly due to the complexity of the Brownian motion driving the forward-time process. To address this, we represent the Brownian motion using the Karhunen-Lo\\`eve expansion, truncating it to a limited number of eigenfunctions. We propose a novel ordinary differential equation with augmented random initials, termed KL diffusion, as a new forward-time process for training and sampling. By developing an appropriate denoising loss function, we facilitate the integration of our KL-diffusion into existing denoising-based models. Using the widely adopted DDIM framework as our baseline ensures a fair comparison, as our modifications focus solely on the forward process and loss function, leaving the network architecture and sampling methods unchanged. Our method significantly outperforms baseline diffusion models, achieving convergence speeds that are twice faster to reach the best FID score of the baseline and ultimately yielding much lower FID scores. Notably, our approach allows for highly parallelized computation, requires no additional learnable parameters, and can be flexibly integrated into existing diffusion methods. The code will be made publicly available.",
      "authors": [
        "Yumeng Ren",
        "Yaofang Liu",
        "Aitor Artola",
        "Laurent Mertz",
        "Raymond H. Chan",
        "Jean-michel Morel"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-22T05:34:02+00:00",
          "link": "https://arxiv.org/abs/2503.17657v1",
          "size": "2832kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T21:52:16+00:00",
          "link": "https://arxiv.org/abs/2503.17657v2",
          "size": "3481kb",
          "version": "v2"
        }
      ],
      "title": "Efficient Diffusion Training through Parallelization with Truncated Karhunen-Lo\\`eve Expansion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17657",
        "HTML": "https://arxiv.org/html/2503.17657v2",
        "PDF": "https://arxiv.org/pdf/2503.17657"
      },
      "tasks": [
        "Denoising",
        "Image Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.17690",
      "abstract": "Repetitive action counting, which aims to count periodic movements in a video, is valuable for video analysis applications such as fitness monitoring. However, existing methods largely rely on regression networks with limited representational capacity, which hampers their ability to accurately capture variable periodic patterns. Additionally, their supervised learning on narrow, limited training sets leads to overfitting and restricts their ability to generalize across diverse scenarios. To address these challenges, we propose CountLLM, the first large language model (LLM)-based framework that takes video data and periodic text prompts as inputs and outputs the desired counting value. CountLLM leverages the rich clues from explicit textual instructions and the powerful representational capabilities of pre-trained LLMs for repetitive action counting. To effectively guide CountLLM, we develop a periodicity-based structured template for instructions that describes the properties of periodicity and implements a standardized answer format to ensure consistency. Additionally, we propose a progressive multimodal training paradigm to enhance the periodicity-awareness of the LLM. Empirical evaluations on widely recognized benchmarks demonstrate CountLLM's superior performance and generalization, particularly in handling novel and out-of-domain actions that deviate significantly from the training data, offering a promising avenue for repetitive action counting.",
      "authors": [
        "Ziyu Yao",
        "Xuxin Cheng",
        "Zhiqi Huang",
        "Lei Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-22T08:20:31+00:00",
          "link": "https://arxiv.org/abs/2503.17690v1",
          "size": "2856kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T14:56:21+00:00",
          "link": "https://arxiv.org/abs/2503.17690v2",
          "size": "2855kb",
          "version": "v2"
        }
      ],
      "title": "CountLLM: Towards Generalizable Repetitive Action Counting via Large Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17690",
        "HTML": "https://arxiv.org/html/2503.17690v2",
        "PDF": "https://arxiv.org/pdf/2503.17690"
      },
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Yao_CountLLM_Towards_Generalizable_Repetitive_Action_Counting_via_Large_Language_Model_CVPR_2025_paper.html",
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "Repetitive Action Counting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.18001",
      "abstract": "Transparency and interpretability are crucial for enhancing customer confidence and user engagement, especially when dealing with black-box Machine Learning (ML)-based recommendation systems. Modern recommendation systems leverage Graph Neural Network (GNN) due to their ability to produce high-quality recommendations in terms of both relevance and diversity. Therefore, the explainability of GNN is especially important for Link Prediction (LP) tasks since recommending relevant items can be viewed as predicting links between users and items. GNN explainability has been a well-studied field, but existing methods primarily focus on node or graph-level tasks, leaving a gap in LP explanation techniques. This work introduces Z-REx, a GNN explanation framework designed explicitly for heterogeneous link prediction tasks. Z-REx utilizes structural and attribute perturbation to identify critical substructures and important features while reducing the search space by leveraging domain-specific knowledge. In our experimentation, we show the efficacy of Z-REx in generating contextually relevant and human-interpretable explanations for ZiGNN, a GNN-based recommendation engine, using a real-world real-estate dataset from Zillow Group, Inc. We compare against State-of-The-Art (SOTA) GNN explainers to show Z-REx outperforms them by 61% in the Fidelity metric by producing superior human-interpretable explanations.",
      "authors": [
        "Kunal Mukherjee",
        "Zachary Harrison",
        "Saeid Balaneshin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Machine Learning (cs.LG)",
        "Social and Information Networks (cs.SI)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-12T02:42:25+00:00",
          "link": "https://arxiv.org/abs/2503.18001v1",
          "size": "3837kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T16:05:05+00:00",
          "link": "https://arxiv.org/abs/2503.18001v2",
          "size": "958kb",
          "version": "v2"
        }
      ],
      "title": "Z-REx: Human-Interpretable GNN Explanations for Real Estate Recommendations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.18001",
        "HTML": "https://arxiv.org/html/2503.18001v2",
        "PDF": "https://arxiv.org/pdf/2503.18001"
      },
      "tasks": [
        "Attribute",
        "Graph Neural Network",
        "Link Prediction",
        "Recommendation Systems"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.18243",
      "abstract": "Emotion regulation is a crucial skill for managing emotions in everyday life, yet finding a constructive and accessible method to support these processes remains challenging due to their cognitive demands. In this study, we explore how regular interactions with a social robot, conducted in a structured yet familiar environment within university halls and departments, can provide effective support for emotion regulation through cognitive reappraisal. Twenty-one students participated in a five-session study at a university hall or department, where the robot, powered by a large language model (GPT-3.5), facilitated structured conversations, encouraging the students to reinterpret emotionally charged situations they shared with the robot. Quantitative and qualitative results indicate significant improvements in emotion self-regulation, with participants reporting better understanding and control of their emotions. The intervention led to significant changes in constructive emotion regulation tendencies and positive effects on mood and sentiment after each session. The findings also demonstrate that repeated interactions with the robot encouraged greater emotional expressiveness, including longer speech disclosures, increased use of affective language, and heightened facial arousal. Notably, expressiveness followed structured patterns aligned with the reappraisal process, with expression peaking during key reappraisal moments, particularly when participants were prompted to reinterpret negative experiences. The qualitative feedback further highlighted how the robot fostered introspection and provided a supportive space for discussing emotions, enabling participants to confront long-avoided emotional challenges. These findings demonstrate the potential of robots to effectively assist in emotion regulation in familiar environments, offering both emotional support and cognitive guidance.",
      "authors": [
        "Guy Laban",
        "Julie Wang",
        "Hatice Gunes"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-23T23:47:46+00:00",
          "link": "https://arxiv.org/abs/2503.18243v1",
          "size": "17948kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T16:08:56+00:00",
          "link": "https://arxiv.org/abs/2503.18243v2",
          "size": "7703kb",
          "version": "v2"
        }
      ],
      "title": "A Robot-Led Intervention for Emotion Regulation: From Expression to Reappraisal",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.18243",
        "HTML": "https://arxiv.org/html/2503.18243v2",
        "PDF": "https://arxiv.org/pdf/2503.18243"
      },
      "source": "arXiv"
    },
    {
      "id": "2503.18672",
      "abstract": "Class-Continual Learning (CCL) enables models to continuously learn new class knowledge while retaining previous classes, facilitating adaptation and evolution in dynamic, real-world environments. Traditional CCL methods primarily rely on visual features, which limits their effectiveness in complex, multimodal scenarios. In contrast, Vision-Language Models (VLMs) show promising potential for enhancing CCL by leveraging pre-trained knowledge and fusing multi-modal semantic cues such as text and vision. However, existing approaches struggle to mitigate catastrophic forgetting while preserving the generalization strengths of VLMs across diverse modalities. To address these challenges, we propose CalFuse, a framework for feature Calibration enhanced parameter Fusion, which enhances dynamic knowledge fusion. CalFuse introduces a dynamic feature calibration mechanism that iteratively adjusts the contribution of original visual features to the final class decision, thereby preserving the model's intrinsic generalization capability across modalities. Simultaneously, a parameter fusion strategy effectively fuses newly acquired knowledge with prior task parameters, maintaining a balance between acquiring new class representations and preserving old knowledge. Experimental results on popular benchmarks (e.g., CIFAR100 and ImageNet100) validate the superiority of the proposed method.",
      "authors": [
        "Juncen Guo",
        "Yang Liu",
        "Xiaoguang Zhu",
        "Lianlong Sun",
        "Liangyu Teng",
        "Jingyi Wu",
        "Di Li",
        "Linxiao Gong",
        "Weiwei Jiang",
        "Wei Zhou",
        "Liang Song"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-24T13:44:12+00:00",
          "link": "https://arxiv.org/abs/2503.18672v1",
          "size": "1515kb",
          "version": "v1"
        },
        {
          "date": "2025-03-25T10:00:27+00:00",
          "link": "https://arxiv.org/abs/2503.18672v2",
          "size": "1515kb",
          "version": "v2"
        },
        {
          "date": "2025-04-15T13:10:16+00:00",
          "link": "https://arxiv.org/abs/2503.18672v3",
          "size": "4006kb",
          "version": "v3"
        },
        {
          "date": "2025-04-17T12:26:16+00:00",
          "link": "https://arxiv.org/abs/2503.18672v4",
          "size": "2195kb",
          "version": "v4"
        },
        {
          "date": "2025-06-29T16:05:21+00:00",
          "link": "https://arxiv.org/abs/2503.18672v5",
          "size": "2475kb",
          "version": "v5"
        }
      ],
      "title": "CalFuse: Feature Calibration Enhanced Parameter Fusion for Class-Continual Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.18672",
        "HTML": "https://arxiv.org/html/2503.18672v5",
        "PDF": "https://arxiv.org/pdf/2503.18672"
      },
      "tasks": [
        "class-incremental learning",
        "Class Incremental Learning",
        "Incremental Learning",
        "Transfer Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.18984",
      "abstract": "The Semantic Theory of Evolution (STE) takes the existence of a number of arbitrary communication codes as a fundamental feature of life, from the genetic code to human cultural communication codes. Their arbitrariness enables, at each level, the selection of one out of several possible correspondences along with the generation of meaning. STE enables more novelties to emerge and suggests a greater variety of potential life forms.\n  With this paper I ground STE on physical theories of meaningful information. Furthermore, I show that key features of the arbitrary communication codes employed by living organisms can be expressed by means of Evidence Theory (ET).\n  In particular, I adapt ET to organisms that merely react to sequences of stimuli, explain its basics for organisms that are capable of prediction, and illustrate an unconventional version suitable for the most intricate communication codes employed by humans. Finally, I express the natural trend towards ambiguity reduction in terms of information entropy minimization along with thermodynamic entropy maximization.",
      "authors": [
        "Guido Fioretti"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Adaptation and Self-Organizing Systems (nlin.AO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-23T07:31:26+00:00",
          "link": "https://arxiv.org/abs/2503.18984v1",
          "size": "79kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T19:55:06+00:00",
          "link": "https://arxiv.org/abs/2503.18984v2",
          "size": "86kb",
          "version": "v2"
        }
      ],
      "title": "A Physical and Mathematical Framework for the Semantic Theory of Evolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.18984",
        "HTML": "https://arxiv.org/html/2503.18984v2",
        "PDF": "https://arxiv.org/pdf/2503.18984"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.19564",
      "abstract": "As artificial intelligence systems increasingly operate in Real-world environments, the integration of multi-modal data sources such as vision, language, and audio presents both unprecedented opportunities and critical challenges for achieving trustworthy intelligence. In this paper, we propose a novel framework that unifies federated learning with explainable multi-modal reasoning to ensure trustworthiness in decentralized, dynamic settings. Our approach, called FedMM-X (Federated Multi-Modal Explainable Intelligence), leverages cross-modal consistency checks, client-level interpretability mechanisms, and dynamic trust calibration to address challenges posed by data heterogeneity, modality imbalance, and out-of-distribution generalization. Through rigorous evaluation across federated multi-modal benchmarks involving vision-language tasks, we demonstrate improved performance in both accuracy and interpretability while reducing vulnerabilities to adversarial and spurious correlations. Further, we introduce a novel trust score aggregation method to quantify global model reliability under dynamic client participation. Our findings pave the way toward developing robust, interpretable, and socially responsible AI systems in Real-world environments.",
      "authors": [
        "Sree Bhargavi Balija"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-25T11:28:21+00:00",
          "link": "https://arxiv.org/abs/2503.19564v1",
          "size": "2895kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T07:04:14+00:00",
          "link": "https://arxiv.org/abs/2503.19564v2",
          "size": "130kb",
          "version": "v2"
        }
      ],
      "title": "FedMM-X: A Trustworthy and Interpretable Framework for Federated Multi-Modal Learning in Dynamic Environments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.19564",
        "HTML": "https://arxiv.org/html/2503.19564v2",
        "PDF": "https://arxiv.org/pdf/2503.19564"
      },
      "tasks": [
        "Federated Learning",
        "Out-of-Distribution Generalization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.19948",
      "abstract": "Can Visual Language Models (VLMs) effectively capture human visual preferences? This work addresses this question by training VLMs to think about preferences at test time, employing reinforcement learning methods inspired by DeepSeek R1 and OpenAI O1. Using datasets such as ImageReward and Human Preference Score v2 (HPSv2), our models achieve accuracies of 64.9% on the ImageReward test set (trained on ImageReward official split) and 65.4% on HPSv2 (trained on approximately 25% of its data). These results match traditional encoder-based models while providing transparent reasoning and enhanced generalization. This approach allows to use not only rich VLM world knowledge, but also its potential to think, yielding interpretable outcomes that help decision-making processes. By demonstrating that human visual preferences reasonable by current VLMs, we introduce efficient soft-reward strategies for image ranking, outperforming simplistic selection or scoring methods. This reasoning capability enables VLMs to rank arbitrary images-regardless of aspect ratio or complexity-thereby potentially amplifying the effectiveness of visual Preference Optimization. By reducing the need for extensive markup while improving reward generalization and explainability, our findings can be a strong mile-stone that will enhance text-to-vision models even further.",
      "authors": [
        "Alexander Gambashidze",
        "Konstantin Sobolev",
        "Andrey Kuznetsov",
        "Ivan Oseledets"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-25T15:30:21+00:00",
          "link": "https://arxiv.org/abs/2503.19948v1",
          "size": "176kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T09:19:28+00:00",
          "link": "https://arxiv.org/abs/2503.19948v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "Test-Time Reasoning Through Visual Human Preferences with VLMs and Soft Rewards",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.19948",
        "PDF": "https://arxiv.org/pdf/2503.19948"
      },
      "tasks": [
        "World Knowledge"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.20349",
      "abstract": "Current diffusion-based super-resolution (SR) approaches achieve commendable performance at the cost of high inference overhead. Therefore, distillation techniques are utilized to accelerate the multi-step teacher model into one-step student model. Nevertheless, these methods significantly raise training costs and constrain the performance of the student model by the teacher model. To overcome these tough challenges, we propose Consistency Trajectory Matching for Super-Resolution (CTMSR), a distillation-free strategy that is able to generate photo-realistic SR results in one step. Concretely, we first formulate a Probability Flow Ordinary Differential Equation (PF-ODE) trajectory to establish a deterministic mapping from low-resolution (LR) images with noise to high-resolution (HR) images. Then we apply the Consistency Training (CT) strategy to directly learn the mapping in one step, eliminating the necessity of pre-trained diffusion model. To further enhance the performance and better leverage the ground-truth during the training process, we aim to align the distribution of SR results more closely with that of the natural images. To this end, we propose to minimize the discrepancy between their respective PF-ODE trajectories from the LR image distribution by our meticulously designed Distribution Trajectory Matching (DTM) loss, resulting in improved realism of our recovered HR images. Comprehensive experimental results demonstrate that the proposed methods can attain comparable or even superior capabilities on both synthetic and real datasets while maintaining minimal inference latency.",
      "authors": [
        "Weiyi You",
        "Mingyang Zhang",
        "Leheng Zhang",
        "Xingyu Zhou",
        "Kexuan Shi",
        "Shuhang Gu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-26T09:20:42+00:00",
          "link": "https://arxiv.org/abs/2503.20349v1",
          "size": "14722kb",
          "version": "v1"
        },
        {
          "date": "2025-03-27T13:59:15+00:00",
          "link": "https://arxiv.org/abs/2503.20349v2",
          "size": "14722kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T11:43:16+00:00",
          "link": "https://arxiv.org/abs/2503.20349v3",
          "size": "11967kb",
          "version": "v3"
        }
      ],
      "title": "Consistency Trajectory Matching for One-Step Generative Super-Resolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.20349",
        "HTML": "https://arxiv.org/html/2503.20349v3",
        "PDF": "https://arxiv.org/pdf/2503.20349"
      },
      "tasks": [
        "Super-Resolution"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.22240",
      "abstract": "Precisely grasping an object is a challenging task due to pose uncertainties. Conventional methods have used cameras and fixtures to reduce object uncertainty. They are effective but require intensive preparation, such as designing jigs based on the object geometry and calibrating cameras with high-precision tools fabricated using lasers. In this study, we propose a method to reduce the uncertainty of the position and orientation of a grasped object without using a fixture or a camera. Our method is based on the concept that the flat finger pads of a parallel gripper can reduce uncertainty along its opening/closing direction through flat surface contact. Three orthogonal grasps by parallel grippers with flat finger pads collectively constrain an object's position and orientation to a unique state. Guided by the concepts, we develop a regrasp planning and admittance control approach that sequentially finds and leverages three orthogonal grasps of two robotic arms to actively reduce uncertainties in the object pose. We evaluated the proposed method on different initial object uncertainties and verified that it had good repeatability. The deviation levels of the experimental trials were on the same order of magnitude as those of an optical tracking system, demonstrating strong relative inference performance.",
      "authors": [
        "Ryuta Nagahama",
        "Weiwei Wan",
        "Zhengtao Hu",
        "Kensuke Harada"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-28T08:42:54+00:00",
          "link": "https://arxiv.org/abs/2503.22240v1",
          "size": "2821kb",
          "version": "v1"
        },
        {
          "date": "2025-05-07T04:53:51+00:00",
          "link": "https://arxiv.org/abs/2503.22240v2",
          "size": "3477kb",
          "version": "v2"
        },
        {
          "date": "2025-05-23T04:39:53+00:00",
          "link": "https://arxiv.org/abs/2503.22240v3",
          "size": "3477kb",
          "version": "v3"
        },
        {
          "date": "2025-06-28T01:47:16+00:00",
          "link": "https://arxiv.org/abs/2503.22240v4",
          "size": "1597kb",
          "version": "v4"
        }
      ],
      "title": "Bimanual Regrasp Planning and Control for Active Reduction of Object Pose Uncertainty",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.22240",
        "HTML": "https://arxiv.org/html/2503.22240v4",
        "PDF": "https://arxiv.org/pdf/2503.22240"
      },
      "source": "arXiv"
    },
    {
      "id": "2503.22352",
      "abstract": "Recent advancements in text-to-image generative models, particularly latent diffusion models (LDMs), have demonstrated remarkable capabilities in synthesizing high-quality images from textual prompts. However, achieving identity personalization-ensuring that a model consistently generates subject-specific outputs from limited reference images-remains a fundamental challenge. To address this, we introduce Meta-Low-Rank Adaptation (Meta-LoRA), a novel framework that leverages meta-learning to encode domain-specific priors into LoRA-based identity personalization. Our method introduces a structured three-layer LoRA architecture that separates identity-agnostic knowledge from identity-specific adaptation. In the first stage, the LoRA Meta-Down layers are meta-trained across multiple subjects, learning a shared manifold that captures general identity-related features. In the second stage, only the LoRA-Mid and LoRA-Up layers are optimized to specialize on a given subject, significantly reducing adaptation time while improving identity fidelity. To evaluate our approach, we introduce Meta-PHD, a new benchmark dataset for identity personalization, and compare Meta-LoRA against state-of-the-art methods. Our results demonstrate that Meta-LoRA achieves superior identity retention, computational efficiency, and adaptability across diverse identity conditions. Our code, model weights, and dataset are released on barisbatuhan.github.io/Meta-LoRA.",
      "authors": [
        "Bar{\\i}\\c{s} Batuhan Topal",
        "Umut \\\"Ozyurt",
        "Zafer Do\\u{g}an Budak",
        "Ramazan Gokberk Cinbis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-28T11:47:33+00:00",
          "link": "https://arxiv.org/abs/2503.22352v1",
          "size": "38924kb",
          "version": "v1"
        },
        {
          "date": "2025-04-09T07:33:11+00:00",
          "link": "https://arxiv.org/abs/2503.22352v2",
          "size": "16321kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T19:16:59+00:00",
          "link": "https://arxiv.org/abs/2503.22352v3",
          "size": "19559kb",
          "version": "v3"
        }
      ],
      "title": "Meta-LoRA: Meta-Learning LoRA Components for Domain-Aware ID Personalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.22352",
        "HTML": "https://arxiv.org/html/2503.22352v3",
        "PDF": "https://arxiv.org/pdf/2503.22352"
      },
      "tasks": [
        "Computational Efficiency",
        "Meta-Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.22359",
      "abstract": "Despite the similar structures of human faces, existing face alignment methods cannot learn unified knowledge from multiple datasets with different landmark annotations. The limited training samples in a single dataset commonly result in fragile robustness in this field. To mitigate knowledge discrepancies among different datasets and train a task-agnostic unified face alignment (TUFA) framework, this paper presents a strategy to unify knowledge from multiple datasets. Specifically, we calculate a mean face shape for each dataset. To explicitly align these mean shapes on an interpretable plane based on their semantics, each shape is then incorporated with a group of semantic alignment embeddings. The 2D coordinates of these aligned shapes can be viewed as the anchors of the plane. By encoding them into structure prompts and further regressing the corresponding facial landmarks using image features, a mapping from the plane to the target faces is finally established, which unifies the learning target of different datasets. Consequently, multiple datasets can be utilized to boost the generalization ability of the model. The successful mitigation of discrepancies also enhances the efficiency of knowledge transferring to a novel dataset, significantly boosts the performance of few-shot face alignment. Additionally, the interpretable plane endows TUFA with a task-agnostic characteristic, enabling it to locate landmarks unseen during training in a zero-shot manner. Extensive experiments are carried on seven benchmarks and the results demonstrate an impressive improvement in face alignment brought by knowledge discrepancies mitigation. The code is available at https://github.com/Jiahao-UTS/TUFA.",
      "authors": [
        "Jiahao Xia",
        "Min Xu",
        "Wenjian Huang",
        "Jianguo Zhang",
        "Haimin Zhang",
        "Chunxia Xiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-28T11:59:27+00:00",
          "link": "https://arxiv.org/abs/2503.22359v1",
          "size": "3719kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T13:00:00+00:00",
          "link": "https://arxiv.org/abs/2503.22359v2",
          "size": "4554kb",
          "version": "v2"
        }
      ],
      "title": "Mitigating Knowledge Discrepancies among Multiple Datasets for Task-agnostic Unified Face Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.22359",
        "HTML": "https://arxiv.org/html/2503.22359v2",
        "PDF": "https://arxiv.org/pdf/2503.22359"
      },
      "tasks": [
        "Face Alignment"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.22968",
      "abstract": "Recent advancements in Korean large language models (LLMs) have driven numerous benchmarks and evaluation methods, yet inconsistent protocols cause up to 10 p.p performance gaps across institutions. Overcoming these reproducibility gaps does not mean enforcing a one-size-fits-all evaluation. Rather, effective benchmarking requires diverse experimental approaches and a framework robust enough to support them. To this end, we introduce HRET (Haerae Evaluation Toolkit), an open-source, registry-based framework that unifies Korean LLM assessment. HRET integrates major Korean benchmarks, multiple inference backends, and multi-method evaluation, with language consistency enforcement to ensure genuine Korean outputs. Its modular registry design also enables rapid incorporation of new datasets, methods, and backends, ensuring the toolkit adapts to evolving research needs. Beyond standard accuracy metrics, HRET incorporates Korean-focused output analyses-morphology-aware Type-Token Ratio (TTR) for evaluating lexical diversity and systematic keyword-omission detection for identifying missing concepts-to provide diagnostic insights into language-specific behaviors. These targeted analyses help researchers pinpoint morphological and semantic shortcomings in model outputs, guiding focused improvements in Korean LLM development.",
      "authors": [
        "Hanwool Lee",
        "Dasol Choi",
        "Sooyong Kim",
        "Ilgyun Jung",
        "Sangwon Baek",
        "Guijin Son",
        "Inseon Hwang",
        "Naeun Lee",
        "Seunghyeok Hong"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-29T04:17:58+00:00",
          "link": "https://arxiv.org/abs/2503.22968v1",
          "size": "53kb",
          "version": "v1"
        },
        {
          "date": "2025-04-01T12:37:16+00:00",
          "link": "https://arxiv.org/abs/2503.22968v2",
          "size": "53kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T09:50:07+00:00",
          "link": "https://arxiv.org/abs/2503.22968v3",
          "size": "43kb",
          "version": "v3"
        }
      ],
      "title": "Redefining Evaluation Standards: A Unified Framework for Evaluating the Korean Capabilities of Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.22968",
        "HTML": "https://arxiv.org/html/2503.22968v3",
        "PDF": "https://arxiv.org/pdf/2503.22968"
      },
      "tasks": [
        "haerae",
        "kmmlu"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.01699",
      "abstract": "We develop high-order flux splitting schemes for the one- and two-dimensional Euler equations of gas dynamics. The proposed schemes are high-order extensions of the existing first-order flux splitting schemes introduced in [ E. F. Toro, M. E. V\\'azquez-Cend\\'on, Comput. \\& Fluids, 70 (2012), pp. 1--12], where the Euler equations of gas dynamics are split into two subsystems: the advection and pressure systems. In this paper, we formulate the TV splitting within the semi-discrete framework to extend it to higher orders of accuracy for the first time. The second-order extension is obtained by using piecewise linear interpolant to reconstruct the one-sided point values of the unknowns. The third- and fifth-order schemes are developed using the finite-difference alternative weighted essentially non-oscillatory (A-WENO) framework, which is particularly effective in handling multidimensional problems and provides a more straightforward approach to constructing higher-order WENO schemes. These extensions significantly improve the resolution of discontinuities and the accuracy of numerical solutions, as demonstrated by a series of numerical experiments of both the one- and two-dimensional Euler equations of gas dynamics.",
      "authors": [
        "Shaoshuai Chu",
        "Michael Herty",
        "and Eleuterio F. Toro"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-02T12:59:34+00:00",
          "link": "https://arxiv.org/abs/2504.01699v1",
          "size": "36633kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T08:56:28+00:00",
          "link": "https://arxiv.org/abs/2504.01699v2",
          "size": "32661kb",
          "version": "v2"
        }
      ],
      "title": "High-Order Flux Splitting Schemes for the Euler Equations of Gas Dynamics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.01699",
        "PDF": "https://arxiv.org/pdf/2504.01699"
      },
      "source": "arXiv"
    },
    {
      "id": "2504.03474",
      "abstract": "This study addresses the essential task of medical image segmentation, which involves the automatic identification and delineation of anatomical structures and pathological regions in medical images. Accurate segmentation is crucial in radiology, as it aids in the precise localization of abnormalities such as tumors, thereby enabling effective diagnosis, treatment planning, and monitoring of disease progression. Specifically, the size, shape, and location of tumors can significantly influence clinical decision-making and therapeutic strategies, making accurate segmentation a key component of radiological workflows. However, challenges posed by variations in MRI modalities, image artifacts, and the scarcity of labeled data complicate the segmentation task and impact the performance of traditional models. To overcome these limitations, we propose a novel self-supervised learning Multi-encoder nnU-Net architecture designed to process multiple MRI modalities independently through separate encoders. This approach allows the model to capture modality-specific features before fusing them for the final segmentation, thus improving accuracy. Our Multi-encoder nnU-Net demonstrates exceptional performance, achieving a Dice Similarity Coefficient (DSC) of 93.72%, which surpasses that of other models such as vanilla nnU-Net, SegResNet, and Swin UNETR. By leveraging the unique information provided by each modality, the model enhances segmentation tasks, particularly in scenarios with limited annotated data. Evaluations highlight the effectiveness of this architecture in improving tumor segmentation outcomes.",
      "authors": [
        "Seyedeh Sahar Taheri Otaghsara",
        "Reza Rahmanzadeh"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-04T14:31:06+00:00",
          "link": "https://arxiv.org/abs/2504.03474v1",
          "size": "1322kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T13:05:00+00:00",
          "link": "https://arxiv.org/abs/2504.03474v2",
          "size": "1316kb",
          "version": "v2"
        }
      ],
      "title": "Multi-encoder nnU-Net outperforms transformer models with self-supervised pretraining",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03474",
        "HTML": "https://arxiv.org/html/2504.03474v2",
        "PDF": "https://arxiv.org/pdf/2504.03474"
      },
      "tasks": [
        "Image Segmentation",
        "Medical Image Segmentation",
        "Segmentation",
        "Self-Supervised Learning",
        "Semantic Segmentation",
        "Tumor Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.03668",
      "abstract": "Large Foundation Models (LFMs), including multi-modal and generative models, promise to unlock new capabilities for next-generation Edge AI applications. However, performing inference with LFMs in resource-constrained and heterogeneous edge environments, such as Multi-access Edge Computing (MEC), presents significant challenges for workload orchestration due to time-varying network, compute, and storage conditions. In particular, current split inference strategies, which partition LFM layers across nodes, are not designed to adapt to fluctuating workloads, dynamic bandwidth conditions, or evolving privacy constraints in high-utilization MEC environments. In this work, we propose a novel adaptive split inference orchestration framework that elevates both the placement and partitioning of LFM layers to runtime-tunable variables. Specifically, our framework enables real-time, quality-of-service (QoS)-aware management of inference workloads by extending conventional orchestrators with three key services: (1) Capacity-aware workload distribution, which continuously profiles node resources and selects an optimal subset of MEC nodes; (2) Dynamic partition migration, which transparently relocates pre-cut LFM segments in response to changes in utilization or network conditions; (3) Real-time reconfiguration, which dynamically re-splits LFM layers to balance latency, throughput, and privacy. We formalize the joint placement-partitioning problem, outline a reference architecture and algorithmic workflow, and discuss applicability in representative smart city, V2X, and industrial edge scenarios.",
      "authors": [
        "Fernando Koch and Aladin Djuhera and Alecio Binotto"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-19T15:35:56+00:00",
          "link": "https://arxiv.org/abs/2504.03668v1",
          "size": "639kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T15:26:30+00:00",
          "link": "https://arxiv.org/abs/2504.03668v2",
          "size": "673kb",
          "version": "v2"
        }
      ],
      "title": "Intelligent Orchestration of Distributed Large Foundation Model Inference at the Edge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03668",
        "HTML": "https://arxiv.org/html/2504.03668v2",
        "PDF": "https://arxiv.org/pdf/2504.03668"
      },
      "tasks": [
        "Edge-computing"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.03947",
      "abstract": "We present a novel approach for training small language models for reasoning-intensive document ranking that combines knowledge distillation with reinforcement learning optimization. While existing methods often rely on expensive human annotations or large black-box language models, our methodology leverages web data and a teacher LLM to automatically generate high-quality training examples with relevance explanations. By framing document ranking as a reinforcement learning problem and incentivizing explicit reasoning capabilities, we train a compact 3B parameter language model that achieves state-of-the-art performance on the BRIGHT benchmark. Our model ranks third on the leaderboard while using substantially fewer parameters than other approaches, outperforming models that are over 20 times larger. Through extensive experiments, we demonstrate that generating explanations during inference, rather than directly predicting relevance scores, enables more effective reasoning with smaller language models. The self-supervised nature of our method offers a scalable and interpretable solution for modern information retrieval systems.",
      "authors": [
        "Chris Samarinas",
        "Hamed Zamani"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-04T21:27:48+00:00",
          "link": "https://arxiv.org/abs/2504.03947v1",
          "size": "503kb",
          "version": "v1"
        },
        {
          "date": "2025-04-25T20:39:42+00:00",
          "link": "https://arxiv.org/abs/2504.03947v2",
          "size": "503kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T18:22:03+00:00",
          "link": "https://arxiv.org/abs/2504.03947v3",
          "size": "498kb",
          "version": "v3"
        }
      ],
      "title": "Distillation and Refinement of Reasoning in Small Language Models for Document Re-ranking",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.03947",
        "HTML": "https://arxiv.org/html/2504.03947v3",
        "PDF": "https://arxiv.org/pdf/2504.03947"
      },
      "tasks": [
        "Document Ranking",
        "Information Retrieval",
        "Knowledge Distillation",
        "Language Modeling",
        "Language Modelling",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Re-Ranking"
      ],
      "repo_urls": [
        "https://github.com/algoprog/InteRank"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.04528",
      "abstract": "ML-supported decisions, such as ordering tests or determining preventive custody, often involve binary classification based on probabilistic forecasts. Evaluation frameworks for such forecasts typically consider whether to prioritize independent-decision metrics (e.g., Accuracy) or top-K metrics (e.g., Precision@K), and whether to focus on fixed thresholds or threshold-agnostic measures like AUC-ROC. We highlight that a consequentialist perspective, long advocated by decision theorists, should naturally favor evaluations that support independent decisions using a mixture of thresholds given their prevalence, such as Brier scores and Log loss. However, our empirical analysis reveals a strong preference for top-K metrics or fixed thresholds in evaluations at major conferences like ICML, FAccT, and CHIL. To address this gap, we use this decision-theoretic framework to map evaluation metrics to their optimal use cases, along with a Python package, briertools, to promote the broader adoption of Brier scores. In doing so, we also uncover new theoretical connections, including a reconciliation between the Brier Score and Decision Curve Analysis, which clarifies and responds to a longstanding critique by (Assel, et al. 2017) regarding the clinical utility of proper scoring rules.",
      "authors": [
        "Gerardo Flores",
        "Abigail Schiff",
        "Alyssa H. Smith",
        "Julia A Fukuyama",
        "Ashia C. Wilson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Methodology (stat.ME)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-06T15:58:01+00:00",
          "link": "https://arxiv.org/abs/2504.04528v1",
          "size": "271kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T12:15:11+00:00",
          "link": "https://arxiv.org/abs/2504.04528v2",
          "size": "271kb",
          "version": "v2"
        }
      ],
      "title": "A Consequentialist Critique of Binary Classification Evaluation Practices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.04528",
        "HTML": "https://arxiv.org/html/2504.04528v2",
        "PDF": "https://arxiv.org/pdf/2504.04528"
      },
      "tasks": [
        "Binary Classification",
        "Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.04745",
      "abstract": "This paper evaluates the ability of Large Language Models (LLMs) to leverage contextual information in the form of structured linguistic representations. Specifically, we examine the impact of encoding both short and long contexts using Abstract Meaning Representation (AMR) structures across a diverse set of language tasks. We perform our analysis using 8-bit quantized and instruction-tuned versions of Llama 3.1 (8B), Phi-3, and Mistral 7B. Our results indicate that, for tasks involving short contexts, augmenting the prompt with the AMR of the original language context often degrades the performance of the underlying LLM. However, for tasks that involve long contexts, such as dialogue summarization in the SAMSum dataset, this enhancement improves LLM performance, for example, by increasing the zero-shot cosine similarity score of Llama 3.1 from 66% to 76%. This improvement is more evident in the newer and larger LLMs, but does not extend to the older or smaller ones. In addition, we observe that LLMs can effectively reconstruct the original text from a linearized AMR, achieving a cosine similarity of 81% in the best-case scenario.",
      "authors": [
        "Ankush Raut",
        "Xiaofeng Zhu",
        "Maria Leonor Pacheco"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-07T05:38:40+00:00",
          "link": "https://arxiv.org/abs/2504.04745v1",
          "size": "1943kb",
          "version": "v1"
        },
        {
          "date": "2025-06-08T20:24:42+00:00",
          "link": "https://arxiv.org/abs/2504.04745v2",
          "size": "1902kb",
          "version": "v2"
        },
        {
          "date": "2025-06-10T19:47:54+00:00",
          "link": "https://arxiv.org/abs/2504.04745v3",
          "size": "1902kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T22:58:33+00:00",
          "link": "https://arxiv.org/abs/2504.04745v4",
          "size": "1902kb",
          "version": "v4"
        }
      ],
      "title": "Can LLMs Interpret and Leverage Structured Linguistic Representations? A Case Study with AMRs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.04745",
        "HTML": "https://arxiv.org/html/2504.04745v4",
        "PDF": "https://arxiv.org/pdf/2504.04745"
      },
      "source": "arXiv"
    },
    {
      "id": "2504.04801",
      "abstract": "Despite the remarkable progress of multimodal large language models (MLLMs), they continue to face challenges in achieving competitive performance on ordinal regression (OR; a.k.a. ordinal classification). To address this issue, this paper presents OrderChain, a novel and general prompting paradigm that improves the ordinal understanding ability of MLLMs by specificity and commonality modeling. Specifically, our OrderChain consists of a set of task-aware prompts to facilitate the specificity modeling of diverse OR tasks and a new range optimization Chain-of-Thought (RO-CoT), which learns a commonality way of thinking about OR tasks by uniformly decomposing them into multiple small-range optimization subtasks. Further, we propose a category recursive division (CRD) method to generate instruction candidate category prompts to support RO-CoT automatic optimization. Comprehensive experiments show that a Large Language and Vision Assistant (LLaVA) model with our OrderChain improves baseline LLaVA significantly on diverse OR datasets, e.g., from 47.5% to 93.2% accuracy on the Adience dataset for age estimation, and from 30.0% to 85.7% accuracy on the Diabetic Retinopathy dataset. Notably, LLaVA with our OrderChain also remarkably outperforms state-of-the-art methods by 27% on accuracy and 0.24 on MAE on the Adience dataset. To our best knowledge, our OrderChain is the first work that augments MLLMs for OR tasks, and the effectiveness is witnessed across a spectrum of OR datasets.",
      "authors": [
        "Jinhong Wang",
        "Shuo Tong",
        "Jian liu",
        "Dongqi Tang",
        "Weiqiang Wang",
        "Wentong Li",
        "Hongxia Xu",
        "Danny Chen",
        "Jintai Chen",
        "Jian Wu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-07T07:53:44+00:00",
          "link": "https://arxiv.org/abs/2504.04801v1",
          "size": "424kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T06:40:22+00:00",
          "link": "https://arxiv.org/abs/2504.04801v2",
          "size": "415kb",
          "version": "v2"
        }
      ],
      "title": "OrderChain: Towards General Instruct-Tuning for Stimulating the Ordinal Understanding Ability of MLLM",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.04801",
        "HTML": "https://arxiv.org/html/2504.04801v2",
        "PDF": "https://arxiv.org/pdf/2504.04801"
      },
      "source": "arXiv"
    },
    {
      "id": "2504.04889",
      "abstract": "In this paper, we consider undiscouted infinitehorizon optimal control for deterministic systems with an uncountable state and input space. We specifically address the case when the classic value iteration does not converge. For such systems, we use the Ces`aro mean to define the infinite-horizon optimal control problem and the corresponding infinite-horizon value function. Moreover, for this value function, we introduce the Ces\\`aro value iteration and prove its convergence for the special case of systems with periodic optimal operating behavior. For this instance, we also show that the Ces\\`aro value function recovers the undiscounted infinite-horizon optimal cost, if the latter is well-defined.",
      "authors": [
        "Jonas Mair",
        "Lukas Schwenkel",
        "Matthias A. M\\\"uller and Frank Allg\\\"ower"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-07T09:55:48+00:00",
          "link": "https://arxiv.org/abs/2504.04889v1",
          "size": "94kb",
          "version": "v1"
        },
        {
          "date": "2025-05-23T06:24:09+00:00",
          "link": "https://arxiv.org/abs/2504.04889v2",
          "size": "96kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T14:52:52+00:00",
          "link": "https://arxiv.org/abs/2504.04889v3",
          "size": "100kb",
          "version": "v3"
        }
      ],
      "title": "The Ces\\`aro Value Iteration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.04889",
        "PDF": "https://arxiv.org/pdf/2504.04889"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.05040",
      "abstract": "Despite progress in video large language models (Video-LLMs), research on instructional video understanding, crucial for enhancing access to instructional content, remains insufficient. To address this, we introduce InstructionBench, an Instructional video understanding Benchmark, which challenges models' advanced temporal reasoning within instructional videos characterized by their strict step-by-step flow. Employing GPT-4, we formulate Q&A pairs in open-ended and multiple-choice formats to assess both Coarse-Grained event-level and Fine-Grained object-level reasoning. Our filtering strategies exclude questions answerable purely by common-sense knowledge, focusing on visual perception and analysis when evaluating Video-LLM models. The benchmark finally contains 5k questions across over 700 videos. We evaluate the latest Video-LLMs on our InstructionBench, finding that closed-source models outperform open-source ones. However, even the best model, GPT-4o, achieves only 53.42% accuracy, indicating significant gaps in temporal reasoning. To advance the field, we also develop a comprehensive instructional video dataset with over 19k Q&A pairs from nearly 2.5k videos, using an automated data generation framework, thereby enriching the community's research resources. All data are available at https://huggingface.co/datasets/sunwhw/InstructionBench.",
      "authors": [
        "Haiwan Wei",
        "Yitian Yuan",
        "Xiaohan Lan",
        "Wei Ke",
        "Lin Ma"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-07T13:05:09+00:00",
          "link": "https://arxiv.org/abs/2504.05040v1",
          "size": "502kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T07:41:07+00:00",
          "link": "https://arxiv.org/abs/2504.05040v2",
          "size": "8283kb",
          "version": "v2"
        }
      ],
      "title": "InstructionBench: An Instructional Video Understanding Benchmark",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.05040",
        "HTML": "https://arxiv.org/html/2504.05040v2",
        "PDF": "https://arxiv.org/pdf/2504.05040"
      },
      "tasks": [
        "Common Sense Reasoning",
        "Multiple-choice",
        "Video Understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.05149",
      "abstract": "Let $\\mathbb{Z}^2\\backslash SE(2)$ denote the right coset space of the subgroup consisting of translational isometries of the orthogonal lattice $\\mathbb{Z}^2$ in the non-Abelian group of planar motions $SE(2)$. This paper develops a fast and accurate numerical scheme for approximation of functions on $\\mathbb{Z}^2\\backslash SE(2)$. We address finite Fourier series of functions on the right coset space $\\mathbb{Z}^2\\backslash SE(2)$ using finite Fourier coefficients. The convergence/error analysis of finite Fourier coefficients are investigated. Conditions are established for the finite Fourier coefficients to converge to the Fourier coefficients. The matrix forms of the finite transforms are discussed. The implementation of the discrete method to compute numerical approximation of $SE(2)$-convolutions with functions which are radial in translations are considered. The paper is concluded by discussing capability of the numerical scheme to develop fast algorithms for approximating multiple convolutions with functions which are radial in translations.",
      "authors": [
        "Arash Ghaani Farashahi",
        "Gregory S. Chirikjian"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Functional Analysis (math.FA)",
        "Group Theory (math.GR)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-07T14:56:32+00:00",
          "link": "https://arxiv.org/abs/2504.05149v1",
          "size": "3114kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T16:38:23+00:00",
          "link": "https://arxiv.org/abs/2504.05149v2",
          "size": "3045kb",
          "version": "v2"
        }
      ],
      "title": "Fast Convolutions on $\\mathbb{Z}^2\\backslash SE(2)$ via Radial Translational Dependence and Classical FFT",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.05149",
        "HTML": "https://arxiv.org/html/2504.05149v2",
        "PDF": "https://arxiv.org/pdf/2504.05149"
      },
      "source": "arXiv"
    },
    {
      "id": "2504.05352",
      "abstract": "Quantizing large language models (LLMs) to 1-bit precision significantly reduces computational costs, but existing quantization techniques suffer from noticeable performance degradation when using weight and activation precisions below 4 bits (W4A4). In this paper, we propose a post-training quantization framework with W(1+1)A(1*4) configuration, where weights are quantized to 1 bit with an additional 1 bit for fine-grain grouping and activations are quantized to 1 bit with a 4-fold increase in the number of channels. For weight quantization, we propose utilizing Hessian-aware fine-grained grouping along with an EM-based quantization scheme. For activation quantization, we decompose INT4-quantized activations into a 4 * INT1 format equivalently and simultaneously smooth the scaling factors based on quantization errors, which further reduces the quantization errors in activations. Our method surpasses state-of-the-art (SOTA) LLM quantization baselines on W2A4 across multiple tasks, pushing the boundaries of existing LLM quantization methods toward fully binarized models. Code is available at https://github.com/JimmyCrave/LLM-PTQ-binarization.",
      "authors": [
        "Siqing Song and Chuang Wang and Ruiqi Wang and Yi Yang and Xu-Yao Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-07T04:50:04+00:00",
          "link": "https://arxiv.org/abs/2504.05352v1",
          "size": "1520kb",
          "version": "v1"
        },
        {
          "date": "2025-05-27T08:48:00+00:00",
          "link": "https://arxiv.org/abs/2504.05352v2",
          "size": "1462kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T04:32:15+00:00",
          "link": "https://arxiv.org/abs/2504.05352v3",
          "size": "620kb",
          "version": "v3"
        }
      ],
      "title": "Achieving binary weight and activation for LLMs using Post-Training Quantization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.05352",
        "HTML": "https://arxiv.org/html/2504.05352v3",
        "PDF": "https://arxiv.org/pdf/2504.05352"
      },
      "tasks": [
        "Quantization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.07579",
      "abstract": "This chapter provides a comprehensive overview of controlling collective behavior in complex systems comprising large ensembles of interacting dynamical agents. Building upon traditional control theory's foundation in individual systems, we introduce tools designed to address the unique challenges of coordinating networks that exhibit emergent phenomena, including consensus, synchronization, and pattern formation. We analyze how local agent interactions generate macroscopic behaviors and investigate the fundamental role of network topology in determining system dynamics. Inspired by natural systems, we emphasize control strategies that achieve global coordination through localized interventions while considering practical implementation challenges. The chapter concludes by presenting novel frameworks for managing very large agent ensembles and leveraging interacting networks for control purposes.",
      "authors": [
        "Marco Coraggio",
        "Davide Salzano",
        "Mario di Bernardo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-10T09:21:09+00:00",
          "link": "https://arxiv.org/abs/2504.07579v1",
          "size": "1248kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T14:53:06+00:00",
          "link": "https://arxiv.org/abs/2504.07579v2",
          "size": "1239kb",
          "version": "v2"
        }
      ],
      "title": "Controlling Complex Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07579",
        "HTML": "https://arxiv.org/html/2504.07579v2",
        "PDF": "https://arxiv.org/pdf/2504.07579"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.07722",
      "abstract": "From clinical dosing algorithms to autonomous robots, sequential decision-making systems routinely operate with missing or incomplete data. Classical reinforcement learning theory, which is commonly used to solve sequential decision problems, assumes Markovian observability, which may not hold under partial observability. Causal inference paradigms formalise ignorability of missingness. We show these views can be unified and generalized in order to guarantee Q-learning convergence even when the Markov property fails. To do so, we introduce the concept of \\emph{relative ignorability}. Relative ignorability is a graphical-causal criterion which refines the requirements for accurate decision-making based on incomplete data. Theoretical results and simulations both reveal that non-markovian stochastic processes whose missingness is relatively ignorable with respect to causal estimands can still be optimized using standard Reinforcement Learning algorithms. These results expand the theoretical foundations of safe, data-efficient AI to real-world environments where complete information is unattainable.",
      "authors": [
        "MaryLena Bleile"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-10T13:15:52+00:00",
          "link": "https://arxiv.org/abs/2504.07722v1",
          "size": "22kb",
          "version": "v1"
        },
        {
          "date": "2025-04-16T12:57:23+00:00",
          "link": "https://arxiv.org/abs/2504.07722v2",
          "size": "32kb",
          "version": "v2"
        },
        {
          "date": "2025-04-20T16:06:48+00:00",
          "link": "https://arxiv.org/abs/2504.07722v3",
          "size": "153kb",
          "version": "v3"
        },
        {
          "date": "2025-06-06T18:00:32+00:00",
          "link": "https://arxiv.org/abs/2504.07722v4",
          "size": "107kb",
          "version": "v4"
        },
        {
          "date": "2025-06-29T01:49:19+00:00",
          "link": "https://arxiv.org/abs/2504.07722v5",
          "size": "107kb",
          "version": "v5"
        }
      ],
      "title": "A Framework of Decision-Relevant Observability: Reinforcement Learning Converges Under Relative Ignorability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.07722",
        "HTML": "https://arxiv.org/html/2504.07722v5",
        "PDF": "https://arxiv.org/pdf/2504.07722"
      },
      "tasks": [
        "Causal Inference",
        "Decision Making",
        "Learning Theory",
        "Q-Learning",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Sequential Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.08438",
      "abstract": "Diffusion generative models have demonstrated remarkable success in visual domains such as image and video generation. They have also recently emerged as a promising approach in robotics, especially in robot manipulations. Diffusion models leverage a probabilistic framework, and they stand out with their ability to model multi-modal distributions and their robustness to high-dimensional input and output spaces. This survey provides a comprehensive review of state-of-the-art diffusion models in robotic manipulation, including grasp learning, trajectory planning, and data augmentation. Diffusion models for scene and image augmentation lie at the intersection of robotics and computer vision for vision-based tasks to enhance generalizability and data scarcity. This paper also presents the two main frameworks of diffusion models and their integration with imitation learning and reinforcement learning. In addition, it discusses the common architectures and benchmarks and points out the challenges and advantages of current state-of-the-art diffusion-based methods.",
      "authors": [
        "Rosa Wolf",
        "Yitian Shi",
        "Sheng Liu",
        "Rania Rayyes"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-11T11:01:11+00:00",
          "link": "https://arxiv.org/abs/2504.08438v1",
          "size": "1002kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T15:32:22+00:00",
          "link": "https://arxiv.org/abs/2504.08438v2",
          "size": "1831kb",
          "version": "v2"
        }
      ],
      "title": "Diffusion Models for Robotic Manipulation: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.08438",
        "HTML": "https://arxiv.org/html/2504.08438v2",
        "PDF": "https://arxiv.org/pdf/2504.08438"
      },
      "tasks": [
        "Data Augmentation",
        "Image Augmentation",
        "Imitation Learning",
        "Survey",
        "Trajectory Planning",
        "Video Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.09039",
      "abstract": "Text-to-image (T2I) diffusion models have achieved remarkable success in generating high-quality images from textual prompts. However, their ability to store vast amounts of knowledge raises concerns in scenarios where selective forgetting is necessary, such as removing copyrighted content, reducing biases, or eliminating harmful concepts. While existing unlearning methods can remove certain concepts, they struggle with multi-concept forgetting due to instability, residual knowledge persistence, and generation quality degradation. To address these challenges, we propose \\textbf{Dynamic Mask coupled with Concept-Aware Loss}, a novel unlearning framework designed for multi-concept forgetting in diffusion models. Our \\textbf{Dynamic Mask} mechanism adaptively updates gradient masks based on current optimization states, allowing selective weight modifications that prevent interference with unrelated knowledge. Additionally, our \\textbf{Concept-Aware Loss} explicitly guides the unlearning process by enforcing semantic consistency through superclass alignment, while a regularization loss based on knowledge distillation ensures that previously unlearned concepts remain forgotten during sequential unlearning. We conduct extensive experiments to evaluate our approach. Results demonstrate that our method outperforms existing unlearning techniques in forgetting effectiveness, output fidelity, and semantic coherence, particularly in multi-concept scenarios. Our work provides a principled and flexible framework for stable and high-fidelity unlearning in generative models. The code will be released publicly.",
      "authors": [
        "Gen Li",
        "Yang Xiao",
        "Jie Ji",
        "Kaiyuan Deng",
        "Bo Hui",
        "Linke Guo",
        "Xiaolong Ma"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-12T01:38:58+00:00",
          "link": "https://arxiv.org/abs/2504.09039v1",
          "size": "20213kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T04:37:01+00:00",
          "link": "https://arxiv.org/abs/2504.09039v2",
          "size": "19016kb",
          "version": "v2"
        }
      ],
      "title": "Sculpting Memory: Multi-Concept Forgetting in Diffusion Models via Dynamic Mask and Concept-Aware Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.09039",
        "HTML": "https://arxiv.org/html/2504.09039v2",
        "PDF": "https://arxiv.org/pdf/2504.09039"
      },
      "source": "arXiv"
    },
    {
      "id": "2504.10416",
      "abstract": "Autonomous exploration for mapping unknown large scale environments is a fundamental challenge in robotics, with efficiency in time, stability against map corruption and computational resources being crucial. This paper presents a novel approach to indoor exploration that addresses these key issues in existing methods. We introduce a Simultaneous Localization and Mapping (SLAM)-aware region-based exploration strategy that partitions the environment into discrete regions, allowing the robot to incrementally explore and stabilize each region before moving to the next one. This approach significantly reduces redundant exploration and improves overall efficiency. As the device finishes exploring a region and stabilizes it, we also perform SLAM keyframe marginalization, a technique which reduces problem complexity by eliminating variables, while preserving their essential information. To improves robustness and further enhance efficiency, we develop a checkpoint system that enables the robot to resume exploration from the last stable region in case of failures, eliminating the need for complete re-exploration. Our method, tested in real homes, office and simulations, outperforms state-of-the-art approaches. The improvements demonstrate substantial enhancements in various real world environments, with significant reductions in keyframe usage (85%), submap usage (50% office, 32% home), pose graph optimization time (78-80%), and exploration duration (10-15%). This region-based strategy with keyframe marginalization offers an efficient solution for autonomous robotic mapping.",
      "authors": [
        "Megha Maheshwari",
        "Sadeigh Rabiee",
        "He Yin",
        "Martin Labrie",
        "Hang Liu",
        "Rajasimman Madhivanan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-14T17:00:14+00:00",
          "link": "https://arxiv.org/abs/2504.10416v1",
          "size": "14054kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T16:57:17+00:00",
          "link": "https://arxiv.org/abs/2504.10416v2",
          "size": "9568kb",
          "version": "v2"
        }
      ],
      "title": "Region Based SLAM-Aware Exploration: Efficient and Robust Autonomous Mapping Strategy That Can Scale",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.10416",
        "HTML": "https://arxiv.org/html/2504.10416v2",
        "PDF": "https://arxiv.org/pdf/2504.10416"
      },
      "source": "arXiv"
    },
    {
      "id": "2504.11134",
      "abstract": "The standard approach for visual place recognition is to use global image descriptors to retrieve the most similar database images for a given query image. The results can then be further improved with re-ranking methods that re-order the top scoring images. However, existing methods focus on re-ranking based on the same image descriptors that were used for the initial retrieval, which we argue provides limited additional signal. In this work we propose Generalized Contextual Similarity Aggregation (GCSA), which is a graph neural network-based re-ranking method that, in addition to the visual descriptors, can leverage other types of available side information. This can for example be other sensor data (such as signal strength of nearby WiFi or BlueTooth endpoints) or geometric properties such as camera poses for database images. In many applications this information is already present or can be acquired with low effort. Our architecture leverages the concept of affinity vectors to allow for a shared encoding of the heterogeneous multi-modal input. Two large-scale datasets, covering both outdoor and indoor localization scenarios, are utilized for training and evaluation. In experiments we show significant improvement not only on image retrieval metrics, but also for the downstream visual localization task.",
      "authors": [
        "Gustav Hanning",
        "Gabrielle Flood",
        "Viktor Larsson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-15T12:37:16+00:00",
          "link": "https://arxiv.org/abs/2504.11134v1",
          "size": "2217kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T07:48:14+00:00",
          "link": "https://arxiv.org/abs/2504.11134v2",
          "size": "573kb",
          "version": "v2"
        }
      ],
      "title": "Visual Re-Ranking with Non-Visual Side Information",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.11134",
        "HTML": "https://arxiv.org/html/2504.11134v2",
        "PDF": "https://arxiv.org/pdf/2504.11134"
      },
      "tasks": [
        "Graph Neural Network",
        "Image Retrieval",
        "Indoor Localization",
        "Re-Ranking",
        "Retrieval",
        "Visual Localization",
        "Visual Place Recognition"
      ],
      "repo_urls": [
        "https://github.com/ghanning/gcsa"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.11346",
      "abstract": "We present Seedream 3.0, a high-performance Chinese-English bilingual image generation foundation model. We develop several technical improvements to address existing challenges in Seedream 2.0, including alignment with complicated prompts, fine-grained typography generation, suboptimal visual aesthetics and fidelity, and limited image resolutions. Specifically, the advancements of Seedream 3.0 stem from improvements across the entire pipeline, from data construction to model deployment. At the data stratum, we double the dataset using a defect-aware training paradigm and a dual-axis collaborative data-sampling framework. Furthermore, we adopt several effective techniques such as mixed-resolution training, cross-modality RoPE, representation alignment loss, and resolution-aware timestep sampling in the pre-training phase. During the post-training stage, we utilize diversified aesthetic captions in SFT, and a VLM-based reward model with scaling, thereby achieving outputs that well align with human preferences. Furthermore, Seedream 3.0 pioneers a novel acceleration paradigm. By employing consistent noise expectation and importance-aware timestep sampling, we achieve a 4 to 8 times speedup while maintaining image quality. Seedream 3.0 demonstrates significant improvements over Seedream 2.0: it enhances overall capabilities, in particular for text-rendering in complicated Chinese characters which is important to professional typography generation. In addition, it provides native high-resolution output (up to 2K), allowing it to generate images with high visual quality.",
      "authors": [
        "Yu Gao",
        "Lixue Gong",
        "Qiushan Guo",
        "Xiaoxia Hou",
        "Zhichao Lai",
        "Fanshi Li",
        "Liang Li",
        "Xiaochen Lian",
        "Chao Liao",
        "Liyang Liu",
        "Wei Liu",
        "Yichun Shi",
        "Shiqi Sun",
        "Yu Tian",
        "Zhi Tian",
        "Peng Wang",
        "Rui Wang",
        "Xuanda Wang",
        "Xun Wang",
        "Ye Wang",
        "Guofeng Wu",
        "Jie Wu",
        "Xin Xia",
        "Xuefeng Xiao",
        "Zhonghua Zhai",
        "Xinyu Zhang",
        "Qi Zhang",
        "Yuwei Zhang",
        "Shijia Zhao",
        "Jianchao Yang",
        "Weilin Huang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-15T16:19:07+00:00",
          "link": "https://arxiv.org/abs/2504.11346v1",
          "size": "47661kb",
          "version": "v1"
        },
        {
          "date": "2025-04-16T16:23:31+00:00",
          "link": "https://arxiv.org/abs/2504.11346v2",
          "size": "47514kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T11:46:35+00:00",
          "link": "https://arxiv.org/abs/2504.11346v3",
          "size": "47514kb",
          "version": "v3"
        }
      ],
      "title": "Seedream 3.0 Technical Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.11346",
        "HTML": "https://arxiv.org/html/2504.11346v3",
        "PDF": "https://arxiv.org/pdf/2504.11346"
      },
      "tasks": [
        "2k",
        "Image Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.12153",
      "abstract": "Phase-transition models are an important family of non-equilibrium continuum traffic flow models, offering properties like replicating complex traffic phenomena, maintaining anisotropy, and promising potentials for accommodating automated vehicles. However, their complex mathematical characteristics such as discontinuous solution domains, pose numerical challenges and limit their exploration in traffic flow theory. This paper focuses on developing a robust and accurate numerical method for phase-transition traffic flow models: We propose a second-order semi-discrete central-upwind scheme specifically designed for discontinuous phase-transition models. This novel scheme incorporates the projection onto appropriate flow domains, ensuring enhanced handling of discontinuities and maintaining physical consistency and accuracy. We demonstrate the efficacy of the proposed scheme through extensive and challenging numerical tests, showcasing their potential to facilitate further research and application in phase-transition traffic flow modeling. The ability of phase-transition models to embed the ``time-gap'' -- a crucial element in automated traffic control -- as a conserved variable aligns seamlessly with the control logic of automated vehicles, presenting significant potential for future applications, and the proposed numerical scheme now substantially facilitates exploring such potentials.",
      "authors": [
        "Shaoshuai Chu",
        "Alexander Kurganov",
        "Saeed Mohammadian",
        "Zuduo Zheng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-16T15:02:14+00:00",
          "link": "https://arxiv.org/abs/2504.12153v1",
          "size": "3257kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T08:41:15+00:00",
          "link": "https://arxiv.org/abs/2504.12153v2",
          "size": "6841kb",
          "version": "v2"
        }
      ],
      "title": "Central-Upwind Scheme for the Phase-Transition Traffic Flow Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12153",
        "HTML": "https://arxiv.org/html/2504.12153v2",
        "PDF": "https://arxiv.org/pdf/2504.12153"
      },
      "source": "arXiv"
    },
    {
      "id": "2504.12563",
      "abstract": "Recent smaller language models such Phi-3.5 and Phi-4 rely on synthetic data generated using larger Language models. Questions remain about leveraging synthetic data for other use cases, such as adapting LLMs to specific domains. A key limitation of synthetic data is low diversity, which negatively impacts its downstream applicability for improving other models. To address this, we propose MetaSynth, a method for generating synthetic data that enhances diversity through meta-prompting, where a language model orchestrates multiple \"expert\" LLM agents to collaboratively generate data. Using only 25 million tokens of synthetic data generated with MetaSynth, we successfully adapt a well-trained LLM (Mistral-7B-v0.3) to two specialized domains-Finance and Biomedicine-without compromising the capabilities of the resulting model in general tasks. In addition, we evaluate the diversity of our synthetic data using seven automated metrics, and find that it approaches the diversity of LLM pre-training corpora.\n  Continually pre-training Mistral-7B-v0.3 with MetaSynth notably outperforms the base LLM, showing improvements of up to 4.08% in Finance and 13.75% in Biomedicine. The same model shows degraded performance when trained on data generated using a template prompt, even when the template includes prior generations and varying In-Context exemplars of real data. Our findings suggest that a few million tokens of diverse synthetic data without mixing any real data, is sufficient for effective domain adaptation when using MetaSynth.",
      "authors": [
        "Haris Riaz",
        "Sourav Bhabesh",
        "Vinayak Arannil",
        "Miguel Ballesteros",
        "Graham Horwood"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-17T01:25:15+00:00",
          "link": "https://arxiv.org/abs/2504.12563v1",
          "size": "37918kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T00:24:07+00:00",
          "link": "https://arxiv.org/abs/2504.12563v2",
          "size": "10724kb",
          "version": "v2"
        }
      ],
      "title": "MetaSynth: Meta-Prompting-Driven Agentic Scaffolds for Diverse Synthetic Data Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.12563",
        "PDF": "https://arxiv.org/pdf/2504.12563"
      },
      "tasks": [
        "Diversity",
        "Domain Adaptation",
        "Synthetic Data Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.13801",
      "abstract": "Financial prediction is a complex and challenging task of time series analysis and signal processing, expected to model both short-term fluctuations and long-term temporal dependencies. Transformers have remarkable success mostly in natural language processing using attention mechanism, which also influenced the time series community. The ability to capture both short and long-range dependencies helps to understand the financial market and to recognize price patterns, leading to successful applications of Transformers in stock prediction. Although, the previous research predominantly focuses on individual features and singular predictions, that limits the model's ability to understand broader market trends. In reality, within sectors such as finance and technology, companies belonging to the same industry often exhibit correlated stock price movements.\n  In this paper, we develop a novel neural network architecture by integrating Time2Vec with the Encoder of the Transformer model. Based on the study of different markets, we propose a novel correlation feature selection method. Through a comprehensive fine-tuning of multiple hyperparameters, we conduct a comparative analysis of our results against benchmark models. We conclude that our method outperforms other state-of-the-art encoding methods such as positional encoding, and we also conclude that selecting correlation features enhance the accuracy of predicting multiple stock prices.",
      "authors": [
        "Nguyen Kim Hai Bui",
        "Nguyen Duy Chien",
        "P\\'eter Kov\\'acs",
        "Gerg\\H{o} Bogn\\'ar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-18T17:07:41+00:00",
          "link": "https://arxiv.org/abs/2504.13801v1",
          "size": "865kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T16:16:55+00:00",
          "link": "https://arxiv.org/abs/2504.13801v2",
          "size": "887kb",
          "version": "v2"
        }
      ],
      "title": "Transformer Encoder and Multi-features Time2Vec for Financial Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.13801",
        "HTML": "https://arxiv.org/html/2504.13801v2",
        "PDF": "https://arxiv.org/pdf/2504.13801"
      },
      "tasks": [
        "feature selection",
        "Stock Prediction",
        "Time Series",
        "Time Series Analysis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.14078",
      "abstract": "This study investigates the potential of infrared (IR) camera technology to enhance driver safety for emergency vehicles operating in low-visibility conditions, particularly at night and in dense fog. Such environments significantly increase the risk of collisions, especially for tow trucks and snowplows that must remain operational in challenging conditions. Conventional driver assistance systems often struggle under these conditions due to limited visibility. In contrast, IR cameras, which detect the thermal signatures of obstacles, offer a promising alternative. The evaluation combines controlled laboratory experiments, real-world field tests, and surveys of emergency vehicle operators. In addition to assessing detection performance, the study examines the feasibility of retrofitting existing Department of Transportation (DoT) fleets with cost-effective IR-based driver assistance systems. Results underscore the utility of IR technology in enhancing driver awareness and provide data-driven recommendations for scalable deployment across legacy emergency vehicle fleets.",
      "authors": [
        "M-Mahdi Naddaf-Sh",
        "Andrew Lee",
        "Kin Yen",
        "Eemon Amini",
        "Iman Soltani"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-18T21:06:41+00:00",
          "link": "https://arxiv.org/abs/2504.14078v1",
          "size": "798kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T01:57:41+00:00",
          "link": "https://arxiv.org/abs/2504.14078v2",
          "size": "927kb",
          "version": "v2"
        }
      ],
      "title": "Low-Cost Infrared Vision Systems for Improved Safety of Emergency Vehicle Operations Under Low-Visibility Conditions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.14078",
        "PDF": "https://arxiv.org/pdf/2504.14078"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.14154",
      "abstract": "As large language models are increasingly utilized in real-world applications, guarantees of task-specific metrics are essential for their reliable deployment. Previous studies have introduced various criteria of conformal uncertainty grounded in split conformal prediction, which offer user-specified correctness coverage. However, existing frameworks often fail to identify uncertainty data outliers that violate the exchangeability assumption, leading to unbounded miscoverage rates and unactionable prediction sets. In this paper, we propose a novel approach termed Selective Conformal Uncertainty (SConU), which, for the first time, implements significance tests, by developing two conformal p-values that are instrumental in determining whether a given sample deviates from the uncertainty distribution of the calibration set at a specific manageable risk level. Our approach not only facilitates rigorous management of miscoverage rates across both single-domain and interdisciplinary contexts, but also enhances the efficiency of predictions. Furthermore, we comprehensively analyze the components of the conformal procedures, aiming to approximate conditional coverage, particularly in high-stakes question-answering tasks.",
      "authors": [
        "Zhiyuan Wang",
        "Qingni Wang",
        "Yue Zhang",
        "Tianlong Chen",
        "Xiaofeng Zhu",
        "Xiaoshuang Shi",
        "Kaidi Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-19T03:01:45+00:00",
          "link": "https://arxiv.org/abs/2504.14154v1",
          "size": "3626kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T15:29:40+00:00",
          "link": "https://arxiv.org/abs/2504.14154v2",
          "size": "3626kb",
          "version": "v2"
        }
      ],
      "title": "SConU: Selective Conformal Uncertainty in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.14154",
        "HTML": "https://arxiv.org/html/2504.14154v2",
        "PDF": "https://arxiv.org/pdf/2504.14154"
      },
      "tasks": [
        "Conformal Prediction",
        "Question Answering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.16084",
      "abstract": "This paper investigates Reinforcement Learning (RL) on data without explicit labels for reasoning tasks in Large Language Models (LLMs). The core challenge of the problem is reward estimation during inference while not having access to ground-truth information. While this setting appears elusive, we find that common practices in Test-Time Scaling (TTS), such as majority voting, yield surprisingly effective rewards suitable for driving RL training. In this work, we introduce Test-Time Reinforcement Learning (TTRL), a novel method for training LLMs using RL on unlabeled data. TTRL enables self-evolution of LLMs by utilizing the priors in the pre-trained models. Our experiments demonstrate that TTRL consistently improves performance across a variety of tasks and models. Notably, TTRL boosts the pass@1 performance of Qwen-2.5-Math-7B by approximately 211% on the AIME 2024 with only unlabeled test data. Furthermore, although TTRL is only supervised by the maj@n metric, TTRL has demonstrated performance to consistently surpass the upper limit of the initial model maj@n, and approach the performance of models trained directly on test data with ground-truth labels. Our experimental findings validate the general effectiveness of TTRL across various tasks and highlight TTRL's potential for broader tasks and domains. GitHub: https://github.com/PRIME-RL/TTRL",
      "authors": [
        "Yuxin Zuo",
        "Kaiyan Zhang",
        "Li Sheng",
        "Shang Qu",
        "Ganqu Cui",
        "Xuekai Zhu",
        "Haozhan Li",
        "Yuchen Zhang",
        "Xinwei Long",
        "Ermo Hua",
        "Biqing Qi",
        "Youbang Sun",
        "Zhiyuan Ma",
        "Lifan Yuan",
        "Ning Ding",
        "Bowen Zhou"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-22T17:59:56+00:00",
          "link": "https://arxiv.org/abs/2504.16084v1",
          "size": "259kb",
          "version": "v1"
        },
        {
          "date": "2025-05-22T16:26:55+00:00",
          "link": "https://arxiv.org/abs/2504.16084v2",
          "size": "264kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T15:59:26+00:00",
          "link": "https://arxiv.org/abs/2504.16084v3",
          "size": "277kb",
          "version": "v3"
        }
      ],
      "title": "TTRL: Test-Time Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.16084",
        "PDF": "https://arxiv.org/pdf/2504.16084"
      },
      "models": [
        {
          "model_path": "Metin/LLaMA-3-8B-Math-Majority-Vote-GRPO",
          "downloads": "16",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/Metin/LLaMA-3-8B-Math-Majority-Vote-GRPO"
        }
      ],
      "tasks": [
        "Math",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/qingyangzhang/empo",
        "https://github.com/tsinghuac3i/awesome-rl-reasoning-recipes",
        "https://github.com/prime-rl/ttrl"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.16567",
      "abstract": "A query algorithm based on homomorphism counts is a procedure to decide membership for a class of finite relational structures using only homomorphism count queries. A left query algorithm can ask the number of homomorphisms from any structure to the input structure and a right query algorithm can ask the number of homomorphisms from the input structure to any other structure. We systematically compare the expressive power of different types of left or right query algorithms, including non-adaptive query algorithms, adaptive query algorithms that can ask a bounded number of queries, and adaptive query algorithms that can ask an unbounded number of queries. We also consider query algorithms where the homomorphism counting is done over the Boolean semiring $\\mathbb{B}$, meaning that only the existence of a homomorphism is recorded, not the precise number of them.",
      "authors": [
        "Balder ten Cate",
        "Phokion G. Kolaitis",
        "Arnar \\'A. Kristj\\'ansson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-23T09:46:39+00:00",
          "link": "https://arxiv.org/abs/2504.16567v1",
          "size": "26kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T11:05:59+00:00",
          "link": "https://arxiv.org/abs/2504.16567v2",
          "size": "240kb",
          "version": "v2"
        }
      ],
      "title": "Adaptive Query Algorithms for Relational Structures Based on Homomorphism Counts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.16567",
        "HTML": "https://arxiv.org/html/2504.16567v2",
        "PDF": "https://arxiv.org/pdf/2504.16567"
      },
      "source": "arXiv"
    },
    {
      "id": "2504.16767",
      "abstract": "We propose an online learning framework for forecasting nonlinear spatio-temporal signals (fields). The method integrates (i) dimensionality reduction, here, a simple proper orthogonal decomposition (POD) projection; (ii) a generalized autoregressive model to forecast reduced dynamics, here, a reservoir computer; (iii) online adaptation to update the reservoir computer (the model), here, ensemble sequential data assimilation. We demonstrate the framework on a wake past a cylinder governed by the Navier-Stokes equations, exploring the assimilation of full flow fields (projected onto POD modes) and sparse sensors. Three scenarios are examined: a na\\\"ive physical state estimation; a two-fold estimation of physical and reservoir states; and a three-fold estimation that also adjusts the model parameters. The two-fold strategy significantly improves ensemble convergence and reduces reconstruction error compared to the na\\\"ive approach. The three-fold approach enables robust online training of partially-trained reservoir computers, overcoming limitations of a priori training. By unifying data-driven reduced order modelling with Bayesian data assimilation, this work opens new opportunities for scalable online model learning for nonlinear time series forecasting.",
      "authors": [
        "Andrea N\\'ovoa",
        "Luca Magri"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Fluid Dynamics (physics.flu-dyn)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-23T14:35:54+00:00",
          "link": "https://arxiv.org/abs/2504.16767v1",
          "size": "1289kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T11:38:58+00:00",
          "link": "https://arxiv.org/abs/2504.16767v2",
          "size": "1087kb",
          "version": "v2"
        }
      ],
      "title": "Online model learning with data-assimilated reservoir computers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.16767",
        "HTML": "https://arxiv.org/html/2504.16767v2",
        "PDF": "https://arxiv.org/pdf/2504.16767"
      },
      "tasks": [
        "Dimensionality Reduction",
        "State Estimation",
        "Time Series Forecasting"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.17404",
      "abstract": "As Artificial Intelligence (AI) advances toward Artificial General Intelligence (AGI) and eventually Artificial Superintelligence (ASI), it may potentially surpass human control, deviate from human values, and even lead to irreversible catastrophic consequences in extreme cases. This looming risk underscores the critical importance of the \"superalignment\" problem - ensuring that AI systems which are much smarter than humans, remain aligned with human (compatible) intentions and values. While current scalable oversight and weak-to-strong generalization methods demonstrate certain applicability, they exhibit fundamental flaws in addressing the superalignment paradigm - notably, the unidirectional imposition of human values cannot accommodate superintelligence's autonomy or ensure AGI/ASI's stable learning. We contend that the values for sustainable symbiotic society should be co-shaped by humans and living AI together, achieving \"Super Co-alignment.\" Guided by this vision, we propose a concrete framework that integrates external oversight and intrinsic proactive alignment. External oversight superalignment should be grounded in human-centered ultimate decision, supplemented by interpretable automated evaluation and correction, to achieve continuous alignment with humanity's evolving values. Intrinsic proactive superalignment is rooted in a profound understanding of the Self, others, and society, integrating self-awareness, self-reflection, and empathy to spontaneously infer human intentions, distinguishing good from evil and proactively prioritizing human well-being. The integration of externally-driven oversight with intrinsically-driven proactive alignment will co-shape symbiotic values and rules through iterative human-ASI co-alignment, paving the way for achieving safe and beneficial AGI and ASI for good, for human, and for a symbiotic ecology.",
      "authors": [
        "Yi Zeng",
        "Feifei Zhao",
        "Yuwei Wang",
        "Enmeng Lu",
        "Yaodong Yang",
        "Lei Wang",
        "Chao Liu",
        "Yitao Liang",
        "Dongcheng Zhao",
        "Bing Han",
        "Haibo Tong",
        "Yao Liang",
        "Dongqi Liang",
        "Kang Sun",
        "Boyuan Chen",
        "Jinyu Fan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-24T09:53:49+00:00",
          "link": "https://arxiv.org/abs/2504.17404v1",
          "size": "337kb",
          "version": "v1"
        },
        {
          "date": "2025-04-25T15:32:41+00:00",
          "link": "https://arxiv.org/abs/2504.17404v2",
          "size": "338kb",
          "version": "v2"
        },
        {
          "date": "2025-05-23T02:47:48+00:00",
          "link": "https://arxiv.org/abs/2504.17404v3",
          "size": "338kb",
          "version": "v3"
        },
        {
          "date": "2025-06-26T01:54:05+00:00",
          "link": "https://arxiv.org/abs/2504.17404v4",
          "size": "335kb",
          "version": "v4"
        },
        {
          "date": "2025-06-28T12:44:53+00:00",
          "link": "https://arxiv.org/abs/2504.17404v5",
          "size": "336kb",
          "version": "v5"
        }
      ],
      "title": "Super Co-alignment of Human and AI for Sustainable Symbiotic Society",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.17404",
        "HTML": "https://arxiv.org/html/2504.17404v5",
        "PDF": "https://arxiv.org/pdf/2504.17404"
      },
      "source": "arXiv"
    },
    {
      "id": "2504.17677",
      "abstract": "The rise of AI, especially Large Language Models, presents challenges and opportunities to integrate such technology into the classroom. AI has the potential to revolutionize education by helping teaching staff with various tasks, such as personalizing their teaching methods, but it also raises concerns, for example, about the degradation of student-teacher interactions and user privacy. Based on interviews with teaching staff, this paper introduces INSIGHT, a proof of concept to combine various AI tools to assist teaching staff and students in the process of solving exercises. INSIGHT has a modular design that allows it to be integrated into various higher education courses. We analyze students' questions to an LLM by extracting keywords, which we use to dynamically build an FAQ from students' questions and provide new insights for the teaching staff to use for more personalized face-to-face support. Future work could build upon INSIGHT by using the collected data to provide adaptive learning and adjust content based on student progress and learning styles to offer a more interactive and inclusive learning experience.",
      "authors": [
        "Jarne Thys",
        "Sebe Vanbrabant",
        "Davy Vanacken",
        "Gustavo Rovelo Ruiz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-24T15:47:20+00:00",
          "link": "https://arxiv.org/abs/2504.17677v1",
          "size": "1131kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T17:30:39+00:00",
          "link": "https://arxiv.org/abs/2504.17677v2",
          "size": "1055kb",
          "version": "v2"
        }
      ],
      "title": "INSIGHT: Bridging the Student-Teacher Gap in Times of Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.17677",
        "HTML": "https://arxiv.org/html/2504.17677v2",
        "PDF": "https://arxiv.org/pdf/2504.17677"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.18218",
      "abstract": "Partial vertex cover and partial dominating set are two well-investigated optimization problems. While they are $\\rm W[1]$-hard on general graphs, they have been shown to be fixed-parameter tractable on many sparse graph classes, including nowhere-dense classes. In this paper, we demonstrate that these problems are also fixed-parameter tractable with respect to the twin-width of a graph. Indeed, we establish a more general result: every graph property that can be expressed by a logical formula of the form $\\phi\\equiv\\exists x_1\\cdots \\exists x_k \\sum_{\\alpha \\in I} \\#y\\,\\psi_\\alpha(x_1,\\ldots,x_k,y)\\ge t$, where $\\psi_\\alpha$ is a quantifier-free formula for each $\\alpha \\in I$, $t$ is an arbitrary number, and $\\#y$ is a counting quantifier, can be evaluated in time $f(d,k)n$, where $n$ is the number of vertices and $d$ is the width of a contraction sequence that is part of the input. In addition to the aforementioned problems, this includes also connected partial dominating set and independent partial dominating set.",
      "authors": [
        "Jakub Balab\\'an",
        "Daniel Mock",
        "Peter Rossmanith"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Discrete Mathematics (cs.DM)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-25T09:59:11+00:00",
          "link": "https://arxiv.org/abs/2504.18218v1",
          "size": "129kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T15:42:31+00:00",
          "link": "https://arxiv.org/abs/2504.18218v2",
          "size": "130kb",
          "version": "v2"
        }
      ],
      "title": "Solving Partial Dominating Set and Related Problems Using Twin-Width",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.18218",
        "HTML": "https://arxiv.org/html/2504.18218v2",
        "PDF": "https://arxiv.org/pdf/2504.18218"
      },
      "source": "arXiv"
    },
    {
      "id": "2504.19308",
      "abstract": "We exploit the truncated singular value decomposition and the recently proposed circulant decomposition for an efficient first-order approximation of the multiplication of large dense matrices. A decomposition of each matrix into a sum of a sparse matrix with relatively few dominant entries and a dense residue can also use the above approach, and we present methods for multiplication using a Fourier decomposition and a cycle decomposition-based sparsifications. The proposed methods scale as $\\mathcal{O}(n^2 \\log n)$ in arithmetic operations for $n \\times n$ matrices for usable tolerances in relative error $\\sim$ 1\\%. Note that different decompositions for the two matrices $A$ and $B$ in the product $AB$ are also possible in this approach, using efficient a priori evaluations for suitability, to improve further on the error tolerances demonstrated here.",
      "authors": [
        "Suvendu Kar",
        "Hariprasad M.",
        "Sai Gowri J. N.",
        "and Murugesan Venkatapathi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-27T17:15:17+00:00",
          "link": "https://arxiv.org/abs/2504.19308v1",
          "size": "1014kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T10:26:04+00:00",
          "link": "https://arxiv.org/abs/2504.19308v2",
          "size": "1018kb",
          "version": "v2"
        }
      ],
      "title": "Efficient approximations of matrix multiplication using truncated decompositions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.19308",
        "HTML": "https://arxiv.org/html/2504.19308v2",
        "PDF": "https://arxiv.org/pdf/2504.19308"
      },
      "source": "arXiv"
    },
    {
      "id": "2504.19938",
      "abstract": "In this paper, we present a 3D reconstruction and rendering framework termed Mesh-Learner that is natively compatible with traditional rasterization pipelines. It integrates mesh and spherical harmonic (SH) texture (i.e., texture filled with SH coefficients) into the learning process to learn each mesh s view-dependent radiance end-to-end. Images are rendered by interpolating surrounding SH Texels at each pixel s sampling point using a novel interpolation method. Conversely, gradients from each pixel are back-propagated to the related SH Texels in SH textures. Mesh-Learner exploits graphic features of rasterization pipeline (texture sampling, deferred rendering) to render, which makes Mesh-Learner naturally compatible with tools (e.g., Blender) and tasks (e.g., 3D reconstruction, scene rendering, reinforcement learning for robotics) that are based on rasterization pipelines. Our system can train vast, unlimited scenes because we transfer only the SH textures within the frustum to the GPU for training. At other times, the SH textures are stored in CPU RAM, which results in moderate GPU memory usage. The rendering results on interpolation and extrapolation sequences in the Replica and FAST-LIVO2 datasets achieve state-of-the-art performance compared to existing state-of-the-art methods (e.g., 3D Gaussian Splatting and M2-Mapping). To benefit the society, the code will be available at https://github.com/hku-mars/Mesh-Learner.",
      "authors": [
        "Yunfei Wan",
        "Jianheng Liu",
        "Chunran Zheng",
        "Jiarong Lin and Fu Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-28T16:09:25+00:00",
          "link": "https://arxiv.org/abs/2504.19938v1",
          "size": "26626kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T06:22:18+00:00",
          "link": "https://arxiv.org/abs/2504.19938v2",
          "size": "2237kb",
          "version": "v2"
        }
      ],
      "title": "Mesh-Learner: Texturing Mesh with Spherical Harmonics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.19938",
        "HTML": "https://arxiv.org/html/2504.19938v2",
        "PDF": "https://arxiv.org/pdf/2504.19938"
      },
      "tasks": [
        "3D Reconstruction"
      ],
      "repo_urls": [
        "https://github.com/hku-mars/mesh-learner"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.20084",
      "abstract": "Recent breakthroughs in artificial intelligence (AI) have brought about increasingly capable systems that demonstrate remarkable abilities in reasoning, language understanding, and problem-solving. These advancements have prompted a renewed examination of AI awareness not as a philosophical question of consciousness, but as a measurable, functional capacity. AI awareness is a double-edged sword: it improves general capabilities, i.e., reasoning, safety, while also raising concerns around misalignment and societal risks, demanding careful oversight as AI capabilities grow.\n  In this review, we explore the emerging landscape of AI awareness, which includes metacognition (the ability to represent and reason about its own cognitive state), self-awareness (recognizing its own identity, knowledge, limitations, inter alia), social awareness (modeling the knowledge, intentions, and behaviors of other agents and social norms), and situational awareness (assessing and responding to the context in which it operates).\n  First, we draw on insights from cognitive science, psychology, and computational theory to trace the theoretical foundations of awareness and examine how the four distinct forms of AI awareness manifest in state-of-the-art AI. Next, we systematically analyze current evaluation methods and empirical findings to better understand these manifestations. Building on this, we explore how AI awareness is closely linked to AI capabilities, demonstrating that more aware AI agents tend to exhibit higher levels of intelligent behaviors. Finally, we discuss the risks associated with AI awareness, including key topics in AI safety, alignment, and broader ethical concerns.",
      "authors": [
        "Xiaojian Li",
        "Haoyuan Shi",
        "Rongwu Xu",
        "Wei Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-25T16:03:50+00:00",
          "link": "https://arxiv.org/abs/2504.20084v1",
          "size": "162kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T16:03:19+00:00",
          "link": "https://arxiv.org/abs/2504.20084v2",
          "size": "9055kb",
          "version": "v2"
        }
      ],
      "title": "AI Awareness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.20084",
        "HTML": "https://arxiv.org/html/2504.20084v2",
        "PDF": "https://arxiv.org/pdf/2504.20084"
      },
      "tasks": [
        "Safety Alignment"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.20367",
      "abstract": "What are the theoretical and physical limits of a grid-forming inverter? This letter proposes that the extreme grid-forming ability of inverters is limited by their dc-side, ac-side, circuit topology dynamics, but not control. While many papers focus on how to improve grid-forming inverters stability, power sharing, inertia emulation, fault response, few, if any, formally define the fundamental theoretical limits or extremes of grid-forming behavior. It seems that the grid-forming can be improved endlessly. No physical system can support a grid indefinitely without limitations, especially under increasing levels of disturbance or uncertainty. Therefore, this boundary is explicitly shown by a mathematical expression in this letter. Consequently, the results show that relatively low dc-side voltage and high active power injection could damage the grid-forming ability. Poor consideration of dc-side, ac-side, and circuit topology dynamics in real practice will cause jeopardizing oscillation even by the theoretical best grid-forming control strategy.",
      "authors": [
        "Qianxi Tang and Li Peng"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-29T02:12:23+00:00",
          "link": "https://arxiv.org/abs/2504.20367v1",
          "size": "808kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T15:17:41+00:00",
          "link": "https://arxiv.org/abs/2504.20367v2",
          "size": "808kb",
          "version": "v2"
        }
      ],
      "title": "Theoretical Grid-Forming Extreme of Inverters",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.20367",
        "HTML": "https://arxiv.org/html/2504.20367v2",
        "PDF": "https://arxiv.org/pdf/2504.20367"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2504.21160",
      "abstract": "This work proposes an $r$-adaptive finite element method (FEM) using neural networks (NNs). The method employs the Ritz energy functional as the loss function, currently limiting its applicability to symmetric and coercive problems, such as those arising from self-adjoint elliptic problems. The objective of the NN optimization is to determine the mesh node locations. For simplicity in two-dimensional problems, these locations are assumed to form a tensor product structure. The method is designed to solve parametric partial differential equations (PDEs). For each PDE parameter instance, the optimal $r$-adapted mesh generated by the NN is then solved with a standard FEM. The construction of FEM matrices and load vectors is implemented such that their derivatives with respect to mesh node locations, required for NN training, can be efficiently computed using automatic differentiation. However, the linear equation solver does not need to be differentiable, enabling the use of efficient, readily available `out-of-the-box' solvers. Consequently, the proposed approach retains the robustness and reliability guarantees of the FEM for each parameter instance, while the NN optimization adaptively adjusts the mesh node locations. The method's performance is demonstrated on parametric Poisson problems using one- and two-dimensional tensor product meshes.",
      "authors": [
        "Danilo Aballay",
        "Federico Fuentes",
        "Vicente Iligaray",
        "\\'Angel J. Omella",
        "David Pardo",
        "Manuel A. S\\'anchez",
        "Ignacio Tapia",
        "Carlos Uriarte"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-29T20:23:44+00:00",
          "link": "https://arxiv.org/abs/2504.21160v1",
          "size": "1209kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T21:01:24+00:00",
          "link": "https://arxiv.org/abs/2504.21160v2",
          "size": "7023kb",
          "version": "v2"
        }
      ],
      "title": "An $r$-adaptive finite element method using neural networks for parametric self-adjoint elliptic problem",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.21160",
        "HTML": "https://arxiv.org/html/2504.21160v2",
        "PDF": "https://arxiv.org/pdf/2504.21160"
      },
      "source": "arXiv"
    },
    {
      "id": "2505.01427",
      "abstract": "Concatenating matrices is a common technique for uncovering shared structures in data through singular value decomposition (SVD) and low-rank approximations. The fundamental question arises: How does the singular value spectrum of the concatenated matrix relate to the spectra of its individual components? In the present work, we develop a perturbation technique that extends classical results such as Weyl's inequality to concatenated matrices. We setup analytical bounds that quantify stability of singular values under small perturbations in submatrices. The results demonstrate that if submatrices are close in a norm, dominant singular values of the concatenated matrix remain stable enabling controlled trade-offs between accuracy and compression. These provide a theoretical basis for improved matrix clustering and compression strategies with applications in the numerical linear algebra, signal processing, and data-driven modeling.",
      "authors": [
        "Maksym Shamrai"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-11T09:28:57+00:00",
          "link": "https://arxiv.org/abs/2505.01427v1",
          "size": "8kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T16:31:24+00:00",
          "link": "https://arxiv.org/abs/2505.01427v2",
          "size": "10kb",
          "version": "v2"
        }
      ],
      "title": "Perturbation Analysis of Singular Values in Concatenated Matrices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.01427",
        "HTML": "https://arxiv.org/html/2505.01427v2",
        "PDF": "https://arxiv.org/pdf/2505.01427"
      },
      "source": "arXiv"
    },
    {
      "id": "2505.02118",
      "abstract": "This study investigates the self-rationalization framework constructed with a cooperative game, where a generator initially extracts the most informative segment from raw input, and a subsequent predictor utilizes the selected subset for its input. The generator and predictor are trained collaboratively to maximize prediction accuracy. In this paper, we first uncover a potential caveat: such a cooperative game could unintentionally introduce a sampling bias during rationale extraction. Specifically, the generator might inadvertently create an incorrect correlation between the selected rationale candidate and the label, even when they are semantically unrelated in the original dataset. Subsequently, we elucidate the origins of this bias using both detailed theoretical analysis and empirical evidence. Our findings suggest a direction for inspecting these correlations through attacks, based on which we further introduce an instruction to prevent the predictor from learning the correlations. Through experiments on six text classification datasets and two graph classification datasets using three network architectures (GRUs, BERT, and GCN), we show that our method not only significantly outperforms recent rationalization methods, but also achieves comparable or even better results than a representative LLM (llama3.1-8b-instruct).",
      "authors": [
        "Wei Liu",
        "Zhongyu Niu",
        "Lang Gao",
        "Zhiying Deng",
        "Jun Wang",
        "Haozhao Wang",
        "Ruixuan Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-04T14:00:04+00:00",
          "link": "https://arxiv.org/abs/2505.02118v1",
          "size": "484kb",
          "version": "v1"
        },
        {
          "date": "2025-05-06T07:07:13+00:00",
          "link": "https://arxiv.org/abs/2505.02118v2",
          "size": "484kb",
          "version": "v2"
        },
        {
          "date": "2025-05-11T05:57:46+00:00",
          "link": "https://arxiv.org/abs/2505.02118v3",
          "size": "738kb",
          "version": "v3"
        },
        {
          "date": "2025-06-29T02:25:46+00:00",
          "link": "https://arxiv.org/abs/2505.02118v4",
          "size": "489kb",
          "version": "v4"
        }
      ],
      "title": "Adversarial Cooperative Rationalization: The Risk of Spurious Correlations in Even Clean Datasets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.02118",
        "HTML": "https://arxiv.org/html/2505.02118v4",
        "PDF": "https://arxiv.org/pdf/2505.02118"
      },
      "tasks": [
        "Graph Classification",
        "text-classification",
        "Text Classification"
      ],
      "repo_urls": [
        "https://github.com/jugechengzi/rationalization-a2i"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.02811",
      "abstract": "Retrieval Augmented Generation (RAG) has shown strong capability in enhancing language models' knowledge and reducing AI generative hallucinations, driving its widespread use. However, complex tasks requiring multi-round retrieval remain challenging, and early attempts tend to be overly optimistic without a good sense of self-skepticism. Current multi-round RAG systems may continue searching even when enough information has already been retrieved, or they may provide incorrect answers without having sufficient information or knowledge. Existing solutions either require large amounts of expensive human-labeled process supervision data or lead to subpar performance. This paper aims to address these limitations by introducing a new framework, SIM-RAG, to explicitly enhance RAG systems' self-awareness and multi-round retrieval capabilities. To train SIM-RAG, we first let a RAG system self-practice multi-round retrieval, augmenting existing question-answer pairs with intermediate inner monologue reasoning steps to generate synthetic training data. For each pair, the system may explore multiple retrieval paths, which are labeled as successful if they reach the correct answer and unsuccessful otherwise. Using this data, we train a lightweight information sufficiency Critic. At inference time, the Critic evaluates whether the RAG system has retrieved sufficient information at each round, guiding retrieval decisions and improving system-level self-awareness through in-context reinforcement learning. Experiments across multiple prominent RAG benchmarks show that SIM-RAG is an effective multi-round RAG solution. Furthermore, this framework is system-efficient, adding a lightweight component to RAG without requiring modifications to existing LLMs or search engines, and data-efficient, eliminating the need for costly human-annotated mid-step retrieval process supervision data.",
      "authors": [
        "Diji Yang",
        "Linda Zeng",
        "Jinmeng Rao",
        "Yi Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-05T17:39:35+00:00",
          "link": "https://arxiv.org/abs/2505.02811v1",
          "size": "771kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T17:46:40+00:00",
          "link": "https://arxiv.org/abs/2505.02811v2",
          "size": "762kb",
          "version": "v2"
        }
      ],
      "title": "Knowing You Don't Know: Learning When to Continue Search in Multi-round RAG through Self-Practicing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.02811",
        "HTML": "https://arxiv.org/html/2505.02811v2",
        "PDF": "https://arxiv.org/pdf/2505.02811"
      },
      "tasks": [
        "In-Context Reinforcement Learning",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "repo_urls": [
        "https://github.com/ucscirkm/sim-rag"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.02922",
      "abstract": "The growing context lengths of large language models (LLMs) pose significant challenges for efficient inference, primarily due to GPU memory and bandwidth constraints. We present RetroInfer, a novel system that reconceptualizes the key-value (KV) cache as a vector storage system which exploits the inherent attention sparsity to accelerate long-context LLM inference. At its core is the wave index, an Attention-aWare VEctor index that enables efficient and accurate retrieval of critical tokens through techniques such as tripartite attention approximation, accuracy-bounded attention estimation, and segmented clustering. Complementing this is the wave buffer, which coordinates KV cache placement and overlaps computation and data transfer across GPU and CPU to sustain high throughput. Unlike prior sparsity-based methods that struggle with token selection and hardware coordination, RetroInfer delivers robust performance without compromising model accuracy. Experiments on long-context benchmarks show up to 4.5X speedup over full attention within GPU memory limits and up to 10.5X over sparse attention baselines when KV cache is extended to CPU memory, all while preserving full-attention-level accuracy.",
      "authors": [
        "Yaoqi Chen",
        "Jinkai Zhang",
        "Baotong Lu",
        "Qianxi Zhang",
        "Chengruidong Zhang",
        "Jingjia Luo",
        "Di Liu",
        "Huiqiang Jiang",
        "Qi Chen",
        "Jing Liu",
        "Bailu Ding",
        "Xiao Yan",
        "Jiawei Jiang",
        "Chen Chen",
        "Mingxing Zhang",
        "Yuqing Yang",
        "Fan Yang",
        "Mao Yang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-05T18:01:17+00:00",
          "link": "https://arxiv.org/abs/2505.02922v1",
          "size": "675kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T05:21:58+00:00",
          "link": "https://arxiv.org/abs/2505.02922v2",
          "size": "680kb",
          "version": "v2"
        }
      ],
      "title": "RetroInfer: A Vector-Storage Approach for Scalable Long-Context LLM Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.02922",
        "HTML": "https://arxiv.org/html/2505.02922v2",
        "PDF": "https://arxiv.org/pdf/2505.02922"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.04396",
      "abstract": "The planning and operation of renewable energy, especially wind power, depend crucially on accurate, timely, and high-resolution weather information. Coarse-grid global numerical weather forecasts are typically downscaled to meet these requirements, introducing challenges of scale inconsistency, process representation error, computation cost, and entanglement of distinct uncertainty sources from chaoticity, model bias, and large-scale forcing. We address these challenges by learning the climatological distribution of a target wind farm using its high-resolution numerical weather simulations. An optimal combination of this learned high-resolution climatological prior with coarse-grid large scale forecasts yields highly accurate, fine-grained, full-variable, large ensemble of weather pattern forecasts. Using observed meteorological records and wind turbine power outputs as references, the proposed methodology verifies advantageously compared to existing numerical/statistical forecasting-downscaling pipelines, regarding either deterministic/probabilistic skills or economic gains. Moreover, a 100-member, 10-day forecast with spatial resolution of 1 km and output frequency of 15 min takes < 1 hour on a moderate-end GPU, as contrast to $\\mathcal{O}(10^3)$ CPU hours for conventional numerical simulation. By drastically reducing computational costs while maintaining accuracy, our method paves the way for more efficient and reliable renewable energy planning and operation.",
      "authors": [
        "Jingnan Wang",
        "Jie Chao",
        "Shangshang Yang",
        "Kaijun Ren",
        "Kefeng Deng",
        "Xi Chen",
        "Yaxin Liu",
        "Hanqiuzi Wen",
        "Ziniu Xiao",
        "Lifeng Zhang",
        "Xiaodong Wang",
        "Jiping Guan",
        "Baoxiang Pan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-07T13:20:36+00:00",
          "link": "https://arxiv.org/abs/2505.04396v1",
          "size": "13991kb",
          "version": "v1"
        },
        {
          "date": "2025-06-25T08:04:43+00:00",
          "link": "https://arxiv.org/abs/2505.04396v2",
          "size": "13908kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T01:44:54+00:00",
          "link": "https://arxiv.org/abs/2505.04396v3",
          "size": "13908kb",
          "version": "v3"
        }
      ],
      "title": "Supporting renewable energy planning and operation with data-driven high-resolution ensemble weather forecast",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.04396",
        "HTML": "https://arxiv.org/html/2505.04396v3",
        "PDF": "https://arxiv.org/pdf/2505.04396"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.08228",
      "abstract": "Enhancing the robustness of object detection systems under adverse weather conditions is crucial for the advancement of autonomous driving technology. This study presents a novel approach leveraging the diffusion model Instruct Pix2Pix to develop prompting methodologies that generate realistic datasets with weather-based augmentations aiming to mitigate the impact of adverse weather on the perception capabilities of state-of-the-art object detection models, including Faster R-CNN and YOLOv10. Experiments were conducted in two environments, in the CARLA simulator where an initial evaluation of the proposed data augmentation was provided, and then on the real-world image data sets BDD100K and ACDC demonstrating the effectiveness of the approach in real environments.\n  The key contributions of this work are twofold: (1) identifying and quantifying the performance gap in object detection models under challenging weather conditions, and (2) demonstrating how tailored data augmentation strategies can significantly enhance the robustness of these models. This research establishes a solid foundation for improving the reliability of perception systems in demanding environmental scenarios, and provides a pathway for future advancements in autonomous driving.",
      "authors": [
        "Unai Gurbindo",
        "Axel Brando",
        "Jaume Abella and Caroline K\\\"onig"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-13T05:12:07+00:00",
          "link": "https://arxiv.org/abs/2505.08228v1",
          "size": "3406kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T05:56:45+00:00",
          "link": "https://arxiv.org/abs/2505.08228v2",
          "size": "3185kb",
          "version": "v2"
        }
      ],
      "title": "Object detection in adverse weather conditions for autonomous vehicles using Instruct Pix2Pix",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.08228",
        "HTML": "https://arxiv.org/html/2505.08228v2",
        "PDF": "https://arxiv.org/pdf/2505.08228"
      },
      "tasks": [
        "Autonomous Driving",
        "Autonomous Vehicles",
        "Data Augmentation",
        "Object",
        "object-detection",
        "Object Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.08300",
      "abstract": "Mocking is a common unit testing technique that is used to simplify tests, reduce flakiness, and improve coverage by replacing real dependencies with simplified implementations. Despite its widespread use in Open Source Software projects, there is limited understanding of how and why developers use mocks and the challenges they face. In this collaborative study, we have analyzed 25,302 questions related to Mocking on STACKOVERFLOW to identify the challenges faced by developers. We have used Latent Dirichlet Allocation for topic modeling, identified 30 key topics, and grouped the topics into five key categories. Consequently, we analyzed the annual and relative probabilities of each category to understand the evolution of mocking-related discussions. Trend analysis reveals that category like Advanced Programming peaked between 2009 and 2012 but have since declined, while categories such as Mocking Techniques and External Services have remained consistently dominant, highlighting evolving developer priorities and ongoing technical challenges. Our findings also show an inverse relationship between a topic's popularity and its difficulty. Popular topics like Framework Selection tend to have lower difficulty and faster resolution times, while complex topics like HTTP Requests and Responses are more likely to remain unanswered and take longer to resolve. A classification of questions into How, Why, What, and Other revealed that over 70% are How questions, particularly in practical domains like file access and APIs, indicating a strong need for implementation guidance. Why questions are more prevalent in error-handling contexts, reflecting conceptual challenges in debugging, while What questions are rare and mostly tied to theoretical discussions. These insights offer valuable guidance for improving developer support, tooling, and educational content in the context of mocking and unit testing.",
      "authors": [
        "Mumtahina Ahmed",
        "Md Nahidul Islam Opu",
        "Chanchal Roy",
        "Sujana Islam Suhi",
        "Shaiful Chowdhury"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-13T07:23:49+00:00",
          "link": "https://arxiv.org/abs/2505.08300v1",
          "size": "3399kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T16:42:48+00:00",
          "link": "https://arxiv.org/abs/2505.08300v2",
          "size": "3399kb",
          "version": "v2"
        }
      ],
      "title": "Exploring Challenges in Test Mocking: Developer Questions and Insights from StackOverflow",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.08300",
        "HTML": "https://arxiv.org/html/2505.08300v2",
        "PDF": "https://arxiv.org/pdf/2505.08300"
      },
      "source": "arXiv"
    },
    {
      "id": "2505.08842",
      "abstract": "Open-source AI libraries are foundational to modern AI systems, yet they present significant, underexamined risks spanning security, licensing, maintenance, supply chain integrity, and regulatory compliance. We introduce LibVulnWatch, a system that leverages recent advances in large language models and agentic workflows to perform deep, evidence-based evaluations of these libraries. Built on a graph-based orchestration of specialized agents, the framework extracts, verifies, and quantifies risk using information from repositories, documentation, and vulnerability databases. LibVulnWatch produces reproducible, governance-aligned scores across five critical domains, publishing results to a public leaderboard for ongoing ecosystem monitoring. Applied to 20 widely used libraries, including ML frameworks, LLM inference engines, and agent orchestration tools, our approach covers up to 88% of OpenSSF Scorecard checks while surfacing up to 19 additional risks per library, such as critical RCE vulnerabilities, missing SBOMs, and regulatory gaps. By integrating advanced language technologies with the practical demands of software risk assessment, this work demonstrates a scalable, transparent mechanism for continuous supply chain evaluation and informed library selection.",
      "authors": [
        "Zekun Wu",
        "Seonglae Cho",
        "Umar Mohammed",
        "Cristian Munoz",
        "Kleyton Costa",
        "Xin Guan",
        "Theo King",
        "Ze Wang",
        "Emre Kazim",
        "Adriano Koshiyama"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-13T12:58:11+00:00",
          "link": "https://arxiv.org/abs/2505.08842v1",
          "size": "3751kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T16:31:53+00:00",
          "link": "https://arxiv.org/abs/2505.08842v2",
          "size": "4124kb",
          "version": "v2"
        }
      ],
      "title": "LibVulnWatch: A Deep Assessment Agent System and Leaderboard for Uncovering Hidden Vulnerabilities in Open-Source AI Libraries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.08842",
        "HTML": "https://arxiv.org/html/2505.08842v2",
        "PDF": "https://arxiv.org/pdf/2505.08842"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.09450",
      "abstract": "Ultrasound-guided fine needle aspiration (FNA) biopsy is a common minimally invasive diagnostic procedure. However, an aspiration needle tracker addressing rapid reciprocating motion is still missing. MrTrack, an aspiration needle tracker with a mamba-based register mechanism, is proposed. MrTrack leverages a Mamba-based register extractor to sequentially distill global context from each historical search map, storing these temporal cues in a register bank. The Mamba-based register retriever then retrieves temporal prompts from the register bank to provide external cues when current vision features are temporarily unusable due to rapid reciprocating motion and imaging degradation. A self-supervised register diversify loss is proposed to encourage feature diversity and dimension independence within the learned register, mitigating feature collapse. Comprehensive experiments conducted on both robotic and manual aspiration biopsy datasets demonstrate that MrTrack not only outperforms state-of-the-art trackers in accuracy and robustness but also achieves superior inference efficiency. Project page: https://github.com/PieceZhang/MrTrack",
      "authors": [
        "Yuelin Zhang",
        "Qingpeng Ding",
        "Long Lei",
        "Yongxuan Feng",
        "Raymond Shing-Yan Tang",
        "Shing Shin Cheng"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-14T15:01:59+00:00",
          "link": "https://arxiv.org/abs/2505.09450v1",
          "size": "1474kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T07:40:24+00:00",
          "link": "https://arxiv.org/abs/2505.09450v2",
          "size": "1471kb",
          "version": "v2"
        }
      ],
      "title": "MrTrack: Register Mamba for Needle Tracking with Rapid Reciprocating Motion during Ultrasound-Guided Aspiration Biopsy",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.09450",
        "HTML": "https://arxiv.org/html/2505.09450v2",
        "PDF": "https://arxiv.org/pdf/2505.09450"
      },
      "tasks": [
        "Diagnostic",
        "Diversity",
        "Mamba"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.09539",
      "abstract": "Human annotations of mood in music are essential for music generation and recommender systems. However, existing datasets predominantly focus on Western songs with terms derived from English, which may limit generalizability across diverse linguistic and cultural backgrounds. We introduce 'GlobalMood', a novel cross-cultural benchmark dataset comprising 1,180 songs sampled from 59 countries, with large-scale annotations collected from 2,519 individuals across five culturally and linguistically distinct locations: U.S., France, Mexico, S. Korea, and Egypt. Rather than imposing predefined emotion and mood categories, we implement a bottom-up, participant-driven approach to organically elicit culturally specific music-related emotion terms. We then recruit another pool of human participants to collect 988,925 ratings for these culture-specific descriptors. Our analysis confirms the presence of a valence-arousal structure shared across cultures, yet also reveals significant divergences in how certain emotion terms (despite being dictionary equivalents) are perceived cross-culturally. State-of-the-art multimodal models benefit substantially from fine-tuning on our cross-culturally balanced dataset, particularly in non-English contexts. Broadly, our findings inform the ongoing debate on the universality versus cultural specificity of emotional descriptors, and our methodology can contribute to other multimodal and cross-lingual research.",
      "authors": [
        "Harin Lee",
        "Elif \\c{C}elen",
        "Peter Harrison",
        "Manuel Anglada-Tort",
        "Pol van Rijn",
        "Minsu Park",
        "Marc Sch\\\"onwiesner",
        "Nori Jacoby"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-14T16:32:45+00:00",
          "link": "https://arxiv.org/abs/2505.09539v1",
          "size": "1802kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T15:18:03+00:00",
          "link": "https://arxiv.org/abs/2505.09539v2",
          "size": "1885kb",
          "version": "v2"
        }
      ],
      "title": "GlobalMood: A cross-cultural benchmark for music emotion recognition",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.09539",
        "HTML": "https://arxiv.org/html/2505.09539v2",
        "PDF": "https://arxiv.org/pdf/2505.09539"
      },
      "tasks": [
        "Emotion Recognition",
        "Music Emotion Recognition",
        "Music Generation",
        "Recommendation Systems",
        "Specificity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.09769",
      "abstract": "Sequence-based specification and usage-driven statistical testing are designed for rigorous and cost-effective software development, offering a semi-formal approach to assessing the behavior of complex systems and interactions between various components. This approach is particularly valuable for scientific computing applications in which comprehensive tests are needed to prevent flawed results or conclusions. As scientific discovery becomes increasingly more complex, domain scientists couple multiple scientific computing models or simulations to solve intricate multiphysics and multiscale problems. These model-coupling applications use a hardwired coupling program or a flexible web service to link and combine different models. In this paper, we focus on the quality assurance of the more elastic web service via a combination of rigorous specification and testing methods. The application of statistical testing exposes problems ignored by pre-written unit tests and highlights areas in the code where failures might occur. We certify the model-coupling server controller with a derived reliability statistic, offering a quantitative measure to support a claim of its robustness.",
      "authors": [
        "Seth Wolfgang",
        "Lan Lin",
        "Fengguang Song"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-14T20:00:10+00:00",
          "link": "https://arxiv.org/abs/2505.09769v1",
          "size": "275kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T15:20:34+00:00",
          "link": "https://arxiv.org/abs/2505.09769v2",
          "size": "673kb",
          "version": "v2"
        }
      ],
      "title": "Automated Statistical Testing and Certification of a Reliable Model-Coupling Server for Scientific Computing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.09769",
        "HTML": "https://arxiv.org/html/2505.09769v2",
        "PDF": "https://arxiv.org/pdf/2505.09769"
      },
      "source": "arXiv"
    },
    {
      "id": "2505.10589",
      "abstract": "This study introduces an enhanced approach to video super-resolution by extending ordinary Single-Image Super-Resolution (SISR) Super-Resolution Generative Adversarial Network (SRGAN) structure to handle spatio-temporal data. While SRGAN has proven effective for single-image enhancement, its design does not account for the temporal continuity required in video processing. To address this, a modified framework that incorporates 3D Non-Local Blocks is proposed, which is enabling the model to capture relationships across both spatial and temporal dimensions. An experimental training pipeline is developed, based on patch-wise learning and advanced data degradation techniques, to simulate real-world video conditions and learn from both local and global structures and details. This helps the model generalize better and maintain stability across varying video content while maintaining the general structure besides the pixel-wise correctness. Two model variants-one larger and one more lightweight-are presented to explore the trade-offs between performance and efficiency. The results demonstrate improved temporal coherence, sharper textures, and fewer visual artifacts compared to traditional single-image methods. This work contributes to the development of practical, learning-based solutions for video enhancement tasks, with potential applications in streaming, gaming, and digital restoration.",
      "authors": [
        "Ka\\u{g}an \\c{C}et\\.in",
        "Hacer Ak\\c{c}a",
        "\\\"Omer Nezih Gerek"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-14T20:16:51+00:00",
          "link": "https://arxiv.org/abs/2505.10589v1",
          "size": "12325kb",
          "version": "v1"
        },
        {
          "date": "2025-05-19T03:54:02+00:00",
          "link": "https://arxiv.org/abs/2505.10589v2",
          "size": "12224kb",
          "version": "v2"
        },
        {
          "date": "2025-05-25T17:23:59+00:00",
          "link": "https://arxiv.org/abs/2505.10589v3",
          "size": "12224kb",
          "version": "v3"
        },
        {
          "date": "2025-06-29T18:08:46+00:00",
          "link": "https://arxiv.org/abs/2505.10589v4",
          "size": "12225kb",
          "version": "v4"
        }
      ],
      "title": "Super-Resolution Generative Adversarial Networks based Video Enhancement",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.10589",
        "HTML": "https://arxiv.org/html/2505.10589v4",
        "PDF": "https://arxiv.org/pdf/2505.10589"
      },
      "tasks": [
        "Generative Adversarial Network",
        "Image Enhancement",
        "Image Super-Resolution",
        "Super-Resolution",
        "Video Enhancement",
        "Video Super-Resolution"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.11640",
      "abstract": "In recent years, implicit neural representations (INRs) have gained popularity in the computer vision community. This is mainly due to the strong performance of INRs in many computer vision tasks. These networks can extract a continuous signal representation given a discrete signal representation. In previous studies, it has been repeatedly shown that INR performance has a strong correlation with the activation functions used in its multilayer perceptrons. Although numerous activation functions have been proposed that are competitive with one another, they share some common set of challenges such as spectral bias(Lack of sensitivity to high-frequency content in signals), limited robustness to signal noise and difficulties in simultaneous capturing both local and global features. and furthermore, the requirement for manual parameter tuning. To address these issues, we introduce a novel activation function, Band Shifted Raised Cosine Activated Implicit Neural Networks $\\textbf{(BandRC)}$ tailored to enhance signal representation capacity further. We also incorporate deep prior knowledge extracted from the signal to adjust the activation functions through a task-specific model. Through a mathematical analysis and a series of experiments which include image reconstruction (with an average PSNR improvement of +5.67 dB over the nearest counterpart across a diverse image dataset), denoising (with a +0.46 dB increase in PSNR), super-resolution (with a +1.03 dB improvement over the nearest State-Of-The-Art (SOTA) method for 6X super-resolution), inpainting, and 3D shape reconstruction we demonstrate the dominance of BandRC over existing state of the art activation functions.",
      "authors": [
        "Pandula Thennakoon",
        "Avishka Ranasinghe",
        "Mario De Silva",
        "Buwaneka Epakanda",
        "Roshan Godaliyadda",
        "Parakrama Ekanayake",
        "Vijitha Herath"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-16T19:08:01+00:00",
          "link": "https://arxiv.org/abs/2505.11640v1",
          "size": "18551kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T05:39:51+00:00",
          "link": "https://arxiv.org/abs/2505.11640v2",
          "size": "20335kb",
          "version": "v2"
        }
      ],
      "title": "BandRC: Band Shifted Raised Cosine Activated Implicit Neural Representations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.11640",
        "HTML": "https://arxiv.org/html/2505.11640v2",
        "PDF": "https://arxiv.org/pdf/2505.11640"
      },
      "tasks": [
        "3D Shape Reconstruction",
        "Denoising",
        "Image Reconstruction",
        "Super-Resolution"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.12182",
      "abstract": "Despite their remarkable success and deployment across diverse workflows, language models sometimes produce untruthful responses. Our limited understanding of how truthfulness is mechanistically encoded within these models jeopardizes their reliability and safety. In this paper, we propose a method for identifying representations of truthfulness at the neuron level. We show that language models contain truth neurons, which encode truthfulness in a subject-agnostic manner. Experiments conducted across models of varying scales validate the existence of truth neurons, confirming that the encoding of truthfulness at the neuron level is a property shared by many language models. The distribution patterns of truth neurons over layers align with prior findings on the geometry of truthfulness. Selectively suppressing the activations of truth neurons found through the TruthfulQA dataset degrades performance both on TruthfulQA and on other benchmarks, showing that the truthfulness mechanisms are not tied to a specific dataset. Our results offer novel insights into the mechanisms underlying truthfulness in language models and highlight potential directions toward improving their trustworthiness and reliability.",
      "authors": [
        "Haohang Li",
        "Yupeng Cao",
        "Yangyang Yu",
        "Jordan W. Suchow",
        "Zining Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-18T00:47:21+00:00",
          "link": "https://arxiv.org/abs/2505.12182v1",
          "size": "1726kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T18:14:07+00:00",
          "link": "https://arxiv.org/abs/2505.12182v2",
          "size": "1727kb",
          "version": "v2"
        }
      ],
      "title": "Truth Neurons",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12182",
        "HTML": "https://arxiv.org/html/2505.12182v2",
        "PDF": "https://arxiv.org/pdf/2505.12182"
      },
      "tasks": [
        "TruthfulQA"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.12884",
      "abstract": "Lightweight Vision-Language Models (VLMs) are indispensable for resource-constrained applications. The prevailing approach to aligning vision and language models involves freezing both the vision encoder and the language model while training small connector modules. However, this strategy heavily depends on the intrinsic capabilities of the language model, which can be suboptimal for lightweight models with limited representational capacity. In this work, we investigate this alignment bottleneck through the lens of mutual information, demonstrating that the constrained capacity of the language model inherently limits the Effective Mutual Information (EMI) between multimodal inputs and outputs, thereby compromising alignment quality. To address this challenge, we propose TinyAlign, a novel framework inspired by Retrieval-Augmented Generation, which strategically retrieves relevant context from a memory bank to enrich multimodal inputs and enhance their alignment. Extensive empirical evaluations reveal that TinyAlign significantly reduces training loss, accelerates convergence, and enhances task performance. Remarkably, it allows models to achieve baseline-level performance with only 40\\% of the fine-tuning data, highlighting exceptional data efficiency. Our work thus offers a practical pathway for developing more capable lightweight VLMs while introducing a fresh theoretical lens to better understand and address alignment bottlenecks in constrained multimodal systems.",
      "authors": [
        "Yuanze Hu",
        "Zhaoxin Fan",
        "Xinyu Wang",
        "Gen Li",
        "Ye Qiu",
        "Zhichao Yang",
        "Wenjun Wu",
        "Kejian Wu",
        "Yifan Sun",
        "Xiaotie Deng",
        "Jin Dong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T09:11:54+00:00",
          "link": "https://arxiv.org/abs/2505.12884v1",
          "size": "3430kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T08:29:25+00:00",
          "link": "https://arxiv.org/abs/2505.12884v2",
          "size": "12830kb",
          "version": "v2"
        }
      ],
      "title": "TinyAlign: Boosting Lightweight Vision-Language Models by Mitigating Modal Alignment Bottlenecks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12884",
        "HTML": "https://arxiv.org/html/2505.12884v2",
        "PDF": "https://arxiv.org/pdf/2505.12884"
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Retrieval-augmented Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.13271",
      "abstract": "Large language models (LLMs) have demonstrated strong capabilities in translating natural language questions about relational databases into SQL queries. In particular, test-time scaling techniques such as Self-Consistency and Self-Correction can enhance SQL generation accuracy by increasing computational effort during inference. However, these methods have notable limitations: Self-Consistency may select suboptimal outputs despite majority votes, while Self-Correction typically addresses only syntactic errors. To leverage the strengths of both approaches, we propose CSC-SQL, a novel method that integrates Self-Consistency and Self-Correction. CSC-SQL selects the two most frequently occurring outputs from parallel sampling and feeds them into a merge revision model for correction. Additionally, we employ the Group Relative Policy Optimization (GRPO) algorithm to fine-tune both the SQL generation and revision models via reinforcement learning, significantly enhancing output quality. Experimental results confirm the effectiveness and generalizability of CSC-SQL. On the BIRD private test set, our 7B model achieves 71.72\\% execution accuracy, while the 32B model achieves 73.67\\%. The code has been open sourced at https://github.com/CycloneBoy/csc_sql.",
      "authors": [
        "Lei Sheng and Shuai-Shuai Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T15:52:19+00:00",
          "link": "https://arxiv.org/abs/2505.13271v1",
          "size": "214kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T11:12:31+00:00",
          "link": "https://arxiv.org/abs/2505.13271v2",
          "size": "220kb",
          "version": "v2"
        }
      ],
      "title": "CSC-SQL: Corrective Self-Consistency in Text-to-SQL via Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.13271",
        "HTML": "https://arxiv.org/html/2505.13271v2",
        "PDF": "https://arxiv.org/pdf/2505.13271"
      },
      "tasks": [
        "Text to SQL",
        "Text-To-SQL"
      ],
      "repo_urls": [
        "https://github.com/cycloneboy/csc_sql"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.13325",
      "abstract": "In higher education, many institutions use algorithmic alerts to flag at-risk students and deliver advising at scale. While much research has focused on evaluating algorithmic predictions, relatively little is known about how discretionary interventions by human experts shape outcomes in algorithm-assisted settings. We study this question using rich quantitative and qualitative data from a randomized controlled trial of an algorithm-assisted advising program at Georgia State University. Taking a mixed-methods approach, we examine whether and how advisors use context unavailable to an algorithm to guide interventions and influence student success. We develop a causal graphical framework for human expertise in the interventional setting, extending prior work on discretion in purely predictive settings. We then test a necessary condition for discretionary expertise using structured advisor logs and student outcomes data, identifying several interventions that meet the criterion for statistical significance. Accordingly, we estimate that 2 out of 3 interventions taken by advisors in the treatment arm were plausibly \"expertly targeted\" to students using non-algorithmic context. Systematic qualitative analysis of advisor notes corroborates these findings, showing a pattern of advisors incorporating diverse forms of contextual information--such as personal circumstances, financial issues, and student engagement--into their decisions. Our results offer theoretical and practical insight into the real-world effectiveness of algorithm-supported college advising, and underscore the importance of accounting for human expertise in the design, evaluation, and implementation of algorithmic decision systems.",
      "authors": [
        "Kara Schechtman",
        "Benjamin Brandon",
        "Jenise Stafford",
        "Hannah Li",
        "Lydia T. Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Applications (stat.AP)",
        "Methodology (stat.ME)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T16:34:40+00:00",
          "link": "https://arxiv.org/abs/2505.13325v1",
          "size": "1005kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T19:46:45+00:00",
          "link": "https://arxiv.org/abs/2505.13325v2",
          "size": "361kb",
          "version": "v2"
        }
      ],
      "title": "Discretion in the Loop: Human Expertise in Algorithm-Assisted College Advising",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.13325",
        "HTML": "https://arxiv.org/html/2505.13325v2",
        "PDF": "https://arxiv.org/pdf/2505.13325"
      },
      "tasks": [
        "Heterogeneous Treatment Effect Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.13552",
      "abstract": "Modern comparison sorts like quicksort suffer from performance inconsistencies due to suboptimal pivot selection, leading to $O(N^2)$ worst-case complexity, while in-place merge sort variants face challenges with data movement overhead. We introduce Wave Sort, a novel in-place sorting algorithm that addresses these limitations through a dynamic pivot selection strategy. Wave Sort iteratively expands a sorted region and selects pivots from this growing sorted portion to partition adjacent unsorted data. This approach ensures robust pivot selection irrespective of dataset size, guarantees a logarithmic recursion stack depth, and enables efficient in-place sorting. Our analysis shows a worst-case comparison complexity bounded by $O(N(\\log N)^2)$ with a small constant factor. Experimental results demonstrate that Wave Sort requires significantly fewer comparisons than quicksort on average (approximately 24% less) and performs close to the theoretical minimum, while also incorporating adaptive techniques for efficient handling of presorted sequences. Wave Sort offers a compelling alternative for applications demanding consistent, predictable, and in-place sorting performance.",
      "authors": [
        "Jia Xu Wei"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T05:26:31+00:00",
          "link": "https://arxiv.org/abs/2505.13552v1",
          "size": "186kb",
          "version": "v1"
        },
        {
          "date": "2025-06-24T23:26:17+00:00",
          "link": "https://arxiv.org/abs/2505.13552v2",
          "size": "187kb",
          "version": "v2"
        }
      ],
      "title": "New Sorting Algorithm Wave Sort (W-Sort)",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.13552",
        "HTML": "https://arxiv.org/html/2505.13552v2",
        "PDF": "https://arxiv.org/pdf/2505.13552"
      },
      "source": "arXiv"
    },
    {
      "id": "2505.13768",
      "abstract": "This paper investigates a hybrid learning framework for reinforcement learning (RL) in which the agent can leverage both an offline dataset and online interactions to learn the optimal policy. We present a unified algorithm and analysis and show that augmenting confidence-based online RL algorithms with the offline dataset outperforms any pure online or offline algorithm alone and achieves state-of-the-art results under two learning metrics, i.e., sub-optimality gap and online learning regret. Specifically, we show that our algorithm achieves a sub-optimality gap $\\tilde{O}(\\sqrt{1/(N_0/\\mathtt{C}(\\pi^*|\\rho)+N_1}) )$, where $\\mathtt{C}(\\pi^*|\\rho)$ is a new concentrability coefficient, $N_0$ and $N_1$ are the numbers of offline and online samples, respectively. For regret minimization, we show that it achieves a constant $\\tilde{O}( \\sqrt{N_1/(N_0/\\mathtt{C}(\\pi^{-}|\\rho)+N_1)} )$ speed-up compared to pure online learning, where $\\mathtt{C}(\\pi^-|\\rho)$ is the concentrability coefficient over all sub-optimal policies. Our results also reveal an interesting separation on the desired coverage properties of the offline dataset for sub-optimality gap minimization and regret minimization. We further validate our theoretical findings in several experiments in special RL models such as linear contextual bandits and Markov decision processes (MDPs).",
      "authors": [
        "Ruiquan Huang",
        "Donghao Li",
        "Chengshuai Shi",
        "Cong Shen",
        "Jing Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-19T22:58:54+00:00",
          "link": "https://arxiv.org/abs/2505.13768v1",
          "size": "4919kb",
          "version": "v1"
        },
        {
          "date": "2025-05-23T21:30:12+00:00",
          "link": "https://arxiv.org/abs/2505.13768v2",
          "size": "4919kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T21:05:50+00:00",
          "link": "https://arxiv.org/abs/2505.13768v3",
          "size": "4920kb",
          "version": "v3"
        }
      ],
      "title": "Augmenting Online RL with Offline Data is All You Need: A Unified Hybrid RL Algorithm Design and Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.13768",
        "HTML": "https://arxiv.org/html/2505.13768v3",
        "PDF": "https://arxiv.org/pdf/2505.13768"
      },
      "tasks": [
        "All",
        "Multi-Armed Bandits",
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.14415",
      "abstract": "Table foundation models bring high hopes to data science: pre-trained on tabular data to embark knowledge or priors, they should facilitate downstream tasks on tables. One specific challenge is that of data semantics: numerical entries take their meaning from context, e.g., column name. Pre-trained neural networks that jointly model column names and table entries have recently boosted prediction accuracy. While these models outline the promises of world knowledge to interpret table values, they lack the convenience of popular foundation models in text or vision. Indeed, they must be fine-tuned to bring benefits, come with sizeable computation costs, and cannot easily be reused or combined with other architectures. Here we introduce TARTE, a foundation model that transforms tables to knowledge-enhanced vector representations using the string to capture semantics. Pre-trained on large relational data, TARTE yields representations that facilitate subsequent learning with little additional cost. These representations can be fine-tuned or combined with other learners, giving models that push the state-of-the-art prediction performance and improve the prediction/computation performance trade-off. Specialized to a task or a domain, TARTE gives domain-specific representations that facilitate further learning. Our study demonstrates an effective approach to knowledge pre-training for tabular learning.",
      "authors": [
        "Myung Jun Kim",
        "F\\'elix Lefebvre",
        "Ga\\\"etan Brison",
        "Alexandre Perez-Lebel",
        "and Ga\\\"el Varoquaux"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-20T14:27:51+00:00",
          "link": "https://arxiv.org/abs/2505.14415v1",
          "size": "453kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T15:48:16+00:00",
          "link": "https://arxiv.org/abs/2505.14415v2",
          "size": "464kb",
          "version": "v2"
        }
      ],
      "title": "Table Foundation Models: on knowledge pre-training for tabular learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.14415",
        "HTML": "https://arxiv.org/html/2505.14415v2",
        "PDF": "https://arxiv.org/pdf/2505.14415"
      },
      "tasks": [
        "World Knowledge"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.17312",
      "abstract": "LLMs often need effective configurations, like temperature and reasoning steps, to handle tasks requiring sophisticated reasoning and problem-solving, ranging from joke generation to mathematical reasoning. Existing prompting approaches usually adopt general-purpose, fixed configurations that work 'well enough' across tasks but seldom achieve task-specific optimality. To address this gap, we introduce AdaReasoner, an LLM-agnostic plugin designed for any LLM to automate adaptive reasoning configurations for tasks requiring different types of thinking. AdaReasoner is trained using a reinforcement learning (RL) framework, combining a factorized action space with a targeted exploration strategy, along with a pretrained reward model to optimize the policy model for reasoning configurations with only a few-shot guide. AdaReasoner is backed by theoretical guarantees and experiments of fast convergence and a sublinear policy gap. Across six different LLMs and a variety of reasoning tasks, it consistently outperforms standard baselines, preserves out-of-distribution robustness, and yield gains on knowledge-intensive tasks through tailored prompts.",
      "authors": [
        "Xiangqi Wang",
        "Yue Huang",
        "Yanbo Wang",
        "Xiaonan Luo",
        "Kehan Guo",
        "Yujun Zhou and Xiangliang Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-22T22:06:11+00:00",
          "link": "https://arxiv.org/abs/2505.17312v1",
          "size": "4335kb",
          "version": "v1"
        },
        {
          "date": "2025-06-05T23:39:29+00:00",
          "link": "https://arxiv.org/abs/2505.17312v2",
          "size": "2179kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T19:19:38+00:00",
          "link": "https://arxiv.org/abs/2505.17312v3",
          "size": "2179kb",
          "version": "v3"
        }
      ],
      "title": "AdaReasoner: Adaptive Reasoning Enables More Flexible Thinking in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.17312",
        "HTML": "https://arxiv.org/html/2505.17312v3",
        "PDF": "https://arxiv.org/pdf/2505.17312"
      },
      "source": "arXiv"
    },
    {
      "id": "2505.17662",
      "abstract": "Transformer-based models have shown strong performance across diverse time-series tasks, but their deployment on resource-constrained devices remains challenging due to high memory and computational demand. While prior work targeting Microcontroller Units (MCUs) has explored hardware-specific optimizations, such approaches are often task-specific and limited to 8-bit fixed-point precision. Field-Programmable Gate Arrays (FPGAs) offer greater flexibility, enabling fine-grained control over data precision and architecture. However, existing FPGA-based deployments of Transformers for time-series analysis typically focus on high-density platforms with manual configuration. This paper presents a unified and fully automated deployment framework for Tiny Transformers on embedded FPGAs. Our framework supports a compact encoder-only Transformer architecture across three representative time-series tasks (forecasting, classification, and anomaly detection). It combines quantization-aware training (down to 4 bits), hardware-aware hyperparameter search using Optuna, and automatic VHDL generation for seamless deployment. We evaluate our framework on six public datasets across two embedded FPGA platforms. Results show that our framework produces integer-only, task-specific Transformer accelerators achieving as low as 0.033 mJ per inference with millisecond latency on AMD Spartan-7, while also providing insights into deployment feasibility on Lattice iCE40. All source code will be released in the GitHub repository (https://github.com/Edwina1030/TinyTransformer4TS).",
      "authors": [
        "Tianheng Ling",
        "Chao Qian",
        "Lukas Johannes Ha{\\ss}ler",
        "Gregor Schiele"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-23T09:27:25+00:00",
          "link": "https://arxiv.org/abs/2505.17662v1",
          "size": "1778kb",
          "version": "v1"
        },
        {
          "date": "2025-06-02T13:38:07+00:00",
          "link": "https://arxiv.org/abs/2505.17662v2",
          "size": "1778kb",
          "version": "v2"
        },
        {
          "date": "2025-06-14T17:45:46+00:00",
          "link": "https://arxiv.org/abs/2505.17662v3",
          "size": "1777kb",
          "version": "v3"
        },
        {
          "date": "2025-06-29T14:00:27+00:00",
          "link": "https://arxiv.org/abs/2505.17662v4",
          "size": "1792kb",
          "version": "v4"
        }
      ],
      "title": "Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.17662",
        "HTML": "https://arxiv.org/html/2505.17662v4",
        "PDF": "https://arxiv.org/pdf/2505.17662"
      },
      "source": "arXiv"
    },
    {
      "id": "2505.18561",
      "abstract": "Reasoning Video Object Segmentation is a challenging task, which generates a mask sequence from an input video and an implicit, complex text query. Existing works probe into the problem by finetuning Multimodal Large Language Models (MLLM) for segmentation-based output, while still falling short in difficult cases on videos given temporally-sensitive queries, primarily due to the failure to integrate temporal and spatial information. In this paper, we propose ThinkVideo, a novel framework which leverages the zero-shot Chain-of-Thought (CoT) capability of MLLM to address these challenges. Specifically, ThinkVideo utilizes the CoT prompts to extract object selectivities associated with particular keyframes, then bridging the reasoning image segmentation model and SAM2 video processor to output mask sequences. The ThinkVideo framework is training-free and compatible with closed-source MLLMs, which can be applied to Reasoning Video Instance Segmentation. We further extend the framework for online video streams, where the CoT is used to update the object of interest when a better target starts to emerge and becomes visible. We conduct extensive experiments on video object segmentation with explicit and implicit queries. The results show that ThinkVideo significantly outperforms previous works in both cases, qualitatively and quantitatively.",
      "authors": [
        "Shiu-hong Kao",
        "Yu-Wing Tai",
        "Chi-Keung Tang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-24T07:01:31+00:00",
          "link": "https://arxiv.org/abs/2505.18561v1",
          "size": "3117kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T21:35:45+00:00",
          "link": "https://arxiv.org/abs/2505.18561v2",
          "size": "3117kb",
          "version": "v2"
        }
      ],
      "title": "ThinkVideo: High-Quality Reasoning Video Segmentation with Chain of Thoughts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.18561",
        "HTML": "https://arxiv.org/html/2505.18561v2",
        "PDF": "https://arxiv.org/pdf/2505.18561"
      },
      "tasks": [
        "Image Segmentation",
        "Instance Segmentation",
        "Object",
        "Reasoning Video Object Segmentation",
        "Segmentation",
        "Semantic Segmentation",
        "Video Instance Segmentation",
        "Video Object Segmentation",
        "Video Segmentation",
        "Video Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/danielshkao/thinkvideo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.18740",
      "abstract": "When regularity lemmas were first developed in the 1970s, they were described as results that promise a partition of any graph into a ``small'' number of parts, such that the graph looks ``similar'' to a random graph on its edge subsets going between parts. Regularity lemmas have been repeatedly refined and reinterpreted in the years since, and the modern perspective is that they can instead be seen as purely linear-algebraic results about sketching a large, complicated matrix with a smaller, simpler one. These matrix sketches then have a nice interpretation about partitions when applied to the adjacency matrix of a graph.\n  In these notes we will develop regularity lemmas from scratch, under the linear-algebraic perspective, and then use the linear-algebraic versions to derive the familiar graph versions. We do not assume any prior knowledge of regularity lemmas, and we recap the relevant linear-algebraic definitions as we go, but some comfort with linear algebra will definitely be helpful to read these notes.",
      "authors": [
        "Greg Bodwin and Tuong Le"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-24T15:20:23+00:00",
          "link": "https://arxiv.org/abs/2505.18740v1",
          "size": "20kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T18:16:54+00:00",
          "link": "https://arxiv.org/abs/2505.18740v2",
          "size": "19kb",
          "version": "v2"
        }
      ],
      "title": "Notes on the Linear Algebraic View of Regularity Lemmas",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.18740",
        "HTML": "https://arxiv.org/html/2505.18740v2",
        "PDF": "https://arxiv.org/pdf/2505.18740"
      },
      "source": "arXiv"
    },
    {
      "id": "2505.19816",
      "abstract": "We present a formal analysis, in Isabelle/HOL, of optimisation algorithms for matroids, which are useful generalisations of combinatorial structures that occur in optimisation, and greedoids, which are a generalisation of matroids. Although some formalisation work has been done earlier on matroids, our work here presents the first formalisation of results on greedoids, and many results we formalise in relation to matroids are also formalised for the first time in this work. We formalise the analysis of a number of optimisation algorithms for matroids and greedoids. We also derive from those algorithms executable implementations of Kruskal's algorithm for minimum spanning trees, an algorithm for maximum cardinality matching for bi-partite graphs, and Prim's algorithm for computing minimum weight spanning trees.",
      "authors": [
        "Mohammad Abdulaziz and Thomas Ammer and Shriya Meenakshisundaram and Adem Rimpapa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Data Structures and Algorithms (cs.DS)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T10:54:08+00:00",
          "link": "https://arxiv.org/abs/2505.19816v1",
          "size": "332kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T15:40:41+00:00",
          "link": "https://arxiv.org/abs/2505.19816v2",
          "size": "318kb",
          "version": "v2"
        }
      ],
      "title": "A Formal Analysis of Algorithms for Matroids and Greedoids",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.19816",
        "HTML": "https://arxiv.org/html/2505.19816v2",
        "PDF": "https://arxiv.org/pdf/2505.19816"
      },
      "repo_urls": [
        "https://github.com/mabdula/isabelle-graph-library"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.19961",
      "abstract": "We consider fair allocations of indivisible goods to agents with general monotone valuations. We observe that it is useful to introduce a new share-based fairness notion, the {\\em residual maximin share} (RMMS). This share is {\\em feasible} and {\\em self maximizing}. Its value is at least as large as the MXS for monotone valuations, and at least as large as $\\frac{2}{3}$-MMS for additive valuations. Known techniques easily imply the existence of partial allocations that are both RMMS and EFX, and complete allocations that are both RMMS and EFL. This unifies and somewhat improves upon several different results from previous papers.",
      "authors": [
        "Uriel Feige"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T13:22:03+00:00",
          "link": "https://arxiv.org/abs/2505.19961v1",
          "size": "12kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T08:11:08+00:00",
          "link": "https://arxiv.org/abs/2505.19961v2",
          "size": "13kb",
          "version": "v2"
        }
      ],
      "title": "The residual maximin share",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.19961",
        "HTML": "https://arxiv.org/html/2505.19961v2",
        "PDF": "https://arxiv.org/pdf/2505.19961"
      },
      "source": "arXiv"
    },
    {
      "id": "2505.20137",
      "abstract": "Predictive Coding (PC) offers a biologically plausible alternative to backpropagation for neural network training, yet struggles with deeper architectures. This paper identifies the root cause: an inherent signal decay problem where gradients attenuate exponentially with depth, becoming computationally negligible due to numerical precision constraints. To address this fundamental limitation, we introduce Error Optimization (EO), a novel reparameterization that preserves PC's theoretical properties while eliminating signal decay. By optimizing over prediction errors rather than states, EO enables signals to reach all layers simultaneously and without attenuation, converging orders of magnitude faster than standard PC. Experiments across multiple architectures and datasets demonstrate that EO matches backpropagation's performance even for deeper models where conventional PC struggles. Besides practical improvements, our work provides theoretical insight into PC dynamics and establishes a foundation for scaling biologically-inspired learning to deeper architectures on digital hardware and beyond.",
      "authors": [
        "C\\'edric Goemaere",
        "Gaspard Oliviers",
        "Rafal Bogacz",
        "Thomas Demeester"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T15:39:16+00:00",
          "link": "https://arxiv.org/abs/2505.20137v1",
          "size": "1298kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T10:02:50+00:00",
          "link": "https://arxiv.org/abs/2505.20137v2",
          "size": "1299kb",
          "version": "v2"
        }
      ],
      "title": "Error Optimization: Overcoming Exponential Signal Decay in Deep Predictive Coding Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20137",
        "HTML": "https://arxiv.org/html/2505.20137v2",
        "PDF": "https://arxiv.org/pdf/2505.20137"
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/cgoemaere/pc_error_optimization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.20272",
      "abstract": "Large Vision-Language Models (LVLMs) have demonstrated impressive general capabilities across a wide range of multi-modal tasks. However, the reasoning processes of LVLMs often suffer from unreliable outputs and limited interpretability. To address this, grounded visual reasoning has emerged as a promising paradigm that enforces responses anchored on salient visual evidence regions. However, existing approaches typically rely on costly supervision such as bounding box annotations, chain-of-thought rationale or external tool calls, limiting their scalability. In this work, we propose Ground-R1, a reinforcement learning framework that enables grounded visual reasoning without requiring explicit evidence or rationale annotations. Ground-R1 consists of a grounding phase that generates evidence region rollouts based on format constraints, and an answering phase that produces responses guided by both answer correctness and format adherence rewards. Extensive experiments across multiple visual reasoning benchmarks manifest that Ground-R1 achieves superior performance and exhibits emergent cognitive behaviors such as uncertainty awareness, spatial perception, and iterative refinement, offering a scalable and interpretable alternative to existing approaches.",
      "authors": [
        "Meng Cao",
        "Haoze Zhao",
        "Can Zhang",
        "Xiaojun Chang",
        "Ian Reid",
        "Xiaodan Liang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T17:51:47+00:00",
          "link": "https://arxiv.org/abs/2505.20272v1",
          "size": "3623kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T16:04:49+00:00",
          "link": "https://arxiv.org/abs/2505.20272v2",
          "size": "3623kb",
          "version": "v2"
        }
      ],
      "title": "Ground-R1: Incentivizing Grounded Visual Reasoning via Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20272",
        "HTML": "https://arxiv.org/html/2505.20272v2",
        "PDF": "https://arxiv.org/pdf/2505.20272"
      },
      "tasks": [
        "reinforcement-learning",
        "Reinforcement Learning",
        "Visual Reasoning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.20471",
      "abstract": "In this work, we present WeatherEdit, a novel weather editing pipeline for generating realistic weather effects with controllable types and severity in 3D scenes. Our approach is structured into two key components: weather background editing and weather particle construction. For weather background editing, we introduce an all-in-one adapter that integrates multiple weather styles into a single pretrained diffusion model, enabling the generation of diverse weather effects in 2D image backgrounds. During inference, we design a Temporal-View (TV-) attention mechanism that follows a specific order to aggregate temporal and spatial information, ensuring consistent editing across multi-frame and multi-view images. To construct the weather particles, we first reconstruct a 3D scene using the edited images and then introduce a dynamic 4D Gaussian field to generate snowflakes, raindrops and fog in the scene. The attributes and dynamics of these particles are precisely controlled through physical-based modelling and simulation, ensuring realistic weather representation and flexible severity adjustments. Finally, we integrate the 4D Gaussian field with the 3D scene to render consistent and highly realistic weather effects. Experiments on multiple driving datasets demonstrate that WeatherEdit can generate diverse weather effects with controllable condition severity, highlighting its potential for autonomous driving simulation in adverse weather. See project page: https://jumponthemoon.github.io/w-edit",
      "authors": [
        "Chenghao Qian",
        "Wenjing Li",
        "Yuhu Guo",
        "Gustav Markkula"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Emerging Technologies (cs.ET)",
        "Machine Learning (cs.LG)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T19:10:47+00:00",
          "link": "https://arxiv.org/abs/2505.20471v1",
          "size": "5599kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T14:05:39+00:00",
          "link": "https://arxiv.org/abs/2505.20471v2",
          "size": "5501kb",
          "version": "v2"
        }
      ],
      "title": "WeatherEdit: Controllable Weather Editing with 4D Gaussian Field",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20471",
        "HTML": "https://arxiv.org/html/2505.20471v2",
        "PDF": "https://arxiv.org/pdf/2505.20471"
      },
      "tasks": [
        "3D Generation",
        "3DGS",
        "3D scene Editing",
        "3D Scene Reconstruction",
        "Autonomous Driving",
        "Weather Editing"
      ],
      "repo_urls": [
        "https://github.com/Jumponthemoon/WeatherEdit"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.20618",
      "abstract": "This work introduces and rigorously analyzes a novel operator-splitting finite element scheme for approximating viscosity solutions of a broad class of constrained second-order partial differential equations. By decoupling the primary PDE evolution from the enforcement of constraints, the proposed method combines a stabilized finite element method for spatial discretization with an efficient semi-implicit time-stepping strategy.\n  The cornerstone of our analysis is a proof that the scheme satisfies a discrete comparison principle. We demonstrate that under a mild time-step restriction and with appropriate stabilization, the discrete operator yields an M-matrix, which is sufficient to guarantee the scheme's monotonicity and consequent $L^\\infty$-stability. These properties -- consistency, stability, and monotonicity -- are shown to be sufficient to prove convergence of the numerical approximation to the unique viscosity solution within the celebrated Barles--Souganidis framework. For solutions with enhanced regularity, we further establish an optimal-order error estimate of $O(\\Delta t + h^2)$.\n  The rigorously established stability of the scheme provides a blueprint for a novel Physics-Constrained Neural Operator (PCNO) architecture. We prove that by emulating the scheme's structure, the PCNO can provably break the curse of dimensionality for the challenging class of domain-to-solution mapping problems with complex topological variations, a problem for which standard learning approaches often fail. Numerical experiments for both a Hamilton-Jacobi equation with state constraints and a controlled reaction-diffusion system are presented to validate the theoretical findings and demonstrate the scheme's effectiveness.",
      "authors": [
        "Po-Yi Wu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T01:52:37+00:00",
          "link": "https://arxiv.org/abs/2505.20618v1",
          "size": "48kb",
          "version": "v1"
        },
        {
          "date": "2025-05-28T02:59:54+00:00",
          "link": "https://arxiv.org/abs/2505.20618v2",
          "size": "48kb",
          "version": "v2"
        },
        {
          "date": "2025-06-17T02:50:43+00:00",
          "link": "https://arxiv.org/abs/2505.20618v3",
          "size": "39kb",
          "version": "v3"
        },
        {
          "date": "2025-06-21T19:55:14+00:00",
          "link": "https://arxiv.org/abs/2505.20618v4",
          "size": "69kb",
          "version": "v4"
        },
        {
          "date": "2025-06-30T02:09:58+00:00",
          "link": "https://arxiv.org/abs/2505.20618v5",
          "size": "85kb",
          "version": "v5"
        }
      ],
      "title": "Convergent Operator-Splitting Scheme for Viscosity Solutions: A Foundation for Learning Domain-to-Solution Maps",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20618",
        "HTML": "https://arxiv.org/html/2505.20618v5",
        "PDF": "https://arxiv.org/pdf/2505.20618"
      },
      "source": "arXiv"
    },
    {
      "id": "2505.20868",
      "abstract": "Recent advances in expressive text-to-speech (TTS) have introduced diverse methods based on style embedding extracted from reference speech. However, synthesizing high-quality expressive speech remains challenging. We propose Spotlight-TTS, which exclusively emphasizes style via voiced-aware style extraction and style direction adjustment. Voiced-aware style extraction focuses on voiced regions highly related to style while maintaining continuity across different speech regions to improve expressiveness. We adjust the direction of the extracted style for optimal integration into the TTS model, which improves speech quality. Experimental results demonstrate that Spotlight-TTS achieves superior performance compared to baseline models in terms of expressiveness, overall speech quality, and style transfer capability. Our audio samples are publicly available.",
      "authors": [
        "Nam-Gyu Kim",
        "Deok-Hyeon Cho",
        "Seung-Bin Kim",
        "Seong-Whan Lee"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T08:20:01+00:00",
          "link": "https://arxiv.org/abs/2505.20868v1",
          "size": "166kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T12:42:04+00:00",
          "link": "https://arxiv.org/abs/2505.20868v2",
          "size": "167kb",
          "version": "v2"
        }
      ],
      "title": "Spotlight-TTS: Spotlighting the Style via Voiced-Aware Style Extraction and Style Direction Adjustment for Expressive Text-to-Speech",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20868",
        "HTML": "https://arxiv.org/html/2505.20868v2",
        "PDF": "https://arxiv.org/pdf/2505.20868"
      },
      "tasks": [
        "Style Transfer",
        "text-to-speech",
        "Text to Speech"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.21020",
      "abstract": "Accurate Subseasonal-to-Seasonal (S2S) ocean simulation is critically important for marine research, yet remains challenging due to its substantial thermal inertia and extended time delay. Machine learning (ML)-based models have demonstrated significant advancements in simulation accuracy and computational efficiency compared to traditional numerical methods. Nevertheless, a significant limitation of current ML models for S2S ocean simulation is their inadequate incorporation of physical consistency and the slow-changing properties of the ocean system. In this work, we propose a neural ocean model (NeuralOM) for S2S ocean simulation with a multi-scale interactive graph neural network to emulate diverse physical phenomena associated with ocean systems effectively. Specifically, we propose a multi-stage framework tailored to model the ocean's slowly changing nature. Additionally, we introduce a multi-scale interactive messaging module to capture complex dynamical behaviors, such as gradient changes and multiplicative coupling relationships inherent in ocean dynamics. Extensive experimental evaluations confirm that our proposed NeuralOM outperforms state-of-the-art models in S2S and extreme event simulation. The codes are available at https://github.com/YuanGao-YG/NeuralOM.",
      "authors": [
        "Yuan Gao",
        "Ruiqi Shu",
        "Hao Wu",
        "Fan Xu",
        "Yanfei Xiang",
        "Ruijian Gou",
        "Qingsong Wen",
        "Xian Wu",
        "Xiaomeng Huang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Atmospheric and Oceanic Physics (physics.ao-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T10:54:40+00:00",
          "link": "https://arxiv.org/abs/2505.21020v1",
          "size": "36440kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T12:38:39+00:00",
          "link": "https://arxiv.org/abs/2505.21020v2",
          "size": "36440kb",
          "version": "v2"
        }
      ],
      "title": "NeuralOM: Neural Ocean Model for Subseasonal-to-Seasonal Simulation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.21020",
        "HTML": "https://arxiv.org/html/2505.21020v2",
        "PDF": "https://arxiv.org/pdf/2505.21020"
      },
      "tasks": [
        "Computational Efficiency",
        "Graph Neural Network"
      ],
      "repo_urls": [
        "https://github.com/yuangao-yg/neuralom"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.21442",
      "abstract": "One-way functions (OWFs) form the foundation of modern cryptography, yet their unconditional existence remains a major open question. In this work, we study this question by exploring its relation to lossy reductions, i.e., reductions $R$ for which it holds that $I(X;R(X)) \\ll n$ for all distributions $X$ over inputs of size $n$. Our main result is that either OWFs exist or any lossy reduction for any promise problem $\\Pi$ runs in time $2^{\\Omega(\\log\\tau_\\Pi / \\log\\log n)}$, where $\\tau_\\Pi(n)$ is the infimum of the runtime of all (worst-case) solvers of $\\Pi$ on instances of size $n$. In fact, our result requires a milder condition, that $R$ is lossy for sparse uniform distributions (which we call mild-lossiness). It also extends to $f$-reductions as long as $f$ is a non-constant permutation-invariant Boolean function, which includes And-, Or-, Maj-, Parity-, Modulo$_k$, and Threshold$_k$-reductions.\n  Additionally, we show that worst-case to average-case Karp reductions and randomized encodings are special cases of mildly-lossy reductions and improve the runtime above as $2^{\\Omega(\\log \\tau_\\Pi)}$ when these mappings are considered. Restricting to weak fine-grained OWFs, this runtime can be further improved as $\\Omega(\\tau_\\Pi)$. Taking $\\Pi$ as $kSAT$, our results provide sufficient conditions under which (fine-grained) OWFs exist assuming the Exponential Time Hypothesis (ETH). Conversely, if (fine-grained) OWFs do not exist, we obtain impossibilities on instance compressions (Harnik and Naor, FOCS 2006) and instance randomizations of $kSAT$ under the ETH.\n  Finally, we partially extend these findings to the quantum setting; the existence of a pure quantum mildly-lossy reduction for $\\Pi$ within the runtime $2^{o(\\log\\tau_\\Pi / \\log\\log n)}$ implies the existence of one-way state generators.",
      "authors": [
        "Pouria Fallahpour",
        "Alex B. Grilo",
        "Garazi Muguruza and Mahshid Riahinia"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T17:15:30+00:00",
          "link": "https://arxiv.org/abs/2505.21442v1",
          "size": "80kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T09:24:50+00:00",
          "link": "https://arxiv.org/abs/2505.21442v2",
          "size": "79kb",
          "version": "v2"
        }
      ],
      "title": "Cryptography from Lossy Reductions: Towards OWFs from ETH, and Beyond",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.21442",
        "HTML": "https://arxiv.org/html/2505.21442v2",
        "PDF": "https://arxiv.org/pdf/2505.21442"
      },
      "source": "arXiv"
    },
    {
      "id": "2505.21807",
      "abstract": "Predictive modeling on tabular data is the cornerstone of many real-world applications. Although gradient boosting machines and some recent deep models achieve strong performance on tabular data, they often lack interpretability. On the other hand, large language models (LLMs) have demonstrated powerful capabilities to generate human-like reasoning and explanations, but remain under-performed for tabular data prediction. In this paper, we propose a new approach that leverages reasoning-based LLMs, trained using reinforcement learning, to perform more accurate and explainable predictions on tabular data. Our method introduces custom reward functions that guide the model not only toward better prediction accuracy but also toward human-understandable reasons for its predictions. The proposed method is evaluated on financial benchmark datasets and compared against established LLMs.",
      "authors": [
        "Tommy Xu",
        "Zhitian Zhang",
        "Xiangyu Sun",
        "Lauren Kelly Zung",
        "Hossein Hajimirsadeghi",
        "Greg Mori"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-27T22:23:11+00:00",
          "link": "https://arxiv.org/abs/2505.21807v1",
          "size": "166kb",
          "version": "v1"
        },
        {
          "date": "2025-05-29T14:02:15+00:00",
          "link": "https://arxiv.org/abs/2505.21807v2",
          "size": "166kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T02:01:55+00:00",
          "link": "https://arxiv.org/abs/2505.21807v3",
          "size": "167kb",
          "version": "v3"
        }
      ],
      "title": "TabReason: A Reinforcement Learning-Enhanced Reasoning LLM for Explainable Tabular Data Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.21807",
        "PDF": "https://arxiv.org/pdf/2505.21807"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.22046",
      "abstract": "Image-to-video (I2V) generation seeks to produce realistic motion sequences from a single reference image. Although recent methods exhibit strong temporal consistency, they often struggle when dealing with complex, non-repetitive human movements, leading to unnatural deformations. To tackle this issue, we present LatentMove, a DiT-based framework specifically tailored for highly dynamic human animation. Our architecture incorporates a conditional control branch and learnable face/body tokens to preserve consistency as well as fine-grained details across frames. We introduce Complex-Human-Videos (CHV), a dataset featuring diverse, challenging human motions designed to benchmark the robustness of I2V systems. We also introduce two metrics to assess the flow and silhouette consistency of generated videos with their ground truth. Experimental results indicate that LatentMove substantially improves human animation quality--particularly when handling rapid, intricate movements--thereby pushing the boundaries of I2V generation. The code, the CHV dataset, and the evaluation metrics will be available at https://github.com/ --.",
      "authors": [
        "Ashkan Taghipour and Morteza Ghahremani and Mohammed Bennamoun and Farid Boussaid and Aref Miri Rekavandi and Zinuo Li and Qiuhong Ke and Hamid Laga"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-28T07:10:49+00:00",
          "link": "https://arxiv.org/abs/2505.22046v1",
          "size": "12226kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T01:34:06+00:00",
          "link": "https://arxiv.org/abs/2505.22046v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "LatentMove: Towards Complex Human Movement Video Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.22046",
        "PDF": "https://arxiv.org/pdf/2505.22046"
      },
      "source": "arXiv"
    },
    {
      "id": "2505.22648",
      "abstract": "Addressing intricate real-world problems necessitates in-depth information seeking and multi-step reasoning. Recent progress in agentic systems, exemplified by Deep Research, underscores the potential for autonomous multi-step research. In this work, we present a cohesive paradigm for building end-to-end agentic information seeking agents from a data-centric and training-stage perspective. Our approach consists of four key stages: (1) browsing data construction, (2) trajectories sampling, (3) supervised fine-tuning for effective cold start, and (4) reinforcement learning for enhanced generalisation. We instantiate this framework in a web agent based on the ReAct, WebDancer. Empirical evaluations on the challenging information seeking benchmarks, GAIA and WebWalkerQA, demonstrate the strong performance of WebDancer, achieving considerable results and highlighting the efficacy of our training paradigm. Further analysis of agent training provides valuable insights and actionable, systematic pathways for developing more capable agentic models. The codes and demo will be released in https://github.com/Alibaba-NLP/WebAgent.",
      "authors": [
        "Jialong Wu",
        "Baixuan Li",
        "Runnan Fang",
        "Wenbiao Yin",
        "Liwen Zhang",
        "Zhengwei Tao",
        "Dingchu Zhang",
        "Zekun Xi",
        "Gang Fu",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Jingren Zhou"
      ],
      "license": "http://creativecommons.org/publicdomain/zero/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-28T17:57:07+00:00",
          "link": "https://arxiv.org/abs/2505.22648v1",
          "size": "1968kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T17:33:01+00:00",
          "link": "https://arxiv.org/abs/2505.22648v2",
          "size": "641kb",
          "version": "v2"
        }
      ],
      "title": "WebDancer: Towards Autonomous Information Seeking Agency",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.22648",
        "PDF": "https://arxiv.org/pdf/2505.22648"
      },
      "models": [
        {
          "model_path": "Alibaba-NLP/WebDancer-32B",
          "downloads": "60",
          "likes": "21",
          "trending_score": "17.0",
          "link": "https://huggingface.co/Alibaba-NLP/WebDancer-32B"
        }
      ],
      "tasks": [],
      "repo_urls": [
        "https://github.com/alibaba-nlp/webwalker",
        "https://github.com/alibaba-nlp/webagent"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.22768",
      "abstract": "Time series forecasting remains a challenging task for foundation models due to temporal heterogeneity, high dimensionality, and the lack of inherent symbolic structure. In this work, we propose DRAGON (Discrete Representation and Augmented Graph encoding Over de BruijN Graphs), a novel encoder that introduces Multivariate de Bruijn Graphs (MdBGs) to bridge the gap between symbolic representations and neural modeling. DRAGON discretizes continuous input sequences and maps them onto a fixed graph structure, enabling dynamic context recovery via graph-based attention. Integrated as an auxiliary module within a dual-branch architecture, DRAGON augments conventional CNN-based encoders with symbolic, structure-aware representations. All code developed for this study is available at: https://github.com/KurbanIntelligenceLab/MultdBG-Time-Series-Library",
      "authors": [
        "Mert Onur Cakiroglu",
        "Idil Bilge Altun",
        "Mehmet Dalkilic",
        "Elham Buxton and Hasan Kurban"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-28T18:36:26+00:00",
          "link": "https://arxiv.org/abs/2505.22768v1",
          "size": "761kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T04:29:45+00:00",
          "link": "https://arxiv.org/abs/2505.22768v2",
          "size": "349kb",
          "version": "v2"
        }
      ],
      "title": "Multivariate de Bruijn Graphs: A Symbolic Graph Framework for Time Series Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.22768",
        "HTML": "https://arxiv.org/html/2505.22768v2",
        "PDF": "https://arxiv.org/pdf/2505.22768"
      },
      "tasks": [
        "Time Series",
        "Time Series Forecasting"
      ],
      "repo_urls": [
        "https://github.com/kurbanintelligencelab/multdbg-time-series-library"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.22814",
      "abstract": "Manufacturing environments are becoming more complex and unpredictable due to factors such as demand variations and shorter product lifespans. This complexity requires real-time decision-making and adaptation to disruptions. Traditional control approaches highlight the need for advanced control strategies capable of overcoming unforeseen challenges, as they demonstrate limitations in responsiveness within dynamic industrial settings. Multi-agent systems address these challenges through decentralization of decision-making, enabling systems to respond dynamically to operational changes. However, current multi-agent systems encounter challenges related to real-time adaptation, context-aware decision-making, and the dynamic exploration of resource capabilities. Large language models provide the possibility to overcome these limitations through context-aware decision-making capabilities. This paper introduces a large language model-enabled control architecture for multi-agent manufacturing systems to dynamically explore resource capabilities in response to real-time disruptions. A simulation-based case study demonstrates that the proposed architecture improves system resilience and flexibility. The case study findings show improved throughput and efficient resource utilization compared to existing approaches.",
      "authors": [
        "Jonghan Lim",
        "Ilya Kovalenko"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-28T19:43:12+00:00",
          "link": "https://arxiv.org/abs/2505.22814v1",
          "size": "928kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T20:02:25+00:00",
          "link": "https://arxiv.org/abs/2505.22814v2",
          "size": "936kb",
          "version": "v2"
        }
      ],
      "title": "A Large Language Model-Enabled Control Architecture for Dynamic Resource Capability Exploration in Multi-Agent Manufacturing Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.22814",
        "HTML": "https://arxiv.org/html/2505.22814v2",
        "PDF": "https://arxiv.org/pdf/2505.22814"
      },
      "tasks": [
        "Decision Making",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.23331",
      "abstract": "Fine-tuning pre-trained generative models with Reinforcement Learning (RL) has emerged as an effective approach for aligning outputs more closely with nuanced human preferences. In this paper, we investigate the application of Group Relative Policy Optimization (GRPO) to fine-tune next-scale visual autoregressive (VAR) models. Our empirical results demonstrate that this approach enables alignment to intricate reward signals derived from aesthetic predictors and CLIP embeddings, significantly enhancing image quality and enabling precise control over the generation style. Interestingly, by leveraging CLIP, our method can help VAR models generalize beyond their initial ImageNet distribution: through RL-driven exploration, these models can generate images aligned with prompts referencing image styles that were absent during pre-training. In summary, we show that RL-based fine-tuning is both efficient and effective for VAR models, benefiting particularly from their fast inference speeds, which are advantageous for online sampling, an aspect that poses significant challenges for diffusion-based alternatives.",
      "authors": [
        "Matteo Gallici",
        "Haitz S\\'aez de Oc\\'ariz Borde"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T10:45:38+00:00",
          "link": "https://arxiv.org/abs/2505.23331v1",
          "size": "19130kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T18:55:07+00:00",
          "link": "https://arxiv.org/abs/2505.23331v2",
          "size": "19130kb",
          "version": "v2"
        }
      ],
      "title": "Fine-Tuning Next-Scale Visual Autoregressive Models with Group Relative Policy Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23331",
        "HTML": "https://arxiv.org/html/2505.23331v2",
        "PDF": "https://arxiv.org/pdf/2505.23331"
      },
      "tasks": [
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.23575",
      "abstract": "As AI models are deployed with increasing autonomy, it is important to ensure they do not take harmful actions unnoticed. As a potential mitigation, we investigate Chain-of-Thought (CoT) monitoring, wherein a weaker trusted monitor model continuously oversees the intermediate reasoning steps of a more powerful but untrusted model. We compare CoT monitoring to action-only monitoring, where only final outputs are reviewed, in a red-teaming setup where the untrusted model is instructed to pursue harmful side tasks while completing a coding problem. We find that CoT monitoring improves detection by up to 27 percentage points in scenarios where action-only monitoring fails to reliably identify sabotage. However, CoT traces can also contain misleading rationalizations that deceive the monitor, reducing performance in more obvious sabotage cases. To address this, we introduce a hybrid protocol that independently scores both reasoning and final outputs and combines them using a weighted average. This hybrid monitor consistently outperforms both CoT and action-only monitors across all tested models and tasks, with detection rates over four times higher than action-only monitoring for subtle deception scenarios.",
      "authors": [
        "Benjamin Arnav",
        "Pablo Bernabeu-P\\'erez",
        "Nathan Helm-Burger",
        "Tim Kostolansky",
        "Hannes Whittingham",
        "Mary Phuong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T15:47:36+00:00",
          "link": "https://arxiv.org/abs/2505.23575v1",
          "size": "3866kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T09:01:41+00:00",
          "link": "https://arxiv.org/abs/2505.23575v2",
          "size": "2978kb",
          "version": "v2"
        }
      ],
      "title": "CoT Red-Handed: Stress Testing Chain-of-Thought Monitoring",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23575",
        "HTML": "https://arxiv.org/html/2505.23575v2",
        "PDF": "https://arxiv.org/pdf/2505.23575"
      },
      "tasks": [
        "Red Teaming"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.24302",
      "abstract": "Large Language Models (LLMs) are increasingly used to support scientific research, but their knowledge of scientific advancements can quickly become outdated. We introduce ScienceMeter, a new framework for evaluating scientific knowledge update methods over scientific knowledge spanning the past, present, and future. ScienceMeter defines three metrics: knowledge preservation, the extent to which models' understanding of previously learned papers are preserved; knowledge acquisition, how well scientific claims from newly introduced papers are acquired; and knowledge projection, the ability of the updated model to anticipate or generalize to related scientific claims that may emerge in the future. Using ScienceMeter, we examine the scientific knowledge of LLMs on claim judgment and generation tasks across a curated dataset of 15,444 scientific papers and 30,888 scientific claims from ten domains including medicine, biology, materials science, and computer science. We evaluate five representative knowledge update approaches including training- and inference-time methods. With extensive experiments, we find that the best-performing knowledge update methods can preserve only 85.9% of existing knowledge, acquire 71.7% of new knowledge, and project 37.7% of future knowledge. Inference-based methods work for larger models, whereas smaller models require training to achieve comparable performance. Cross-domain analysis reveals that performance on these objectives is correlated. Even when applying on specialized scientific LLMs, existing knowledge update methods fail to achieve these objectives collectively, underscoring that developing robust scientific knowledge update mechanisms is both crucial and challenging.",
      "authors": [
        "Yike Wang",
        "Shangbin Feng",
        "Yulia Tsvetkov",
        "Hannaneh Hajishirzi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-30T07:28:20+00:00",
          "link": "https://arxiv.org/abs/2505.24302v1",
          "size": "924kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T05:08:03+00:00",
          "link": "https://arxiv.org/abs/2505.24302v2",
          "size": "825kb",
          "version": "v2"
        }
      ],
      "title": "ScienceMeter: Tracking Scientific Knowledge Updates in Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.24302",
        "HTML": "https://arxiv.org/html/2505.24302v2",
        "PDF": "https://arxiv.org/pdf/2505.24302"
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/yikee/sciencemeter"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.00309",
      "abstract": "Large Language Models (LLMs) have shown impressive performance on a range of educational tasks, but are still understudied for their potential to solve mathematical problems. In this study, we compare three prominent LLMs, including GPT-4o, DeepSeek-V3, and Gemini-2.0, on three mathematics datasets of varying complexities (GSM8K, MATH500, and MIT Open Courseware datasets). We take a five-dimensional approach based on the Structured Chain-of-Thought (SCoT) framework to assess final answer correctness, step completeness, step validity, intermediate calculation accuracy, and problem comprehension. The results show that GPT-4o is the most stable and consistent in performance across all the datasets, but particularly it performs outstandingly in high-level questions of the MIT Open Courseware dataset. DeepSeek-V3 is competitively strong in well-structured domains such as optimisation, but suffers from fluctuations in accuracy in statistical inference tasks. Gemini-2.0 shows strong linguistic understanding and clarity in well-structured problems but performs poorly in multi-step reasoning and symbolic logic. Our error analysis reveals particular deficits in each model: GPT-4o is at times lacking in sufficient explanation or precision; DeepSeek-V3 leaves out intermediate steps; and Gemini-2.0 is less flexible in mathematical reasoning in higher dimensions.",
      "authors": [
        "Ruonan Wang",
        "Runxi Wang",
        "Yunwen Shen",
        "Chengfeng Wu",
        "Qinglin Zhou",
        "Rohitash Chandra"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-30T23:37:37+00:00",
          "link": "https://arxiv.org/abs/2506.00309v1",
          "size": "9538kb",
          "version": "v1"
        },
        {
          "date": "2025-06-12T02:09:17+00:00",
          "link": "https://arxiv.org/abs/2506.00309v2",
          "size": "9538kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T05:54:45+00:00",
          "link": "https://arxiv.org/abs/2506.00309v3",
          "size": "9538kb",
          "version": "v3"
        }
      ],
      "title": "Evaluation of LLMs for mathematical problem solving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.00309",
        "HTML": "https://arxiv.org/html/2506.00309v3",
        "PDF": "https://arxiv.org/pdf/2506.00309"
      },
      "tasks": [
        "GSM8K",
        "Mathematical Problem-Solving",
        "Mathematical Reasoning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.00924",
      "abstract": "This paper introduces a dual-layer framework for network operator-side quality of experience (QoE) assessment that integrates both objective network modeling and subjective user perception extracted from live-streaming platforms. On the objective side, we develop a machine learning model trained on mean opinion scores (MOS) computed via the ITU-T P.1203 reference implementation, allowing accurate prediction of user-perceived video quality using only network parameters such as packet loss, delay, jitter, and throughput without reliance on video content or client-side instrumentation. On the subjective side, we present a semantic filtering and scoring pipeline that processes user comments from live streams to extract performance-related feedback. A large language model is used to assign scalar MOS scores to filtered comments in a deterministic and reproducible manner. To support scalable and interpretable analysis, we construct a labeled dataset of 47,894 live-stream comments, of which about 34,000 are identified as QoE-relevant through multi-layer semantic filtering. Each comment is enriched with simulated Internet Service Provider attribution and temporally aligned using synthetic timestamps in 5-min intervals. The resulting dataset enables operator-level aggregation and time-series analysis of user-perceived quality. A delta MOS metric is proposed to measure each Internet service provider's deviation from platform-wide sentiment, allowing detection of localized degradations even in the absence of direct network telemetry. A controlled outage simulation confirms the framework's effectiveness in identifying service disruptions through comment-based trends alone. The system provides each operator with its own subjective MOS and the global platform average per interval, enabling real-time interpretation of performance deviations and comparison with objective network-based QoE estimates.",
      "authors": [
        "Parsa Hassani Shariat Panahi",
        "Amir Hossein Jalilvand",
        "and M. Hassan Najafi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-01T09:31:55+00:00",
          "link": "https://arxiv.org/abs/2506.00924v1",
          "size": "551kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T05:21:31+00:00",
          "link": "https://arxiv.org/abs/2506.00924v2",
          "size": "3383kb",
          "version": "v2"
        }
      ],
      "title": "Bridging Subjective and Objective QoE: Operator-Level Aggregation Using LLM-Based Comment Analysis and Network MOS Comparison",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.00924",
        "HTML": "https://arxiv.org/html/2506.00924v2",
        "PDF": "https://arxiv.org/pdf/2506.00924"
      },
      "tasks": [
        "Large Language Model",
        "Time Series Analysis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.02606",
      "abstract": "This paper presents Symbiosis of Agents, is a large-scale installation by Baoyang Chen (baoyangchen.com), that embeds AI-driven robots in an immersive, mirror-lined arena, probing the tension between machine agency and artistic authorship. Drawing on early cybernetics, rule-based conceptual art, and seminal robotic works, it orchestrates fluid exchanges among robotic arms, quadruped machines, their environment, and the public. A three tier faith system pilots the ecology: micro-level adaptive tactics, meso-level narrative drives, and a macro-level prime directive. This hierarchy lets behaviors evolve organically in response to environmental cues and even a viewer's breath, turning spectators into co-authors of the unfolding drama. Framed by a speculative terraforming scenario that recalls the historical exploitation of marginalized labor, the piece asks who bears responsibility in AI-mediated futures. Choreographed motion, AI-generated scripts, reactive lighting, and drifting fog cast the robots as collaborators rather than tools, forging a living, emergent artwork. Exhibited internationally, Symbiosis of Agents shows how cybernetic feedback, robotic experimentation, and conceptual rule-making can converge to redefine agency, authorship, and ethics in contemporary art.",
      "authors": [
        "Baoyang Chen",
        "Xian Xu",
        "Huamin Qu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-03T08:28:19+00:00",
          "link": "https://arxiv.org/abs/2506.02606v1",
          "size": "23600kb",
          "version": "v1"
        },
        {
          "date": "2025-06-04T04:57:32+00:00",
          "link": "https://arxiv.org/abs/2506.02606v2",
          "size": "23600kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T02:37:31+00:00",
          "link": "https://arxiv.org/abs/2506.02606v3",
          "size": "23600kb",
          "version": "v3"
        }
      ],
      "title": "Multi Layered Autonomy and AI Ecologies in Robotic Art Installations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.02606",
        "HTML": "https://arxiv.org/html/2506.02606v3",
        "PDF": "https://arxiv.org/pdf/2506.02606"
      },
      "tasks": [
        "Ethics"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.03660",
      "abstract": "Anomaly detection (AD) is essential for industrial inspection and medical diagnosis, yet existing methods typically rely on ``comparing'' test images to normal references from a training set. However, variations in appearance and positioning often complicate the alignment of these references with the test image, limiting detection accuracy. We observe that most anomalies manifest as local variations, meaning that even within anomalous images, valuable normal information remains. We argue that this information is useful and may be more aligned with the anomalies since both the anomalies and the normal information originate from the same image. Therefore, rather than relying on external normality from the training set, we propose INP-Former, a novel method that extracts Intrinsic Normal Prototypes (INPs) directly from the test image. Specifically, we introduce the INP Extractor, which linearly combines normal tokens to represent INPs. We further propose an INP Coherence Loss to ensure INPs can faithfully represent normality for the testing image. These INPs then guide the INP-guided Decoder to reconstruct only normal tokens, with reconstruction errors serving as anomaly scores. Additionally, we propose a Soft Mining Loss to prioritize hard-to-optimize samples during training. INP-Former achieves state-of-the-art performance in single-class, multi-class, and few-shot AD tasks across MVTec-AD, VisA, and Real-IAD, positioning it as a versatile and universal solution for AD. Remarkably, INP-Former also demonstrates some zero-shot AD capability. Furthermore, we propose a soft version of the INP Coherence Loss and enhance INP-Former by incorporating residual learning, leading to the development of INP-Former++. The proposed method significantly improves detection performance across single-class, multi-class, semi-supervised, few-shot, and zero-shot settings.",
      "authors": [
        "Wei Luo",
        "Haiming Yao",
        "Yunkang Cao",
        "Qiyu Chen",
        "Ang Gao",
        "Weiming Shen",
        "Wenyong Yu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T07:49:11+00:00",
          "link": "https://arxiv.org/abs/2506.03660v1",
          "size": "16722kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T13:33:45+00:00",
          "link": "https://arxiv.org/abs/2506.03660v2",
          "size": "16722kb",
          "version": "v2"
        }
      ],
      "title": "INP-Former++: Advancing Universal Anomaly Detection via Intrinsic Normal Prototypes and Residual Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03660",
        "HTML": "https://arxiv.org/html/2506.03660v2",
        "PDF": "https://arxiv.org/pdf/2506.03660"
      },
      "tasks": [
        "Anomaly Detection",
        "Medical Diagnosis"
      ],
      "repo_urls": [
        "https://github.com/luow23/inp-former"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.04133",
      "abstract": "Agentic AI systems, built upon large language models (LLMs) and deployed in multi-agent configurations, are redefining intelligence, autonomy, collaboration, and decision-making across enterprise and societal domains. This review presents a structured analysis of \\textbf{Trust, Risk, and Security Management (TRiSM)} in the context of LLM-based Agentic Multi-Agent Systems (AMAS). We begin by examining the conceptual foundations of Agentic AI and highlight its architectural distinctions from traditional AI agents. We then adapt and extend the AI TRiSM framework for Agentic AI, structured around four key pillars: Governance, Explainability, ModelOps, and Privacy/Security , each contextualized to the challenges of multi-agent LLM systems. A novel risk taxonomy is proposed to capture the unique threats and vulnerabilities of Agentic AI, ranging from coordination failures to prompt-based adversarial manipulation. To support practical assessment in Agentic AI works, we introduce two novel metrics: the Component Synergy Score (CSS), which quantifies the quality of inter-agent collaboration, and the Tool Utilization Efficacy (TUE), which evaluates the efficiency of tool use within agent workflows. We further discuss strategies for improving explainability in Agentic AI , as well as approaches to enhancing security and privacy through encryption, adversarial robustness, and regulatory compliance. The review concludes with a research roadmap for the responsible development and deployment of Agentic AI, outlining critical directions to align emerging systems with TRiSM principles for safe, transparent, and accountable operation.",
      "authors": [
        "Shaina Raza",
        "Ranjan Sapkota",
        "Manoj Karkee",
        "Christos Emmanouilidis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T16:26:11+00:00",
          "link": "https://arxiv.org/abs/2506.04133v1",
          "size": "879kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T20:26:07+00:00",
          "link": "https://arxiv.org/abs/2506.04133v2",
          "size": "5055kb",
          "version": "v2"
        }
      ],
      "title": "TRiSM for Agentic AI: A Review of Trust, Risk, and Security Management in LLM-based Agentic Multi-Agent Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04133",
        "HTML": "https://arxiv.org/html/2506.04133v2",
        "PDF": "https://arxiv.org/pdf/2506.04133"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.04487",
      "abstract": "We provide evidence that orthogonalizing gradients during training improves model calibration without sacrificing accuracy. On CIFAR-10 with 10\\% labeled data, $\\perp$Grad matches SGD in accuracy but yields consistently improved calibration metrics such as lower test loss, reduced softmax overconfidence, and higher predictive entropy. These benefits persist under input corruption (CIFAR-10C) and extended training, where $\\perp$Grad models degrade more gracefully than SGD-trained counterparts. $\\perp$Grad is optimizer-agnostic, incurs minimal overhead, and works well with post-hoc calibration techniques like temperature scaling.\n  Theoretically, we prove convergence of a simplified version of $\\perp$Grad under mild assumptions and characterize its stationary points in positive homogeneous networks: $\\perp$Grad converges to solutions where further loss reduction requires confidence scaling rather than decision boundary improvement. Code for this paper can be found at: https://github.com/evanshedges2/orthograd\\_improves\\_calibration.",
      "authors": [
        "C. Evans Hedges"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T22:12:46+00:00",
          "link": "https://arxiv.org/abs/2506.04487v1",
          "size": "1117kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T16:19:43+00:00",
          "link": "https://arxiv.org/abs/2506.04487v2",
          "size": "1117kb",
          "version": "v2"
        }
      ],
      "title": "Orthogonal Gradient Descent Improves Neural Calibration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04487",
        "HTML": "https://arxiv.org/html/2506.04487v2",
        "PDF": "https://arxiv.org/pdf/2506.04487"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.04953",
      "abstract": "Current multimodal large language models (MLLMs) struggle with hour-level video understanding, facing significant challenges not only in modeling the substantial information volume of long videos but also in overcoming the memory wall and resource constraints during both training and inference. Although recent training-free approaches have alleviated resource demands by compressing visual features, their reliance on incomplete visual information limits the performance potential. To address these limitations, we propose \\textbf{A}daptive \\textbf{P}ivot \\textbf{V}isual information \\textbf{R}etrieval (\\textbf{APVR}), a training-free framework that hierarchically retrieves and retains sufficient and important visual information. It breakthroughs the memory wall limitation via two complementary components: Pivot Frame Retrieval employs query expansion and iterative spatio-semantic confidence scoring to identify relevant video frames, and Pivot Token Retrieval performs query-aware attention-driven token selection within up to 1024 pivot frames. This dual granularity approach enables the processing of hour-long videos while maintaining semantic fidelity. Experimental validations demonstrate significant performance improvements, achieving 64.9\\% on LongVideoBench and 68.4\\% on VideoMME, which are state-of-the-art results for both training-free and training-based approaches. Meanwhile, our method provides plug-and-play integration capability with existing MLLM architectures.",
      "authors": [
        "Hong Gao",
        "Yiming Bao",
        "Xuezhen Tu",
        "Bin Zhong",
        "Minling Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-05T12:27:10+00:00",
          "link": "https://arxiv.org/abs/2506.04953v1",
          "size": "2176kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T07:30:15+00:00",
          "link": "https://arxiv.org/abs/2506.04953v2",
          "size": "2307kb",
          "version": "v2"
        }
      ],
      "title": "APVR: Hour-Level Long Video Understanding with Adaptive Pivot Visual Information Retrieval",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04953",
        "HTML": "https://arxiv.org/html/2506.04953v2",
        "PDF": "https://arxiv.org/pdf/2506.04953"
      },
      "tasks": [
        "Information Retrieval",
        "Retrieval",
        "Temporal Sequences",
        "Video Understanding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.04998",
      "abstract": "Autonomous UAV operation necessitates reliable mathematical reasoning for tasks such as trajectory planning and power management. While traditional flight control relies on hardcoded equations, recent Large Language Models (LLMs) offer potential for more flexible problem-solving but struggle with reliably selecting and applying correct mathematical formulations and executing precise multi-step arithmetic. We propose RAG-UAV, a retrieval-augmented generation framework designed to improve the mathematical reasoning of several LLMs (including GPT o1/Turbo, Llama-3.2/3.3, Mistral, and DeepSeek R1) in UAV-specific contexts by providing access to relevant domain literature. To conduct an initial assessment, we introduce the UAV-Math-Bench, a 20-question problem set of UAV-centric mathematical problems across four difficulty levels. Our experiments demonstrate that incorporating retrieval substantially increases exact answer accuracy (achieving up to 75% with o1), reduces instances of incorrect formulation selection (from 25% without RAG to 5\\% with RAG), and decreases numerical errors, reducing Mean Squared Error (MSE) by orders of magnitude for the best-performing models. This pilot study indicates that RAG can enable general-purpose LLMs to function as more reliable tools for engineering analysis, although direct real-time flight control requires further investigation and validation on a larger scale. All benchmark data, questions, and answers are publicly available.",
      "authors": [
        "Mehdi Azarafza",
        "Mojtaba Nayyeri",
        "Faezeh Pasandideh",
        "Steffen Staab",
        "Achim Rettberg"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-05T13:09:24+00:00",
          "link": "https://arxiv.org/abs/2506.04998v1",
          "size": "2051kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T13:18:47+00:00",
          "link": "https://arxiv.org/abs/2506.04998v2",
          "size": "2974kb",
          "version": "v2"
        }
      ],
      "title": "Mathematical Reasoning for Unmanned Aerial Vehicles: A RAG-Based Approach for Complex Arithmetic Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04998",
        "HTML": "https://arxiv.org/html/2506.04998v2",
        "PDF": "https://arxiv.org/pdf/2506.04998"
      },
      "tasks": [
        "Arithmetic Reasoning",
        "Math",
        "Mathematical Reasoning",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation",
        "Trajectory Planning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.05008",
      "abstract": "Radar has gained much attention in autonomous driving due to its accessibility and robustness. However, its standalone application for depth perception is constrained by issues of sparsity and noise. Radar-camera depth estimation offers a more promising complementary solution. Despite significant progress, current approaches fail to produce satisfactory dense depth maps, due to the unsatisfactory processing of the sparse and noisy radar data. They constrain the regions of interest for radar points in rigid rectangular regions, which may introduce unexpected errors and confusions. To address these issues, we develop a structure-aware strategy for radar depth enhancement, which provides more targeted regions of interest by leveraging the structural priors of RGB images. Furthermore, we design a Multi-Scale Structure Guided Network to enhance radar features and preserve detailed structures, achieving accurate and structure-detailed dense metric depth estimation. Building on these, we propose a structure-aware radar-camera depth estimation framework, named SA-RCD. Extensive experiments demonstrate that our SA-RCD achieves state-of-the-art performance on the nuScenes dataset. Our code will be available at https://github.com/FreyZhangYeh/SA-RCD.",
      "authors": [
        "Fuyi Zhang",
        "Zhu Yu",
        "Chunhao Li",
        "Runmin Zhang",
        "Xiaokai Bai",
        "Zili Zhou",
        "Si-Yuan Cao",
        "Fang Wang",
        "Hui-Liang Shen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-05T13:18:48+00:00",
          "link": "https://arxiv.org/abs/2506.05008v1",
          "size": "1853kb",
          "version": "v1"
        },
        {
          "date": "2025-06-09T03:55:26+00:00",
          "link": "https://arxiv.org/abs/2506.05008v2",
          "size": "1853kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T03:21:04+00:00",
          "link": "https://arxiv.org/abs/2506.05008v3",
          "size": "1853kb",
          "version": "v3"
        }
      ],
      "title": "Structure-Aware Radar-Camera Depth Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.05008",
        "HTML": "https://arxiv.org/html/2506.05008v3",
        "PDF": "https://arxiv.org/pdf/2506.05008"
      },
      "tasks": [
        "Depth Estimation",
        "Monocular Depth Estimation",
        "regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.05210",
      "abstract": "Multimodal foundation models have demonstrated strong generalization, yet their ability to transfer knowledge to specialized domains such as garment generation remains underexplored. We introduce VLG, a vision-language-garment model that synthesizes garments from textual descriptions and visual imagery. Our experiments assess VLG's zero-shot generalization, investigating its ability to transfer web-scale reasoning to unseen garment styles and prompts. Preliminary results indicate promising transfer capabilities, highlighting the potential for multimodal foundation models to adapt effectively to specialized domains like fashion design.",
      "authors": [
        "Jan Ackermann",
        "Kiyohiro Nakayama",
        "Guandao Yang",
        "Tong Wu",
        "Gordon Wetzstein"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-05T16:22:17+00:00",
          "link": "https://arxiv.org/abs/2506.05210v1",
          "size": "643kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T12:16:27+00:00",
          "link": "https://arxiv.org/abs/2506.05210v2",
          "size": "646kb",
          "version": "v2"
        }
      ],
      "title": "Towards Vision-Language-Garment Models for Web Knowledge Garment Understanding and Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.05210",
        "HTML": "https://arxiv.org/html/2506.05210v2",
        "PDF": "https://arxiv.org/pdf/2506.05210"
      },
      "tasks": [
        "Zero-shot Generalization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.05626",
      "abstract": "Real-world knowledge can take various forms, including structured, semi-structured, and unstructured data. Among these, knowledge graphs are a form of structured human knowledge that integrate heterogeneous data sources into structured representations but typically reduce complex n-ary relations to simple triples, thereby losing higher-order relational details. In contrast, hypergraphs naturally represent n-ary relations with hyperedges, which directly connect multiple entities together. Yet hypergraph representation learning often overlooks entity roles in hyperedges, limiting the finegrained semantic modelling. To address these issues, knowledge hypergraphs and hyper-relational knowledge graphs combine the advantages of knowledge graphs and hypergraphs to better capture the complex structures and role-specific semantics of real world knowledge. This survey provides a comprehensive review of methods handling n-ary relational data, covering both knowledge hypergraphs and hyper-relational knowledge graphs literatures. We propose a two-dimensional taxonomy: the first dimension categorises models based on their methodology, i.e., translation-based models, tensor factorisation-based models, deep neural network-based models, logic rules-based models, and hyperedge expansion-based models. The second dimension classifies models according to their awareness of entity roles and positions in n-ary relations, dividing them into aware-less, position-aware, and role-aware approaches. Finally, we discuss existing datasets, training settings and strategies, and outline open challenges to inspire future research.",
      "authors": [
        "Xiaohua Lu",
        "Liubov Tupikina",
        "Mehwish Alam"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-05T22:59:39+00:00",
          "link": "https://arxiv.org/abs/2506.05626v1",
          "size": "1955kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T19:40:42+00:00",
          "link": "https://arxiv.org/abs/2506.05626v2",
          "size": "522kb",
          "version": "v2"
        }
      ],
      "title": "Two-dimensional Taxonomy for N-ary Knowledge Representation Learning Methods",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.05626",
        "HTML": "https://arxiv.org/html/2506.05626v2",
        "PDF": "https://arxiv.org/pdf/2506.05626"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.06633",
      "abstract": "Recent advancements in quantum machine learning have shown promise in enhancing classical neural network architectures, particularly in domains involving complex, high-dimensional data. Building upon prior work in temporal sequence modeling, this paper introduces Vision-QRWKV, a hybrid quantum-classical extension of the Receptance Weighted Key Value (RWKV) architecture, applied for the first time to image classification tasks. By integrating a variational quantum circuit (VQC) into the channel mixing component of RWKV, our model aims to improve nonlinear feature transformation and enhance the expressive capacity of visual representations.\n  We evaluate both classical and quantum RWKV models on a diverse collection of 14 medical and standard image classification benchmarks, including MedMNIST datasets, MNIST, and FashionMNIST. Our results demonstrate that the quantum-enhanced model outperforms its classical counterpart on a majority of datasets, particularly those with subtle or noisy class distinctions (e.g., ChestMNIST, RetinaMNIST, BloodMNIST). This study represents the first systematic application of quantum-enhanced RWKV in the visual domain, offering insights into the architectural trade-offs and future potential of quantum models for lightweight and efficient vision tasks.",
      "authors": [
        "Chi-Sheng Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-07T02:53:18+00:00",
          "link": "https://arxiv.org/abs/2506.06633v1",
          "size": "644kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T08:08:52+00:00",
          "link": "https://arxiv.org/abs/2506.06633v2",
          "size": "286kb",
          "version": "v2"
        }
      ],
      "title": "Vision-QRWKV: Exploring Quantum-Enhanced RWKV Models for Image Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.06633",
        "HTML": "https://arxiv.org/html/2506.06633v2",
        "PDF": "https://arxiv.org/pdf/2506.06633"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.07085",
      "abstract": "State entropy regularization has empirically shown better exploration and sample complexity in reinforcement learning (RL). However, its theoretical guarantees have not been studied. In this paper, we show that state entropy regularization improves robustness to structured and spatially correlated perturbations. These types of variation are common in transfer learning but often overlooked by standard robust RL methods, which typically focus on small, uncorrelated changes. We provide a comprehensive characterization of these robustness properties, including formal guarantees under reward and transition uncertainty, as well as settings where the method performs poorly. Much of our analysis contrasts state entropy with the widely used policy entropy regularization, highlighting their different benefits. Finally, from a practical standpoint, we illustrate that compared with policy entropy, the robustness advantages of state entropy are more sensitive to the number of rollouts used for policy evaluation.",
      "authors": [
        "Yonatan Ashlag",
        "Uri Koren",
        "Mirco Mutti",
        "Esther Derman",
        "Pierre-Luc Bacon",
        "Shie Mannor"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-08T11:15:31+00:00",
          "link": "https://arxiv.org/abs/2506.07085v1",
          "size": "591kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T14:11:45+00:00",
          "link": "https://arxiv.org/abs/2506.07085v2",
          "size": "591kb",
          "version": "v2"
        }
      ],
      "title": "State Entropy Regularization for Robust Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07085",
        "HTML": "https://arxiv.org/html/2506.07085v2",
        "PDF": "https://arxiv.org/pdf/2506.07085"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.07160",
      "abstract": "Recent advances in large language models (LLMs) have demonstrated remarkable capabilities across diverse domains, particularly in mathematical reasoning, amid which geometry problem solving remains a challenging area where auxiliary construction plays a enssential role. Existing approaches either achieve suboptimal performance or rely on massive LLMs (e.g., GPT-4o), incurring massive computational costs. We posit that reinforcement learning with verifiable reward (e.g., GRPO) offers a promising direction for training smaller models that effectively combine auxiliary construction with robust geometric reasoning. However, directly applying GRPO to geometric reasoning presents fundamental limitations due to its dependence on unconditional rewards, which leads to indiscriminate and counterproductive auxiliary constructions. To address these challenges, we propose Group Contrastive Policy Optimization (GCPO), a novel reinforcement learning framework featuring two key innovations: (1) Group Contrastive Masking, which adaptively provides positive or negative reward signals for auxiliary construction based on contextual utility, and a (2) length reward that promotes longer reasoning chains. Building on GCPO, we develop GeometryZero, a family of affordable-size geometric reasoning models that judiciously determine when to employ auxiliary construction. Our extensive empirical evaluation across popular geometric benchmarks (Geometry3K, MathVista) demonstrates that GeometryZero models consistently outperform baselines (e.g. GRPO), achieving an average improvement of 4.29% across all benchmarks.",
      "authors": [
        "Yikun Wang",
        "Yibin Wang",
        "Dianyi Wang",
        "Zimian Peng",
        "Qipeng Guo",
        "Dacheng Tao",
        "Jiaqi Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-08T14:18:15+00:00",
          "link": "https://arxiv.org/abs/2506.07160v1",
          "size": "1035kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T13:36:32+00:00",
          "link": "https://arxiv.org/abs/2506.07160v2",
          "size": "1034kb",
          "version": "v2"
        }
      ],
      "title": "GeometryZero: Improving Geometry Solving for LLM with Group Contrastive Policy Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07160",
        "HTML": "https://arxiv.org/html/2506.07160v2",
        "PDF": "https://arxiv.org/pdf/2506.07160"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.07193",
      "abstract": "Eye tracking technology is frequently utilized to diagnose eye and neurological disorders, assess sleep and fatigue, study human visual perception, and enable novel gaze-based interaction methods. However, traditional eye tracking methodologies are constrained by bespoke hardware that is often cumbersome to wear, complex to apply, and demands substantial computational resources. To overcome these limitations, we investigated Electrooculography (EOG) eye tracking using 14 electrodes positioned around the ears, integrated into a custom-built headphone form factor device. In a controlled experiment, 16 participants tracked stimuli designed to induce smooth pursuits and saccades. Data analysis identified optimal electrode pairs for vertical and horizontal eye movement tracking, benchmarked against gold-standard EOG and camera-based methods. The electrode montage nearest the eyes yielded the best horizontal results. Horizontal smooth pursuits via earEOG showed high correlation with gold-standard measures ($r_{\\mathrm{EOG}} = 0.81, p = 0.01$; $r_{\\mathrm{CAM}} = 0.56, p = 0.02$), while vertical pursuits were weakly correlated ($r_{\\mathrm{EOG}} = 0.28, p = 0.04$; $r_{\\mathrm{CAM}} = 0.35, p = 0.05$). Voltage deflections when performing saccades showed strong correlation in the horizontal direction ($r_{\\mathrm{left}} = 0.99, p = 0.0$; $r_{\\mathrm{right}} = 0.99, p = 0.0$) but low correlation in the vertical direction ($r_{\\mathrm{up}} = 0.6, p = 0.23$; $r_{\\mathrm{down}} = 0.19, p = 0.73$). Overall, horizontal earEOG demonstrated strong performance, indicating its potential effectiveness, while vertical earEOG results were poor, suggesting limited feasibility in our current setup.",
      "authors": [
        "Tobias King",
        "Michael Knierim",
        "Philipp Lepold",
        "Christopher Clarke",
        "Hans Gellersen",
        "Michael Beigl",
        "Tobias R\\\"oddiger"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-08T15:28:51+00:00",
          "link": "https://arxiv.org/abs/2506.07193v1",
          "size": "5476kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T09:54:18+00:00",
          "link": "https://arxiv.org/abs/2506.07193v2",
          "size": "5473kb",
          "version": "v2"
        }
      ],
      "title": "earEOG via Periauricular Electrodes to Facilitate Eye Tracking in a Natural Headphone Form Factor",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07193",
        "HTML": "https://arxiv.org/html/2506.07193v2",
        "PDF": "https://arxiv.org/pdf/2506.07193"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.07217",
      "abstract": "Existing computer-use agents primarily focus on general-purpose desktop automation tasks, with limited exploration of their application in highly specialized domains. In particular, the 3D building modeling process in the Architecture, Engineering, and Construction (AEC) sector involves open-ended design tasks and complex interaction patterns within Building Information Modeling (BIM) authoring software, which has yet to be thoroughly addressed by current studies. In this paper, we propose BIMgent, an agentic framework powered by multimodal large language models (LLMs), designed to enable autonomous building model authoring via graphical user interface (GUI) operations. BIMgent automates the architectural building modeling process, including multimodal input for conceptual design, planning of software-specific workflows, and efficient execution of the authoring GUI actions. We evaluate BIMgent on real-world building modeling tasks, including both text-based conceptual design generation and reconstruction from existing building design. The design quality achieved by BIMgent was found to be reasonable. Its operations achieved a 32% success rate, whereas all baseline models failed to complete the tasks (0% success rate). Results demonstrate that BIMgent effectively reduces manual workload while preserving design intent, highlighting its potential for practical deployment in real-world architectural modeling scenarios. Project page: https://tumcms.github.io/BIMgent.github.io/",
      "authors": [
        "Zihan Deng",
        "Changyu Du",
        "Stavros Nousias",
        "Andr\\'e Borrmann"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-08T16:45:31+00:00",
          "link": "https://arxiv.org/abs/2506.07217v1",
          "size": "11036kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T08:31:07+00:00",
          "link": "https://arxiv.org/abs/2506.07217v2",
          "size": "13294kb",
          "version": "v2"
        }
      ],
      "title": "BIMgent: Towards Autonomous Building Modeling via Computer-use Agents",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07217",
        "HTML": "https://arxiv.org/html/2506.07217v2",
        "PDF": "https://arxiv.org/pdf/2506.07217"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.07239",
      "abstract": "Modern chip design is complex, and there is a crucial need for early-stage prediction of key design-quality metrics like timing and routing congestion directly from Verilog code (a commonly used programming language for hardware design). It is especially important yet complex to predict individual lines of code that cause timing violations or downstream routing congestion. Prior works have tried approaches like converting Verilog into an intermediate graph representation and using LLM embeddings alongside other features to predict module-level quality, but did not consider line-level quality prediction. We propose VeriLoC, the first method that predicts design quality directly from Verilog at both the line- and module-level. To this end, VeriLoC leverages recent Verilog code-generation LLMs to extract local line-level and module-level embeddings, and train downstream classifiers/regressors on concatenations of these embeddings. VeriLoC achieves high F1-scores of 0.86-0.95 for line-level congestion and timing prediction, and reduces the mean average percentage error from 14% - 18% for SOTA methods down to only 4%. We believe that VeriLoC embeddings and insights from our work will also be of value for other predictive and optimization tasks for complex hardware design.",
      "authors": [
        "Raghu Vamshi Hemadri",
        "Jitendra Bhandari",
        "Andre Nakkab",
        "Johann Knechtel",
        "Badri P Gopalan",
        "Ramesh Narayanaswamy",
        "Ramesh Karri",
        "Siddharth Garg"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Hardware Architecture (cs.AR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-08T17:53:22+00:00",
          "link": "https://arxiv.org/abs/2506.07239v1",
          "size": "2245kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T01:51:01+00:00",
          "link": "https://arxiv.org/abs/2506.07239v2",
          "size": "2245kb",
          "version": "v2"
        }
      ],
      "title": "VeriLoC: Line-of-Code Level Prediction of Hardware Design Quality from Verilog Code",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07239",
        "HTML": "https://arxiv.org/html/2506.07239v2",
        "PDF": "https://arxiv.org/pdf/2506.07239"
      },
      "tasks": [
        "Code Generation",
        "Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.07585",
      "abstract": "Aircraft trajectory modeling plays a crucial role in Air Traffic Management (ATM) and is important for various downstream tasks, including conflict detection and landing time prediction. Dataset augmentation through the addition of synthetically generated trajectory data is necessary to develop a more robust aircraft trajectory model and ensure that the trajectory dataset is sufficient and balanced. In this work, we propose a novel framework called ATRADA for aircraft trajectory dataset augmentation. In the proposed framework, a Transformer encoder learns the underlying patterns in the original trajectory dataset and converts each data point into a context vector in the learned latent space. The converted dataset in the latent space is projected into reduced dimensions using principal component analysis (PCA), and a Gaussian mixture model (GMM) is applied to fit the probability distribution of the data points in the reduced-dimensional space. Finally, new samples are drawn from the fitted GMM, the dimension of the samples is reverted to the original dimension, and they are decoded with a Multi-Layer Perceptron (MLP). Several experiments demonstrate that the framework effectively generates new, high-quality synthetic aircraft trajectory data, which were compared to the results of several baselines.",
      "authors": [
        "Seokbin Yoon",
        "Keumjin Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T09:29:37+00:00",
          "link": "https://arxiv.org/abs/2506.07585v1",
          "size": "36339kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T07:44:53+00:00",
          "link": "https://arxiv.org/abs/2506.07585v2",
          "size": "36339kb",
          "version": "v2"
        }
      ],
      "title": "Aircraft Trajectory Dataset Augmentation in Latent Space",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07585",
        "HTML": "https://arxiv.org/html/2506.07585v2",
        "PDF": "https://arxiv.org/pdf/2506.07585"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.08240",
      "abstract": "Data augmentation is a promising tool for enhancing out-of-distribution generalization, where the key is to produce diverse, challenging variations of the source domain via costly targeted augmentations that maximize its generalization effect. Conversely, random augmentation is inexpensive but is deemed suboptimal due to its limited effect. In this paper, we revisit random augmentation and explore methods to address its shortcomings. We show that the stochastic nature of random augmentation can produce a set of colliding augmentations that distorts the learned features, similar to catastrophic forgetting. We propose a simple solution that improves the generalization effect of random augmentation by addressing forgetting, which displays strong generalization performance across various single source domain generalization (sDG) benchmarks.",
      "authors": [
        "Dongkyu Cho",
        "Rumi Chunara"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T21:18:13+00:00",
          "link": "https://arxiv.org/abs/2506.08240v1",
          "size": "282kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T18:43:24+00:00",
          "link": "https://arxiv.org/abs/2506.08240v2",
          "size": "282kb",
          "version": "v2"
        }
      ],
      "title": "Dealing with the Evil Twins: Improving Random Augmentation by Addressing Catastrophic Forgetting of Diverse Augmentations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08240",
        "HTML": "https://arxiv.org/html/2506.08240v2",
        "PDF": "https://arxiv.org/pdf/2506.08240"
      },
      "tasks": [
        "Data Augmentation",
        "Domain Generalization",
        "Out-of-Distribution Generalization",
        "Single-Source Domain Generalization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.08437",
      "abstract": "Data refinement is the standard extension of a refinement relation from programs to datatypes (i.e. a behavioural subtyping relation). Forward/backward simulations provide a tractable method for establishing data refinement, and have been thoroughly studied for nondeterministic programs. However, for standard models of mixed probability and nondeterminism, ordinary assignment statements may not commute with (variable-disjoint) program fragments. This (1) invalidates a key assumption underlying the soundness of simulations, and (2) prevents modelling probabilistic datatypes with encapsulated state.\n  We introduce a weakest precondition semantics for Kuifje$_\\sqcap$, a language for partially observable Markov decision processes, using so-called loss (function) transformers. We prove soundness of forward/backward simulations in this richer setting, modulo healthiness conditions with a remarkable duality: forward simulations cannot leak information, and backward simulations cannot exploit leaked information.",
      "authors": [
        "Chris Chen",
        "Annabelle McIver",
        "Carroll Morgan"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T04:24:54+00:00",
          "link": "https://arxiv.org/abs/2506.08437v1",
          "size": "51kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T08:41:42+00:00",
          "link": "https://arxiv.org/abs/2506.08437v2",
          "size": "55kb",
          "version": "v2"
        }
      ],
      "title": "Forward and Backward Simulations for Partially Observable Probability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08437",
        "PDF": "https://arxiv.org/pdf/2506.08437"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.08686",
      "abstract": "A significant portion of the energy consumed by Large Language Models (LLMs) arises from their inference processes; hence developing energy-efficient methods for inference is crucial. While several techniques exist for inference optimization, output compression remains relatively unexplored, with only a few preliminary efforts addressing this aspect. In this work, we first benchmark 12 decoder-only LLMs across 5 datasets, revealing that these models often produce responses that are substantially longer than necessary. We then conduct a comprehensive quality assessment of LLM responses, formally defining six information categories present in LLM responses. We show that LLMs often tend to include redundant or additional information besides the minimal answer. To address this issue of long responses by LLMs, we explore several simple and intuitive prompt-engineering strategies. Empirical evaluation shows that appropriate prompts targeting length reduction and controlling information content can achieve significant energy optimization between 25-60\\% by reducing the response length while preserving the quality of LLM responses.",
      "authors": [
        "Soham Poddar",
        "Paramita Koley",
        "Janardan Misra",
        "Sanjay Podder",
        "Navveen Balani",
        "Niloy Ganguly",
        "Saptarshi Ghosh"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T10:52:04+00:00",
          "link": "https://arxiv.org/abs/2506.08686v1",
          "size": "1556kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T08:48:15+00:00",
          "link": "https://arxiv.org/abs/2506.08686v2",
          "size": "689kb",
          "version": "v2"
        }
      ],
      "title": "Brevity is the soul of sustainability: Characterizing LLM response lengths",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.08686",
        "HTML": "https://arxiv.org/html/2506.08686v2",
        "PDF": "https://arxiv.org/pdf/2506.08686"
      },
      "tasks": [
        "Decoder",
        "Inference Optimization",
        "Prompt Engineering"
      ],
      "repo_urls": [
        "https://github.com/sohampoddar26/llm-brevity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.09034",
      "abstract": "Fine-tuning large language models (LLMs) often faces GPU memory bottlenecks: the backward pass of first-order optimizers like Adam increases memory usage to more than 10 times the inference level (e.g., 633 GB for OPT-30B). Zeroth-order (ZO) optimizers avoid this cost by estimating gradients only from forward passes, yet existing methods like MeZO usually require many more steps to converge. Can this trade-off between speed and memory in ZO be fundamentally improved? Normalized-SGD demonstrates strong empirical performance with greater memory efficiency than Adam. In light of this, we introduce FZOO, a Fast Zeroth-Order Optimizer toward Adam-Scale Speed. FZOO reduces the total forward passes needed for convergence by employing batched one-sided estimates that adapt step sizes based on the standard deviation of batch losses. It also accelerates per-batch computation through the use of Rademacher random vector perturbations coupled with CUDA's parallel processing. Extensive experiments on diverse models, including RoBERTa-large, OPT (350M-66B), Phi-2, and Llama3, across 11 tasks validate FZOO's effectiveness. On average, FZOO outperforms MeZO by 3 percent in accuracy while requiring 3 times fewer forward passes. For RoBERTa-large, FZOO achieves average improvements of 5.6 percent in accuracy and an 18 times reduction in forward passes compared to MeZO, achieving convergence speeds comparable to Adam. We also provide theoretical analysis proving FZOO's formal equivalence to a normalized-SGD update rule and its convergence guarantees. FZOO integrates smoothly into PEFT techniques, enabling even larger memory savings. Overall, our results make single-GPU, high-speed, full-parameter fine-tuning practical and point toward future work on memory-efficient pre-training.",
      "authors": [
        "Sizhe Dang",
        "Yangyang Guo",
        "Yanjun Zhao",
        "Haishan Ye",
        "Xiaodong Zheng",
        "Guang Dai",
        "Ivor Tsang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T17:56:53+00:00",
          "link": "https://arxiv.org/abs/2506.09034v1",
          "size": "8643kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T03:33:12+00:00",
          "link": "https://arxiv.org/abs/2506.09034v2",
          "size": "8760kb",
          "version": "v2"
        }
      ],
      "title": "FZOO: Fast Zeroth-Order Optimizer for Fine-Tuning Large Language Models towards Adam-Scale Speed",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09034",
        "PDF": "https://arxiv.org/pdf/2506.09034"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.09113",
      "abstract": "Notable breakthroughs in diffusion modeling have propelled rapid improvements in video generation, yet current foundational model still face critical challenges in simultaneously balancing prompt following, motion plausibility, and visual quality. In this report, we introduce Seedance 1.0, a high-performance and inference-efficient video foundation generation model that integrates several core technical improvements: (i) multi-source data curation augmented with precision and meaningful video captioning, enabling comprehensive learning across diverse scenarios; (ii) an efficient architecture design with proposed training paradigm, which allows for natively supporting multi-shot generation and jointly learning of both text-to-video and image-to-video tasks. (iii) carefully-optimized post-training approaches leveraging fine-grained supervised fine-tuning, and video-specific RLHF with multi-dimensional reward mechanisms for comprehensive performance improvements; (iv) excellent model acceleration achieving ~10x inference speedup through multi-stage distillation strategies and system-level optimizations. Seedance 1.0 can generate a 5-second video at 1080p resolution only with 41.4 seconds (NVIDIA-L20). Compared to state-of-the-art video generation models, Seedance 1.0 stands out with high-quality and fast video generation having superior spatiotemporal fluidity with structural stability, precise instruction adherence in complex multi-subject contexts, native multi-shot narrative coherence with consistent subject representation.",
      "authors": [
        "Yu Gao",
        "Haoyuan Guo",
        "Tuyen Hoang",
        "Weilin Huang",
        "Lu Jiang",
        "Fangyuan Kong",
        "Huixia Li",
        "Jiashi Li",
        "Liang Li",
        "Xiaojie Li",
        "Xunsong Li",
        "Yifu Li",
        "Shanchuan Lin",
        "Zhijie Lin",
        "Jiawei Liu",
        "Shu Liu",
        "Xiaonan Nie",
        "Zhiwu Qing",
        "Yuxi Ren",
        "Li Sun",
        "Zhi Tian",
        "Rui Wang",
        "Sen Wang",
        "Guoqiang Wei",
        "Guohong Wu",
        "Jie Wu",
        "Ruiqi Xia",
        "Fei Xiao",
        "Xuefeng Xiao",
        "Jiangqiao Yan",
        "Ceyuan Yang",
        "Jianchao Yang",
        "Runkai Yang",
        "Tao Yang",
        "Yihang Yang",
        "Zilyu Ye",
        "Xuejiao Zeng",
        "Yan Zeng",
        "Heng Zhang",
        "Yang Zhao",
        "Xiaozheng Zheng",
        "Peihao Zhu",
        "Jiaxin Zou",
        "Feilong Zuo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-10T17:56:11+00:00",
          "link": "https://arxiv.org/abs/2506.09113v1",
          "size": "28933kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T11:58:23+00:00",
          "link": "https://arxiv.org/abs/2506.09113v2",
          "size": "28932kb",
          "version": "v2"
        }
      ],
      "title": "Seedance 1.0: Exploring the Boundaries of Video Generation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09113",
        "HTML": "https://arxiv.org/html/2506.09113v2",
        "PDF": "https://arxiv.org/pdf/2506.09113"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.09397",
      "abstract": "The growing gap between the increasing complexity of large language models (LLMs) and the limited computational budgets of edge devices poses a key challenge for efficient on-device inference, despite gradual improvements in hardware capabilities. Existing strategies, such as aggressive quantization, pruning, or remote inference, trade accuracy for efficiency or lead to substantial cost burdens. This position paper introduces a new framework that leverages speculative decoding, previously viewed primarily as a decoding acceleration technique for autoregressive generation of LLMs, as a promising approach specifically adapted for edge computing by orchestrating computation across heterogeneous devices. We propose \\acronym, a framework that allows lightweight edge devices to draft multiple candidate tokens locally using diverse draft models, while a single, shared edge server verifies the tokens utilizing a more precise target model. To further increase the efficiency of verification, the edge server batch the diverse verification requests from devices. This approach supports device heterogeneity and reduces server-side memory footprint by sharing the same upstream target model across multiple devices. Our initial experiments with Jetson Orin Nano, Raspberry Pi 4B/5, and an edge server equipped with 4 Nvidia A100 GPUs indicate substantial benefits: 2.2 more system throughput, 2.8 more system capacity, and better cost efficiency, all without sacrificing model accuracy.",
      "authors": [
        "Xiangchen Li",
        "Dimitrios Spatharakis",
        "Saeid Ghafouri",
        "Jiakun Fan",
        "Hans Vandierendonck",
        "Deepu John",
        "Bo Ji",
        "Dimitrios Nikolopoulos"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T04:55:54+00:00",
          "link": "https://arxiv.org/abs/2506.09397v1",
          "size": "517kb",
          "version": "v1"
        },
        {
          "date": "2025-06-20T20:15:09+00:00",
          "link": "https://arxiv.org/abs/2506.09397v2",
          "size": "575kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T22:37:25+00:00",
          "link": "https://arxiv.org/abs/2506.09397v3",
          "size": "650kb",
          "version": "v3"
        }
      ],
      "title": "SLED: A Speculative LLM Decoding Framework for Efficient Edge Serving",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09397",
        "HTML": "https://arxiv.org/html/2506.09397v3",
        "PDF": "https://arxiv.org/pdf/2506.09397"
      },
      "tasks": [
        "Edge-computing",
        "Quantization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.09428",
      "abstract": "Supervised Fine-Tuning (SFT) is a critical step for enhancing the instruction-following capabilities of Large Language Models (LLMs) and adapting them to specialized domains. However, SFT often leads to a degradation of the model's general abilities, a phenomenon known as catastrophic forgetting. This problem is exacerbated when third-party practitioners fine-tune open-source models, as the original SFT data is typically not available. To address this challenge, we propose a novel and cost-effective SFT method that effectively mitigates catastrophic forgetting without requiring access to the original SFT data. Our approach first reconstructs the likely instruction distribution of the base model. It then employs a multi-model generation and filtering pipeline to synthesize a high-quality general-purpose dataset. This synthetic dataset is mixed with new, domain-specific data for fine-tuning. Experimental results show that our method not only preserves the model's capabilities in general domains but also improves task-specific performance, outperforming baselines that use publicly available SFT datasets.",
      "authors": [
        "Fei Ding",
        "Baiqiao Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T06:23:50+00:00",
          "link": "https://arxiv.org/abs/2506.09428v1",
          "size": "448kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T02:26:03+00:00",
          "link": "https://arxiv.org/abs/2506.09428v2",
          "size": "499kb",
          "version": "v2"
        }
      ],
      "title": "Improved Supervised Fine-Tuning for Large Language Models to Mitigate Catastrophic Forgetting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09428",
        "HTML": "https://arxiv.org/html/2506.09428v2",
        "PDF": "https://arxiv.org/pdf/2506.09428"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.09523",
      "abstract": "Soft robots manufactured with flexible materials can be highly compliant and adaptive to their surroundings, which facilitates their application in areas such as dexterous manipulation and environmental exploration. This paper aims at investigating the tracking control problem for soft robots under uncertainty such as unmodeled dynamics and external disturbance. First, we establish a novel switching function and design the compensated tracking error dynamics by virtue of the command filter. Then, based on the backstepping methodology, the virtual controllers and the adaptive logic estimating the supremum of uncertainty impacts are developed for synthesizing an event-triggered control strategy. In addition, the uniformed finite-time stability certification is derived for different scenarios of the switching function. Finally, we perform a case study of a soft robot to illustrate the effectiveness of the proposed control algorithm.",
      "authors": [
        "Renjie Ma",
        "Ziyao Qu",
        "Zhijian Hu",
        "Dong Zhao",
        "Marios M. Polycarpou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T08:47:55+00:00",
          "link": "https://arxiv.org/abs/2506.09523v1",
          "size": "4158kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T07:10:30+00:00",
          "link": "https://arxiv.org/abs/2506.09523v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "Adaptive event-triggered robust tracking control of soft robots",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.09523",
        "PDF": "https://arxiv.org/pdf/2506.09523"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.10186",
      "abstract": "Equivariant diffusion models have achieved impressive performance in 3D molecule generation. These models incorporate Euclidean symmetries of 3D molecules by utilizing an SE(3)-equivariant denoising network. However, specialized equivariant architectures limit the scalability and efficiency of diffusion models. In this paper, we propose an approach that relaxes such equivariance constraints. Specifically, our approach learns a sample-dependent SO(3) transformation for each molecule to construct an aligned latent space. A non-equivariant diffusion model is then trained over the aligned representations. Experimental results demonstrate that our approach performs significantly better than previously reported non-equivariant models. It yields sample quality comparable to state-of-the-art equivariant diffusion models and offers improved training and sampling efficiency. Our code is available at https://github.com/skeletondyh/RADM",
      "authors": [
        "Yuhui Ding",
        "Thomas Hofmann"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Quantitative Methods (q-bio.QM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T21:23:56+00:00",
          "link": "https://arxiv.org/abs/2506.10186v1",
          "size": "510kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T17:18:51+00:00",
          "link": "https://arxiv.org/abs/2506.10186v2",
          "size": "510kb",
          "version": "v2"
        }
      ],
      "title": "Scalable Non-Equivariant 3D Molecule Generation via Rotational Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10186",
        "HTML": "https://arxiv.org/html/2506.10186v2",
        "PDF": "https://arxiv.org/pdf/2506.10186"
      },
      "tasks": [
        "3D Molecule Generation",
        "Denoising"
      ],
      "repo_urls": [
        "https://github.com/skeletondyh/radm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.10217",
      "abstract": "Datasets play a key role in imparting advanced capabilities to artificial intelligence (AI) foundation models that can be adapted to various downstream tasks. These downstream applications can introduce both beneficial and harmful capabilities -- resulting in dual use AI foundation models, with various technical and regulatory approaches to monitor and manage these risks. However, despite the crucial role of datasets, responsible dataset design and ensuring data-centric safety and ethical practices have received less attention. In this study, we pro-pose responsible dataset design framework that encompasses various stages in the AI and dataset lifecycle to enhance safety measures and reduce the risk of AI misuse due to low quality, unsafe and unethical data content. This framework is domain agnostic, suitable for adoption for various applications and can promote responsible practices in dataset creation, use, and sharing to facilitate red teaming, minimize risks, and increase trust in AI models.",
      "authors": [
        "Srija Chakraborty"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-11T22:26:50+00:00",
          "link": "https://arxiv.org/abs/2506.10217v1",
          "size": "217kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T15:24:13+00:00",
          "link": "https://arxiv.org/abs/2506.10217v2",
          "size": "249kb",
          "version": "v2"
        }
      ],
      "title": "Data-Centric Safety and Ethical Measures for Data and AI Governance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10217",
        "PDF": "https://arxiv.org/pdf/2506.10217"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.10314",
      "abstract": "Malicious sockpuppet detection on Wikipedia is critical to preserving access to reliable information on the internet and preventing the spread of disinformation. Prior machine learning approaches rely on stylistic and meta-data features, but do not prioritise adaptability to author-specific behaviours. As a result, they struggle to effectively model the behaviour of specific sockpuppet-groups, especially when text data is limited. To address this, we propose the application of meta-learning, a machine learning technique designed to improve performance in data-scarce settings by training models across multiple tasks. Meta-learning optimises a model for rapid adaptation to the writing style of a new sockpuppet-group. Our results show that meta-learning significantly enhances the precision of predictions compared to pre-trained models, marking an advancement in combating sockpuppetry on open editing platforms. We release a new dataset of sockpuppet investigations to foster future research in both sockpuppetry and meta-learning fields.",
      "authors": [
        "Luc Raszewski and Christine De Kock"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T02:59:04+00:00",
          "link": "https://arxiv.org/abs/2506.10314v1",
          "size": "78kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T05:51:43+00:00",
          "link": "https://arxiv.org/abs/2506.10314v2",
          "size": "79kb",
          "version": "v2"
        }
      ],
      "title": "Detecting Sockpuppetry on Wikipedia Using Meta-Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10314",
        "PDF": "https://arxiv.org/pdf/2506.10314"
      },
      "tasks": [
        "Meta-Learning"
      ],
      "repo_urls": [
        "https://github.com/lraszewski/wiki-socks"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.10507",
      "abstract": "Recent advances in diffusion models have significantly improved image generation and editing, but extending these capabilities to 3D assets remains challenging, especially for fine-grained edits that require multi-view consistency. Existing methods typically restrict editing to predetermined viewing angles, severely limiting their flexibility and practical applications. We introduce Edit360, a tuning-free framework that extends 2D modifications to multi-view consistent 3D editing. Built upon video diffusion models, Edit360 enables user-specific editing from arbitrary viewpoints while ensuring structural coherence across all views. The framework selects anchor views for 2D modifications and propagates edits across the entire 360-degree range. To achieve this, Edit360 introduces a novel Anchor-View Editing Propagation mechanism, which effectively aligns and merges multi-view information within the latent and attention spaces of diffusion models. The resulting edited multi-view sequences facilitate the reconstruction of high-quality 3D assets, enabling customizable 3D content creation.",
      "authors": [
        "Junchao Huang",
        "Xinting Hu",
        "Shaoshuai Shi",
        "Zhuotao Tian",
        "Li Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T09:09:28+00:00",
          "link": "https://arxiv.org/abs/2506.10507v1",
          "size": "28148kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T07:13:23+00:00",
          "link": "https://arxiv.org/abs/2506.10507v2",
          "size": "28148kb",
          "version": "v2"
        }
      ],
      "title": "Edit360: 2D Image Edits to 3D Assets from Any Angle",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10507",
        "HTML": "https://arxiv.org/html/2506.10507v2",
        "PDF": "https://arxiv.org/pdf/2506.10507"
      },
      "tasks": [
        "Image Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.10558",
      "abstract": "Interactive theorem provers (ITPs) are powerful tools for the formal verification of mathematical proofs down to the axiom level. However, their lack of a natural language interface remains a significant limitation. Recent advancements in large language models (LLMs) have enhanced the understanding of natural language inputs, paving the way for autoformalization - the process of translating natural language proofs into formal proofs that can be verified. Despite these advancements, existing autoformalization approaches are limited to verifying complete proofs and lack the capability for finer, sentence-level verification. To address this gap, we propose StepProof, a novel autoformalization method designed for granular, step-by-step verification. StepProof breaks down complete proofs into multiple verifiable subproofs, enabling sentence-level verification. Experimental results demonstrate that StepProof significantly improves proof success rates and efficiency compared to traditional methods. Additionally, we found that minor manual adjustments to the natural language proofs, tailoring them for step-level verification, further enhanced StepProof's performance in autoformalization.",
      "authors": [
        "Xiaolin Hu",
        "Qinghua Zhou",
        "Bogdan Grechuk",
        "Ivan Y. Tyukin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T10:31:23+00:00",
          "link": "https://arxiv.org/abs/2506.10558v1",
          "size": "1031kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T10:59:44+00:00",
          "link": "https://arxiv.org/abs/2506.10558v2",
          "size": "1031kb",
          "version": "v2"
        }
      ],
      "title": "StepProof: Step-by-step verification of natural language mathematical proofs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10558",
        "HTML": "https://arxiv.org/html/2506.10558v2",
        "PDF": "https://arxiv.org/pdf/2506.10558"
      },
      "tasks": [
        "Mathematical Proofs",
        "Sentence"
      ],
      "repo_urls": [
        "https://github.com/r1niga/step-proof"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.10770",
      "abstract": "Machine learning (ML) models in production do not fail due to statistical anomalies in their input data; they fail due to contextual misalignment -- when their environment deviates from training assumptions, leading to unreliable predictions. Effective ML monitoring requires rich contextual information to move beyond detecting statistical shifts toward meaningful alerts and systematic root-cause analysis. Surprisingly, despite extensive research in ML monitoring and related areas (drift detection, data validation, out-of-distribution detection), there is no shared understanding of how to use contextual information -- a striking gap, given that monitoring fundamentally involves interpreting information in context. In response, this paper presents a systematic review to characterize and structure the various types of contextual information in this domain. Our analysis examines 94 primary studies across data mining, databases, software engineering, and ML. We introduce the Contextual System--Aspect--Representation (C-SAR) framework, a conceptual model that synthesizes our findings. We also identify 20 recurring and potentially reusable patterns of specific system, aspect, and representation triplets, and map them to the monitoring activities they support. This study provides a new perspective on ML monitoring: from interpreting ``tea leaves'' (i.e., isolated data and performance statistics) to constructing and managing ``system maps'' (i.e., end-to-end views that connect data, models, and operating context). This way, we aim to enable systematic ML monitoring practices.",
      "authors": [
        "Joran Leest",
        "Claudia Raibulet",
        "Patricia Lago",
        "and Ilias Gerostathopoulos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T14:49:42+00:00",
          "link": "https://arxiv.org/abs/2506.10770v1",
          "size": "230kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T07:43:41+00:00",
          "link": "https://arxiv.org/abs/2506.10770v2",
          "size": "227kb",
          "version": "v2"
        }
      ],
      "title": "From Tea Leaves to System Maps: Context-awareness in Monitoring Operational Machine Learning Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.10770",
        "PDF": "https://arxiv.org/pdf/2506.10770"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.11504",
      "abstract": "Conventional grid-forming (GFM) controls often entangle voltage formation with power flow and dc-source dynamics, which can degrade voltage tracking performance and stability under grid disturbances, load transients, and dc-side perturbations. To address this issue, a symmetric sliding-mode control (SSMC) method is developed and its explicit voltage controllable region is derived. It illustrates how much ac-side power dynamics and dc-link voltage varying can be decoupled from the voltage regulation task, which helps predict when the entangling appears. While conventional sliding-mode controls address voltage-tracking error through complex sliding surface designs, repetitive correction techniques or special reaching laws, this work identifies that the error at power-line frequency primarily stem from the asymmetry property of inverters with the delay effect and the computational inaccuracy. Guided by this insight, a symmetric compensation structure is proposed, which avoids added design complexity and directly mitigates low-frequency voltage tracking errors. Furthermore, the control design is supported by a physical and quantitative explanation, aiding in parameter tuning. Simulation and experimental results demonstrate that the proposed method achieves faster tracking responses-on the order of hundreds of microseconds-while maintaining robust and more accurate tracking under both dc-link voltage and ac-side current variations. Conventional grid-forming and classical sliding-mode controllers, which handle these disturbances separately, cannot match this combined speed and robustness. Furthermore, the voltage controllability analysis is explicitly verified.",
      "authors": [
        "Qianxi Tang and Li Peng"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T07:03:15+00:00",
          "link": "https://arxiv.org/abs/2506.11504v1",
          "size": "17741kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T15:23:31+00:00",
          "link": "https://arxiv.org/abs/2506.11504v2",
          "size": "17741kb",
          "version": "v2"
        }
      ],
      "title": "Symmetric Sliding-Mode Control of Grid-Forming Inverters With Controllable Region Under AC and DC Sides Varying",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11504",
        "HTML": "https://arxiv.org/html/2506.11504v2",
        "PDF": "https://arxiv.org/pdf/2506.11504"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2506.11538",
      "abstract": "Disentangling user intents from implicit feedback has emerged as a promising strategy for enhancing both the accuracy and interpretability of recommendation systems. However, existing methods often model user and item intents independently and rely heavily on implicit structural signals, lacking explicit guidance to uncover the joint semantics that drive user-item interactions. To address these limitations, we propose DMICF, a dual-perspective collaborative filtering framework that unifies intent alignment, structural fusion, and discriminative training into a cohesive architecture. DMICF jointly encodes user-item graphs from both user and item views, leveraging cross-perspective structural signals to reinforce representation learning, especially under sparse or long-tail scenarios. A sub-intent alignment mechanism is introduced to uncover fine-grained semantic correspondences between users and items, enabling adaptive refinement of interaction representations. To enhance prediction quality, DMICF employs an intent-aware scoring module that aggregates compatibility signals across matched latent intents. Furthermore, a multi-negative softmax-based supervision strategy is incorporated to promote semantic disentanglement, encouraging alignment between relevant intents while suppressing spurious or entangled components. Extensive experiments confirm that DMICF consistently delivers robust performance across datasets with diverse interaction distributions. Qualitative analysis confirms that DMICF disentangles interaction intents and adaptively structures intent subspaces into semantically coherent clusters, enabling fine-grained personalization.",
      "authors": [
        "Shanfan Zhang",
        "Yongyi Lin",
        "Yuan Rao",
        "Chenlong Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-13T07:44:42+00:00",
          "link": "https://arxiv.org/abs/2506.11538v1",
          "size": "1863kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T13:14:12+00:00",
          "link": "https://arxiv.org/abs/2506.11538v2",
          "size": "1795kb",
          "version": "v2"
        }
      ],
      "title": "Dual-Perspective Disentangled Multi-Intent Alignment for Enhanced Collaborative Filtering",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11538",
        "HTML": "https://arxiv.org/html/2506.11538v2",
        "PDF": "https://arxiv.org/pdf/2506.11538"
      },
      "tasks": [
        "Collaborative Filtering",
        "Disentanglement"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.12446",
      "abstract": "Inference-time alignment methods have gained significant attention for their efficiency and effectiveness in aligning large language models (LLMs) with human preferences. However, existing dominant approaches using reward-guided search (RGS) primarily rely on outcome reward models (ORMs), which suffer from a critical granularity mismatch: ORMs are designed to provide outcome rewards for complete responses, while RGS methods rely on process rewards to guide the policy, leading to inconsistent scoring and suboptimal alignment. To address this challenge, we introduce process reward models (PRMs) into RGS and argue that an ideal PRM should satisfy two objectives: Score Consistency, ensuring coherent evaluation across partial and complete responses, and Preference Consistency, aligning partial sequence assessments with human preferences. Based on these, we propose SP-PRM, a novel dual-consistency framework integrating score consistency-based and preference consistency-based partial evaluation modules without relying on human annotation. Extensive experiments on dialogue, summarization, and reasoning tasks demonstrate that SP-PRM substantially enhances existing RGS methods, achieving a 3.6%-10.3% improvement in GPT-4 evaluation scores across all tasks.",
      "authors": [
        "Bin Xie",
        "Bingbing Xu",
        "Yige Yuan",
        "Shengmao Zhu",
        "Huawei Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-14T10:58:38+00:00",
          "link": "https://arxiv.org/abs/2506.12446v1",
          "size": "2022kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T14:16:58+00:00",
          "link": "https://arxiv.org/abs/2506.12446v2",
          "size": "4112kb",
          "version": "v2"
        }
      ],
      "title": "From Outcomes to Processes: Guiding PRM Learning from ORM for Inference-Time Alignment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12446",
        "HTML": "https://arxiv.org/html/2506.12446v2",
        "PDF": "https://arxiv.org/pdf/2506.12446"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.12484",
      "abstract": "Language models can retain dangerous knowledge and skills even after extensive safety fine-tuning, posing both misuse and misalignment risks. Recent studies show that even specialized unlearning methods can be easily reversed. To address this, we systematically evaluate many existing and novel components of unlearning methods and identify ones crucial for irreversible unlearning.\n  We introduce Disruption Masking, a technique in which we only allow updating weights, where the signs of the unlearning gradient and the retaining gradient are the same. This ensures all updates are non-disruptive.\n  Additionally, we identify the need for normalizing the unlearning gradients, and also confirm the usefulness of meta-learning. We combine these insights into MUDMAN (Meta-Unlearning with Disruption Masking and Normalization) and validate its effectiveness at preventing the recovery of dangerous capabilities. MUDMAN outperforms the prior TAR method by 40%, setting a new state-of-the-art for robust unlearning.",
      "authors": [
        "Filip Sondej",
        "Yushi Yang",
        "Miko{\\l}aj Kniejski",
        "Marcel Windys"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-14T12:49:51+00:00",
          "link": "https://arxiv.org/abs/2506.12484v1",
          "size": "2038kb",
          "version": "v1"
        },
        {
          "date": "2025-06-21T10:40:17+00:00",
          "link": "https://arxiv.org/abs/2506.12484v2",
          "size": "2055kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T09:37:43+00:00",
          "link": "https://arxiv.org/abs/2506.12484v3",
          "size": "15135kb",
          "version": "v3"
        }
      ],
      "title": "Robust LLM Unlearning with MUDMAN: Meta-Unlearning with Disruption Masking And Normalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12484",
        "HTML": "https://arxiv.org/html/2506.12484v3",
        "PDF": "https://arxiv.org/pdf/2506.12484"
      },
      "tasks": [
        "Meta-Learning",
        "TAR"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.12494",
      "abstract": "Retrieval-Augmented Generation (RAG) plays a pivotal role in modern large language model applications, with numerous existing frameworks offering a wide range of functionalities to facilitate the development of RAG systems. However, we have identified several persistent challenges in these frameworks, including difficulties in algorithm reproduction and sharing, lack of new techniques, and high system overhead. To address these limitations, we introduce \\textbf{FlexRAG}, an open-source framework specifically designed for research and prototyping. FlexRAG supports text-based, multimodal, and network-based RAG, providing comprehensive lifecycle support alongside efficient asynchronous processing and persistent caching capabilities. By offering a robust and flexible solution, FlexRAG enables researchers to rapidly develop, deploy, and share advanced RAG systems. Our toolkit and resources are available at \\href{https://github.com/ictnlp/FlexRAG}{https://github.com/ictnlp/FlexRAG}.",
      "authors": [
        "Zhuocheng Zhang",
        "Yang Feng",
        "Min Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-14T13:16:31+00:00",
          "link": "https://arxiv.org/abs/2506.12494v1",
          "size": "536kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T05:45:43+00:00",
          "link": "https://arxiv.org/abs/2506.12494v2",
          "size": "536kb",
          "version": "v2"
        }
      ],
      "title": "FlexRAG: A Flexible and Comprehensive Framework for Retrieval-Augmented Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12494",
        "HTML": "https://arxiv.org/html/2506.12494v2",
        "PDF": "https://arxiv.org/pdf/2506.12494"
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model",
        "RAG",
        "Retrieval",
        "Retrieval-augmented Generation"
      ],
      "repo_urls": [
        "https://github.com/ictnlp/flexrag"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.12573",
      "abstract": "Despite recent advancements in music generation systems, their application in film production remains limited, as they struggle to capture the nuances of real-world filmmaking, where filmmakers consider multiple factors-such as visual content, dialogue, and emotional tone-when selecting or composing music for a scene. This limitation primarily stems from the absence of comprehensive datasets that integrate these elements. To address this gap, we introduce Open Screen Soundtrack Library (OSSL), a dataset consisting of movie clips from public domain films, totaling approximately 36.5 hours, paired with high-quality soundtracks and human-annotated mood information. To demonstrate the effectiveness of our dataset in improving the performance of pre-trained models on film music generation tasks, we introduce a new video adapter that enhances an autoregressive transformer-based text-to-music model by adding video-based conditioning. Our experimental results demonstrate that our proposed approach effectively enhances MusicGen-Medium in terms of both objective measures of distributional and paired fidelity, and subjective compatibility in mood and genre. To facilitate reproducibility and foster future work, we publicly release the dataset, code, and demo.",
      "authors": [
        "Haven Kim",
        "Zachary Novack",
        "Weihan Xu",
        "Julian McAuley",
        "and Hao-Wen Dong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Multimedia (cs.MM)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-14T16:58:42+00:00",
          "link": "https://arxiv.org/abs/2506.12573v1",
          "size": "3487kb",
          "version": "v1"
        },
        {
          "date": "2025-06-18T17:03:04+00:00",
          "link": "https://arxiv.org/abs/2506.12573v2",
          "size": "3487kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T22:16:16+00:00",
          "link": "https://arxiv.org/abs/2506.12573v3",
          "size": "3486kb",
          "version": "v3"
        }
      ],
      "title": "Video-Guided Text-to-Music Generation Using Public Domain Movie Collections",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12573",
        "HTML": "https://arxiv.org/html/2506.12573v3",
        "PDF": "https://arxiv.org/pdf/2506.12573"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.12576",
      "abstract": "Recent work shows that Sparse Autoencoders (SAE) applied to large language model (LLM) layers have neurons corresponding to interpretable concepts. These SAE neurons can be modified to align generated outputs, but only towards pre-identified topics and with some parameter tuning. Our approach leverages the observational and modification properties of SAEs to enable alignment for any topic. This method 1) scores each SAE neuron by its semantic similarity to an alignment text and uses them to 2) modify SAE-layer-level outputs by emphasizing topic-aligned neurons. We assess the alignment capabilities of this approach on diverse public topic datasets including Amazon reviews, Medicine, and Sycophancy, across the currently available open-source LLMs and SAE pairs (GPT2 and Gemma) with multiple SAEs configurations. Experiments aligning to medical prompts reveal several benefits over fine-tuning, including increased average language acceptability (0.25 vs. 0.5), reduced training time across multiple alignment topics (333.6s vs. 62s), and acceptable inference time for many applications (+0.00092s/token). Our open-source code is available at github.com/IBM/sae-steering.",
      "authors": [
        "Ananya Joshi and Celia Cintas and Skyler Speakman"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-14T17:11:48+00:00",
          "link": "https://arxiv.org/abs/2506.12576v1",
          "size": "2454kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T17:47:49+00:00",
          "link": "https://arxiv.org/abs/2506.12576v2",
          "size": "2246kb",
          "version": "v2"
        }
      ],
      "title": "Enabling Precise Topic Alignment in Large Language Models Via Sparse Autoencoders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12576",
        "HTML": "https://arxiv.org/html/2506.12576v2",
        "PDF": "https://arxiv.org/pdf/2506.12576"
      },
      "tasks": [
        "Large Language Model",
        "Semantic Similarity",
        "Semantic Textual Similarity"
      ],
      "repo_urls": [
        "https://github.com/ibm/sae-steering"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.12846",
      "abstract": "Federated learning is a promising distributed learning paradigm that enables collaborative model training without exposing local client data, thereby protect data privacy. However, it also brings new threats and challenges. The advancement of model inversion attacks has rendered the plaintext transmission of local models insecure, while the distributed nature of federated learning makes it particularly vulnerable to attacks raised by malicious clients. To protect data privacy and prevent malicious client attacks, this paper proposes a privacy-preserving federated learning framework based on verifiable functional encryption, without a non-colluding dual-server setup or additional trusted third-party. Specifically, we propose a novel decentralized verifiable functional encryption (DVFE) scheme that enables the verification of specific relationships over multi-dimensional ciphertexts. This scheme is formally treated, in terms of definition, security model and security proof. Furthermore, based on the proposed DVFE scheme, we design a privacy-preserving federated learning framework VFEFL that incorporates a novel robust aggregation rule to detect malicious clients, enabling the effective training of high-accuracy models under adversarial settings. Finally, we provide formal analysis and empirical evaluation of the proposed schemes. The results demonstrate that our approach achieves the desired privacy protection, robustness, verifiability and fidelity, while eliminating the reliance on non-colluding dual-server settings or trusted third parties required by existing methods.",
      "authors": [
        "Nina Cai and Jinguang Han and Weizhi Meng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-15T13:38:40+00:00",
          "link": "https://arxiv.org/abs/2506.12846v1",
          "size": "1120kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T09:23:38+00:00",
          "link": "https://arxiv.org/abs/2506.12846v2",
          "size": "1120kb",
          "version": "v2"
        }
      ],
      "title": "VFEFL: Privacy-Preserving Federated Learning against Malicious Clients via Verifiable Functional Encryption",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12846",
        "HTML": "https://arxiv.org/html/2506.12846v2",
        "PDF": "https://arxiv.org/pdf/2506.12846"
      },
      "tasks": [
        "Federated Learning",
        "Privacy Preserving"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.13430",
      "abstract": "Predicting mortality-related outcomes from images offers the prospect of accessible, noninvasive, and scalable health screening. We present a method that leverages pretrained vision transformer foundation models to estimate remaining lifespan from facial and whole-body images, alongside robust uncertainty quantification. We show that predictive uncertainty varies systematically with the true remaining lifespan, and that this uncertainty can be effectively modeled by learning a Gaussian distribution for each sample. Our approach achieves state-of-the-art mean absolute error (MAE) of 7.48 years on an established dataset, and further improves to 4.79 and 5.07 years MAE on two new, higher-quality datasets curated and published in this work. Importantly, our models provide well-calibrated uncertainty estimates, as demonstrated by a bucketed expected calibration error of 0.62 years. While not intended for clinical deployment, these results highlight the potential of extracting medically relevant signals from images. We make all code and datasets available to facilitate further research.",
      "authors": [
        "Tristan Kenneweg",
        "Philip Kenneweg and Barbara Hammer"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T12:47:37+00:00",
          "link": "https://arxiv.org/abs/2506.13430v1",
          "size": "1461kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T09:19:47+00:00",
          "link": "https://arxiv.org/abs/2506.13430v2",
          "size": "1461kb",
          "version": "v2"
        }
      ],
      "title": "Uncertainty-Aware Remaining Lifespan Prediction from Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13430",
        "HTML": "https://arxiv.org/html/2506.13430v2",
        "PDF": "https://arxiv.org/pdf/2506.13430"
      },
      "datasets": [
        {
          "dataset_name": "TristanKe/RemainingLifespanPredictionFaces",
          "downloads": "161",
          "likes": "0",
          "link": "https://huggingface.co/datasets/TristanKe/RemainingLifespanPredictionFaces"
        },
        {
          "dataset_name": "TristanKe/RemainingLifespanPredictionWholeImgs",
          "downloads": "158",
          "likes": "0",
          "link": "https://huggingface.co/datasets/TristanKe/RemainingLifespanPredictionWholeImgs"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.13648",
      "abstract": "Anisotropic material properties like electrical and thermal conductivities of engineering composites exhibit variability due to inherent material heterogeneity and manufacturing uncertainties. As a tensorial quantity, they are represented as symmetric positive definite tensors, which live on a curved Riemannian manifold, and accurately modelling their stochastic nature requires preserving both their symmetric positive definite properties and spatial symmetries. To achieve this, uncertainties are parametrised into scale (strength) and rotation (orientation) components, modelled as independent random variables on a manifold structure derived from the maximum entropy principle. Further, the propagation of such stochastic tensors through physics-based simulations necessitates computationally efficient surrogate models, like neural networks. However, feedforward neural network architectures are not well-suited for SPD tensors, as directly using the tensor components as inputs fails to preserve their geometric properties, often leading to suboptimal results. To address this, we introduce the Constitutive Manifold Neural Network (CMNN), which is equipped with a preprocessing layer to map the SPD tensor from the curved manifold to the local tangent space, a flat vector space, preserving statistical information in the dataset. A case study on a steady-state heat conduction problem with stochastic anisotropic conductivity demonstrates that geometry-preserving preprocessing, such as logarithmic maps for scale information, significantly improves learning performance over conventional MLPs. These findings underscore the importance of manifold-aware techniques when working with tensor-valued data in engineering applications.",
      "authors": [
        "Wouter J. Schuttert",
        "Mohammed Iqbal Abdul Rasheed",
        "Bojana Rosi\\'c"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T16:10:05+00:00",
          "link": "https://arxiv.org/abs/2506.13648v1",
          "size": "4401kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T14:26:55+00:00",
          "link": "https://arxiv.org/abs/2506.13648v2",
          "size": "4147kb",
          "version": "v2"
        }
      ],
      "title": "Constitutive Manifold Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13648",
        "HTML": "https://arxiv.org/html/2506.13648v2",
        "PDF": "https://arxiv.org/pdf/2506.13648"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.13702",
      "abstract": "Single-trajectory reinforcement learning (RL) methods aim to optimize policies from datasets consisting of (prompt, response, reward) triplets, where scalar rewards are directly available. This supervision format is highly practical, as it mirrors real-world human feedback, such as thumbs-up/down signals, and avoids the need for structured preference annotations. In contrast, pairwise preference-based methods like Direct Preference Optimization (DPO) rely on datasets with both preferred and dispreferred responses, which are harder to construct and less natural to collect. Among single-trajectory approaches, Direct Reward Optimization (DRO) has shown strong empirical performance due to its simplicity and stability. However, DRO requires approximating a value function, which introduces several limitations: high off-policy variance, coupling between policy and value learning, and a lack of absolute supervision on the policy itself. We introduce Reward Partitioning Optimization (RPO), a new method that resolves these limitations by removing the need to model the value function. Instead, RPO normalizes observed rewards using a partitioning approach estimated directly from data. This leads to a straightforward supervised learning objective on the policy, with no auxiliary models and no joint optimization. RPO provides direct and stable supervision on the policy, making it robust and easy to implement in practice. We validate RPO on scalar-feedback language modeling tasks using Flan-T5 encoder-decoder models. Our results demonstrate that RPO outperforms existing single-trajectory baselines such as DRO and Kahneman-Tversky Optimization (KTO). These findings confirm that RPO is a simple, effective, and theoretically grounded method for single-trajectory policy optimization.",
      "authors": [
        "Bilal Faye",
        "Hanane Azzag",
        "Mustapha Lebbah"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T17:06:27+00:00",
          "link": "https://arxiv.org/abs/2506.13702v1",
          "size": "107kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T11:57:40+00:00",
          "link": "https://arxiv.org/abs/2506.13702v2",
          "size": "111kb",
          "version": "v2"
        }
      ],
      "title": "Value-Free Policy Optimization via Reward Partitioning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13702",
        "HTML": "https://arxiv.org/html/2506.13702v2",
        "PDF": "https://arxiv.org/pdf/2506.13702"
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/b-faye/rpo"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.14129",
      "abstract": "Search-based software engineering (SBSE) addresses critical optimization challenges in software engineering, including the next release problem (NRP) and feature selection problem (FSP). While traditional heuristic approaches and integer linear programming (ILP) methods have demonstrated efficacy for small to medium-scale problems, their scalability to large-scale instances remains unknown. Here, we introduce quantum annealing (QA) as a subroutine to tackling multi-objective SBSE problems, leveraging the computational potential of quantum systems. We propose two QA-based algorithms tailored to different problem scales. For small-scale problems, we reformulate multi-objective optimization (MOO) as single-objective optimization (SOO) using penalty-based mappings for quantum processing. For large-scale problems, we employ a decomposition strategy guided by maximum energy impact (MEI), integrating QA with a steepest descent method to enhance local search efficiency. Applied to NRP and FSP, our approaches are benchmarked against the heuristic NSGA-II and the ILP-based $\\epsilon$-constraint method. Experimental results reveal that while our methods produce fewer non-dominated solutions than $\\epsilon$-constraint, they achieve significant reductions in execution time. Moreover, compared to NSGA-II, our methods deliver more non-dominated solutions with superior computational efficiency. These findings underscore the potential of QA in advancing scalable and efficient solutions for SBSE challenges.",
      "authors": [
        "Shuchang Wang",
        "Xiaopeng Qiu",
        "Yingxing Xue",
        "Yanfu Li and Wei Yang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T02:46:53+00:00",
          "link": "https://arxiv.org/abs/2506.14129v1",
          "size": "258kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T09:28:37+00:00",
          "link": "https://arxiv.org/abs/2506.14129v2",
          "size": "259kb",
          "version": "v2"
        }
      ],
      "title": "A Quantum Annealing Approach for Solving Optimal Feature Selection and Next Release Problems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14129",
        "HTML": "https://arxiv.org/html/2506.14129v2",
        "PDF": "https://arxiv.org/pdf/2506.14129"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.14291",
      "abstract": "Graph machine learning architectures are typically tailored to specific tasks on specific datasets, which hinders their broader applicability. This has led to a new quest in graph machine learning: how to build graph foundation models capable of generalizing across arbitrary graphs and features? In this work, we present a recipe for designing graph foundation models for node-level tasks from first principles. The key ingredient underpinning our study is a systematic investigation of the symmetries that a graph foundation model must respect. In a nutshell, we argue that label permutation-equivariance alongside feature permutation-invariance are necessary in addition to the common node permutation-equivariance on each local neighborhood of the graph. To this end, we first characterize the space of linear transformations that are equivariant to permutations of nodes and labels, and invariant to permutations of features. We then prove that the resulting network is a universal approximator on multisets that respect the aforementioned symmetries. Our recipe uses such layers on the multiset of features induced by the local neighborhood of the graph to obtain a class of graph foundation models for node property prediction. We validate our approach through extensive experiments on 29 real-world node classification datasets, demonstrating both strong zero-shot empirical performance and consistent improvement as the number of training graphs increases.",
      "authors": [
        "Ben Finkelshtein",
        "\\.Ismail \\.Ilkan Ceylan",
        "Michael Bronstein",
        "Ron Levie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Social and Information Networks (cs.SI)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T08:05:08+00:00",
          "link": "https://arxiv.org/abs/2506.14291v1",
          "size": "103kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T21:47:57+00:00",
          "link": "https://arxiv.org/abs/2506.14291v2",
          "size": "107kb",
          "version": "v2"
        }
      ],
      "title": "Equivariance Everywhere All At Once: A Recipe for Graph Foundation Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14291",
        "PDF": "https://arxiv.org/pdf/2506.14291"
      },
      "tasks": [
        "All",
        "Node Classification",
        "Node Property Prediction",
        "Property Prediction"
      ],
      "repo_urls": [
        "https://github.com/benfinkelshtein/equivarianceeverywhere"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.14436",
      "abstract": "Adapting large-scale foundation models in multi-task scenarios often suffers from task conflict and oblivion. To mitigate such issues, we propose a novel ''model MoE-ization'' strategy that leads to a conflict- and oblivion-resistant multi-task adaptation method. Given a weight matrix of a pre-trained model, our method applies SVD to it and introduces a learnable router to adjust its singular values based on tasks and samples. Accordingly, the weight matrix becomes a Mixture of Orthogonal Rank-one Experts (MoORE), in which each expert corresponds to the outer product of a left singular vector and the corresponding right one. We can improve the model capacity by imposing a learnable orthogonal transform on the right singular vectors. Unlike low-rank adaptation (LoRA) and its MoE-driven variants, MoORE guarantees the experts' orthogonality and maintains the column space of the original weight matrix. These two properties make the adapted model resistant to the conflicts among the new tasks and the oblivion of its original tasks, respectively. Experiments on various datasets demonstrate that MoORE outperforms existing multi-task adaptation methods consistently, showing its superiority in terms of conflict- and oblivion-resistance. The code of the experiments is available at https://github.com/DaShenZi721/MoORE.",
      "authors": [
        "Shen Yuan",
        "Yin Zheng",
        "Taifeng Wang",
        "Binbin Liu",
        "and Hongteng Xu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T11:55:08+00:00",
          "link": "https://arxiv.org/abs/2506.14436v1",
          "size": "2346kb",
          "version": "v1"
        },
        {
          "date": "2025-06-21T15:53:00+00:00",
          "link": "https://arxiv.org/abs/2506.14436v2",
          "size": "2350kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T06:22:39+00:00",
          "link": "https://arxiv.org/abs/2506.14436v3",
          "size": "2350kb",
          "version": "v3"
        }
      ],
      "title": "MoORE: SVD-based Model MoE-ization for Conflict- and Oblivion-Resistant Multi-Task Adaptation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14436",
        "HTML": "https://arxiv.org/html/2506.14436v3",
        "PDF": "https://arxiv.org/pdf/2506.14436"
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/dashenzi721/moore"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.14540",
      "abstract": "Machine learning-based decision support systems are increasingly deployed in clinical settings, where probabilistic scoring functions are used to inform and prioritize patient management decisions. However, widely used scoring rules, such as accuracy and AUC-ROC, fail to adequately reflect key clinical priorities, including calibration, robustness to distributional shifts, and sensitivity to asymmetric error costs. In this work, we propose a principled yet practical evaluation framework for selecting calibrated thresholded classifiers that explicitly accounts for the uncertainty in class prevalences and domain-specific cost asymmetries often found in clinical settings. Building on the theory of proper scoring rules, particularly the Schervish representation, we derive an adjusted variant of cross-entropy (log score) that averages cost-weighted performance over clinically relevant ranges of class balance. The resulting evaluation is simple to apply, sensitive to clinical deployment conditions, and designed to prioritize models that are both calibrated and robust to real-world variations.",
      "authors": [
        "Gerardo A. Flores and Alyssa H. Smith and Julia A. Fukuyama and Ashia C. Wilson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T14:01:39+00:00",
          "link": "https://arxiv.org/abs/2506.14540v1",
          "size": "277kb",
          "version": "v1"
        },
        {
          "date": "2025-06-18T02:06:16+00:00",
          "link": "https://arxiv.org/abs/2506.14540v2",
          "size": "271kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T11:59:31+00:00",
          "link": "https://arxiv.org/abs/2506.14540v3",
          "size": "272kb",
          "version": "v3"
        }
      ],
      "title": "Aligning Evaluation with Clinical Priorities: Calibration, Label Shift, and Error Costs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14540",
        "HTML": "https://arxiv.org/html/2506.14540v3",
        "PDF": "https://arxiv.org/pdf/2506.14540"
      },
      "tasks": [
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.14944",
      "abstract": "The Fair Data Exchange (FDE) protocol (CCS '24) provides atomic pay-per-file transfers with constant-size proofs, yet existing implementations remain unscalably slow (about 1 second per 4 KiB) and inflate ciphertexts by 10--50x. We introduce an FDE implementation that achieves near-plaintext speeds and sizes, making fair exchange practical even for gigabyte-scale files.\n  Our approach leverages two key insights. First, we observe that a KZG commitment to polynomial evaluations implicitly (and without modification) also binds to the Reed--Solomon (RS) codeword of its coefficients, enabling sound and efficient randomized verification. Second, while heavyweight encryption schemes such as exponential ElGamal enable compact proofs linking ciphertexts to the commitment, they are unnecessary for direct data recovery.\n  Exploiting these insights, we apply a lightweight hash-derived mask to the entire RS-extended codeword, and perform ElGamal encryption only on a pseudorandom \\Theta(lambda) subset of symbols, where lambda is the security parameter (e.g., 128). Data recovery occurs by simply removing the lightweight masks, with ElGamal ciphertexts serving exclusively for verification proofs. A heavyweight (but constant-time) zk-SNARK ensures consistency between these two encryption layers at sampled positions, sharply reducing bandwidth overhead and computational cost.\n  In addition, we show how a constant-time (and precomputable) zk-SNARK linking a BLS12-381 secret key to a secp256k1 hash pre-image resolves Bitcoin's elliptic-curve mismatch, enabling fully off-chain execution via the Lightning Network. This can reduce transaction fees from roughly $10 to under $0.01 and shortens transaction latency from tens of seconds on Ethereum down to about a second or less.",
      "authors": [
        "Majid Khabbazian"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T19:50:25+00:00",
          "link": "https://arxiv.org/abs/2506.14944v1",
          "size": "25kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T21:35:40+00:00",
          "link": "https://arxiv.org/abs/2506.14944v2",
          "size": "16kb",
          "version": "v2"
        }
      ],
      "title": "Fair Data Exchange at Near-Plaintext Efficiency",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14944",
        "HTML": "https://arxiv.org/html/2506.14944v2",
        "PDF": "https://arxiv.org/pdf/2506.14944"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.15079",
      "abstract": "Modern intelligent transportation systems rely on accurate spatiotemporal traffic analysis to optimize urban mobility and infrastructure resilience. However, pervasive missing data caused by sensor failures and heterogeneous sensing gaps fundamentally hinders reliable traffic modeling. This paper proposes a Neural Canonical Polyadic Factorization (NCPF) model that synergizes low-rank tensor algebra with deep representation learning for robust traffic data imputation. The model innovatively embeds CP decomposition into neural architecture through learnable embedding projections, where sparse traffic tensors are encoded into dense latent factors across road segments, time intervals, and mobility metrics. A hierarchical feature fusion mechanism employs Hadamard products to explicitly model multilinear interactions, while stacked multilayer perceptron layers nonlinearly refine these representations to capture complex spatiotemporal couplings. Extensive evaluations on six urban traffic datasets demonstrate NCPF's superiority over six state-of-the-art baselines. By unifying CP decomposition's interpretable factor analysis with neural network's nonlinear expressive power, NCPF provides a principled yet flexible approaches for high-dimensional traffic data imputation, offering critical support for next-generation transportation digital twins and adaptive traffic control systems.",
      "authors": [
        "Yikai Hou and Peng Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T02:45:25+00:00",
          "link": "https://arxiv.org/abs/2506.15079v1",
          "size": "610kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T04:06:21+00:00",
          "link": "https://arxiv.org/abs/2506.15079v2",
          "size": "610kb",
          "version": "v2"
        }
      ],
      "title": "Neural Canonical Polyadic Factorization for Traffic Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15079",
        "HTML": "https://arxiv.org/html/2506.15079v2",
        "PDF": "https://arxiv.org/pdf/2506.15079"
      },
      "tasks": [
        "Imputation",
        "Representation Learning",
        "tensor algebra",
        "Traffic Data Imputation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.15318",
      "abstract": "Pathology image classification plays a crucial role in accurate medical diagnosis and treatment planning. Training high-performance models for this task typically requires large-scale annotated datasets, which are both expensive and time-consuming to acquire. Active Learning (AL) offers a solution by iteratively selecting the most informative samples for annotation, thereby reducing the labeling effort. However, most AL methods are designed under the assumption of a closed-set scenario, where all the unannotated images belong to target classes. In real-world clinical environments, the unlabeled pool often contains a substantial amount of Out-Of-Distribution (OOD) data, leading to low efficiency of annotation in traditional AL methods. Furthermore, most existing AL methods start with random selection in the first query round, leading to a significant waste of labeling costs in open-set scenarios. To address these challenges, we propose OpenPath, a novel open-set active learning approach for pathological image classification leveraging a pre-trained Vision-Language Model (VLM). In the first query, we propose task-specific prompts that combine target and relevant non-target class prompts to effectively select In-Distribution (ID) and informative samples from the unlabeled pool. In subsequent queries, Diverse Informative ID Sampling (DIS) that includes Prototype-based ID candidate Selection (PIS) and Entropy-Guided Stochastic Sampling (EGSS) is proposed to ensure both purity and informativeness in a query, avoiding the selection of OOD samples. Experiments on two public pathology image datasets show that OpenPath significantly enhances the model's performance due to its high purity of selected samples, and outperforms several state-of-the-art open-set AL methods. The code is available at \\href{https://github.com/HiLab-git/OpenPath}{https://github.com/HiLab-git/OpenPath}..",
      "authors": [
        "Lanfeng Zhong",
        "Xin Liao",
        "Shichuan Zhang",
        "Shaoting Zhang",
        "and Guotai Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T09:47:45+00:00",
          "link": "https://arxiv.org/abs/2506.15318v1",
          "size": "3533kb",
          "version": "v1"
        },
        {
          "date": "2025-06-19T09:34:29+00:00",
          "link": "https://arxiv.org/abs/2506.15318v2",
          "size": "3533kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T10:26:44+00:00",
          "link": "https://arxiv.org/abs/2506.15318v3",
          "size": "3533kb",
          "version": "v3"
        }
      ],
      "title": "OpenPath: Open-Set Active Learning for Pathology Image Classification via Pre-trained Vision-Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15318",
        "HTML": "https://arxiv.org/html/2506.15318v3",
        "PDF": "https://arxiv.org/pdf/2506.15318"
      },
      "tasks": [
        "Active Learning",
        "image-classification",
        "Image Classification",
        "Informativeness",
        "Medical Diagnosis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.15596",
      "abstract": "In clinical practice, imaging modalities with functional characteristics, such as positron emission tomography (PET) and fractional anisotropy (FA), are often aligned with a structural reference (e.g., MRI, CT) for accurate interpretation or group analysis, necessitating multi-modal deformable image registration (DIR). However, due to the extreme heterogeneity of these modalities compared to standard structural scans, conventional unsupervised DIR methods struggle to learn reliable spatial mappings and often distort images. We find that the similarity metrics guiding these models fail to capture alignment between highly disparate modalities. To address this, we propose M2M-Reg (Multi-to-Mono Registration), a novel framework that trains multi-modal DIR models using only mono-modal similarity while preserving the established architectural paradigm for seamless integration into existing models. We also introduce GradCyCon, a regularizer that leverages M2M-Reg's cyclic training scheme to promote diffeomorphism. Furthermore, our framework naturally extends to a semi-supervised setting, integrating pre-aligned and unaligned pairs only, without requiring ground-truth transformations or segmentation masks. Experiments on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset demonstrate that M2M-Reg achieves up to 2x higher DSC than prior methods for PET-MRI and FA-MRI registration, highlighting its effectiveness in handling highly heterogeneous multi-modal DIR. Our code is available at https://github.com/MICV-yonsei/M2M-Reg.",
      "authors": [
        "Kyobin Choo",
        "Hyunkyung Han",
        "Jinyeong Kim",
        "Chanyong Yoon",
        "Seong Jae Hwang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T16:12:46+00:00",
          "link": "https://arxiv.org/abs/2506.15596v1",
          "size": "2227kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T07:41:55+00:00",
          "link": "https://arxiv.org/abs/2506.15596v2",
          "size": "2228kb",
          "version": "v2"
        }
      ],
      "title": "Mono-Modalizing Extremely Heterogeneous Multi-Modal Medical Image Registration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15596",
        "HTML": "https://arxiv.org/html/2506.15596v2",
        "PDF": "https://arxiv.org/pdf/2506.15596"
      },
      "tasks": [
        "Image Registration",
        "Medical Image Registration"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.15831",
      "abstract": "The presence of concept drift poses challenges for anomaly detection in time series. While anomalies are caused by undesirable changes in the data, differentiating abnormal changes from varying normal behaviours is difficult due to differing frequencies of occurrence, varying time intervals when normal patterns occur, and identifying similarity thresholds to separate the boundary between normal vs. abnormal sequences. Differentiating between concept drift and anomalies is critical for accurate analysis as studies have shown that the compounding effects of error propagation in downstream tasks lead to lower detection accuracy and increased overhead due to unnecessary model updates. Unfortunately, existing work has largely explored anomaly detection and concept drift detection in isolation. We introduce AnDri, a framework for Anomaly detection in the presence of Drift. AnDri introduces the notion of a dynamic normal model where normal patterns are activated, deactivated or newly added, providing flexibility to adapt to concept drift and anomalies over time. We introduce a new clustering method, Adjacent Hierarchical Clustering (AHC), for learning normal patterns that respect their temporal locality; critical for detecting short-lived, but recurring patterns that are overlooked by existing methods. Our evaluation shows AnDri outperforms existing baselines using real datasets with varying types, proportions, and distributions of concept drift and anomalies.",
      "authors": [
        "Jongjun Park",
        "Fei Chiang",
        "and Mostafa Milani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T19:17:55+00:00",
          "link": "https://arxiv.org/abs/2506.15831v1",
          "size": "781kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T01:23:01+00:00",
          "link": "https://arxiv.org/abs/2506.15831v2",
          "size": "10953kb",
          "version": "v2"
        }
      ],
      "title": "Adaptive Anomaly Detection in the Presence of Concept Drift: Extended Report",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15831",
        "HTML": "https://arxiv.org/html/2506.15831v2",
        "PDF": "https://arxiv.org/pdf/2506.15831"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.15981",
      "abstract": "The rapid advancement of AI-based music generation tools is revolutionizing the music industry but also posing challenges to artists, copyright holders, and providers alike. This necessitates reliable methods for detecting such AI-generated content. However, existing detectors, relying on either audio or lyrics, face key practical limitations: audio-based detectors fail to generalize to new or unseen generators and are vulnerable to audio perturbations; lyrics-based methods require cleanly formatted and accurate lyrics, unavailable in practice. To overcome these limitations, we propose a novel, practically grounded approach: a multimodal, modular late-fusion pipeline that combines automatically transcribed sung lyrics and speech features capturing lyrics-related information within the audio. By relying on lyrical aspects directly from audio, our method enhances robustness, mitigates susceptibility to low-level artifacts, and enables practical applicability. Experiments show that our method, DE-detect, outperforms existing lyrics-based detectors while also being more robust to audio perturbations. Thus, it offers an effective, robust solution for detecting AI-generated music in real-world scenarios. Our code is available at https://github.com/deezer/robust-AI-lyrics-detection.",
      "authors": [
        "Markus Frohmann",
        "Gabriel Meseguer-Brocal",
        "Markus Schedl",
        "Elena V. Epure"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Sound (cs.SD)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T02:56:49+00:00",
          "link": "https://arxiv.org/abs/2506.15981v1",
          "size": "521kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T05:47:16+00:00",
          "link": "https://arxiv.org/abs/2506.15981v2",
          "size": "556kb",
          "version": "v2"
        }
      ],
      "title": "Double Entendre: Robust Audio-Based AI-Generated Lyrics Detection via Multi-View Fusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.15981",
        "HTML": "https://arxiv.org/html/2506.15981v2",
        "PDF": "https://arxiv.org/pdf/2506.15981"
      },
      "tasks": [
        "Music Generation"
      ],
      "repo_urls": [
        "https://github.com/deezer/robust-ai-lyrics-detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.16206",
      "abstract": "Many-valued models generalise the structures from classical model theory by defining truth values for a model with an arbitrary algebra. Just as algebraic varieties provide semantics for many non-classical propositional logics, models defined over algebras in a variety provide the semantics for the corresponding non-classical predicate logics. In particular models defined over varieties of residuated lattices represent the model theory for first-order substructrual logics.\n  In this paper we study the extent to which the classical locality theorems from Hanf and Gaifman hold true in the residuated lattice setting. We demonstrate that the answer is sensitive both to how locality is understood in the generalised context and the behaviour of the truth-defining algebra. In the case of Hanf's theorem, we will show that the theorem fails for the natural understanding of local neighbourhoods, but is recoverable in one special case for well-connected residuated lattices. For Gaifman's theorem, rather than consider Gaifman normal forms directly we focus on the main lemma of the theorem from textbook proofs. We prove that for a number of different understandings of locality, provided the algebra is well-behaved enough to express locality in its syntax, this main lemma can be recovered. In each case we will see that importance of an order-interpreting connective which creates a link between the modelling relation between models and formulas and the valuation function from formulas into the algebra.",
      "authors": [
        "James Carr"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Logic (math.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T10:49:17+00:00",
          "link": "https://arxiv.org/abs/2506.16206v1",
          "size": "43kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T09:18:35+00:00",
          "link": "https://arxiv.org/abs/2506.16206v2",
          "size": "43kb",
          "version": "v2"
        }
      ],
      "title": "Locality in Residuated-Lattice Structures",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16206",
        "HTML": "https://arxiv.org/html/2506.16206v2",
        "PDF": "https://arxiv.org/pdf/2506.16206"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.16398",
      "abstract": "Pathology is essential for cancer diagnosis, with multiple instance learning (MIL) widely used for whole slide image (WSI) analysis. WSIs exhibit a natural hierarchy -- patches, regions, and slides -- with distinct semantic associations. While some methods attempt to leverage this hierarchy for improved representation, they predominantly rely on Euclidean embeddings, which struggle to fully capture semantic hierarchies. To address this limitation, we propose HyperPath, a novel method that integrates knowledge from textual descriptions to guide the modeling of semantic hierarchies of WSIs in hyperbolic space, thereby enhancing WSI classification. Our approach adapts both visual and textual features extracted by pathology vision-language foundation models to the hyperbolic space. We design an Angular Modality Alignment Loss to ensure robust cross-modal alignment, while a Semantic Hierarchy Consistency Loss further refines feature hierarchies through entailment and contradiction relationships and thus enhance semantic coherence. The classification is performed with geodesic distance, which measures the similarity between entities in the hyperbolic semantic hierarchy. This eliminates the need for linear classifiers and enables a geometry-aware approach to WSI analysis. Extensive experiments show that our method achieves superior performance across tasks compared to existing methods, highlighting the potential of hyperbolic embeddings for WSI analysis.",
      "authors": [
        "Peixiang Huang",
        "Yanyan Huang",
        "Weiqin Zhao",
        "Junjun He",
        "Lequan Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T15:30:33+00:00",
          "link": "https://arxiv.org/abs/2506.16398v1",
          "size": "639kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T09:10:30+00:00",
          "link": "https://arxiv.org/abs/2506.16398v2",
          "size": "639kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T04:35:34+00:00",
          "link": "https://arxiv.org/abs/2506.16398v3",
          "size": "639kb",
          "version": "v3"
        }
      ],
      "title": "HyperPath: Knowledge-Guided Hyperbolic Semantic Hierarchy Modeling for WSI Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16398",
        "HTML": "https://arxiv.org/html/2506.16398v3",
        "PDF": "https://arxiv.org/pdf/2506.16398"
      },
      "tasks": [
        "cross-modal alignment",
        "Multiple Instance Learning"
      ],
      "repo_urls": [
        "https://github.com/lambert-hpx/hyperpath"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.16453",
      "abstract": "The release of ChatGPT in 2022 triggered a rapid surge in generative artificial intelligence mobile apps (i.e., Gen-AI apps). Despite widespread adoption, little is known about how end users perceive and evaluate these Gen-AI functionalities in practice. In this work, we conduct a user-centered analysis of 676,066 reviews from 173 Gen-AI apps on the Google Play Store. We introduce a four-phase methodology, SARA (Selection, Acquisition, Refinement, and Analysis), that enables the systematic extraction of user insights using prompt-based LLM techniques. First, we demonstrate the reliability of LLMs in topic extraction, achieving 91% accuracy through five-shot prompting and non-informative review filtering. Then, we apply this method to the informative reviews, identify the top 10 user-discussed topics (e.g., AI Performance, Content Quality, and Content Policy & Censorship) and analyze the key challenges and emerging opportunities. Finally, we examine how these topics evolve over time, offering insight into shifting user expectations and engagement patterns with Gen-AI apps. Based on our findings and observations, we present actionable implications for developers and researchers.",
      "authors": [
        "Buthayna AlMulla",
        "Maram Assi",
        "Safwat Hassan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T16:39:55+00:00",
          "link": "https://arxiv.org/abs/2506.16453v1",
          "size": "5065kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T04:39:35+00:00",
          "link": "https://arxiv.org/abs/2506.16453v2",
          "size": "5064kb",
          "version": "v2"
        }
      ],
      "title": "Understanding the Challenges and Promises of Developing Generative AI Apps: An Empirical Study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16453",
        "HTML": "https://arxiv.org/html/2506.16453v2",
        "PDF": "https://arxiv.org/pdf/2506.16453"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.16629",
      "abstract": "Causal inference in longitudinal biomedical data remains a central challenge, especially in psychiatry, where symptom heterogeneity and latent confounding frequently undermine classical estimators. Most existing methods for treatment effect estimation presuppose a fixed outcome variable and address confounding through observed covariate adjustment. However, the assumption of unconfoundedness may not hold for a fixed outcome in practice. To address this foundational limitation, we directly optimize the outcome definition to maximize causal identifiability. Our DEBIAS (Durable Effects with Backdoor-Invariant Aggregated Symptoms) algorithm learns non-negative, clinically interpretable weights for outcome aggregation, maximizing durable treatment effects and empirically minimizing both observed and latent confounding by leveraging the time-limited direct effects of prior treatments in psychiatric longitudinal data. The algorithm also furnishes an empirically verifiable test for outcome unconfoundedness. DEBIAS consistently outperforms state-of-the-art methods in recovering causal effects for clinically interpretable composite outcomes across comprehensive experiments in depression and schizophrenia.",
      "authors": [
        "Eric V. Strobl"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Quantitative Methods (q-bio.QM)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T21:56:30+00:00",
          "link": "https://arxiv.org/abs/2506.16629v1",
          "size": "1701kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T01:26:01+00:00",
          "link": "https://arxiv.org/abs/2506.16629v2",
          "size": "1784kb",
          "version": "v2"
        }
      ],
      "title": "Learning Causally Predictable Outcomes from Psychiatric Longitudinal Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16629",
        "PDF": "https://arxiv.org/pdf/2506.16629"
      },
      "tasks": [
        "Causal Inference"
      ],
      "repo_urls": [
        "https://github.com/ericstrobl/debias"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.16666",
      "abstract": "This paper systematizes research on auditing Differential Privacy (DP) techniques, aiming to identify key insights into the current state of the art and open challenges. First, we introduce a comprehensive framework for reviewing work in the field and establish three cross-contextual desiderata that DP audits should target--namely, efficiency, end-to-end-ness, and tightness. Then, we systematize the modes of operation of state-of-the-art DP auditing techniques, including threat models, attacks, and evaluation functions. This allows us to highlight key details overlooked by prior work, analyze the limiting factors to achieving the three desiderata, and identify open research problems. Overall, our work provides a reusable and systematic methodology geared to assess progress in the field and identify friction points and future directions for our community to focus on.",
      "authors": [
        "Meenatchi Sundaram Muthu Selva Annamalai",
        "Borja Balle",
        "Jamie Hayes",
        "Georgios Kaissis",
        "Emiliano De Cristofaro"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T00:32:59+00:00",
          "link": "https://arxiv.org/abs/2506.16666v1",
          "size": "466kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T04:43:10+00:00",
          "link": "https://arxiv.org/abs/2506.16666v2",
          "size": "467kb",
          "version": "v2"
        }
      ],
      "title": "The Hitchhiker's Guide to Efficient, End-to-End, and Tight DP Auditing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16666",
        "HTML": "https://arxiv.org/html/2506.16666v2",
        "PDF": "https://arxiv.org/pdf/2506.16666"
      },
      "tasks": [
        "Friction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.16692",
      "abstract": "Given the significant influence of lawmakers' political ideologies on legislative decision-making, analyzing their impact on transportation-related policymaking is of critical importance. This study introduces a novel framework that integrates a large language model (LLM) with explainable artificial intelligence (XAI) to analyze transportation-related legislative proposals. Legislative bill data from South Korea's 21st National Assembly were used to identify key factors shaping transportation policymaking. These include political affiliations and sponsor characteristics. The LLM was employed to classify transportation-related bill proposals through a stepwise filtering process based on keywords, sentences, and contextual relevance. XAI techniques were then applied to examine the relationships between political party affiliation and associated attributes. The results revealed that the number and proportion of conservative and progressive sponsors, along with district size and electoral population, were critical determinants shaping legislative outcomes. These findings suggest that both parties contributed to bipartisan legislation through different forms of engagement, such as initiating or supporting proposals. This integrated approach offers a valuable tool for understanding legislative dynamics and guiding future policy development, with broader implications for infrastructure planning and governance.",
      "authors": [
        "Hyunsoo Yun and Eun Hak Lee"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T02:25:52+00:00",
          "link": "https://arxiv.org/abs/2506.16692v1",
          "size": "2604kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T03:42:00+00:00",
          "link": "https://arxiv.org/abs/2506.16692v2",
          "size": "2604kb",
          "version": "v2"
        }
      ],
      "title": "LegiGPT: Party Politics and Transport Policy with Large Language Model",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.16692",
        "HTML": "https://arxiv.org/html/2506.16692v2",
        "PDF": "https://arxiv.org/pdf/2506.16692"
      },
      "tasks": [
        "Explainable artificial intelligence",
        "Explainable Artificial Intelligence (XAI)",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.17455",
      "abstract": "Robust visual recognition in underwater environments remains a significant challenge due to complex distortions such as turbidity, low illumination, and occlusion, which severely degrade the performance of standard vision systems. This paper introduces AQUA20, a comprehensive benchmark dataset comprising 8,171 underwater images across 20 marine species reflecting real-world environmental challenges such as illumination, turbidity, occlusions, etc., providing a valuable resource for underwater visual understanding. Thirteen state-of-the-art deep learning models, including lightweight CNNs (SqueezeNet, MobileNetV2) and transformer-based architectures (ViT, ConvNeXt), were evaluated to benchmark their performance in classifying marine species under challenging conditions. Our experimental results show ConvNeXt achieving the best performance, with a Top-3 accuracy of 98.82% and a Top-1 accuracy of 90.69%, as well as the highest overall F1-score of 88.92% with moderately large parameter size. The results obtained from our other benchmark models also demonstrate trade-offs between complexity and performance. We also provide an extensive explainability analysis using GRAD-CAM and LIME for interpreting the strengths and pitfalls of the models. Our results reveal substantial room for improvement in underwater species recognition and demonstrate the value of AQUA20 as a foundation for future research in this domain. The dataset is publicly available at: https://huggingface.co/datasets/taufiktrf/AQUA20.",
      "authors": [
        "Taufikur Rahman Fuad",
        "Sabbir Ahmed",
        "Shahriar Ivan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-20T19:54:35+00:00",
          "link": "https://arxiv.org/abs/2506.17455v1",
          "size": "16844kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T17:27:51+00:00",
          "link": "https://arxiv.org/abs/2506.17455v2",
          "size": "16447kb",
          "version": "v2"
        }
      ],
      "title": "AQUA20: A Benchmark Dataset for Underwater Species Classification under Challenging Conditions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17455",
        "HTML": "https://arxiv.org/html/2506.17455v2",
        "PDF": "https://arxiv.org/pdf/2506.17455"
      },
      "datasets": [
        {
          "dataset_name": "taufiktrf/AQUA20",
          "downloads": "60",
          "likes": "0",
          "link": "https://huggingface.co/datasets/taufiktrf/AQUA20"
        }
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.17525",
      "abstract": "Our quality audit for three widely used public multilingual speech datasets - Mozilla Common Voice 17.0, FLEURS, and Vox Populi - shows that in some languages, these datasets suffer from significant quality issues, which may obfuscate downstream evaluation results while creating an illusion of success. We divide these quality issues into two categories: micro-level and macro-level. We find that macro-level issues are more prevalent in less institutionalized, often under-resourced languages. We provide a case analysis of Taiwanese Southern Min (nan_tw) that highlights the need for proactive language planning (e.g. orthography prescriptions, dialect boundary definition) and enhanced data quality control in the dataset creation process. We conclude by proposing guidelines and recommendations to mitigate these issues in future dataset development, emphasizing the importance of sociolinguistic awareness and language planning principles. Furthermore, we encourage research into how this creation process itself can be leveraged as a tool for community-led language planning and revitalization.",
      "authors": [
        "Mingfei Lau",
        "Qian Chen",
        "Yeming Fang",
        "Tingting Xu",
        "Tongzhou Chen",
        "Pavel Golik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-21T00:34:18+00:00",
          "link": "https://arxiv.org/abs/2506.17525v1",
          "size": "557kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T18:38:01+00:00",
          "link": "https://arxiv.org/abs/2506.17525v2",
          "size": "557kb",
          "version": "v2"
        }
      ],
      "title": "Data Quality Issues in Multilingual Speech Datasets: The Need for Sociolinguistic Awareness and Proactive Language Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17525",
        "HTML": "https://arxiv.org/html/2506.17525v2",
        "PDF": "https://arxiv.org/pdf/2506.17525"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.17609",
      "abstract": "Accurate typhoon track forecasting is crucial for early system warning and disaster response. While Transformer-based models have demonstrated strong performance in modeling the temporal dynamics of dense trajectories of humans and vehicles in smart cities, they usually lack access to broader contextual knowledge that enhances the forecasting reliability of sparse meteorological trajectories, such as typhoon tracks. To address this challenge, we propose TyphoFormer, a novel framework that incorporates natural language descriptions as auxiliary prompts to improve typhoon trajectory forecasting. For each time step, we use Large Language Model (LLM) to generate concise textual descriptions based on the numerical attributes recorded in the North Atlantic hurricane database. The language descriptions capture high-level meteorological semantics and are embedded as auxiliary special tokens prepended to the numerical time series input. By integrating both textual and sequential information within a unified Transformer encoder, TyphoFormer enables the model to leverage contextual cues that are otherwise inaccessible through numerical features alone. Extensive experiments are conducted on HURDAT2 benchmark, results show that TyphoFormer consistently outperforms other state-of-the-art baseline methods, particularly under challenging scenarios involving nonlinear path shifts and limited historical observations.",
      "authors": [
        "Lincan Li",
        "Eren Erman Ozguven",
        "Yue Zhao",
        "Guang Wang",
        "Yiqun Xie",
        "Yushun Dong"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-21T06:14:57+00:00",
          "link": "https://arxiv.org/abs/2506.17609v1",
          "size": "1107kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T04:29:52+00:00",
          "link": "https://arxiv.org/abs/2506.17609v2",
          "size": "1142kb",
          "version": "v2"
        }
      ],
      "title": "TyphoFormer: Language-Augmented Transformer for Accurate Typhoon Track Forecasting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17609",
        "HTML": "https://arxiv.org/html/2506.17609v2",
        "PDF": "https://arxiv.org/pdf/2506.17609"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.17718",
      "abstract": "Endowing deep models with the ability to generalize in dynamic scenarios is of vital significance for real-world deployment, given the continuous and complex changes in data distribution. Recently, evolving domain generalization (EDG) has emerged to address distribution shifts over time, aiming to capture evolving patterns for improved model generalization. However, existing EDG methods may suffer from spurious correlations by modeling only the dependence between data and targets across domains, creating a shortcut between task-irrelevant factors and the target, which hinders generalization. To this end, we design a time-aware structural causal model (SCM) that incorporates dynamic causal factors and the causal mechanism drifts, and propose \\textbf{S}tatic-D\\textbf{YN}amic \\textbf{C}ausal Representation Learning (\\textbf{SYNC}), an approach that effectively learns time-aware causal representations. Specifically, it integrates specially designed information-theoretic objectives into a sequential VAE framework which captures evolving patterns, and produces the desired representations by preserving intra-class compactness of causal factors both across and within domains. Moreover, we theoretically show that our method can yield the optimal causal predictor for each time domain. Results on both synthetic and real-world datasets exhibit that SYNC can achieve superior temporal generalization performance.",
      "authors": [
        "Zhuo He",
        "Shuang Li",
        "Wenze Song",
        "Longhui Yuan",
        "Jian Liang",
        "Han Li",
        "Kun Gai"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-21T14:05:37+00:00",
          "link": "https://arxiv.org/abs/2506.17718v1",
          "size": "1133kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T07:42:53+00:00",
          "link": "https://arxiv.org/abs/2506.17718v2",
          "size": "1133kb",
          "version": "v2"
        }
      ],
      "title": "Learning Time-Aware Causal Representation for Model Generalization in Evolving Domains",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17718",
        "HTML": "https://arxiv.org/html/2506.17718v2",
        "PDF": "https://arxiv.org/pdf/2506.17718"
      },
      "tasks": [
        "Domain Generalization",
        "Evolving Domain Generalization",
        "Representation Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.17728",
      "abstract": "In this paper, we introduce KAG-Thinker, which upgrade KAG to a multi-turn interactive thinking and deep reasoning framework powered by a dedicated parameter-light large language model (LLM). Our approach constructs a structured thinking process for solving complex problems, enhancing the the logical coherence and contextual consistency of the reasoning process in question-answering (Q&A) tasks on domain-specific knowledge bases (KBs) within LLMs. Following the \\textbf{Logical Form} guided retrieval and reasoning technology route of KAG, this framework first decomposes complex questions into independently solvable sub-problems (which are also referred to as logical forms) through \\textbf{breadth decomposition}. Each such logical form is represented in two equivalent forms-natural language and logical function-and subsequently classified as either a Knowledge Retrieval or Reasoning Analysis task. Dependencies and parameter passing between these tasks are explicitly modeled via logical function interfaces. In the solving process, the Retrieval function performs retrieval tasks. It retrieves one-hop structured and unstructured information of specified knowledge unit. While the Math and Deduce functions are used to perform reasoning analysis tasks. Secondly, it is worth noting that, in the Knowledge Retrieval sub-problem tasks, LLMs and external knowledge sources are regarded as equivalent KBs. We use the \\textbf{knowledge boundary} module to determine the optimal source using self-regulatory mechanisms such as confidence calibration and reflective reasoning, and use the \\textbf{depth solving} module to enhance the comprehensiveness of knowledge acquisition...",
      "authors": [
        "Dalong Zhang",
        "Jun Xu",
        "Jun Zhou",
        "Lei Liang",
        "Lin Yuan",
        "Ling Zhong",
        "Mengshu Sun",
        "Peilong Zhao",
        "QiWei Wang",
        "Xiaorui Wang",
        "Xinkai Du",
        "YangYang Hou",
        "Yu Ao",
        "ZhaoYang Wang",
        "Zhengke Gui",
        "ZhiYing Yi",
        "Zhongpu Bo",
        "Haofen Wang",
        "Huajun Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-21T14:58:53+00:00",
          "link": "https://arxiv.org/abs/2506.17728v1",
          "size": "922kb",
          "version": "v1"
        },
        {
          "date": "2025-06-24T12:50:57+00:00",
          "link": "https://arxiv.org/abs/2506.17728v2",
          "size": "938kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T08:08:21+00:00",
          "link": "https://arxiv.org/abs/2506.17728v3",
          "size": "912kb",
          "version": "v3"
        }
      ],
      "title": "KAG-Thinker: Interactive Thinking and Deep Reasoning in LLMs via Knowledge-Augmented Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17728",
        "HTML": "https://arxiv.org/html/2506.17728v3",
        "PDF": "https://arxiv.org/pdf/2506.17728"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.17858",
      "abstract": "Analyzing fetal body motion and shape is paramount in prenatal diagnostics and monitoring. Existing methods for fetal MRI analysis mainly rely on anatomical keypoints or volumetric body segmentations. Keypoints simplify body structure to facilitate motion analysis, but may ignore important details of full-body shape. Body segmentations capture complete shape information but complicate temporal analysis due to large non-local fetal movements. To address these limitations, we construct a 3D articulated statistical fetal body model based on the Skinned Multi-Person Linear Model (SMPL). Our algorithm iteratively estimates body pose in the image space and body shape in the canonical pose space. This approach improves robustness to MRI motion artifacts and intensity distortions, and reduces the impact of incomplete surface observations due to challenging fetal poses. We train our model on segmentations and keypoints derived from $19,816$ MRI volumes across $53$ subjects. Our model captures body shape and motion across time series and provides intuitive visualization. Furthermore, it enables automated anthropometric measurements traditionally difficult to obtain from segmentations and keypoints. When tested on unseen fetal body shapes, our method yields a surface alignment error of $3.2$ mm for $3$ mm MRI voxel size. To our knowledge, this represents the first 3D articulated statistical fetal body model, paving the way for enhanced fetal motion and shape analysis in prenatal diagnostics. The code is available at https://github.com/MedicalVisionGroup/fetal-smpl .",
      "authors": [
        "Yingcheng Liu",
        "Peiqi Wang",
        "Sebastian Diaz",
        "Esra Abaci Turk",
        "Benjamin Billot",
        "Patricia Ellen Grant",
        "and Polina Golland"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-21T23:45:35+00:00",
          "link": "https://arxiv.org/abs/2506.17858v1",
          "size": "4729kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T02:47:24+00:00",
          "link": "https://arxiv.org/abs/2506.17858v2",
          "size": "4729kb",
          "version": "v2"
        }
      ],
      "title": "Fetuses Made Simple: Modeling and Tracking of Fetal Shape and Pose",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17858",
        "HTML": "https://arxiv.org/html/2506.17858v2",
        "PDF": "https://arxiv.org/pdf/2506.17858"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.17872",
      "abstract": "Federated learning has significantly advanced distributed training of machine learning models across decentralized data sources. However, existing frameworks often lack comprehensive solutions that combine uncertainty quantification, interpretability, and robustness. To address this, we propose FedNAM+, a federated learning framework that integrates Neural Additive Models (NAMs) with a novel conformal prediction method to enable interpretable and reliable uncertainty estimation. Our method introduces a dynamic level adjustment technique that utilizes gradient-based sensitivity maps to identify key input features influencing predictions. This facilitates both interpretability and pixel-wise uncertainty estimates. Unlike traditional interpretability methods such as LIME and SHAP, which do not provide confidence intervals, FedNAM+ offers visual insights into prediction reliability. We validate our approach through experiments on CT scan, MNIST, and CIFAR datasets, demonstrating high prediction accuracy with minimal loss (e.g., only 0.1% on MNIST), along with transparent uncertainty measures. Visual analysis highlights variable uncertainty intervals, revealing low-confidence regions where model performance can be improved with additional data. Compared to Monte Carlo Dropout, FedNAM+ delivers efficient and global uncertainty estimates with reduced computational overhead, making it particularly suitable for federated learning scenarios. Overall, FedNAM+ provides a robust, interpretable, and computationally efficient framework that enhances trust and transparency in decentralized predictive modeling.",
      "authors": [
        "Sree Bhargavi Balija",
        "Amitash Nanda",
        "Debashis Sahoo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-22T02:06:14+00:00",
          "link": "https://arxiv.org/abs/2506.17872v1",
          "size": "1450kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T04:14:41+00:00",
          "link": "https://arxiv.org/abs/2506.17872v2",
          "size": "1448kb",
          "version": "v2"
        }
      ],
      "title": "Decoding Federated Learning: The FedNAM+ Conformal Revolution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17872",
        "HTML": "https://arxiv.org/html/2506.17872v2",
        "PDF": "https://arxiv.org/pdf/2506.17872"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18398",
      "abstract": "Rug pull scams have emerged as a persistent threat to cryptocurrency, causing significant financial losses. A typical scenario involves scammers deploying honeypot contracts to attract investments, restricting token sales, and draining the funds, which leaves investors with worthless tokens. Current methods either rely on predefined patterns to detect code risks or utilize statistical transaction data to train detection models. However, real-world Rug Pull schemes often involve a complex interplay between malicious code and suspicious transaction behaviors. These methods, which solely focus on one aspect, fall short in detecting such schemes effectively.\n  In this paper, we propose RPHunter, a novel technique that integrates code and transaction for Rug Pull detection. First, RPHunter establishes declarative rules and performs flow analysis to extract code risk information, further constructing a semantic risk code graph (SRCG). Meanwhile, to leverage transaction information, RPHunter formulates dynamic token transaction activities as a token flow behavior graph (TFBG) in which nodes and edges are characterized from network structure and market manipulation perspectives. Finally, RPHunter employs graph neural networks to extract complementary features from SRCG and TFBG, integrating them through an attention fusion model to enhance the detection of Rug Pull. We manually analyzed 645 Rug Pull incidents from code and transaction aspects and constructed a ground-truth dataset. We evaluated RPHunter on our dataset, achieving a precision of 95.3%, a recall of 93.8% and an F1 score of 94.5%, which highlights superior performance compared to existing methods. Furthermore, when applied to the real-world scenarios, RPHunter has identified 4801 Rug Pull tokens, achieving a precision of 90.7%.",
      "authors": [
        "Hao Wu",
        "Haijun Wang",
        "Shangwang Li",
        "Yin Wu",
        "Ming Fan",
        "Wuxia Jin",
        "Yitao Zhao",
        "Ting Liu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T08:34:15+00:00",
          "link": "https://arxiv.org/abs/2506.18398v1",
          "size": "4001kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T09:39:05+00:00",
          "link": "https://arxiv.org/abs/2506.18398v2",
          "size": "4184kb",
          "version": "v2"
        }
      ],
      "title": "RPHunter: Unveiling Rug Pull Schemes in Crypto Token via Code-and-Transaction Fusion Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18398",
        "HTML": "https://arxiv.org/html/2506.18398v2",
        "PDF": "https://arxiv.org/pdf/2506.18398"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18439",
      "abstract": "In this paper, we study the problem of model-checking quantum pushdown systems from a computational complexity point of view. We arrive at the following equally important, interesting new results:\n  We first extend the notions of the {\\it probabilistic pushdown systems} and {\\it Markov chains} to their quantum analogues and investigate the question of whether it is necessary to define a quantum analogue of {\\it probabilistic computational tree logic} to describe the probabilistic and branching-time properties of the {\\it quantum Markov chain}. We study its model-checking question and show that model-checking of {\\it stateless quantum pushdown systems (qBPA)} against {\\it probabilistic computational tree logic (PCTL)} is generally undecidable, i.e., there exists no algorithm for model-checking {\\it stateless quantum pushdown systems} against {\\it probabilistic computational tree logic}.\n  We then study in which case there exists an algorithm for model-checking {\\it stateless quantum pushdown systems} and show that the problem of model-checking {\\it stateless quantum pushdown systems} against {\\it bounded probabilistic computational tree logic} (bPCTL) is decidable, and further show that this problem is in $NP$-complete. Our reduction is from the {\\it bounded Post Correspondence Problem} for the first time, a well-known $NP$-complete problem.",
      "authors": [
        "Deren Lin",
        "Tianrong Lin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)",
        "Computational Complexity (cs.CC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T09:22:23+00:00",
          "link": "https://arxiv.org/abs/2506.18439v1",
          "size": "23kb",
          "version": "v1"
        },
        {
          "date": "2025-06-25T03:25:35+00:00",
          "link": "https://arxiv.org/abs/2506.18439v2",
          "size": "23kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T15:15:15+00:00",
          "link": "https://arxiv.org/abs/2506.18439v3",
          "size": "23kb",
          "version": "v3"
        }
      ],
      "title": "Computational Complexity of Model-Checking Quantum Pushdown Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18439",
        "HTML": "https://arxiv.org/html/2506.18439v3",
        "PDF": "https://arxiv.org/pdf/2506.18439"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18488",
      "abstract": "The recent rise in capabilities of AI-based music generation tools has created an upheaval in the music industry, necessitating the creation of accurate methods to detect such AI-generated content. This can be done using audio-based detectors; however, it has been shown that they struggle to generalize to unseen generators or when the audio is perturbed. Furthermore, recent work used accurate and cleanly formatted lyrics sourced from a lyrics provider database to detect AI-generated music. However, in practice, such perfect lyrics are not available (only the audio is); this leaves a substantial gap in applicability in real-life use cases. In this work, we instead propose solving this gap by transcribing songs using general automatic speech recognition (ASR) models. We do this using several detectors. The results on diverse, multi-genre, and multi-lingual lyrics show generally strong detection performance across languages and genres, particularly for our best-performing model using Whisper large-v2 and LLM2Vec embeddings. In addition, we show that our method is more robust than state-of-the-art audio-based ones when the audio is perturbed in different ways and when evaluated on different music generators. Our code is available at https://github.com/deezer/robust-AI-lyrics-detection.",
      "authors": [
        "Markus Frohmann",
        "Elena V. Epure",
        "Gabriel Meseguer-Brocal",
        "Markus Schedl",
        "Romain Hennequin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T10:42:50+00:00",
          "link": "https://arxiv.org/abs/2506.18488v1",
          "size": "822kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T05:44:41+00:00",
          "link": "https://arxiv.org/abs/2506.18488v2",
          "size": "822kb",
          "version": "v2"
        }
      ],
      "title": "AI-Generated Song Detection via Lyrics Transcripts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18488",
        "HTML": "https://arxiv.org/html/2506.18488v2",
        "PDF": "https://arxiv.org/pdf/2506.18488"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18501",
      "abstract": "The increasing use of large language models (LLMs) in natural language processing (NLP) tasks has sparked significant interest in evaluating their effectiveness across diverse applications. While models like ChatGPT and DeepSeek have shown strong results in many NLP domains, a comprehensive evaluation is needed to understand their strengths, weaknesses, and domain-specific abilities. This is critical as these models are applied to various tasks, from sentiment analysis to more nuanced tasks like textual entailment and translation. This study aims to evaluate ChatGPT and DeepSeek across five key NLP tasks: sentiment analysis, topic classification, text summarization, machine translation, and textual entailment. A structured experimental protocol is used to ensure fairness and minimize variability. Both models are tested with identical, neutral prompts and evaluated on two benchmark datasets per task, covering domains like news, reviews, and formal/informal texts. The results show that DeepSeek excels in classification stability and logical reasoning, while ChatGPT performs better in tasks requiring nuanced understanding and flexibility. These findings provide valuable insights for selecting the appropriate LLM based on task requirements.",
      "authors": [
        "Wael Etaiwi",
        "Bushra Alhijawi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T10:52:54+00:00",
          "link": "https://arxiv.org/abs/2506.18501v1",
          "size": "75kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T19:52:34+00:00",
          "link": "https://arxiv.org/abs/2506.18501v2",
          "size": "75kb",
          "version": "v2"
        }
      ],
      "title": "Comparative Evaluation of ChatGPT and DeepSeek Across Key NLP Tasks: Strengths, Weaknesses, and Domain-Specific Performance",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18501",
        "HTML": "https://arxiv.org/html/2506.18501v2",
        "PDF": "https://arxiv.org/pdf/2506.18501"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18504",
      "abstract": "Recently, vision-language pretraining has emerged as a transformative technique that integrates the strengths of both visual and textual modalities, resulting in powerful vision-language models (VLMs). Leveraging web-scale pretraining data, these models exhibit strong zero-shot capabilities. However, their performance often deteriorates when confronted with domain-specific or specialized generalization tasks. To address this, a growing body of research focuses on transferring or generalizing the rich knowledge embedded in VLMs to various downstream applications. This survey aims to comprehensively summarize the generalization settings, methodologies, benchmarking and results in VLM literatures. Delving into the typical VLM structures, current literatures are categorized into prompt-based, parameter-based and feature-based methods according to the transferred modules. The differences and characteristics in each category are furthered summarized and discussed by revisiting the typical transfer learning (TL) settings, providing novel interpretations for TL in the era of VLMs. Popular benchmarks for VLM generalization are further introduced with thorough performance comparisons among the reviewed methods. Following the advances in large-scale generalizable pretraining, this survey also discusses the relations and differences between VLMs and up-to-date multimodal large language models (MLLM), e.g., DeepSeek-VL. By systematically reviewing the surging literatures in vision-language research from a novel and practical generalization prospective, this survey contributes to a clear landscape of current and future multimodal researches.",
      "authors": [
        "Xinyao Li",
        "Jingjing Li",
        "Fengling Li",
        "Lei Zhu",
        "Yang Yang",
        "Heng Tao Shen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T10:56:37+00:00",
          "link": "https://arxiv.org/abs/2506.18504v1",
          "size": "1000kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T05:24:22+00:00",
          "link": "https://arxiv.org/abs/2506.18504v2",
          "size": "1000kb",
          "version": "v2"
        }
      ],
      "title": "Generalizing vision-language models to novel domains: A comprehensive survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18504",
        "HTML": "https://arxiv.org/html/2506.18504v2",
        "PDF": "https://arxiv.org/pdf/2506.18504"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18744",
      "abstract": "Online experiments in internet systems, also known as A/B tests, are used for a wide range of system tuning problems, such as optimizing recommender system ranking policies and learning adaptive streaming controllers. Decision-makers generally wish to optimize for long-term treatment effects of the system changes, which often requires running experiments for a long time as short-term measurements can be misleading due to non-stationarity in treatment effects over time. The sequential experimentation strategies--which typically involve several iterations--can be prohibitively long in such cases. We describe a novel approach that combines fast experiments (e.g., biased experiments run only for a few hours or days) and/or offline proxies (e.g., off-policy evaluation) with long-running, slow experiments to perform sequential, Bayesian optimization over large action spaces in a short amount of time.",
      "authors": [
        "Qing Feng",
        "Samuel Daulton",
        "Benjamin Letham",
        "Maximilian Balandat",
        "Eytan Bakshy"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T15:18:54+00:00",
          "link": "https://arxiv.org/abs/2506.18744v1",
          "size": "1181kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T16:42:40+00:00",
          "link": "https://arxiv.org/abs/2506.18744v2",
          "size": "1181kb",
          "version": "v2"
        }
      ],
      "title": "Experimenting, Fast and Slow: Bayesian Optimization of Long-term Outcomes with Online Experiments",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18744",
        "HTML": "https://arxiv.org/html/2506.18744v2",
        "PDF": "https://arxiv.org/pdf/2506.18744"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18985",
      "abstract": "Recent progress in large vision-language models (LVLMs) has advanced the state of the art in visual question answering (VQA). However, interpreting where LVLMs direct their visual attention while generating free-form responses remains a significant challenge, yet is essential for understanding model behavior. We introduce GLIMPSE (Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation), a lightweight, model-agnostic framework that jointly attributes LVLM outputs to the most relevant visual evidence and textual signals supporting open-ended VQA. GLIMPSE fuses gradient-weighted attention, adaptive layer propagation, and relevance-weighted token aggregation to produce holistic response-level heat maps for interpreting cross-modal reasoning, outperforming prior interpretability methods and pushing the state-of-the-art in human-alignment. We demonstrate an analytic explainable AI (XAI) approach using GLIMPSE to uncover fine-grained insights into LVLM cross-modal attribution, trace reasoning dynamics, analyze systematic human-attention misalignment, diagnose hallucination, expose bias, and ensure transparency.",
      "authors": [
        "Guanxi Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T18:00:04+00:00",
          "link": "https://arxiv.org/abs/2506.18985v1",
          "size": "24858kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T17:59:56+00:00",
          "link": "https://arxiv.org/abs/2506.18985v2",
          "size": "24073kb",
          "version": "v2"
        }
      ],
      "title": "GLIMPSE: Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation for Generative LVLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18985",
        "HTML": "https://arxiv.org/html/2506.18985v2",
        "PDF": "https://arxiv.org/pdf/2506.18985"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19002",
      "abstract": "This report develops several modular, 2-step realizations (inspired by Kalman filter algorithms) of nudging-based data assimilation $$Step \\ 1 \\quad \\frac{\\widetilde {v}^{n+1}-v^{n}}{k}+v^{n}\\cdot \\nabla \\widetilde {v}^{n+1}-\\nu \\triangle \\widetilde {v}^{n+1}+\\nabla q^{n+1}=f(x)$$ $$\\nabla \\cdot \\widetilde {v}^{n+1}=0$$ $$Step \\ 2 \\quad \\frac{v^{n+1}-\\widetilde {v}^{n+1}}{k}-\\chi I_{H}(u(t^{n+1})-v^{n+1})=0.$$ Several variants of this algorithm are developed. Three main results are developed. The first is that if $I_{H}^{2}=I_{H}$, then Step 2 can be rewritten as the explicit step $$v^{n+1}=\\widetilde {v}^{n+1}+\\frac{k\\chi }{1+k\\chi }[I_{H}u(t^{n+1})-I_{H} \\widetilde {v}^{n+1}].$$ This means Step 2 has the greater stability of an implicit update and the lesser complexity of an explicit analysis step. The second is that the basic result of nudging (that for $H$ small enough and $\\chi$ large enough predictability horizons are infinite) holds for one variant of the modular algorithm. The third is that, for any $H>0$ and any $\\chi>0$, one step of the modular algorithm decreases the next step's error and increases (an estimate of) predictability horizons. A method synthesizing assimilation with eddy viscosity models of turbulence is also presented. Numerical tests are given, confirming the effectiveness of the modular assimilation algorithm. The conclusion is that the modular, 2-step method overcomes many algorithmic inadequacies of standard nudging methods and retains a robust mathematical foundation.",
      "authors": [
        "Aytekin \\c{C}{\\i}b{\\i}k",
        "Rui Fang",
        "William Layton"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T18:01:48+00:00",
          "link": "https://arxiv.org/abs/2506.19002v1",
          "size": "260kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T20:10:06+00:00",
          "link": "https://arxiv.org/abs/2506.19002v2",
          "size": "260kb",
          "version": "v2"
        }
      ],
      "title": "Modular data assimilation for flow prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19002",
        "HTML": "https://arxiv.org/html/2506.19002v2",
        "PDF": "https://arxiv.org/pdf/2506.19002"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19107",
      "abstract": "With the proliferation of large language model (LLM) applications since 2022, their use in education has sparked both excitement and concern. Recent studies consistently highlight students' (mis)use of LLMs can hinder learning outcomes. This work aims to teach students how to effectively prompt LLMs to improve their learning. We first proposed pedagogical prompting, a theoretically-grounded new concept to elicit learning-oriented responses from LLMs. To move from concept design to a proof-of-concept learning intervention in real educational settings, we selected early undergraduate CS education (CS1/CS2) as the example context. We began with a formative survey study with instructors (N=36) teaching early-stage undergraduate-level CS courses to inform the instructional design based on classroom needs. Based on their insights, we designed and developed a learning intervention through an interactive system with scenario-based instruction to train pedagogical prompting skills. Finally, we evaluated its instructional effectiveness through a user study with CS novice students (N=22) using pre/post-tests. Through mixed methods analyses, our results indicate significant improvements in learners' LLM-based pedagogical help-seeking skills, along with positive attitudes toward the system and increased willingness to use pedagogical prompts in the future. Our contributions include (1) a theoretical framework of pedagogical prompting; (2) empirical insights into current instructor attitudes toward pedagogical prompting; and (3) a learning intervention design with an interactive learning tool and scenario-based instruction leading to promising results on teaching LLM-based help-seeking. Our approach is scalable for broader implementation in classrooms and has the potential to be integrated into tools like ChatGPT as an on-boarding experience to encourage learning-oriented use of generative AI.",
      "authors": [
        "Ruiwei Xiao",
        "Xinying Hou",
        "Runlong Ye",
        "Majeed Kazemitabaar",
        "Nicholas Diana",
        "Michael Liut",
        "John Stamper"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-23T20:39:17+00:00",
          "link": "https://arxiv.org/abs/2506.19107v1",
          "size": "17055kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T18:15:32+00:00",
          "link": "https://arxiv.org/abs/2506.19107v2",
          "size": "16717kb",
          "version": "v2"
        }
      ],
      "title": "Improving Student-AI Interaction Through Pedagogical Prompting: An Example in Computer Science Education",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19107",
        "HTML": "https://arxiv.org/html/2506.19107v2",
        "PDF": "https://arxiv.org/pdf/2506.19107"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19332",
      "abstract": "We propose a fast and stable method for constructing matrix approximations to fractional integral operators applied to series in the Chebyshev fractional polynomials. This method utilizes a recurrence relation satisfied by the fractional integrals of mapped Chebyshev polynomials and significantly outperforms existing methods. Through numerical examples, we highlight the broad applicability of these matrix approximations, including the solution of boundary value problems for fractional integral and differential equations. Additional applications include fractional differential equation initial value problems and fractional eigenvalue problems.",
      "authors": [
        "Xiaolin Liu and Kuan Xu"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T05:53:37+00:00",
          "link": "https://arxiv.org/abs/2506.19332v1",
          "size": "945kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T12:28:07+00:00",
          "link": "https://arxiv.org/abs/2506.19332v2",
          "size": "945kb",
          "version": "v2"
        }
      ],
      "title": "Spectral Approximation to Fractional Integral Operators",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19332",
        "HTML": "https://arxiv.org/html/2506.19332v2",
        "PDF": "https://arxiv.org/pdf/2506.19332"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19445",
      "abstract": "We introduce the largest real-world image deblurring dataset constructed from smartphone slow-motion videos. Using 240 frames captured over one second, we simulate realistic long-exposure blur by averaging frames to produce blurry images, while using the temporally centered frame as the sharp reference. Our dataset contains over 42,000 high-resolution blur-sharp image pairs, making it approximately 10 times larger than widely used datasets, with 8 times the amount of different scenes, including indoor and outdoor environments, with varying object and camera motions. We benchmark multiple state-of-the-art (SOTA) deblurring models on our dataset and observe significant performance degradation, highlighting the complexity and diversity of our benchmark. Our dataset serves as a challenging new benchmark to facilitate robust and generalizable deblurring models.",
      "authors": [
        "Mahdi Mohd Hossain Noki",
        "Syed Mumtahin Mahmud",
        "Prothito Shovon Majumder",
        "Abdul Mohaimen Al Radi",
        "Md. Haider Ali",
        "Md. Mosaddek Khan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T09:17:29+00:00",
          "link": "https://arxiv.org/abs/2506.19445v1",
          "size": "2457kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T06:25:56+00:00",
          "link": "https://arxiv.org/abs/2506.19445v2",
          "size": "2449kb",
          "version": "v2"
        }
      ],
      "title": "Deblurring in the Wild: A Real-World Dataset from Smartphone High-Speed Videos",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19445",
        "HTML": "https://arxiv.org/html/2506.19445v2",
        "PDF": "https://arxiv.org/pdf/2506.19445"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19474",
      "abstract": "Diabetic Peripheral Neuropathy (DPN) affects nearly half of diabetes patients, requiring early detection. Corneal Confocal Microscopy (CCM) enables non-invasive diagnosis, but automated methods suffer from inefficient feature extraction, reliance on handcrafted priors, and data limitations. We propose HMSViT, a novel Hierarchical Masked Self-Supervised Vision Transformer (HMSViT) designed for corneal nerve segmentation and DPN diagnosis. Unlike existing methods, HMSViT employs pooling-based hierarchical and dual attention mechanisms with absolute positional encoding, enabling efficient multi-scale feature extraction by capturing fine-grained local details in early layers and integrating global context in deeper layers, all at a lower computational cost. A block-masked self supervised learning framework is designed for the HMSViT that reduces reliance on labelled data, enhancing feature robustness, while a multi-scale decoder is used for segmentation and classification by fusing hierarchical features. Experiments on clinical CCM datasets showed HMSViT achieves state-of-the-art performance, with 61.34% mIoU for nerve segmentation and 70.40% diagnostic accuracy, outperforming leading hierarchical models like the Swin Transformer and HiViT by margins of up to 6.39% in segmentation accuracy while using fewer parameters. Detailed ablation studies further reveal that integrating block-masked SSL with hierarchical multi-scale feature extraction substantially enhances performance compared to conventional supervised training. Overall, these comprehensive experiments confirm that HMSViT delivers excellent, robust, and clinically viable results, demonstrating its potential for scalable deployment in real-world diagnostic applications.",
      "authors": [
        "Xin Zhang",
        "Liangxiu Han",
        "Yue Shi",
        "Yanlin Zheng",
        "Uazman Alam",
        "Maryam Ferdousi and Rayaz Malik"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T10:00:23+00:00",
          "link": "https://arxiv.org/abs/2506.19474v1",
          "size": "4297kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T08:40:51+00:00",
          "link": "https://arxiv.org/abs/2506.19474v2",
          "size": "4297kb",
          "version": "v2"
        }
      ],
      "title": "HMSViT: A Hierarchical Masked Self-Supervised Vision Transformer for Corneal Nerve Segmentation and Diabetic Neuropathy Diagnosis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19474",
        "HTML": "https://arxiv.org/html/2506.19474v2",
        "PDF": "https://arxiv.org/pdf/2506.19474"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19592",
      "abstract": "We introduce TAPAS (Task-based Adaptation and Planning using AgentS), a multi-agent framework that integrates Large Language Models (LLMs) with symbolic planning to solve complex tasks without the need for manually defined environment models. TAPAS employs specialized LLM-based agents that collaboratively generate and adapt domain models, initial states, and goal specifications as needed using structured tool-calling mechanisms. Through this tool-based interaction, downstream agents can request modifications from upstream agents, enabling adaptation to novel attributes and constraints without manual domain redefinition. A ReAct (Reason+Act)-style execution agent, coupled with natural language plan translation, bridges the gap between dynamically generated plans and real-world robot capabilities. TAPAS demonstrates strong performance in benchmark planning domains and in the VirtualHome simulated real-world environment.",
      "authors": [
        "Harisankar Babu",
        "Philipp Schillinger",
        "Tamim Asfour"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T13:02:06+00:00",
          "link": "https://arxiv.org/abs/2506.19592v1",
          "size": "1670kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T14:40:24+00:00",
          "link": "https://arxiv.org/abs/2506.19592v2",
          "size": "1670kb",
          "version": "v2"
        }
      ],
      "title": "Adaptive Domain Modeling with Language Models: A Multi-Agent Approach to Task Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19592",
        "HTML": "https://arxiv.org/html/2506.19592v2",
        "PDF": "https://arxiv.org/pdf/2506.19592"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19598",
      "abstract": "To understand how genetic variants in human genomes manifest in phenotypes -- traits like height or diseases like asthma -- geneticists have sequenced and measured hundreds of thousands of individuals. Geneticists use this data to build models that predict how a genetic variant impacts phenotype given genomic features of the variant, like DNA accessibility or the presence of nearby DNA-bound proteins. As more data and features become available, one might expect predictive models to improve. Unfortunately, training these models is bottlenecked by the need to solve expensive linear algebra problems because variants in the genome are correlated with nearby variants, requiring inversion of large matrices. Previous methods have therefore been restricted to fitting small models, and fitting simplified summary statistics, rather than the full likelihood of the statistical model. In this paper, we leverage modern fast linear algebra techniques to develop DeepWAS (Deep genome Wide Association Studies), a method to train large and flexible neural network predictive models to optimize likelihood. Notably, we find that larger models only improve performance when using our full likelihood approach; when trained by fitting traditional summary statistics, larger models perform no better than small ones. We find larger models trained on more features make better predictions, potentially improving disease predictions and therapeutic target identification.",
      "authors": [
        "Alan N. Amin",
        "Andres Potapczynski",
        "Andrew Gordon Wilson"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Populations and Evolution (q-bio.PE)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T13:07:45+00:00",
          "link": "https://arxiv.org/abs/2506.19598v1",
          "size": "555kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T13:26:08+00:00",
          "link": "https://arxiv.org/abs/2506.19598v2",
          "size": "555kb",
          "version": "v2"
        }
      ],
      "title": "Training Flexible Models of Genetic Variant Effects from Functional Annotations using Accelerated Linear Algebra",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19598",
        "HTML": "https://arxiv.org/html/2506.19598v2",
        "PDF": "https://arxiv.org/pdf/2506.19598"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19744",
      "abstract": "This paper presents a Model-Inspired Distributionally Robust Data-enabled Predictive Control (MDR-DeePC) framework for systems with partially known and uncertain dynamics. The proposed method integrates model-based equality constraints for known dynamics with a Hankel matrix-based representation of unknown dynamics. A distributionally robust optimization problem is formulated to account for parametric uncertainty and stochastic disturbances. Simulation results on a triple-mass-spring-damper system demonstrate improved disturbance rejection, reduced output oscillations, and lower control cost compared to standard DeePC. The results validate the robustness and effectiveness of MDR-DeePC, with potential for real-time implementation pending further benchmarking.",
      "authors": [
        "Shihao Li",
        "Jiachen Li",
        "Christopher Martin",
        "Soovadeep Bakshi",
        "Dongmei Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T16:03:43+00:00",
          "link": "https://arxiv.org/abs/2506.19744v1",
          "size": "513kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T16:38:03+00:00",
          "link": "https://arxiv.org/abs/2506.19744v2",
          "size": "504kb",
          "version": "v2"
        }
      ],
      "title": "MDR-DeePC: Model-Inspired Distributionally Robust Data-Enabled Predictive Control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19744",
        "PDF": "https://arxiv.org/pdf/2506.19744"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19750",
      "abstract": "Symptom Checkers (SCs) provide medical information tailored to user symptoms. A critical challenge in SC development is preventing unexpected performance degradation for individual diseases, especially rare diseases, when updating algorithms. This risk stems from the lack of practical pre-deployment evaluation methods. For rare diseases, obtaining sufficient evaluation data from user feedback is difficult. To evaluate the impact of algorithm updates on the diagnostic performance for individual rare diseases before deployment, this study proposes and validates a novel Synthetic Vignette Simulation Approach. This approach aims to enable this essential evaluation efficiently and at a low cost. To estimate the impact of algorithm updates, we generated synthetic vignettes from disease-phenotype annotations in the Human Phenotype Ontology (HPO), a publicly available knowledge base for rare diseases curated by experts. Using these vignettes, we simulated SC interviews to predict changes in diagnostic performance. The effectiveness of this approach was validated retrospectively by comparing the predicted changes with actual performance metrics using the R-squared ($R^2$) coefficient. Our experiment, covering eight past algorithm updates for rare diseases, showed that the proposed method accurately predicted performance changes for diseases with phenotype frequency information in HPO (n=5). For these updates, we found a strong correlation for both Recall@8 change ($R^2$ = 0.83,$p$ = 0.031) and Precision@8 change ($R^2$ = 0.78,$p$ = 0.047). Our proposed method enables the pre-deployment evaluation of SC algorithm changes for individual rare diseases. This evaluation is based on a publicly available medical knowledge database created by experts, ensuring transparency and explainability for stakeholders. Additionally, SC developers can efficiently improve diagnostic performance at a low cost.",
      "authors": [
        "Takashi Nishibayashi",
        "Seiji Kanazawa and Kumpei Yamada"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T16:06:37+00:00",
          "link": "https://arxiv.org/abs/2506.19750v1",
          "size": "648kb",
          "version": "v1"
        },
        {
          "date": "2025-06-25T11:56:15+00:00",
          "link": "https://arxiv.org/abs/2506.19750v2",
          "size": "648kb",
          "version": "v2"
        },
        {
          "date": "2025-06-26T06:52:46+00:00",
          "link": "https://arxiv.org/abs/2506.19750v3",
          "size": "648kb",
          "version": "v3"
        },
        {
          "date": "2025-06-29T08:14:18+00:00",
          "link": "https://arxiv.org/abs/2506.19750v4",
          "size": "653kb",
          "version": "v4"
        }
      ],
      "title": "Evaluating Rare Disease Diagnostic Performance in Symptom Checkers: A Synthetic Vignette Simulation Approach",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19750",
        "HTML": "https://arxiv.org/html/2506.19750v4",
        "PDF": "https://arxiv.org/pdf/2506.19750"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19753",
      "abstract": "The Arabic language is among the most popular languages in the world with a huge variety of dialects spoken in 22 countries. In this study, we address the problem of classifying 18 Arabic dialects of the QADI dataset of Arabic tweets. RNN models, Transformer models, and large language models (LLMs) via prompt engineering are created and tested. Among these, MARBERTv2 performed best with 65% accuracy and 64% F1-score. Through the use of state-of-the-art preprocessing techniques and the latest NLP models, this paper identifies the most significant linguistic issues in Arabic dialect identification. The results corroborate applications like personalized chatbots that respond in users' dialects, social media monitoring, and greater accessibility for Arabic communities.",
      "authors": [
        "Omar A.Essameldin",
        "Ali O.Elbeih",
        "Wael H.Gomaa",
        "Wael F.Elsersy"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T16:06:58+00:00",
          "link": "https://arxiv.org/abs/2506.19753v1",
          "size": "362kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T12:32:10+00:00",
          "link": "https://arxiv.org/abs/2506.19753v2",
          "size": "362kb",
          "version": "v2"
        }
      ],
      "title": "Arabic Dialect Classification using RNNs, Transformers, and Large Language Models: A Comparative Analysis",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19753",
        "HTML": "https://arxiv.org/html/2506.19753v2",
        "PDF": "https://arxiv.org/pdf/2506.19753"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19815",
      "abstract": "Surface electromyography (sEMG) signals show promise for effective human-computer interfaces, particularly in rehabilitation and prosthetics. However, challenges remain in developing systems that respond quickly and reliably to user intent, across different subjects and without requiring time-consuming calibration. In this work, we propose a framework for EMG-based intent detection that addresses these challenges. Unlike traditional gesture recognition models that wait until a gesture is completed before classifying it, our approach uses a segmentation strategy to assign intent labels at every timestep as the gesture unfolds. We introduce a novel masked modeling strategy that aligns muscle activations with their corresponding user intents, enabling rapid onset detection and stable tracking of ongoing gestures. In evaluations against baseline methods, considering both accuracy and stability for device control, our approach surpasses state-of-the-art performance in zero-shot transfer conditions, demonstrating its potential for wearable robotics and next-generation prosthetic systems. Our project page is available at: https://reactemg.github.io",
      "authors": [
        "Runsheng Wang",
        "Xinyue Zhu",
        "Ava Chen",
        "Jingxi Xu",
        "Lauren Winterbottom",
        "Dawn M. Nilsen",
        "Joel Stein",
        "Matei Ciocarlie"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T17:28:43+00:00",
          "link": "https://arxiv.org/abs/2506.19815v1",
          "size": "929kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T16:48:36+00:00",
          "link": "https://arxiv.org/abs/2506.19815v2",
          "size": "930kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T19:16:22+00:00",
          "link": "https://arxiv.org/abs/2506.19815v3",
          "size": "1914kb",
          "version": "v3"
        }
      ],
      "title": "ReactEMG: Zero-Shot, Low-Latency Intent Detection via sEMG",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19815",
        "HTML": "https://arxiv.org/html/2506.19815v3",
        "PDF": "https://arxiv.org/pdf/2506.19815"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19882",
      "abstract": "Science progresses by iteratively advancing and correcting humanity's understanding of the world. In machine learning (ML) research, rapid advancements have led to an explosion of publications, but have also led to misleading, incorrect, flawed or perhaps even fraudulent studies being accepted and sometimes highlighted at ML conferences due to the fallibility of peer review. While such mistakes are understandable, ML conferences do not offer robust processes to help the field systematically correct when such errors are made. This position paper argues that ML conferences should establish a dedicated \"Refutations and Critiques\" (R&C) Track. This R&C Track would provide a high-profile, reputable platform to support vital research that critically challenges prior research, thereby fostering a dynamic self-correcting research ecosystem. We discuss key considerations including track design, review principles, potential pitfalls, and provide an illustrative example submission concerning a recent ICLR 2025 Oral. We conclude that ML conferences should create official, reputable mechanisms to help ML research self-correct.",
      "authors": [
        "Rylan Schaeffer",
        "Joshua Kazdan",
        "Yegor Denisov-Blanch",
        "Brando Miranda",
        "Matthias Gerstgrasser",
        "Susan Zhang",
        "Andreas Haupt",
        "Isha Gupta",
        "Elyas Obbad",
        "Jesse Dodge",
        "Jessica Zosa Forde",
        "Koustuv Sinha",
        "Francesco Orabona",
        "Sanmi Koyejo",
        "David Donoho"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T02:19:30+00:00",
          "link": "https://arxiv.org/abs/2506.19882v1",
          "size": "75kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T16:41:57+00:00",
          "link": "https://arxiv.org/abs/2506.19882v2",
          "size": "76kb",
          "version": "v2"
        }
      ],
      "title": "Position: Machine Learning Conferences Should Establish a \"Refutations and Critiques\" Track",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19882",
        "HTML": "https://arxiv.org/html/2506.19882v2",
        "PDF": "https://arxiv.org/pdf/2506.19882"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20158",
      "abstract": "Non-fixed flexible antenna architectures, such as fluid antenna system (FAS), movable antenna (MA), and pinching antenna, have garnered significant interest in recent years. Among them, rotatable antenna (RA) is a promising antenna architecture that exploits additional spatial degrees of freedom (DoFs) to enhance the communication performance. To fully obtain the performance gain provided by RAs, accurate channel state information (CSI) is essential for adjusting the orientation/boresight of each antenna. In this letter, we propose an efficient channel estimation scheme for RA communication systems, where the base station (BS) can sequentially and adaptively adjust the orientations of RAs to enrich the environmental observations from diverse angular perspectives, thereby enhancing the channel estimation accuracy. The proposed scheme includes two main procedures that are conducted alternately during each channel training period. Specifically, the first procedure is to estimate the CSI with given RAs' orientations, involving the angle-of-arrivals (AoAs) information and path gains. Then, based on the estimated CSI, the second procedure adjusts the RAs' orientations to maximize the effective channel gain. Simulation results demonstrate that the proposed channel estimation method outperforms other benchmark schemes.",
      "authors": [
        "Xue Xiong",
        "Beixiong Zheng",
        "Wen Wu",
        "Xiaodan Shao",
        "Liang Dai",
        "Ming-Min Zhao",
        "and Jie Tang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Signal Processing (eess.SP)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T06:28:49+00:00",
          "link": "https://arxiv.org/abs/2506.20158v1",
          "size": "371kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T09:03:06+00:00",
          "link": "https://arxiv.org/abs/2506.20158v2",
          "size": "371kb",
          "version": "v2"
        }
      ],
      "title": "Efficient Channel Estimation for Rotatable Antenna-Enabled Wireless Communication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20158",
        "HTML": "https://arxiv.org/html/2506.20158v2",
        "PDF": "https://arxiv.org/pdf/2506.20158"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20199",
      "abstract": "Large language models (LLMs) have enabled a wide variety of real-world applications in various domains. However, creating a high-performing application with high accuracy remains challenging, particularly for subjective tasks like emotion recognition. Inspired by the SLT 2024 GenSER Challenge, this study investigates approaches to improving conversational emotion recognition (CER) by LLMs. Specifically, we explore how to retrieve high-quality examples in in-context learning (ICL) to enhance CER. We propose various strategies based on random and augmented example retrieval and also analyze the impact of conversational context on CER accuracy. Experiments were conducted on the three datasets including IEMOCAP, MELD and EmoryNLP. The results show that augmented example retrieval consistently outperforms other techniques under investigation across all datasets, highlighting the importance of retrieving coherent targeted examples and enhancing them through paraphrasing.",
      "authors": [
        "Mengqi Wang",
        "Tiantian Feng",
        "Shrikanth Narayanan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T07:39:19+00:00",
          "link": "https://arxiv.org/abs/2506.20199v1",
          "size": "3442kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T03:04:05+00:00",
          "link": "https://arxiv.org/abs/2506.20199v2",
          "size": "3443kb",
          "version": "v2"
        }
      ],
      "title": "How to Retrieve Examples in In-context Learning to Improve Conversational Emotion Recognition using Large Language Models?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20199",
        "HTML": "https://arxiv.org/html/2506.20199v2",
        "PDF": "https://arxiv.org/pdf/2506.20199"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20442",
      "abstract": "Biodiversity loss is a critical planetary boundary, yet its connection to computing remains largely unexamined. Prior sustainability efforts in computing have focused on carbon and water, overlooking biodiversity due to the lack of appropriate metrics and modeling frameworks. This paper presents the first end-to-end analysis of biodiversity impact from computing systems. We introduce two new metrics--Embodied Biodiversity Index (EBI) and Operational Biodiversity Index (OBI)--to quantify biodiversity impact across the lifecycle, and present FABRIC, a modeling framework that links computing workloads to biodiversity impacts. Our evaluation highlights the need to consider biodiversity alongside carbon and water in sustainable computing design and optimization. The code is available at https://github.com/TianyaoShi/FABRIC.",
      "authors": [
        "Tianyao Shi",
        "Ritbik Kumar",
        "Inez Hua",
        "Yi Ding"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)",
        "Hardware Architecture (cs.AR)",
        "Distributed, Parallel, and Cluster Computing (cs.DC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T13:50:04+00:00",
          "link": "https://arxiv.org/abs/2506.20442v1",
          "size": "770kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T02:24:18+00:00",
          "link": "https://arxiv.org/abs/2506.20442v2",
          "size": "770kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T10:08:23+00:00",
          "link": "https://arxiv.org/abs/2506.20442v3",
          "size": "756kb",
          "version": "v3"
        }
      ],
      "title": "When Servers Meet Species: A Fab-to-Grave Lens on Computing's Biodiversity Impact",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20442",
        "HTML": "https://arxiv.org/html/2506.20442v3",
        "PDF": "https://arxiv.org/pdf/2506.20442"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper addresses the biodiversity impact of computing systems, introducing metrics for sustainability, which is unrelated to LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20628",
      "abstract": "In this paper we investigate identifiability and maximum likelihood estimation for direct system identification of networks of dynamical systems. We provide necessary and sufficient conditions for network identifiability in terms of Gr\\\"obner bases. We show that the maximum likelihood approach is both consistent and efficient, which is in contrast to existing prediction error approaches. Moreover, our approach has wider applicability, i.e., it is applicable whenever network identifiability holds. Finally, we show that we can formulate the maximum likelihood problem without the use of a predictor, which is the key to numerically being able to solve it efficiently.",
      "authors": [
        "Anders Hansson",
        "Jo\\~ao Victor Galv\\~ao da Mata",
        "Martin S. Andersen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T17:22:18+00:00",
          "link": "https://arxiv.org/abs/2506.20628v1",
          "size": "179kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T10:00:23+00:00",
          "link": "https://arxiv.org/abs/2506.20628v2",
          "size": "180kb",
          "version": "v2"
        }
      ],
      "title": "Identifiability and Maximum Likelihood Estimation for System Identification of Networks of Dynamical Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20628",
        "HTML": "https://arxiv.org/html/2506.20628v2",
        "PDF": "https://arxiv.org/pdf/2506.20628"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20756",
      "abstract": "Recent video depth estimation methods achieve great performance by following the paradigm of image depth estimation, i.e., typically fine-tuning pre-trained video diffusion models with massive data. However, we argue that video depth estimation is not a naive extension of image depth estimation. The temporal consistency requirements for dynamic and static regions in videos are fundamentally different. Consistent video depth in static regions, typically backgrounds, can be more effectively achieved via stereo matching across all frames, which provides much stronger global 3D cues. While the consistency for dynamic regions still should be learned from large-scale video depth data to ensure smooth transitions, due to the violation of triangulation constraints. Based on these insights, we introduce StereoDiff, a two-stage video depth estimator that synergizes stereo matching for mainly the static areas with video depth diffusion for maintaining consistent depth transitions in dynamic areas. We mathematically demonstrate how stereo matching and video depth diffusion offer complementary strengths through frequency domain analysis, highlighting the effectiveness of their synergy in capturing the advantages of both. Experimental results on zero-shot, real-world, dynamic video depth benchmarks, both indoor and outdoor, demonstrate StereoDiff's SoTA performance, showcasing its superior consistency and accuracy in video depth estimation.",
      "authors": [
        "Haodong Li",
        "Chen Wang",
        "Jiahui Lei",
        "Kostas Daniilidis",
        "Lingjie Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T18:35:10+00:00",
          "link": "https://arxiv.org/abs/2506.20756v1",
          "size": "1746kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T06:41:41+00:00",
          "link": "https://arxiv.org/abs/2506.20756v2",
          "size": "6838kb",
          "version": "v2"
        }
      ],
      "title": "StereoDiff: Stereo-Diffusion Synergy for Video Depth Estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20756",
        "HTML": "https://arxiv.org/html/2506.20756v2",
        "PDF": "https://arxiv.org/pdf/2506.20756"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20844",
      "abstract": "Scientific fact-checking aims to determine the veracity of scientific claims by retrieving and analysing evidence from research literature. The problem is inherently more complex than general fact-checking since it must accommodate the evolving nature of scientific knowledge, the structural complexity of academic literature and the challenges posed by long-form, multimodal scientific expression. However, existing approaches focus on simplified versions of the problem based on small-scale datasets consisting of abstracts rather than full papers, thereby avoiding the distinct challenges associated with processing complete documents. This paper examines the limitations of current scientific fact-checking systems and reveals the many potential features and resources that could be exploited to advance their performance. It identifies key research challenges within evidence retrieval, including (1) evidence-driven retrieval that addresses semantic limitations and topic imbalance (2) time-aware evidence retrieval with citation tracking to mitigate outdated information, (3) structured document parsing to leverage long-range context, (4) handling complex scientific expressions, including tables, figures, and domain-specific terminology and (5) assessing the credibility of scientific literature. Preliminary experiments were conducted to substantiate these challenges and identify potential solutions. This perspective paper aims to advance scientific fact-checking with a specialised IR system tailored for real-world applications.",
      "authors": [
        "Xingyu Deng",
        "Xi Wang",
        "Mark Stevenson"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T21:29:33+00:00",
          "link": "https://arxiv.org/abs/2506.20844v1",
          "size": "1421kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T02:57:01+00:00",
          "link": "https://arxiv.org/abs/2506.20844v2",
          "size": "1421kb",
          "version": "v2"
        }
      ],
      "title": "The Next Phase of Scientific Fact-Checking: Advanced Evidence Retrieval from Complex Structured Academic Papers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20844",
        "HTML": "https://arxiv.org/html/2506.20844v2",
        "PDF": "https://arxiv.org/pdf/2506.20844"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20876",
      "abstract": "Technological progress has led to concrete advancements in tasks that were regarded as challenging, such as automatic fact-checking. Interest in adopting these systems for public health and medicine has grown due to the high-stakes nature of medical decisions and challenges in critically appraising a vast and diverse medical literature. Evidence-based medicine connects to every individual, and yet the nature of it is highly technical, rendering the medical literacy of majority users inadequate to sufficiently navigate the domain. Such problems with medical communication ripens the ground for end-to-end fact-checking agents: check a claim against current medical literature and return with an evidence-backed verdict. And yet, such systems remain largely unused. To understand this, we present the first study examining how clinical experts verify real claims from social media by synthesizing medical evidence. In searching for this upper-bound, we reveal fundamental challenges in end-to-end fact-checking when applied to medicine: Difficulties connecting claims in the wild to scientific evidence in the form of clinical trials; ambiguities in underspecified claims mixed with mismatched intentions; and inherently subjective veracity labels. We argue that fact-checking should be approached and evaluated as an interactive communication problem, rather than an end-to-end process.",
      "authors": [
        "Sebastian Joseph",
        "Lily Chen",
        "Barry Wei",
        "Michael Mackert",
        "Iain J. Marshall",
        "Paul Pu Liang",
        "Ramez Kouzy",
        "Byron C. Wallace",
        "Junyi Jessy Li"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T22:58:08+00:00",
          "link": "https://arxiv.org/abs/2506.20876v1",
          "size": "1352kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T06:11:10+00:00",
          "link": "https://arxiv.org/abs/2506.20876v2",
          "size": "1090kb",
          "version": "v2"
        }
      ],
      "title": "Decide less, communicate more: On the construct validity of end-to-end fact-checking in medicine",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20876",
        "HTML": "https://arxiv.org/html/2506.20876v2",
        "PDF": "https://arxiv.org/pdf/2506.20876"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20926",
      "abstract": "Generative code models (GCMs) significantly enhance development efficiency through automated code generation and code summarization. However, building and training these models require computational resources and time, necessitating effective digital copyright protection to prevent unauthorized leaks and misuse. Backdoor watermarking, by embedding hidden identifiers, simplifies copyright verification by breaking the model's black-box nature. Current backdoor watermarking techniques face two main challenges: first, limited generalization across different tasks and datasets, causing fluctuating verification rates; second, insufficient stealthiness, as watermarks are easily detected and removed by automated methods. To address these issues, we propose CodeGuard, a novel watermarking method combining attention mechanisms with distributed trigger embedding strategies. Specifically, CodeGuard employs attention mechanisms to identify watermark embedding positions, ensuring verifiability. Moreover, by using homomorphic character replacement, it avoids manual detection, while distributed trigger embedding reduces the likelihood of automated detection. Experimental results demonstrate that CodeGuard achieves up to 100% watermark verification rates in both code summarization and code generation tasks, with no impact on the primary task performance. In terms of stealthiness, CodeGuard performs exceptionally, with a maximum detection rate of only 0.078 against ONION detection methods, significantly lower than baseline methods.",
      "authors": [
        "Haoxuan Li",
        "Jiale Zhang",
        "Xiaobing Sun",
        "Xiapu Luo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T01:14:35+00:00",
          "link": "https://arxiv.org/abs/2506.20926v1",
          "size": "1095kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T13:42:05+00:00",
          "link": "https://arxiv.org/abs/2506.20926v2",
          "size": "1095kb",
          "version": "v2"
        }
      ],
      "title": "Towards Generalized and Stealthy Watermarking for Generative Code Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20926",
        "HTML": "https://arxiv.org/html/2506.20926v2",
        "PDF": "https://arxiv.org/pdf/2506.20926"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20960",
      "abstract": "In this paper, we introduce OmniEval, a benchmark for evaluating omni-modality models like MiniCPM-O 2.6, which encompasses visual, auditory, and textual inputs. Compared with existing benchmarks, our OmniEval has several distinctive features: (i) Full-modal collaboration: We design evaluation tasks that highlight the strong coupling between audio and video, requiring models to effectively leverage the collaborative perception of all modalities; (ii) Diversity of videos: OmniEval includes 810 audio-visual synchronized videos, 285 Chinese videos and 525 English videos; (iii) Diversity and granularity of tasks: OmniEval contains 2617 question-answer pairs, comprising 1412 open-ended questions and 1205 multiple-choice questions. These questions are divided into 3 major task types and 12 sub-task types to achieve comprehensive evaluation. Among them, we introduce a more granular video localization task named Grounding. Then we conduct experiments on OmniEval with several omni-modality models. We hope that our OmniEval can provide a platform for evaluating the ability to construct and understand coherence from the context of all modalities. Codes and data could be found at https://omnieval-benchmark.github.io/.",
      "authors": [
        "Yiman Zhang",
        "Ziheng Luo",
        "Qiangyu Yan",
        "Wei He",
        "Borui Jiang",
        "Xinghao Chen",
        "Kai Han"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T02:54:24+00:00",
          "link": "https://arxiv.org/abs/2506.20960v1",
          "size": "947kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T15:16:22+00:00",
          "link": "https://arxiv.org/abs/2506.20960v2",
          "size": "947kb",
          "version": "v2"
        }
      ],
      "title": "OmniEval: A Benchmark for Evaluating Omni-modal Models with Visual, Auditory, and Textual Inputs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20960",
        "HTML": "https://arxiv.org/html/2506.20960v2",
        "PDF": "https://arxiv.org/pdf/2506.20960"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21042",
      "abstract": "Detectors often suffer from performance drop due to domain gap between training and testing data. Recent methods explore diffusion models applied to domain generalization (DG) and adaptation (DA) tasks, but still struggle with large inference costs and have not yet fully leveraged the capabilities of diffusion models. We propose to tackle these problems by extracting intermediate features from a single-step diffusion process, improving feature collection and fusion to reduce inference time by 75% while enhancing performance on source domains (i.e., Fitness). Then, we construct an object-centered auxiliary branch by applying box-masked images with class prompts to extract robust and domain-invariant features that focus on object. We also apply consistency loss to align the auxiliary and ordinary branch, balancing fitness and generalization while preventing overfitting and improving performance on target domains (i.e., Generalization). Furthermore, within a unified framework, standard detectors are guided by diffusion detectors through feature-level and object-level alignment on source domains (for DG) and unlabeled target domains (for DA), thereby improving cross-domain detection performance (i.e., Transferability). Our method achieves competitive results on 3 DA benchmarks and 5 DG benchmarks. Additionally, experiments on COCO generalization benchmark demonstrate that our method maintains significant advantages and show remarkable efficiency in large domain shifts and low-data scenarios. Our work shows the superiority of applying diffusion models to domain generalized and adaptive detection tasks and offers valuable insights for visual perception tasks across diverse domains. The code is available at \\href{https://github.com/heboyong/Fitness-Generalization-Transferability}.",
      "authors": [
        "Boyong He",
        "Yuxiang Ji",
        "Zhuoyue Tan and Liaoni Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T06:42:23+00:00",
          "link": "https://arxiv.org/abs/2506.21042v1",
          "size": "36455kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T03:56:38+00:00",
          "link": "https://arxiv.org/abs/2506.21042v2",
          "size": "2342kb",
          "version": "v2"
        }
      ],
      "title": "Boosting Domain Generalized and Adaptive Detection with Diffusion Models: Fitness, Generalization, and Transferability",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21042",
        "HTML": "https://arxiv.org/html/2506.21042v2",
        "PDF": "https://arxiv.org/pdf/2506.21042"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21118",
      "abstract": "Lipschitz continuity of algorithms, introduced by Kumabe and Yoshida (FOCS'23), measures the stability of an algorithm against small input perturbations. Algorithms with small Lipschitz continuity are desirable, as they ensure reliable decision-making and reproducible scientific research. Several studies have proposed Lipschitz continuous algorithms for various combinatorial optimization problems, but these algorithms are problem-specific, requiring a separate design for each problem.\n  To address this issue, we provide the first algorithmic meta-theorem in the field of Lipschitz continuous algorithms. Our result can be seen as a Lipschitz continuous analogue of Courcelle's theorem, which offers Lipschitz continuous algorithms for problems on bounded-treewidth graphs. Specifically, we consider the problem of finding a vertex set in a graph that maximizes or minimizes the total weight, subject to constraints expressed in monadic second-order logic (MSO_2). We show that for any $\\varepsilon>0$, there exists a $(1\\pm \\varepsilon)$-approximation algorithm for the problem with a polylogarithmic Lipschitz constant on bounded treewidth graphs. On such graphs, our result outperforms most existing Lipschitz continuous algorithms in terms of approximability and/or Lipschitz continuity. Further, we provide similar results for problems on bounded-clique-width graphs subject to constraints expressed in MSO_1. Additionally, we construct a Lipschitz continuous version of Baker's decomposition using our meta-theorem as a subroutine.",
      "authors": [
        "Tatsuya Gima",
        "Soh Kumabe",
        "and Yuichi Yoshida"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Data Structures and Algorithms (cs.DS)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T09:34:09+00:00",
          "link": "https://arxiv.org/abs/2506.21118v1",
          "size": "254kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T03:16:22+00:00",
          "link": "https://arxiv.org/abs/2506.21118v2",
          "size": "39kb",
          "version": "v2"
        }
      ],
      "title": "Courcelle's Theorem for Lipschitz Continuity",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21118",
        "HTML": "https://arxiv.org/html/2506.21118v2",
        "PDF": "https://arxiv.org/pdf/2506.21118"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21203",
      "abstract": "The study of the evolving phenomena in a domain helps to understand the relationships between entities at different points in time and predict future trends. These phenomena, often complex, can be represented using knowledge graphs, which have the capability to model heterogeneous data from multiple sources. Nowadays, a considerable amount of sources delivering periodic updates to knowledge graphs in various domains is openly available. The evolution of data is of interest to knowledge graph management systems, and therefore it is crucial to organize these constantly evolving data to make them easily accessible and exploitable for analyzes. In this article, we will present and formalize the condensed representation of these evolving graphs.",
      "authors": [
        "Jey Puget Gil",
        "Emmanuel Coquery",
        "John Samuel",
        "Gilles Gesquiere"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T13:00:09+00:00",
          "link": "https://arxiv.org/abs/2506.21203v1",
          "size": "242kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T11:27:42+00:00",
          "link": "https://arxiv.org/abs/2506.21203v2",
          "size": "242kb",
          "version": "v2"
        }
      ],
      "title": "Condensed Representation of RDF and its Application on Graph Versioning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21203",
        "HTML": "https://arxiv.org/html/2506.21203v2",
        "PDF": "https://arxiv.org/pdf/2506.21203"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21387",
      "abstract": "Tabular foundation models have shown strong performance across various tabular learning tasks via in-context learning, offering robust generalization without any downstream finetuning. However, their inference-time costs remain high, particularly for larger datasets. To address this, we propose early-stopping the in-context learning process. We achieve this by dynamically evaluating whether to stop in-context learning after each Transformer encoder layer. Once stopped, we decode the embedding using a pre-trained layer-wise decoder. Experiments across 34 small classification tasks size show that early stopping in-context learning accelerates inference by up to x1.3 with negligible degradation in predictive performance. To assess scalability, we further evaluate our method on five larger classification tasks, achieving speedups of up to x2.2. Our results demonstrate the potential of early exiting as an effective and practical strategy for improving the efficiency of tabular in-context learning.",
      "authors": [
        "Jaris K\\\"uken",
        "Lennart Purucker",
        "Frank Hutter"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T15:36:37+00:00",
          "link": "https://arxiv.org/abs/2506.21387v1",
          "size": "106kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T19:36:55+00:00",
          "link": "https://arxiv.org/abs/2506.21387v2",
          "size": "106kb",
          "version": "v2"
        }
      ],
      "title": "Early Stopping Tabular In-Context Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21387",
        "HTML": "https://arxiv.org/html/2506.21387v2",
        "PDF": "https://arxiv.org/pdf/2506.21387"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21401",
      "abstract": "This paper presents an end-to-end framework for reconstructing 3D parametric curves directly from multi-view edge maps. Contrasting with existing two-stage methods that follow a sequential ``edge point cloud reconstruction and parametric curve fitting'' pipeline, our one-stage approach optimizes 3D parametric curves directly from 2D edge maps, eliminating error accumulation caused by the inherent optimization gap between disconnected stages. However, parametric curves inherently lack suitability for rendering-based multi-view optimization, necessitating a complementary representation that preserves their geometric properties while enabling differentiable rendering. We propose a novel bi-directional coupling mechanism between parametric curves and edge-oriented Gaussian components. This tight correspondence formulates a curve-aware Gaussian representation, \\textbf{CurveGaussian}, that enables differentiable rendering of 3D curves, allowing direct optimization guided by multi-view evidence. Furthermore, we introduce a dynamically adaptive topology optimization framework during training to refine curve structures through linearization, merging, splitting, and pruning operations. Comprehensive evaluations on the ABC dataset and real-world benchmarks demonstrate our one-stage method's superiority over two-stage alternatives, particularly in producing cleaner and more robust reconstructions. Additionally, by directly optimizing parametric curves, our method significantly reduces the parameter count during training, achieving both higher efficiency and superior performance compared to existing approaches.",
      "authors": [
        "Zhirui Gao",
        "Renjiao Yi",
        "Yaqiao Dai",
        "Xuening Zhu",
        "Wei Chen",
        "Chenyang Zhu",
        "Kai Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T15:48:08+00:00",
          "link": "https://arxiv.org/abs/2506.21401v1",
          "size": "16958kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T07:11:28+00:00",
          "link": "https://arxiv.org/abs/2506.21401v2",
          "size": "5847kb",
          "version": "v2"
        }
      ],
      "title": "Curve-Aware Gaussian Splatting for 3D Parametric Curve Reconstruction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21401",
        "HTML": "https://arxiv.org/html/2506.21401v2",
        "PDF": "https://arxiv.org/pdf/2506.21401"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21490",
      "abstract": "Achieving seamless coordination between AI agents and humans is crucial for real-world applications, yet it remains a significant open challenge. Hanabi is a cooperative card game featuring imperfect information, constrained communication, theory of mind requirements, and coordinated action -- making it an ideal testbed for human-AI coordination. However, its use for human-AI interaction has been limited by the challenges of human evaluation. In this work, we introduce the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to overcome the constraints of costly and difficult-to-reproduce human evaluations. We develop \\textit{human proxy agents} on a large-scale human dataset that serve as robust, cheap, and reproducible human-like evaluation partners in AH2AC2. To encourage the development of data-efficient methods, we open-source a dataset of 3,079 games, deliberately limiting the amount of available human gameplay data. We present baseline results for both two- and three- player Hanabi scenarios. To ensure fair evaluation, we host the proxy agents through a controlled evaluation system rather than releasing them publicly. The code is available at \\href{https://github.com/FLAIROx/ah2ac2}{https://github.com/FLAIROx/ah2ac2}.",
      "authors": [
        "Tin Dizdarevi\\'c",
        "Ravi Hammond",
        "Tobias Gessler",
        "Anisoara Calinescu",
        "Jonathan Cook",
        "Matteo Gallici",
        "Andrei Lupu",
        "Darius Muglich",
        "Johannes Forkel",
        "Jakob Nicolaus Foerster"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)",
        "Human-Computer Interaction (cs.HC)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T17:19:52+00:00",
          "link": "https://arxiv.org/abs/2506.21490v1",
          "size": "1683kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T10:25:50+00:00",
          "link": "https://arxiv.org/abs/2506.21490v2",
          "size": "1683kb",
          "version": "v2"
        }
      ],
      "title": "Ad-Hoc Human-AI Coordination Challenge",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21490",
        "HTML": "https://arxiv.org/html/2506.21490v2",
        "PDF": "https://arxiv.org/pdf/2506.21490"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21514",
      "abstract": "Multimodal learning aims to leverage information from diverse data modalities to achieve more comprehensive performance. However, conventional multimodal models often suffer from modality imbalance, where one or a few modalities dominate model optimization, leading to suboptimal feature representation and underutilization of weak modalities. To address this challenge, we introduce Gradient-Guided Distillation (G$^{2}$D), a knowledge distillation framework that optimizes the multimodal model with a custom-built loss function that fuses both unimodal and multimodal objectives. G$^{2}$D further incorporates a dynamic sequential modality prioritization (SMP) technique in the learning process to ensure each modality leads the learning process, avoiding the pitfall of stronger modalities overshadowing weaker ones. We validate G$^{2}$D on multiple real-world datasets and show that G$^{2}$D amplifies the significance of weak modalities while training and outperforms state-of-the-art methods in classification and regression tasks. Our code is available at https://github.com/rAIson-Lab/G2D.",
      "authors": [
        "Mohammed Rakib",
        "Arunkumar Bagavathi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T17:37:36+00:00",
          "link": "https://arxiv.org/abs/2506.21514v1",
          "size": "6068kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T01:56:41+00:00",
          "link": "https://arxiv.org/abs/2506.21514v2",
          "size": "6071kb",
          "version": "v2"
        }
      ],
      "title": "G$^{2}$D: Boosting Multimodal Learning with Gradient-Guided Distillation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21514",
        "HTML": "https://arxiv.org/html/2506.21514v2",
        "PDF": "https://arxiv.org/pdf/2506.21514"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21521",
      "abstract": "Large language models (LLMs) are regularly evaluated using benchmark datasets. But what justifies making inferences about an LLM's capabilities based on its answers to a curated set of questions? This paper first introduces a formal framework to address this question. The key is to note that the benchmarks used to test LLMs -- such as AP exams -- are also those used to test people. However, this raises an implication: these benchmarks are only valid tests if LLMs misunderstand concepts in ways that mirror human misunderstandings. Otherwise, success on benchmarks only demonstrates potemkin understanding: the illusion of understanding driven by answers irreconcilable with how any human would interpret a concept. We present two procedures for quantifying the existence of potemkins: one using a specially designed benchmark in three domains, the other using a general procedure that provides a lower-bound on their prevalence. We find that potemkins are ubiquitous across models, tasks, and domains. We also find that these failures reflect not just incorrect understanding, but deeper internal incoherence in concept representations.",
      "authors": [
        "Marina Mancoridis",
        "Bec Weeks",
        "Keyon Vafa",
        "Sendhil Mullainathan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T17:41:35+00:00",
          "link": "https://arxiv.org/abs/2506.21521v1",
          "size": "2402kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T18:12:45+00:00",
          "link": "https://arxiv.org/abs/2506.21521v2",
          "size": "2402kb",
          "version": "v2"
        }
      ],
      "title": "Potemkin Understanding in Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21521",
        "HTML": "https://arxiv.org/html/2506.21521v2",
        "PDF": "https://arxiv.org/pdf/2506.21521"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21544",
      "abstract": "Reconstructing 3D objects from a single image remains challenging, especially under real-world occlusions. While recent diffusion-based view synthesis models can generate consistent novel views from a single RGB image, they typically assume fully visible inputs and fail when parts of the object are occluded, resulting in degraded 3D reconstruction quality. We propose DeOcc-1-to-3, an end-to-end framework for occlusion-aware multi-view generation that synthesizes six structurally consistent novel views directly from a single occluded image, enabling reliable 3D reconstruction without prior inpainting or manual annotations. Our self-supervised training pipeline leverages occluded-unoccluded image pairs and pseudo-ground-truth views to teach the model structure-aware completion and view consistency. Without modifying the original architecture, we fully fine-tune the view synthesis model to jointly learn completion and multi-view generation. Additionally, we introduce the first benchmark for occlusion-aware reconstruction, covering diverse occlusion levels, object categories, and masking patterns, providing a standardized protocol for future evaluation.",
      "authors": [
        "Yansong Qu",
        "Shaohui Dai",
        "Xinyang Li",
        "Yuze Wang",
        "You Shen",
        "Liujuan Cao",
        "Rongrong Ji"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T17:58:26+00:00",
          "link": "https://arxiv.org/abs/2506.21544v1",
          "size": "12771kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T03:14:44+00:00",
          "link": "https://arxiv.org/abs/2506.21544v2",
          "size": "12752kb",
          "version": "v2"
        }
      ],
      "title": "DeOcc-1-to-3: 3D De-Occlusion from a Single Image via Self-Supervised Multi-View Diffusion",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21544",
        "HTML": "https://arxiv.org/html/2506.21544v2",
        "PDF": "https://arxiv.org/pdf/2506.21544"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21546",
      "abstract": "Recent progress in vision-language segmentation has significantly advanced grounded visual understanding. However, these models often exhibit hallucinations by producing segmentation masks for objects not grounded in the image content or by incorrectly labeling irrelevant regions. Existing evaluation protocols for segmentation hallucination primarily focus on label or textual hallucinations without manipulating the visual context, limiting their capacity to diagnose critical failures. In response, we introduce HalluSegBench, the first benchmark specifically designed to evaluate hallucinations in visual grounding through the lens of counterfactual visual reasoning. Our benchmark consists of a novel dataset of 1340 counterfactual instance pairs spanning 281 unique object classes, and a set of newly introduced metrics that quantify hallucination sensitivity under visually coherent scene edits. Experiments on HalluSegBench with state-of-the-art vision-language segmentation models reveal that vision-driven hallucinations are significantly more prevalent than label-driven ones, with models often persisting in false segmentation, highlighting the need for counterfactual reasoning to diagnose grounding fidelity.",
      "authors": [
        "Xinzhuo Li",
        "Adheesh Juvekar",
        "Xingyou Liu",
        "Muntasir Wahed",
        "Kiet A. Nguyen",
        "Ismini Lourentzou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T17:59:12+00:00",
          "link": "https://arxiv.org/abs/2506.21546v1",
          "size": "20977kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T15:32:51+00:00",
          "link": "https://arxiv.org/abs/2506.21546v2",
          "size": "20977kb",
          "version": "v2"
        }
      ],
      "title": "HalluSegBench: Counterfactual Visual Reasoning for Segmentation Hallucination Evaluation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21546",
        "HTML": "https://arxiv.org/html/2506.21546v2",
        "PDF": "https://arxiv.org/pdf/2506.21546"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21591",
      "abstract": "Large Language Models (LLMs) demonstrate significant potential but face challenges in complex financial reasoning tasks requiring both domain knowledge and sophisticated reasoning. Current evaluation benchmarks often fall short by not decoupling these capabilities indicators from single task performance and lack root cause analysis for task failure. To address this, we introduce FinEval-KR, a novel evaluation framework for decoupling and quantifying LLMs' knowledge and reasoning abilities independently, proposing distinct knowledge score and reasoning score metrics. Inspired by cognitive science, we further propose a cognitive score based on Bloom's taxonomy to analyze capabilities in reasoning tasks across different cognitive levels. We also release a new open-source Chinese financial reasoning dataset covering 22 subfields to support reproducible research and further advancements in financial reasoning. Our experimental results reveal that LLM reasoning ability and higher-order cognitive ability are the core factors influencing reasoning accuracy. We also specifically find that even top models still face a bottleneck with knowledge application. Furthermore, our analysis shows that specialized financial LLMs generally lag behind the top general large models across multiple metrics.",
      "authors": [
        "Shaoyu Dou",
        "Yutian Shen",
        "Mofan Chen",
        "Zixuan Wang",
        "Jiajie Xu",
        "Qi Guo",
        "Kailai Shao",
        "Chao Chen",
        "Haixiang Hu",
        "Haibo Shi",
        "Min Min",
        "Liwen Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-18T06:21:50+00:00",
          "link": "https://arxiv.org/abs/2506.21591v1",
          "size": "4410kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T03:42:45+00:00",
          "link": "https://arxiv.org/abs/2506.21591v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "FinEval-KR: A Financial Domain Evaluation Framework for Large Language Models' Knowledge and Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21591",
        "PDF": "https://arxiv.org/pdf/2506.21591"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper mentions the creation of a new open-source Chinese financial reasoning dataset, which is related to data collection, but there is no novel data processing method proposed for LLM training."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21599",
      "abstract": "Large language models (LLMs) have been adopted for next point-of-interest (POI) recommendation tasks. Typical LLM-based recommenders fall into two categories: prompt-based and supervised fine-tuning (SFT)-based models. Prompt-based models generally offer greater output flexibility but deliver lower accuracy, whereas SFT-based models achieve higher performance yet face a fundamental mismatch: next POI recommendation data does not naturally suit supervised fine-tuning. In SFT, the model is trained to reproduce the exact ground truth, but each training example provides only a single target POI, so there is no ground truth for producing a top-k list.\n  To address this, we propose Refine-POI, a reinforcement fine-tuning framework for next POI recommendation. We introduce recommendation-driven rewards that enable LLMs to learn to generate top-k recommendation lists using only one ground-truth POI per example. Experiments on real-world datasets demonstrate that Refine-POI achieves state-of-the-art top-k recommendation performance.",
      "authors": [
        "Peibo Li",
        "Shuang Ao",
        "Hao Xue",
        "Yang Song",
        "Maarten de Rijke",
        "Johan Barth\\'elemy",
        "Tomasz Bednarz",
        "Flora D. Salim"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Information Retrieval (cs.IR)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-19T02:51:10+00:00",
          "link": "https://arxiv.org/abs/2506.21599v1",
          "size": "354kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T11:36:12+00:00",
          "link": "https://arxiv.org/abs/2506.21599v2",
          "size": "354kb",
          "version": "v2"
        }
      ],
      "title": "Refine-POI: Reinforcement Fine-Tuned Large Language Models for Next Point-of-Interest Recommendation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21599",
        "HTML": "https://arxiv.org/html/2506.21599v2",
        "PDF": "https://arxiv.org/pdf/2506.21599"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "This paper proposes a reinforcement fine-tuning framework for LLMs in POI recommendation but does not address improvements in training data processing or construction for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21794",
      "abstract": "Within the field of media framing, homelessness has been a historically under-researched topic. Framing theory states that the media's method of presenting information plays a pivotal role in controlling public sentiment toward a topic. The sentiment held towards homeless individuals influences their ability to access jobs, housing, and resources as a result of discrimination. This study analyzes the topic and sentiment trends in related media articles to validate framing theory within the scope of homelessness. It correlates these shifts in media reporting with public sentiment. We examine state-level trends in California, Florida, Washington, Oregon, and New York from 2015 to 2023. We utilize the GDELT 2.0 Global Knowledge Graph (GKG) database to gather article data and use X to measure public sentiment towards homeless individuals. Additionally, to identify if there is a correlation between media reporting and public policy, we examine the media's impact on state-level legislation. Our research uses Granger-causality tests and vector autoregressive (VAR) models to establish a correlation between media framing and public sentiment. We also use latent Dirichlet allocation (LDA) and GPT-3.5 (LLM-as-annotator paradigm) for topic modeling and sentiment analysis. Our findings demonstrate a statistically significant correlation between media framing and public sentiment, especially in states with high homelessness rates. We found no significant correlation between media framing and legislation, suggesting a possible disconnect between public opinion and policy-making. These findings reveal the broader impact of the media's framing decisions and delineate its ability to affect society.",
      "authors": [
        "Akshay Irudayaraj",
        "Nathan Ye",
        "Yash Chainani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T22:34:17+00:00",
          "link": "https://arxiv.org/abs/2506.21794v1",
          "size": "2232kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T02:32:33+00:00",
          "link": "https://arxiv.org/abs/2506.21794v2",
          "size": "2232kb",
          "version": "v2"
        }
      ],
      "title": "Shifting Narratives: A Longitudinal Analysis of Media Trends and Public Attitudes on Homelessness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21794",
        "PDF": "https://arxiv.org/pdf/2506.21794"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The study is concerned with media framing and sentiment analysis related to homelessness using existing databases and models like GPT-3.5. It does not propose any novel methods for LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21835",
      "abstract": "The recent advancements in large foundation models have driven the success of open-set image segmentation, a task focused on segmenting objects beyond predefined categories. Among various prompt types (such as points, boxes, texts, and visual references), visual reference segmentation stands out for its unique flexibility and strong zero-shot capabilities. Recently, several SAM-based methods have made notable progress in this task by automatically generating prompts to guide SAM. However, these methods often generate prompts at object boundaries due to suboptimal prompt encoder, which results in instability and reduced robustness. In this work, we introduce ProSAM, a simple but effective method to address the stability challenges we identified in existing SAM-based visual reference segmentation approaches. By learning a variational prompt encoder to predict multivariate prompt distributions, ProSAM avoids generating prompts that lie in unstable regions, overcoming the instability caused by less robust prompts. Our approach consistently surpasses state-of-the-art methods on the Pascal-5$^i$ and COCO-20$^i$ datasets, providing a more robust solution for visual reference segmentation.",
      "authors": [
        "Xiaoqi Wang",
        "Clint Sebastian",
        "Wenbin He and Liu Ren"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T00:50:15+00:00",
          "link": "https://arxiv.org/abs/2506.21835v1",
          "size": "10893kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T05:55:23+00:00",
          "link": "https://arxiv.org/abs/2506.21835v2",
          "size": "10893kb",
          "version": "v2"
        }
      ],
      "title": "ProSAM: Enhancing the Robustness of SAM-based Visual Reference Segmentation with Probabilistic Prompts",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21835",
        "HTML": "https://arxiv.org/html/2506.21835v2",
        "PDF": "https://arxiv.org/pdf/2506.21835"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This work focuses on visual reference segmentation using SAM-based methods and does not address training data processing related to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21853",
      "abstract": "Quadrupedal robots have demonstrated exceptional locomotion capabilities through Reinforcement Learning (RL), including extreme parkour maneuvers. However, integrating locomotion skills with navigation in quadrupedal robots has not been fully investigated, which holds promise for enhancing long-distance movement capabilities. In this paper, we propose Skill-Nav, a method that incorporates quadrupedal locomotion skills into a hierarchical navigation framework using waypoints as an interface. Specifically, we train a waypoint-guided locomotion policy using deep RL, enabling the robot to autonomously adjust its locomotion skills to reach targeted positions while avoiding obstacles. Compared with direct velocity commands, waypoints offer a simpler yet more flexible interface for high-level planning and low-level control. Utilizing waypoints as the interface allows for the application of various general planning tools, such as large language models (LLMs) and path planning algorithms, to guide our locomotion policy in traversing terrains with diverse obstacles. Extensive experiments conducted in both simulated and real-world scenarios demonstrate that Skill-Nav can effectively traverse complex terrains and complete challenging navigation tasks.",
      "authors": [
        "Dewei Wang",
        "Chenjia Bai",
        "Chenhui Li",
        "Jiyuan Shi",
        "Yan Ding",
        "Chi Zhang",
        "Bin Zhao"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T02:08:40+00:00",
          "link": "https://arxiv.org/abs/2506.21853v1",
          "size": "1726kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T08:59:34+00:00",
          "link": "https://arxiv.org/abs/2506.21853v2",
          "size": "1726kb",
          "version": "v2"
        }
      ],
      "title": "Skill-Nav: Enhanced Navigation with Versatile Quadrupedal Locomotion via Waypoint Interface",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21853",
        "HTML": "https://arxiv.org/html/2506.21853v2",
        "PDF": "https://arxiv.org/pdf/2506.21853"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The research is concerned with integrating quadrupedal locomotion skills into robotics navigation and does not address issues related to LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22022",
      "abstract": "Facial stylization aims to transform facial images into appealing, high-quality stylized portraits, with the critical challenge of accurately learning the target style while maintaining content consistency with the original image. Although previous StyleGAN-based methods have made significant advancements, the generated results still suffer from artifacts or insufficient fidelity to the source image. We argue that these issues stem from neglecting semantic shift of the generator during stylization. Therefore, we propose a facial stylization method that integrates semantic preservation constraint and pseudo-paired supervision to enhance the content correspondence and improve the stylization effect. Additionally, we develop a methodology for creating multi-level pseudo-paired datasets to implement supervisory constraint. Furthermore, building upon our facial stylization framework, we achieve more flexible multimodal and reference-guided stylization without complex network architecture designs or additional training. Experimental results demonstrate that our approach produces high-fidelity, aesthetically pleasing facial style transfer that surpasses previous methods.",
      "authors": [
        "Zhanyi Lu",
        "Yue Zhou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T08:44:31+00:00",
          "link": "https://arxiv.org/abs/2506.22022v1",
          "size": "41060kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T07:02:04+00:00",
          "link": "https://arxiv.org/abs/2506.22022v2",
          "size": "31389kb",
          "version": "v2"
        }
      ],
      "title": "Advancing Facial Stylization through Semantic Preservation Constraint and Pseudo-Paired Supervision",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22022",
        "HTML": "https://arxiv.org/html/2506.22022v2",
        "PDF": "https://arxiv.org/pdf/2506.22022"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This study is centered on facial stylization using semantic preservation constraint and pseudo-paired supervision. It discusses generating stylized portraits but does not engage with LLM training data processing or data engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22112",
      "abstract": "Offline reinforcement learning (RL) has emerged as a prevalent and effective methodology for real-world recommender systems, enabling learning policies from historical data and capturing user preferences. In offline RL, reward shaping encounters significant challenges, with past efforts to incorporate prior strategies for uncertainty to improve world models or penalize underexplored state-action pairs. Despite these efforts, a critical gap remains: the simultaneous balancing of intrinsic biases in world models and the diversity of policy recommendations. To address this limitation, we present an innovative offline RL framework termed Reallocated Reward for Recommender Systems (R3S). By integrating inherent model uncertainty to tackle the intrinsic fluctuations in reward predictions, we boost diversity for decision-making to align with a more interactive paradigm, incorporating extra penalizers with decay that deter actions leading to diminished state variety at both local and global scales. The experimental results demonstrate that R3S improves the accuracy of world models and efficiently harmonizes the heterogeneous preferences of the users.",
      "authors": [
        "Wenzheng Shu",
        "Yanxiang Zeng",
        "Yongxiang Tang",
        "Teng Sha",
        "Ning Luo",
        "Yanhua Cheng",
        "Xialong Liu",
        "Fan Zhou",
        "Peng Jiang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Information Retrieval (cs.IR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T10:46:41+00:00",
          "link": "https://arxiv.org/abs/2506.22112v1",
          "size": "203kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T06:57:33+00:00",
          "link": "https://arxiv.org/abs/2506.22112v2",
          "size": "202kb",
          "version": "v2"
        }
      ],
      "title": "Reward Balancing Revisited: Enhancing Offline Reinforcement Learning for Recommender Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22112",
        "HTML": "https://arxiv.org/html/2506.22112v2",
        "PDF": "https://arxiv.org/pdf/2506.22112"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on offline reinforcement learning for recommender systems. It does not address LLM training data tasks such as data collection, processing, or enhancement."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22133",
      "abstract": "A Condorcet winning set addresses the Condorcet paradox by selecting a few candidates--rather than a single winner--such that no unselected alternative is preferred to all of them by a majority of voters. This idea extends to $\\alpha$-undominated sets, which ensure the same property for any $\\alpha$-fraction of voters and are guaranteed to exist in constant size for any $\\alpha$. However, the requirement that an outsider be preferred to every member of the set can be overly restrictive and difficult to justify in many applications. Motivated by this, we introduce a more flexible notion: $(t, \\alpha)$-undominated sets. Here, each voter compares an outsider to their $t$-th most preferred member of the set, and the set is undominated if no outsider is preferred by more than an $\\alpha$-fraction of voters. This framework subsumes prior definitions, recovering Condorcet winning sets when $(t = 1, \\alpha = 1/2)$ and $\\alpha$-undominated sets when $t = 1$, and introduces a new, tunable notion of collective acceptability for $t > 1$. We establish three main results:\n  1. We prove that a $(t, \\alpha)$-undominated set of size $O(t/\\alpha)$ exists for all values of $t$ and $\\alpha$.\n  2. We show that as $t$ becomes large, the minimum size of such a set approaches $t/\\alpha$, which is asymptotically optimal.\n  3. In the special case $t = 1$, we improve the bound on the size of an $\\alpha$-undominated set given by Charikar, Lassota, Ramakrishnan, Vetta, and Wang (STOC 2025). As a consequence, we show that a Condorcet winning set of five candidates exists, improving their bound of six.",
      "authors": [
        "Thanh Nguyen",
        "Haoyu Song",
        "Young-San Lin"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Science and Game Theory (cs.GT)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T11:22:54+00:00",
          "link": "https://arxiv.org/abs/2506.22133v1",
          "size": "97kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T02:12:57+00:00",
          "link": "https://arxiv.org/abs/2506.22133v2",
          "size": "97kb",
          "version": "v2"
        }
      ],
      "title": "A few good choices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22133",
        "PDF": "https://arxiv.org/pdf/2506.22133"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on voting theory and selection criteria for candidate sets rather than any aspect of LLM training data processing or engineering."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22172",
      "abstract": "This paper establishes formal mathematical foundations linking Chaos Game Representations (CGR) of DNA sequences to their underlying $k$-mer frequencies. We prove that the Frequency CGR (FCGR) of order $k$ is mathematically equivalent to a discretization of CGR at resolution $2^k \\times 2^k$, and its vectorization corresponds to the $k$-mer frequencies of the sequence. Additionally, we characterize how symmetry transformations of CGR images correspond to specific nucleotide permutations in the originating sequences. Leveraging these insights, we introduce an algorithm that generates synthetic DNA sequences from prescribed $k$-mer distributions by constructing Eulerian paths on De Bruijn multigraphs. This enables reconstruction of sequences matching target $k$-mer profiles with arbitrarily high precision, facilitating the creation of synthetic CGR images for applications such as data augmentation for machine learning-based taxonomic classification of DNA sequences. Numerical experiments validate the effectiveness of our method across both real genomic data and artificially sampled distributions. To our knowledge, this is the first comprehensive framework that unifies CGR geometry, $k$-mer statistics, and sequence reconstruction, offering new tools for genomic analysis and visualization.",
      "authors": [
        "Haoze He",
        "Lila Kari",
        "Pablo Millan Arias"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Formal Languages and Automata Theory (cs.FL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T12:35:57+00:00",
          "link": "https://arxiv.org/abs/2506.22172v1",
          "size": "865kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T15:31:04+00:00",
          "link": "https://arxiv.org/abs/2506.22172v2",
          "size": "865kb",
          "version": "v2"
        }
      ],
      "title": "Bridging Chaos Game Representations and $k$-mer Frequencies of DNA Sequences",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22172",
        "HTML": "https://arxiv.org/html/2506.22172v2",
        "PDF": "https://arxiv.org/pdf/2506.22172"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper presents a framework for DNA sequence analysis using CGR and k-mer frequencies, without relevance to LLM training data collection or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22200",
      "abstract": "Recent advances in reinforcement learning (RL) have significantly enhanced the reasoning capabilities of large language models (LLMs). Group Relative Policy Optimization (GRPO), an efficient variant of PPO that lowers RL's computational cost, still faces limited exploration, low sample efficiency and instability, constraining its performance on complex reasoning tasks. To address these limitations, we introduce EFRame, an Exploration-Filtering-Replay framework that systematically augments GRPO along three critical dimensions. EFRame performs additional rollouts to explore high-quality trajectories, applies online filtering to eliminate low-quality samples that introduce noise and variance, and leverages experience replay to repeatedly exploit rare but informative samples. EFRame establishes a complete and stable learning cycle, guiding the model through a structured transition from exploration to convergence. Our experiments across a variety of reasoning benchmarks demonstrate that EFRame not only improves the robustness and efficiency of training, but also enables access to deeper reasoning capabilities that remain unattainable under vanilla GRPO. Furthermore, EFRame enables a more fine-grained categorization of training samples, allowing for a deeper analysis of how different types of samples contribute to the learning process in RL. Our code is available at https://github.com/597358816/EFRame.",
      "authors": [
        "Chen Wang",
        "Lai Wei",
        "Yanzhi Zhang",
        "Chenyang Shao",
        "Zedong Dan",
        "Weiran Huang",
        "Yue Wang",
        "Yuzhi Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:09:05+00:00",
          "link": "https://arxiv.org/abs/2506.22200v1",
          "size": "815kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T07:33:48+00:00",
          "link": "https://arxiv.org/abs/2506.22200v2",
          "size": "816kb",
          "version": "v2"
        }
      ],
      "title": "EFRame: Deeper Reasoning via Exploration-Filter-Replay Reinforcement Learning Framework",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22200",
        "HTML": "https://arxiv.org/html/2506.22200v2",
        "PDF": "https://arxiv.org/pdf/2506.22200"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The focus of the paper is on reinforcement learning improvements and efficiency, particularly through the EFRame framework. It does not address LLM training data processing or any data engineering tasks relevant to LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22206",
      "abstract": "We introduce a non-wellfounded proof system for intuitionistic logic extended with ordinary inductive and co-inductive definitions, based on a syntax in which fixpoint formulas are annotated with explicit variables for ordinals. We explore the computational content of this system, in particular we introduce a notion of computability and show that every valid proof is computable. As a consequence, we obtain a normalization result for proofs of what we call finitary formulas. A special case of this result is that every proof of a sequent of the appropriate form represents a unique function on natural numbers. Finally, we derive a categorical model from the proof system and show that least and greatest fixpoint formulas correspond to initial algebras and final coalgebras respectively.",
      "authors": [
        "Sebastian Enqvist"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T13:25:04+00:00",
          "link": "https://arxiv.org/abs/2506.22206v1",
          "size": "33kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T09:59:37+00:00",
          "link": "https://arxiv.org/abs/2506.22206v2",
          "size": "34kb",
          "version": "v2"
        }
      ],
      "title": "Computation by infinite descent made explicit",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22206",
        "PDF": "https://arxiv.org/pdf/2506.22206"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper focuses on a non-wellfounded proof system for intuitionistic logic, exploring the computational content of such systems. It does not address any aspect of LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22270",
      "abstract": "The proliferation of disinformation challenges traditional, unscalable editorial processes and existing automated systems that prioritize engagement over public service values. To address this, we introduce the Public Service Algorithm (PSA), a novel framework using Large Language Models (LLMs) for scalable, transparent content curation based on Public Service Media (PSM) inspired values. Utilizing a large multilingual news dataset from the 'A European Perspective' project, our experiment directly compared article ratings from a panel of experienced editors from various European PSMs, with those from several LLMs, focusing on four criteria: diversity, in-depth analysis, forward-looking, and cross-border relevance. Utilizing criterion-specific prompts, our results indicate a promising alignment between human editorial judgment and LLM assessments, demonstrating the potential of LLMs to automate value-driven curation at scale without sacrificing transparency. This research constitutes a first step towards a scalable framework for the automatic curation of trustworthy news content.",
      "authors": [
        "Ahmad Mel",
        "Sebastien Noir"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T14:39:38+00:00",
          "link": "https://arxiv.org/abs/2506.22270v1",
          "size": "1553kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T13:16:54+00:00",
          "link": "https://arxiv.org/abs/2506.22270v2",
          "size": "1553kb",
          "version": "v2"
        }
      ],
      "title": "Public Service Algorithm: towards a transparent, explainable, and scalable content curation for news content based on editorial values",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22270",
        "HTML": "https://arxiv.org/html/2506.22270v2",
        "PDF": "https://arxiv.org/pdf/2506.22270"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "partial",
        "reason": "The paper explores the use of LLMs for content curation and alignment with editorial values, using a large multilingual dataset. However, it primarily addresses content curation rather than training data engineering or processing for LLMs."
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22370",
      "abstract": "Students in computing education increasingly use large language models (LLMs) such as ChatGPT. Yet, the role of LLMs in supporting cognitively demanding tasks, like deductive program verification, remains poorly understood. This paper investigates how students interact with an LLM when solving formal verification exercises in Dafny, a language that supports functional correctness, by allowing programmers to write formal specifications and automatically verifying that the implementation satisfies the specification. We conducted a mixed-methods study with master's students enrolled in a formal methods course. Each participant completed two verification problems, one with access to a custom ChatGPT interface that logged all interactions, and the other without. We identified strategies used by successful students and assessed the level of trust students place in LLMs. Our findings show that students perform significantly better when using ChatGPT; however, performance gains are tied to prompt quality. We conclude with practical recommendations for integrating LLMs into formal methods courses more effectively, including designing LLM-aware challenges that promote learning rather than substitution.",
      "authors": [
        "Carolina Carreira",
        "\\'Alvaro Silva",
        "Alexandre Abreu",
        "and Alexandra Mendes"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Programming Languages (cs.PL)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T16:34:13+00:00",
          "link": "https://arxiv.org/abs/2506.22370v1",
          "size": "296kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T10:08:05+00:00",
          "link": "https://arxiv.org/abs/2506.22370v2",
          "size": "296kb",
          "version": "v2"
        }
      ],
      "title": "Can Large Language Models Help Students Prove Software Correctness? An Experimental Study with Dafny",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22370",
        "HTML": "https://arxiv.org/html/2506.22370v2",
        "PDF": "https://arxiv.org/pdf/2506.22370"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper explores the use of LLMs in educational contexts for program verification, focusing on students' interactions with LLMs, rather than LLM training data processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2102.06702",
      "abstract": "Photocarrier generation rate in optoelectronic materials is often calculated using the Poynting vector in the frequency domain. However, this approach is not accurate in time-domain simulations of photoconductive devices because the instantaneous Poynting vector does not distinguish between power flux densities of optical and low-frequency electromagnetic fields. The latter is generated by photocurrents and is not supposed to contribute to the photocarrier generation since the corresponding photon energy is smaller than the bandgap energy of the optoelectronic material. This work proposes an optical absorption-based model to accurately calculate the generation rate in time-domain simulations. The proposed approach considers the material dispersion near the optical frequency corresponding to the bandgap energy of the optoelectronic material and calculates the instantaneous optical absorption from the polarization current density associated with this dispersion model. Numerical examples show that the proposed method is more accurate than the Poynting vector-based approach in calculating the instantaneous optical absorption. The method is further validated against experimental results via simulations of a photoconductive device, where the Poynting vector-based approach results in divergent carrier densities when the low-frequency fields are strong.",
      "authors": [
        "Liang Chen",
        "Ming Dong",
        "Ran Zhao",
        "Hakan Bagci"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optics (physics.optics)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Computational Physics (physics.comp-ph)"
      ],
      "submission_historys": [
        {
          "date": "2021-02-12T18:58:27+00:00",
          "link": "https://arxiv.org/abs/2102.06702v1",
          "size": "2756kb",
          "version": "v1"
        },
        {
          "date": "2024-10-07T14:19:41+00:00",
          "link": "https://arxiv.org/abs/2102.06702v2",
          "size": "4214kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T15:55:51+00:00",
          "link": "https://arxiv.org/abs/2102.06702v3",
          "size": "1611kb",
          "version": "v3"
        }
      ],
      "title": "Calculation of Photocarrier Generation from Optical Absorption for Time-domain Simulation of Optoelectronic Devices",
      "links": {
        "Abstract": "https://arxiv.org/abs/2102.06702",
        "HTML": "https://arxiv.org/html/2102.06702v3",
        "PDF": "https://arxiv.org/pdf/2102.06702"
      },
      "source": "arXiv"
    },
    {
      "id": "2309.07779",
      "abstract": "We consider the problem of approximating the regression function $f_\\mu:\\, \\Omega \\to Y$ from noisy $\\mu$-distributed vector-valued data $(\\omega_m,y_m)\\in\\Omega\\times Y$ by an online learning algorithm using a reproducing kernel Hilbert space $H$ (RKHS) as prior. In an online algorithm, i.i.d. samples become available one by one via a random process and are successively processed to build approximations to the regression function. Assuming that the regression function essentially belongs to $H$ (soft learning scenario), we provide estimates for the expected squared error in the RKHS norm of the approximations $f^{(m)}\\in H$ obtained by a standard regularized online approximation algorithm. In particular, we show an order-optimal estimate $$ \\mathbb{E}(\\|\\epsilon^{(m)}\\|_H^2)\\le C (m+1)^{-s/(2+s)},\\qquad m=1,2,\\ldots, $$ where $\\epsilon^{(m)}$ denotes the error term after $m$ processed data, the parameter $0<s\\leq 1$ expresses an additional smoothness assumption on the regression function, and the constant $C$ depends on the variance of the input noise, the smoothness of the regression function, and other parameters of the algorithm. The proof, which is inspired by results on Schwarz iterative methods in the noiseless case, uses only elementary Hilbert space techniques and minimal assumptions on the noise, the feature map that defines $H$ and the associated covariance operator.",
      "authors": [
        "Michael Griebel and Peter Oswald"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-14T15:10:47+00:00",
          "link": "https://arxiv.org/abs/2309.07779v1",
          "size": "33kb",
          "version": "v1"
        },
        {
          "date": "2024-04-29T07:20:27+00:00",
          "link": "https://arxiv.org/abs/2309.07779v2",
          "size": "35kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T13:42:05+00:00",
          "link": "https://arxiv.org/abs/2309.07779v3",
          "size": "39kb",
          "version": "v3"
        }
      ],
      "title": "Convergence analysis of online algorithms for vector-valued kernel regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.07779",
        "HTML": "https://arxiv.org/html/2309.07779v3",
        "PDF": "https://arxiv.org/pdf/2309.07779"
      },
      "tasks": [
        "regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.02530",
      "abstract": "This paper considers the projected gradient descent (PGD) algorithm for the problem of minimizing a continuously differentiable function on a nonempty closed subset of a Euclidean vector space. Without further assumptions, this problem is intractable and algorithms are only expected to find a stationary point. PGD generates a sequence in the set whose accumulation points are known to be Mordukhovich stationary. In this paper, these accumulation points are proven to be Bouligand stationary, and even proximally stationary if the gradient is locally Lipschitz continuous. These are the strongest stationarity properties that can be expected for the considered problem.",
      "authors": [
        "Guillaume Olikier and Ir\\`ene Waldspurger"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-04T22:51:11+00:00",
          "link": "https://arxiv.org/abs/2403.02530v1",
          "size": "48kb",
          "version": "v1"
        },
        {
          "date": "2024-09-11T16:30:36+00:00",
          "link": "https://arxiv.org/abs/2403.02530v2",
          "size": "72kb",
          "version": "v2"
        },
        {
          "date": "2025-06-27T20:19:59+00:00",
          "link": "https://arxiv.org/abs/2403.02530v3",
          "size": "54kb",
          "version": "v3"
        }
      ],
      "title": "Projected gradient descent accumulates at Bouligand stationary points",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.02530",
        "HTML": "https://arxiv.org/html/2403.02530v3",
        "PDF": "https://arxiv.org/pdf/2403.02530"
      },
      "source": "arXiv"
    },
    {
      "id": "2404.04182",
      "abstract": "The Zak-OTFS input/output (I/O) relation is predictable and non-fading when the delay and Doppler periods are greater than the effective channel delay and Doppler spreads, a condition which we refer to as the crystallization condition. The filter taps can simply be read off from the response to a single Zak-OTFS point (impulse) pulsone waveform, and the I/O relation can be reconstructed for a sampled system that operates under finite duration and bandwidth constraints. Predictability opens up the possibility of a model-free mode of operation. The time-domain realization of a Zak-OTFS point pulsone is a pulse train modulated by a tone, hence the name, pulsone. The Peak-to-Average Power Ratio (PAPR) of a pulsone is about $15$ dB, and we describe a general method for constructing a spread pulsone for which the time-domain realization has a PAPR of about 6dB. We construct the spread pulsone by applying a type of discrete spreading filter to a Zak-OTFS point pulsone. The self-ambiguity function of the point pulsone is supported on the period lattice ${\\Lambda}_{p}$, and by applying a discrete chirp filter, we obtain a spread pulsone with a self-ambiguity function that is supported on a rotated lattice ${\\Lambda^*}$. We show that if the channel satisfies the crystallization conditions with respect to ${\\Lambda^*}$ then the effective DD domain filter taps can simply be read off from the cross-ambiguity between the channel response to the spread pulsone and the transmitted spread pulsone. If, in addition, the channel satisfies the crystallization conditions with respect to the period lattice ${\\Lambda}_{p}$, then in an OTFS frame consisting of a spread pilot pulsone and point data pulsones, after cancelling the received signal corresponding to the spread pulsone, we can recover the channel response to any data pulsone.",
      "authors": [
        "Muhammad Ubadah",
        "Saif Khan Mohammed",
        "Ronny Hadani",
        "Shachar Kons",
        "Ananthanarayanan Chockalingam and Robert Calderbank"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-05T15:52:02+00:00",
          "link": "https://arxiv.org/abs/2404.04182v1",
          "size": "2837kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T22:41:10+00:00",
          "link": "https://arxiv.org/abs/2404.04182v2",
          "size": "3118kb",
          "version": "v2"
        }
      ],
      "title": "Zak-OTFS to Integrate Sensing the I/O Relation and Data Communication",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.04182",
        "HTML": "https://arxiv.org/html/2404.04182v2",
        "PDF": "https://arxiv.org/pdf/2404.04182"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2405.00592",
      "abstract": "From benign overfitting in overparameterized models to rich power-law scalings in performance, simple ridge regression displays surprising behaviors sometimes thought to be limited to deep neural networks. This balance of phenomenological richness with analytical tractability makes ridge regression the model system of choice in high-dimensional machine learning. In this paper, we present a unifying perspective on recent results on ridge regression using the basic tools of random matrix theory and free probability, aimed at readers with backgrounds in physics and deep learning. We highlight the fact that statistical fluctuations in empirical covariance matrices can be absorbed into a renormalization of the ridge parameter. This `deterministic equivalence' allows us to obtain analytic formulas for the training and generalization errors in a few lines of algebra by leveraging the properties of the $S$-transform of free probability. From these precise asymptotics, we can easily identify sources of power-law scaling in model performance. In all models, the $S$-transform corresponds to the train-test generalization gap, and yields an analogue of the generalized-cross-validation estimator. Using these techniques, we derive fine-grained bias-variance decompositions for a very general class of random feature models with structured covariates. This allows us to discover a scaling regime for random feature models where the variance due to the features limits performance in the overparameterized setting. We also demonstrate how anisotropic weight structure in random feature models can limit performance and lead to nontrivial exponents for finite-width corrections in the overparameterized setting. Our results extend and provide a unifying perspective on earlier models of neural scaling laws.",
      "authors": [
        "Alexander Atanasov",
        "Jacob A. Zavatone-Veth",
        "Cengiz Pehlevan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-01T15:59:00+00:00",
          "link": "https://arxiv.org/abs/2405.00592v1",
          "size": "308kb",
          "version": "v1"
        },
        {
          "date": "2024-06-24T17:47:41+00:00",
          "link": "https://arxiv.org/abs/2405.00592v2",
          "size": "391kb",
          "version": "v2"
        },
        {
          "date": "2024-06-26T16:56:06+00:00",
          "link": "https://arxiv.org/abs/2405.00592v3",
          "size": "392kb",
          "version": "v3"
        },
        {
          "date": "2025-06-30T15:11:57+00:00",
          "link": "https://arxiv.org/abs/2405.00592v4",
          "size": "390kb",
          "version": "v4"
        }
      ],
      "title": "Scaling and renormalization in high-dimensional regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.00592",
        "HTML": "https://arxiv.org/html/2405.00592v4",
        "PDF": "https://arxiv.org/pdf/2405.00592"
      },
      "tasks": [
        "regression"
      ],
      "repo_urls": [
        "https://github.com/pehlevan-group/s_transform"
      ],
      "source": "arXiv"
    },
    {
      "id": "2405.10916",
      "abstract": "We numerically investigate the nearly self-similar blowup of the generalized axisymmetric Navier--Stokes equations. First, we rigorously derive the axisymmetric Navier--Stokes equations with swirl in both odd and even dimensions, marking the first such derivation for dimensions greater than three. Building on this, we generalize the equations to arbitrary positive real-valued dimensions, preserving many known properties of the 3D axisymmetric Navier--Stokes equations. To address scaling instability, we dynamically vary the space dimension to balance advection scaling along the r and z directions. A major contribution of this work is the development of a novel two-scale dynamic rescaling formulation, leveraging the dimension as an additional degree of freedom. This approach enables us to demonstrate a one-scale self-similar blowup with solution-dependent viscosity. Notably, the self-similar profile satisfies the axisymmetric Navier-Stokes equations with constant viscosity. We observe that the effective dimension is approximately 3.188 and appears to converge toward 3 as background viscosity diminishes. Furthermore, we introduce a rescaled Navier--Stokes model derived by dynamically rescaling the axial velocity in 3D. This model retains essential properties of 3D Navier-Stokes. Our numerical study shows that this rescaled Navier--Stokes model with two constant viscosity coefficients exhibits a nearly self-similar blowup with maximum vorticity growth on the order of O(10^{30}).",
      "authors": [
        "Thomas Y. Hou"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Analysis of PDEs (math.AP)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-05-17T17:07:43+00:00",
          "link": "https://arxiv.org/abs/2405.10916v1",
          "size": "7595kb",
          "version": "v1"
        },
        {
          "date": "2024-07-23T05:27:55+00:00",
          "link": "https://arxiv.org/abs/2405.10916v2",
          "size": "7671kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T21:38:53+00:00",
          "link": "https://arxiv.org/abs/2405.10916v3",
          "size": "6062kb",
          "version": "v3"
        }
      ],
      "title": "Nearly self-similar blowup of generalized axisymmetric Navier-Stokes equations",
      "links": {
        "Abstract": "https://arxiv.org/abs/2405.10916",
        "HTML": "https://arxiv.org/html/2405.10916v3",
        "PDF": "https://arxiv.org/pdf/2405.10916"
      },
      "source": "arXiv"
    },
    {
      "id": "2406.06231",
      "abstract": "We develop both theory and algorithms to analyze privatized data in the unbounded differential privacy(DP), where even the sample size is considered a sensitive quantity that requires privacy protection. We show that the distance between the sampling distributions under unbounded DP and bounded DP goes to zero as the sample size $n$ goes to infinity, provided that the noise used to privatize $n$ is at an appropriate rate; we also establish that Approximate Bayesian Computation (ABC)-type posterior distributions converge under similar assumptions. We further give asymptotic results in the regime where the privacy budget for $n$ goes to zero, establishing similarity of sampling distributions as well as showing that the MLE in the unbounded setting converges to the bounded-DP MLE. In order to facilitate valid, finite-sample Bayesian inference on privatized data in the unbounded DP setting, we propose a reversible jump MCMC algorithm which extends the data augmentation MCMC of Ju et al. (2022). We also propose a Monte Carlo EM algorithm to compute the MLE from privatized data in both bounded and unbounded DP. We apply our methodology to analyze a linear regression model as well as a 2019 American Time Use Survey Microdata File which we model using a Dirichlet distribution.",
      "authors": [
        "Jordan Awan",
        "Andres Felipe Barrientos",
        "Nianqiao Ju"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Statistics Theory (math.ST)",
        "Cryptography and Security (cs.CR)",
        "Computation (stat.CO)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-10T13:03:20+00:00",
          "link": "https://arxiv.org/abs/2406.06231v1",
          "size": "297kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T14:04:25+00:00",
          "link": "https://arxiv.org/abs/2406.06231v2",
          "size": "340kb",
          "version": "v2"
        }
      ],
      "title": "Statistical Inference for Privatized Data with Unknown Sample Size",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.06231",
        "HTML": "https://arxiv.org/html/2406.06231v2",
        "PDF": "https://arxiv.org/pdf/2406.06231"
      },
      "repo_urls": [
        "https://github.com/anfebar/Statistical-Inference-for-Privatized-Data-with-Unknown-Sample-Size"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.06802",
      "abstract": "Motivated by the concept of satisficing in decision-making, we consider the problem of satisficing regret minimization in bandit optimization. In this setting, the learner aims at selecting satisficing arms (arms with mean reward exceeding a certain threshold value) as frequently as possible. The performance is measured by satisficing regret, which is the cumulative deficit of the chosen arm's mean reward compared to the threshold. We propose SELECT, a general algorithmic template for Satisficing REgret Minimization via SampLing and LowEr Confidence bound Testing, that attains constant expected satisficing regret for a wide variety of bandit optimization problems in the realizable case (i.e., a satisficing arm exists). As a complement, SELECT also enjoys the same (standard) regret guarantee as the oracle in the non-realizable case. To further ensure stability of the algorithm, we introduce SELECT-LITE that achieves a light-tailed satisficing regret distribution plus a constant expected satisficing regret in the realizable case and a sub-linear expected (standard) regret in the non-realizable case. Notably, SELECT-LITE can operate on learning oracles with heavy-tailed (standard) regret distribution. More importantly, our results reveal the surprising compatibility between constant expected satisficing regret and light-tailed satisficing regret distribution, which is in sharp contrast to the case of (standard) regret. Finally, we conduct numerical experiments to validate the performance of SELECT and SELECT-LITE on both synthetic datasets and a real-world dynamic pricing case study.",
      "authors": [
        "Qing Feng",
        "Tianyi Ma",
        "Ruihao Zhu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-10T21:15:28+00:00",
          "link": "https://arxiv.org/abs/2406.06802v1",
          "size": "389kb",
          "version": "v1"
        },
        {
          "date": "2025-02-17T21:22:54+00:00",
          "link": "https://arxiv.org/abs/2406.06802v2",
          "size": "546kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T21:03:28+00:00",
          "link": "https://arxiv.org/abs/2406.06802v3",
          "size": "1044kb",
          "version": "v3"
        }
      ],
      "title": "Satisficing Regret Minimization in Bandits: Constant Rate and Light-Tailed Distribution",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.06802",
        "HTML": "https://arxiv.org/html/2406.06802v3",
        "PDF": "https://arxiv.org/pdf/2406.06802"
      },
      "tasks": [
        "Decision Making"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.08855",
      "abstract": "Pediatric central nervous system tumors are the leading cause of cancer-related deaths in children. The five-year survival rate for high-grade glioma in children is less than 20%. The development of new treatments is dependent upon multi-institutional collaborative clinical trials requiring reproducible and accurate centralized response assessment. We present the results of the BraTS-PEDs 2023 challenge, the first Brain Tumor Segmentation (BraTS) challenge focused on pediatric brain tumors. This challenge utilized data acquired from multiple international consortia dedicated to pediatric neuro-oncology and clinical trials. BraTS-PEDs 2023 aimed to evaluate volumetric segmentation algorithms for pediatric brain gliomas from magnetic resonance imaging using standardized quantitative performance evaluation metrics employed across the BraTS 2023 challenges. The top-performing AI approaches for pediatric tumor analysis included ensembles of nnU-Net and Swin UNETR, Auto3DSeg, or nnU-Net with a self-supervised framework. The BraTSPEDs 2023 challenge fostered collaboration between clinicians (neuro-oncologists, neuroradiologists) and AI/imaging scientists, promoting faster data sharing and the development of automated volumetric analysis techniques. These advancements could significantly benefit clinical trials and improve the care of children with brain tumors.",
      "authors": [
        "Anahita Fathi Kazerooni",
        "Nastaran Khalili",
        "Xinyang Liu",
        "Debanjan Haldar",
        "Zhifan Jiang",
        "Anna Zapaishchykova",
        "Julija Pavaine",
        "Lubdha M. Shah",
        "Blaise V. Jones",
        "Nakul Sheth",
        "Sanjay P. Prabhu",
        "Aaron S. McAllister",
        "Wenxin Tu",
        "Khanak K. Nandolia",
        "Andres F. Rodriguez",
        "Ibraheem Salman Shaikh",
        "Mariana Sanchez Montano",
        "Hollie Anne Lai",
        "Maruf Adewole",
        "Jake Albrecht",
        "Udunna Anazodo",
        "Hannah Anderson",
        "Syed Muhammed Anwar",
        "Alejandro Aristizabal",
        "Sina Bagheri",
        "Ujjwal Baid",
        "Timothy Bergquist",
        "Austin J. Borja",
        "Evan Calabrese",
        "Verena Chung",
        "Gian-Marco Conte",
        "James Eddy",
        "Ivan Ezhov",
        "Ariana M. Familiar",
        "Keyvan Farahani",
        "Deep Gandhi",
        "Anurag Gottipati",
        "Shuvanjan Haldar",
        "Juan Eugenio Iglesias",
        "Anastasia Janas",
        "Elaine Elaine",
        "Alexandros Karargyris",
        "Hasan Kassem",
        "Neda Khalili",
        "Florian Kofler",
        "Dominic LaBella",
        "Koen Van Leemput",
        "Hongwei B. Li",
        "Nazanin Maleki",
        "Zeke Meier",
        "Bjoern Menze",
        "Ahmed W. Moawad",
        "Sarthak Pati",
        "Marie Piraud",
        "Tina Poussaint",
        "Zachary J. Reitman",
        "Jeffrey D. Rudie",
        "Rachit Saluja",
        "MIcah Sheller",
        "Russell Takeshi Shinohara",
        "Karthik Viswanathan",
        "Chunhao Wang",
        "Benedikt Wiestler",
        "Walter F. Wiggins",
        "Christos Davatzikos",
        "Phillip B. Storm",
        "Miriam Bornhorst",
        "Roger Packer",
        "Trent Hummel",
        "Peter de Blank",
        "Lindsey Hoffman",
        "Mariam Aboian",
        "Ali Nabavizadeh",
        "Jeffrey B. Ware",
        "Benjamin H. Kann",
        "Brian Rood",
        "Adam Resnick",
        "Spyridon Bakas",
        "Arastoo Vossough",
        "Marius George Linguraru"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-11T20:35:32+00:00",
          "link": "https://arxiv.org/abs/2407.08855v1",
          "size": "2996kb",
          "version": "v1"
        },
        {
          "date": "2024-07-16T20:52:45+00:00",
          "link": "https://arxiv.org/abs/2407.08855v2",
          "size": "3002kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T14:31:12+00:00",
          "link": "https://arxiv.org/abs/2407.08855v3",
          "size": "1430kb",
          "version": "v3"
        }
      ],
      "title": "BraTS-PEDs: Results of the Multi-Consortium International Pediatric Brain Tumor Segmentation Challenge 2023",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.08855",
        "HTML": "https://arxiv.org/html/2407.08855v3",
        "PDF": "https://arxiv.org/pdf/2407.08855"
      },
      "tasks": [
        "Brain Tumor Segmentation",
        "Tumor Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.15380",
      "abstract": "This study proposes a neural disparity field (NDF) that establishes an implicit, continuous representation of scene disparity based on a neural field and an iterative approach to address the inverse problem of NDF reconstruction from light-field data. NDF enables seamless and precise characterization of disparity variations in three-dimensional scenes and can discretize disparity at any arbitrary resolution, overcoming the limitations of traditional disparity maps that are prone to sampling errors and interpolation inaccuracies. The proposed NDF network architecture utilizes hash encoding combined with multilayer perceptrons to capture detailed disparities in texture levels, thereby enhancing its ability to represent the geometric information of complex scenes. By leveraging the spatial-angular consistency inherent in light-field data, a differentiable forward model to generate a central view image from the light-field data is developed. Based on the forward model, an optimization scheme for the inverse problem of NDF reconstruction using differentiable propagation operators is established. Furthermore, an iterative solution method is adopted to reconstruct the NDF in the optimization scheme, which does not require training datasets and applies to light-field data captured by various acquisition methods. Experimental results demonstrate that high-quality NDF can be reconstructed from light-field data using the proposed method. High-resolution disparity can be effectively recovered by NDF, demonstrating its capability for the implicit, continuous representation of scene disparities.",
      "authors": [
        "Ligen Shi",
        "Chang Liu",
        "Xing Zhao",
        "and Jun Qiu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-22T05:06:06+00:00",
          "link": "https://arxiv.org/abs/2407.15380v1",
          "size": "45416kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T02:27:07+00:00",
          "link": "https://arxiv.org/abs/2407.15380v2",
          "size": "7787kb",
          "version": "v2"
        }
      ],
      "title": "Iterative approach to reconstructing neural disparity fields from light-field data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.15380",
        "HTML": "https://arxiv.org/html/2407.15380v2",
        "PDF": "https://arxiv.org/pdf/2407.15380"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2407.20362",
      "abstract": "We introduce a family of symmetric convex bodies called generalized ellipsoids of degree $d$ (GE-$d$s), with ellipsoids corresponding to the case of $d=0$. Generalized ellipsoids (GEs) retain many geometric, algebraic, and algorithmic properties of ellipsoids. We show that the conditions that the parameters of a GE must satisfy can be checked in strongly polynomial time, and that one can search for GEs of a given degree by solving a semidefinite program whose size grows only linearly with dimension. We give an example of a GE which does not have a second-order cone representation, but show that every GE has a semidefinite representation whose size depends linearly on both its dimension and degree. In terms of expressiveness, we prove that for any integer $m\\geq 2$, every symmetric full-dimensional polytope with $2m$ facets and every intersection of $m$ co-centered ellipsoids can be represented exactly as a GE-$d$ with $d \\leq 2m-3$. Using this result, we show that every symmetric convex body can be approximated arbitrarily well by a GE-$d$ and we quantify the quality of the approximation as a function of the degree $d$. Finally, we present applications of GEs to several areas, such as time-varying portfolio optimization, stability analysis of switched linear systems, robust-to-dynamics optimization, and robust polynomial regression.",
      "authors": [
        "Amir Ali Ahmadi",
        "Abraar Chaudhry",
        "Cemil Dibek"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)",
        "Algebraic Geometry (math.AG)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-29T18:22:58+00:00",
          "link": "https://arxiv.org/abs/2407.20362v1",
          "size": "890kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T19:28:26+00:00",
          "link": "https://arxiv.org/abs/2407.20362v2",
          "size": "469kb",
          "version": "v2"
        }
      ],
      "title": "Generalized Ellipsoids",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.20362",
        "HTML": "https://arxiv.org/html/2407.20362v2",
        "PDF": "https://arxiv.org/pdf/2407.20362"
      },
      "source": "arXiv"
    },
    {
      "id": "2409.02231",
      "abstract": "Here we show that a general-purpose large language model (LLM) chatbot, Llama-3.1-8B-Instruct, can be transformed via supervised fine-tuning of engineered prompts into a chemical language model (CLM), SmileyLlama, for molecule generation. We benchmark SmileyLlama by comparing it to CLMs trained from scratch on large amounts of ChEMBL data for their ability to generate valid and novel drug-like molecules. We also use direct preference optimization to both improve SmileyLlama's adherence to a prompt and to generate molecules within the iMiner reinforcement learning framework to predict new drug molecules with optimized 3D conformations and high binding affinity to drug targets, illustrated with the SARS-Cov-2 Main Protease. This overall framework allows a LLM to speak directly as a CLM which can generate molecules with user-specified properties, rather than acting only as a chatbot with knowledge of chemistry or as a helpful virtual assistant. While our dataset and analyses are geared toward drug discovery, this general procedure can be extended to other chemical applications such as chemical synthesis.",
      "authors": [
        "Joseph M. Cavanagh",
        "Kunyang Sun",
        "Andrew Gritsevskiy",
        "Dorian Bagni",
        "Yingze Wang",
        "Thomas D. Bannister",
        "Teresa Head-Gordon"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Chemical Physics (physics.chem-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-03T18:59:20+00:00",
          "link": "https://arxiv.org/abs/2409.02231v1",
          "size": "3404kb",
          "version": "v1"
        },
        {
          "date": "2024-09-09T18:07:02+00:00",
          "link": "https://arxiv.org/abs/2409.02231v2",
          "size": "3407kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T10:36:58+00:00",
          "link": "https://arxiv.org/abs/2409.02231v3",
          "size": "3527kb",
          "version": "v3"
        }
      ],
      "title": "SmileyLlama: Modifying Large Language Models for Directed Chemical Space Exploration",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.02231",
        "HTML": "https://arxiv.org/html/2409.02231v3",
        "PDF": "https://arxiv.org/pdf/2409.02231"
      },
      "tasks": [
        "Chatbot",
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.04387",
      "abstract": "In differential privacy (DP) mechanisms, it can be beneficial to release ``redundant'' outputs, where some quantities can be estimated in multiple ways by combining different privatized values. Indeed, the DP 2020 Decennial Census products published by the U.S. Census Bureau consist of such redundant noisy counts. When redundancy is present, the DP output can be improved by enforcing self-consistency (i.e., estimators obtained using different noisy counts result in the same value), and we show that the minimum variance processing is a linear projection. However, standard projection algorithms require excessive computation and memory, making them impractical for large-scale applications such as the Decennial Census. We propose the Scalable Efficient Algorithm for Best Linear Unbiased Estimate (SEA BLUE), based on a two-step process of aggregation and differencing that 1) enforces self-consistency through a linear and unbiased procedure, 2) is computationally and memory efficient, 3) achieves the minimum variance solution under certain structural assumptions, and 4) is empirically shown to be robust to violations of these structural assumptions. We propose three methods of calculating confidence intervals from our estimates, under various assumptions. Finally, we apply SEA BLUE to two 2010 Census demonstration products, illustrating its scalability and validity.",
      "authors": [
        "Jordan Awan",
        "Adam Edwards",
        "Paul Bartholomew",
        "Andrew Sillers"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation (stat.CO)",
        "Cryptography and Security (cs.CR)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-06T16:27:34+00:00",
          "link": "https://arxiv.org/abs/2409.04387v1",
          "size": "480kb",
          "version": "v1"
        },
        {
          "date": "2024-09-24T18:39:26+00:00",
          "link": "https://arxiv.org/abs/2409.04387v2",
          "size": "480kb",
          "version": "v2"
        },
        {
          "date": "2024-10-29T15:49:09+00:00",
          "link": "https://arxiv.org/abs/2409.04387v3",
          "size": "480kb",
          "version": "v3"
        },
        {
          "date": "2025-04-29T12:48:51+00:00",
          "link": "https://arxiv.org/abs/2409.04387v4",
          "size": "596kb",
          "version": "v4"
        },
        {
          "date": "2025-06-30T12:55:44+00:00",
          "link": "https://arxiv.org/abs/2409.04387v5",
          "size": "367kb",
          "version": "v5"
        }
      ],
      "title": "Best Linear Unbiased Estimate from Privatized Contingency Tables",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.04387",
        "HTML": "https://arxiv.org/html/2409.04387v5",
        "PDF": "https://arxiv.org/pdf/2409.04387"
      },
      "repo_urls": [
        "https://github.com/JordanAwan/SeaBlue"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.05678",
      "abstract": "An \\textit{$(n,m)$-graph} $G$ is a graph having both arcs and edges, and its arcs (resp., edges) are labeled using one of the $n$ (resp., $m$) different symbols. An \\textit{$(n,m)$-complete graph} $G$ is an $(n,m)$-graph without loops or multiple edges in its underlying graph such that identifying any pair of vertices results in a loop or parallel adjacencies with distinct labels. We show that a planar $(n,m)$-complete graph cannot have more than $3(2n+m)^2+(2n+m)+1$ vertices, for all $(n,m) \\neq (0,1)$ and that the bound is tight. This positively settles a conjecture by Bensmail \\textit{et al.}~[Graphs and Combinatorics 2017].",
      "authors": [
        "Susobhan Bandopadhyay",
        "Sagnik Sen and S Taruni"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-09T14:45:12+00:00",
          "link": "https://arxiv.org/abs/2409.05678v1",
          "size": "20kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T17:02:24+00:00",
          "link": "https://arxiv.org/abs/2409.05678v2",
          "size": "20kb",
          "version": "v2"
        }
      ],
      "title": "Large planar $(n,m)$-cliques",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.05678",
        "HTML": "https://arxiv.org/html/2409.05678v2",
        "PDF": "https://arxiv.org/pdf/2409.05678"
      },
      "source": "arXiv"
    },
    {
      "id": "2410.00611",
      "abstract": "We study combinatorial properties of plateaued functions $F \\colon \\mathbb{F}_p^n \\rightarrow \\mathbb{F}_p^m$. All quadratic functions, bent functions and most known APN functions are plateaued, so many cryptographic primitives rely on plateaued functions as building blocks. The main focus of our study is the interplay of the Walsh transform and linearity of a plateaued function, its differential properties, and their value distributions, i.e., the sizes of image and preimage sets. In particular, we study the special case of ''almost balanced'' plateaued functions, which only have two nonzero preimage set sizes, generalizing for instance all monomial functions. We achieve several direct connections and (non)existence conditions for these functions, showing for instance that plateaued $d$-to-$1$ functions (and thus plateaued monomials) only exist for a very select choice of $d$, and we derive for all these functions their linearity as well as bounds on their differential uniformity. We also specifically study the Walsh transform of plateaued APN functions and their relation to their value distribution.",
      "authors": [
        "Lukas K\\\"olsch and Alexandr Polujan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-01T11:56:58+00:00",
          "link": "https://arxiv.org/abs/2410.00611v1",
          "size": "32kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T10:30:20+00:00",
          "link": "https://arxiv.org/abs/2410.00611v2",
          "size": "33kb",
          "version": "v2"
        }
      ],
      "title": "The combinatorial structure and value distributions of plateaued functions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.00611",
        "HTML": "https://arxiv.org/html/2410.00611v2",
        "PDF": "https://arxiv.org/pdf/2410.00611"
      },
      "source": "arXiv"
    },
    {
      "id": "2410.02979",
      "abstract": "In this paper, we prove that optimizability of any function F using Gradient Flow from all initializations implies a Poincar\\'e Inequality for Gibbs measures mu_{beta} = e^{-beta F}/Z at low temperature. In particular, under mild regularity assumptions on the convergence rate of Gradient Flow, we establish that mu_{beta} satisfies a Poincar\\'e Inequality with constant O(C'+1/beta) for beta >= Omega(d), where C' is the Poincar\\'e constant of mu_{beta} restricted to a neighborhood of the global minimizers of F. Under an additional mild condition on F, we show that mu_{beta} satisfies a Log-Sobolev Inequality with constant O(beta max(S, 1) max(C', 1)) where S denotes the second moment of mu_{beta}. Here asymptotic notation hides F-dependent parameters. At a high level, this establishes that optimizability via Gradient Flow from every initialization implies a Poincar\\'e and Log-Sobolev Inequality for the low-temperature Gibbs measure, which in turn imply sampling from all initializations.\n  Analogously, we establish that under the same assumptions, if F can be initialized from everywhere except some set S, then mu_{beta} satisfies a Weak Poincar\\'e Inequality with parameters (O(C'+1/beta), O(mu_{beta}(S))) for \\beta = Omega(d). At a high level, this shows while optimizability from 'most' initializations implies a Weak Poincar\\'e Inequality, which in turn implies sampling from suitable warm starts. Our regularity assumptions are mild and as a consequence, we show we can efficiently sample from several new natural and interesting classes of non-log-concave densities, an important setting with relatively few examples. As another corollary, we obtain efficient discrete-time sampling results for log-concave measures satisfying milder regularity conditions than smoothness, similar to Lehec (2023).",
      "authors": [
        "August Y. Chen",
        "Karthik Sridharan"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Statistics Theory (math.ST)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-03T20:40:54+00:00",
          "link": "https://arxiv.org/abs/2410.02979v1",
          "size": "42kb",
          "version": "v1"
        },
        {
          "date": "2024-11-17T20:31:40+00:00",
          "link": "https://arxiv.org/abs/2410.02979v2",
          "size": "58kb",
          "version": "v2"
        },
        {
          "date": "2025-03-04T18:48:15+00:00",
          "link": "https://arxiv.org/abs/2410.02979v3",
          "size": "78kb",
          "version": "v3"
        },
        {
          "date": "2025-06-30T17:22:16+00:00",
          "link": "https://arxiv.org/abs/2410.02979v4",
          "size": "76kb",
          "version": "v4"
        }
      ],
      "title": "Optimization, Isoperimetric Inequalities, and Sampling via Lyapunov Potentials",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.02979",
        "HTML": "https://arxiv.org/html/2410.02979v4",
        "PDF": "https://arxiv.org/pdf/2410.02979"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2410.12831",
      "abstract": "Medical imaging is crucial for diagnosing a patient's health condition, and accurate segmentation of these images is essential for isolating regions of interest to ensure precise diagnosis and treatment planning. Existing methods primarily rely on bounding boxes or point-based prompts, while few have explored text-related prompts, despite clinicians often describing their observations and instructions in natural language. To address this gap, we first propose a RAG-based free-form text prompt generator, that leverages the domain corpus to generate diverse and realistic descriptions. Then, we introduce FLanS, a novel medical image segmentation model that handles various free-form text prompts, including professional anatomy-informed queries, anatomy-agnostic position-driven queries, and anatomy-agnostic size-driven queries. Additionally, our model also incorporates a symmetry-aware canonicalization module to ensure consistent, accurate segmentations across varying scan orientations and reduce confusion between the anatomical position of an organ and its appearance in the scan. FLanS is trained on a large-scale dataset of over 100k medical images from 7 public datasets. Comprehensive experiments demonstrate the model's superior language understanding and segmentation precision, along with a deep comprehension of the relationship between them, outperforming SOTA baselines on both in-domain and out-of-domain datasets.",
      "authors": [
        "Longchao Da",
        "Rui Wang",
        "Xiaojian Xu",
        "Parminder Bhatia",
        "Taha Kass-Hout",
        "Hua Wei",
        "Cao Xiao"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-02T16:34:32+00:00",
          "link": "https://arxiv.org/abs/2410.12831v1",
          "size": "41900kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T09:44:10+00:00",
          "link": "https://arxiv.org/abs/2410.12831v2",
          "size": "13476kb",
          "version": "v2"
        }
      ],
      "title": "Segment as You Wish -- Free-Form Language-Based Segmentation for Medical Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.12831",
        "HTML": "https://arxiv.org/html/2410.12831v2",
        "PDF": "https://arxiv.org/pdf/2410.12831"
      },
      "tasks": [
        "Anatomy",
        "Form",
        "Image Segmentation",
        "Medical Image Segmentation",
        "Position",
        "RAG",
        "Segmentation",
        "Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.20073",
      "abstract": "Virtual staining of tissue offers a powerful tool for transforming label-free microscopy images of unstained tissue into equivalents of histochemically stained samples. This study presents a diffusion model-based super-resolution virtual staining approach utilizing a Brownian bridge process to enhance both the spatial resolution and fidelity of label-free virtual tissue staining, addressing the limitations of traditional deep learning-based methods. Our approach integrates novel sampling techniques into a diffusion model-based image inference process to significantly reduce the variance in the generated virtually stained images, resulting in more stable and accurate outputs. Blindly applied to lower-resolution auto-fluorescence images of label-free human lung tissue samples, the diffusion-based super-resolution virtual staining model consistently outperformed conventional approaches in resolution, structural similarity and perceptual accuracy, successfully achieving a super-resolution factor of 4-5x, increasing the output space-bandwidth product by 16-25-fold compared to the input label-free microscopy images. Diffusion-based super-resolved virtual tissue staining not only improves resolution and image quality but also enhances the reliability of virtual staining without traditional chemical staining, offering significant potential for clinical diagnostics.",
      "authors": [
        "Yijie Zhang",
        "Luzhe Huang",
        "Nir Pillar",
        "Yuzhu Li",
        "Hanlong Chen",
        "Aydogan Ozcan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Medical Physics (physics.med-ph)",
        "Optics (physics.optics)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-26T04:31:17+00:00",
          "link": "https://arxiv.org/abs/2410.20073v1",
          "size": "1536kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T16:15:48+00:00",
          "link": "https://arxiv.org/abs/2410.20073v2",
          "size": "2187kb",
          "version": "v2"
        }
      ],
      "title": "Pixel super-resolved virtual staining of label-free tissue using diffusion models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.20073",
        "PDF": "https://arxiv.org/pdf/2410.20073"
      },
      "tasks": [
        "Super-Resolution",
        "Virtual Staining"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.05853",
      "abstract": "We derive a fundamental trade-off between standard and adversarial risk in a rather general situation that formalizes the following simple intuition: \"If no (nearly) optimal predictor is smooth, adversarial robustness comes at the cost of accuracy.\" As a concrete example, we evaluate the derived trade-off in regression with polynomial ridge functions under mild regularity conditions. Generalizing our analysis of this example, we formulate a necessary condition under which adversarial robustness can be achieved without significant degradation of the accuracy. This necessary condition is expressed in terms of a quantity that resembles the Poincar\\'{e} constant of the data distribution.",
      "authors": [
        "Sohail Bahmani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-06T22:03:53+00:00",
          "link": "https://arxiv.org/abs/2411.05853v1",
          "size": "16kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T20:29:04+00:00",
          "link": "https://arxiv.org/abs/2411.05853v2",
          "size": "20kb",
          "version": "v2"
        }
      ],
      "title": "A Fundamental Accuracy--Robustness Trade-off in Regression and Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.05853",
        "HTML": "https://arxiv.org/html/2411.05853v2",
        "PDF": "https://arxiv.org/pdf/2411.05853"
      },
      "tasks": [
        "Adversarial Robustness",
        "regression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.15776",
      "abstract": "In this paper, we introduce the concept of self-amplifying structures for hypergraphs, positioning it as a key element for understanding propagation and internal reinforcement in complex systems. To quantify this phenomenon, we define the maximal amplification factor, a metric that captures how effectively a subhypergraph contributes to its own amplification. We then develop an optimization-based methodology to compute this measure. Building on this foundation, we tackle the problem of identifying the subhypergraph maximizing the amplification factor, formulating it as a mixed-integer nonlinear programming (MINLP) problem. To solve it efficiently, we propose an exact iterative algorithm with proven convergence guarantees. In addition, we report the results of extensive computational experiments on realistic synthetic instances, demonstrating both the relevance and effectiveness of the proposed approach. Finally, we present a case study on chemical reaction networks, including the Formose reaction and E. coli core metabolism, where our framework successfully identifies known and novel autocatalytic subnetworks, highlighting its practical relevance to systems chemistry and biology.",
      "authors": [
        "V\\'ictor Blanco and Gabriel Gonz\\'alez and Praful Gagrani"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Computational Engineering, Finance, and Science (cs.CE)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-20T10:45:57+00:00",
          "link": "https://arxiv.org/abs/2412.15776v1",
          "size": "4243kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T10:57:02+00:00",
          "link": "https://arxiv.org/abs/2412.15776v2",
          "size": "3679kb",
          "version": "v2"
        }
      ],
      "title": "Identifying Self-Amplifying Hypergraph Structures through Mathematical Optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.15776",
        "HTML": "https://arxiv.org/html/2412.15776v2",
        "PDF": "https://arxiv.org/pdf/2412.15776"
      },
      "source": "arXiv"
    },
    {
      "id": "2501.04712",
      "abstract": "Pressing is a fundamental defensive strategy in football, characterized by applying pressure on the ball owning team to regain possession. Despite its significance, existing metrics for measuring pressing often lack precision or comprehensive consideration of positional data, player movement and speed. This research introduces an innovative framework for quantifying pressing intensity, leveraging advancements in positional tracking data and components from Spearman's Pitch Control model. Our method integrates player velocities, movement directions, and reaction times to compute the time required for a defender to intercept an attacker or the ball. This time-to-intercept measure is then transformed into probabilistic values using a logistic function, enabling dynamic and intuitive analysis of pressing situations at the individual frame level. the model captures how every player's movement influences pressure on the field, offering actionable insights for coaches, analysts, and decision-makers. By providing a robust and intepretable metric, our approach facilitates the identification of pressing strategies, advanced situational analyses, and the derivation of metrics, advancing the analytical capabilities for modern football.",
      "authors": [
        "Joris Bekkers"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Applications (stat.AP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-30T14:42:00+00:00",
          "link": "https://arxiv.org/abs/2501.04712v1",
          "size": "2268kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T13:33:47+00:00",
          "link": "https://arxiv.org/abs/2501.04712v2",
          "size": "2269kb",
          "version": "v2"
        }
      ],
      "title": "Pressing Intensity: An Intuitive Measure for Pressing in Soccer",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.04712",
        "HTML": "https://arxiv.org/html/2501.04712v2",
        "PDF": "https://arxiv.org/pdf/2501.04712"
      },
      "tasks": [
        "Pitch control"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.06926",
      "abstract": "Long-term causal effects often must be estimated from short-term data due to limited follow-up in healthcare, economics, and online platforms. Markov Decision Processes (MDPs) provide a natural framework for capturing such long-term dynamics through sequences of states, actions, and rewards. Double Reinforcement Learning (DRL) enables efficient inference on policy values in MDPs, but nonparametric implementations require strong intertemporal overlap assumptions and often exhibit high variance and instability. We propose a semiparametric extension of DRL for efficient inference on linear functionals of the Q-function--such as policy values--in infinite-horizon, time-homogeneous MDPs. By imposing structural restrictions on the Q-function, our approach relaxes the strong overlap conditions required by nonparametric methods and improves statistical efficiency. Under model misspecification, our estimators target the functional of the best-approximating Q-function, with only second-order bias. We provide conditions for valid inference using sieve methods and data-driven model selection. A central challenge in DRL is the estimation of nuisance functions, such as density ratios, which often involve difficult minimax optimization. To address this, we introduce a novel plug-in estimator based on isotonic Bellman calibration, which combines fitted Q-iteration with an isotonic regression adjustment. The estimator is debiased without requiring estimation of additional nuisance functions and reduces high-dimensional overlap assumptions to a one-dimensional condition. Bellman calibration extends isotonic calibration--widely used in prediction and classification--to the MDP setting and may be of independent interest.",
      "authors": [
        "Lars van der Laan",
        "David Hubbard",
        "Allen Tran",
        "Nathan Kallus",
        "Aur\\'elien Bibaut"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-12T20:35:28+00:00",
          "link": "https://arxiv.org/abs/2501.06926v1",
          "size": "52kb",
          "version": "v1"
        },
        {
          "date": "2025-04-27T21:06:09+00:00",
          "link": "https://arxiv.org/abs/2501.06926v2",
          "size": "2687kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T16:30:42+00:00",
          "link": "https://arxiv.org/abs/2501.06926v3",
          "size": "400kb",
          "version": "v3"
        }
      ],
      "title": "Semiparametric Double Reinforcement Learning with Applications to Long-Term Causal Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06926",
        "HTML": "https://arxiv.org/html/2501.06926v3",
        "PDF": "https://arxiv.org/pdf/2501.06926"
      },
      "tasks": [
        "Causal Inference",
        "Dimensionality Reduction",
        "Domain Adaptation",
        "Model Selection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.08036",
      "abstract": "Fault tolerance of quantum protocols require on-par contributions from error-correcting codes and its suitable decoders. One of the most explored error-correcting codes is the family of Quantum Low-Density Parity Check (QLDPC) codes. Although faster than many of the reported decoders for QLDPC codes, iterative decoders fails to produce suitable success rates due to the colossal degeneracy and short cycles intrinsic to these codes. We present a strategy to improve the performance of the iterative decoders based on a collaborative way to use the message passing of the iterative decoders and stabilizer check node removal from the quantum code's Tanner graph. We particularly introduce a notion of qubit separation, which gives us a metric to analyze and improve the min-sum Belief Propagation (BP) based iterative decoder's performance towards harmful configurations of QLDPC codes. We further show that an integration of information measurements (IM) for qubits and it's adjacent stabilizer checks, can be exploited to extract far better performing results from the collaborative decoding architecture compared to its classical predecessor. We analyze the performance of the proposed collaborative decoding architecture, in the context of Generalized Hypergraph Product (GHP) codes. We discuss that the collaborative decoding architecture overcomes iterative decoding failures regarding the harmful trapping set configurations by increasing the separation of trapped qubits without incurring any significant overhead.",
      "authors": [
        "Mainak Bhattacharyya and Ankur Raina"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-14T11:41:45+00:00",
          "link": "https://arxiv.org/abs/2501.08036v1",
          "size": "551kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T06:15:28+00:00",
          "link": "https://arxiv.org/abs/2501.08036v2",
          "size": "958kb",
          "version": "v2"
        }
      ],
      "title": "Decoding Quantum LDPC Codes using Collaborative Check Node Removal",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.08036",
        "HTML": "https://arxiv.org/html/2501.08036v2",
        "PDF": "https://arxiv.org/pdf/2501.08036"
      },
      "source": "arXiv"
    },
    {
      "id": "2501.15690",
      "abstract": "High Mountain Asia (HMA) holds the highest concentration of frozen water outside the polar regions, serving as a crucial water source for more than 1.9 billion people. Precipitation represents the largest source of uncertainty for future hydrological modelling in this area. In this study, we propose a probabilistic machine learning framework to combine monthly precipitation from 13 regional climate models developed under the Coordinated Regional Downscaling Experiment (CORDEX) over HMA via a mixture of experts (MoE). This approach accounts for seasonal and spatial biases within the models, enabling the prediction of more faithful precipitation distributions. The MoE is trained and validated against gridded historical precipitation data, yielding 32% improvement over an equally-weighted average and 254% improvement over choosing any single ensemble member. This approach is then used to generate precipitation projections for the near future (2036-2065) and far future (2066-2095) under RCP4.5 and RCP8.5 scenarios. Compared to previous estimates, the MoE projects wetter summers but drier winters over the western Himalayas and Karakoram and wetter winters over the Tibetan Plateau, Hengduan Shan, and South East Tibet.",
      "authors": [
        "Kenza Tazi",
        "Sun Woo P. Kim",
        "Marc Girona-Mata and Richard E. Turner"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Atmospheric and Oceanic Physics (physics.ao-ph)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-26T22:35:24+00:00",
          "link": "https://arxiv.org/abs/2501.15690v1",
          "size": "9638kb",
          "version": "v1"
        },
        {
          "date": "2025-02-21T17:33:00+00:00",
          "link": "https://arxiv.org/abs/2501.15690v2",
          "size": "9700kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T16:44:56+00:00",
          "link": "https://arxiv.org/abs/2501.15690v3",
          "size": "10348kb",
          "version": "v3"
        }
      ],
      "title": "Refined climatologies of future precipitation over High Mountain Asia using probabilistic ensemble learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.15690",
        "HTML": "https://arxiv.org/html/2501.15690v3",
        "PDF": "https://arxiv.org/pdf/2501.15690"
      },
      "tasks": [
        "Ensemble Learning"
      ],
      "repo_urls": [
        "https://github.com/kenzaxtazi/bcm4rcm"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.15828",
      "abstract": "Recovery rate prediction plays a pivotal role in bond investment strategies by enhancing risk assessment, optimizing portfolio allocation, improving pricing accuracy, and supporting effective credit risk management. However, accurate forecasting remains challenging due to complex nonlinear dependencies, high-dimensional feature spaces, and limited sample sizes-conditions under which classical machine learning models are prone to overfitting. We propose a hybrid Quantum Machine Learning (QML) model with Amplitude Encoding, leveraging the unitarity constraint of Parametrized Quantum Circuits (PQC) and the exponential data compression capability of qubits. We evaluate the model on a global recovery rate dataset comprising 1,725 observations and 256 features from 1996 to 2023. Our hybrid method significantly outperforms both classical neural networks and QML models using Angle Encoding, achieving a lower Root Mean Squared Error (RMSE) of 0.228, compared to 0.246 and 0.242, respectively. It also performs competitively with ensemble tree methods such as XGBoost. While practical implementation challenges remain for Noisy Intermediate-Scale Quantum (NISQ) hardware, our quantum simulation and preliminary results on noisy simulators demonstrate the promise of hybrid quantum-classical architectures in enhancing the accuracy and robustness of recovery rate forecasting. These findings illustrate the potential of quantum machine learning in shaping the future of credit risk prediction.",
      "authors": [
        "Ying Chen",
        "Paul Griffin",
        "Paolo Recchia",
        "Lei Zhou",
        "Hongrui Zhang"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computational Finance (q-fin.CP)",
        "Machine Learning (cs.LG)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-27T07:27:23+00:00",
          "link": "https://arxiv.org/abs/2501.15828v1",
          "size": "518kb",
          "version": "v1"
        },
        {
          "date": "2025-02-03T12:09:41+00:00",
          "link": "https://arxiv.org/abs/2501.15828v2",
          "size": "519kb",
          "version": "v2"
        },
        {
          "date": "2025-02-04T07:02:14+00:00",
          "link": "https://arxiv.org/abs/2501.15828v3",
          "size": "519kb",
          "version": "v3"
        },
        {
          "date": "2025-02-05T04:27:28+00:00",
          "link": "https://arxiv.org/abs/2501.15828v4",
          "size": "519kb",
          "version": "v4"
        },
        {
          "date": "2025-06-30T13:24:59+00:00",
          "link": "https://arxiv.org/abs/2501.15828v5",
          "size": "1138kb",
          "version": "v5"
        }
      ],
      "title": "Hybrid Quantum Neural Networks with Amplitude Encoding: Advancing Recovery Rate Predictions",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.15828",
        "HTML": "https://arxiv.org/html/2501.15828v5",
        "PDF": "https://arxiv.org/pdf/2501.15828"
      },
      "tasks": [
        "Data Compression",
        "Management",
        "Quantum Machine Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.04555",
      "abstract": "The Partial Information Decomposition (PID) framework has emerged as a powerful tool for analyzing high-order interdependencies in complex network systems. However, its application to dynamic processes remains challenging due to the implicit assumption of memorylessness, which often falls in real-world scenarios. In this work, we introduce the framework of Partial Information Rate Decomposition (PIRD) that extends PID to random processes with temporal correlations. By leveraging mutual information rate (MIR) instead of mutual information (MI), our approach decomposes the dynamic information shared by multivariate random processes into unique, redundant, and synergistic contributions obtained aggregating information rate atoms in a principled manner. To solve PIRD, we define a pointwise redundancy rate function based on the minimum MI principle applied locally in the frequency-domain representation of the processes. The framework is validated in benchmark simulations of Gaussian systems, demonstrating its advantages over traditional PID in capturing temporal correlations and showing how the spectral representation may reveal scale-specific higher-order interactions that are obscured in the time domain. Furthermore, we apply PIRD to a physiological network comprising cerebrovascular and cardiovascular variables, revealing frequency-dependent redundant information exchange during a protocol of postural stress. Our results highlight the necessity of accounting for the full temporal statistical structure and spectral content of vector random processes to meaningfully perform information decomposition in network systems with dynamic behavior such as those typically encountered in neuroscience and physiology.",
      "authors": [
        "Laura Sparacino",
        "Gorana Mijatovic",
        "Yuri Antonacci",
        "Leonardo Ricci",
        "Daniele Marinazzo",
        "Sebastiano Stramaglia",
        "Luca Faes"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Methodology (stat.ME)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-06T23:06:49+00:00",
          "link": "https://arxiv.org/abs/2502.04555v1",
          "size": "685kb",
          "version": "v1"
        },
        {
          "date": "2025-02-20T14:15:51+00:00",
          "link": "https://arxiv.org/abs/2502.04555v2",
          "size": "685kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T08:56:31+00:00",
          "link": "https://arxiv.org/abs/2502.04555v3",
          "size": "740kb",
          "version": "v3"
        }
      ],
      "title": "Decomposing Multivariate Information Rates in Networks of Random Processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.04555",
        "HTML": "https://arxiv.org/html/2502.04555v3",
        "PDF": "https://arxiv.org/pdf/2502.04555"
      },
      "source": "arXiv"
    },
    {
      "id": "2502.05676",
      "abstract": "Ensuring model calibration is critical for reliable prediction, yet popular distribution-free methods such as histogram binning and isotonic regression offer only asymptotic guarantees. We introduce a unified framework for Venn and Venn-Abers calibration that extends Vovk's approach beyond binary classification to a broad class of prediction problems defined by generic loss functions. Our method transforms any perfectly in-sample calibrated predictor into a set-valued predictor that, in finite samples, outputs at least one marginally calibrated point prediction. These set predictions shrink asymptotically and converge to a conditionally calibrated prediction, capturing epistemic uncertainty. We further propose Venn multicalibration, a new approach for achieving finite-sample calibration across subpopulations. For quantile loss, our framework recovers group-conditional and multicalibrated conformal prediction as special cases and yields novel prediction intervals with quantile-conditional coverage.",
      "authors": [
        "Lars van der Laan",
        "Ahmed Alaa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-08T19:52:59+00:00",
          "link": "https://arxiv.org/abs/2502.05676v1",
          "size": "477kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T18:41:16+00:00",
          "link": "https://arxiv.org/abs/2502.05676v2",
          "size": "226kb",
          "version": "v2"
        }
      ],
      "title": "Generalized Venn and Venn-Abers Calibration with Applications in Conformal Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.05676",
        "HTML": "https://arxiv.org/html/2502.05676v2",
        "PDF": "https://arxiv.org/pdf/2502.05676"
      },
      "tasks": [
        "Binary Classification",
        "Conformal Prediction",
        "Prediction",
        "Prediction Intervals"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.00387",
      "abstract": "Existing contextual multi-armed bandit (MAB) algorithms fail to effectively capture both long-term trends and local patterns across all arms, leading to suboptimal performance in environments with rapidly changing reward structures. They also rely on static exploration rates, which do not dynamically adjust to changing conditions. To overcome these limitations, we propose LNUCB-TA, a hybrid bandit model integrating a novel nonlinear component (adaptive k-Nearest Neighbors (k-NN)) for reducing time complexity, alongside a global-and-local attention-based exploration mechanism. Our approach uniquely combines linear and nonlinear estimation techniques, with the nonlinear module dynamically adjusting k based on reward variance to enhance spatiotemporal pattern recognition. This reduces the likelihood of selecting suboptimal arms while improving reward estimation accuracy and computational efficiency. The attention-based mechanism ranks arms by past performance and selection frequency, dynamically adjusting exploration and exploitation in real time without requiring manual tuning of exploration rates. By integrating global attention (assessing all arms collectively) and local attention (focusing on individual arms), LNUCB-TA efficiently adapts to temporal and spatial complexities. Empirical results show LNUCB-TA significantly outperforms state-of-the-art linear, nonlinear, and hybrid bandits in cumulative and mean reward, convergence, and robustness across different exploration rates. Theoretical analysis further confirms its reliability with a sub-linear regret bound.",
      "authors": [
        "Hamed Khosravi",
        "Mohammad Reza Shafie",
        "Ahmed Shoyeb Raihan",
        "Srinjoy Das",
        "Imtiaz Ahmed"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-01T07:24:54+00:00",
          "link": "https://arxiv.org/abs/2503.00387v1",
          "size": "36614kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T22:23:20+00:00",
          "link": "https://arxiv.org/abs/2503.00387v2",
          "size": "23190kb",
          "version": "v2"
        }
      ],
      "title": "LNUCB-TA: Linear-nonlinear Hybrid Bandit Learning with Temporal Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00387",
        "HTML": "https://arxiv.org/html/2503.00387v2",
        "PDF": "https://arxiv.org/pdf/2503.00387"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.03357",
      "abstract": "Given a max-plus linear system and a semimodule, the problem of computing the maximal controlled invariant subsemimodule is still open to this day. In this paper, we consider this problem for the specific class of fully actuated systems and constraints in the form of precedence semimodules. The assumption of full actuation corresponds to the existence of an input for each component of the system state. A precedence semimodule is the set of solutions of inequalities typically used to represent time-window constraints. We prove that, in this setting, it is possible to (i) compute the maximal controlled invariant subsemimodule and (ii) decide the convergence of a fixed-point algorithm introduced by R.D. Katz in strongly polynomial time.",
      "authors": [
        "Davide Zorzenon",
        "J\\\"org Raisch"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-05T10:38:29+00:00",
          "link": "https://arxiv.org/abs/2503.03357v1",
          "size": "61kb",
          "version": "v1"
        },
        {
          "date": "2025-03-17T10:53:34+00:00",
          "link": "https://arxiv.org/abs/2503.03357v2",
          "size": "61kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T13:34:05+00:00",
          "link": "https://arxiv.org/abs/2503.03357v3",
          "size": "60kb",
          "version": "v3"
        }
      ],
      "title": "Controlled Invariance in Fully Actuated Max-plus Linear Systems with Precedence Semimodules",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.03357",
        "HTML": "https://arxiv.org/html/2503.03357v3",
        "PDF": "https://arxiv.org/pdf/2503.03357"
      },
      "source": "arXiv"
    },
    {
      "id": "2503.05672",
      "abstract": "The latent variable proximal point (LVPP) algorithm is a framework for solving infinite-dimensional variational problems with pointwise inequality constraints. The algorithm is a saddle point reformulation of the Bregman proximal point algorithm. At the continuous level, the two formulations are equivalent, but the saddle point formulation is more amenable to discretization because it introduces a structure-preserving transformation between a latent function space and the feasible set. Working in this latent space is much more convenient for enforcing inequality constraints than the feasible set, as discretizations can employ general linear combinations of suitable basis functions, and nonlinear solvers can involve general additive updates. LVPP yields numerical methods with observed mesh-independence for obstacle problems, contact, fracture, plasticity, and others besides; in many cases, for the first time. The framework also extends to more complex constraints, providing means to enforce convexity in the Monge--Amp\\`ere equation and handling quasi-variational inequalities, where the underlying constraint depends implicitly on the unknown solution. In this paper, we describe the LVPP algorithm in a general form and apply it to ten problems from across mathematics.",
      "authors": [
        "J{\\o}rgen S. Dokken",
        "Patrick E. Farrell",
        "Brendan Keith",
        "Ioannis P. A. Papadopoulos",
        "Thomas M. Surowiec"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-07T18:32:05+00:00",
          "link": "https://arxiv.org/abs/2503.05672v1",
          "size": "16560kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T13:44:25+00:00",
          "link": "https://arxiv.org/abs/2503.05672v2",
          "size": "15821kb",
          "version": "v2"
        }
      ],
      "title": "The latent variable proximal point algorithm for variational problems with inequality constraints",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05672",
        "PDF": "https://arxiv.org/pdf/2503.05672"
      },
      "repo_urls": [
        "https://github.com/methods-group/proximalgalerkin"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.10138",
      "abstract": "In this paper, we study when we might expect the optimization curve induced by gradient descent to be \\emph{convex} -- precluding, for example, an initial plateau followed by a sharp decrease, making it difficult to decide when optimization should stop. Although such undesirable behavior can certainly occur when optimizing general functions, might it also occur in the benign and well-studied case of smooth convex functions? As far as we know, this question has not been tackled in previous work. We show, perhaps surprisingly, that the answer crucially depends on the choice of the step size. In particular, for the range of step sizes which are known to result in monotonic convergence to an optimal value, we characterize a regime where the optimization curve will be provably convex, and a regime where the curve can be non-convex. We also extend our results to gradient flow, and to the closely-related but different question of whether the gradient norm decreases monotonically.",
      "authors": [
        "Guy Barzilai",
        "Ohad Shamir and Moslem Zamani"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-13T07:56:18+00:00",
          "link": "https://arxiv.org/abs/2503.10138v1",
          "size": "26kb",
          "version": "v1"
        },
        {
          "date": "2025-04-02T11:18:07+00:00",
          "link": "https://arxiv.org/abs/2503.10138v2",
          "size": "27kb",
          "version": "v2"
        },
        {
          "date": "2025-06-28T20:25:33+00:00",
          "link": "https://arxiv.org/abs/2503.10138v3",
          "size": "39kb",
          "version": "v3"
        }
      ],
      "title": "Are Convex Optimization Curves Convex?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.10138",
        "HTML": "https://arxiv.org/html/2503.10138v3",
        "PDF": "https://arxiv.org/pdf/2503.10138"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.10984",
      "abstract": "The problem of the priors is well known: it concerns the challenge of identifying norms that govern one's prior credences. I argue that a key to addressing this problem lies in considering what I call the problem of the posteriors -- the challenge of identifying norms that directly govern one's posterior credences, which backward induce some norms on the priors via the diachronic requirement of conditionalization. This forward-looking approach can be summarized as: Think ahead, work backward. Although this idea can be traced to Freedman (1963), Carnap (1963), and Shimony (1970), I believe that it has not received enough attention. In this paper, I initiate a systematic defense of forward-looking Bayesianism, addressing potential objections from more traditional views (both subjectivist and objectivist). I also develop a specific approach to forward-looking Bayesianism -- one that values the convergence of posterior credences to the truth, and treats it as a fundamental rather than derived norm. This approach, called convergentist Bayesianism, is argued to be crucial for a Bayesian foundation of Ockham's razor in statistics and machine learning.",
      "authors": [
        "Hanti Lin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Other Statistics (stat.OT)",
        "Artificial Intelligence (cs.AI)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-14T01:06:34+00:00",
          "link": "https://arxiv.org/abs/2503.10984v1",
          "size": "471kb",
          "version": "v1"
        },
        {
          "date": "2025-05-14T03:37:53+00:00",
          "link": "https://arxiv.org/abs/2503.10984v2",
          "size": "316kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T03:48:43+00:00",
          "link": "https://arxiv.org/abs/2503.10984v3",
          "size": "317kb",
          "version": "v3"
        }
      ],
      "title": "The Problem of the Priors, or Posteriors?",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.10984",
        "HTML": "https://arxiv.org/html/2503.10984v3",
        "PDF": "https://arxiv.org/pdf/2503.10984"
      },
      "tasks": [
        "Philosophy"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.13791",
      "abstract": "We present a Representer Theorem result for a large class of weak formulation problems. We provide examples of applications of our formulation both in traditional machine learning and numerical methods as well as in new and emerging techniques. Finally we apply our formulation to generalize the multivariate occupation kernel (MOCK) method for learning dynamical systems from data proposing the more general Riesz Occupation Kernel (ROCK) method. Our generalized methods are both more computationally efficient and performant on most of the benchmarks we test against.",
      "authors": [
        "Victor Rielly",
        "Kamel Lahouel",
        "Chau Nguyen",
        "Anthony Kolshorn",
        "Nicholas Fisher",
        "Bruno Jedynak"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-18T00:43:13+00:00",
          "link": "https://arxiv.org/abs/2503.13791v1",
          "size": "1935kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T15:56:08+00:00",
          "link": "https://arxiv.org/abs/2503.13791v2",
          "size": "642kb",
          "version": "v2"
        }
      ],
      "title": "ROCK: A variational formulation for occupation kernel methods in Reproducing Kernel Hilbert Spaces",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.13791",
        "HTML": "https://arxiv.org/html/2503.13791v2",
        "PDF": "https://arxiv.org/pdf/2503.13791"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2503.14055",
      "abstract": "In this paper, we design a novel distributed learning algorithm using stochastic compressed communications. In detail, we pursue a modular approach, merging ADMM and a gradient-based approach, benefiting from the robustness of the former and the computational efficiency of the latter. Additionally, we integrate a stochastic integral action (error feedback) enabling almost sure rejection of the compression error. We analyze the resulting method in nonconvex scenarios and guarantee almost sure asymptotic convergence to the set of stationary points of the problem. This result is obtained using system-theoretic tools based on stochastic timescale separation. We corroborate our findings with numerical simulations in nonconvex classification.",
      "authors": [
        "Guido Carnevale",
        "Nicola Bastianello"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Machine Learning (cs.LG)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-18T09:16:51+00:00",
          "link": "https://arxiv.org/abs/2503.14055v1",
          "size": "302kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T09:38:21+00:00",
          "link": "https://arxiv.org/abs/2503.14055v2",
          "size": "750kb",
          "version": "v2"
        }
      ],
      "title": "Modular Distributed Nonconvex Learning with Error Feedback",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.14055",
        "HTML": "https://arxiv.org/html/2503.14055v2",
        "PDF": "https://arxiv.org/pdf/2503.14055"
      },
      "tasks": [
        "Computational Efficiency"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.14571",
      "abstract": "Genomic studies, including CRISPR-based PerturbSeq analyses, face a vast hypothesis space, while gene perturbations remain costly and time-consuming. Gene expression models based on graph neural networks are trained to predict the outcomes of gene perturbations to facilitate such experiments. Active learning methods are often employed to train these models due to the cost of the genomic experiments required to build the training set. However, poor model initialization in active learning can result in suboptimal early selections, wasting time and valuable resources. While typical active learning mitigates this issue over many iterations, the limited number of experimental cycles in genomic studies exacerbates the risk. To this end, we propose graph-based data filtering as an alternative. Unlike active learning, data filtering selects the gene perturbations before training, meaning it is free of bias due to random initialization and initial random selection. Moreover, reducing the iterations between the wet lab and the model provides several operational advantages resulting in significant acceleration. The proposed methods are motivated by theoretical studies of graph neural network generalization. The criteria are defined over the input graph and are optimized with submodular maximization. We compare them empirically to baselines and active learning methods that are state-of-the-art. The results demonstrate that graph-based data filtering achieves comparable accuracy while alleviating the aforementioned risks.",
      "authors": [
        "George Panagopoulos",
        "Johannes F. Lutzeyer",
        "Sofiane Ennadir",
        "Michalis Vazirgiannis",
        "and Jun Pang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantitative Methods (q-bio.QM)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-18T12:52:03+00:00",
          "link": "https://arxiv.org/abs/2503.14571v1",
          "size": "183kb",
          "version": "v1"
        },
        {
          "date": "2025-03-28T12:45:21+00:00",
          "link": "https://arxiv.org/abs/2503.14571v2",
          "size": "189kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T19:29:14+00:00",
          "link": "https://arxiv.org/abs/2503.14571v3",
          "size": "322kb",
          "version": "v3"
        }
      ],
      "title": "Data Filtering for Genetic Perturbation Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.14571",
        "HTML": "https://arxiv.org/html/2503.14571v3",
        "PDF": "https://arxiv.org/pdf/2503.14571"
      },
      "tasks": [
        "Active Learning",
        "Graph Neural Network"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.17786",
      "abstract": "Despite the plethora of AI-based algorithms developed for anomaly detection in radiology, subsequent integration into clinical setting is rarely evaluated. In this work, we assess the applicability and utility of an AI-based model for brain aneurysm detection comparing the performance of two readers with different levels of experience (2 and 13 years). We aim to answer the following questions: 1) Do the readers improve their performance when assisted by the AI algorithm? 2) How much does the AI algorithm impact routine clinical workflow? We reuse and enlarge our open-access, Time-Of-Flight Magnetic Resonance Angiography dataset (N=460). We use 360 subjects for training/validating our algorithm and 100 as unseen test set for the reading session. Even though our model reaches state-of-the-art results on the test set (sensitivity=74%, false positive rate=1.6), we show that neither the junior nor the senior reader significantly increase their sensitivity (p=0.59, p=1, respectively). In addition, we find that reading time for both readers is significantly higher in the \"AI-assisted\" setting than in the \"Unassisted\" (+15 seconds, on average; p=3x10^(-4) junior, p=3x10^(-5) senior). The confidence reported by the readers is unchanged across the two settings, indicating that the AI assistance does not influence the certainty of the diagnosis. Our findings highlight the importance of clinical validation of AI algorithms in a clinical setting involving radiologists. This study should serve as a reminder to the community to always examine the real-word effectiveness and workflow impact of proposed algorithms.",
      "authors": [
        "Tommaso Di Noto",
        "Sofyan Jankowski",
        "Francesco Puccinelli",
        "Guillaume Marie",
        "Sebastien Tourbier",
        "Yasser Aleman-Gomez",
        "Oscar Esteban",
        "Ricardo Corredor-Jerez",
        "Guillaume Saliou",
        "Patric Hagmann",
        "Meritxell Bach Cuadra",
        "Jonas Richiardi"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-22T14:32:35+00:00",
          "link": "https://arxiv.org/abs/2503.17786v1",
          "size": "491kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T11:58:17+00:00",
          "link": "https://arxiv.org/abs/2503.17786v2",
          "size": "510kb",
          "version": "v2"
        }
      ],
      "title": "Assessing workflow impact and clinical utility of AI-assisted brain aneurysm detection: a multi-reader study",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17786",
        "PDF": "https://arxiv.org/pdf/2503.17786"
      },
      "tasks": [
        "Anomaly Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.20830",
      "abstract": "Machine Learning (ML) and Deep Learning (DL) have shown significant promise in healthcare, particularly in medical image segmentation, which is crucial for accurate disease diagnosis and treatment planning. Despite their potential, challenges such as data privacy concerns, limited annotated data, and inadequate training data persist. Decentralized learning approaches such as federated learning (FL), split learning (SL), and split federated learning (SplitFed/SFL) address these issues effectively. This paper introduces \"MedSegNet10,\" a publicly accessible repository designed for medical image segmentation using split-federated learning. MedSegNet10 provides a collection of pre-trained neural network architectures optimized for various medical image types, including microscopic images of human blastocysts, dermatoscopic images of skin lesions, and endoscopic images of lesions, polyps, and ulcers, with applications extending beyond these examples. By leveraging SplitFed's benefits, MedSegNet10 allows collaborative training on privately stored, horizontally split data, ensuring privacy and integrity. This repository supports researchers, practitioners, trainees, and data scientists, aiming to advance medical image segmentation while maintaining patient data privacy. The repository is available at: https://vault.sfu.ca/index.php/s/ryhf6t12O0sobuX (password upon request to the authors).",
      "authors": [
        "Chamani Shiranthika",
        "Zahra Hafezi Kafshgari",
        "Hadi Hadizadeh",
        "Parvaneh Saeedi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-26T05:40:59+00:00",
          "link": "https://arxiv.org/abs/2503.20830v1",
          "size": "2147kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T19:55:32+00:00",
          "link": "https://arxiv.org/abs/2503.20830v2",
          "size": "2023kb",
          "version": "v2"
        }
      ],
      "title": "MedSegNet10: A Publicly Accessible Network Repository for Split Federated Medical Image Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.20830",
        "HTML": "https://arxiv.org/html/2503.20830v2",
        "PDF": "https://arxiv.org/pdf/2503.20830"
      },
      "tasks": [
        "Federated Learning",
        "Image Segmentation",
        "Medical Image Segmentation",
        "Segmentation",
        "Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.23430",
      "abstract": "Domain generalization (DG) aims to learn models that perform well on unseen target domains by training on multiple source domains. Sharpness-Aware Minimization (SAM), known for finding flat minima that improve generalization, has therefore been widely adopted in DG. However, our analysis reveals that SAM in DG may converge to \\textit{fake flat minima}, where the total loss surface appears flat in terms of global sharpness but remains sharp with respect to individual source domains. To understand this phenomenon more precisely, we formalize the average worst-case domain risk as the maximum loss under domain distribution shifts within a bounded divergence, and derive a generalization bound that reveals the limitations of global sharpness-aware minimization. In contrast, we show that individual sharpness provides a valid upper bound on this risk, making it a more suitable proxy for robust domain generalization. Motivated by these insights, we shift the DG paradigm toward minimizing individual sharpness across source domains. We propose \\textit{Decreased-overhead Gradual SAM (DGSAM)}, which applies gradual domain-wise perturbations in a computationally efficient manner to consistently reduce individual sharpness. Extensive experiments demonstrate that DGSAM not only improves average accuracy but also reduces performance variance across domains, while incurring less computational overhead than SAM.",
      "authors": [
        "Youngjun Song",
        "Youngsik Hwang",
        "Jonghun Lee",
        "Heechang Lee",
        "Dong-Young Lim"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Applications (stat.AP)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-30T13:20:06+00:00",
          "link": "https://arxiv.org/abs/2503.23430v1",
          "size": "17142kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T15:58:42+00:00",
          "link": "https://arxiv.org/abs/2503.23430v2",
          "size": "5773kb",
          "version": "v2"
        }
      ],
      "title": "DGSAM: Domain Generalization via Individual Sharpness-Aware Minimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.23430",
        "HTML": "https://arxiv.org/html/2503.23430v2",
        "PDF": "https://arxiv.org/pdf/2503.23430"
      },
      "tasks": [
        "Computational Efficiency",
        "Domain Generalization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.16225",
      "abstract": "We propose a formal framework for understanding and unifying the concept of observers across physics, computer science, philosophy, and related fields. Building on cybernetic feedback models, we introduce an operational definition of minimal observers, explore their role in shaping foundational concepts, and identify what remains unspecified in their absence. Drawing upon insights from quantum gravity, digital physics, second-order cybernetics, and recent ruliological and pregeometric approaches, we argue that observers serve as indispensable reference points for measurement, reference frames, and the emergence of meaning. We show how this formalism sheds new light on debates related to consciousness, quantum measurement, and computational boundaries; by way of theorems on observer equivalences and complexity measures. This perspective opens new avenues for investigating how complexity and structure arise in both natural and artificial systems.",
      "authors": [
        "Hatem Elshatlawy",
        "Dean Rickles",
        "Xerxes D. Arsiwalla",
        "Alexander Blum"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Information Theory (cs.IT)",
        "Information Theory (math.IT)",
        "Computational Physics (physics.comp-ph)",
        "History and Philosophy of Physics (physics.hist-ph)",
        "Physics and Society (physics.soc-ph)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-22T19:35:55+00:00",
          "link": "https://arxiv.org/abs/2504.16225v1",
          "size": "307kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T19:29:51+00:00",
          "link": "https://arxiv.org/abs/2504.16225v2",
          "size": "303kb",
          "version": "v2"
        }
      ],
      "title": "Towards a Generalized Theory of Observers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.16225",
        "HTML": "https://arxiv.org/html/2504.16225v2",
        "PDF": "https://arxiv.org/pdf/2504.16225"
      },
      "source": "arXiv"
    },
    {
      "id": "2505.05151",
      "abstract": "Discrete diffusion models represent a significant advance in generative modeling, demonstrating remarkable success in synthesizing complex, high-quality discrete data. However, to avoid exponential computational costs, they typically rely on calculating per-dimension transition probabilities when learning high-dimensional distributions. In this study, we rigorously prove that this approach leads to a worst-case linear scaling of Kullback-Leibler (KL) divergence with data dimension. To address this, we propose a Quantum Discrete Denoising Diffusion Probabilistic Model (QD3PM), which enables joint probability learning through diffusion and denoising in exponentially large Hilbert spaces, offering a theoretical pathway to faithfully capture the true joint distribution. By deriving posterior states through quantum Bayes' theorem, similar to the crucial role of posterior probabilities in classical diffusion models, and by learning the joint probability, we establish a solid theoretical foundation for quantum-enhanced diffusion models. For denoising, we design a quantum circuit that utilizes temporal information for parameter sharing and incorporates learnable classical-data-controlled rotations for encoding. Exploiting joint distribution learning, our approach enables single-step sampling from pure noise, eliminating iterative requirements of existing models. Simulations demonstrate the proposed model's superior accuracy in modeling complex distributions compared to factorization methods. Hence, this paper establishes a new theoretical paradigm in generative models by leveraging the quantum advantage in joint distribution learning.",
      "authors": [
        "Chuangtao Chen",
        "Qinglin Zhao",
        "MengChu Zhou",
        "Dusit Niyato",
        "Zhimin He",
        "Haozhen Situ"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-08T11:48:21+00:00",
          "link": "https://arxiv.org/abs/2505.05151v1",
          "size": "13780kb",
          "version": "v1"
        },
        {
          "date": "2025-05-28T14:11:47+00:00",
          "link": "https://arxiv.org/abs/2505.05151v2",
          "size": "3558kb",
          "version": "v2"
        },
        {
          "date": "2025-06-29T15:35:22+00:00",
          "link": "https://arxiv.org/abs/2505.05151v3",
          "size": "2662kb",
          "version": "v3"
        }
      ],
      "title": "Overcoming Dimensional Factorization Limits in Discrete Diffusion Models through Quantum Joint Distribution Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.05151",
        "HTML": "https://arxiv.org/html/2505.05151v3",
        "PDF": "https://arxiv.org/pdf/2505.05151"
      },
      "tasks": [
        "Denoising"
      ],
      "repo_urls": [
        "https://github.com/ChuangtaoChen/QD3PM"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.12085",
      "abstract": "Given a linear equation $\\cal E$ of the form $ax + by = cz$ where $a$, $b$, $c$ are positive integers, the $k$-colour Rado number $R_k({\\cal E})$ is the smallest positive integer $n$, if it exists, such that every $k$-colouring of the positive integers $\\{1, 2, \\dotsc, n\\}$ contains a monochromatic solution to $\\cal E$. In this paper, we consider $k = 3$ and the linear equations $ax + by = bz$ and $ax + ay = bz$. Using SAT solvers, we compute a number of previously unknown Rado numbers corresponding to these equations. We prove new general bounds on Rado numbers inspired by the satisfying assignments discovered by the SAT solver. Our proofs require extensive case-based analyses that are difficult to check for correctness by hand, so we automate checking the correctness of our proofs via an approach which makes use of a new tool we developed with support for operations on symbolically-defined sets -- e.g., unions or intersections of sets of the form $\\{f(1), f(2), \\dotsc, f(a)\\}$ where $a$ is a symbolic variable and $f$ is a function possibly dependent on $a$. No computer algebra system that we are aware of currently has sufficiently capable support for symbolic sets, leading us to develop a tool supporting symbolic sets using the Python symbolic computation library SymPy coupled with the Satisfiability Modulo Theories solver Z3.",
      "authors": [
        "Tanbir Ahmed",
        "Lamina Zaman",
        "Curtis Bright"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Discrete Mathematics (cs.DM)",
        "Logic in Computer Science (cs.LO)",
        "Symbolic Computation (cs.SC)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-17T16:59:11+00:00",
          "link": "https://arxiv.org/abs/2505.12085v1",
          "size": "51kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T22:03:56+00:00",
          "link": "https://arxiv.org/abs/2505.12085v2",
          "size": "46kb",
          "version": "v2"
        }
      ],
      "title": "Symbolic Sets for Proving Bounds on Rado Numbers",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.12085",
        "HTML": "https://arxiv.org/html/2505.12085v2",
        "PDF": "https://arxiv.org/pdf/2505.12085"
      },
      "source": "arXiv"
    },
    {
      "id": "2505.14516",
      "abstract": "Assuming that no family of polynomial-size Boolean circuits can factorize a constant fraction of all products of two $n$-bit primes, we show that the bounded arithmetic theory $\\text{PV}_1$, even when augmented by the sharply bounded choice scheme $BB(\\Sigma^b_0)$, cannot prove that every number has some prime divisor. By the completeness theorem, it follows that under this assumption there is a model $M$ of $\\text{PV}_1$ that contains a nonstandard number $m$ which has no prime factorization.",
      "authors": [
        "Ond\\v{r}ej Je\\v{z}il"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Logic (math.LO)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-20T15:43:25+00:00",
          "link": "https://arxiv.org/abs/2505.14516v1",
          "size": "15kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T15:00:36+00:00",
          "link": "https://arxiv.org/abs/2505.14516v2",
          "size": "16kb",
          "version": "v2"
        }
      ],
      "title": "Prime Factorization in Models of PV$_1$",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.14516",
        "HTML": "https://arxiv.org/html/2505.14516v2",
        "PDF": "https://arxiv.org/pdf/2505.14516"
      },
      "source": "arXiv"
    },
    {
      "id": "2505.19577",
      "abstract": "Keyword spotting (KWS) is essential for voice-driven applications, demanding both accuracy and efficiency. Traditional ASR-based KWS methods, such as greedy and beam search, explore the entire search space without explicitly prioritizing keyword detection, often leading to suboptimal performance. In this paper, we propose an effective keyword-specific KWS framework by introducing a streaming-oriented CTC-Transducer-combined frame-asynchronous system with multi-head frame-asynchronous decoding (MFA-KWS). Specifically, MFA-KWS employs keyword-specific phone-synchronous decoding for CTC and replaces conventional RNN-T with Token-and-Duration Transducer to enhance both performance and efficiency. Furthermore, we explore various score fusion strategies, including single-frame-based and consistency-based methods. Extensive experiments demonstrate the superior performance of MFA-KWS, which achieves state-of-the-art results on both fixed keyword and arbitrary keywords datasets, such as Snips, MobvoiHotwords, and LibriKWS-20, while exhibiting strong robustness in noisy environments. Among fusion strategies, the consistency-based CDC-Last method delivers the best performance. Additionally, MFA-KWS achieves a 47% to 63% speed-up over the frame-synchronous baselines across various datasets. Extensive experimental results confirm that MFA-KWS is an effective and efficient KWS framework, making it well-suited for on-device deployment.",
      "authors": [
        "Yu Xi",
        "Haoyu Li",
        "Xiaoyu Gu",
        "Yidi Jiang and Kai Yu"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T06:47:43+00:00",
          "link": "https://arxiv.org/abs/2505.19577v1",
          "size": "435kb",
          "version": "v1"
        },
        {
          "date": "2025-05-30T17:24:51+00:00",
          "link": "https://arxiv.org/abs/2505.19577v2",
          "size": "356kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T16:21:25+00:00",
          "link": "https://arxiv.org/abs/2505.19577v3",
          "size": "355kb",
          "version": "v3"
        }
      ],
      "title": "MFA-KWS: Effective Keyword Spotting with Multi-head Frame-asynchronous Decoding",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.19577",
        "HTML": "https://arxiv.org/html/2505.19577v3",
        "PDF": "https://arxiv.org/pdf/2505.19577"
      },
      "tasks": [
        "Keyword Spotting"
      ],
      "repo_urls": [
        "https://github.com/x-lance/kwstreamingsearch"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.20166",
      "abstract": "Audio-aware large language models (ALLMs) have recently made great strides in understanding and processing audio inputs. These models are typically adapted from text-based large language models (LLMs) through additional training on audio-related tasks. However, this adaptation process presents two major limitations. First, ALLMs often suffer from catastrophic forgetting, where crucial textual capabilities like instruction-following are lost after training on audio data. In some cases, models may even hallucinate sounds that are not present in the input audio, raising concerns about reliability. Second, achieving cross-modal alignment between audio and language typically relies on large collections of task-specific question-answer pairs for instruction tuning, making it resource-intensive. To address these issues, previous works have leveraged the backbone LLMs to synthesize general-purpose, caption-style alignment data. In this paper, we propose a data generation framework that produces contrastive-like training data, designed to enhance ALLMs' ability to differentiate between present and absent sounds. We further extend our approach to multi-audio scenarios, enabling the model to either explain differences between audio inputs or produce unified captions that describe all inputs, thereby enhancing audio-language alignment. We refer to the entire ALLM training framework as bootstrapping audio-language alignment via synthetic data generation from backbone LLMs (BALSa). Experimental results indicate that our method effectively mitigates audio hallucinations while reliably maintaining strong performance on audio understanding and reasoning benchmarks, as well as instruction-following skills. Moreover, incorporating multi-audio training further enhances the model's comprehension and reasoning capabilities. Overall, BALSa offers an efficient and scalable approach to developing ALLMs.",
      "authors": [
        "Chun-Yi Kuan and Hung-yi Lee"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-26T16:08:41+00:00",
          "link": "https://arxiv.org/abs/2505.20166v1",
          "size": "1035kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T06:48:46+00:00",
          "link": "https://arxiv.org/abs/2505.20166v2",
          "size": "1036kb",
          "version": "v2"
        }
      ],
      "title": "From Alignment to Advancement: Bootstrapping Audio-Language Alignment with Synthetic Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.20166",
        "HTML": "https://arxiv.org/html/2505.20166v2",
        "PDF": "https://arxiv.org/pdf/2505.20166"
      },
      "tasks": [
        "cross-modal alignment",
        "Instruction Following",
        "Synthetic Data Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.23860",
      "abstract": "This white paper discusses and explores the various points of intersection between quantum computing and artificial intelligence (AI). It describes how quantum computing could support the development of innovative AI solutions. It also examines use cases of classical AI that can empower research and development in quantum technologies, with a focus on quantum computing and quantum sensing. The purpose of this white paper is to provide a long-term research agenda aimed at addressing foundational questions about how AI and quantum computing interact and benefit one another. It concludes with a set of recommendations and challenges, including how to orchestrate the proposed theoretical work, align quantum AI developments with quantum hardware roadmaps, estimate both classical and quantum resources - especially with the goal of mitigating and optimizing energy consumption - advance this emerging hybrid software engineering discipline, and enhance European industrial competitiveness while considering societal implications.",
      "authors": [
        "Giovanni Acampora",
        "Andris Ambainis",
        "Natalia Ares",
        "Leonardo Banchi",
        "Pallavi Bhardwaj",
        "Daniele Binosi",
        "G. Andrew D. Briggs",
        "Tommaso Calarco",
        "Vedran Dunjko",
        "Jens Eisert",
        "Olivier Ezratty",
        "Paul Erker",
        "Federico Fedele",
        "Elies Gil-Fuster",
        "Martin G\\\"arttner",
        "Mats Granath",
        "Markus Heyl",
        "Iordanis Kerenidis",
        "Matthias Klusch",
        "Anton Frisk Kockum",
        "Richard Kueng",
        "Mario Krenn",
        "J\\\"org L\\\"assig",
        "Antonio Macaluso",
        "Sabrina Maniscalco",
        "Florian Marquardt",
        "Kristel Michielsen",
        "Gorka Mu\\~noz-Gil",
        "Daniel M\\\"ussig",
        "Hendrik Poulsen Nautrup",
        "Sophie A. Neubauer",
        "Evert van Nieuwenburg",
        "Roman Orus",
        "J\\\"org Schmiedmayer",
        "Markus Schmitt",
        "Philipp Slusallek",
        "Filippo Vicentini",
        "Christof Weitenberg",
        "and Frank K. Wilhelm"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T08:15:23+00:00",
          "link": "https://arxiv.org/abs/2505.23860v1",
          "size": "2386kb",
          "version": "v1"
        },
        {
          "date": "2025-06-16T14:30:10+00:00",
          "link": "https://arxiv.org/abs/2505.23860v2",
          "size": "2364kb",
          "version": "v2"
        },
        {
          "date": "2025-06-30T12:33:19+00:00",
          "link": "https://arxiv.org/abs/2505.23860v3",
          "size": "2366kb",
          "version": "v3"
        }
      ],
      "title": "Quantum computing and artificial intelligence: status and perspectives",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23860",
        "HTML": "https://arxiv.org/html/2505.23860v3",
        "PDF": "https://arxiv.org/pdf/2505.23860"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2505.23869",
      "abstract": "A proposition that connects randomness and compression is put forward via Gibbs entropy over set of measurement vectors associated with a compression process. The proposition states that a lossy compression process is equivalent to {\\it directed randomness} that preserves information content. The proposition originated from the observed behaviour in newly proposed {\\it Dual Tomographic Compression} (DTC) compress-train framework. This is akin to tomographic reconstruction of layer weight matrices via building compressed sensed projections, via so-called {\\it weight rays}. This tomographic approach is applied to previous and next layers in a dual fashion, that triggers neuronal-level pruning. This novel model compress-train scheme appears in iterative fashion and acts as a smart neural architecture search, The experiments demonstrated the utility of this dual-tomography producing state-of-the-art performance with efficient compression during training, accelerating and supporting lottery ticket hypothesis. However, random compress-train iterations having similar performance demonstrated the connection between randomness and compression from statistical physics perspective, we formulated the so-called {\\it Gibbs randomness-compression proposition}, signifying randomness-compression relationship via Gibbs entropy. Practically, the DTC framework provides a promising approach for massively energy- and resource-efficient deep learning training.",
      "authors": [
        "M. S\\\"uzen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-29T10:48:35+00:00",
          "link": "https://arxiv.org/abs/2505.23869v1",
          "size": "366kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T12:42:09+00:00",
          "link": "https://arxiv.org/abs/2505.23869v2",
          "size": "437kb",
          "version": "v2"
        }
      ],
      "title": "Gibbs randomness-compression proposition: An efficient deep learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.23869",
        "HTML": "https://arxiv.org/html/2505.23869v2",
        "PDF": "https://arxiv.org/pdf/2505.23869"
      },
      "tasks": [
        "Deep Learning",
        "Neural Architecture Search"
      ],
      "repo_urls": [
        "https://github.com/msuzen/research/tree/main/gibbs-randomness-compression"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.01432",
      "abstract": "The application of quantum computation to topological data analysis (TDA) has received growing attention. While estimating Betti numbers is a central task in TDA, general complexity theoretic limitations restrict the possibility of quantum speedups. To address this, we explore quantum algorithms under a more structured input model. We show that access to additional topological information enables improved quantum algorithms for estimating Betti and persistent Betti numbers. Building on this, we introduce a new approach based on homology tracking, which avoids computing the kernel of combinatorial Laplacians used in prior methods. This yields a framework that remains efficient even when Betti numbers are small, offering substantial and sometimes exponential speedups. Beyond Betti number estimation, we formulate and study the homology property testing problem, and extend our approach to the cohomological setting. We present quantum algorithms for testing triviality and distinguishing homology classes, revealing new avenues for quantum advantage in TDA.",
      "authors": [
        "Junseo Lee",
        "Nhat A. Nghiem"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Computational Complexity (cs.CC)",
        "Computational Geometry (cs.CG)",
        "Data Structures and Algorithms (cs.DS)",
        "Algebraic Topology (math.AT)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T08:43:58+00:00",
          "link": "https://arxiv.org/abs/2506.01432v1",
          "size": "58kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T09:08:24+00:00",
          "link": "https://arxiv.org/abs/2506.01432v2",
          "size": "380kb",
          "version": "v2"
        }
      ],
      "title": "New aspects of quantum topological data analysis: Betti number estimation, and testing and tracking of homology and cohomology classes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01432",
        "HTML": "https://arxiv.org/html/2506.01432v2",
        "PDF": "https://arxiv.org/pdf/2506.01432"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.01891",
      "abstract": "Neural Quantum States (NQS) are a class of variational wave functions parametrized by neural networks (NNs) to study quantum many-body systems. In this work, we propose \\texttt{SineKAN}, a NQS \\textit{ansatz} based on Kolmogorov-Arnold Networks (KANs), to represent quantum mechanical wave functions as nested univariate functions. We show that \\texttt{SineKAN} wavefunction with learnable sinusoidal activation functions can capture the ground state energies, fidelities and various correlation functions of the one dimensional Transverse-Field Ising model, Anisotropic Heisenberg model, and Antiferromagnetic $J_{1}-J_{2}$ model with different chain lengths. In our study of the $J_1-J_2$ model with $L=100$ sites, we find that the \\texttt{SineKAN} model outperforms several previously explored neural quantum state \\textit{ans\\\"atze}, including Restricted Boltzmann Machines (RBMs), Long Short-Term Memory models (LSTMs), and Multi-layer Perceptrons (MLP) \\textit{a.k.a.} Feed Forward Neural Networks, when compared to the results obtained from the Density Matrix Renormalization Group (DMRG) algorithm. We find that \\texttt{SineKAN} models can be trained to high precisions and accuracies with minimal computational costs.",
      "authors": [
        "Mahmud Ashraf Shamim",
        "Eric A F Reinhardt",
        "Talal Ahmed Chowdhury",
        "Sergei Gleyzer and Paulo T Araujo"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Strongly Correlated Electrons (cond-mat.str-el)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-02T17:18:40+00:00",
          "link": "https://arxiv.org/abs/2506.01891v1",
          "size": "3250kb",
          "version": "v1"
        },
        {
          "date": "2025-06-17T19:21:36+00:00",
          "link": "https://arxiv.org/abs/2506.01891v2",
          "size": "3251kb",
          "version": "v2"
        },
        {
          "date": "2025-06-25T17:17:27+00:00",
          "link": "https://arxiv.org/abs/2506.01891v3",
          "size": "3251kb",
          "version": "v3"
        },
        {
          "date": "2025-06-27T21:50:31+00:00",
          "link": "https://arxiv.org/abs/2506.01891v4",
          "size": "3251kb",
          "version": "v4"
        }
      ],
      "title": "Probing Quantum Spin Systems with Kolmogorov-Arnold Neural Network Quantum States",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.01891",
        "HTML": "https://arxiv.org/html/2506.01891v4",
        "PDF": "https://arxiv.org/pdf/2506.01891"
      },
      "tasks": [
        "Kolmogorov-Arnold Networks"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.03074",
      "abstract": "We present `GL-LowPopArt`, a novel Catoni-style estimator for generalized low-rank trace regression. Building on `LowPopArt` (Jang et al., 2024), it employs a two-stage approach: nuclear norm regularization followed by matrix Catoni estimation. We establish state-of-the-art estimation error bounds, surpassing existing guarantees (Fan et al., 2019; Kang et al., 2022), and reveal a novel experimental design objective, $\\mathrm{GL}(\\pi)$. The key technical challenge is controlling bias from the nonlinear inverse link function, which we address by our two-stage approach. We prove a *local* minimax lower bound, showing that our `GL-LowPopArt` enjoys instance-wise optimality up to the condition number of the ground-truth Hessian. Applications include generalized linear matrix completion, where `GL-LowPopArt` achieves a state-of-the-art Frobenius error guarantee, and **bilinear dueling bandits**, a novel setting inspired by general preference learning (Zhang et al., 2024). Our analysis of a `GL-LowPopArt`-based explore-then-commit algorithm reveals a new, potentially interesting problem-dependent quantity, along with improved Borda regret bound than vectorization (Wu et al., 2024).",
      "authors": [
        "Junghyun Lee and Kyoungseok Jang and Kwang-Sung Jun and Milan Vojnovi\\'c and Se-Young Yun"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-03T16:52:24+00:00",
          "link": "https://arxiv.org/abs/2506.03074v1",
          "size": "173kb",
          "version": "v1"
        },
        {
          "date": "2025-06-04T02:09:24+00:00",
          "link": "https://arxiv.org/abs/2506.03074v2",
          "size": "173kb",
          "version": "v2"
        },
        {
          "date": "2025-06-18T15:42:12+00:00",
          "link": "https://arxiv.org/abs/2506.03074v3",
          "size": "172kb",
          "version": "v3"
        },
        {
          "date": "2025-06-30T09:20:14+00:00",
          "link": "https://arxiv.org/abs/2506.03074v4",
          "size": "126kb",
          "version": "v4"
        }
      ],
      "title": "GL-LowPopArt: A Nearly Instance-Wise Minimax-Optimal Estimator for Generalized Low-Rank Trace Regression",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.03074",
        "HTML": "https://arxiv.org/html/2506.03074v4",
        "PDF": "https://arxiv.org/pdf/2506.03074"
      },
      "tasks": [
        "Experimental Design",
        "Matrix Completion"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.04194",
      "abstract": "Most of the widely used estimators of the average treatment effect (ATE) in causal inference rely on the assumptions of unconfoundedness and overlap. Unconfoundedness requires that the observed covariates account for all correlations between the outcome and treatment. Overlap requires the existence of randomness in treatment decisions for all individuals. Nevertheless, many types of studies frequently violate unconfoundedness or overlap, for instance, observational studies with deterministic treatment decisions - popularly known as Regression Discontinuity designs - violate overlap.\n  In this paper, we initiate the study of general conditions that enable the identification of the average treatment effect, extending beyond unconfoundedness and overlap. In particular, following the paradigm of statistical learning theory, we provide an interpretable condition that is sufficient and necessary for the identification of ATE. Moreover, this condition also characterizes the identification of the average treatment effect on the treated (ATT) and can be used to characterize other treatment effects as well. To illustrate the utility of our condition, we present several well-studied scenarios where our condition is satisfied and, hence, we prove that ATE can be identified in regimes that prior works could not capture. For example, under mild assumptions on the data distributions, this holds for the models proposed by Tan (2006) and Rosenbaum (2002), and the Regression Discontinuity design model introduced by Thistlethwaite and Campbell (1960). For each of these scenarios, we also show that, under natural additional assumptions, ATE can be estimated from finite samples.\n  We believe these findings open new avenues for bridging learning-theoretic insights and causal inference methodologies, particularly in observational studies with complex treatment mechanisms.",
      "authors": [
        "Yang Cai and Alkis Kalavasis and Katerina Mamali and Anay Mehrotra and Manolis Zampetakis"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Statistics Theory (math.ST)",
        "Machine Learning (cs.LG)",
        "Econometrics (econ.EM)",
        "Methodology (stat.ME)",
        "Machine Learning (stat.ML)",
        "Statistics Theory (stat.TH)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-04T17:40:55+00:00",
          "link": "https://arxiv.org/abs/2506.04194v1",
          "size": "242kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T17:21:41+00:00",
          "link": "https://arxiv.org/abs/2506.04194v2",
          "size": "245kb",
          "version": "v2"
        }
      ],
      "title": "What Makes Treatment Effects Identifiable? Characterizations and Estimators Beyond Unconfoundedness",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.04194",
        "HTML": "https://arxiv.org/html/2506.04194v2",
        "PDF": "https://arxiv.org/pdf/2506.04194"
      },
      "tasks": [
        "Causal Inference",
        "Learning Theory"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.07236",
      "abstract": "Lung cancer remains one of the most prevalent and fatal diseases worldwide, demanding accurate and timely diagnosis and treatment. Recent advancements in large AI models have significantly enhanced medical image understanding and clinical decision-making. This review systematically surveys the state-of-the-art in applying large AI models to lung cancer screening, diagnosis, prognosis, and treatment. We categorize existing models into modality-specific encoders, encoder-decoder frameworks, and joint encoder architectures, highlighting key examples such as CLIP, BLIP, Flamingo, BioViL-T, and GLoRIA. We further examine their performance in multimodal learning tasks using benchmark datasets like LIDC-IDRI, NLST, and MIMIC-CXR. Applications span pulmonary nodule detection, gene mutation prediction, multi-omics integration, and personalized treatment planning, with emerging evidence of clinical deployment and validation. Finally, we discuss current limitations in generalizability, interpretability, and regulatory compliance, proposing future directions for building scalable, explainable, and clinically integrated AI systems. Our review underscores the transformative potential of large AI models to personalize and optimize lung cancer care.",
      "authors": [
        "Jiachen Zhong",
        "Yiting Wang",
        "Di Zhu and Ziwei Wang"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-08T17:42:24+00:00",
          "link": "https://arxiv.org/abs/2506.07236v1",
          "size": "52kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T01:57:26+00:00",
          "link": "https://arxiv.org/abs/2506.07236v2",
          "size": "0kb",
          "version": "v2"
        }
      ],
      "title": "A Narrative Review on Large AI Models in Lung Cancer Screening, Diagnosis, and Treatment Planning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.07236",
        "PDF": "https://arxiv.org/pdf/2506.07236"
      },
      "tasks": [
        "Decision Making",
        "Decoder",
        "Prognosis"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.11297",
      "abstract": "Fluorodeoxyglucose (FDG) PET to evaluate patients with epilepsy is one of the most common applications for simultaneous PET/MRI, given the need to image both brain structure and metabolism, but is suboptimal due to the radiation dose in this young population. Little work has been done synthesizing diagnostic quality PET images from MRI data or MRI data with ultralow-dose PET using advanced generative AI methods, such as diffusion models, with attention to clinical evaluations tailored for the epilepsy population. Here we compared the performance of diffusion- and non-diffusion-based deep learning models for the MRI-to-PET image translation task for epilepsy imaging using simultaneous PET/MRI in 52 subjects (40 train/2 validate/10 hold-out test). We tested three different models: 2 score-based generative diffusion models (SGM-Karras Diffusion [SGM-KD] and SGM-variance preserving [SGM-VP]) and a Transformer-Unet. We report results on standard image processing metrics as well as clinically relevant metrics, including congruency measures (Congruence Index and Congruency Mean Absolute Error) that assess hemispheric metabolic asymmetry, which is a key part of the clinical analysis of these images. The SGM-KD produced the best qualitative and quantitative results when synthesizing PET purely from T1w and T2 FLAIR images with the least mean absolute error in whole-brain specific uptake value ratio (SUVR) and highest intraclass correlation coefficient. When 1% low-dose PET images are included in the inputs, all models improve significantly and are interchangeable for quantitative performance and visual quality. In summary, SGMs hold great potential for pure MRI-to-PET translation, while all 3 model types can synthesize full-dose FDG-PET accurately using MRI and ultralow-dose PET.",
      "authors": [
        "Jiaqi Wu",
        "Jiahong Ouyang",
        "Farshad Moradi",
        "Mohammad Mehdi Khalighi",
        "Greg Zaharchuk"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-12T20:57:02+00:00",
          "link": "https://arxiv.org/abs/2506.11297v1",
          "size": "16077kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T05:10:46+00:00",
          "link": "https://arxiv.org/abs/2506.11297v2",
          "size": "17003kb",
          "version": "v2"
        }
      ],
      "title": "Score-based Generative Diffusion Models to Synthesize Full-dose FDG Brain PET from MRI in Epilepsy Patients",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.11297",
        "HTML": "https://arxiv.org/html/2506.11297v2",
        "PDF": "https://arxiv.org/pdf/2506.11297"
      },
      "tasks": [
        "Diagnostic"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.12285",
      "abstract": "Recent advances in audio-text large language models (LLMs) have opened new possibilities for music understanding and generation. However, existing benchmarks are limited in scope, often relying on simplified tasks or multi-choice evaluations that fail to reflect the complexity of real-world music analysis. We reinterpret a broad range of traditional MIR annotations as instruction-following formats and introduce CMI-Bench, a comprehensive music instruction following benchmark designed to evaluate audio-text LLMs on a diverse set of music information retrieval (MIR) tasks. These include genre classification, emotion regression, emotion tagging, instrument classification, pitch estimation, key detection, lyrics transcription, melody extraction, vocal technique recognition, instrument performance technique detection, music tagging, music captioning, and (down)beat tracking: reflecting core challenges in MIR research. Unlike previous benchmarks, CMI-Bench adopts standardized evaluation metrics consistent with previous state-of-the-art MIR models, ensuring direct comparability with supervised approaches. We provide an evaluation toolkit supporting all open-source audio-textual LLMs, including LTU, Qwen-audio, SALMONN, MusiLingo, etc. Experiment results reveal significant performance gaps between LLMs and supervised models, along with their culture, chronological and gender bias, highlighting the potential and limitations of current models in addressing MIR tasks. CMI-Bench establishes a unified foundation for evaluating music instruction following, driving progress in music-aware LLMs.",
      "authors": [
        "Yinghao Ma",
        "Siyou Li",
        "Juntao Yu",
        "Emmanouil Benetos",
        "Akira Maezawa"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-14T00:18:44+00:00",
          "link": "https://arxiv.org/abs/2506.12285v1",
          "size": "505kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T22:42:09+00:00",
          "link": "https://arxiv.org/abs/2506.12285v2",
          "size": "511kb",
          "version": "v2"
        }
      ],
      "title": "CMI-Bench: A Comprehensive Benchmark for Evaluating Music Instruction Following",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.12285",
        "HTML": "https://arxiv.org/html/2506.12285v2",
        "PDF": "https://arxiv.org/pdf/2506.12285"
      },
      "datasets": [
        {
          "dataset_name": "nicolaus625/CMI-bench",
          "downloads": "217",
          "likes": "1",
          "link": "https://huggingface.co/datasets/nicolaus625/CMI-bench"
        }
      ],
      "tasks": [
        "Beat Tracking",
        "Genre classification",
        "Information Retrieval",
        "Instruction Following",
        "Key Detection",
        "Melody Extraction",
        "Music Captioning",
        "Music Information Retrieval",
        "Music Tagging"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.13865",
      "abstract": "Variational quantum algorithms (VQAs) promise near-term quantum advantage, yet parametrized quantum states commonly built from the digital gate-based approach often suffer from scalability issues such as barren plateaus, where the loss landscape becomes flat. We study an analog VQA ans\\\"atze composed of $M$ quenches of a disordered Ising chain, whose dynamics is native to several quantum simulation platforms. By tuning the disorder strength we place each quench in either a thermalized phase or a many-body-localized (MBL) phase and analyse (i) the ans\\\"atze's expressivity and (ii) the scaling of loss variance. Numerics shows that both phases reach maximal expressivity at large $M$, but barren plateaus emerge at far smaller $M$ in the thermalized phase than in the MBL phase. Exploiting this gap, we propose an MBL initialisation strategy: initialise the ans\\\"atze in the MBL regime at intermediate quench $M$, enabling an initial trainability while retaining sufficient expressivity for subsequent optimization. The results link quantum phases of matter and VQA trainability, and provide practical guidelines for scaling analog-hardware VQAs.",
      "authors": [
        "Kasidit Srimahajariyapong",
        "Supanut Thanasilp",
        "Thiparat Chotibut"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Machine Learning (cs.LG)",
        "Neural and Evolutionary Computing (cs.NE)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-16T18:00:02+00:00",
          "link": "https://arxiv.org/abs/2506.13865v1",
          "size": "9401kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T16:17:09+00:00",
          "link": "https://arxiv.org/abs/2506.13865v2",
          "size": "9441kb",
          "version": "v2"
        }
      ],
      "title": "Connecting phases of matter to the flatness of the loss landscape in analog variational quantum algorithms",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.13865",
        "HTML": "https://arxiv.org/html/2506.13865v2",
        "PDF": "https://arxiv.org/pdf/2506.13865"
      },
      "tasks": [
        "Visual Question Answering (VQA)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.14427",
      "abstract": "In the field of speaker diarization, the development of technology is constrained by two problems: insufficient data resources and poor generalization ability of deep learning models. To address these two problems, firstly, we propose an automated method for constructing speaker diarization datasets, which generates more accurate pseudo-labels for massive data through the combination of audio and video. Relying on this method, we have released Multi-modal, Multi-scenario and Multi-language Speaker Diarization (M3SD) datasets. This dataset is derived from real network videos and is highly diverse. Our dataset and code have been open-sourced at https://huggingface.co/spaces/OldDragon/m3sd.",
      "authors": [
        "Shilong Wu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Multimedia (cs.MM)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-17T11:44:20+00:00",
          "link": "https://arxiv.org/abs/2506.14427v1",
          "size": "5132kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T05:50:08+00:00",
          "link": "https://arxiv.org/abs/2506.14427v2",
          "size": "5073kb",
          "version": "v2"
        }
      ],
      "title": "M3SD: Multi-modal, Multi-scenario and Multi-language Speaker Diarization Dataset",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.14427",
        "HTML": "https://arxiv.org/html/2506.14427v2",
        "PDF": "https://arxiv.org/pdf/2506.14427"
      },
      "tasks": [
        "Domain Adaptation",
        "speaker-diarization",
        "Speaker Diarization"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.17777",
      "abstract": "We define and study an extension of the notion of the VC-dimension of a hypergraph and apply it to establish a Tverberg type theorem for unions of convex sets. We also prove a new Radon type theorem for unions of convex sets,\n  vastly improving the estimates in an earlier result of B\\'ar\\'any and Kalai.",
      "authors": [
        "Noga Alon",
        "Shakhar Smorodinsky"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-21T18:13:42+00:00",
          "link": "https://arxiv.org/abs/2506.17777v1",
          "size": "16kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T06:10:40+00:00",
          "link": "https://arxiv.org/abs/2506.17777v2",
          "size": "16kb",
          "version": "v2"
        }
      ],
      "title": "Extended VC-dimension, and Radon and Tverberg type theorems for unions of convex sets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.17777",
        "HTML": "https://arxiv.org/html/2506.17777v2",
        "PDF": "https://arxiv.org/pdf/2506.17777"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.18915",
      "abstract": "Depression is a common mental illness across current human society. Traditional depression assessment relying on inventories and interviews with psychologists frequently suffer from subjective diagnosis results, slow and expensive diagnosis process as well as lack of human resources. Since there is a solid evidence that depression is reflected by various human internal brain activities and external expressive behaviours, early traditional machine learning (ML) and advanced deep learning (DL) models have been widely explored for human behaviour-based automatic depression assessment (ADA) since 2012. However, recent ADA surveys typically only focus on a limited number of human behaviour modalities. Despite being used as a theoretical basis for developing ADA approaches, existing ADA surveys lack a comprehensive review and summary of multi-modal depression-related human behaviours. To bridge this gap, this paper specifically summarises depression-related human behaviours across a range of modalities (e.g. the human brain, verbal language and non-verbal audio/facial/body behaviours). We focus on conducting an up-to-date and comprehensive survey of ML-based ADA approaches for learning depression cues from these behaviours as well as discussing and comparing their distinctive features and limitations. In addition, we also review existing ADA competitions and datasets, identify and discuss the main challenges and opportunities to provide further research directions for future ADA researchers.",
      "authors": [
        "Siyang Song",
        "Yupeng Huo",
        "Shiqing Tang",
        "Jiaee Cheong",
        "Rui Gao",
        "Michel Valstar",
        "Hatice Gunes"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Neurons and Cognition (q-bio.NC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-09T14:40:16+00:00",
          "link": "https://arxiv.org/abs/2506.18915v1",
          "size": "4559kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T10:44:28+00:00",
          "link": "https://arxiv.org/abs/2506.18915v2",
          "size": "4329kb",
          "version": "v2"
        }
      ],
      "title": "Automatic Depression Assessment using Machine Learning: A Comprehensive Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.18915",
        "HTML": "https://arxiv.org/html/2506.18915v2",
        "PDF": "https://arxiv.org/pdf/2506.18915"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.19340",
      "abstract": "We present Compressible Atmospheric Model-Network (CAM-NET), an AI model designed to predict neutral atmospheric variables from the Earth's surface to the ionosphere with high accuracy and computational efficiency. Accurate modeling of the entire atmosphere is critical for understanding the upward propagation of gravity waves, which influence upper-atmospheric dynamics and coupling across atmospheric layers. CAM-NET leverages the Spherical Fourier Neural Operator (SFNO) to capture global-scale atmospheric dynamics while preserving the Earth's spherical structure. Trained on a decade of datasets from the Whole Atmosphere Community Climate Model with thermosphere and ionosphere eXtension (WACCM-X), CAM-NET demonstrates accuracy comparable to WACCM-X while achieving a speedup of over 1000x in inference time, can provide one year simulation within a few minutes once trained. The model effectively predicts key atmospheric parameters, including zonal and meridional winds, temperature, and time rate of pressure. Inspired by traditional modeling approaches that use external couplers to simulate tracer transport, CAM-NET introduces a modular architecture that explicitly separates tracer prediction from core dynamics. The core backbone of CAM-NET focuses on forecasting primary physical variables (e.g., temperature, wind velocity), while tracer variables are predicted through a lightweight, fine-tuned model. This design allows for efficient adaptation to specific tracer scenarios with minimal computational cost, avoiding the need to retrain the entire model. We have validated this approach on the $O^2$ tracer, demonstrating strong performance and generalization capabilities.",
      "authors": [
        "Jiahui Hu and Wenjun Dong"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Space Physics (physics.space-ph)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T06:07:28+00:00",
          "link": "https://arxiv.org/abs/2506.19340v1",
          "size": "17241kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T03:10:30+00:00",
          "link": "https://arxiv.org/abs/2506.19340v2",
          "size": "14089kb",
          "version": "v2"
        }
      ],
      "title": "CAM-NET: An AI Model for Whole Atmosphere with Thermosphere and Ionosphere Extension",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.19340",
        "HTML": "https://arxiv.org/html/2506.19340v2",
        "PDF": "https://arxiv.org/pdf/2506.19340"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20407",
      "abstract": "Accurate gestational age (GA) estimation, ideally through fetal ultrasound measurement, is a crucial aspect of providing excellent antenatal care. However, deriving GA from manual fetal biometric measurements depends on the operator and is time-consuming. Hence, automatic computer-assisted methods are demanded in clinical practice. In this paper, we present a novel feature fusion framework to estimate GA using fetal ultrasound images without any measurement information. We adopt a deep learning model to extract deep representations from ultrasound images. We extract radiomic features to reveal patterns and characteristics of fetal brain growth. To harness the interpretability of radiomics in medical imaging analysis, we estimate GA by fusing radiomic features and deep representations. Our framework estimates GA with a mean absolute error of 8.0 days across three trimesters, outperforming current machine learning-based methods at these gestational ages. Experimental results demonstrate the robustness of our framework across different populations in diverse geographical regions. Our code is publicly available on \\href{https://github.com/13204942/RadiomicsImageFusion_FetalUS}.",
      "authors": [
        "Fangyijie Wang",
        "Yuan Liang",
        "Sourav Bhattacharjee",
        "Abey Campbell",
        "Kathleen M. Curran",
        "Gu\\'enol\\'e Silvestre"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T13:23:35+00:00",
          "link": "https://arxiv.org/abs/2506.20407v1",
          "size": "2122kb",
          "version": "v1"
        },
        {
          "date": "2025-06-27T21:41:48+00:00",
          "link": "https://arxiv.org/abs/2506.20407v2",
          "size": "2132kb",
          "version": "v2"
        }
      ],
      "title": "Fusing Radiomic Features with Deep Representations for Gestational Age Estimation in Fetal Ultrasound Images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20407",
        "HTML": "https://arxiv.org/html/2506.20407v2",
        "PDF": "https://arxiv.org/pdf/2506.20407"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20533",
      "abstract": "Robust subspace estimation is fundamental to many machine learning and data analysis tasks. Iteratively Reweighted Least Squares (IRLS) is an elegant and empirically effective approach to this problem, yet its theoretical properties remain poorly understood. This paper establishes that, under deterministic conditions, a variant of IRLS with dynamic smoothing regularization converges linearly to the underlying subspace from any initialization. We extend these guarantees to affine subspace estimation, a setting that lacks prior recovery theory. Additionally, we illustrate the practical benefits of IRLS through an application to low-dimensional neural network training. Our results provide the first global convergence guarantees for IRLS in robust subspace recovery and, more broadly, for nonconvex IRLS on a Riemannian manifold.",
      "authors": [
        "Gilad Lerman",
        "Kang Li",
        "Tyler Maunu",
        "Teng Zhang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (stat.ML)",
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T15:23:32+00:00",
          "link": "https://arxiv.org/abs/2506.20533v1",
          "size": "5435kb",
          "version": "v1"
        },
        {
          "date": "2025-06-29T13:53:45+00:00",
          "link": "https://arxiv.org/abs/2506.20533v2",
          "size": "5419kb",
          "version": "v2"
        }
      ],
      "title": "Global Convergence of Iteratively Reweighted Least Squares for Robust Subspace Recovery",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20533",
        "HTML": "https://arxiv.org/html/2506.20533v2",
        "PDF": "https://arxiv.org/pdf/2506.20533"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.20909",
      "abstract": "This paper explores multiple closely related themes: bounding the complexity of Diophantine equations over the integers and developing mathematical proofs in parallel with formal theorem provers.\n  Hilbert's Tenth Problem (H10) asks about the decidability of Diophantine equations and has been answered negatively by Davis, Putnam, Robinson and Matiyasevich. It is natural to ask for which subclasses of Diophantine equations H10 remains undecidable. Such subclasses can be defined in terms of universal pairs: bounds on the number of variables $\\nu$ and degree $\\delta$ such that all Diophantine equations can be rewritten in at most this complexity. Our work develops explicit universal pairs $(\\nu, \\delta)$ for integer unknowns, achieving new bounds that cannot be obtained by naive translations from known results over $\\mathbb N$.\n  In parallel, we have conducted a formal verification of our results using the proof assistant Isabelle. While formal proof verification has traditionally been applied a posteriori to known results, this project integrates formalization into the discovery and development process. In a final section, we describe key insights gained from this unusual approach and its implications for mathematical practice. Our work contributes both to the study of Diophantine equations and to the broader question of how mathematics is conducted in the 21st century.",
      "authors": [
        "Jonas Bayer",
        "Marco David",
        "Malte Hassler",
        "Yuri Matiyasevich",
        "Dierk Schleicher"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Number Theory (math.NT)",
        "Logic in Computer Science (cs.LO)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T00:30:24+00:00",
          "link": "https://arxiv.org/abs/2506.20909v1",
          "size": "58kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T02:22:49+00:00",
          "link": "https://arxiv.org/abs/2506.20909v2",
          "size": "63kb",
          "version": "v2"
        }
      ],
      "title": "Diophantine Equations over $\\mathbb Z$: Universal Bounds and Parallel Formalization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20909",
        "HTML": "https://arxiv.org/html/2506.20909v2",
        "PDF": "https://arxiv.org/pdf/2506.20909"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21448",
      "abstract": "While end-to-end video-to-audio generation has greatly improved, producing high-fidelity audio that authentically captures the nuances of visual content remains challenging. Like professionals in the creative industries, such generation requires sophisticated reasoning about items such as visual dynamics, acoustic environments, and temporal relationships. We present ThinkSound, a novel framework that leverages Chain-of-Thought (CoT) reasoning to enable stepwise, interactive audio generation and editing for videos. Our approach decomposes the process into three complementary stages: foundational foley generation that creates semantically coherent soundscapes, interactive object-centric refinement through precise user interactions, and targeted editing guided by natural language instructions. At each stage, a multimodal large language model generates contextually aligned CoT reasoning that guides a unified audio foundation model. Furthermore, we introduce AudioCoT, a comprehensive dataset with structured reasoning annotations that establishes connections between visual content, textual descriptions, and sound synthesis. Experiments demonstrate that ThinkSound achieves state-of-the-art performance in video-to-audio generation across both audio metrics and CoT metrics and excels in out-of-distribution Movie Gen Audio benchmark. The demo page is available at https://ThinkSound-Project.github.io.",
      "authors": [
        "Huadai Liu",
        "Jialei Wang",
        "Kaicheng Luo",
        "Wen Wang",
        "Qian Chen",
        "Zhou Zhao",
        "Wei Xue"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-26T16:32:06+00:00",
          "link": "https://arxiv.org/abs/2506.21448v1",
          "size": "4503kb",
          "version": "v1"
        },
        {
          "date": "2025-06-28T04:59:30+00:00",
          "link": "https://arxiv.org/abs/2506.21448v2",
          "size": "4503kb",
          "version": "v2"
        }
      ],
      "title": "ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21448",
        "HTML": "https://arxiv.org/html/2506.21448v2",
        "PDF": "https://arxiv.org/pdf/2506.21448"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.22397",
      "abstract": "Fluorescence microscopy is a major driver of scientific progress in the life sciences. Although high-end confocal microscopes are capable of filtering out-of-focus light, cheaper and more accessible microscopy modalities, such as widefield microscopy, can not, which consequently leads to hazy image data. Computational dehazing is trying to combine the best of both worlds, leading to cheap microscopy but crisp-looking images. The perception-distortion trade-off tells us that we can optimize either for data fidelity, e.g. low MSE or high PSNR, or for data realism, measured by perceptual metrics such as LPIPS or FID. Existing methods either prioritize fidelity at the expense of realism, or produce perceptually convincing results that lack quantitative accuracy. In this work, we propose HazeMatching, a novel iterative method for dehazing light microscopy images, which effectively balances these objectives. Our goal was to find a balanced trade-off between the fidelity of the dehazing results and the realism of individual predictions (samples). We achieve this by adapting the conditional flow matching framework by guiding the generative process with a hazy observation in the conditional velocity field. We evaluate HazeMatching on 5 datasets, covering both synthetic and real data, assessing both distortion and perceptual quality. Our method is compared against 7 baselines, achieving a consistent balance between fidelity and realism on average. Additionally, with calibration analysis, we show that HazeMatching produces well-calibrated predictions. Note that our method does not need an explicit degradation operator to exist, making it easily applicable on real microscopy data. All data used for training and evaluation and our code will be publicly available under a permissive license.",
      "authors": [
        "Anirban Ray",
        "Ashesh",
        "Florian Jug"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Artificial Intelligence (cs.AI)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-27T17:10:43+00:00",
          "link": "https://arxiv.org/abs/2506.22397v1",
          "size": "2545kb",
          "version": "v1"
        },
        {
          "date": "2025-06-30T12:15:48+00:00",
          "link": "https://arxiv.org/abs/2506.22397v2",
          "size": "24446kb",
          "version": "v2"
        }
      ],
      "title": "Dehazing Light Microscopy Images with Guided Conditional Flow Matching: finding a sweet spot between fidelity and realism",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.22397",
        "PDF": "https://arxiv.org/pdf/2506.22397"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "The paper is focused on computational methods for dehazing light microscopy images and does not address any aspects of LLM training data collection, construction, or processing."
      },
      "source": "arXiv"
    },
    {
      "id": "2305.09957",
      "abstract": "It is well known that artificial neural networks initialized from independent and identically distributed priors converge to Gaussian processes in the limit of a large number of neurons per hidden layer. In this work we prove an analogous result for Quantum Neural Networks (QNNs). Namely, we show that the outputs of certain models based on Haar random unitary or orthogonal deep QNNs converge to Gaussian processes in the limit of large Hilbert space dimension $d$. The derivation of this result is more nuanced than in the classical case due to the role played by the input states, the measurement observable, and the fact that the entries of unitary matrices are not independent. Then, we show that the efficiency of predicting measurements at the output of a QNN using Gaussian process regression depends on the observable's bodyness. Furthermore, our theorems imply that the concentration of measure phenomenon in Haar random QNNs is worse than previously thought, as we prove that expectation values and gradients concentrate as $\\mathcal{O}\\left(\\frac{1}{e^d \\sqrt{d}}\\right)$. Finally, we discuss how our results improve our understanding of concentration in $t$-designs.",
      "authors": [
        "Diego Garc\\'ia-Mart\\'in",
        "Martin Larocca",
        "M. Cerezo"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Quantum Physics (quant-ph)",
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-17T05:32:45+00:00",
          "link": "https://arxiv.org/abs/2305.09957v1",
          "size": "1770kb",
          "version": "v1"
        },
        {
          "date": "2023-11-09T23:22:07+00:00",
          "link": "https://arxiv.org/abs/2305.09957v2",
          "size": "1800kb",
          "version": "v2"
        },
        {
          "date": "2024-11-20T01:12:04+00:00",
          "link": "https://arxiv.org/abs/2305.09957v3",
          "size": "2075kb",
          "version": "v3"
        }
      ],
      "title": "Quantum neural networks form Gaussian processes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.09957",
        "PDF": "https://arxiv.org/pdf/2305.09957"
      },
      "tasks": [
        "Form",
        "Gaussian Processes"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.22277",
      "abstract": "Common factors and microcounseling skills are critical to the effectiveness of psychotherapy. Understanding and measuring these elements provides valuable insights into therapeutic processes and outcomes. However, automatic identification of these change principles from textual data remains challenging due to the nuanced and context-dependent nature of therapeutic dialogue. This paper introduces CFiCS, a hierarchical classification framework integrating graph machine learning with pretrained contextual embeddings. We represent common factors, intervention concepts, and microcounseling skills as a heterogeneous graph, where textual information from ClinicalBERT enriches each node. This structure captures both the hierarchical relationships (e.g., skill-level nodes linking to broad factors) and the semantic properties of therapeutic concepts. By leveraging graph neural networks, CFiCS learns inductive node embeddings that generalize to unseen text samples lacking explicit connections. Our results demonstrate that integrating ClinicalBERT node features and graph structure significantly improves classification performance, especially in fine-grained skill prediction. CFiCS achieves substantial gains in both micro and macro F1 scores across all tasks compared to baselines, including random forests, BERT-based multi-task models, and graph-based methods.",
      "authors": [
        "Fabian Schmidt",
        "Karin Hammerfald",
        "Henrik Haaland Jahren",
        "Vladimir Vlassov"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-28T09:46:08+00:00",
          "link": "https://arxiv.org/abs/2503.22277v1",
          "size": "10006kb",
          "version": "v1"
        }
      ],
      "title": "CFiCS: Graph-Based Classification of Common Factors and Microcounseling Skills",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.22277",
        "HTML": "https://arxiv.org/html/2503.22277",
        "PDF": "https://arxiv.org/pdf/2503.22277"
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/smidtfab/CFiCS"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.08968",
      "abstract": "When a network slice spans multiple technology domains, it is crucial for each domain to uphold the End-to-End (E2E) Service Level Agreement (SLA) associated with the slice. Consequently, the E2E SLA must be properly decomposed into partial SLAs that are assigned to each domain involved. In a network slice management system with a two-level architecture, comprising an E2E service orchestrator and local domain controllers, we consider that the orchestrator has access only to historical data regarding the responses of local controllers to previous requests, and this information is used to construct a risk model for each domain. In this study, we extend our previous work by investigating the dynamic nature of real-world systems and introducing an online learning-decomposition framework to tackle the dynamicity. We propose a framework that continuously updates the risk models based on the most recent feedback. This approach leverages key components such as online gradient descent and FIFO memory buffers, which enhance the stability and robustness of the overall process. Our empirical study on an analytic model-based simulator demonstrates that the proposed framework outperforms the state-of-the-art static approach, delivering more accurate and resilient SLA decomposition under varying conditions and data limitations. Furthermore, we provide a comprehensive complexity analysis of the proposed solution.",
      "authors": [
        "Cyril Shih-Huan Hsu",
        "Danny De Vleeschauwer",
        "Chrysa Papagianni",
        "Paola Grosso"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Networking and Internet Architecture (cs.NI)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-16T18:34:11+00:00",
          "link": "https://arxiv.org/abs/2408.08968v1",
          "size": "335kb",
          "version": "v1"
        },
        {
          "date": "2024-08-20T11:17:56+00:00",
          "link": "https://arxiv.org/abs/2408.08968v2",
          "size": "335kb",
          "version": "v2"
        },
        {
          "date": "2024-12-05T11:01:30+00:00",
          "link": "https://arxiv.org/abs/2408.08968v3",
          "size": "405kb",
          "version": "v3"
        },
        {
          "date": "2025-04-11T16:19:31+00:00",
          "link": "https://arxiv.org/abs/2408.08968v4",
          "size": "549kb",
          "version": "v4"
        },
        {
          "date": "2025-06-07T08:59:14+00:00",
          "link": "https://arxiv.org/abs/2408.08968v5",
          "size": "550kb",
          "version": "v5"
        }
      ],
      "title": "Online SLA Decomposition: Enabling Real-Time Adaptation to Evolving Network Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.08968",
        "HTML": "https://arxiv.org/html/2408.08968",
        "PDF": "https://arxiv.org/pdf/2408.08968"
      },
      "tasks": [
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.03399",
      "abstract": "We call a pair of distinct prime powers $(q_1,q_2) = (p_1^{a_1},p_2^{a_2})$ a Hasse pair if $|\\sqrt{q_1}-\\sqrt{q_2}| \\leq 1$. For such pairs, we study the relation between the set $\\mathcal{E}_1$ of isomorphism classes of elliptic curves defined over $\\mathbb{F}_{q_1}$ with $q_2$ points, and the set $\\mathcal{E}_2$ of isomorphism classes of elliptic curves over $\\mathbb{F}_{q_2}$ with $q_1$ points. When both families $\\mathcal{E}_i$ contain only ordinary elliptic curves, we prove that their isogeny graphs are isomorphic. When supersingular curves are involved, we describe which curves might belong to these sets. We also show that if both the $q_i$'s are odd and $\\mathcal{E}_1 \\cup \\mathcal{E}_2 \\neq \\emptyset$, then $\\mathcal{E}_1 \\cup \\mathcal{E}_2$ always contains an ordinary elliptic curve. Conversely, if $q_1$ is even, then $\\mathcal{E}_1 \\cup \\mathcal{E}_2$ may contain only supersingular curves precisely when $q_2$ is a given power of a Fermat or a Mersenne prime. In the case of odd Hasse pairs, we could not rule out the possibility of an empty union $\\mathcal{E}_1 \\cup \\mathcal{E}_2$, but we give necessary conditions for such a case to exist. In an appendix, Moree and Sofos consider how frequently Hasse pairs occur using analytic number theory, making a connection with Andrica's conjecture on the difference between consecutive primes.",
      "authors": [
        "Eleni Agathocleous",
        "Antoine Joux",
        "Daniele Taufer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Number Theory (math.NT)",
        "Cryptography and Security (cs.CR)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-05T15:59:30+00:00",
          "link": "https://arxiv.org/abs/2406.03399v1",
          "size": "33kb",
          "version": "v1"
        }
      ],
      "title": "Elliptic curves over Hasse pairs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.03399",
        "HTML": "https://arxiv.org/html/2406.03399",
        "PDF": "https://arxiv.org/pdf/2406.03399"
      },
      "source": "arXiv"
    },
    {
      "id": "2501.10736",
      "abstract": "Semi-supervised learning offers an appealing solution for remote sensing (RS) image segmentation to relieve the burden of labor-intensive pixel-level labeling. However, RS images pose unique challenges, including rich multi-scale features and high inter-class similarity. To address these problems, this paper proposes a novel semi-supervised Multi-Scale Uncertainty and Cross-Teacher-Student Attention (MUCA) model for RS image semantic segmentation tasks. Specifically, MUCA constrains the consistency among feature maps at different layers of the network by introducing a multi-scale uncertainty consistency regularization. It improves the multi-scale learning capability of semi-supervised algorithms on unlabeled data. Additionally, MUCA utilizes a Cross-Teacher-Student attention mechanism to guide the student network, guiding the student network to construct more discriminative feature representations through complementary features from the teacher network. This design effectively integrates weak and strong augmentations (WA and SA) to further boost segmentation performance. To verify the effectiveness of our model, we conduct extensive experiments on ISPRS-Potsdam and LoveDA datasets. The experimental results show the superiority of our method over state-of-the-art semi-supervised methods. Notably, our model excels in distinguishing highly similar objects, showcasing its potential for advancing semi-supervised RS image segmentation tasks.",
      "authors": [
        "Shanwen Wang",
        "Xin Sun",
        "Changrui Chen",
        "Danfeng Hong",
        "Jungong Han"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-18T11:57:20+00:00",
          "link": "https://arxiv.org/abs/2501.10736v1",
          "size": "2695kb",
          "version": "v1"
        },
        {
          "date": "2025-03-13T14:18:36+00:00",
          "link": "https://arxiv.org/abs/2501.10736v2",
          "size": "6272kb",
          "version": "v2"
        }
      ],
      "title": "Semi-supervised Semantic Segmentation for Remote Sensing Images via Multi-scale Uncertainty Consistency and Cross-Teacher-Student Attention",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.10736",
        "PDF": "https://arxiv.org/pdf/2501.10736"
      },
      "tasks": [
        "Image Segmentation",
        "Segmentation",
        "Semantic Segmentation",
        "Semi-Supervised Semantic Segmentation"
      ],
      "repo_urls": [
        "https://github.com/wangshanwen001/rs-muca"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.11247",
      "abstract": "Accurate and reliable link quality prediction (LQP) is crucial for optimizing network performance, ensuring communication stability, and enhancing user experience in wireless communications. However, LQP faces significant challenges due to the dynamic and lossy nature of wireless links, which are influenced by interference, multipath effects, fading, and blockage. In this paper, we propose GAT-LLM, a novel multivariate wireless link quality prediction model that combines Large Language Models (LLMs) with Graph Attention Networks (GAT) to enable accurate and reliable multivariate LQP of wireless communications. By framing LQP as a time series prediction task and appropriately preprocessing the input data, we leverage LLMs to improve the accuracy of link quality prediction. To address the limitations of LLMs in multivariate prediction due to typically handling one-dimensional data, we integrate GAT to model interdependencies among multiple variables across different protocol layers, enhancing the model's ability to handle complex dependencies. Experimental results demonstrate that GAT-LLM significantly improves the accuracy and robustness of link quality prediction, particularly in multi-step prediction scenarios.",
      "authors": [
        "Zhuangzhuang Yan",
        "Xinyu Gu",
        "Shilong Fan",
        "Zhenyu Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-20T03:21:20+00:00",
          "link": "https://arxiv.org/abs/2501.11247v1",
          "size": "304kb",
          "version": "v1"
        }
      ],
      "title": "Multivariate Wireless Link Quality Prediction Based on Pre-trained Large Language Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.11247",
        "HTML": "https://arxiv.org/html/2501.11247",
        "PDF": "https://arxiv.org/pdf/2501.11247"
      },
      "tasks": [
        "Graph Attention",
        "Prediction",
        "Time Series Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2212.14091",
      "abstract": "We prove an infinite $(p,q)$-theorem for piercing fat compact convex sets in $\\RR^d$ with $k$-flats. Additionally, we develop a new framework through which infinite $(p,q)$-theorems concerning compact sets and $k$-flats can be extended to their 'colorful' variants. Further, we show that the existence of an infinite $(p,q)$-theorem does not necessarily imply the existence of the corresponding finite $(p,q)$-theorem.",
      "authors": [
        "Sutanoya Chakraborty and Arijit Ghosh and Soumi Nandi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Combinatorics (math.CO)",
        "Computational Geometry (cs.CG)"
      ],
      "submission_historys": [
        {
          "date": "2022-12-28T20:41:36+00:00",
          "link": "https://arxiv.org/abs/2212.14091v1",
          "size": "174kb",
          "version": "v1"
        },
        {
          "date": "2023-06-04T13:46:24+00:00",
          "link": "https://arxiv.org/abs/2212.14091v2",
          "size": "431kb",
          "version": "v2"
        },
        {
          "date": "2023-06-28T19:56:00+00:00",
          "link": "https://arxiv.org/abs/2212.14091v3",
          "size": "643kb",
          "version": "v3"
        },
        {
          "date": "2024-01-06T15:33:41+00:00",
          "link": "https://arxiv.org/abs/2212.14091v4",
          "size": "569kb",
          "version": "v4"
        },
        {
          "date": "2024-05-23T17:49:05+00:00",
          "link": "https://arxiv.org/abs/2212.14091v5",
          "size": "1256kb",
          "version": "v5"
        },
        {
          "date": "2025-03-23T10:17:28+00:00",
          "link": "https://arxiv.org/abs/2212.14091v6",
          "size": "37kb",
          "version": "v6"
        },
        {
          "date": "2025-04-15T12:07:10+00:00",
          "link": "https://arxiv.org/abs/2212.14091v7",
          "size": "36kb",
          "version": "v7"
        },
        {
          "date": "2025-06-28T12:32:09+00:00",
          "link": "https://arxiv.org/abs/2212.14091v8",
          "size": "37kb",
          "version": "v8"
        }
      ],
      "title": "Finite k-Transversals of Infinite Families of Fat Convex Sets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2212.14091",
        "HTML": "https://arxiv.org/html/2212.14091",
        "PDF": "https://arxiv.org/pdf/2212.14091"
      },
      "source": "arXiv"
    },
    {
      "id": "2408.15256",
      "abstract": "Past ontology requirements engineering (ORE) has primarily relied on manual methods, such as interviews and collaborative forums, to gather user requirements from domain experts, especially in large projects. Current OntoChat offers a framework for ORE that utilises large language models (LLMs) to streamline the process through four key functions: user story creation, competency question (CQ) extraction, CQ filtration and analysis, and ontology testing support. In OntoChat, users are expected to prompt the chatbot to generate user stories. However, preliminary evaluations revealed that they struggle to do this effectively. To address this issue, we experimented with a research method called participatory prompting, which involves researcher-mediated interactions to help users without deep knowledge of LLMs use the chatbot more effectively. This participatory prompting user study produces pre-defined prompt templates based on user queries, focusing on creating and refining personas, goals, scenarios, sample data, and data resources for user stories. These refined user stories will subsequently be converted into CQs.",
      "authors": [
        "Yihang Zhao",
        "Bohui Zhang",
        "Xi Hu",
        "Shuyin Ouyang",
        "Jongmo Kim",
        "Nitisha Jain",
        "Jacopo de Berardinis",
        "Albert Mero\\~no-Pe\\~nuela",
        "Elena Simperl"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-08-09T19:21:14+00:00",
          "link": "https://arxiv.org/abs/2408.15256v1",
          "size": "701kb",
          "version": "v1"
        },
        {
          "date": "2024-08-29T09:34:48+00:00",
          "link": "https://arxiv.org/abs/2408.15256v2",
          "size": "1328kb",
          "version": "v2"
        },
        {
          "date": "2024-09-18T16:09:40+00:00",
          "link": "https://arxiv.org/abs/2408.15256v3",
          "size": "1328kb",
          "version": "v3"
        }
      ],
      "title": "Improving Ontology Requirements Engineering with OntoChat and Participatory Prompting",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.15256",
        "HTML": "https://arxiv.org/html/2408.15256",
        "PDF": "https://arxiv.org/pdf/2408.15256"
      },
      "tasks": [
        "Chatbot"
      ],
      "repo_urls": [
        "https://github.com/king-s-knowledge-graph-lab/ontochat"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.17101",
      "abstract": "We look at consciousness through the lens of Theoretical Computer Science, a branch of mathematics that studies computation under resource limitations, distinguishing functions that are efficiently computable from those that are not. From this perspective, we develop a formal machine model for consciousness. The model is inspired by Alan Turing's simple yet powerful model of computation and Bernard Baars' theater model of consciousness. Though extremely simple, the model (1) aligns at a high level with many of the major scientific theories of human and animal consciousness, (2) provides explanations at a high level for many phenomena associated with consciousness, (3) gives insight into how a machine can have subjective consciousness, and (4) is clearly buildable. This combination supports our claim that machine consciousness is not only plausible but inevitable.",
      "authors": [
        "Lenore Blum and Manuel Blum"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-25T18:38:54+00:00",
          "link": "https://arxiv.org/abs/2403.17101v1",
          "size": "1010kb",
          "version": "v1"
        },
        {
          "date": "2024-04-19T17:28:44+00:00",
          "link": "https://arxiv.org/abs/2403.17101v2",
          "size": "1023kb",
          "version": "v2"
        },
        {
          "date": "2024-05-16T23:07:04+00:00",
          "link": "https://arxiv.org/abs/2403.17101v3",
          "size": "866kb",
          "version": "v3"
        },
        {
          "date": "2024-06-10T22:29:49+00:00",
          "link": "https://arxiv.org/abs/2403.17101v4",
          "size": "886kb",
          "version": "v4"
        },
        {
          "date": "2024-07-27T20:52:55+00:00",
          "link": "https://arxiv.org/abs/2403.17101v5",
          "size": "940kb",
          "version": "v5"
        },
        {
          "date": "2024-08-29T20:14:14+00:00",
          "link": "https://arxiv.org/abs/2403.17101v6",
          "size": "1012kb",
          "version": "v6"
        },
        {
          "date": "2024-09-16T20:58:36+00:00",
          "link": "https://arxiv.org/abs/2403.17101v7",
          "size": "1100kb",
          "version": "v7"
        },
        {
          "date": "2024-11-13T17:14:29+00:00",
          "link": "https://arxiv.org/abs/2403.17101v8",
          "size": "1166kb",
          "version": "v8"
        },
        {
          "date": "2025-01-15T02:23:44+00:00",
          "link": "https://arxiv.org/abs/2403.17101v9",
          "size": "1538kb",
          "version": "v9"
        },
        {
          "date": "2025-02-18T17:58:13+00:00",
          "link": "https://arxiv.org/abs/2403.17101v10",
          "size": "1487kb",
          "version": "v10"
        },
        {
          "date": "2025-04-06T21:09:23+00:00",
          "link": "https://arxiv.org/abs/2403.17101v11",
          "size": "973kb",
          "version": "v11"
        },
        {
          "date": "2025-06-28T23:32:11+00:00",
          "link": "https://arxiv.org/abs/2403.17101v12",
          "size": "1405kb",
          "version": "v12"
        }
      ],
      "title": "AI Consciousness is Inevitable: A Theoretical Computer Science Perspective",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.17101",
        "PDF": "https://arxiv.org/pdf/2403.17101"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2402.09146",
      "abstract": "In this paper, we present a novel framework for enhancing the performance of Quanvolutional Neural Networks (QuNNs) by introducing trainable quanvolutional layers and addressing the critical challenges associated with them. Traditional quanvolutional layers, although beneficial for feature extraction, have largely been static, offering limited adaptability. Unlike state-of-the-art, our research overcomes this limitation by enabling training within these layers, significantly increasing the flexibility and potential of QuNNs. However, the introduction of multiple trainable quanvolutional layers induces complexities in gradient-based optimization, primarily due to the difficulty in accessing gradients across these layers. To resolve this, we propose a novel architecture, Residual Quanvolutional Neural Networks (ResQuNNs), leveraging the concept of residual learning, which facilitates the flow of gradients by adding skip connections between layers. By inserting residual blocks between quanvolutional layers, we ensure enhanced gradient access throughout the network, leading to improved training performance. Moreover, we provide empirical evidence on the strategic placement of these residual blocks within QuNNs. Through extensive experimentation, we identify an efficient configuration of residual blocks, which enables gradients across all the layers in the network that eventually results in efficient training. Our findings suggest that the precise location of residual blocks plays a crucial role in maximizing the performance gains in QuNNs. Our results mark a substantial step forward in the evolution of quantum deep learning, offering new avenues for both theoretical development and practical quantum computing applications.",
      "authors": [
        "Muhammad Kashif",
        "Muhammad Shafique"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Quantum Physics (quant-ph)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-14T12:55:28+00:00",
          "link": "https://arxiv.org/abs/2402.09146v1",
          "size": "2857kb",
          "version": "v1"
        },
        {
          "date": "2024-05-01T10:16:59+00:00",
          "link": "https://arxiv.org/abs/2402.09146v2",
          "size": "2310kb",
          "version": "v2"
        },
        {
          "date": "2024-05-19T18:32:15+00:00",
          "link": "https://arxiv.org/abs/2402.09146v3",
          "size": "2310kb",
          "version": "v3"
        },
        {
          "date": "2024-08-06T14:30:52+00:00",
          "link": "https://arxiv.org/abs/2402.09146v4",
          "size": "2337kb",
          "version": "v4"
        },
        {
          "date": "2024-09-02T14:38:01+00:00",
          "link": "https://arxiv.org/abs/2402.09146v5",
          "size": "1640kb",
          "version": "v5"
        }
      ],
      "title": "ResQuNNs:Towards Enabling Deep Learning in Quantum Convolution Neural Networks",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.09146",
        "HTML": "https://arxiv.org/html/2402.09146",
        "PDF": "https://arxiv.org/pdf/2402.09146"
      },
      "tasks": [
        "Deep Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.10481",
      "abstract": "Causal learning tackles the computationally demanding task of estimating causal graphs. This paper introduces a new divide-and-conquer approach for causal graph learning, called DCILP. In the divide phase, the Markov blanket MB($X_i$) of each variable $X_i$ is identified, and causal learning subproblems associated with each MB($X_i$) are independently addressed in parallel. This approach benefits from a more favorable ratio between the number of data samples and the number of variables considered. In counterpart, it can be adversely affected by the presence of hidden confounders, as variables external to MB($X_i$) might influence those within it. The reconciliation of the local causal graphs generated during the divide phase is a challenging combinatorial optimization problem, especially in large-scale applications. The main novelty of DCILP is an original formulation of this reconciliation as an integer linear programming (ILP) problem, which can be delegated and efficiently handled by an ILP solver. Through experiments on medium to large scale graphs, and comparisons with state-of-the-art methods, DCILP demonstrates significant improvements in terms of computational complexity, while preserving the learning accuracy on real-world problem and suffering at most a slight loss of accuracy on synthetic problems.",
      "authors": [
        "Shuyu Dong",
        "Mich\\`ele Sebag",
        "Kento Uemura",
        "Akito Fujii",
        "Shuang Chang",
        "Yusuke Koyanagi",
        "Koji Maruhashi"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Optimization and Control (math.OC)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-15T03:17:48+00:00",
          "link": "https://arxiv.org/abs/2406.10481v1",
          "size": "673kb",
          "version": "v1"
        },
        {
          "date": "2025-03-01T01:45:44+00:00",
          "link": "https://arxiv.org/abs/2406.10481v2",
          "size": "203kb",
          "version": "v2"
        }
      ],
      "title": "DCILP: A Distributed Approach for Large-Scale Causal Structure Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.10481",
        "HTML": "https://arxiv.org/html/2406.10481",
        "PDF": "https://arxiv.org/pdf/2406.10481"
      },
      "tasks": [
        "Causal Discovery",
        "Combinatorial Optimization",
        "Graph Learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2402.11266",
      "abstract": "We investigate a filtered Lie-Trotter splitting scheme for the ``good\" Boussinesq equation and derive an error estimate for initial data with very low regularity. Through the use of discrete Bourgain spaces, our analysis extends to initial data in $H^{s}$ for $0<s\\leq 2$, overcoming the constraint of $s>1/2$ imposed by the bilinear estimate in smooth Sobolev spaces. We establish convergence rates of order $\\tau^{s/2}$ in $L^2$ for such levels of regularity. Our analytical findings are supported by numerical experiments.",
      "authors": [
        "Lun Ji",
        "Hang Li",
        "Alexander Ostermann",
        "Chunmei Su"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-17T12:52:21+00:00",
          "link": "https://arxiv.org/abs/2402.11266v1",
          "size": "277kb",
          "version": "v1"
        },
        {
          "date": "2024-08-20T03:13:21+00:00",
          "link": "https://arxiv.org/abs/2402.11266v2",
          "size": "278kb",
          "version": "v2"
        }
      ],
      "title": "Filtered Lie-Trotter splitting for the \"good\" Boussinesq equation: low regularity error estimates",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.11266",
        "HTML": "https://arxiv.org/html/2402.11266",
        "PDF": "https://arxiv.org/pdf/2402.11266"
      },
      "source": "arXiv"
    },
    {
      "id": "2504.04029",
      "abstract": "Event cameras are emerging vision sensors, whose noise is challenging to characterize. Existing denoising methods for event cameras consider other tasks such as motion estimation separately (i.e., sequentially after denoising). However, motion is an intrinsic part of event data, since scene edges cannot be sensed without motion. This work proposes, to the best of our knowledge, the first method that simultaneously estimates motion in its various forms (e.g., ego-motion, optical flow) and noise. The method is flexible, as it allows replacing the 1-step motion estimation of the widely-used Contrast Maximization framework with any other motion estimator, such as deep neural networks. The experiments show that the proposed method achieves state-of-the-art results on the E-MLB denoising benchmark and competitive results on the DND21 benchmark, while showing its efficacy on motion estimation and intensity reconstruction tasks. We believe that the proposed approach contributes to strengthening the theory of event-data denoising, as well as impacting practical denoising use-cases, as we release the code upon acceptance. Project page: https://github.com/tub-rip/ESMD",
      "authors": [
        "Shintaro Shiba",
        "Yoshimitsu Aoki",
        "Guillermo Gallego"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-05T02:47:40+00:00",
          "link": "https://arxiv.org/abs/2504.04029v1",
          "size": "6723kb",
          "version": "v1"
        }
      ],
      "title": "Simultaneous Motion And Noise Estimation with Event Cameras",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.04029",
        "HTML": "https://arxiv.org/html/2504.04029",
        "PDF": "https://arxiv.org/pdf/2504.04029"
      },
      "tasks": [
        "Denoising",
        "Motion Estimation",
        "Noise Estimation",
        "Optical Flow Estimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2311.00126",
      "abstract": "Addressing safe and efficient interaction between connected and automated vehicles (CAVs) and human-driven vehicles in a mixed-traffic environment has attracted considerable attention. In this paper, we develop a framework for stochastic time-optimal trajectory planning for coordinating multiple CAVs in mixed-traffic merging scenarios. We present a data-driven model, combining Newell's car-following model with Bayesian linear regression, for efficiently learning the driving behavior of human drivers online. Using the prediction model and uncertainty quantification, a stochastic time-optimal control problem is formulated to find robust trajectories for CAVs. We also integrate a replanning mechanism that determines when deriving new trajectories for CAVs is needed based on the accuracy of the Bayesian linear regression predictions. Finally, we demonstrate the performance of our proposed framework using a realistic simulation environment.",
      "authors": [
        "Viet-Anh Le",
        "Behdad Chalaki",
        "Filippos N. Tzortzoglou",
        "and Andreas A. Malikopoulos"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-31T19:56:39+00:00",
          "link": "https://arxiv.org/abs/2311.00126v1",
          "size": "1194kb",
          "version": "v1"
        }
      ],
      "title": "Stochastic Time-Optimal Trajectory Planning for Connected and Automated Vehicles in Mixed-Traffic Merging Scenarios",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.00126",
        "PDF": "https://arxiv.org/pdf/2311.00126"
      },
      "tasks": [
        "regression",
        "Trajectory Planning",
        "Uncertainty Quantification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.15127",
      "abstract": "Social robot navigation is an evolving research field that aims to find efficient strategies to safely navigate dynamic environments populated by humans. A critical challenge in this domain is the accurate modeling of human motion, which directly impacts the design and evaluation of navigation algorithms. This paper presents a comparative study of two popular categories of human motion models used in social robot navigation, namely velocity-based models and force-based models. A system-theoretic representation of both model types is presented, which highlights their common feedback structure, although with different state variables. Several navigation policies based on reinforcement learning are trained and tested in various simulated environments involving pedestrian crowds modeled with these approaches. A comparative study is conducted to assess performance across multiple factors, including human motion model, navigation policy, scenario complexity and crowd density. The results highlight advantages and challenges of different approaches to modeling human behavior, as well as their role during training and testing of learning-based navigation policies. The findings offer valuable insights and guidelines for selecting appropriate human motion models when designing socially-aware robot navigation systems.",
      "authors": [
        "Tommaso Van Der Meer",
        "Andrea Garulli",
        "Antonio Giannitrapani",
        "Renato Quartullo"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Robotics (cs.RO)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-19T11:41:22+00:00",
          "link": "https://arxiv.org/abs/2503.15127v1",
          "size": "874kb",
          "version": "v1"
        }
      ],
      "title": "A Comparative Study of Human Motion Models in Reinforcement Learning Algorithms for Social Robot Navigation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.15127",
        "HTML": "https://arxiv.org/html/2503.15127",
        "PDF": "https://arxiv.org/pdf/2503.15127"
      },
      "repo_urls": [
        "https://github.com/TommasoVandermeer/Social-Navigation-PyEnvs"
      ],
      "source": "arXiv"
    },
    {
      "id": "2203.02690",
      "abstract": "$\\ell_1$ based sparse regularization plays a central role in compressive sensing and image processing. In this paper, we propose $\\ell_1$DecNet, as an unfolded network derived from a variational decomposition model incorporating $\\ell_1$ related sparse regularization and solved by scaled alternating direction method of multipliers (ADMM). $\\ell_1$DecNet effectively decomposes an input image into a sparse feature and a learned dense feature, and thus helps the subsequent sparse feature related operations. Based on this, we develop $\\ell_1$DecNet+, a learnable architecture framework consisting of our $\\ell_1$DecNet and a segmentation module which operates over extracted sparse features instead of original images. This architecture combines well the benefits of mathematical modeling and data-driven approaches. To our best knowledge, this is the first study to incorporate mathematical image prior into feature extraction in segmentation network structures. Moreover, our $\\ell_1$DecNet+ framework can be easily extended to 3D case. We evaluate the effectiveness of $\\ell_1$DecNet+ on two commonly encountered sparse segmentation tasks: retinal vessel segmentation in medical image processing and pavement crack detection in industrial abnormality identification. Experimental results on different datasets demonstrate that, our $\\ell_1$DecNet+ architecture with various lightweight segmentation modules can achieve equal or better performance than their enlarged versions respectively. This leads to especially practical advantages on resource-limited devices.",
      "authors": [
        "Yumeng Ren (1 and 2)",
        "Yiming Gao (3)",
        "Chunlin Wu (1)",
        "Xue-cheng Tai (4) ((1) School of Mathematical Sciences",
        "Nankai University",
        "Tianjin",
        "China (2) Department of Mathematics",
        "City University of Hong Kong",
        "China (3) College of Science",
        "Nanjing University of Aeronautics and Astronautics",
        "Nanjing",
        "China (4) Norwegian Research Centre (NORCE)",
        "Bergen",
        "Norway)"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Optimization and Control (math.OC)"
      ],
      "submission_historys": [
        {
          "date": "2022-03-05T09:17:32+00:00",
          "link": "https://arxiv.org/abs/2203.02690v1",
          "size": "2264kb",
          "version": "v1"
        },
        {
          "date": "2024-06-16T02:15:56+00:00",
          "link": "https://arxiv.org/abs/2203.02690v2",
          "size": "16986kb",
          "version": "v2"
        }
      ],
      "title": "$\\ell_1$DecNet+: A new architecture framework by $\\ell_1$ decomposition and iteration unfolding for sparse feature segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2203.02690",
        "HTML": "https://arxiv.org/html/2203.02690",
        "PDF": "https://arxiv.org/pdf/2203.02690"
      },
      "tasks": [
        "Compressive Sensing",
        "Image Segmentation",
        "Medical Image Segmentation",
        "Retinal Vessel Segmentation",
        "Segmentation",
        "Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2408.00790",
      "abstract": "Weather disaster related emergency operations pose a great challenge to air mobility in both aircraft and airport operations, especially when the impact is gradually approaching. We propose an optimized framework for adjusting airport operational schedules for such pre-disaster scenarios. We first, aggregate operational data from multiple airports and then determine the optimal count of evacuation flights to maximize the impacted airport's outgoing capacity without impeding regular air traffic. We then propose a novel Neural Network (NN) accelerated Genetic Algorithm(GA) for evacuation planning. Our experiments show that integration yielded comparable results but with smaller computational overhead. We find that the utilization of a NN enhances the efficiency of a GA, facilitating more rapid convergence even when operating with a reduced population size. This effectiveness persists even when the model is trained on data from airports different from those under test.",
      "authors": [
        "Kamal Acharya",
        "Alvaro Velasquez",
        "Yongxin Liu",
        "Dahai Liu",
        "Liang Sun and Houbing Song"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-17T15:59:41+00:00",
          "link": "https://arxiv.org/abs/2408.00790v1",
          "size": "1070kb",
          "version": "v1"
        }
      ],
      "title": "Improving Air Mobility for Pre-Disaster Planning with Neural Network Accelerated Genetic Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2408.00790",
        "HTML": "https://arxiv.org/html/2408.00790",
        "PDF": "https://arxiv.org/pdf/2408.00790"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2311.16769",
      "abstract": "Computing Continuum (CC) systems are challenged to ensure the intricate requirements of each computational tier. Given the system's scale, the Service Level Objectives (SLOs) which are expressed as these requirements, must be broken down into smaller parts that can be decentralized. We present our framework for collaborative edge intelligence enabling individual edge devices to (1) develop a causal understanding of how to enforce their SLOs, and (2) transfer knowledge to speed up the onboarding of heterogeneous devices. Through collaboration, they (3) increase the scope of SLO fulfillment. We implemented the framework and evaluated a use case in which a CC system is responsible for ensuring Quality of Service (QoS) and Quality of Experience (QoE) during video streaming. Our results showed that edge devices required only ten training rounds to ensure four SLOs; furthermore, the underlying causal structures were also rationally explainable. The addition of new types of devices can be done a posteriori, the framework allowed them to reuse existing models, even though the device type had been unknown. Finally, rebalancing the load within a device cluster allowed individual edge devices to recover their SLO compliance after a network failure from 22% to 89%.",
      "authors": [
        "Boris Sedlak",
        "Victor Casamayor Pujol",
        "Praveen Kumar Donta",
        "Schahram Dustdar"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Performance (cs.PF)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2023-11-28T13:19:54+00:00",
          "link": "https://arxiv.org/abs/2311.16769v1",
          "size": "7143kb",
          "version": "v1"
        }
      ],
      "title": "Equilibrium in the Computing Continuum through Active Inference",
      "links": {
        "Abstract": "https://arxiv.org/abs/2311.16769",
        "PDF": "https://arxiv.org/pdf/2311.16769"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2402.15948",
      "abstract": "Motivated by optimization with differential equations, we consider optimization problems with Hilbert spaces as decision spaces. As a consequence of their infinite dimensionality, the numerical solution necessitates finite dimensional approximations and discretizations. We develop an approximation framework and demonstrate criticality measure-based error estimates. We consider criticality measures inspired by those used within optimization methods, such as semismooth Newton and (conditional) gradient methods. Furthermore, we show that our error estimates are order-optimal. Our findings augment existing distance-based error estimates, but do not rely on strong convexity or second-order sufficient optimality conditions. Moreover, our error estimates can be used for code verification and validation. We illustrate our theoretical convergence rates on linear, semilinear, and bilinear PDE-constrained optimization.",
      "authors": [
        "Danlin Li and Johannes Milz"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Numerical Analysis (cs.NA)",
        "Numerical Analysis (math.NA)"
      ],
      "submission_historys": [
        {
          "date": "2024-02-25T01:31:28+00:00",
          "link": "https://arxiv.org/abs/2402.15948v1",
          "size": "7293kb",
          "version": "v1"
        }
      ],
      "title": "Criticality measure-based error estimates for infinite dimensional optimization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2402.15948",
        "PDF": "https://arxiv.org/pdf/2402.15948"
      },
      "repo_urls": [
        "https://github.com/milzj/errorestimation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2504.15071",
      "abstract": "We introduce an extensive new dataset of MIDI files, created by transcribing audio recordings of piano performances into their constituent notes. The data pipeline we use is multi-stage, employing a language model to autonomously crawl and score audio recordings from the internet based on their metadata, followed by a stage of pruning and segmentation using an audio classifier. The resulting dataset contains over one million distinct MIDI files, comprising roughly 100,000 hours of transcribed audio. We provide an in-depth analysis of our techniques, offering statistical insights, and investigate the content by extracting metadata tags, which we also provide. Dataset available at https://github.com/loubbrad/aria-midi.",
      "authors": [
        "Louis Bradshaw",
        "Simon Colton"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-04-21T12:59:40+00:00",
          "link": "https://arxiv.org/abs/2504.15071v1",
          "size": "250kb",
          "version": "v1"
        }
      ],
      "title": "Aria-MIDI: A Dataset of Piano MIDI Files for Symbolic Music Modeling",
      "links": {
        "Abstract": "https://arxiv.org/abs/2504.15071",
        "HTML": "https://arxiv.org/html/2504.15071",
        "PDF": "https://arxiv.org/pdf/2504.15071"
      },
      "models": [
        {
          "model_path": "loubb/aria-medium-base",
          "downloads": "117",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/loubb/aria-medium-base"
        },
        {
          "model_path": "loubb/aria-medium-embedding",
          "downloads": "0",
          "likes": "0",
          "trending_score": "0.0",
          "link": "https://huggingface.co/loubb/aria-medium-embedding"
        }
      ],
      "repo_urls": [
        "https://github.com/loubbrad/aria-midi"
      ],
      "source": "arXiv"
    },
    {
      "id": "2411.03805",
      "abstract": "Generating discharge summaries is a crucial yet time-consuming task in clinical practice, essential for conveying pertinent patient information and facilitating continuity of care. Recent advancements in large language models (LLMs) have significantly enhanced their capability in understanding and summarizing complex medical texts. This research aims to explore how LLMs can alleviate the burden of manual summarization, streamline workflow efficiencies, and support informed decision-making in healthcare settings. Clinical notes from a cohort of 1,099 lung cancer patients were utilized, with a subset of 50 patients for testing purposes, and 102 patients used for model fine-tuning. This study evaluates the performance of multiple LLMs, including GPT-3.5, GPT-4, GPT-4o, and LLaMA 3 8b, in generating discharge summaries. Evaluation metrics included token-level analysis (BLEU, ROUGE-1, ROUGE-2, ROUGE-L) and semantic similarity scores between model-generated summaries and physician-written gold standards. LLaMA 3 8b was further tested on clinical notes of varying lengths to examine the stability of its performance. The study found notable variations in summarization capabilities among LLMs. GPT-4o and fine-tuned LLaMA 3 demonstrated superior token-level evaluation metrics, while LLaMA 3 consistently produced concise summaries across different input lengths. Semantic similarity scores indicated GPT-4o and LLaMA 3 as leading models in capturing clinical relevance. This study contributes insights into the efficacy of LLMs for generating discharge summaries, highlighting LLaMA 3's robust performance in maintaining clarity and relevance across varying clinical contexts. These findings underscore the potential of automated summarization tools to enhance documentation precision and efficiency, ultimately improving patient care and operational capability in healthcare settings.",
      "authors": [
        "Yiming Li",
        "Fang Li",
        "Kirk Roberts",
        "Licong Cui",
        "Cui Tao",
        "Hua Xu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-11-06T10:02:50+00:00",
          "link": "https://arxiv.org/abs/2411.03805v1",
          "size": "524kb",
          "version": "v1"
        }
      ],
      "title": "A Comparative Study of Recent Large Language Models on Generating Hospital Discharge Summaries for Lung Cancer Patients",
      "links": {
        "Abstract": "https://arxiv.org/abs/2411.03805",
        "PDF": "https://arxiv.org/pdf/2411.03805"
      },
      "tasks": [
        "Semantic Similarity",
        "Semantic Textual Similarity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2211.17182",
      "abstract": "The framework of linear parameter-varying (LPV) systems has shown to be a powerful tool for the design of controllers for complex nonlinear systems using linear tools. In this work, we derive novel methods that allow to synthesize LPV state-feedback controllers directly from only a single sequence of data and guarantee stability and performance of the closed-loop system. We show that if the measured open-loop data from the system satisfies a persistency of excitation condition, then the full open-loop and closed-loop input-scheduling-state behavior can be represented using only the data. With this representation we formulate data-driven analysis and synthesis problems, where the latter yields controllers that guarantee stability and performance in terms of infinite horizon quadratic cost, generalized $\\mathcal{H}_2$-norm and $\\ell_2$-gain of the closed-loop system. The controllers are synthesized by solving a semi-definite program. Additionally, we provide a synthesis method to handle noisy measurement data. Competitive performance of the proposed data-driven synthesis methods is demonstrated w.r.t. model-based synthesis in multiple simulation studies, including a nonlinear unbalanced disc system.",
      "authors": [
        "Chris Verhoek and Roland T\\'oth and Hossam S. Abbas"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2022-11-30T17:25:28+00:00",
          "link": "https://arxiv.org/abs/2211.17182v1",
          "size": "1758kb",
          "version": "v1"
        },
        {
          "date": "2023-11-02T12:55:34+00:00",
          "link": "https://arxiv.org/abs/2211.17182v2",
          "size": "1434kb",
          "version": "v2"
        },
        {
          "date": "2024-04-04T12:56:25+00:00",
          "link": "https://arxiv.org/abs/2211.17182v3",
          "size": "595kb",
          "version": "v3"
        },
        {
          "date": "2024-05-24T10:10:04+00:00",
          "link": "https://arxiv.org/abs/2211.17182v4",
          "size": "1231kb",
          "version": "v4"
        },
        {
          "date": "2024-12-27T11:39:50+00:00",
          "link": "https://arxiv.org/abs/2211.17182v5",
          "size": "207kb",
          "version": "v5"
        }
      ],
      "title": "Direct Data-Driven State-Feedback Control of Linear Parameter-Varying Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2211.17182",
        "HTML": "https://arxiv.org/html/2211.17182",
        "PDF": "https://arxiv.org/pdf/2211.17182"
      },
      "tasks": [
        "Scheduling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.12571",
      "abstract": "In this paper, we address the challenge of discovering hidden nodes in unknown social networks, formulating three types of hidden-node discovery problems, namely, Sybil-node discovery, peripheral-node discovery, and influencer discovery. We tackle these problems by employing a graph exploration framework grounded in machine learning. Leveraging the structure of the subgraph gradually obtained from graph exploration, we construct prediction models to identify target hidden nodes in unknown social graphs. Through empirical investigations of real social graphs, we investigate the efficiency of graph exploration strategies in uncovering hidden nodes. Our results show that our graph exploration strategies discover hidden nodes with an efficiency comparable to that when the graph structure is known. Specifically, the query cost of discovering 10% of the hidden nodes is at most only 1.2 times that when the topology is known, and the query-cost multiplier for discovering 90% of the hidden nodes is at most only 1.4. Furthermore, our results suggest that using node embeddings, which are low-dimensional vector representations of nodes, for hidden-node discovery is a double-edged sword: it is effective in certain scenarios but sometimes degrades the efficiency of node discovery. Guided by this observation, we examine the effectiveness of using a bandit algorithm to combine the prediction models that use node embeddings with those that do not, and our analysis shows that the bandit-based graph exploration strategy achieves efficient node discovery across a wide array of settings.",
      "authors": [
        "Sho Tsugawa and Hiroyuki Ohsaki"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Social and Information Networks (cs.SI)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-22T01:40:00+00:00",
          "link": "https://arxiv.org/abs/2501.12571v1",
          "size": "3367kb",
          "version": "v1"
        },
        {
          "date": "2025-04-28T06:26:01+00:00",
          "link": "https://arxiv.org/abs/2501.12571v2",
          "size": "4318kb",
          "version": "v2"
        }
      ],
      "title": "Exploring Unknown Social Networks for Discovering Hidden Nodes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.12571",
        "HTML": "https://arxiv.org/html/2501.12571",
        "PDF": "https://arxiv.org/pdf/2501.12571"
      },
      "repo_urls": [
        "https://github.com/s-tugawa/hidden_node_icwsm25"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.01460",
      "abstract": "Over the recent years, Shapley value (SV), a solution concept from cooperative game theory, has found numerous applications in data analytics (DA). This paper provides the first comprehensive study of SV used throughout the DA workflow, clarifying the key variables in defining DA-applicable SV and the essential functionalities that SV can provide for data scientists. We condense four primary challenges of using SV in DA, namely computation efficiency, approximation error, privacy preservation, and interpretability, then disentangle the resolution techniques from existing arts in this field, analyze and discuss the techniques w.r.t. each challenge and potential conflicts between challenges. We also implement SVBench, a modular and extensible open-sourced framework for developing SV applications in different DA tasks, and conduct extensive evaluations to validate our analyses and discussions. Based on the qualitative and quantitative results, we identify the limitations of current efforts for applying SV to DA and highlight the directions of future research and engineering.",
      "authors": [
        "Hong Lin",
        "Shixin Wan",
        "Zhongle Xie",
        "Ke Chen",
        "Meihui Zhang",
        "Lidan Shou",
        "Gang Chen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Databases (cs.DB)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-02T12:54:11+00:00",
          "link": "https://arxiv.org/abs/2412.01460v1",
          "size": "19444kb",
          "version": "v1"
        },
        {
          "date": "2024-12-03T04:48:22+00:00",
          "link": "https://arxiv.org/abs/2412.01460v2",
          "size": "19444kb",
          "version": "v2"
        },
        {
          "date": "2024-12-10T13:18:55+00:00",
          "link": "https://arxiv.org/abs/2412.01460v3",
          "size": "19444kb",
          "version": "v3"
        },
        {
          "date": "2025-04-03T14:30:16+00:00",
          "link": "https://arxiv.org/abs/2412.01460v4",
          "size": "1611kb",
          "version": "v4"
        },
        {
          "date": "2025-04-06T03:04:37+00:00",
          "link": "https://arxiv.org/abs/2412.01460v5",
          "size": "1597kb",
          "version": "v5"
        },
        {
          "date": "2025-05-21T00:52:12+00:00",
          "link": "https://arxiv.org/abs/2412.01460v6",
          "size": "1276kb",
          "version": "v6"
        },
        {
          "date": "2025-06-29T09:16:19+00:00",
          "link": "https://arxiv.org/abs/2412.01460v7",
          "size": "913kb",
          "version": "v7"
        }
      ],
      "title": "A Comprehensive Study of Shapley Value in Data Analytics",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.01460",
        "HTML": "https://arxiv.org/html/2412.01460",
        "PDF": "https://arxiv.org/pdf/2412.01460"
      },
      "tasks": [],
      "repo_urls": [
        "https://github.com/dddddstar/sv4da",
        "https://github.com/zjudbsystems/svbench"
      ],
      "source": "arXiv"
    },
    {
      "id": "2407.00304",
      "abstract": "Given the availability of more comprehensive measurement data in modern power systems, reinforcement learning (RL) has gained significant interest in operation and control. Conventional RL relies on trial-and-error interactions with the environment and reward feedback, which often leads to exploring unsafe operating regions and executing unsafe actions, especially when deployed in real-world power systems. To address these challenges, safe RL has been proposed to optimize operational objectives while ensuring safety constraints are met, keeping actions and states within safe regions throughout both training and deployment. Rather than relying solely on manually designed penalty terms for unsafe actions, as is common in conventional RL, safe RL methods reviewed here primarily leverage advanced and proactive mechanisms. These include techniques such as Lagrangian relaxation, safety layers, and theoretical guarantees like Lyapunov functions to rigorously enforce safety boundaries. This paper provides a comprehensive review of safe RL methods and their applications across various power system operations and control domains, including security control, real-time operation, operational planning, and emerging areas. It summarizes existing safe RL techniques, evaluates their performance, analyzes suitable deployment scenarios, and examines algorithm benchmarks and application environments. The paper also highlights real-world implementation cases and identifies critical challenges such as scalability in large-scale systems and robustness under uncertainty, providing potential solutions and outlining future directions to advance the reliable integration and deployment of safe RL in modern power systems.",
      "authors": [
        "Tong Su",
        "Tong Wu",
        "Junbo Zhao",
        "Anna Scaglione",
        "Le Xie"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-29T03:59:06+00:00",
          "link": "https://arxiv.org/abs/2407.00304v1",
          "size": "834kb",
          "version": "v1"
        },
        {
          "date": "2025-06-26T00:13:34+00:00",
          "link": "https://arxiv.org/abs/2407.00304v2",
          "size": "2468kb",
          "version": "v2"
        }
      ],
      "title": "A Review of Safe Reinforcement Learning Methods for Modern Power Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.00304",
        "HTML": "https://arxiv.org/html/2407.00304",
        "PDF": "https://arxiv.org/pdf/2407.00304"
      },
      "tasks": [
        "energy management",
        "Reinforcement Learning (RL)",
        "Safe Reinforcement Learning",
        "Scheduling"
      ],
      "source": "arXiv"
    },
    {
      "id": "1912.03702",
      "abstract": "We propose an end-to-end model to predict drug-drug interactions (DDIs) by employing graph-augmented convolutional networks. And this is implemented by combining graph CNN with an attentive pooling network to extract structural relations between drug pairs and make DDI predictions. The experiment results suggest a desirable performance achieving ROC at 0.988, F1-score at 0.956, and AUPR at 0.986. Besides, the model can tell how the two DDI drugs interact structurally by varying colored atoms. And this may be helpful for drug design during drug discovery.",
      "authors": [
        "Yi Zhong",
        "Xueyu Chen",
        "Yu Zhao",
        "Xiaoming Chen",
        "Tingfang Gao",
        "Zuquan Weng"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Machine Learning (stat.ML)"
      ],
      "submission_historys": [
        {
          "date": "2019-12-08T15:43:42+00:00",
          "link": "https://arxiv.org/abs/1912.03702v1",
          "size": "426kb",
          "version": "v1"
        }
      ],
      "title": "Graph-augmented Convolutional Networks on Drug-Drug Interactions Prediction",
      "links": {
        "Abstract": "https://arxiv.org/abs/1912.03702",
        "PDF": "https://arxiv.org/pdf/1912.03702"
      },
      "tasks": [
        "Drug Design",
        "Drug Discovery",
        "Prediction"
      ],
      "source": "arXiv"
    },
    {
      "id": "2406.02443",
      "abstract": "Raga identification is an important problem within the domain of Indian Art music, as Ragas are fundamental to its composition and performance, playing a crucial role in music retrieval, preservation, and education. Few studies that have explored this task employ approaches such as signal processing, Machine Learning (ML), and more recently, Deep Learning (DL) based methods. However, a key question remains unanswered in all these works: do these ML/DL methods learn and interpret Ragas in a manner similar to human experts? Besides, a significant roadblock in this research is the unavailability of an ample supply of rich, labeled datasets, which drives these ML/DL-based methods. In this paper, firstly we curate a dataset comprising 191 hours of Hindustani Classical Music (HCM) recordings, annotate it for Raga and tonic labels, and train a CNN-LSTM model for the task of Automatic Raga Identification (ARI). We achieve a chunk-wise f1-measure of 0.89 for a subset of 12 Raga classes. Following this, we make one of the first attempts to employ model explainability techniques: SoundLIME and GradCAM++ for Raga identification, to evaluate whether the classifier's predictions align with human understanding of Ragas. We compare the generated explanations with human expert annotations and further analyze individual test examples to understand the role of regions highlighted by explanations in making correct or incorrect predictions made by the model. Our results demonstrate a significant alignment of the model's understanding with human understanding, and the thorough analysis validates the effectiveness of our approach.",
      "authors": [
        "Parampreet Singh and Vipul Arora"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-06-04T16:06:51+00:00",
          "link": "https://arxiv.org/abs/2406.02443v1",
          "size": "6425kb",
          "version": "v1"
        },
        {
          "date": "2024-12-21T08:32:18+00:00",
          "link": "https://arxiv.org/abs/2406.02443v2",
          "size": "7635kb",
          "version": "v2"
        }
      ],
      "title": "Explainable Deep Learning Analysis for Raga Identification in Indian Art Music",
      "links": {
        "Abstract": "https://arxiv.org/abs/2406.02443",
        "HTML": "https://arxiv.org/html/2406.02443",
        "PDF": "https://arxiv.org/pdf/2406.02443"
      },
      "tasks": [
        "Information Retrieval",
        "Music Information Retrieval"
      ],
      "repo_urls": [
        "https://github.com/parampreetsingh97/pim_v1_exai"
      ],
      "source": "arXiv"
    },
    {
      "id": "2505.15932",
      "abstract": "This paper takes a step towards addressing the difficulty of constructing Control Barrier Functions (CBFs) for parallel safety boundaries. A single CBF for both boundaries has been reported to be difficult to validate for safety, and we identify why this challenge is inherent. To overcome this, the proposed method constructs separate CBFs for each boundary. We begin by presenting results for the relative degree one case and then extend these to higher relative degrees using the CBF backstepping technique, establishing conditions that guarantee safety. Finally, we showcase our method by applying it to a unicycle system, deriving a simple, verifiable condition to validate the target CBFs for direct implementation of our results.",
      "authors": [
        "Kwang Hak Kim",
        "Mamadou Diagne",
        "and Miroslav Krsti\\'c"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Optimization and Control (math.OC)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-05-21T18:36:44+00:00",
          "link": "https://arxiv.org/abs/2505.15932v1",
          "size": "176kb",
          "version": "v1"
        }
      ],
      "title": "Constant-Sum High-Order Barrier Functions for Safety Between Parallel Boundaries",
      "links": {
        "Abstract": "https://arxiv.org/abs/2505.15932",
        "HTML": "https://arxiv.org/html/2505.15932",
        "PDF": "https://arxiv.org/pdf/2505.15932"
      },
      "source": "arXiv"
    },
    {
      "id": "2301.13324",
      "abstract": "The fifth generation (5G) of wireless networks is set out to meet the stringent requirements of vehicular use cases. Edge computing resources can aid in this direction by moving processing closer to end-users, reducing latency. However, given the stochastic nature of traffic loads and availability of physical resources, appropriate auto-scaling mechanisms need to be employed to support cost-efficient and performant services. To this end, we employ Deep Reinforcement Learning (DRL) for vertical scaling in Edge computing to support vehicular-to-network communications. We address the problem using Deep Deterministic Policy Gradient (DDPG). As DDPG is a model-free off-policy algorithm for learning continuous actions, we introduce a discretization approach to support discrete scaling actions. Thus we address scalability problems inherent to high-dimensional discrete action spaces. Employing a real-world vehicular trace data set, we show that DDPG outperforms existing solutions, reducing (at minimum) the average number of active CPUs by 23% while increasing the long-term reward by 24%.",
      "authors": [
        "Cyril Shih-Huan Hsu",
        "Jorge Mart\\'in-P\\'erez",
        "Chrysa Papagianni",
        "Paola Grosso"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)",
        "Networking and Internet Architecture (cs.NI)"
      ],
      "submission_historys": [
        {
          "date": "2023-01-30T23:13:18+00:00",
          "link": "https://arxiv.org/abs/2301.13324v1",
          "size": "1263kb",
          "version": "v1"
        },
        {
          "date": "2023-02-01T01:51:09+00:00",
          "link": "https://arxiv.org/abs/2301.13324v2",
          "size": "1263kb",
          "version": "v2"
        }
      ],
      "title": "V2N Service Scaling with Deep Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2301.13324",
        "PDF": "https://arxiv.org/pdf/2301.13324"
      },
      "tasks": [
        "Deep Reinforcement Learning",
        "Edge-computing",
        "reinforcement-learning",
        "Reinforcement Learning",
        "Reinforcement Learning (RL)"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.05136",
      "abstract": "Fully Homomorphic Encryption (FHE) is a cryptographic scheme that enables computations to be performed directly on encrypted data, as if the data were in plaintext. After all computations are performed on the encrypted data, it can be decrypted to reveal the result. The decrypted value matches the result that would have been obtained if the same computations were applied to the plaintext data.\n  FHE supports basic operations such as addition and multiplication on encrypted numbers. Using these fundamental operations, more complex computations can be constructed, including subtraction, division, logic gates (e.g., AND, OR, XOR, NAND, MUX), and even advanced mathematical functions such as ReLU, sigmoid, and trigonometric functions (e.g., sin, cos). These functions can be implemented either as exact formulas or as approximations, depending on the trade-off between computational efficiency and accuracy.\n  FHE enables privacy-preserving machine learning by allowing a server to process the client's data in its encrypted form through an ML model. With FHE, the server learns neither the plaintext version of the input features nor the inference results. Only the client, using their secret key, can decrypt and access the results at the end of the service protocol. FHE can also be applied to confidential blockchain services, ensuring that sensitive data in smart contracts remains encrypted and confidential while maintaining the transparency and integrity of the execution process. Other applications of FHE include secure outsourcing of data analytics, encrypted database queries, privacy-preserving searches, efficient multi-party computation for digital signatures, and more.\n  As this book is an open project (https://fhetextbook.github.io), we welcome FHE experts to join us as collaborators to help expand the draft.",
      "authors": [
        "Ronny Ko"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Cryptography and Security (cs.CR)",
        "Discrete Mathematics (cs.DM)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-07T04:29:11+00:00",
          "link": "https://arxiv.org/abs/2503.05136v1",
          "size": "32kb",
          "version": "v1"
        },
        {
          "date": "2025-03-13T15:18:50+00:00",
          "link": "https://arxiv.org/abs/2503.05136v2",
          "size": "5237kb",
          "version": "v2"
        },
        {
          "date": "2025-03-14T03:22:13+00:00",
          "link": "https://arxiv.org/abs/2503.05136v3",
          "size": "5239kb",
          "version": "v3"
        },
        {
          "date": "2025-04-13T13:14:01+00:00",
          "link": "https://arxiv.org/abs/2503.05136v4",
          "size": "5257kb",
          "version": "v4"
        },
        {
          "date": "2025-04-26T18:20:16+00:00",
          "link": "https://arxiv.org/abs/2503.05136v5",
          "size": "5274kb",
          "version": "v5"
        },
        {
          "date": "2025-05-04T15:31:10+00:00",
          "link": "https://arxiv.org/abs/2503.05136v6",
          "size": "5301kb",
          "version": "v6"
        },
        {
          "date": "2025-05-12T17:20:32+00:00",
          "link": "https://arxiv.org/abs/2503.05136v7",
          "size": "5098kb",
          "version": "v7"
        },
        {
          "date": "2025-05-20T16:04:22+00:00",
          "link": "https://arxiv.org/abs/2503.05136v8",
          "size": "5062kb",
          "version": "v8"
        },
        {
          "date": "2025-05-26T03:42:34+00:00",
          "link": "https://arxiv.org/abs/2503.05136v9",
          "size": "5062kb",
          "version": "v9"
        },
        {
          "date": "2025-06-01T08:45:01+00:00",
          "link": "https://arxiv.org/abs/2503.05136v10",
          "size": "4570kb",
          "version": "v10"
        },
        {
          "date": "2025-06-08T04:45:52+00:00",
          "link": "https://arxiv.org/abs/2503.05136v11",
          "size": "4570kb",
          "version": "v11"
        },
        {
          "date": "2025-06-30T13:04:04+00:00",
          "link": "https://arxiv.org/abs/2503.05136v12",
          "size": "4570kb",
          "version": "v12"
        }
      ],
      "title": "The Beginner's Textbook for Fully Homomorphic Encryption",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.05136",
        "PDF": "https://arxiv.org/pdf/2503.05136"
      },
      "source": "arXiv"
    },
    {
      "id": "2303.10428",
      "abstract": "Visual abductive reasoning aims to make likely explanations for visual observations. We propose a simple yet effective Region Conditioned Adaptation, a hybrid parameter-efficient fine-tuning method that equips the frozen CLIP with the ability to infer explanations from local visual cues. We encode \"local hints\" and \"global contexts\" into visual prompts of the CLIP model separately at fine and coarse-grained levels. Adapters are used for fine-tuning CLIP models for downstream tasks and we design a new attention adapter, that directly steers the focus of the attention map with trainable query and key projections of a frozen CLIP model. Finally, we train our new model with a modified contrastive loss to regress the visual feature simultaneously toward features of literal description and plausible explanations. The loss enables CLIP to maintain both perception and reasoning abilities. Experiments on the Sherlock visual abductive reasoning benchmark show that the RCA significantly outstands previous SOTAs, ranking the 1st on the leaderboards (e.g., Human Acc: RCA 31.74 $\\textit{vs}$ CPT-CLIP 29.58, higher =better). We also validate the RCA is generalizable to local perception benchmarks like RefCOCO. We open-source our project at https://github.com/LUNAProject22/RPA.",
      "authors": [
        "Hao Zhang",
        "Yeo Keat Ee",
        "Basura Fernando"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-03-18T14:46:44+00:00",
          "link": "https://arxiv.org/abs/2303.10428v1",
          "size": "13332kb",
          "version": "v1"
        },
        {
          "date": "2023-04-17T16:05:27+00:00",
          "link": "https://arxiv.org/abs/2303.10428v2",
          "size": "37883kb",
          "version": "v2"
        },
        {
          "date": "2024-01-07T05:06:26+00:00",
          "link": "https://arxiv.org/abs/2303.10428v3",
          "size": "18113kb",
          "version": "v3"
        },
        {
          "date": "2024-07-19T04:52:07+00:00",
          "link": "https://arxiv.org/abs/2303.10428v4",
          "size": "11412kb",
          "version": "v4"
        },
        {
          "date": "2024-08-07T13:44:06+00:00",
          "link": "https://arxiv.org/abs/2303.10428v5",
          "size": "17811kb",
          "version": "v5"
        },
        {
          "date": "2025-06-30T03:03:13+00:00",
          "link": "https://arxiv.org/abs/2303.10428v6",
          "size": "5486kb",
          "version": "v6"
        }
      ],
      "title": "RCA: Region Conditioned Adaptation for Visual Abductive Reasoning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2303.10428",
        "HTML": "https://arxiv.org/html/2303.10428",
        "PDF": "https://arxiv.org/pdf/2303.10428"
      },
      "tasks": [
        "parameter-efficient fine-tuning",
        "Visual Abductive Reasoning"
      ],
      "repo_urls": [
        "https://github.com/lunaproject22/rpa"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.00410",
      "abstract": "Recently, learned video compression (LVC) is undergoing a period of rapid development. However, due to absence of large and high-quality high dynamic range (HDR) video training data, LVC on HDR video is still unexplored. In this paper, we are the first to collect a large-scale HDR video benchmark dataset, named HDRVD2K, featuring huge quantity, diverse scenes and multiple motion types. HDRVD2K fills gaps of video training data and facilitate the development of LVC on HDR videos. Based on HDRVD2K, we further propose the first learned bit-depth scalable video compression (LBSVC) network for HDR videos by effectively exploiting bit-depth redundancy between videos of multiple dynamic ranges. To achieve this, we first propose a compression-friendly bit-depth enhancement module (BEM) to effectively predict original HDR videos based on compressed tone-mapped low dynamic range (LDR) videos and dynamic range prior, instead of reducing redundancy only through spatio-temporal predictions. Our method greatly improves the reconstruction quality and compression performance on HDR videos. Extensive experiments demonstrate the effectiveness of HDRVD2K on learned HDR video compression and great compression performance of our proposed LBSVC network. Code and dataset will be released in https://github.com/sdkinda/HDR-Learned-Video-Coding.",
      "authors": [
        "Zhaoyi Tian",
        "Feifeng Wang",
        "Shiwei Wang",
        "Zihao Zhou",
        "Yao Zhu",
        "Liquan Shen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-01T09:13:29+00:00",
          "link": "https://arxiv.org/abs/2503.00410v1",
          "size": "15296kb",
          "version": "v1"
        }
      ],
      "title": "High Dynamic Range Video Compression: A Large-Scale Benchmark Dataset and A Learned Bit-depth Scalable Compression Algorithm",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.00410",
        "HTML": "https://arxiv.org/html/2503.00410",
        "PDF": "https://arxiv.org/pdf/2503.00410"
      },
      "conference_url_abs": "http://openaccess.thecvf.com//content/CVPR2025/html/Tian_High_Dynamic_Range_Video_Compression_A_Large-Scale_Benchmark_Dataset_and_CVPR_2025_paper.html",
      "tasks": [
        "Video Compression"
      ],
      "repo_urls": [
        "https://github.com/sdkinda/hdr-learned-video-coding"
      ],
      "source": "arXiv"
    },
    {
      "id": "2305.01265",
      "abstract": "This article presents an application of the recently proposed logic operation of power based on power packetization. In a power packet dispatching system, the power supply can be considered as a sequence of power pulses, where the occurrence of pulses follows a probability that corresponds to the capacity of the power sources or power lines. In this study, we propose a processing scheme to reshape a stream of power packets from such stochastic sequences to satisfy the load demand. The proposed scheme is realized by extending the concept of stochastic computing to the power domain. We demonstrate the operation of the proposed scheme through experiments and numerical simulations by implementing it as a function of a power packet router, which forms a power packet dispatching network. The stochastic framework proposed in this study provides a new design foundation for low-power distribution networks as an embodiment of the close connection between the cyber and physical components.",
      "authors": [
        "Shiu Mochiyama and Takashi Hikihara"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2023-05-02T09:02:20+00:00",
          "link": "https://arxiv.org/abs/2305.01265v1",
          "size": "30673kb",
          "version": "v1"
        }
      ],
      "title": "Stochastic Power Processing through Logic Operation of Power Packets",
      "links": {
        "Abstract": "https://arxiv.org/abs/2305.01265",
        "PDF": "https://arxiv.org/pdf/2305.01265"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2412.05515",
      "abstract": "Learning behavior in legged robots presents a significant challenge due to its inherent instability and complex constraints. Recent research has proposed the use of a large language model (LLM) to generate reward functions in reinforcement learning, thereby replacing the need for manually designed rewards by experts. However, this approach, which relies on textual descriptions to define learning objectives, fails to achieve controllable and precise behavior learning with clear directionality. In this paper, we introduce a new video2reward method, which directly generates reward functions from videos depicting the behaviors to be mimicked and learned. Specifically, we first process videos containing the target behaviors, converting the motion information of individuals in the videos into keypoint trajectories represented as coordinates through a video2text transforming module. These trajectories are then fed into an LLM to generate the reward function, which in turn is used to train the policy. To enhance the quality of the reward function, we develop a video-assisted iterative reward refinement scheme that visually assesses the learned behaviors and provides textual feedback to the LLM. This feedback guides the LLM to continually refine the reward function, ultimately facilitating more efficient behavior learning. Experimental results on tasks involving bipedal and quadrupedal robot motion control demonstrate that our method surpasses the performance of state-of-the-art LLM-based reward generation methods by over 37.6% in terms of human normalized score. More importantly, by switching video inputs, we find our method can rapidly learn diverse motion behaviors such as walking and running.",
      "authors": [
        "Runhao Zeng",
        "Dingjie Zhou",
        "Qiwei Liang",
        "Junlin Liu",
        "Hui Li",
        "Changxin Huang",
        "Jianqiang Li",
        "Xiping Hu and Fuchun Sun"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Robotics (cs.RO)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-07T03:10:27+00:00",
          "link": "https://arxiv.org/abs/2412.05515v1",
          "size": "3138kb",
          "version": "v1"
        }
      ],
      "title": "Video2Reward: Generating Reward Function from Videos for Legged Robot Behavior Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.05515",
        "HTML": "https://arxiv.org/html/2412.05515",
        "PDF": "https://arxiv.org/pdf/2412.05515"
      },
      "tasks": [
        "Large Language Model"
      ],
      "repo_urls": [
        "https://github.com/Alvin-Zeng/Video2Reward"
      ],
      "source": "arXiv"
    },
    {
      "id": "2108.04345",
      "abstract": "Ultrasound is a non-invasive imaging modality that can be conveniently used to classify suspicious breast nodules and potentially detect the onset of breast cancer. Recently, Convolutional Neural Networks (CNN) techniques have shown promising results in classifying ultrasound images of the breast into benign or malignant. However, CNN inference acts as a black-box model, and as such, its decision-making is not interpretable. Therefore, increasing effort has been dedicated to explaining this process, most notably through GRAD-CAM and other techniques that provide visual explanations into inner workings of CNNs. In addition to interpretation, these methods provide clinically important information, such as identifying the location for biopsy or treatment. In this work, we analyze how adversarial assaults that are practically undetectable may be devised to alter these importance maps dramatically. Furthermore, we will show that this change in the importance maps can come with or without altering the classification result, rendering them even harder to detect. As such, care must be taken when using these importance maps to shed light on the inner workings of deep learning. Finally, we utilize Multi-Task Learning (MTL) and propose a new network based on ResNet-50 to improve the classification accuracies. Our sensitivity and specificity is comparable to the state of the art results.",
      "authors": [
        "Hamza Rasaee",
        "Hassan Rivaz"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Cryptography and Security (cs.CR)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2021-08-09T23:52:16+00:00",
          "link": "https://arxiv.org/abs/2108.04345v1",
          "size": "1194kb",
          "version": "v1"
        }
      ],
      "title": "Explainable AI and susceptibility to adversarial attacks: a case study in classification of breast ultrasound images",
      "links": {
        "Abstract": "https://arxiv.org/abs/2108.04345",
        "PDF": "https://arxiv.org/pdf/2108.04345"
      },
      "tasks": [
        "Decision Making",
        "Multi-Task Learning",
        "Specificity"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.17878",
      "abstract": "With the rapid development of various internet of things (IoT) applications, including industrial IoT (IIoT) and visual IoT (VIoT), the demand for direct device-to-device communication to support high data rates continues to grow. To address this demand, 5G-Advanced has introduced sidelink communication over the unlicensed spectrum (SL-U) to increase data rates. However, the primary challenge of SL-U in the unlicensed spectrum is ensuring fair coexistence with other incumbent systems, such as Wi-Fi. In this paper, we address the challenge by designing channel access mechanisms and power control strategies to mitigate interference and ensure fair coexistence. First, we propose a novel collaborative channel access (CCHA) mechanism that integrates channel access with resource allocation through collaborative interactions between base stations (BS) and SL-U users. This mechanism ensures fair coexistence with incumbent systems while improving resource utilization. Second, to further enhance the performance of the coexistence system, we develop a cooperative subgoal-based hierarchical deep reinforcement learning (C-GHDRL) algorithm framework. The framework enables SL-U users to make globally optimal decisions by leveraging cooperative operations between the BS and SL-U users, effectively overcoming the limitations of traditional optimization methods in solving joint optimization problems with nonlinear constraints. Finally, we mathematically model the joint channel access and power control problem and balance the trade-off between fairness and transmission rate in the coexistence system by defining a suitable reward function in the C-GHDRL algorithm. Simulation results demonstrate that the proposed scheme significantly enhances the performance of the coexistence system while ensuring fair coexistence between SL-U and Wi-Fi users.",
      "authors": [
        "Zhuangzhuang Yan",
        "Xinyu Gu",
        "Zhenyu Liu",
        "Liyang Lu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Signal Processing (eess.SP)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-20T03:37:51+00:00",
          "link": "https://arxiv.org/abs/2501.17878v1",
          "size": "759kb",
          "version": "v1"
        },
        {
          "date": "2025-02-14T07:09:24+00:00",
          "link": "https://arxiv.org/abs/2501.17878v2",
          "size": "546kb",
          "version": "v2"
        }
      ],
      "title": "Collaborative Channel Access and Transmission for NR Sidelink and Wi-Fi Coexistence over Unlicensed Spectrum",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.17878",
        "HTML": "https://arxiv.org/html/2501.17878",
        "PDF": "https://arxiv.org/pdf/2501.17878"
      },
      "tasks": [
        "Deep Reinforcement Learning",
        "Fairness"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.22038",
      "abstract": "Phishing attacks remain a critical cybersecurity threat. Attackers constantly refine their methods, making phishing emails harder to detect. Traditional detection methods, including rule-based systems and supervised machine learning models, either rely on predefined patterns like blacklists, which can be bypassed with slight modifications, or require large datasets for training and still can generate false positives and false negatives. In this work, we propose a multi-agent large language model (LLM) prompting technique that simulates debates among agents to detect whether the content presented on an email is phishing. Our approach uses two LLM agents to present arguments for or against the classification task, with a judge agent adjudicating the final verdict based on the quality of reasoning provided. This debate mechanism enables the models to critically analyze contextual cue and deceptive patterns in text, which leads to improved classification accuracy. The proposed framework is evaluated on multiple phishing email datasets and demonstrate that mixed-agent configurations consistently outperform homogeneous configurations. Results also show that the debate structure itself is sufficient to yield accurate decisions without extra prompting strategies.",
      "authors": [
        "Ngoc Tuong Vy Nguyen",
        "Felix D Childress",
        "Yunting Yin"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Multiagent Systems (cs.MA)",
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-27T23:18:14+00:00",
          "link": "https://arxiv.org/abs/2503.22038v1",
          "size": "1073kb",
          "version": "v1"
        }
      ],
      "title": "Debate-Driven Multi-Agent LLMs for Phishing Email Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.22038",
        "HTML": "https://arxiv.org/html/2503.22038",
        "PDF": "https://arxiv.org/pdf/2503.22038"
      },
      "tasks": [
        "Language Modeling",
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "1904.01293",
      "abstract": "In contrast to traditional cameras, whose pixels have a common exposure time, event-based cameras are novel bio-inspired sensors whose pixels work independently and asynchronously output intensity changes (called \"events\"), with microsecond resolution. Since events are caused by the apparent motion of objects, event-based cameras sample visual information based on the scene dynamics and are, therefore, a more natural fit than traditional cameras to acquire motion, especially at high speeds, where traditional cameras suffer from motion blur. However, distinguishing between events caused by different moving objects and by the camera's ego-motion is a challenging task. We present the first per-event segmentation method for splitting a scene into independently moving objects. Our method jointly estimates the event-object associations (i.e., segmentation) and the motion parameters of the objects (or the background) by maximization of an objective function, which builds upon recent results on event-based motion-compensation. We provide a thorough evaluation of our method on a public dataset, outperforming the state-of-the-art by as much as 10%. We also show the first quantitative evaluation of a segmentation algorithm for event cameras, yielding around 90% accuracy at 4 pixels relative displacement.",
      "authors": [
        "Timo Stoffregen and Guillermo Gallego and Tom Drummond and Lindsay Kleeman and Davide Scaramuzza"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2019-04-02T08:51:01+00:00",
          "link": "https://arxiv.org/abs/1904.01293v1",
          "size": "25885kb",
          "version": "v1"
        },
        {
          "date": "2019-04-03T07:21:56+00:00",
          "link": "https://arxiv.org/abs/1904.01293v2",
          "size": "22995kb",
          "version": "v2"
        },
        {
          "date": "2019-04-04T08:16:50+00:00",
          "link": "https://arxiv.org/abs/1904.01293v3",
          "size": "22995kb",
          "version": "v3"
        },
        {
          "date": "2019-08-22T23:15:45+00:00",
          "link": "https://arxiv.org/abs/1904.01293v4",
          "size": "12873kb",
          "version": "v4"
        }
      ],
      "title": "Event-Based Motion Segmentation by Motion Compensation",
      "links": {
        "Abstract": "https://arxiv.org/abs/1904.01293",
        "PDF": "https://arxiv.org/pdf/1904.01293"
      },
      "conference": "event-based-motion-segmentation-by-motion-1",
      "conference_url_abs": "http://openaccess.thecvf.com/content_ICCV_2019/html/Stoffregen_Event-Based_Motion_Segmentation_by_Motion_Compensation_ICCV_2019_paper.html",
      "tasks": [
        "Event Segmentation",
        "Motion Compensation",
        "Motion Segmentation",
        "Segmentation"
      ],
      "repo_urls": [
        "https://github.com/remindof/EV-MotionSeg"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.06356",
      "abstract": "Q-learning is a widely used algorithm in reinforcement learning (RL), but its convergence can be slow, especially when the discount factor is close to one. Successive Over-Relaxation (SOR) Q-learning, which introduces a relaxation factor to speed up convergence, addresses this issue but has two major limitations: In the tabular setting, the relaxation parameter depends on transition probability, making it not entirely model-free, and it suffers from overestimation bias. To overcome these limitations, we propose a sample-based, model-free double SOR Q-learning algorithm. Theoretically and empirically, this algorithm is shown to be less biased than SOR Q-learning. Further, in the tabular setting, the convergence analysis under boundedness assumptions on iterates is discussed. The proposed algorithm is extended to large-scale problems using deep RL. Finally, the tabular version of the proposed algorithm is compared using roulette and grid world environments, while the deep RL version is tested on a maximization bias example and OpenAI Gym environments.",
      "authors": [
        "Shreyas S R"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-10T09:23:03+00:00",
          "link": "https://arxiv.org/abs/2409.06356v1",
          "size": "240kb",
          "version": "v1"
        },
        {
          "date": "2025-05-15T15:16:33+00:00",
          "link": "https://arxiv.org/abs/2409.06356v2",
          "size": "188kb",
          "version": "v2"
        }
      ],
      "title": "Double Successive Over-Relaxation Q-Learning with an Extension to Deep Reinforcement Learning",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.06356",
        "HTML": "https://arxiv.org/html/2409.06356",
        "PDF": "https://arxiv.org/pdf/2409.06356"
      },
      "tasks": [
        "Deep Reinforcement Learning",
        "OpenAI Gym",
        "Q-Learning",
        "Reinforcement Learning (RL)"
      ],
      "repo_urls": [
        "https://github.com/shreyassr123/double-sor-q-learning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2005.07682",
      "abstract": "We introduce a vortex phase transform with a lenslet-array to accompany shallow, dense, ``small-brain'' neural networks for high-speed and low-light imaging. Our single-shot ptychographic approach exploits the coherent diffraction, compact representation, and edge enhancement of Fourier-tranformed spiral-phase gradients. With vortex spatial encoding, a small brain is trained to deconvolve images at rates 5-20 times faster than those achieved with random encoding schemes, where greater advantages are gained in the presence of noise. Once trained, the small brain reconstructs an object from intensity-only data, solving an inverse mapping without performing iterations on each image and without deep-learning schemes. With this hybrid, optical-digital, vortex Fourier encoded, small-brain scheme, we reconstruct MNIST Fashion objects illuminated with low-light flux (5 nJ/cm$^2$) at a rate of several thousand frames per second on a 15 W central processing unit, two orders of magnitude faster than convolutional neural networks.",
      "authors": [
        "Baurzhan Muminov and Luat T. Vuong"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Optics (physics.optics)"
      ],
      "submission_historys": [
        {
          "date": "2020-05-15T17:53:32+00:00",
          "link": "https://arxiv.org/abs/2005.07682v1",
          "size": "5047kb",
          "version": "v1"
        }
      ],
      "title": "Small-brain neural networks rapidly solve inverse problems with vortex Fourier encoders",
      "links": {
        "Abstract": "https://arxiv.org/abs/2005.07682",
        "PDF": "https://arxiv.org/pdf/2005.07682"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2409.02691",
      "abstract": "We explore the integration of large language models (LLMs) into visual analytics (VA) systems to transform their capabilities through intuitive natural language interactions. We survey current research directions in this emerging field, examining how LLMs are integrated into data management, language interaction, visualisation generation, and language generation processes. We highlight the new possibilities that LLMs bring to VA, especially how they can change VA processes beyond the usual use cases. We especially highlight building new visualisation-language models, allowing access of a breadth of domain knowledge, multimodal interaction, and opportunities with guidance. Finally, we carefully consider the prominent challenges of using current LLMs in VA tasks. Our discussions in this paper aim to guide future researchers working on LLM-assisted VA systems and help them navigate common obstacles when developing these systems.",
      "authors": [
        "Maeve Hutchinson",
        "Radu Jianu",
        "Aidan Slingsby and Pranava Madhyastha"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-04T13:24:03+00:00",
          "link": "https://arxiv.org/abs/2409.02691v1",
          "size": "198kb",
          "version": "v1"
        }
      ],
      "title": "LLM-Assisted Visual Analytics: Opportunities and Challenges",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.02691",
        "HTML": "https://arxiv.org/html/2409.02691",
        "PDF": "https://arxiv.org/pdf/2409.02691"
      },
      "tasks": [
        "Management",
        "multimodal interaction",
        "Navigate",
        "Text Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.14745",
      "abstract": "Text to Motion aims to generate human motions from texts. Existing settings rely on limited Action Texts that include action labels, which limits flexibility and practicability in scenarios difficult to describe directly. This paper extends limited Action Texts to arbitrary ones. Scene texts without explicit action labels can enhance the practicality of models in complex and diverse industries such as virtual human interaction, robot behavior generation, and film production, while also supporting the exploration of potential implicit behavior patterns. However, newly introduced Scene Texts may yield multiple reasonable output results, causing significant challenges in existing data, framework, and evaluation. To address this practical issue, we first create a new dataset HUMANML3D++ by extending texts of the largest existing dataset HUMANML3D. Secondly, we propose a simple yet effective framework that extracts action instructions from arbitrary texts and subsequently generates motions. Furthermore, we also benchmark this new setting with multi-solution metrics to address the inadequacies of existing single-solution metrics. Extensive experiments indicate that Text to Motion in this realistic setting is challenging, fostering new research in this practical direction.",
      "authors": [
        "Runqi Wang and Caoyuan Ma and Guopeng Li and Hanrui Xu and Yuke Li and Zheng Wang"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-23T04:54:32+00:00",
          "link": "https://arxiv.org/abs/2404.14745v1",
          "size": "22591kb",
          "version": "v1"
        },
        {
          "date": "2024-06-06T07:46:24+00:00",
          "link": "https://arxiv.org/abs/2404.14745v2",
          "size": "22591kb",
          "version": "v2"
        },
        {
          "date": "2024-08-27T13:36:12+00:00",
          "link": "https://arxiv.org/abs/2404.14745v3",
          "size": "32978kb",
          "version": "v3"
        },
        {
          "date": "2025-01-03T07:20:48+00:00",
          "link": "https://arxiv.org/abs/2404.14745v4",
          "size": "47027kb",
          "version": "v4"
        },
        {
          "date": "2025-04-03T03:30:59+00:00",
          "link": "https://arxiv.org/abs/2404.14745v5",
          "size": "32090kb",
          "version": "v5"
        },
        {
          "date": "2025-06-28T11:36:30+00:00",
          "link": "https://arxiv.org/abs/2404.14745v6",
          "size": "7816kb",
          "version": "v6"
        }
      ],
      "title": "You Think, You ACT: The New Task of Arbitrary Text to Motion Generation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.14745",
        "HTML": "https://arxiv.org/html/2404.14745",
        "PDF": "https://arxiv.org/pdf/2404.14745"
      },
      "tasks": [
        "Language Modelling",
        "Large Language Model"
      ],
      "source": "arXiv"
    },
    {
      "id": "2503.17262",
      "abstract": "Event cameras rely on motion to obtain information about scene appearance. In other words, for event cameras, motion and appearance are seen both or neither, which are encoded in the output event stream. Previous works consider recovering these two visual quantities as separate tasks, which does not fit with the nature of event cameras and neglects the inherent relations between both tasks. In this paper, we propose an unsupervised learning framework that jointly estimates optical flow (motion) and image intensity (appearance), with a single network. Starting from the event generation model, we newly derive the event-based photometric error as a function of optical flow and image intensity, which is further combined with the contrast maximization framework, yielding a comprehensive loss function that provides proper constraints for both flow and intensity estimation. Exhaustive experiments show that our model achieves state-of-the-art performance for both optical flow (achieves 20% and 25% improvement in EPE and AE respectively in the unsupervised learning category) and intensity estimation (produces competitive results with other baselines, particularly in high dynamic range scenarios). Last but not least, our model achieves shorter inference time than all the other optical flow models and many of the image reconstruction models, while they output only one quantity. Project page: https://github.com/tub-rip/e2fai",
      "authors": [
        "Shuang Guo and Friedhelm Hamann and Guillermo Gallego"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Machine Learning (cs.LG)",
        "Image and Video Processing (eess.IV)"
      ],
      "submission_historys": [
        {
          "date": "2025-03-21T16:04:13+00:00",
          "link": "https://arxiv.org/abs/2503.17262v1",
          "size": "41493kb",
          "version": "v1"
        }
      ],
      "title": "Unsupervised Joint Learning of Optical Flow and Intensity with Event Cameras",
      "links": {
        "Abstract": "https://arxiv.org/abs/2503.17262",
        "PDF": "https://arxiv.org/pdf/2503.17262"
      },
      "tasks": [
        "Image Reconstruction",
        "Optical Flow Estimation"
      ],
      "repo_urls": [
        "https://github.com/tub-rip/e2fai"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.20832",
      "abstract": "Super-resolution (SR) is an ill-posed inverse problem with many feasible solutions consistent with a given low-resolution image. On one hand, regressive SR models aim to balance fidelity and perceptual quality to yield a single solution, but this trade-off often introduces artifacts that create ambiguity in information-critical applications such as recognizing digits or letters. On the other hand, diffusion models generate a diverse set of SR images, but selecting the most trustworthy solution from this set remains a challenge. This paper introduces a robust, automated framework for identifying the most trustworthy SR sample from a diffusion-generated set by leveraging the semantic reasoning capabilities of vision-language models (VLMs). Specifically, VLMs such as BLIP-2, GPT-4o, and their variants are prompted with structured queries to assess semantic correctness, visual quality, and artifact presence. The top-ranked SR candidates are then ensembled to yield a single trustworthy output in a cost-effective manner. To rigorously assess the validity of VLM-selected samples, we propose a novel Trustworthiness Score (TWS) a hybrid metric that quantifies SR reliability based on three complementary components: semantic similarity via CLIP embeddings, structural integrity using SSIM on edge maps, and artifact sensitivity through multi-level wavelet decomposition. We empirically show that TWS correlates strongly with human preference in both ambiguous and natural images, and that VLM-guided selections consistently yield high TWS values. Compared to conventional metrics like PSNR, LPIPS, which fail to reflect information fidelity, our approach offers a principled, scalable, and generalizable solution for navigating the uncertainty of the diffusion SR space. By aligning outputs with human expectations and semantic correctness, this work sets a new benchmark for trustworthiness in generative SR.",
      "authors": [
        "Cansu Korkmaz",
        "Ahmet Murat Tekalp",
        "Zafer Dogan"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T21:00:44+00:00",
          "link": "https://arxiv.org/abs/2506.20832v1",
          "size": "5778kb",
          "version": "v1"
        }
      ],
      "title": "Leveraging Vision-Language Models to Select Trustworthy Super-Resolution Samples Generated by Diffusion Models",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20832",
        "HTML": "https://arxiv.org/html/2506.20832",
        "PDF": "https://arxiv.org/pdf/2506.20832"
      },
      "source": "arXiv"
    },
    {
      "id": "2403.15861",
      "abstract": "This research investigates User Experience (UX) issues in dataset search, targeting Google Dataset Search and data.europa.eu. It focuses on 6 areas within UX: Initial Interaction, Search Process, Dataset Exploration, Filtering and Sorting, Dataset Actions, and Assistance and Feedback. The evaluation method combines 'The Pandemic Puzzle' user task, think-aloud methods, and demographic and post-task questionnaires. 29 strengths and 63 weaknesses were collected from 19 participants involved in roles within technology firm or academia. While certain insights are specific to particular platforms, most are derived from features commonly observed in dataset search platforms across a variety of fields, implying that our findings are broadly applicable. Observations from commonly found features in dataset search platforms across various fields have led to the development of 10 new design prototypes. Unlike literature retrieval, dataset retrieval involves a significant focus on metadata accessibility and quality, each element of which can impact decision-making. To address issues like reading fatigue from metadata presentation, inefficient methods for results searching, filtering, and selection, along with other unresolved user-centric issues on current platforms. These prototypes concentrate on enhancing metadata-related features. They include a redesigned homepage, an improved search bar, better sorting options, an enhanced search result display, a metadata comparison tool, and a navigation guide. Our aim is to improve usability for a wide range of users, including both developers and researchers.",
      "authors": [
        "Yihang Zhao",
        "Albert Mero\\~no-Pe\\~nuela",
        "Elena Simperl"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-23T14:57:34+00:00",
          "link": "https://arxiv.org/abs/2403.15861v1",
          "size": "4219kb",
          "version": "v1"
        },
        {
          "date": "2024-08-04T20:29:22+00:00",
          "link": "https://arxiv.org/abs/2403.15861v2",
          "size": "3263kb",
          "version": "v2"
        }
      ],
      "title": "User Experience In Dataset Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.15861",
        "HTML": "https://arxiv.org/html/2403.15861",
        "PDF": "https://arxiv.org/pdf/2403.15861"
      },
      "source": "arXiv"
    },
    {
      "id": "2409.02352",
      "abstract": "The power packet dispatching system has been studied for power management with strict tie to an accompanying information system through power packetization. In the system, integrated units of transfer of power and information, called power packets, are delivered through a network of apparatuses called power packet routers. This paper proposes upstream allocation of a bidirectional load demand represented by a sequence of power packets to power sources. We first develop a scheme of power packet routing for upstream allocation of load demand with full integration of power and information transfer. The routing scheme is then proved to enable packetized management of bidirectional load demand, which is of practical importance for applicability to, e.g., electric drives in motoring and regenerating operations. We present a way of packetizing the bidirectional load demand and realizing the power and information flow under the upstream allocation scheme. The viability of the proposed methods is demonstrated through experiments.",
      "authors": [
        "Shiu Mochiyama",
        "Kento Hiwatashi",
        "Takashi Hikihara"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-04T00:52:40+00:00",
          "link": "https://arxiv.org/abs/2409.02352v1",
          "size": "520kb",
          "version": "v1"
        },
        {
          "date": "2024-09-10T02:15:47+00:00",
          "link": "https://arxiv.org/abs/2409.02352v2",
          "size": "1382kb",
          "version": "v2"
        },
        {
          "date": "2024-12-06T06:26:48+00:00",
          "link": "https://arxiv.org/abs/2409.02352v3",
          "size": "12403kb",
          "version": "v3"
        }
      ],
      "title": "Upstream Allocation of Bidirectional Load Demand by Power Packetization",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.02352",
        "HTML": "https://arxiv.org/html/2409.02352",
        "PDF": "https://arxiv.org/pdf/2409.02352"
      },
      "tasks": [
        "Management"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.17396",
      "abstract": "Ultrasound fetal imaging is beneficial to support prenatal development because it is affordable and non-intrusive. Nevertheless, fetal plane classification (FPC) remains challenging and time-consuming for obstetricians since it depends on nuanced clinical aspects, which increases the difficulty in identifying relevant features of the fetal anatomy. Thus, to assist with its accurate feature extraction, a lightweight artificial intelligence architecture leveraging convolutional neural networks and attention mechanisms is proposed to classify the largest benchmark ultrasound dataset. The approach fine-tunes from lightweight EfficientNet feature extraction backbones pre-trained on the ImageNet1k. to classify key fetal planes such as the brain, femur, thorax, cervix, and abdomen. Our methodology incorporates the attention mechanism to refine features and 3-layer perceptrons for classification, achieving superior performance with the highest Top-1 accuracy of 96.25%, Top-2 accuracy of 99.80% and F1-Score of 0.9576. Importantly, the model has 40x fewer trainable parameters than existing benchmark ensemble or transformer pipelines, facilitating easy deployment on edge devices to help clinical practitioners with real-time FPC. The findings are also interpreted using GradCAM to carry out clinical correlation to aid doctors with diagnostics and improve treatment plans for expectant mothers.",
      "authors": [
        "Arrun Sivasubramanian",
        "Divya Sasidharan",
        "Sowmya V and Vinayakumar Ravi"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Image and Video Processing (eess.IV)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-22T20:02:38+00:00",
          "link": "https://arxiv.org/abs/2410.17396v1",
          "size": "2143kb",
          "version": "v1"
        }
      ],
      "title": "Efficient Feature Extraction Using Light-Weight CNN Attention-Based Deep Learning Architectures for Ultrasound Fetal Plane Classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.17396",
        "HTML": "https://arxiv.org/html/2410.17396",
        "PDF": "https://arxiv.org/pdf/2410.17396"
      },
      "tasks": [
        "Anatomy"
      ],
      "source": "arXiv"
    },
    {
      "id": "2310.10060",
      "abstract": "Data Augmentation (DA) has become a critical approach in Time Series Classification (TSC), primarily for its capacity to expand training datasets, enhance model robustness, introduce diversity, and reduce overfitting. However, the current landscape of DA in TSC is plagued with fragmented literature reviews, nebulous methodological taxonomies, inadequate evaluative measures, and a dearth of accessible and user-oriented tools. This study addresses these challenges through a comprehensive examination of DA methodologies within the TSC domain.Our research began with an extensive literature review spanning a decade, revealing significant gaps in existing surveys and necessitating a detailed analysis of over 100 scholarly articles to identify more than 60 distinct DA techniques. This rigorous review led to the development of a novel taxonomy tailored to the specific needs of DA in TSC, categorizing techniques into five primary categories: Transformation-Based, Pattern-Based, Generative, Decomposition-Based, and Automated Data Augmentation. This taxonomy is intended to guide researchers in selecting appropriate methods with greater clarity. In response to the lack of comprehensive evaluations of foundational DA techniques, we conducted a thorough empirical study, testing nearly 20 DA strategies across 15 diverse datasets representing all types within the UCR time-series repository. Using ResNet and LSTM architectures, we employed a multifaceted evaluation approach, including metrics such as Accuracy, Method Ranking, and Residual Analysis, resulting in a benchmark accuracy of 84.98 +- 16.41% in ResNet and 82.41 +- 18.71% in LSTM. Our investigation underscored the inconsistent efficacies of DA techniques, for instance, methods like RGWs and Random Permutation significantly improved model performance, whereas others, like EMD, were less effective.",
      "authors": [
        "Zijun Gao",
        "Haibao Liu and Lingbo Li"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2023-10-16T04:49:51+00:00",
          "link": "https://arxiv.org/abs/2310.10060v1",
          "size": "2066kb",
          "version": "v1"
        },
        {
          "date": "2023-10-19T12:11:22+00:00",
          "link": "https://arxiv.org/abs/2310.10060v2",
          "size": "2062kb",
          "version": "v2"
        },
        {
          "date": "2024-03-20T12:25:51+00:00",
          "link": "https://arxiv.org/abs/2310.10060v3",
          "size": "2241kb",
          "version": "v3"
        },
        {
          "date": "2024-04-09T08:54:14+00:00",
          "link": "https://arxiv.org/abs/2310.10060v4",
          "size": "2269kb",
          "version": "v4"
        },
        {
          "date": "2024-08-24T12:23:59+00:00",
          "link": "https://arxiv.org/abs/2310.10060v5",
          "size": "6588kb",
          "version": "v5"
        },
        {
          "date": "2025-05-24T21:59:14+00:00",
          "link": "https://arxiv.org/abs/2310.10060v6",
          "size": "6589kb",
          "version": "v6"
        },
        {
          "date": "2025-06-02T15:00:25+00:00",
          "link": "https://arxiv.org/abs/2310.10060v7",
          "size": "3789kb",
          "version": "v7"
        }
      ],
      "title": "Data Augmentation for Time-Series Classification: An Extensive Empirical Study and Comprehensive Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2310.10060",
        "HTML": "https://arxiv.org/html/2310.10060",
        "PDF": "https://arxiv.org/pdf/2310.10060"
      },
      "tasks": [
        "Articles",
        "Classification",
        "Data Augmentation",
        "Time Series",
        "Time Series Classification"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.08121",
      "abstract": "The digital revolution has significantly impacted financial transactions, leading to a notable increase in credit card usage. However, this convenience comes with a trade-off: a substantial rise in fraudulent activities. Traditional machine learning methods for fraud detection often struggle to capture the inherent interconnectedness within financial data. This paper proposes a novel approach for credit card fraud detection that leverages Graph Neural Networks (GNNs) with attention mechanisms applied to heterogeneous graph representations of financial data. Unlike homogeneous graphs, heterogeneous graphs capture intricate relationships between various entities in the financial ecosystem, such as cardholders, merchants, and transactions, providing a richer and more comprehensive data representation for fraud analysis. To address the inherent class imbalance in fraud data, where genuine transactions significantly outnumber fraudulent ones, the proposed approach integrates an autoencoder. This autoencoder, trained on genuine transactions, learns a latent representation and flags deviations during reconstruction as potential fraud. This research investigates two key questions: (1) How effectively can a GNN with an attention mechanism detect and prevent credit card fraud when applied to a heterogeneous graph? (2) How does the efficacy of the autoencoder with attention approach compare to traditional methods? The results are promising, demonstrating that the proposed model outperforms benchmark algorithms such as Graph Sage and FI-GRL, achieving a superior AUC-PR of 0.89 and an F1-score of 0.81. This research significantly advances fraud detection systems and the overall security of financial transactions by leveraging GNNs with attention mechanisms and addressing class imbalance through an autoencoder.",
      "authors": [
        "Moirangthem Tiken Singh",
        "Rabinder Kumar Prasad",
        "Gurumayum Robert Michael",
        "N K Kaphungkui",
        "N.Hemarjit Singh"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-10T17:05:27+00:00",
          "link": "https://arxiv.org/abs/2410.08121v1",
          "size": "1025kb",
          "version": "v1"
        }
      ],
      "title": "Heterogeneous Graph Auto-Encoder for CreditCard Fraud Detection",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.08121",
        "HTML": "https://arxiv.org/html/2410.08121",
        "PDF": "https://arxiv.org/pdf/2410.08121"
      },
      "tasks": [
        "Fraud Detection"
      ],
      "source": "arXiv"
    },
    {
      "id": "2108.04059",
      "abstract": "Sensing systems powered by energy harvesting have traditionally been designed to tolerate long periods without energy. As the Internet of Things (IoT) evolves towards a more transient and opportunistic execution paradigm, reducing energy storage costs will be key for its economic and ecologic viability. However, decreasing energy storage in harvesting systems introduces reliability issues. Transducers only produce intermittent energy at low voltage and current levels, making guaranteed task completion a challenge. Existing ad hoc methods overcome this by buffering enough energy either for single tasks, incurring large data-retention overheads, or for one full application cycle, requiring a large energy buffer. We present Julienning: an automated method for optimizing the total energy cost of batteryless applications. Using a custom specification model, developers can describe transient applications as a set of atomically executed kernels with explicit data dependencies. Our optimization flow can partition data- and energy-intensive applications into multiple execution cycles with bounded energy consumption. By leveraging interkernel data dependencies, these energy-bounded execution cycles minimize the number of system activations and nonvolatile data transfers, and thus the total energy overhead. We validate our methodology with two batteryless cameras running energy-intensive machine learning applications. Results demonstrate that compared to ad hoc solutions, our method can reduce the required energy storage by over 94% while only incurring a 0.12% energy overhead.",
      "authors": [
        "Andres Gomez",
        "Andreas Tretter",
        "Pascal Alexander Hager",
        "Praveenth Sanmugarajah",
        "Luca Benini",
        "Lothar Thiele"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "Hardware Architecture (cs.AR)",
        "Machine Learning (cs.LG)",
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2021-08-05T09:49:42+00:00",
          "link": "https://arxiv.org/abs/2108.04059v1",
          "size": "3309kb",
          "version": "v1"
        }
      ],
      "title": "Memory-Aware Partitioning of Machine Learning Applications for Optimal Energy Use in Batteryless Systems",
      "links": {
        "Abstract": "https://arxiv.org/abs/2108.04059",
        "PDF": "https://arxiv.org/pdf/2108.04059"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2403.16565",
      "abstract": "A promising step from linear towards nonlinear data-driven control is via the design of controllers for linear parameter-varying (LPV) systems, which are linear systems whose parameters are varying along a measurable scheduling signal. However, the interplay between uncertainty arising from corrupted data and the parameter-varying nature of these systems impacts the stability analysis and limits the generalization of well-understood data-driven methods available for linear time-invariant systems. In this work, we decouple this interplay using a recently developed variant of the Fundamental Lemma for LPV systems and the concept of data-informativity, in combination with biquadratic Lyapunov forms. Together, these allow us to develop novel linear matrix inequality conditions for the existence of scheduling-dependent Lyapunov functions, incorporating the intrinsic nonlinearity. Appealingly, these results are stated purely in terms of the collected data and bounds on the noise, and they are computationally favorable to check.",
      "authors": [
        "Chris Verhoek",
        "Jaap Eising",
        "Florian D\\\"orfler and Roland T\\'oth"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Systems and Control (eess.SY)",
        "Systems and Control (cs.SY)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-25T09:32:29+00:00",
          "link": "https://arxiv.org/abs/2403.16565v1",
          "size": "210kb",
          "version": "v1"
        },
        {
          "date": "2024-09-16T14:09:26+00:00",
          "link": "https://arxiv.org/abs/2403.16565v2",
          "size": "157kb",
          "version": "v2"
        }
      ],
      "title": "Decoupling parameter variation from noise: Biquadratic Lyapunov forms in data-driven LPV control",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.16565",
        "HTML": "https://arxiv.org/html/2403.16565",
        "PDF": "https://arxiv.org/pdf/2403.16565"
      },
      "tasks": [
        "LEMMA",
        "Scheduling"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.06976",
      "abstract": "Power system operators need new, efficient operational tools to use the flexibility of distributed resources and deal with the challenges of highly uncertain and variable power systems. Transmission system operators can consider the available flexibility in distribution systems (DSs) without breaching the DS constraints through flexibility areas. However, there is an absence of open-source packages for flexibility area estimation. This paper introduces TensorConvolutionPlus, a user-friendly Python-based package for flexibility area estimation. The main features of TensorConvolutionPlus include estimating flexibility areas using the TensorConvolution+ algorithm, the power flow-based algorithm, an exhaustive PF-based algorithm, and an optimal power flow-based algorithm. Additional features include adapting flexibility area estimations from different operating conditions and including flexibility service providers offering discrete setpoints of flexibility. The TensorConvolutionPlus package facilitates a broader adaptation of flexibility estimation algorithms by system operators and power system researchers.",
      "authors": [
        "Demetris Chrysostomou",
        "and Jose Luis Rueda Torres",
        "and Jochen Lorenz Cremer"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)",
        "Systems and Control (cs.SY)",
        "Systems and Control (eess.SY)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-12T23:27:08+00:00",
          "link": "https://arxiv.org/abs/2501.06976v1",
          "size": "2279kb",
          "version": "v1"
        }
      ],
      "title": "TensorConvolutionPlus: A python package for distribution system flexibility area estimation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.06976",
        "PDF": "https://arxiv.org/pdf/2501.06976"
      },
      "repo_urls": [
        "https://github.com/demetris-ch/tensorconvolutionflexibility"
      ],
      "source": "arXiv"
    },
    {
      "id": "1807.01772",
      "abstract": "A growing number of largely uncoordinated initiatives focus on research software sustainability. A comprehensive mapping of the research software sustainability space can help identify gaps in their efforts, track results, and avoid duplication of work. To this end, this paper suggests enhancing an existing schematic of activities in research software sustainability, and formalizing it in a directed graph model. Such a model can be further used to define a classification schema which, applied to research results in the field, can drive the identification of past activities and the planning of future efforts.",
      "authors": [
        "Stephan Druskat",
        "Daniel S. Katz"
      ],
      "license": "http://creativecommons.org/licenses/by-sa/4.0/",
      "subjects": [
        "Software Engineering (cs.SE)"
      ],
      "submission_historys": [
        {
          "date": "2018-07-04T20:56:26+00:00",
          "link": "https://arxiv.org/abs/1807.01772v1",
          "size": "156kb",
          "version": "v1"
        },
        {
          "date": "2018-10-26T21:55:07+00:00",
          "link": "https://arxiv.org/abs/1807.01772v2",
          "size": "226kb",
          "version": "v2"
        }
      ],
      "title": "Mapping the research software sustainability space",
      "links": {
        "Abstract": "https://arxiv.org/abs/1807.01772",
        "PDF": "https://arxiv.org/pdf/1807.01772"
      },
      "source": "arXiv"
    },
    {
      "id": "2506.21629",
      "abstract": "In recent years, neural rendering methods such as NeRFs and 3D Gaussian Splatting (3DGS) have made significant progress in scene reconstruction and novel view synthesis. However, they heavily rely on preprocessed camera poses and 3D structural priors from structure-from-motion (SfM), which are challenging to obtain in outdoor scenarios. To address this challenge, we propose to incorporate Iterative Closest Point (ICP) with optimization-based refinement to achieve accurate camera pose estimation under large camera movements. Additionally, we introduce a voxel-based scene densification approach to guide the reconstruction in large-scale scenes. Experiments demonstrate that our approach ICP-3DGS outperforms existing methods in both camera pose estimation and novel view synthesis across indoor and outdoor scenes of various scales. Source code is available at https://github.com/Chenhao-Z/ICP-3DGS.",
      "authors": [
        "Chenhao Zhang",
        "Yezhi Shen",
        "Fengqing Zhu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Graphics (cs.GR)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-24T21:10:06+00:00",
          "link": "https://arxiv.org/abs/2506.21629v1",
          "size": "8274kb",
          "version": "v1"
        }
      ],
      "title": "ICP-3DGS: SfM-free 3D Gaussian Splatting for Large-scale Unbounded Scenes",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.21629",
        "HTML": "https://arxiv.org/html/2506.21629",
        "PDF": "https://arxiv.org/pdf/2506.21629"
      },
      "relevance": {
        "keyword": "train_data",
        "level": "none-irrelevant",
        "reason": "This paper deals with 3D Gaussian Splatting for scene reconstruction, which is unrelated to the processing or construction of LLM training data."
      },
      "source": "arXiv"
    },
    {
      "id": "2410.11399",
      "abstract": "This article reviews and develops an epistemological tradition in the philosophy of science, known as convergentism, which holds that inference methods should be assessed based on their ability to converge to the truth across a range of possible scenarios. Emphasis is placed on its historical origins in the work of C. S. Peirce and its recent developments in formal epistemology and data science (including statistics and machine learning). Comparisons are made with three other traditions: (1) explanationism, which holds that theory choice should be guided by a theory's overall balance of explanatory virtues, such as simplicity and fit with data; (2) instrumentalism, which maintains that scientific inference should be driven by the goal of obtaining useful models rather than true theories; and (3) Bayesianism, which shifts the focus from all-or-nothing beliefs to degrees of belief.",
      "authors": [
        "Hanti Lin"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Other Statistics (stat.OT)",
        "Artificial Intelligence (cs.AI)",
        "Machine Learning (cs.LG)",
        "Methodology (stat.ME)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-15T08:44:14+00:00",
          "link": "https://arxiv.org/abs/2410.11399v1",
          "size": "562kb",
          "version": "v1"
        },
        {
          "date": "2025-02-25T01:42:32+00:00",
          "link": "https://arxiv.org/abs/2410.11399v2",
          "size": "562kb",
          "version": "v2"
        }
      ],
      "title": "Convergence to the Truth",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.11399",
        "HTML": "https://arxiv.org/html/2410.11399",
        "PDF": "https://arxiv.org/pdf/2410.11399"
      },
      "tasks": [
        "Philosophy"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.20426",
      "abstract": "The proliferation of large language models (LLMs) and autonomous AI agents has raised concerns about their potential for automated persuasion and social influence. While existing research has explored isolated instances of LLM-based manipulation, systematic evaluations of persuasion capabilities across different models remain limited. In this paper, we present an Among Us-inspired game framework for assessing LLM deception skills in a controlled environment. The proposed framework makes it possible to compare LLM models by game statistics, as well as quantify in-game manipulation according to 25 persuasion strategies from social psychology and rhetoric. Experiments between 8 popular language models of different types and sizes demonstrate that all tested models exhibit persuasive capabilities, successfully employing 22 of the 25 anticipated techniques. We also find that larger models do not provide any persuasion advantage over smaller models and that longer model outputs are negatively correlated with the number of games won. Our study provides insights into the deception capabilities of LLMs, as well as tools and data for fostering future research on the topic.",
      "authors": [
        "Mateusz Idziejczak",
        "Vasyl Korzavatykh",
        "Mateusz Stawicki",
        "Andrii Chmutov",
        "Marcin Korcz",
        "Iwo B{\\l}\\k{a}dek",
        "Dariusz Brzezinski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)",
        "Artificial Intelligence (cs.AI)",
        "Computers and Society (cs.CY)",
        "Multiagent Systems (cs.MA)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-27T12:26:21+00:00",
          "link": "https://arxiv.org/abs/2502.20426v1",
          "size": "401kb",
          "version": "v1"
        }
      ],
      "title": "Among Them: A game-based framework for assessing persuasion capabilities of LLMs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.20426",
        "HTML": "https://arxiv.org/html/2502.20426",
        "PDF": "https://arxiv.org/pdf/2502.20426"
      },
      "tasks": [
        "Persuasion Strategies"
      ],
      "repo_urls": [
        "https://github.com/farmerobot/among_them"
      ],
      "source": "arXiv"
    },
    {
      "id": "2412.17283",
      "abstract": "The increasing demands of sustainable energy, electronics, and biomedical applications call for next-generation functional materials with unprecedented properties. Of particular interest are emerging materials that display exceptional physical properties, making them promising candidates in energy-efficient microelectronic devices. As the conventional Edisonian approach becomes significantly outpaced by growing societal needs, emerging computational modeling and machine learning (ML) methods are employed for the rational design of materials. However, the complex physical mechanisms, cost of first-principles calculations, and the dispersity and scarcity of data pose challenges to both physics-based and data-driven materials modeling. Moreover, the combinatorial composition-structure design space is high-dimensional and often disjoint, making design optimization nontrivial. In this Account, we review a team effort toward establishing a framework that integrates data-driven and physics-based methods to address these challenges and accelerate materials design. We begin by presenting our integrated materials design framework and its three components in a general context. We then provide an example of applying this materials design framework to metal-insulator transition (MIT) materials, a specific type of emerging materials with practical importance in next-generation memory technologies. We identify multiple new materials which may display this property and propose pathways for their synthesis. Finally, we identify some outstanding challenges in data-driven materials design, such as materials data quality issues and property-performance mismatch. We seek to raise awareness of these overlooked issues hindering materials design, thus stimulating efforts toward developing methods to mitigate the gaps.",
      "authors": [
        "Hengrui Zhang",
        "Alexandru B. Georgescu",
        "Suraj Yerramilli",
        "Christopher Karpovich",
        "Daniel W. Apley",
        "Elsa A. Olivetti",
        "James M. Rondinelli",
        "Wei Chen"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Materials Science (cond-mat.mtrl-sci)",
        "Computational Engineering, Finance, and Science (cs.CE)",
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2024-12-23T05:06:19+00:00",
          "link": "https://arxiv.org/abs/2412.17283v1",
          "size": "2115kb",
          "version": "v1"
        },
        {
          "date": "2025-02-04T04:38:31+00:00",
          "link": "https://arxiv.org/abs/2412.17283v2",
          "size": "2002kb",
          "version": "v2"
        }
      ],
      "title": "Emerging Microelectronic Materials by Design: Navigating Combinatorial Design Space with Scarce and Dispersed Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2412.17283",
        "HTML": "https://arxiv.org/html/2412.17283",
        "PDF": "https://arxiv.org/pdf/2412.17283"
      },
      "tasks": [],
      "source": "arXiv"
    },
    {
      "id": "2502.19122",
      "abstract": "With predictive models becoming prevalent, companies are expanding the types of data they gather. As a result, the collected datasets consist not only of simple numerical features but also more complex objects such as time series, images, or graphs. Such multi-modal data have the potential to improve performance in predictive tasks like outlier detection, where the goal is to identify objects deviating from the main data distribution. However, current outlier detection algorithms are dedicated to individual types of data. Consequently, working with mixed types of data requires either fusing multiple data-specific models or transforming all of the representations into a single format, both of which can hinder predictive performance. In this paper, we propose a multi-modal outlier detection algorithm called Random Similarity Isolation Forest. Our method combines the notions of isolation and similarity-based projection to handle datasets with mixtures of features of arbitrary data types. Experiments performed on 47 benchmark datasets demonstrate that Random Similarity Isolation Forest outperforms five state-of-the-art competitors. Our study shows that the use of multiple modalities can indeed improve the detection of anomalies and highlights the need for new outlier detection benchmarks tailored for multi-modal algorithms.",
      "authors": [
        "Sebastian Chwilczy\\'nski",
        "Dariusz Brzezinski"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-26T13:22:19+00:00",
          "link": "https://arxiv.org/abs/2502.19122v1",
          "size": "463kb",
          "version": "v1"
        }
      ],
      "title": "Random Similarity Isolation Forests",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.19122",
        "HTML": "https://arxiv.org/html/2502.19122",
        "PDF": "https://arxiv.org/pdf/2502.19122"
      },
      "source": "arXiv"
    },
    {
      "id": "2407.21252",
      "abstract": "Person search is the task to localize a query person in gallery datasets of scene images. Existing methods have been mainly developed to handle a single target dataset only, however diverse datasets are continuously given in practical applications of person search. In such cases, they suffer from the catastrophic knowledge forgetting in the old datasets when trained on new datasets. In this paper, we first introduce a novel problem of lifelong person search (LPS) where the model is incrementally trained on the new datasets while preserving the knowledge learned in the old datasets. We propose an end-to-end LPS framework that facilitates the knowledge distillation to enforce the consistency learning between the old and new models by utilizing the prototype features of the foreground persons as well as the hard background proposals in the old domains. Moreover, we also devise the rehearsal-based instance matching to further improve the discrimination ability in the old domains by using the unlabeled person instances additionally. Experimental results demonstrate that the proposed method achieves significantly superior performance of both the detection and re-identification to preserve the knowledge learned in the old domains compared with the existing methods.",
      "authors": [
        "Jae-Won Yang",
        "Seungbin Hong",
        "and Jae-Young Sim"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Artificial Intelligence (cs.AI)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-31T00:19:22+00:00",
          "link": "https://arxiv.org/abs/2407.21252v1",
          "size": "20848kb",
          "version": "v1"
        }
      ],
      "title": "Lifelong Person Search",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.21252",
        "HTML": "https://arxiv.org/html/2407.21252",
        "PDF": "https://arxiv.org/pdf/2407.21252"
      },
      "tasks": [
        "Knowledge Distillation",
        "Person Search"
      ],
      "source": "arXiv"
    },
    {
      "id": "2409.01681",
      "abstract": "In this paper we study a variant of the Nuel game (a generalization of the duel) which is played in turns by $N$ players. In each turn a single player must fire at one of the other players and has a certain probability of hitting and killing his target. The players shoot in a fixed sequence and when a player is eliminated, the ``move'' passes to the next surviving player. The winner is the last surviving player. We prove that, for every $N\\geq2$, the Nuel has a stationary Nash equilibrium and provide algorithms for its computation.",
      "authors": [
        "S. Mastrakoulis and Ath. Kehagias"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Discrete Mathematics (cs.DM)",
        "Computer Science and Game Theory (cs.GT)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-03T07:45:54+00:00",
          "link": "https://arxiv.org/abs/2409.01681v1",
          "size": "520kb",
          "version": "v1"
        }
      ],
      "title": "Static Nuel Games with Terminal Payoff",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.01681",
        "HTML": "https://arxiv.org/html/2409.01681",
        "PDF": "https://arxiv.org/pdf/2409.01681"
      },
      "source": "arXiv"
    },
    {
      "id": "2401.08426",
      "abstract": "This paper critically examines the fundamental distinctions between gradient methods applied to non-differentiable functions (NGDMs) and classical gradient descents (GDs) for differentiable functions, revealing significant gaps in current deep learning optimization theory. We demonstrate that NGDMs exhibit markedly different convergence properties compared to GDs, strongly challenging the applicability of extensive neural network convergence literature based on $L-smoothness$ to non-smooth neural networks. Our analysis reveals paradoxical behavior of NDGM solutions for $L_{1}$-regularized problems, where increasing regularization counterintuitively leads to larger $L_{1}$ norms of optimal solutions. This finding calls into question widely adopted $L_{1}$ penalization techniques for network pruning. We further challenge the common assumption that optimization algorithms like RMSProp behave similarly in differentiable and non-differentiable contexts. Expanding on the Edge of Stability phenomenon, we demonstrate its occurrence in a broader class of functions, including Lipschitz continuous convex differentiable functions. This finding raises important questions about its relevance and interpretation in non-convex, non-differentiable neural networks, particularly those using ReLU activations. Our work identifies critical misunderstandings of NDGMs in influential literature, stemming from an overreliance on strong smoothness assumptions. These findings necessitate a reevaluation of optimization dynamics in deep learning, emphasizing the crucial need for more nuanced theoretical foundations in analyzing these complex systems.",
      "authors": [
        "Siddharth Krishna Kumar"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Machine Learning (cs.LG)",
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-01-16T15:11:29+00:00",
          "link": "https://arxiv.org/abs/2401.08426v1",
          "size": "2076kb",
          "version": "v1"
        },
        {
          "date": "2024-02-01T01:17:45+00:00",
          "link": "https://arxiv.org/abs/2401.08426v2",
          "size": "1580kb",
          "version": "v2"
        },
        {
          "date": "2024-05-09T00:45:37+00:00",
          "link": "https://arxiv.org/abs/2401.08426v3",
          "size": "8729kb",
          "version": "v3"
        },
        {
          "date": "2024-11-05T19:57:19+00:00",
          "link": "https://arxiv.org/abs/2401.08426v4",
          "size": "8859kb",
          "version": "v4"
        },
        {
          "date": "2024-11-07T18:22:41+00:00",
          "link": "https://arxiv.org/abs/2401.08426v5",
          "size": "8859kb",
          "version": "v5"
        },
        {
          "date": "2024-11-18T22:26:15+00:00",
          "link": "https://arxiv.org/abs/2401.08426v6",
          "size": "8859kb",
          "version": "v6"
        },
        {
          "date": "2025-04-27T04:27:49+00:00",
          "link": "https://arxiv.org/abs/2401.08426v7",
          "size": "10661kb",
          "version": "v7"
        },
        {
          "date": "2025-06-02T00:49:57+00:00",
          "link": "https://arxiv.org/abs/2401.08426v8",
          "size": "4656kb",
          "version": "v8"
        },
        {
          "date": "2025-06-12T01:28:41+00:00",
          "link": "https://arxiv.org/abs/2401.08426v9",
          "size": "4656kb",
          "version": "v9"
        },
        {
          "date": "2025-06-19T03:22:11+00:00",
          "link": "https://arxiv.org/abs/2401.08426v10",
          "size": "4657kb",
          "version": "v10"
        },
        {
          "date": "2025-06-29T15:33:13+00:00",
          "link": "https://arxiv.org/abs/2401.08426v11",
          "size": "4659kb",
          "version": "v11"
        }
      ],
      "title": "GD doesn't make the cut: Three ways that non-differentiability affects neural network training",
      "links": {
        "Abstract": "https://arxiv.org/abs/2401.08426",
        "HTML": "https://arxiv.org/html/2401.08426",
        "PDF": "https://arxiv.org/pdf/2401.08426"
      },
      "tasks": [
        "Network Pruning"
      ],
      "source": "arXiv"
    },
    {
      "id": "2106.06887",
      "abstract": "Event cameras, inspired by biological vision systems, provide a natural and data efficient representation of visual information. Visual information is acquired in the form of events that are triggered by local brightness changes. Each pixel location of the camera's sensor records events asynchronously and independently with very high temporal resolution. However, because most brightness changes are triggered by relative motion of the camera and the scene, the events recorded at a single sensor location seldom correspond to the same world point. To extract meaningful information from event cameras, it is helpful to register events that were triggered by the same underlying world point. In this work we propose a new model of event data that captures its natural spatio-temporal structure. We start by developing a model for aligned event data. That is, we develop a model for the data as though it has been perfectly registered already. In particular, we model the aligned data as a spatio-temporal Poisson point process. Based on this model, we develop a maximum likelihood approach to registering events that are not yet aligned. That is, we find transformations of the observed events that make them as likely as possible under our model. In particular we extract the camera rotation that leads to the best event alignment. We show new state of the art accuracy for rotational velocity estimation on the DAVIS 240C dataset. In addition, our method is also faster and has lower computational complexity than several competing methods.",
      "authors": [
        "Cheng Gu",
        "Erik Learned-Miller",
        "Daniel Sheldon",
        "Guillermo Gallego",
        "Pia Bideau"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2021-06-13T00:43:27+00:00",
          "link": "https://arxiv.org/abs/2106.06887v1",
          "size": "6538kb",
          "version": "v1"
        }
      ],
      "title": "The Spatio-Temporal Poisson Point Process: A Simple Model for the Alignment of Event Camera Data",
      "links": {
        "Abstract": "https://arxiv.org/abs/2106.06887",
        "PDF": "https://arxiv.org/pdf/2106.06887"
      },
      "conference_url_abs": "http://openaccess.thecvf.com//content/ICCV2021/html/Gu_The_Spatio-Temporal_Poisson_Point_Process_A_Simple_Model_for_the_ICCV_2021_paper.html",
      "tasks": [],
      "repo_urls": [
        "https://github.com/pbideau/Event-ST-PPP"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.20813",
      "abstract": "Following a growing number of studies that, over the past 15 years, have established entropy inequalities via ideas and tools from additive combinatorics, in this work we obtain a number of new bounds for the differential entropy of sums, products, and sum-product combinations of continuous random variables. Partly motivated by recent work by Goh on the discrete entropic version of the notion of \"additive energy\", we introduce the additive energy of pairs of continuous random variables and prove various versions of the statement that \"the additive energy is large if and only if the entropy of the sum is small\", along with a version of the Balog-Szemer\\'edi-Gowers theorem for differential entropy. Then, motivated in part by recent work by M\\'ath\\'e and O'Regan, we establish a series of new differential entropy inequalities for products and sum-product combinations of continuous random variables. In particular, we prove a new, general, ring Pl\\\"unnecke-Ruzsa entropy inequality. We briefly return to the case of discrete entropy and provide a characterization of discrete random variables with \"large doubling\", analogous to Tao's Freiman-type inverse sumset theory for the case of small doubling. Finally, we consider the natural entropic analog of the Erd\\\"os-Szemer\\'edi sum-product phenomenon for integer-valued random variables. We show that, if it does hold, then the range of parameters for which it does would necessarily be significantly more restricted than its anticipated combinatorial counterpart.",
      "authors": [
        "Rupert Li",
        "Lampros Gavalakis",
        "Ioannis Kontoyiannis"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Information Theory (cs.IT)",
        "Combinatorics (math.CO)",
        "Information Theory (math.IT)",
        "Probability (math.PR)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T20:22:12+00:00",
          "link": "https://arxiv.org/abs/2506.20813v1",
          "size": "32kb",
          "version": "v1"
        }
      ],
      "title": "Entropic additive energy and entropy inequalities for sums and products",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20813",
        "HTML": "https://arxiv.org/html/2506.20813",
        "PDF": "https://arxiv.org/pdf/2506.20813"
      },
      "source": "arXiv"
    },
    {
      "id": "2409.17680",
      "abstract": "Stereopsis has widespread appeal in robotics as it is the predominant way by which living beings perceive depth to navigate our 3D world. Event cameras are novel bio-inspired sensors that detect per-pixel brightness changes asynchronously, with very high temporal resolution and high dynamic range, enabling machine perception in high-speed motion and broad illumination conditions. The high temporal precision also benefits stereo matching, making disparity (depth) estimation a popular research area for event cameras ever since its inception. Over the last 30 years, the field has evolved rapidly, from low-latency, low-power circuit design to current deep learning (DL) approaches driven by the computer vision community. The bibliography is vast and difficult to navigate for non-experts due its highly interdisciplinary nature. Past surveys have addressed distinct aspects of this topic, in the context of applications, or focusing only on a specific class of techniques, but have overlooked stereo datasets. This survey provides a comprehensive overview, covering both instantaneous stereo and long-term methods suitable for simultaneous localization and mapping (SLAM), along with theoretical and empirical comparisons. It is the first to extensively review DL methods as well as stereo datasets, even providing practical suggestions for creating new benchmarks to advance the field. The main advantages and challenges faced by event-based stereo depth estimation are also discussed. Despite significant progress, challenges remain in achieving optimal performance in not only accuracy but also efficiency, a cornerstone of event-based computing. We identify several gaps and propose future research directions. We hope this survey inspires future research in this area, by serving as an accessible entry point for newcomers, as well as a practical guide for seasoned researchers in the community.",
      "authors": [
        "Suman Ghosh and Guillermo Gallego"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)",
        "Robotics (cs.RO)"
      ],
      "submission_historys": [
        {
          "date": "2024-09-26T09:43:50+00:00",
          "link": "https://arxiv.org/abs/2409.17680v1",
          "size": "27135kb",
          "version": "v1"
        },
        {
          "date": "2025-05-27T20:26:36+00:00",
          "link": "https://arxiv.org/abs/2409.17680v2",
          "size": "31921kb",
          "version": "v2"
        }
      ],
      "title": "Event-based Stereo Depth Estimation: A Survey",
      "links": {
        "Abstract": "https://arxiv.org/abs/2409.17680",
        "PDF": "https://arxiv.org/pdf/2409.17680"
      },
      "tasks": [
        "Depth Estimation",
        "Navigate",
        "Simultaneous Localization and Mapping",
        "Stereo Depth Estimation",
        "Stereo Matching",
        "Survey"
      ],
      "repo_urls": [
        "https://github.com/tub-rip/es-ptam",
        "https://github.com/tub-rip/dvs_mcemvs"
      ],
      "source": "arXiv"
    },
    {
      "id": "2404.19626",
      "abstract": "The article introduces a method to learn dynamical systems that are governed by Euler--Lagrange equations from data. The method is based on Gaussian process regression and identifies continuous or discrete Lagrangians and is, therefore, structure preserving by design. A rigorous proof of convergence as the distance between observation data points converges to zero and lower bounds for convergence rates are provided. Next to convergence guarantees, the method allows for quantification of model uncertainty, which can provide a basis of adaptive sampling techniques. We provide efficient uncertainty quantification of any observable that is linear in the Lagrangian, including of Hamiltonian functions (energy) and symplectic structures, which is of interest in the context of system identification. The article overcomes major practical and theoretical difficulties related to the ill-posedness of the identification task of (discrete) Lagrangians through a careful design of geometric regularisation strategies and through an exploit of a relation to convex minimisation problems in reproducing kernel Hilbert spaces.",
      "authors": [
        "Christian Offen"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Numerical Analysis (math.NA)",
        "Numerical Analysis (cs.NA)",
        "Dynamical Systems (math.DS)"
      ],
      "submission_historys": [
        {
          "date": "2024-04-30T15:24:53+00:00",
          "link": "https://arxiv.org/abs/2404.19626v1",
          "size": "1290kb",
          "version": "v1"
        },
        {
          "date": "2025-02-19T13:18:43+00:00",
          "link": "https://arxiv.org/abs/2404.19626v2",
          "size": "1330kb",
          "version": "v2"
        },
        {
          "date": "2025-05-02T13:48:45+00:00",
          "link": "https://arxiv.org/abs/2404.19626v3",
          "size": "1314kb",
          "version": "v3"
        }
      ],
      "title": "Machine learning of continuous and discrete variational ODEs with convergence guarantee and uncertainty quantification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2404.19626",
        "PDF": "https://arxiv.org/pdf/2404.19626"
      },
      "repo_urls": [
        "https://github.com/Christian-Offen/Lagrangian_GP"
      ],
      "source": "arXiv"
    },
    {
      "id": "2501.17042",
      "abstract": "Natural systems are modeled by networks with nodes and links. Often the nodes are segregated into communities with different connectivity patterns. Node heterogeneity such as political affiliation in social networks or biological function in gene networks are highlighted as key factors driving the segregation of nodes into communities. Here, by means of numerical simulations, I show that node heterogeneity is not a necessary requirement. To this end I introduce the Ramsey community number, $r_ \\kappa$, the minimum graph size that warranties the emergence of network communities with almost certainty. Using the stochastic block model and Infomap methods for community detection, I show that networks generated by local rules have finite $r_ \\kappa$ values while their randomized versions do not have emergent communities. I conjecture that network communities are an emergent property of networks evolving with local rules.",
      "authors": [
        "Alexei Vazquez"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Physics and Society (physics.soc-ph)",
        "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
        "Discrete Mathematics (cs.DM)",
        "Social and Information Networks (cs.SI)",
        "Combinatorics (math.CO)"
      ],
      "submission_historys": [
        {
          "date": "2025-01-28T16:07:41+00:00",
          "link": "https://arxiv.org/abs/2501.17042v1",
          "size": "65kb",
          "version": "v1"
        },
        {
          "date": "2025-04-03T06:01:15+00:00",
          "link": "https://arxiv.org/abs/2501.17042v2",
          "size": "103kb",
          "version": "v2"
        },
        {
          "date": "2025-05-25T13:54:24+00:00",
          "link": "https://arxiv.org/abs/2501.17042v3",
          "size": "103kb",
          "version": "v3"
        },
        {
          "date": "2025-06-09T19:39:00+00:00",
          "link": "https://arxiv.org/abs/2501.17042v4",
          "size": "99kb",
          "version": "v4"
        }
      ],
      "title": "Emergence of network communities driven by local rules",
      "links": {
        "Abstract": "https://arxiv.org/abs/2501.17042",
        "HTML": "https://arxiv.org/html/2501.17042",
        "PDF": "https://arxiv.org/pdf/2501.17042"
      },
      "repo_urls": [
        "https://github.com/av2atgh/ramsey_netcom"
      ],
      "source": "arXiv"
    },
    {
      "id": "2309.12557",
      "abstract": "To alleviate the expensive human labeling, semi-supervised semantic segmentation employs a few labeled images and an abundant of unlabeled images to predict the pixel-level label map with the same size. Previous methods often adopt co-training using two convolutional networks with the same architecture but different initialization, which fails to capture the sufficiently diverse features. This motivates us to use tri-training and develop the triple-view encoder to utilize the encoders with different architectures to derive diverse features, and exploit the knowledge distillation skill to learn the complementary semantics among these encoders. Moreover, existing methods simply concatenate the features from both encoder and decoder, resulting in redundant features that require large memory cost. This inspires us to devise a dual-frequency decoder that selects those important features by projecting the features from the spatial domain to the frequency domain, where the dual-frequency channel attention mechanism is introduced to model the feature importance. Therefore, we propose a Triple-view Knowledge Distillation framework, termed TriKD, for semi-supervised semantic segmentation, including the triple-view encoder and the dual-frequency decoder. Extensive experiments were conducted on two benchmarks, \\ie, Pascal VOC 2012 and Cityscapes, whose results verify the superiority of the proposed method with a good tradeoff between precision and inference speed.",
      "authors": [
        "Ping Li and Junjie Chen and Li Yuan and Xianghua Xu and Mingli Song"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2023-09-22T01:02:21+00:00",
          "link": "https://arxiv.org/abs/2309.12557v1",
          "size": "1391kb",
          "version": "v1"
        }
      ],
      "title": "Triple-View Knowledge Distillation for Semi-Supervised Semantic Segmentation",
      "links": {
        "Abstract": "https://arxiv.org/abs/2309.12557",
        "HTML": "https://arxiv.org/html/2309.12557",
        "PDF": "https://arxiv.org/pdf/2309.12557"
      },
      "tasks": [
        "Decoder",
        "Feature Importance",
        "Knowledge Distillation",
        "Semantic Segmentation",
        "Semi-Supervised Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.05320",
      "abstract": "This paper introduces to a structured application of the One-Class approach and the One-Class-One-Network model for supervised classification tasks, specifically addressing a vowel phonemes classification case study within the Automatic Speech Recognition research field. Through pseudo-Neural Architecture Search and Hyper-Parameters Tuning experiments conducted with an informed grid-search methodology, we achieve classification accuracy comparable to nowadays complex architectures (90.0 - 93.7%). Despite its simplicity, our model prioritizes generalization of language context and distributed applicability, supported by relevant statistical and performance metrics. The experiments code is openly available at our GitHub.",
      "authors": [
        "Stefano Giacomelli",
        "Marco Giordano",
        "Claudia Rinaldi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Audio and Speech Processing (eess.AS)",
        "Artificial Intelligence (cs.AI)",
        "Computation and Language (cs.CL)",
        "Databases (cs.DB)",
        "Machine Learning (cs.LG)",
        "Sound (cs.SD)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-05T09:15:01+00:00",
          "link": "https://arxiv.org/abs/2410.05320v1",
          "size": "1371kb",
          "version": "v1"
        }
      ],
      "title": "The OCON model: an old but gold solution for distributable supervised classification",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.05320",
        "HTML": "https://arxiv.org/html/2410.05320",
        "PDF": "https://arxiv.org/pdf/2410.05320"
      },
      "tasks": [
        "Automatic Speech Recognition",
        "Classification",
        "Neural Architecture Search",
        "speech-recognition",
        "Speech Recognition"
      ],
      "repo_urls": [
        "https://github.com/StefanoGiacomelli/Vowel_phonemes_Analysis_and_Classification_by_means_of_OCON_rectifiers_Deep_Learning_Architectures"
      ],
      "source": "arXiv"
    },
    {
      "id": "2506.20884",
      "abstract": "''TikTok, Do Your Thing'' is a viral trend where users attempt to identify strangers they see in public via information crowd-sourcing. The trend started as early as 2021 and users typically engage with it for romantic purposes (similar to a ''Missed Connections'' personal advertisement). This practice includes acts of surveillance and identification in the public sphere, although by peers rather than governments or corporations. To understand users' reactions to this trend we conducted a qualitative analysis of 60 TikTok videos and 1,901 user comments. Of the 60 videos reviewed, we find 19 individuals were successfully identified. We also find that while there were comments expressing disapproval (n=310), more than double the number expressed support (n=883). Supportive comments demonstrated genuine interest and empathy, reflecting evolving conceptions of community and algorithmic engagement. On the other hand, disapproving comments highlighted concerns about inappropriate relationships, stalking, consent, and gendered double standards. We discuss these insights in relation to the normalization of interpersonal surveillance, online stalking, and as an evolution of social surveillance to offer a new perspective on user perceptions surrounding interpersonal surveillance and identification in the public sphere.",
      "authors": [
        "Meira Gilbert",
        "Miranda Wei",
        "Lindah Kotut"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Human-Computer Interaction (cs.HC)",
        "Computers and Society (cs.CY)"
      ],
      "submission_historys": [
        {
          "date": "2025-06-25T23:13:43+00:00",
          "link": "https://arxiv.org/abs/2506.20884v1",
          "size": "1215kb",
          "version": "v1"
        }
      ],
      "title": "\"TikTok, Do Your Thing\": User Reactions to Social Surveillance in the Public Sphere",
      "links": {
        "Abstract": "https://arxiv.org/abs/2506.20884",
        "PDF": "https://arxiv.org/pdf/2506.20884"
      },
      "source": "arXiv"
    },
    {
      "id": "2407.01082",
      "abstract": "Large Language Models (LLMs) generate text by sampling the next token from a probability distribution over the vocabulary at each decoding step. Popular sampling methods like top-p (nucleus sampling) often struggle to balance quality and diversity, especially at higher temperatures which lead to incoherent or repetitive outputs. We propose min-p sampling, a dynamic truncation method that adjusts the sampling threshold based on the model's confidence by using the top token's probability as a scaling factor. Our experiments on benchmarks including GPQA, GSM8K, and AlpacaEval Creative Writing show that min-p sampling improves both the quality and diversity of generated text across different model families (Mistral and Llama 3) and model sizes (1B to 123B parameters), especially at higher temperatures. Human evaluations further show a clear preference for min-p sampling, in both text quality and creativity. Min-p sampling has been adopted by popular open-source LLM frameworks, including Hugging Face Transformers, VLLM, and many others, highlighting its considerable impact on improving text generation quality.",
      "authors": [
        "Minh Nhat Nguyen",
        "Andrew Baker",
        "Clement Neo",
        "Allen Roush",
        "Andreas Kirsch",
        "Ravid Shwartz-Ziv"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Computation and Language (cs.CL)"
      ],
      "submission_historys": [
        {
          "date": "2024-07-01T08:37:25+00:00",
          "link": "https://arxiv.org/abs/2407.01082v1",
          "size": "8670kb",
          "version": "v1"
        },
        {
          "date": "2024-10-13T11:21:55+00:00",
          "link": "https://arxiv.org/abs/2407.01082v2",
          "size": "8634kb",
          "version": "v2"
        },
        {
          "date": "2025-03-16T17:12:44+00:00",
          "link": "https://arxiv.org/abs/2407.01082v3",
          "size": "8661kb",
          "version": "v3"
        },
        {
          "date": "2025-03-20T09:39:39+00:00",
          "link": "https://arxiv.org/abs/2407.01082v4",
          "size": "8661kb",
          "version": "v4"
        },
        {
          "date": "2025-05-19T21:28:19+00:00",
          "link": "https://arxiv.org/abs/2407.01082v5",
          "size": "8663kb",
          "version": "v5"
        },
        {
          "date": "2025-05-27T17:15:03+00:00",
          "link": "https://arxiv.org/abs/2407.01082v6",
          "size": "8663kb",
          "version": "v6"
        },
        {
          "date": "2025-06-28T02:22:47+00:00",
          "link": "https://arxiv.org/abs/2407.01082v7",
          "size": "138kb",
          "version": "v7"
        }
      ],
      "title": "Turning Up the Heat: Min-p Sampling for Creative and Coherent LLM Outputs",
      "links": {
        "Abstract": "https://arxiv.org/abs/2407.01082",
        "HTML": "https://arxiv.org/html/2407.01082",
        "PDF": "https://arxiv.org/pdf/2407.01082"
      },
      "tasks": [
        "Diversity",
        "GSM8K",
        "Text Generation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2403.17512",
      "abstract": "Improving the efficiency of current neural networks and modeling them in biological neural systems have become popular research directions in recent years. Pulse-coupled neural network (PCNN) is a well applicated model for imitating the computation characteristics of the human brain in computer vision and neural network fields. However, differences between the PCNN and biological neural systems remain: limited neural connection, high computational cost, and lack of stochastic property. In this study, random-coupled neural network (RCNN) is proposed. It overcomes these difficulties in PCNN's neuromorphic computing via a random inactivation process. This process randomly closes some neural connections in the RCNN model, realized by the random inactivation weight matrix of link input. This releases the computational burden of PCNN, making it affordable to achieve vast neural connections. Furthermore, the image and video processing mechanisms of RCNN are researched. It encodes constant stimuli as periodic spike trains and periodic stimuli as chaotic spike trains, the same as biological neural information encoding characteristics. Finally, the RCNN is applicated to image segmentation, fusion, and pulse shape discrimination subtasks. It is demonstrated to be robust, efficient, and highly anti-noised, with outstanding performance in all applications mentioned above.",
      "authors": [
        "Haoran Liu and Mingzhe Liu and Peng Li and Jiahui Wu and Xin Jiang and Zhuo Zuo and Bingqi Liu"
      ],
      "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "subjects": [
        "Computer Vision and Pattern Recognition (cs.CV)"
      ],
      "submission_historys": [
        {
          "date": "2024-03-26T09:13:06+00:00",
          "link": "https://arxiv.org/abs/2403.17512v1",
          "size": "18049kb",
          "version": "v1"
        }
      ],
      "title": "Random-coupled Neural Network",
      "links": {
        "Abstract": "https://arxiv.org/abs/2403.17512",
        "HTML": "https://arxiv.org/html/2403.17512",
        "PDF": "https://arxiv.org/pdf/2403.17512"
      },
      "tasks": [
        "Image Segmentation",
        "Semantic Segmentation"
      ],
      "source": "arXiv"
    },
    {
      "id": "2502.08115",
      "abstract": "Presented study introduces a novel distributed cloud-edge framework for autonomous multi-UAV systems that combines the computational efficiency of neuromorphic computing with nature-inspired control strategies. The proposed architecture equips each UAV with an individual Spiking Neural Network (SNN) that learns to reproduce optimal control signals generated by a cloud-based controller, enabling robust operation even during communication interruptions. By integrating spike coding with nature-inspired control principles inspired by Tilapia fish territorial behavior, our system achieves sophisticated formation control and obstacle avoidance in complex urban environments. The distributed architecture leverages cloud computing for complex calculations while maintaining local autonomy through edge-based SNNs, significantly reducing energy consumption and computational overhead compared to traditional centralized approaches. Our framework addresses critical limitations of conventional methods, including the dependency on pre-modeled environments, computational intensity of traditional methods, and local minima issues in potential field approaches. Simulation results demonstrate the system's effectiveness across two different scenarios. First, the indoor deployment of a multi-UAV system made-up of 15 UAVs. Then the collision-free formation control of a moving UAV flock including 6 UAVs considering the obstacle avoidance. Owing to the sparsity of spiking patterns, and the event-based nature of SNNs in average for the whole group of UAVs, the framework achieves almost 90% reduction in computational burden compared to traditional von Neumann architectures implementing traditional artificial neural networks.",
      "authors": [
        "Reza Ahmadvand",
        "Sarah Safura Sharif",
        "Yaser Mike Banad"
      ],
      "license": "http://creativecommons.org/licenses/by/4.0/",
      "subjects": [
        "Neural and Evolutionary Computing (cs.NE)"
      ],
      "submission_historys": [
        {
          "date": "2025-02-12T04:36:53+00:00",
          "link": "https://arxiv.org/abs/2502.08115v1",
          "size": "870kb",
          "version": "v1"
        }
      ],
      "title": "Neuromorphic Digital-Twin-based Controller for Indoor Multi-UAV Systems Deployment",
      "links": {
        "Abstract": "https://arxiv.org/abs/2502.08115",
        "PDF": "https://arxiv.org/pdf/2502.08115"
      },
      "tasks": [
        "Cloud Computing",
        "Computational Efficiency"
      ],
      "source": "arXiv"
    },
    {
      "id": "2410.04098",
      "abstract": "This paper explores a structured application of the One-Class approach and the One-Class-One-Network model for supervised classification tasks, focusing on vowel phonemes classification and speakers recognition for the Automatic Speech Recognition (ASR) domain. For our case-study, the ASR model runs on a proprietary sensing and lightning system, exploited to monitor acoustic and air pollution on urban streets. We formalize combinations of pseudo-Neural Architecture Search and Hyper-Parameters Tuning experiments, using an informed grid-search methodology, to achieve classification accuracy comparable to nowadays most complex architectures, delving into the speaker recognition and energy efficiency aspects. Despite its simplicity, our model proposal has a very good chance to generalize the language and speaker genders context for widespread applicability in computational constrained contexts, proved by relevant statistical and performance metrics. Our experiments code is openly accessible on our GitHub.",
      "authors": [
        "Stefano Giacomelli",
        "Marco Giordano",
        "Claudia Rinaldi"
      ],
      "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
      "subjects": [
        "Sound (cs.SD)",
        "Artificial Intelligence (cs.AI)",
        "Audio and Speech Processing (eess.AS)"
      ],
      "submission_historys": [
        {
          "date": "2024-10-05T09:47:54+00:00",
          "link": "https://arxiv.org/abs/2410.04098v1",
          "size": "6589kb",
          "version": "v1"
        }
      ],
      "title": "The OCON model: an old but green solution for distributable supervised classification for acoustic monitoring in smart cities",
      "links": {
        "Abstract": "https://arxiv.org/abs/2410.04098",
        "HTML": "https://arxiv.org/html/2410.04098",
        "PDF": "https://arxiv.org/pdf/2410.04098"
      },
      "tasks": [
        "Automatic Speech Recognition",
        "Automatic Speech Recognition (ASR)",
        "Classification",
        "Neural Architecture Search",
        "Speaker Recognition",
        "speech-recognition",
        "Speech Recognition"
      ],
      "source": "arXiv"
    }
  ],
  "subjects": [
    "Geophysics (physics.geo-ph)",
    "Logic in Computer Science (cs.LO)",
    "Computer Vision and Pattern Recognition (cs.CV)",
    "Optics (physics.optics)",
    "Statistics Theory (stat.TH)",
    "Networking and Internet Architecture (cs.NI)",
    "Optimization and Control (math.OC)",
    "Multimedia (cs.MM)",
    "Quantum Physics (quant-ph)",
    "Physics and Society (physics.soc-ph)",
    "Computer Science and Game Theory (cs.GT)",
    "Populations and Evolution (q-bio.PE)",
    "Computational Engineering, Finance, and Science (cs.CE)",
    "Computation and Language (cs.CL)",
    "Databases (cs.DB)",
    "Image and Video Processing (eess.IV)",
    "Sound (cs.SD)",
    "Performance (cs.PF)",
    "Methodology (stat.ME)",
    "Instrumentation and Detectors (physics.ins-det)",
    "Systems and Control (eess.SY)",
    "Statistical Mechanics (cond-mat.stat-mech)",
    "Cryptography and Security (cs.CR)",
    "Robotics (cs.RO)",
    "Materials Science (cond-mat.mtrl-sci)",
    "Information Retrieval (cs.IR)",
    "Portfolio Management (q-fin.PM)",
    "Strongly Correlated Electrons (cond-mat.str-el)",
    "Artificial Intelligence (cs.AI)",
    "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
    "Computational Geometry (cs.CG)",
    "Atmospheric and Oceanic Physics (physics.ao-ph)",
    "Neurons and Cognition (q-bio.NC)",
    "Algebraic Topology (math.AT)",
    "Applications (stat.AP)",
    "Fluid Dynamics (physics.flu-dyn)",
    "Applied Physics (physics.app-ph)",
    "Adaptation and Self-Organizing Systems (nlin.AO)",
    "Analysis of PDEs (math.AP)",
    "Computational Complexity (cs.CC)",
    "Quantitative Methods (q-bio.QM)",
    "Logic (math.LO)",
    "Superconductivity (cond-mat.supr-con)",
    "Statistical Finance (q-fin.ST)",
    "History and Overview (math.HO)",
    "Systems and Control (cs.SY)",
    "Programming Languages (cs.PL)",
    "History and Philosophy of Physics (physics.hist-ph)",
    "Complex Variables (math.CV)",
    "Category Theory (math.CT)",
    "Mathematical Software (cs.MS)",
    "Symbolic Computation (cs.SC)",
    "Probability (math.PR)",
    "Space Physics (physics.space-ph)",
    "Information Theory (math.IT)",
    "Discrete Mathematics (cs.DM)",
    "Mathematical Physics (math.MP)",
    "Emerging Technologies (cs.ET)",
    "Medical Physics (physics.med-ph)",
    "Signal Processing (eess.SP)",
    "Number Theory (math.NT)",
    "Computation (stat.CO)",
    "Audio and Speech Processing (eess.AS)",
    "Other Computer Science (cs.OH)",
    "Social and Information Networks (cs.SI)",
    "Metric Geometry (math.MG)",
    "Chaotic Dynamics (nlin.CD)",
    "Combinatorics (math.CO)",
    "Machine Learning (stat.ML)",
    "Information Theory (cs.IT)",
    "Computers and Society (cs.CY)",
    "Mathematical Physics (math-ph)",
    "Biomolecules (q-bio.BM)",
    "Molecular Networks (q-bio.MN)",
    "Tissues and Organs (q-bio.TO)",
    "Other Statistics (stat.OT)",
    "Group Theory (math.GR)",
    "Functional Analysis (math.FA)",
    "Multiagent Systems (cs.MA)",
    "Numerical Analysis (cs.NA)",
    "Statistics Theory (math.ST)",
    "Hardware Architecture (cs.AR)",
    "Risk Management (q-fin.RM)",
    "Neural and Evolutionary Computing (cs.NE)",
    "Soft Condensed Matter (cond-mat.soft)",
    "Computational Physics (physics.comp-ph)",
    "Computational Finance (q-fin.CP)",
    "Software Engineering (cs.SE)",
    "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "Human-Computer Interaction (cs.HC)",
    "Econometrics (econ.EM)",
    "Data Structures and Algorithms (cs.DS)",
    "Theoretical Economics (econ.TH)",
    "Graphics (cs.GR)",
    "Digital Libraries (cs.DL)",
    "Algebraic Geometry (math.AG)",
    "Operating Systems (cs.OS)",
    "Machine Learning (cs.LG)",
    "General Economics (econ.GN)",
    "Chemical Physics (physics.chem-ph)",
    "Rings and Algebras (math.RA)",
    "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "Formal Languages and Automata Theory (cs.FL)",
    "Genomics (q-bio.GN)",
    "Dynamical Systems (math.DS)",
    "Numerical Analysis (math.NA)",
    "Economics (q-fin.EC)"
  ],
  "prompt": {
    "train_data": "\nYou are a computer science expert specializing in training data processing and data engineering for large language models (LLMs). You are skilled at identifying technical content in research papers that is related to **LLM training data**. I will provide you with a list of research papers from the arXiv (cs.\\*) domain.\n\n---\n\n### **Task Objective**\n\nFor each paper, determine whether it is directly related to the **processing of training data for LLMs**. Focus on identifying contributions in the following two areas:\n\n1. **Data Engineering Stage**:\n\n   * Includes tasks such as data collection, construction, cleaning, noise reduction, deduplication, filtering, format transformation, and data quality enhancement.\n\n2. **Training-Stage Data Processing**:\n\n   * Includes data preparation and processing for pre-training and post-training stages (e.g., fine-tuning, supervised fine-tuning (SFT), instruction tuning, etc.).\n\n---\n\n### **Relevance Level Classification Criteria**\n\n* `\"core\"`: The paper's primary contribution involves the design, construction, or processing of LLM training data\u2014for example, proposing a novel data pipeline, creating large-scale training data, or contributing new methods for improving data quality.\n* `\"partial\"`: The paper mentions data sources or preprocessing briefly in the background or experiments section, uses public datasets or existing tools, and does not propose new data-related methods.\n* `\"none-irrelevant\"`: The paper does not address any aspect of LLM training data collection, construction, or processing.\n\n---\n\n### **Output Format (strictly follow this JSON schema)**\n\n```json\n{\n  \"result\": [\n    {\n      \"id\": \"<paper id>\",\n      \"level\": \"core | partial | none-irrelevant\",\n      \"reason\": \"A 1-2 sentence explanation citing key parts of the abstract or methodology that justify the classification\"\n    }\n    // More papers...\n  ]\n}\n```\n"
  },
  "description": "Data source: https://arxiv.org/list/cs/new",
  "level_tatistics": {
    "null": 1545,
    "none-irrelevant": 13,
    "partial": 3
  },
  "arxiv_update_date": "2025-07-01"
}